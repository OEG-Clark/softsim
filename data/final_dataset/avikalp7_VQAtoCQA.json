{"home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel.__init__": [[48, 71], ["base_model.BaseModel.__init__", "image_models.Resnet"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__"], ["def", "__init__", "(", "self", ",", "model_name", ",", "is_trainable", ",", "config", "=", "None", ")", ":", "\n", "        ", "\"\"\"Call the BaseModel constructor, set common attributes\n\n        Parameters\n        ----------\n        :param model_name: ModelName Enum from global_hyperparams\n\n        :param config : dict, contains param name-value pairs for writing config file\n        \"\"\"", "\n", "# Call the BaseModel constructor", "\n", "super", "(", "ImageTextModel", ",", "self", ")", ".", "__init__", "(", "model_name", "=", "model_name", ",", "model_type", "=", "ModelType", ".", "image_text", ",", "config", "=", "config", ",", "\n", "is_trainable", "=", "is_trainable", ")", "\n", "# Construct the base image Resnet model", "\n", "self", ".", "base_image_model", "=", "Resnet", "(", "restore", "=", "False", ",", "is_trainable", "=", "False", ",", "train_last_block", "=", "TRAIN_RESNET_LAST_BLOCK", ")", "\n", "# Define some common class attributes", "\n", "self", ".", "base_text_model", "=", "None", "\n", "self", ".", "base_text_model_name", "=", "None", "\n", "self", ".", "base_image_model_name", "=", "self", ".", "base_image_model_name", "=", "self", ".", "base_image_model", ".", "model_name", "\n", "self", ".", "base_image_model_last_layer", "=", "None", "\n", "self", ".", "v_I", "=", "None", "\n", "self", ".", "v_T", "=", "None", "\n", "self", ".", "activation", "=", "None", "\n", "self", ".", "initializer_type", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel.restore_base_models": [[72, 105], ["paths.get_stored_checkpoint_filename", "tensorflow.train.Saver", "image_text_models.ImageTextModel.base_image_model.restore_model_from_filename", "paths.get_resnet_stored_filename", "tensorflow.train.Saver", "image_text_models.ImageTextModel.restore_model_from_filename", "ValueError", "tensorflow.global_variables", "tensorflow.global_variables", "v.name.split", "v.name.split", "v.name.split", "v.name.split"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.paths.get_stored_checkpoint_filename", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.restore_model_from_filename", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.paths.get_resnet_stored_filename", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.restore_model_from_filename"], ["", "def", "restore_base_models", "(", "self", ",", "sess", ")", ":", "\n", "        ", "\"\"\"Restore pretrained image model that forms a component of the full model\n\n        Raises\n        ------\n        ValueError: if self.config['base_image_model'] is neither of ModelName.image_cnn_v2 and ModelName.resnet\n        \"\"\"", "\n", "if", "self", ".", "config", "[", "'base_image_model'", "]", "==", "ModelName", ".", "image_cnn_v2", ":", "\n", "            ", "image_model_ckpt_filename", "=", "get_stored_checkpoint_filename", "(", "\n", "model_type", "=", "self", ".", "base_image_model", ".", "model_type", ",", "\n", "model_name", "=", "self", ".", "base_image_model", ".", "model_name", ",", "\n", "date", "=", "best_date", "[", "self", ".", "base_image_model", ".", "model_name", "]", ",", "\n", "num_epochs", "=", "best_epochs", "[", "self", ".", "base_image_model", ".", "model_name", "]", "\n", ")", "\n", "vars_to_restore", "=", "[", "v", "for", "v", "in", "tf", ".", "global_variables", "(", ")", "\n", "if", "v", ".", "name", ".", "split", "(", "'/'", ")", "[", "0", "]", "!=", "self", ".", "model_name", ".", "name", "\n", "and", "v", ".", "name", ".", "split", "(", "'/'", ")", "[", "0", "]", "!=", "self", ".", "base_text_model", ".", "model_name", ".", "name", "]", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "vars_to_restore", ")", "\n", "self", ".", "base_image_model", ".", "restore_model_from_filename", "(", "sess", "=", "sess", ",", "model_filename", "=", "image_model_ckpt_filename", ",", "\n", "saver", "=", "saver", ")", "\n", "", "elif", "self", ".", "config", "[", "'base_image_model'", "]", "==", "ModelName", ".", "resnet", ":", "\n", "            ", "resnet_ckpt_filename", "=", "get_resnet_stored_filename", "(", "file_type", "=", "'ckpt'", ",", "num_layers", "=", "RESNET_LAYERS", ")", "\n", "# vars with name not matching current model and it's base text model will all be resnet vars", "\n", "vars_to_restore", "=", "[", "v", "for", "v", "in", "tf", ".", "global_variables", "(", ")", "\n", "if", "v", ".", "name", ".", "split", "(", "'/'", ")", "[", "0", "]", "!=", "self", ".", "model_name", ".", "name", "\n", "and", "v", ".", "name", ".", "split", "(", "'/'", ")", "[", "0", "]", "!=", "self", ".", "base_text_model", ".", "model_name", ".", "name", "]", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "vars_to_restore", ")", "\n", "self", ".", "restore_model_from_filename", "(", "sess", ",", "model_filename", "=", "resnet_ckpt_filename", ",", "saver", "=", "saver", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unimplemented base_image_model\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._train_helper_SGD": [[106, 179], ["range", "print", "print", "image_text_models.ImageTextModel.early_stopping_procedure", "image_text_models.ImageTextModel._train_SGD_loop", "image_text_models.ImageTextModel._val_prediction_loop", "utils.training_epoch_finish_routine", "val_acc_history.append", "print", "max", "print", "print", "float", "sess.run"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.early_stopping_procedure", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel._train_SGD_loop", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel._val_prediction_loop", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.training_epoch_finish_routine"], ["", "", "def", "_train_helper_SGD", "(", "self", ",", "sess", ",", "train_writer", ",", "train_ids", ",", "train_labels", ",", "train_texts", ",", "\n", "val_ids", ",", "val_labels", ",", "val_texts", ",", "iterator_train_init", ",", "\n", "next_element_train", ",", "iterator_val_init", ",", "next_element_val", ")", ":", "\n", "        ", "\"\"\"Run mini-batch gradient descent on the training data\n\n        :param sess: tf.Session() object\n\n        :param train_writer: tf.summary.FileWriter object, file writer for TensorBoard\n\n        :param train_ids: np.array of shape [NUM_TRAIN_SAMPLES] and type int, containing Chiebukuro question ids\n\n        :param train_labels: np.array of shape [NUM_TRAIN_SAMPLES, NUM_CLASSES] of type bool,\n            containing category labels\n\n        :param train_texts: np.array of shape [NUM_TRAIN_SAMPLES, TEXT_LENGTH] of type int\n\n        :param val_ids: np.array of shape [NUM_VAL_SAMPLES] and type int\n\n        :param val_labels: np.array of shape [NUM_VAL_SAMPLES, NUM_CLASSES] and type bool\n\n        :param val_texts: np.array of shape [NUM_VAL_SAMPLES, TEXT_LENGTH] and type int\n\n        :param iterator_train_init: tf.contrib.data.TFRecordDataset.Iterator.initializeer object for train data\n\n        :param next_element_train: tf operation, on run generates next batch (using iterator.get_next())\n\n        :param iterator_val_init: tf.contrib.data.TFRecordDataset.Iterator.initializeer object for validation data\n\n        :param next_element_val: tf operation, on run generates next batch (using iterator.get_next())\n        \"\"\"", "\n", "text_train", ",", "text_val", "=", "train_texts", ",", "val_texts", "\n", "\n", "training_epochs", "=", "training_epochs_dict", "[", "self", ".", "model_type", "]", "\n", "\n", "# EARLY STOPPING VARS", "\n", "val_acc_history", "=", "[", "]", "\n", "epochs_with_current_lrate", "=", "0", "\n", "min_increment", "=", "0.0002", "\n", "tolerable_decrease", "=", "0.0004", "\n", "\n", "global_step", "=", "0", "\n", "for", "epoch", "in", "range", "(", "training_epochs", ")", ":", "\n", "# Decay learning rate if required", "\n", "            ", "early_stop", ",", "epochs_with_current_lrate", "=", "self", ".", "early_stopping_procedure", "(", "sess", ",", "\n", "epochs_with_current_lrate", ",", "\n", "val_acc_history", ",", "\n", "min_increment", ",", "tolerable_decrease", ")", "\n", "if", "early_stop", ":", "break", "\n", "\n", "# Running over full training data", "\n", "try", ":", "\n", "                ", "print", "(", "\"\\nCurrent learning rate: {}\"", ".", "format", "(", "sess", ".", "run", "(", "self", ".", "learning_rate", ")", ")", ")", "\n", "", "except", "TypeError", ":", "\n", "                ", "print", "(", "\"\\nCurrent learning rate: {}\"", ".", "format", "(", "self", ".", "learning_rate", ")", ")", "\n", "# Running training GD for this epoch", "\n", "", "global_step", "=", "self", ".", "_train_SGD_loop", "(", "sess", ",", "iterator_train_init", ",", "next_element_train", ",", "\n", "train_labels", ",", "text_train", ",", "train_writer", ",", "global_step", ")", "\n", "\n", "# Now performing validation", "\n", "num_val_samples", ",", "val_acc_sum", "=", "self", ".", "_val_prediction_loop", "(", "sess", ",", "iterator_val_init", ",", "\n", "next_element_val", ",", "val_labels", ",", "\n", "text_val", ",", "epoch", ")", "\n", "\n", "training_epoch_finish_routine", "(", "sess", ",", "val_acc_sum", ",", "num_val_samples", ",", "self", ".", "train_logfile_name", ",", "\n", "self", ".", "checkpoint_dir", ",", "epoch", ",", "self", ".", "saver", ")", "\n", "val_acc_history", ".", "append", "(", "val_acc_sum", "/", "float", "(", "num_val_samples", ")", ")", "\n", "print", "(", "'Previous Val Accs:'", ",", "val_acc_history", "[", "-", "10", ":", "]", ")", "\n", "epochs_with_current_lrate", "+=", "1", "\n", "\n", "# Completed all epochs", "\n", "", "print", "(", "'BEST VAL: '", ",", "max", "(", "val_acc_history", ")", ")", "\n", "# noinspection PyUnboundLocalVariable", "\n", "print", "(", "\"Completed training %s model, with %d epochs\"", "%", "(", "self", ".", "model_name", ".", "name", ",", "epoch", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._train_SGD_loop": [[180, 206], ["sess.run", "print", "int", "image_text_models.ImageTextModel._train_SGD_batch_step", "utils.update_train_batch", "sess.run", "len"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ResnetClf._train_SGD_batch_step", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.update_train_batch"], ["", "def", "_train_SGD_loop", "(", "self", ",", "sess", ",", "iterator_train_init", ",", "next_element_train", ",", "train_labels", ",", "text_train", ",", "\n", "train_writer", ",", "global_step", ")", ":", "\n", "        ", "\"\"\"Run the gradient descent loop over batches for this epoch\"\"\"", "\n", "# Initialize the iterator", "\n", "sess", ".", "run", "(", "iterator_train_init", ")", "\n", "# Initialize other book-keeping variables", "\n", "batch_size", "=", "batch_size_dict", "[", "self", ".", "model_type", "]", "\n", "total_batches", "=", "int", "(", "len", "(", "train_labels", ")", "/", "batch_size", ")", "+", "1", "\n", "batches_completed_this_epoch", "=", "0", "\n", "total_epoch_acc_val", "=", "0.", "\n", "print", "(", "\"*** TOTAL BATCHES: %d ***\"", "%", "total_batches", ")", "\n", "# Running over all mini-batches in this epoch", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "batch_image", ",", "_", ",", "batch_ids", "=", "sess", ".", "run", "(", "next_element_train", ")", "\n", "batches_completed_this_epoch", "+=", "1", "\n", "# Completed all minibatches in train set", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "\n", "", "S", ",", "loss_val", ",", "acc_val", "=", "self", ".", "_train_SGD_batch_step", "(", "sess", ",", "batch_image", ",", "train_labels", "[", "batch_ids", "]", ",", "\n", "batch_ids", ",", "text_train", ",", "batch_step", "=", "global_step", ")", "\n", "global_step", ",", "total_epoch_acc_val", "=", "update_train_batch", "(", "global_step", ",", "S", ",", "loss_val", ",", "acc_val", ",", "train_writer", ",", "\n", "total_epoch_acc_val", ",", "batches_completed_this_epoch", ")", "\n", "\n", "", "return", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._val_prediction_loop": [[207, 231], ["print", "sess.run", "int", "image_text_models.ImageTextModel._validation_batch_step", "utils.update_val_batch", "len", "sess.run", "len"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ResnetClf._validation_batch_step", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.update_val_batch"], ["", "def", "_val_prediction_loop", "(", "self", ",", "sess", ",", "iterator_val_init", ",", "next_element_val", ",", "val_labels", ",", "text_val", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Run prediction over all batches in the validation set\"\"\"", "\n", "print", "(", "\"\\nRunning on validation data for epoch number %d\"", "%", "(", "epoch", "+", "1", ")", ")", "\n", "\n", "batch_size", "=", "batch_size_dict", "[", "self", ".", "model_type", "]", "\n", "total_batches", "=", "int", "(", "len", "(", "val_labels", ")", "/", "batch_size", ")", "+", "1", "\n", "\n", "# Initialize the iterator and other book-keeping vars", "\n", "sess", ".", "run", "(", "iterator_val_init", ")", "\n", "val_acc_sum", "=", "0", "\n", "num_steps", "=", "0", "\n", "num_val_samples", "=", "0", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "batch_image", ",", "_", ",", "batch_ids", "=", "sess", ".", "run", "(", "next_element_val", ")", "\n", "# Completed all minibatches in validation set", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "\n", "", "val_acc", "=", "self", ".", "_validation_batch_step", "(", "sess", ",", "batch_image", ",", "val_labels", "[", "batch_ids", "]", ",", "batch_ids", ",", "text_val", ",", "\n", "batch_step", "=", "num_steps", ")", "\n", "val_acc_sum", ",", "num_steps", "=", "update_val_batch", "(", "num_steps", ",", "val_acc", ",", "val_acc_sum", ",", "total_batches", ")", "\n", "num_val_samples", "+=", "len", "(", "batch_ids", ")", "\n", "", "return", "num_val_samples", ",", "val_acc_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._run_tests": [[232, 268], ["print", "tensorflow.contrib.metrics.confusion_matrix", "sess.run", "utils.test_finish_routine", "float", "tensorflow.argmax", "image_text_models.ImageTextModel._test_batch_step", "utils.update_test_batch", "len", "sess.run", "list", "len"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.test_finish_routine", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ResnetClf._test_batch_step", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.update_test_batch"], ["", "def", "_run_tests", "(", "self", ",", "sess", ",", "test_ids", ",", "test_labels", ",", "test_texts", ",", "iterator_test_init", ",", "next_element_test", ")", ":", "\n", "        ", "text_test", "=", "test_texts", "\n", "\n", "print", "(", "\"\\nRunning test data through model ...\"", ")", "\n", "# Some required variables", "\n", "conf_matrix", "=", "None", "\n", "prediction", "=", "None", "\n", "test_accuracy", "=", "0.", "\n", "c_mat", "=", "tf", ".", "contrib", ".", "metrics", ".", "confusion_matrix", "(", "self", ".", "predictions", ",", "tf", ".", "argmax", "(", "self", ".", "labels_placeholder", ",", "1", ")", ",", "\n", "num_classes", "=", "NUM_CLASSES", ")", "\n", "\n", "total_batches", "=", "(", "len", "(", "test_labels", ")", "/", "batch_size_dict", "[", "self", ".", "model_type", "]", ")", "+", "1", "\n", "sess", ".", "run", "(", "iterator_test_init", ")", "\n", "batch_num", "=", "0", "\n", "total_samples", "=", "0", "\n", "all_batch_ids", "=", "[", "]", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "batch_image", ",", "_", ",", "batch_ids", "=", "sess", ".", "run", "(", "next_element_test", ")", "\n", "all_batch_ids", "+=", "list", "(", "batch_ids", ")", "\n", "total_samples", "+=", "len", "(", "batch_ids", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "# Completed all minibatches in test set", "\n", "                ", "break", "\n", "\n", "", "pred", ",", "mat", ",", "test_acc", "=", "self", ".", "_test_batch_step", "(", "sess", ",", "c_mat", ",", "\n", "batch_image", ",", "test_labels", "[", "batch_ids", "]", ",", "batch_ids", ",", "text_test", ")", "\n", "\n", "conf_matrix", ",", "prediction", ",", "test_accuracy", "=", "update_test_batch", "(", "batch_num", ",", "pred", ",", "mat", ",", "test_acc", ",", "conf_matrix", ",", "prediction", ",", "test_accuracy", ",", "total_batches", ")", "\n", "batch_num", "+=", "1", "\n", "\n", "", "labels", ",", "results", "=", "test_finish_routine", "(", "test_labels", "[", "all_batch_ids", "]", ",", "prediction", ")", "\n", "test_accuracy", "/=", "float", "(", "total_samples", ")", "\n", "\n", "return", "test_accuracy", ",", "labels", ",", "results", ",", "conf_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._run_validation_test": [[269, 274], ["image_text_models.ImageTextModel._val_prediction_loop", "print", "float"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel._val_prediction_loop"], ["", "def", "_run_validation_test", "(", "self", ",", "sess", ",", "val_ids", ",", "val_labels", ",", "val_texts", ",", "iterator_validation_init", ",", "next_element_val", ")", ":", "\n", "        ", "text_val", "=", "val_texts", "\n", "val_acc_sum", ",", "num_samples", "=", "self", ".", "_val_prediction_loop", "(", "sess", ",", "iterator_validation_init", ",", "next_element_val", ",", "\n", "val_labels", ",", "text_val", ",", "0", ")", "\n", "print", "(", "\"*** Validation accuracy: %0.4f ***\"", "%", "(", "val_acc_sum", "/", "float", "(", "num_samples", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._train_SGD_batch_step": [[275, 278], ["None"], "methods", ["None"], ["", "def", "_train_SGD_batch_step", "(", "self", ",", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_train", ",", "batch_step", "=", "None", ")", ":", "\n", "        ", "\"\"\" Abstract method \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._validation_batch_step": [[279, 282], ["None"], "methods", ["None"], ["", "def", "_validation_batch_step", "(", "self", ",", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_val", ",", "batch_step", "=", "None", ")", ":", "\n", "        ", "\"\"\" Abstact method \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._test_batch_step": [[283, 286], ["None"], "methods", ["None"], ["", "def", "_test_batch_step", "(", "self", ",", "sess", ",", "c_mat", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_test", ")", ":", "\n", "        ", "\"\"\" Abstract method \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._get_derived_image_representation_dimensions": [[287, 301], ["int"], "methods", ["None"], ["", "def", "_get_derived_image_representation_dimensions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Originally there was a choice between a from-scratch-image-cnn and ResNet,\n            leading to different derived dims\n\n        Returns\n        -------\n        image_dim: int, m if the spatial image representation is m*m\n\n        image_depth:int,  dimension for the embedding of each region\n        \"\"\"", "\n", "image_division_factor", "=", "16", "if", "self", ".", "base_image_model", ".", "model_name", "==", "ModelName", ".", "image_cnn_v2", "else", "32", "\n", "image_dim", "=", "int", "(", "IMAGE_SIZE", "/", "image_division_factor", ")", "\n", "image_depth", "=", "512", "if", "self", ".", "base_image_model", ".", "model_name", "==", "ModelName", ".", "image_cnn_v2", "else", "2048", "\n", "return", "image_dim", ",", "image_depth", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._dim_reduction_with_one_one_conv": [[302, 333], ["tensorflow.reshape", "network.weight_variable", "network.bias_variable", "network.batch_norm_conv_activation", "image_text_models.ImageTextModel.activation", "network.conv2d", "network.conv2d"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_conv_activation", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d"], ["", "def", "_dim_reduction_with_one_one_conv", "(", "self", ",", "image_dim", ",", "dim_D", ",", "dim_k", ",", "is_trainable", ")", ":", "\n", "        ", "\"\"\"Reduce a 4D tensor's last dimension using 1x1 convolutions\n\n        Parameters\n        ----------\n        :param image_dim: int, m if the spatial image representation is m*m\n\n        :param dim_D: int, last dimension\n\n        :param dim_k: int, dimension to which to reduce to\n\n        :param is_trainable: whether the convolution weights will be trainable\n\n        Returns\n        -------\n        conv_output: 4-d tensor, output of applying the convolution\n        \"\"\"", "\n", "f_I_spatial", "=", "tf", ".", "reshape", "(", "self", ".", "base_image_model_last_layer", ",", "\n", "shape", "=", "[", "-", "1", ",", "image_dim", ",", "image_dim", ",", "dim_D", "]", ",", "\n", "name", "=", "'f_I_spatial'", ")", "\n", "# [filter_size, filter_size, channel_size, num_filters]", "\n", "W_conv", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "1", ",", "1", ",", "dim_D", ",", "dim_k", "]", ",", "\n", "initializer_type", "=", "self", ".", "initializer_type", ")", "\n", "b_conv", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "dim_k", "]", ")", "\n", "if", "use_batch_norm", ":", "\n", "            ", "conv_output", "=", "batch_norm_conv_activation", "(", "is_trainable", "=", "is_trainable", ",", "\n", "inputs", "=", "conv2d", "(", "x", "=", "f_I_spatial", ",", "W", "=", "W_conv", ")", "+", "b_conv", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "activation", "=", "self", ".", "activation", ")", "\n", "", "else", ":", "\n", "            ", "conv_output", "=", "self", ".", "activation", "(", "conv2d", "(", "x", "=", "f_I_spatial", ",", "W", "=", "W_conv", ")", "+", "b_conv", ")", "\n", "", "return", "conv_output", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.EmbeddingConcatWithSemiFreeze.__init__": [[338, 458], ["network.get_initializer_type", "ValueError", "tensorflow.variable_scope", "image_text_models.ImageTextModel.__init__", "image_text_models.EmbeddingConcatWithSemiFreeze._get_derived_image_representation_dimensions", "print", "tensorflow.reshape", "tensorflow.reduce_mean", "int", "text_models.TextCNN", "ValueError", "tensorflow.nn.dropout", "tensorflow.variable_scope", "tensorflow.reshape", "tensorflow.nn.dropout", "tensorflow.variable_scope", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.variable_scope", "image_text_models.EmbeddingConcatWithSemiFreeze._set_predictions_optimizer_and_loss", "int", "int", "tensorflow.variable_scope", "image_text_models.EmbeddingConcatWithSemiFreeze._dim_reduction_with_one_one_conv", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.variable_scope", "network.standard_FC_layer", "tensorflow.reshape", "tensorflow.reshape", "int", "compact_bilinear_pooling_layer", "tensorflow.matmul", "tensorflow.variable_scope", "network.standard_FC_layer", "tensorflow.concat", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.get_initializer_type", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._get_derived_image_representation_dimensions", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._set_predictions_optimizer_and_loss", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._dim_reduction_with_one_one_conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.standard_FC_layer", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.standard_FC_layer"], ["def", "__init__", "(", "self", ",", "is_trainable", "=", "True", ",", "dim_k", "=", "2048", ")", ":", "\n", "        ", "\"\"\"Implement the model components\n\n        Parameters\n        ----------\n        :param is_trainable: bool, whether the model weights will be trainable\n\n        :param dim_k: int, the common dimension to which derived image & text embeddings are projected\n        \"\"\"", "\n", "\n", "self", ".", "model_name", "=", "ModelName", ".", "embedding_concat_semifreeze", "\n", "# Set use_simple_concat to True to implement Embedding-Concat", "\n", "# Set use_add_mul_concat to True to implement Add-Mul-Concat", "\n", "# Set use_MCB to True to use non attention-based MCB", "\n", "self", ".", "config", "=", "{", "\n", "'TRAIN_RESNET_LAST_BLOCK'", ":", "TRAIN_RESNET_LAST_BLOCK", ",", "\n", "'activation'", ":", "tf", ".", "nn", ".", "tanh", ",", "\n", "'base_text_model'", ":", "ModelName", ".", "text_cnn", ",", "\n", "'base_image_model'", ":", "ModelName", ".", "resnet", ",", "\n", "'base_text_activation'", ":", "tf", ".", "nn", ".", "relu", ",", "\n", "'base_text_filter_sizes'", ":", "(", "1", ",", "2", ",", "3", ")", ",", "\n", "'base_text_num_filters'", ":", "(", "128", ",", "256", ",", "256", ")", ",", "\n", "'use_conv_for_img_reduction'", ":", "True", ",", "\n", "'use_add_mul_concat'", ":", "True", ",", "\n", "'use_MCB'", ":", "False", ",", "\n", "'use_simple_concat'", ":", "False", ",", "\n", "}", "\n", "self", ".", "activation", "=", "self", ".", "config", "[", "'activation'", "]", "\n", "self", ".", "initializer_type", "=", "get_initializer_type", "(", "self", ".", "activation", ")", "\n", "self", ".", "base_text_model_name", "=", "self", ".", "config", "[", "'base_text_model'", "]", "\n", "self", ".", "base_image_model_last_layer", "=", "self", ".", "base_image_model", ".", "representation", "\n", "\n", "# Ensure that compact_bilinear_pooling module is present. See the github link at top", "\n", "if", "self", ".", "config", "[", "'use_MCB'", "]", "and", "compact_bilinear_pooling_layer", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"compact_bilinear_pooling_layer module not found. Can't implement MCB\"", ")", "\n", "\n", "# Ensure that configuration is properly set to just one of the models", "\n", "", "assert", "(", "int", "(", "self", ".", "config", "[", "'use_add_mul_concat'", "]", ")", "+", "int", "(", "self", ".", "config", "[", "'use_MCB'", "]", ")", "+", "\n", "int", "(", "self", ".", "config", "[", "'use_simple_concat'", "]", ")", "==", "1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "model_name", ".", "name", ")", ":", "\n", "            ", "super", "(", "EmbeddingConcatWithSemiFreeze", ",", "self", ")", ".", "__init__", "(", "model_name", "=", "self", ".", "model_name", ",", "config", "=", "self", ".", "config", ",", "\n", "is_trainable", "=", "is_trainable", ")", "\n", "if", "self", ".", "config", "[", "'base_text_model'", "]", "==", "ModelName", ".", "text_cnn", ":", "\n", "                ", "self", ".", "base_text_model", "=", "TextCNN", "(", "filter_sizes", "=", "self", ".", "config", "[", "'base_text_filter_sizes'", "]", ",", "\n", "num_filters", "=", "self", ".", "config", "[", "'base_text_num_filters'", "]", ",", "\n", "activation", "=", "self", ".", "config", "[", "'base_text_activation'", "]", ",", "\n", "is_trainable", "=", "is_trainable", ",", "\n", "is_primary_model", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"No other text model yet supported for %s model\"", "%", "self", ".", "model_name", ".", "name", ")", "\n", "\n", "# Deciding what dimensional image embedding we'd get depending on the base image model", "\n", "", "image_dim", ",", "image_depth", "=", "self", ".", "_get_derived_image_representation_dimensions", "(", ")", "\n", "dim_d", "=", "self", ".", "base_text_model", ".", "final_embedding_dimension", "\n", "dim_m", "=", "image_dim", "*", "image_dim", "\n", "dim_D", "=", "image_depth", "\n", "print", "(", "\"For EmbedConcat: dim_d = %d, dim_m = %d, dim_D = %d\"", "%", "(", "dim_d", ",", "dim_m", ",", "dim_D", ")", ")", "\n", "\n", "# If common dimension is different from derived image's dimension,", "\n", "# Apply transformation to bring it to dim_k", "\n", "if", "dim_D", "!=", "dim_k", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'dimD_to_dimk'", ")", ":", "\n", "                    ", "self", ".", "v_spI", "=", "self", ".", "_dim_reduction_with_one_one_conv", "(", "image_dim", ",", "dim_D", ",", "dim_k", ",", "is_trainable", ")", "\n", "v_spI_unfolded", "=", "tf", ".", "reshape", "(", "self", ".", "v_spI", ",", "shape", "=", "[", "-", "1", ",", "dim_m", ",", "dim_k", "]", ")", "\n", "self", ".", "v_I", "=", "tf", ".", "reduce_mean", "(", "v_spI_unfolded", ",", "axis", "=", "1", ")", "\n", "# Else if derived image dimension is same as common dimension, nothing to do", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "v_spI", "=", "self", ".", "base_image_model_last_layer", "\n", "\n", "# Derive the flat embedding from the spatial representation", "\n", "", "v_spI_unfolded", "=", "tf", ".", "reshape", "(", "self", ".", "v_spI", ",", "shape", "=", "[", "-", "1", ",", "dim_m", ",", "dim_k", "]", ",", "name", "=", "'v_spI_unfolded'", ")", "\n", "self", ".", "v_I", "=", "tf", ".", "reduce_mean", "(", "v_spI_unfolded", ",", "axis", "=", "1", ")", "\n", "\n", "if", "self", ".", "config", "[", "'use_dropout_on_init_embeddings'", "]", ":", "\n", "                ", "self", ".", "v_I", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "v_I", ",", "self", ".", "dropout_keep_prob", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"Init_Ques_Emb\"", ")", ":", "\n", "# v_T -> [B, dim_d]", "\n", "                ", "self", ".", "v_T", "=", "tf", ".", "reshape", "(", "self", ".", "base_text_model", ".", "h_pool", ",", "shape", "=", "[", "-", "1", ",", "dim_d", "]", ")", "\n", "self", ".", "v_T", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "v_T", ",", "self", ".", "dropout_keep_prob", ")", "\n", "\n", "# If common dimension is different from derived text's dimension,", "\n", "# Apply transformation to bring it to dim_k", "\n", "", "if", "dim_d", "!=", "dim_k", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'FCLayer_TextDim_to_dimk'", ")", ":", "\n", "                    ", "self", ".", "v_T", "=", "standard_FC_layer", "(", "self", ".", "v_T", ",", "dim_d", ",", "dim_k", ",", "use_batch_norm", ",", "self", ".", "activation", ",", "\n", "self", ".", "train_mode", ",", "is_trainable", ",", "self", ".", "dropout_keep_prob", ",", "'text'", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"Concat\"", ")", ":", "\n", "                ", "if", "self", ".", "config", "[", "'use_MCB'", "]", ":", "\n", "                    ", "text_embed", "=", "tf", ".", "reshape", "(", "self", ".", "v_T", ",", "shape", "=", "[", "-", "1", ",", "1", ",", "1", ",", "dim_k", "]", ")", "\n", "image_embed", "=", "tf", ".", "reshape", "(", "self", ".", "v_I", ",", "shape", "=", "[", "-", "1", ",", "1", ",", "1", ",", "dim_k", "]", ")", "\n", "embed_dim_big", "=", "dim_k", "*", "4", "\n", "embed_dim", "=", "int", "(", "dim_k", "/", "2", ")", "\n", "# noinspection PyCallingNonCallable", "\n", "mcb_out", "=", "compact_bilinear_pooling_layer", "(", "bottom1", "=", "text_embed", ",", "\n", "bottom2", "=", "image_embed", ",", "\n", "output_dim", "=", "embed_dim_big", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"MCB_FC\"", ")", ":", "\n", "                        ", "self", ".", "embed_concat", "=", "standard_FC_layer", "(", "mcb_out", ",", "embed_dim_big", ",", "embed_dim", ",", "use_batch_norm", ",", "\n", "self", ".", "activation", ",", "self", ".", "train_mode", ",", "is_trainable", ",", "\n", "self", ".", "dropout_keep_prob", ",", "name_suffix", "=", "'mcb_fc'", ")", "\n", "", "", "elif", "self", ".", "config", "[", "'use_simple_concat'", "]", ":", "\n", "                    ", "self", ".", "embed_concat", "=", "tf", ".", "concat", "(", "(", "self", ".", "v_I", ",", "self", ".", "v_T", ")", ",", "axis", "=", "1", ")", "\n", "embed_dim", "=", "dim_k", "*", "2", "\n", "", "else", ":", "\n", "                    ", "self", ".", "embed_add", "=", "self", ".", "v_I", "+", "self", ".", "v_T", "\n", "self", ".", "embed_mul", "=", "self", ".", "v_I", "*", "self", ".", "v_T", "\n", "self", ".", "embed_concat", "=", "tf", ".", "concat", "(", "(", "self", ".", "embed_add", ",", "self", ".", "embed_mul", ")", ",", "axis", "=", "1", ")", "\n", "embed_dim", "=", "dim_k", "*", "2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"softmax\"", ")", ":", "\n", "                ", "W_u", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "embed_dim", ",", "NUM_CLASSES", "]", ",", "name", "=", "'W_u'", ")", "\n", "b_u", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "NUM_CLASSES", "]", ",", "name", "=", "'b_u'", ")", "\n", "self", ".", "scores", "=", "tf", ".", "matmul", "(", "self", ".", "embed_concat", ",", "W_u", ")", "+", "b_u", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"optimization\"", ")", ":", "\n", "# Finalize the predictions, the optimizing function, loss/accuracy stats etc.", "\n", "                ", "self", ".", "_set_predictions_optimizer_and_loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.EmbeddingConcatWithSemiFreeze._train_SGD_batch_step": [[459, 478], ["sess.run", "utils.text_batch_from_ids"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.text_batch_from_ids"], ["", "", "", "def", "_train_SGD_batch_step", "(", "self", ",", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_train", ",", "train_mode", "=", "True", ",", "\n", "batch_step", "=", "1", ")", ":", "\n", "        ", "\"\"\"Run the TF's graph to perform GD over the current batch\"\"\"", "\n", "S", ",", "_", ",", "loss_val", ",", "acc_val", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "train_summary_op", ",", "self", ".", "train_op", ",", "self", ".", "loss", ",", "self", ".", "accuracy", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "0.5", ",", "\n", "self", ".", "base_image_model", ".", "images_placeholder", ":", "batch_image", ",", "\n", "self", ".", "base_image_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "base_text_model", ".", "texts_placeholder", ":", "text_batch_from_ids", "(", "batch_ids", ",", "text_data", "=", "text_train", ")", ",", "\n", "self", ".", "base_text_model", ".", "embedding_dropout", ":", "0.3", ",", "\n", "self", ".", "base_text_model", ".", "embedding_noise_std", ":", "0.01", ",", "\n", "self", ".", "base_text_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "base_text_model", ".", "phase_train", ":", "train_mode", "\n", "}", ")", "\n", "\n", "return", "S", ",", "loss_val", ",", "acc_val", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.EmbeddingConcatWithSemiFreeze._validation_batch_step": [[479, 497], ["sess.run", "utils.text_batch_from_ids"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.text_batch_from_ids"], ["", "def", "_validation_batch_step", "(", "self", ",", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_val", ",", "train_mode", "=", "False", ",", "\n", "batch_step", "=", "1", ")", ":", "\n", "        ", "val_acc", "=", "sess", ".", "run", "(", "\n", "self", ".", "sum_accuracy", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "1.", ",", "\n", "self", ".", "base_image_model", ".", "images_placeholder", ":", "batch_image", ",", "\n", "self", ".", "base_image_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "base_text_model", ".", "texts_placeholder", ":", "text_batch_from_ids", "(", "batch_ids", ",", "text_data", "=", "text_val", ")", ",", "\n", "self", ".", "base_text_model", ".", "embedding_dropout", ":", "0.", ",", "\n", "self", ".", "base_text_model", ".", "embedding_noise_std", ":", "0.", ",", "\n", "self", ".", "base_text_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "base_text_model", ".", "phase_train", ":", "train_mode", "\n", "}", ")", "\n", "\n", "return", "val_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.EmbeddingConcatWithSemiFreeze._test_batch_step": [[498, 516], ["sess.run", "utils.text_batch_from_ids"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.text_batch_from_ids"], ["", "def", "_test_batch_step", "(", "self", ",", "sess", ",", "c_mat", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_test", ",", "\n", "train_mode", "=", "False", ")", ":", "\n", "        ", "pred", ",", "mat", ",", "test_acc", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "probabilities", ",", "c_mat", ",", "self", ".", "sum_accuracy", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "1.", ",", "\n", "self", ".", "base_image_model", ".", "images_placeholder", ":", "batch_image", ",", "\n", "self", ".", "base_image_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "base_text_model", ".", "texts_placeholder", ":", "text_batch_from_ids", "(", "batch_ids", ",", "text_data", "=", "text_test", ")", ",", "\n", "self", ".", "base_text_model", ".", "embedding_dropout", ":", "0.", ",", "\n", "self", ".", "base_text_model", ".", "embedding_noise_std", ":", "0.", ",", "\n", "self", ".", "base_text_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "base_text_model", ".", "phase_train", ":", "train_mode", "\n", "}", ")", "\n", "\n", "return", "pred", ",", "mat", ",", "test_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.StackedAttentionWithSemiFreezeCNN.__init__": [[519, 623], ["network.get_initializer_type", "tensorflow.variable_scope", "image_text_models.ImageTextModel.__init__", "image_text_models.StackedAttentionWithSemiFreezeCNN._get_derived_image_representation_dimensions", "sum", "print", "text_models.TextCNN", "ValueError", "tensorflow.variable_scope", "image_text_models.StackedAttentionWithSemiFreezeCNN._dim_reduction_with_one_one_conv", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.reshape", "tensorflow.nn.dropout", "tensorflow.variable_scope", "range", "tensorflow.variable_scope", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.variable_scope", "image_text_models.StackedAttentionWithSemiFreezeCNN._set_predictions_optimizer_and_loss", "tensorflow.variable_scope", "network.standard_FC_layer", "image_text_models.StackedAttentionWithSemiFreezeCNN._stack_attention_layer", "tensorflow.concat", "tensorflow.matmul"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.get_initializer_type", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._get_derived_image_representation_dimensions", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._dim_reduction_with_one_one_conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._set_predictions_optimizer_and_loss", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.standard_FC_layer", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.StackedAttentionWithSemiFreezeCNN._stack_attention_layer"], ["    ", "def", "__init__", "(", "self", ",", "nlayers", "=", "1", ",", "dim_k", "=", "1024", ",", "dim_att", "=", "512", ",", "is_trainable", "=", "True", ")", ":", "\n", "        ", "\"\"\"Contruct the SAN model, with options for model w/ and w/o global image weight\n\n        * Implement the SAN layer-1 and layer-2 according to passed argument\n\n        * Implement the global image weight model according to config\n\n        Parameters\n        ----------\n        :param nlayers: int, number of stacked layers in the network\n\n        :param dim_k: int, the common dimension for image and text representations\n\n        :param dim_att: int, the dimensions of the attention layer representation\n\n        :param is_trainable: bool, whether weights of the model can be updated\n        \"\"\"", "\n", "self", ".", "model_name", "=", "ModelName", ".", "stacked_attention_with_semi_freeze_cnn", "\n", "self", ".", "config", "=", "{", "\n", "'TRAIN_RESNET_LAST_BLOCK'", ":", "TRAIN_RESNET_LAST_BLOCK", ",", "\n", "'activation'", ":", "tf", ".", "nn", ".", "tanh", ",", "\n", "'base_text_model'", ":", "ModelName", ".", "text_cnn", ",", "\n", "'base_image_model'", ":", "ModelName", ".", "resnet", ",", "\n", "'base_text_activation'", ":", "tf", ".", "nn", ".", "relu", ",", "\n", "'base_text_filter_sizes'", ":", "(", "1", ",", "2", ",", "3", ")", ",", "\n", "'base_text_num_filters'", ":", "(", "128", ",", "256", ",", "256", ")", ",", "\n", "'num_layers'", ":", "nlayers", ",", "\n", "'dim_k'", ":", "dim_att", ",", "\n", "'include_global_image_wt'", ":", "False", ",", "\n", "'use_prod_in_embed'", ":", "True", ",", "\n", "}", "\n", "self", ".", "activation", "=", "self", ".", "config", "[", "'activation'", "]", "\n", "self", ".", "initializer_type", "=", "get_initializer_type", "(", "self", ".", "activation", ")", "\n", "self", ".", "base_text_model_name", "=", "self", ".", "config", "[", "'base_text_model'", "]", "\n", "self", ".", "base_image_model_last_layer", "=", "self", ".", "base_image_model", ".", "representation", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "model_name", ".", "name", ")", ":", "\n", "            ", "super", "(", "StackedAttentionWithSemiFreezeCNN", ",", "self", ")", ".", "__init__", "(", "model_name", "=", "self", ".", "model_name", ",", "\n", "config", "=", "self", ".", "config", ",", "\n", "is_trainable", "=", "is_trainable", ")", "\n", "\n", "# Construct the base text model", "\n", "if", "self", ".", "config", "[", "'base_text_model'", "]", "==", "ModelName", ".", "text_cnn", ":", "\n", "                ", "self", ".", "base_text_model", "=", "TextCNN", "(", "filter_sizes", "=", "self", ".", "config", "[", "'base_text_filter_sizes'", "]", ",", "\n", "num_filters", "=", "self", ".", "config", "[", "'base_text_num_filters'", "]", ",", "\n", "activation", "=", "self", ".", "config", "[", "'base_text_activation'", "]", ",", "\n", "is_trainable", "=", "is_trainable", ",", "\n", "is_primary_model", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"No other text model yet supported for %s model\"", "%", "self", ".", "model_name", ".", "name", ")", "\n", "\n", "# Deciding what dimensional image embedding we'd get depending on the base image model", "\n", "", "image_dim", ",", "image_depth", "=", "self", ".", "_get_derived_image_representation_dimensions", "(", ")", "\n", "text_embedding_dimension", "=", "sum", "(", "self", ".", "config", "[", "'base_text_num_filters'", "]", ")", "\n", "dim_d", "=", "text_embedding_dimension", "\n", "dim_m", "=", "image_dim", "*", "image_dim", "\n", "dim_D", "=", "image_depth", "\n", "print", "(", "\"For Stacked CNN: dim_d = %d, dim_m = %d, dim_D = %d\"", "%", "(", "dim_d", ",", "dim_m", ",", "dim_D", ")", ")", "\n", "\n", "# Convert f_I of dimensions [B*dim_m, dim_D] to v_I of dimensions [B*dim_m, dim_d]", "\n", "with", "tf", ".", "variable_scope", "(", "'dimD_to_dimk'", ")", ":", "\n", "                ", "self", ".", "v_spI", "=", "self", ".", "_dim_reduction_with_one_one_conv", "(", "image_dim", ",", "dim_D", ",", "dim_k", ",", "is_trainable", ")", "\n", "v_spI_unfolded", "=", "tf", ".", "reshape", "(", "self", ".", "v_spI", ",", "shape", "=", "[", "-", "1", ",", "dim_m", ",", "dim_k", "]", ")", "\n", "self", ".", "v_I", "=", "tf", ".", "reduce_mean", "(", "v_spI_unfolded", ",", "axis", "=", "1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"Init_Ques_Emb\"", ")", ":", "\n", "# v_Q -> [B, dim_d]", "\n", "                ", "self", ".", "v_T", "=", "tf", ".", "reshape", "(", "self", ".", "base_text_model", ".", "h_pool", ",", "\n", "shape", "=", "[", "-", "1", ",", "self", ".", "base_text_model", ".", "final_embedding_dimension", "]", ")", "\n", "self", ".", "v_T", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "v_T", ",", "self", ".", "dropout_keep_prob", ")", "\n", "self", ".", "u", "=", "[", "None", "]", "*", "(", "nlayers", "+", "1", ")", "\n", "self", ".", "u", "[", "0", "]", "=", "self", ".", "v_T", "\n", "\n", "", "if", "dim_d", "!=", "dim_k", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'FCLayer_TextDim_to_dimk'", ")", ":", "\n", "                    ", "self", ".", "u", "[", "0", "]", "=", "standard_FC_layer", "(", "self", ".", "u", "[", "0", "]", ",", "dim_d", ",", "dim_k", ",", "\n", "use_batch_norm", ",", "self", ".", "activation", ",", "self", ".", "train_mode", ",", "\n", "is_trainable", ",", "self", ".", "dropout_keep_prob", ",", "'text'", ")", "\n", "\n", "", "", "uprod", "=", "None", "\n", "with", "tf", ".", "variable_scope", "(", "\"stacked_attention\"", ")", ":", "\n", "                ", "for", "layer_num", "in", "range", "(", "nlayers", ")", ":", "\n", "                    ", "self", ".", "u", "[", "layer_num", "+", "1", "]", ",", "uprod", "=", "self", ".", "_stack_attention_layer", "(", "v_Q", "=", "self", ".", "u", "[", "layer_num", "]", ",", "\n", "layer_num", "=", "(", "layer_num", "+", "1", ")", ",", "\n", "v_spI", "=", "self", ".", "v_spI", ",", "dim_k", "=", "dim_k", ",", "\n", "dim_m", "=", "dim_m", ",", "dim_att", "=", "dim_att", ",", "\n", "is_trainable", "=", "is_trainable", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"final_embedding\"", ")", ":", "\n", "                ", "if", "self", ".", "config", "[", "'use_prod_in_embed'", "]", ":", "\n", "                    ", "self", ".", "final_embedding", "=", "tf", ".", "concat", "(", "(", "self", ".", "u", "[", "nlayers", "]", ",", "uprod", ")", ",", "axis", "=", "1", ",", "name", "=", "'final_embedding'", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "final_embedding", "=", "self", ".", "u", "[", "nlayers", "]", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"softmax\"", ")", ":", "\n", "                ", "W_u", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "\n", "shape", "=", "[", "self", ".", "final_embedding", ".", "shape", "[", "1", "]", ".", "value", ",", "NUM_CLASSES", "]", ",", "\n", "name", "=", "'W_u'", ")", "\n", "b_u", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "NUM_CLASSES", "]", ",", "name", "=", "'b_u'", ")", "\n", "self", ".", "scores", "=", "tf", ".", "matmul", "(", "self", ".", "final_embedding", ",", "W_u", ")", "+", "b_u", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"optimization\"", ")", ":", "\n", "# Finalize the predictions, the optimizing function, loss/accuracy stats etc.", "\n", "                ", "self", ".", "_set_predictions_optimizer_and_loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.StackedAttentionWithSemiFreezeCNN._stack_attention_layer": [[624, 738], ["tensorflow.variable_scope", "network.weight_variable", "network.weight_variable", "network.bias_variable", "tensorflow.nn.xw_plus_b", "tensorflow.expand_dims", "tensorflow.reshape", "tensorflow.nn.dropout", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.softmax", "tensorflow.reshape", "tensorflow.variable_scope", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.variable_scope", "tensorflow.matmul", "tensorflow.reshape", "network.batch_norm_dense_activation", "image_text_models.StackedAttentionWithSemiFreezeCNN.activation", "tensorflow.reshape", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.xw_plus_b", "tensorflow.nn.dropout", "tensorflow.expand_dims", "tensorflow.reshape", "tensorflow.concat", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.nn.xw_plus_b", "network.batch_norm_dense_activation", "image_text_models.StackedAttentionWithSemiFreezeCNN.activation"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_dense_activation", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_dense_activation"], ["", "", "", "def", "_stack_attention_layer", "(", "self", ",", "v_Q", ",", "layer_num", ",", "v_spI", ",", "dim_k", ",", "dim_m", ",", "dim_att", ",", "is_trainable", ")", ":", "\n", "        ", "\"\"\"Implement the attention layer in SAN\n\n        Parameters\n        ----------\n        :param v_Q: tensor, derived text embedding of shape [B, dim_k]\n\n        :param layer_num: int, the 0-indexed layer number\n\n        :param v_spI: tensor, derived spatial image representation of shape [B*dim_m, dim_k]\n\n        :param dim_k: int, the dimension of derived image and text representations\n\n        :param dim_m: int, the number of regions in the image\n\n        :param dim_att: int, the attention layer dimension\n\n        :param is_trainable: bool, whether the weights are trainable\n\n        Returns\n        -------\n        u_sum: Vt + Vi, of shape [B, dim_k]\n        u_prod: Vt * Vi, of shape [B, dim_k]\n        \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "'FCLayer_Attention_%d'", "%", "layer_num", ")", ":", "\n", "            ", "W_IA", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "dim_k", ",", "dim_att", "]", ",", "\n", "initializer_type", "=", "self", ".", "initializer_type", ",", "name", "=", "'W_IA'", ")", "\n", "W_QA", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "dim_k", ",", "dim_att", "]", ",", "\n", "initializer_type", "=", "self", ".", "initializer_type", ",", "name", "=", "'W_QA'", ")", "\n", "b_A", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "dim_att", "]", ",", "name", "=", "'b_A'", ")", "\n", "\n", "# question_prod -> [B, dim_att]", "\n", "question_prod", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "x", "=", "v_Q", ",", "weights", "=", "W_QA", ",", "biases", "=", "b_A", ",", "name", "=", "'question_prod_%d'", "%", "layer_num", ")", "\n", "# question_prod -> [B, 1, dim_att]", "\n", "question_prod", "=", "tf", ".", "expand_dims", "(", "input", "=", "question_prod", ",", "axis", "=", "1", ")", "\n", "\n", "v_spI_dash", "=", "None", "\n", "if", "self", ".", "config", "[", "'include_global_image_wt'", "]", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'global_image_wt_%d'", "%", "layer_num", ")", ":", "\n", "                    ", "W_fb", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "dim_k", ",", "dim_k", "]", ",", "\n", "initializer_type", "=", "self", ".", "initializer_type", ",", "name", "=", "'W_fb'", ")", "\n", "b_fb", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "dim_k", "]", ",", "name", "=", "'b_fb'", ")", "\n", "# text_feature shape -> [B, dim_k]", "\n", "v_T_dash", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "x", "=", "v_Q", ",", "weights", "=", "W_fb", ",", "biases", "=", "b_fb", ",", "name", "=", "'text_feature'", ")", "\n", "\n", "if", "use_batch_norm", ":", "\n", "                        ", "v_T_dash", "=", "batch_norm_dense_activation", "(", "v_T_dash", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "\n", "activation", "=", "self", ".", "activation", ",", "\n", "is_trainable", "=", "is_trainable", ")", "\n", "", "else", ":", "\n", "                        ", "v_T_dash", "=", "self", ".", "activation", "(", "v_T_dash", ")", "\n", "\n", "", "v_T_dash", "=", "tf", ".", "nn", ".", "dropout", "(", "v_T_dash", ",", "self", ".", "dropout_keep_prob", ")", "\n", "v_T_dash_unrolled", "=", "tf", ".", "expand_dims", "(", "v_T_dash", ",", "axis", "=", "1", ")", "\n", "v_spI_unrolled", "=", "tf", ".", "reshape", "(", "v_spI", ",", "shape", "=", "[", "-", "1", ",", "dim_m", ",", "dim_k", "]", ")", "\n", "# [B, dim_m + 1, dim_k]", "\n", "v_spI_dash_unrolled", "=", "tf", ".", "concat", "(", "(", "v_spI_unrolled", ",", "v_T_dash_unrolled", ")", ",", "axis", "=", "1", ")", "\n", "# [B * (dim_m + 1), dim_k]", "\n", "v_spI_dash", "=", "tf", ".", "reshape", "(", "v_spI_dash_unrolled", ",", "shape", "=", "[", "-", "1", ",", "dim_k", "]", ")", "\n", "# [B * (dim_m + 1), dim_att]", "\n", "image_prod", "=", "tf", ".", "matmul", "(", "v_spI_dash", ",", "W_IA", ")", "\n", "# image_prod_unrolled -> [B, dim_m+1, dim_att]", "\n", "image_prod_unrolled", "=", "tf", ".", "reshape", "(", "image_prod", ",", "shape", "=", "[", "-", "1", ",", "dim_m", "+", "1", ",", "dim_k", "]", ")", "\n", "new_dim_m", "=", "dim_m", "+", "1", "\n", "", "", "else", ":", "\n", "# image_prod -> [B*dim_m, dim_att]", "\n", "                ", "image_prod", "=", "tf", ".", "matmul", "(", "v_spI", ",", "W_IA", ")", "\n", "# image_prod_unrolled -> [B, dim_m, dim_att]", "\n", "image_prod_unrolled", "=", "tf", ".", "reshape", "(", "image_prod", ",", "shape", "=", "[", "-", "1", ",", "dim_m", ",", "dim_k", "]", ")", "\n", "new_dim_m", "=", "dim_m", "\n", "\n", "# image_question_prod_sum -> [B*dim_m(+1), dim_k]", "\n", "", "image_question_prod_sum", "=", "tf", ".", "reshape", "(", "image_prod_unrolled", "+", "question_prod", ",", "shape", "=", "[", "-", "1", ",", "dim_att", "]", ")", "\n", "\n", "# h_A -> [B*dim_m(+1), dim_k]", "\n", "if", "use_batch_norm", ":", "\n", "                ", "h_A", "=", "batch_norm_dense_activation", "(", "inputs", "=", "image_question_prod_sum", ",", "activation", "=", "self", ".", "activation", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "is_trainable", "=", "is_trainable", ")", "\n", "", "else", ":", "\n", "                ", "h_A", "=", "self", ".", "activation", "(", "image_question_prod_sum", ")", "\n", "", "h_A_drop", "=", "tf", ".", "nn", ".", "dropout", "(", "h_A", ",", "self", ".", "dropout_keep_prob", ")", "\n", "# h_A_drop_folded -> [B*dim_m(+1), dim_att]", "\n", "h_A_drop_folded", "=", "h_A_drop", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Softmax_Attention_%d'", "%", "layer_num", ")", ":", "\n", "            ", "W_P", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "dim_att", ",", "1", "]", ",", "name", "=", "'W_P'", ")", "\n", "b_P", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "1", "]", ")", "\n", "p_I_unfolded", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "reshape", "(", "tf", ".", "nn", ".", "xw_plus_b", "(", "x", "=", "h_A_drop_folded", ",", "\n", "weights", "=", "W_P", ",", "\n", "biases", "=", "b_P", ")", ",", "\n", "shape", "=", "[", "-", "1", ",", "new_dim_m", "]", ")", ")", "\n", "# p_I -> [B*dim_m(+1), 1]", "\n", "p_I", "=", "tf", ".", "reshape", "(", "p_I_unfolded", ",", "shape", "=", "[", "-", "1", ",", "1", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Attention_Weighting_%d'", "%", "layer_num", ")", ":", "\n", "# v_I_weighted -> [B*dim_m(+1), dim_k]", "\n", "            ", "if", "self", ".", "config", "[", "'include_global_image_wt'", "]", ":", "\n", "                ", "v_I_weighted", "=", "v_spI_dash", "*", "p_I", "\n", "", "else", ":", "\n", "                ", "v_I_weighted", "=", "v_spI", "*", "p_I", "\n", "\n", "", "v_I_weighted", "=", "tf", ".", "reshape", "(", "v_I_weighted", ",", "\n", "shape", "=", "[", "-", "1", ",", "new_dim_m", ",", "dim_k", "]", ",", "\n", "name", "=", "'v_I_weighted_%d'", "%", "layer_num", ")", "\n", "# v_I_cap -> [B, dim_k]", "\n", "v_I_cap", "=", "tf", ".", "reduce_sum", "(", "v_I_weighted", ",", "axis", "=", "1", ",", "name", "=", "'v_I_cap_%d'", "%", "layer_num", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'New_Query_%d'", "%", "layer_num", ")", ":", "\n", "# u -> [B, dim_k]", "\n", "            ", "u_sum", "=", "v_I_cap", "+", "v_Q", "\n", "u_prod", "=", "v_I_cap", "*", "v_Q", "\n", "\n", "", "return", "u_sum", ",", "u_prod", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.StackedAttentionWithSemiFreezeCNN._train_SGD_batch_step": [[739, 757], ["sess.run", "utils.text_batch_from_ids"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.text_batch_from_ids"], ["", "def", "_train_SGD_batch_step", "(", "self", ",", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_train", ",", "train_mode", "=", "True", ",", "\n", "batch_step", "=", "1", ")", ":", "\n", "        ", "S", ",", "_", ",", "loss_val", ",", "acc_val", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "train_summary_op", ",", "self", ".", "train_op", ",", "self", ".", "loss", ",", "self", ".", "accuracy", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "0.5", ",", "\n", "self", ".", "base_image_model", ".", "images_placeholder", ":", "batch_image", ",", "\n", "self", ".", "base_image_model", ".", "train_mode", ":", "False", ",", "\n", "self", ".", "base_text_model", ".", "texts_placeholder", ":", "text_batch_from_ids", "(", "batch_ids", ",", "text_data", "=", "text_train", ")", ",", "\n", "self", ".", "base_text_model", ".", "embedding_dropout", ":", "0.3", ",", "\n", "self", ".", "base_text_model", ".", "embedding_noise_std", ":", "0.01", ",", "\n", "self", ".", "base_text_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "base_text_model", ".", "phase_train", ":", "train_mode", ",", "\n", "}", ")", "\n", "\n", "return", "S", ",", "loss_val", ",", "acc_val", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.StackedAttentionWithSemiFreezeCNN._validation_batch_step": [[758, 776], ["sess.run", "utils.text_batch_from_ids"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.text_batch_from_ids"], ["", "def", "_validation_batch_step", "(", "self", ",", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_val", ",", "train_mode", "=", "False", ",", "\n", "batch_step", "=", "1", ")", ":", "\n", "        ", "val_acc", "=", "sess", ".", "run", "(", "\n", "self", ".", "sum_accuracy", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "1.", ",", "\n", "self", ".", "base_image_model", ".", "images_placeholder", ":", "batch_image", ",", "\n", "self", ".", "base_image_model", ".", "train_mode", ":", "True", ",", "\n", "self", ".", "base_text_model", ".", "texts_placeholder", ":", "text_batch_from_ids", "(", "batch_ids", ",", "text_data", "=", "text_val", ")", ",", "\n", "self", ".", "base_text_model", ".", "embedding_dropout", ":", "0.", ",", "\n", "self", ".", "base_text_model", ".", "embedding_noise_std", ":", "0.", ",", "\n", "self", ".", "base_text_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "base_text_model", ".", "phase_train", ":", "train_mode", ",", "\n", "}", ")", "\n", "\n", "return", "val_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.StackedAttentionWithSemiFreezeCNN._test_batch_step": [[777, 795], ["sess.run", "utils.text_batch_from_ids"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.text_batch_from_ids"], ["", "def", "_test_batch_step", "(", "self", ",", "sess", ",", "c_mat", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_test", ",", "\n", "train_mode", "=", "False", ")", ":", "\n", "        ", "pred", ",", "mat", ",", "test_acc", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "probabilities", ",", "c_mat", ",", "self", ".", "sum_accuracy", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "1.", ",", "\n", "self", ".", "base_image_model", ".", "images_placeholder", ":", "batch_image", ",", "\n", "self", ".", "base_image_model", ".", "train_mode", ":", "True", ",", "\n", "self", ".", "base_text_model", ".", "texts_placeholder", ":", "text_batch_from_ids", "(", "batch_ids", ",", "text_data", "=", "text_test", ")", ",", "\n", "self", ".", "base_text_model", ".", "embedding_dropout", ":", "0.", ",", "\n", "self", ".", "base_text_model", ".", "embedding_noise_std", ":", "0.", ",", "\n", "self", ".", "base_text_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "base_text_model", ".", "phase_train", ":", "train_mode", ",", "\n", "}", ")", "\n", "\n", "return", "pred", ",", "mat", ",", "test_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.AuxTaskModel.__init__": [[798, 912], ["network.get_initializer_type", "image_text_models.AuxTaskModel._load_aux_data", "tensorflow.variable_scope", "image_text_models.ImageTextModel.__init__", "tensorflow.placeholder", "tensorflow.placeholder", "image_text_models.AuxTaskModel._get_derived_image_representation_dimensions", "sum", "print", "text_models.TextCNN", "ValueError", "tensorflow.variable_scope", "image_text_models.AuxTaskModel._dim_reduction_with_one_one_conv", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.reshape", "tensorflow.nn.dropout", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.reshape", "tensorflow.variable_scope", "network.standard_FC_layer", "tensorflow.expand_dims", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.reshape", "tensorflow.variable_scope", "network.standard_conv_layer", "tensorflow.variable_scope", "network.standard_conv_layer", "tensorflow.variable_scope", "tensorflow.reshape", "tensorflow.nn.softmax", "tensorflow.variable_scope", "image_text_models.AuxTaskModel._set_aux_predictions_optimizer_and_loss"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.get_initializer_type", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.AuxTaskModel._load_aux_data", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._get_derived_image_representation_dimensions", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._dim_reduction_with_one_one_conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.standard_FC_layer", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.standard_conv_layer", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.standard_conv_layer", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.AuxTaskModel._set_aux_predictions_optimizer_and_loss"], ["    ", "def", "__init__", "(", "self", ",", "dim_k", "=", "1024", ",", "dim_att", "=", "256", ",", "is_trainable", "=", "True", ",", "is_primary_model", "=", "True", ")", ":", "\n", "        ", "self", ".", "model_name", "=", "ModelName", ".", "aux_task_model", "\n", "self", ".", "config", "=", "{", "\n", "'TRAIN_RESNET_LAST_BLOCK'", ":", "TRAIN_RESNET_LAST_BLOCK", ",", "\n", "'activation'", ":", "tf", ".", "nn", ".", "tanh", ",", "\n", "'base_text_model'", ":", "ModelName", ".", "text_cnn", ",", "\n", "'base_image_model'", ":", "ModelName", ".", "resnet", ",", "\n", "'base_text_activation'", ":", "tf", ".", "nn", ".", "relu", ",", "\n", "'base_text_filter_sizes'", ":", "(", "1", ",", "2", ",", "3", ")", ",", "\n", "'base_text_num_filters'", ":", "(", "128", ",", "256", ",", "256", ")", ",", "\n", "'embedding_size_multiplier'", ":", "1.5", ",", "\n", "'dim_k'", ":", "dim_k", ",", "\n", "'dim_att'", ":", "dim_att", ",", "\n", "'use_prod_in_embed'", ":", "True", ",", "\n", "}", "\n", "self", ".", "activation", "=", "self", ".", "config", "[", "'activation'", "]", "\n", "self", ".", "initializer_type", "=", "get_initializer_type", "(", "self", ".", "activation", ")", "\n", "self", ".", "base_text_model_name", "=", "self", ".", "config", "[", "'base_text_model'", "]", "\n", "self", ".", "base_image_model_last_layer", "=", "self", ".", "base_image_model", ".", "representation", "\n", "\n", "# Load the train and validation data if in train mode, and test data if in test mode", "\n", "self", ".", "_load_aux_data", "(", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "model_name", ".", "name", ")", ":", "\n", "            ", "super", "(", "AuxTaskModel", ",", "self", ")", ".", "__init__", "(", "model_name", "=", "self", ".", "model_name", ",", "config", "=", "self", ".", "config", ",", "\n", "is_trainable", "=", "is_trainable", ")", "\n", "\n", "# Define model specific placeholders", "\n", "self", ".", "aux_labels_placeholder", "=", "tf", ".", "placeholder", "(", "dtype", "=", "\"float\"", ",", "shape", "=", "[", "None", ",", "NUM_TEXT_IN_MULTI_CHOICE", "]", ",", "\n", "name", "=", "'aux_labels_placeholder'", ")", "\n", "# Whether the task is image-to-texts mathcing, or text-to-images matching", "\n", "self", ".", "image_to_texts_bool_placeholder", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "bool", ",", "name", "=", "'image_to_texts_bool_placeholder'", ")", "\n", "\n", "self", ".", "aux_probabilities", "=", "None", "\n", "\n", "if", "self", ".", "config", "[", "'base_text_model'", "]", "==", "ModelName", ".", "text_cnn", ":", "\n", "                ", "self", ".", "base_text_model", "=", "TextCNN", "(", "filter_sizes", "=", "self", ".", "config", "[", "'base_text_filter_sizes'", "]", ",", "\n", "num_filters", "=", "self", ".", "config", "[", "'base_text_num_filters'", "]", ",", "\n", "activation", "=", "self", ".", "config", "[", "'base_text_activation'", "]", ",", "\n", "is_trainable", "=", "is_trainable", ",", "\n", "is_primary_model", "=", "False", ",", "\n", "embed_size_multiplier", "=", "self", ".", "config", "[", "'embedding_size_multiplier'", "]", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"No other text model yet supported for %s model\"", "%", "self", ".", "model_name", ".", "name", ")", "\n", "\n", "# Deciding what dimensional image embedding we'd get depending on the base image model", "\n", "", "image_dim", ",", "image_depth", "=", "self", ".", "_get_derived_image_representation_dimensions", "(", ")", "\n", "text_embedding_dimension", "=", "sum", "(", "self", ".", "config", "[", "'base_text_num_filters'", "]", ")", "\n", "dim_d", "=", "text_embedding_dimension", "\n", "dim_m", "=", "image_dim", "*", "image_dim", "\n", "dim_D", "=", "image_depth", "\n", "print", "(", "\"For Stacked CNN: dim_d = %d, dim_m = %d, dim_D = %d\"", "%", "(", "dim_d", ",", "dim_m", ",", "dim_D", ")", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'dimD_to_dimk'", ")", ":", "\n", "                ", "self", ".", "v_spI", "=", "self", ".", "_dim_reduction_with_one_one_conv", "(", "image_dim", ",", "dim_D", ",", "dim_k", ",", "is_trainable", ")", "\n", "v_spI_unfolded", "=", "tf", ".", "reshape", "(", "self", ".", "v_spI", ",", "shape", "=", "[", "-", "1", ",", "dim_m", ",", "dim_k", "]", ")", "\n", "self", ".", "v_I", "=", "tf", ".", "reduce_mean", "(", "v_spI_unfolded", ",", "axis", "=", "1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"Init_Ques_Emb\"", ")", ":", "\n", "# v_T -> [B(*N), dim_d]", "\n", "                ", "self", ".", "v_T", "=", "tf", ".", "reshape", "(", "self", ".", "base_text_model", ".", "h_pool", ",", "\n", "shape", "=", "[", "-", "1", ",", "self", ".", "base_text_model", ".", "final_embedding_dimension", "]", ")", "\n", "self", ".", "v_T", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "v_T", ",", "self", ".", "dropout_keep_prob", ",", "name", "=", "'v_T'", ")", "\n", "\n", "", "if", "dim_d", "!=", "dim_k", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'FCLayer_TextDim_to_dimk'", ")", ":", "\n", "                    ", "self", ".", "v_T", "=", "standard_FC_layer", "(", "self", ".", "v_T", ",", "dim_d", ",", "dim_k", ",", "use_batch_norm", ",", "self", ".", "activation", ",", "\n", "self", ".", "train_mode", ",", "is_trainable", ",", "self", ".", "dropout_keep_prob", ",", "'text'", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"add_mul_concat\"", ")", ":", "\n", "# If the aux task is image-to-texts, we tile the image", "\n", "                ", "if", "self", ".", "image_to_texts_bool_placeholder", ":", "\n", "# v_I_expanded -> [B(*N), 1, dim_k]", "\n", "                    ", "v_I_expanded", "=", "tf", ".", "expand_dims", "(", "self", ".", "v_I", ",", "axis", "=", "1", ")", "\n", "# v_T_unfoled -> [B, NUM_TEXT_IN_MULTI_CHOICE, dim_k]", "\n", "v_T_unfolded", "=", "tf", ".", "reshape", "(", "self", ".", "v_T", ",", "shape", "=", "[", "-", "1", ",", "NUM_TEXT_IN_MULTI_CHOICE", ",", "dim_k", "]", ")", "\n", "self", ".", "embedding_add", "=", "v_I_expanded", "+", "v_T_unfolded", "\n", "self", ".", "embedding_mul", "=", "v_I_expanded", "*", "v_T_unfolded", "\n", "# Else if the aux task is text-to-images, we tile the text", "\n", "", "else", ":", "\n", "# v_T_expanded -> [B(*N), 1, dim_k]", "\n", "                    ", "v_T_expanded", "=", "tf", ".", "expand_dims", "(", "self", ".", "v_T", ",", "axis", "=", "1", ")", "\n", "# v_I_unfolded -> [B, NUM_TEXT_IN_MULTI_CHOICE, dim_k]", "\n", "v_I_unfolded", "=", "tf", ".", "reshape", "(", "self", ".", "v_I", ",", "shape", "=", "[", "-", "1", ",", "NUM_TEXT_IN_MULTI_CHOICE", ",", "dim_k", "]", ")", "\n", "self", ".", "embedding_add", "=", "v_T_expanded", "+", "v_I_unfolded", "\n", "self", ".", "embedding_mul", "=", "v_T_expanded", "*", "v_I_unfolded", "\n", "\n", "# embedding_concat -> [B, NUM_TEXT_IN_MULTI_CHOICE, 2*tdim]", "\n", "", "self", ".", "embedding_concat", "=", "tf", ".", "concat", "(", "values", "=", "(", "self", ".", "embedding_add", ",", "self", ".", "embedding_mul", ")", ",", "\n", "axis", "=", "2", ",", "\n", "name", "=", "\"embedding_concat\"", ")", "\n", "# embedding_concat_4dtensor -> [B, NUM_TEXT_IN_MULTI_CHOICE, 1, 2*tdim]", "\n", "self", ".", "embedding_concat_4dtensor", "=", "tf", ".", "reshape", "(", "self", ".", "embedding_concat", ",", "\n", "shape", "=", "[", "-", "1", ",", "NUM_TEXT_IN_MULTI_CHOICE", ",", "1", ",", "2", "*", "dim_k", "]", ",", "\n", "name", "=", "\"embedding_concat_4dtensor\"", ")", "\n", "self", ".", "final_embedding", "=", "self", ".", "embedding_concat_4dtensor", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"conv_layer_1\"", ")", ":", "\n", "                    ", "filter_shape", "=", "[", "1", ",", "1", ",", "2", "*", "dim_k", "if", "self", ".", "config", "[", "'use_prod_in_embed'", "]", "else", "dim_k", ",", "256", "]", "\n", "h_conv1", "=", "standard_conv_layer", "(", "self", ".", "final_embedding", ",", "filter_shape", ",", "self", ".", "activation", ",", "\n", "use_batch_norm", ",", "self", ".", "train_mode", ",", "is_trainable", ",", "'conv1'", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"conv_layer_2\"", ")", ":", "\n", "                    ", "filter_shape", "=", "[", "1", ",", "1", ",", "256", ",", "1", "]", "\n", "h_conv2", "=", "standard_conv_layer", "(", "h_conv1", ",", "filter_shape", ",", "self", ".", "activation", ",", "\n", "use_batch_norm", ",", "self", ".", "train_mode", ",", "is_trainable", ",", "'conv2'", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"conv_softmax_output\"", ")", ":", "\n", "                    ", "h_conv_out", "=", "tf", ".", "reshape", "(", "h_conv2", ",", "shape", "=", "[", "-", "1", ",", "NUM_TEXT_IN_MULTI_CHOICE", "]", ",", "name", "=", "'h_conv_out'", ")", "\n", "self", ".", "aux_probabilities", "=", "tf", ".", "nn", ".", "softmax", "(", "h_conv_out", ",", "name", "=", "\"aux_probabilities\"", ")", "\n", "\n", "", "", "if", "is_primary_model", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"optimization\"", ")", ":", "\n", "                    ", "self", ".", "_set_aux_predictions_optimizer_and_loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.AuxTaskModel._load_aux_data": [[913, 936], ["numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load"], "methods", ["None"], ["", "", "", "", "def", "_load_aux_data", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "trainable", ":", "\n", "            ", "self", ".", "aux_train_labels", "=", "np", ".", "load", "(", "data_directory", "+", "image_match_data_subdirectory", "+", "'train_new_labels%d%s.npy'", "\n", "%", "(", "NUM_CLASSES", ",", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "\n", "self", ".", "aux_text_train_ids", "=", "np", ".", "load", "(", "data_directory", "+", "image_match_data_subdirectory", "+", "'train_text_ids%d%s.npy'", "\n", "%", "(", "NUM_CLASSES", ",", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "\n", "self", ".", "aux_val_labels", "=", "np", ".", "load", "(", "data_directory", "+", "image_match_data_subdirectory", "+", "'val_new_labels%d%s.npy'", "\n", "%", "(", "NUM_CLASSES", ",", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "\n", "self", ".", "aux_text_val_ids", "=", "np", ".", "load", "(", "data_directory", "+", "image_match_data_subdirectory", "+", "'val_text_ids%d%s.npy'", "\n", "%", "(", "NUM_CLASSES", ",", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "aux_train_labels", ",", "self", ".", "aux_text_train_ids", ",", "self", ".", "aux_val_labels", ",", "self", ".", "aux_text_val_ids", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "self", ".", "aux_test_labels", "=", "np", ".", "load", "(", "data_directory", "+", "image_match_data_subdirectory", "+", "'test_new_labels%d%s.npy'", "\n", "%", "(", "NUM_CLASSES", ",", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "\n", "self", ".", "aux_text_test_ids", "=", "np", ".", "load", "(", "data_directory", "+", "image_match_data_subdirectory", "+", "'test_text_ids%d%s.npy'", "\n", "%", "(", "NUM_CLASSES", ",", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.AuxTaskModel._set_aux_predictions_optimizer_and_loss": [[937, 1016], ["tensorflow.argmax", "tensorflow.get_collection", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.global_variables", "tensorflow.train.Saver", "tensorflow.summary.merge", "print", "tensorflow.Variable", "tensorflow.variable_scope", "tensorflow.constant", "tensorflow.train.exponential_decay", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.control_dependencies", "tensorflow.train.AdamOptimizer", "image_text_models.AuxTaskModel.optimizer.minimize", "tensorflow.variable_scope", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.constant", "tensorflow.constant", "tensorflow.summary.FileWriter", "tensorflow.reduce_sum", "int", "tensorflow.train.piecewise_constant", "tensorflow.train.AdamOptimizer", "tensorflow.argmax", "tensorflow.cast", "tensorflow.cast", "tensorflow.get_default_graph", "int", "tensorflow.cast", "tensorflow.Variable", "tensorflow.train.RMSPropOptimizer", "ValueError", "tensorflow.log", "tensorflow.clip_by_value"], "methods", ["None"], ["", "", "def", "_set_aux_predictions_optimizer_and_loss", "(", "self", ")", ":", "\n", "        ", "self", ".", "aux_predictions", "=", "tf", ".", "argmax", "(", "self", ".", "aux_probabilities", ",", "1", ",", "name", "=", "\"aux_predictions\"", ")", "\n", "\n", "if", "self", ".", "trainable", ":", "\n", "            ", "self", ".", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "dtype", "=", "tf", ".", "int32", ",", "trainable", "=", "False", ",", "name", "=", "'global_step'", ")", "\n", "\n", "# Calculate mean cross-entropy loss", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"loss\"", ")", ":", "\n", "            ", "self", ".", "aux_loss", "=", "-", "tf", ".", "reduce_sum", "(", "\n", "self", ".", "aux_labels_placeholder", "*", "tf", ".", "log", "(", "tf", ".", "clip_by_value", "(", "self", ".", "aux_probabilities", ",", "1e-10", ",", "1.0", ")", ")", ",", "\n", "name", "=", "'aux_loss'", ")", "\n", "self", ".", "loss", "=", "tf", ".", "constant", "(", "0.", ",", "dtype", "=", "\"float\"", ",", "name", "=", "'dummy_loss'", ")", "\n", "self", ".", "total_loss", "=", "self", ".", "aux_loss", "\n", "\n", "", "if", "decay_learning_rate", ":", "\n", "            ", "self", ".", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "self", ".", "learning_rate", ",", "self", ".", "global_step", ",", "\n", "3000", ",", "0.90", ",", "staircase", "=", "True", ")", "\n", "", "elif", "scale_learning_rate", ":", "\n", "            ", "initial_learning_rate", "=", "self", ".", "learning_rate", "*", "batch_size_dict", "[", "self", ".", "model_type", "]", "/", "256.", "\n", "batches_per_epoch", "=", "int", "(", "NUM_IMAGES", "[", "'train'", "]", "/", "batch_size_dict", "[", "self", ".", "model_type", "]", ")", "\n", "# Multiply the learning rate by 0.5 at 2, 4, 80, and 90 epochs.", "\n", "boundaries", "=", "[", "\n", "int", "(", "batches_per_epoch", "*", "epoch", ")", "for", "epoch", "in", "scale_epochs_dict", "[", "self", ".", "model_type", "]", "]", "\n", "values", "=", "[", "\n", "initial_learning_rate", "*", "scale", "for", "scale", "in", "scale_factors_dict", "[", "self", ".", "model_type", "]", "]", "\n", "self", ".", "learning_rate", "=", "tf", ".", "train", ".", "piecewise_constant", "(", "\n", "tf", ".", "cast", "(", "self", ".", "global_step", ",", "tf", ".", "int32", ")", ",", "boundaries", ",", "values", ")", "\n", "\n", "", "elif", "early_stopping_learning_rate", ":", "\n", "            ", "self", ".", "learning_rate", "=", "tf", ".", "Variable", "(", "self", ".", "learning_rate", ",", "trainable", "=", "False", ",", "name", "=", "'learning_rate_var'", ")", "\n", "\n", "", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ",", "scope", "=", "self", ".", "model_name", ".", "name", ")", "\n", "\n", "if", "self", ".", "base_image_model", ".", "model_name", "==", "ModelName", ".", "image_cnn_v2", "and", "self", ".", "config", "[", "'train_image_last_layers'", "]", ":", "\n", "            ", "imgcnn_update_ops1", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ",", "scope", "=", "'image_conv_8'", ")", "\n", "imgcnn_update_ops2", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ",", "scope", "=", "'image_conv_7'", ")", "\n", "imgcnn_update_ops3", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ",", "scope", "=", "'image_conv_6'", ")", "\n", "update_ops", "=", "update_ops", "+", "imgcnn_update_ops1", "+", "imgcnn_update_ops2", "+", "imgcnn_update_ops3", "\n", "\n", "", "with", "tf", ".", "control_dependencies", "(", "update_ops", ")", ":", "\n", "# Define Training procedure", "\n", "            ", "if", "OPTIMIZER", "==", "OptimizerType", ".", "adam", ":", "\n", "                ", "self", ".", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "learning_rate", ")", "\n", "", "elif", "OPTIMIZER", "==", "OptimizerType", ".", "rms_optimizer", ":", "\n", "                ", "self", ".", "optimizer", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "learning_rate", "=", "self", ".", "learning_rate", ",", "\n", "momentum", "=", "OPTIMIZER_MOMENTUM", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Invalid value for OPTIMIZER var\"", ")", "\n", "\n", "", "self", ".", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "learning_rate", ")", "\n", "self", ".", "train_op", "=", "self", ".", "optimizer", ".", "minimize", "(", "self", ".", "total_loss", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "\n", "# Calculate Accuracy", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"accuracy\"", ")", ":", "\n", "            ", "self", ".", "aux_correct_predictions", "=", "tf", ".", "equal", "(", "self", ".", "aux_predictions", ",", "tf", ".", "argmax", "(", "self", ".", "aux_labels_placeholder", ",", "1", ")", ")", "\n", "self", ".", "aux_accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "self", ".", "aux_correct_predictions", ",", "\"float\"", ")", ",", "name", "=", "\"aux_accuracy\"", ")", "\n", "self", ".", "aux_sum_accuracy", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "cast", "(", "self", ".", "aux_correct_predictions", ",", "\"float\"", ")", ",", "\n", "name", "=", "\"aux_sum_accuracy\"", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "constant", "(", "0.", ",", "name", "=", "\"dummy_accuracy\"", ")", "\n", "self", ".", "sum_accuracy", "=", "tf", ".", "constant", "(", "0.", ",", "name", "=", "\"dummy_sum_accuracy\"", ")", "\n", "\n", "# Summaries for loss and accuracy", "\n", "", "self", ".", "loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "\"loss\"", ",", "self", ".", "loss", ")", "\n", "self", ".", "acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "\"accuracy\"", ",", "self", ".", "accuracy", ")", "\n", "self", ".", "aux_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "\"aux_loss\"", ",", "self", ".", "aux_loss", ")", "\n", "self", ".", "aux_accuracy_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "\"aux_accuracy\"", ",", "self", ".", "aux_accuracy", ")", "\n", "\n", "vars_to_restore", "=", "tf", ".", "global_variables", "(", ")", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "vars_to_restore", ",", "max_to_keep", "=", "None", ")", "\n", "\n", "# Train Summaries at Tensorboard", "\n", "self", ".", "train_summary_op", "=", "tf", ".", "summary", ".", "merge", "(", "[", "self", ".", "loss_summary", ",", "self", ".", "acc_summary", ",", "self", ".", "aux_loss_summary", ",", "\n", "self", ".", "aux_accuracy_summary", "]", ")", "\n", "\n", "if", "self", ".", "is_primary_model", ":", "\n", "# Define the file writer for tensorboard", "\n", "            ", "self", ".", "train_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "self", ".", "train_log_dir", "+", "\"train_tensorboard\"", ",", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "", "print", "(", "'Completed %s object construction.'", "%", "self", ".", "model_name", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.AuxTaskModel._train_SGD_batch_step": [[1017, 1038], ["utils.text_batch_from_ids", "sess.run", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.text_batch_from_ids"], ["", "def", "_train_SGD_batch_step", "(", "self", ",", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_train", ",", "train_mode", "=", "True", ",", "\n", "batch_step", "=", "1", ")", ":", "\n", "        ", "multi_choice_text", "=", "text_batch_from_ids", "(", "np", ".", "reshape", "(", "self", ".", "aux_text_train_ids", "[", "batch_ids", "]", ",", "-", "1", ")", ",", "\n", "text_data", "=", "text_train", ")", "\n", "S", ",", "_", ",", "loss_val", ",", "acc_val", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "train_summary_op", ",", "self", ".", "train_op", ",", "self", ".", "aux_loss", ",", "self", ".", "aux_accuracy", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "base_image_model", ".", "images_placeholder", ":", "batch_image", ",", "\n", "self", ".", "base_image_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "aux_labels_placeholder", ":", "self", ".", "aux_train_labels", "[", "batch_ids", "]", ",", "\n", "self", ".", "dropout_keep_prob", ":", "0.5", ",", "\n", "self", ".", "base_text_model", ".", "dropout_keep_prob", ":", "0.5", ",", "\n", "self", ".", "base_text_model", ".", "texts_placeholder", ":", "multi_choice_text", ",", "\n", "self", ".", "base_text_model", ".", "embedding_dropout", ":", "0.3", ",", "\n", "self", ".", "base_text_model", ".", "embedding_noise_std", ":", "0.01", ",", "\n", "self", ".", "base_text_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "base_text_model", ".", "phase_train", ":", "train_mode", ",", "\n", "}", ")", "\n", "\n", "return", "S", ",", "loss_val", ",", "acc_val", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.AuxTaskModel._validation_batch_step": [[1039, 1060], ["utils.text_batch_from_ids", "sess.run", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.text_batch_from_ids"], ["", "def", "_validation_batch_step", "(", "self", ",", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_val", ",", "train_mode", "=", "False", ",", "\n", "batch_step", "=", "None", ")", ":", "\n", "        ", "multi_choice_text", "=", "text_batch_from_ids", "(", "np", ".", "reshape", "(", "self", ".", "aux_text_val_ids", "[", "batch_ids", "]", ",", "-", "1", ")", ",", "\n", "text_data", "=", "text_val", ")", "\n", "val_aux_acc", "=", "sess", ".", "run", "(", "\n", "self", ".", "aux_sum_accuracy", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "base_image_model", ".", "images_placeholder", ":", "batch_image", ",", "\n", "self", ".", "base_image_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "aux_labels_placeholder", ":", "self", ".", "aux_val_labels", "[", "batch_ids", "]", ",", "\n", "self", ".", "dropout_keep_prob", ":", "1.", ",", "\n", "self", ".", "base_text_model", ".", "dropout_keep_prob", ":", "1.", ",", "\n", "self", ".", "base_text_model", ".", "texts_placeholder", ":", "multi_choice_text", ",", "\n", "self", ".", "base_text_model", ".", "embedding_dropout", ":", "0.", ",", "\n", "self", ".", "base_text_model", ".", "embedding_noise_std", ":", "0.", ",", "\n", "self", ".", "base_text_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "base_text_model", ".", "phase_train", ":", "train_mode", ",", "\n", "}", ")", "\n", "\n", "return", "val_aux_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.AuxTaskModel._test_batch_step": [[1061, 1064], ["None"], "methods", ["None"], ["", "def", "_test_batch_step", "(", "self", ",", "sess", ",", "c_mat", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_test", ")", ":", "\n", "# No test set for auxiliary tasks", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.HieCoAtt.__init__": [[1074, 1197], ["network.get_initializer_type", "tensorflow.variable_scope", "image_text_models.ImageTextModel.__init__", "text_models.HieText", "image_text_models.HieCoAtt._get_derived_image_representation_dimensions", "print", "image_text_models.HieCoAtt._co_attention", "image_text_models.HieCoAtt._co_attention", "image_text_models.HieCoAtt._co_attention", "tensorflow.variable_scope", "image_text_models.HieCoAtt._dim_reduction_with_one_one_conv", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.xw_plus_b", "tensorflow.nn.xw_plus_b", "tensorflow.nn.xw_plus_b", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.dropout", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.dropout", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "activation", "tensorflow.nn.dropout", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "network.batch_norm_dense_activation", "activation", "network.batch_norm_dense_activation", "activation", "tensorflow.nn.xw_plus_b", "tensorflow.name_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.xw_plus_b", "tensorflow.variable_scope", "image_text_models.HieCoAtt._set_predictions_optimizer_and_loss", "tensorflow.nn.xw_plus_b", "tensorflow.nn.xw_plus_b", "tensorflow.nn.xw_plus_b", "tensorflow.nn.xw_plus_b", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.get_initializer_type", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._get_derived_image_representation_dimensions", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.HieCoAtt._co_attention", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.HieCoAtt._co_attention", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.HieCoAtt._co_attention", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.ImageTextModel._dim_reduction_with_one_one_conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_dense_activation", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_dense_activation", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._set_predictions_optimizer_and_loss"], ["def", "__init__", "(", "self", ",", "is_primary_model", ",", "is_trainable", ",", "dim_k", "=", "256", ")", ":", "\n", "        ", "self", ".", "model_name", "=", "ModelName", ".", "hie_co_att", "\n", "self", ".", "config", "=", "{", "\n", "'TRAIN_RESNET_LAST_BLOCK'", ":", "TRAIN_RESNET_LAST_BLOCK", ",", "\n", "'activation'", ":", "tf", ".", "nn", ".", "tanh", ",", "\n", "'base_image_model'", ":", "ModelName", ".", "resnet", ",", "\n", "'base_text_activation'", ":", "tf", ".", "nn", ".", "tanh", ",", "\n", "'base_text_filter_sizes'", ":", "(", "1", ",", "2", ",", "3", ")", ",", "\n", "'base_text_num_filters'", ":", "(", "100", ",", "100", ",", "100", ")", ",", "\n", "'adaptive'", ":", "False", ",", "\n", "'dim_k'", ":", "dim_k", ",", "\n", "'use_conv_for_img_reduction'", ":", "True", ",", "\n", "'use_dropout_on_init_embeddings'", ":", "True", ",", "\n", "}", "\n", "self", ".", "activation", "=", "self", ".", "config", "[", "'activation'", "]", "\n", "self", ".", "initializer_type", "=", "get_initializer_type", "(", "self", ".", "activation", ")", "\n", "self", ".", "base_text_model_name", "=", "self", ".", "config", "[", "'base_text_model'", "]", "\n", "self", ".", "base_image_model_last_layer", "=", "self", ".", "base_image_model", ".", "representation", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "model_name", ".", "name", ")", ":", "\n", "            ", "super", "(", "HieCoAtt", ",", "self", ")", ".", "__init__", "(", "model_name", "=", "self", ".", "model_name", ",", "config", "=", "self", ".", "config", ",", "is_trainable", "=", "is_trainable", ")", "\n", "\n", "# Construct the text model", "\n", "self", ".", "base_text_model", "=", "HieText", "(", "is_primary_model", "=", "False", ",", "\n", "is_trainable", "=", "is_trainable", ",", "\n", "filter_sizes", "=", "self", ".", "config", "[", "'base_text_filter_sizes'", "]", ",", "\n", "num_filters", "=", "self", ".", "config", "[", "'base_text_num_filters'", "]", ",", "\n", "activation", "=", "self", ".", "config", "[", "'base_text_activation'", "]", ")", "\n", "\n", "# Deciding what dimensional image embedding we'd get depending on the base image model", "\n", "image_dim", ",", "image_depth", "=", "self", ".", "_get_derived_image_representation_dimensions", "(", ")", "\n", "self", ".", "base_image_model_last_layer", "=", "self", ".", "base_image_model", ".", "representation", "\n", "text_embedding_dimension", "=", "self", ".", "base_text_model", ".", "final_embedding_dimension", "\n", "dim_d", "=", "text_embedding_dimension", "\n", "dim_m", "=", "image_dim", "*", "image_dim", "\n", "dim_D", "=", "image_depth", "\n", "self", ".", "dim_k", "=", "dim_k", "\n", "activation", "=", "self", ".", "activation", "\n", "print", "(", "\"For HieCoAtt: dim_d = %d, dim_m = %d, dim_D = %d\"", "%", "(", "dim_d", ",", "dim_m", ",", "dim_D", ")", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'dimD_to_dimk'", ")", ":", "\n", "\n", "                ", "self", ".", "v_spI", "=", "self", ".", "_dim_reduction_with_one_one_conv", "(", "image_dim", ",", "dim_D", ",", "dim_k", ",", "is_trainable", ")", "\n", "v_spI_unfolded", "=", "tf", ".", "reshape", "(", "self", ".", "v_spI", ",", "shape", "=", "[", "-", "1", ",", "dim_m", ",", "dim_k", "]", ")", "\n", "self", ".", "v_I", "=", "tf", ".", "reduce_mean", "(", "v_spI_unfolded", ",", "axis", "=", "1", ")", "\n", "\n", "# Without this layer, performance is worse", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"text_dimk\"", ")", ":", "\n", "                ", "W_t", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "EMBED_SIZES", ",", "dim_k", "]", ",", "\n", "initializer_type", "=", "self", ".", "initializer_type", ",", "name", "=", "'W_t'", ")", "\n", "b_t", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "dim_k", "]", ",", "name", "=", "'b_t'", ")", "\n", "\n", "word_level", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "tf", ".", "reshape", "(", "self", ".", "base_text_model", ".", "word_level", ",", "[", "-", "1", ",", "EMBED_SIZES", "]", ")", ",", "W_t", ",", "b_t", ")", "\n", "phrase_level", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "tf", ".", "reshape", "(", "self", ".", "base_text_model", ".", "phase_level", ",", "[", "-", "1", ",", "EMBED_SIZES", "]", ")", ",", "\n", "W_t", ",", "b_t", ")", "\n", "sentence_level", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "tf", ".", "reshape", "(", "self", ".", "base_text_model", ".", "sentence_level", ",", "\n", "[", "-", "1", ",", "EMBED_SIZES", "]", ")", ",", "W_t", ",", "b_t", ")", "\n", "\n", "word_level", "=", "tf", ".", "reshape", "(", "tf", ".", "nn", ".", "dropout", "(", "word_level", ",", "self", ".", "dropout_keep_prob", ")", ",", "\n", "[", "-", "1", ",", "TEXT_LENTH", ",", "dim_k", "]", ")", "\n", "phrase_level", "=", "tf", ".", "reshape", "(", "tf", ".", "nn", ".", "dropout", "(", "phrase_level", ",", "self", ".", "dropout_keep_prob", ")", ",", "\n", "[", "-", "1", ",", "TEXT_LENTH", ",", "dim_k", "]", ")", "\n", "sentence_level", "=", "tf", ".", "reshape", "(", "tf", ".", "nn", ".", "dropout", "(", "sentence_level", ",", "self", ".", "dropout_keep_prob", ")", ",", "\n", "[", "-", "1", ",", "TEXT_LENTH", ",", "dim_k", "]", ")", "\n", "\n", "# [B, d]", "\n", "", "v_w", ",", "q_w", ",", "self", ".", "att_q_w", ",", "self", ".", "att_v_w", "=", "self", ".", "_co_attention", "(", "word_level", ",", "\n", "self", ".", "v_spI", ",", "dim_m", ",", "is_trainable", ",", "level", "=", "'word'", ",", "\n", "activation", "=", "activation", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"fc1\"", ")", ":", "\n", "                ", "W_1", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "dim_k", ",", "dim_k", "]", ",", "\n", "initializer_type", "=", "self", ".", "initializer_type", ",", "name", "=", "'W_1'", ")", "\n", "b_1", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "dim_k", "]", ",", "name", "=", "'b_1'", ")", "\n", "if", "use_batch_norm", ":", "\n", "                    ", "self", ".", "h_w", "=", "batch_norm_dense_activation", "(", "tf", ".", "nn", ".", "xw_plus_b", "(", "x", "=", "v_w", "+", "q_w", ",", "weights", "=", "W_1", ",", "biases", "=", "b_1", ")", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "activation", "=", "activation", ",", "\n", "is_trainable", "=", "is_trainable", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "h_w", "=", "activation", "(", "tf", ".", "nn", ".", "xw_plus_b", "(", "x", "=", "v_w", "+", "q_w", ",", "weights", "=", "W_1", ",", "biases", "=", "b_1", ",", "name", "=", "'h_w'", ")", ")", "\n", "", "self", ".", "h_w", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "h_w", ",", "self", ".", "dropout_keep_prob", ")", "\n", "\n", "# [B, d]", "\n", "", "v_p", ",", "q_p", ",", "self", ".", "att_q_p", ",", "self", ".", "att_v_p", "=", "self", ".", "_co_attention", "(", "phrase_level", ",", "\n", "self", ".", "v_spI", ",", "dim_m", ",", "is_trainable", ",", "level", "=", "'phrase'", ",", "\n", "activation", "=", "activation", ")", "\n", "# [B, 2d]", "\n", "with", "tf", ".", "variable_scope", "(", "\"fc2\"", ")", ":", "\n", "                ", "W_2", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "2", "*", "dim_k", ",", "2", "*", "dim_k", "]", ",", "\n", "initializer_type", "=", "self", ".", "initializer_type", ",", "name", "=", "'W_2'", ")", "\n", "b_2", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "2", "*", "dim_k", "]", ",", "name", "=", "'b_2'", ")", "\n", "if", "use_batch_norm", ":", "\n", "                    ", "self", ".", "h_p", "=", "batch_norm_dense_activation", "(", "tf", ".", "nn", ".", "xw_plus_b", "(", "x", "=", "tf", ".", "concat", "(", "[", "v_p", "+", "q_p", ",", "self", ".", "h_w", "]", ",", "1", ")", ",", "\n", "weights", "=", "W_2", ",", "biases", "=", "b_2", ")", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "\n", "activation", "=", "activation", ",", "is_trainable", "=", "is_trainable", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "h_p", "=", "activation", "(", "tf", ".", "nn", ".", "xw_plus_b", "(", "x", "=", "tf", ".", "concat", "(", "[", "v_p", "+", "q_p", ",", "self", ".", "h_w", "]", ",", "1", ")", ",", "\n", "weights", "=", "W_2", ",", "biases", "=", "b_2", ",", "name", "=", "'h_p'", ")", ")", "\n", "", "self", ".", "h_p", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "h_p", ",", "self", ".", "dropout_keep_prob", ")", "\n", "\n", "", "v_s", ",", "q_s", ",", "self", ".", "att_q_s", ",", "self", ".", "att_v_s", "=", "self", ".", "_co_attention", "(", "sentence_level", ",", "\n", "self", ".", "v_spI", ",", "dim_m", ",", "is_trainable", ",", "level", "=", "'sentence'", ",", "\n", "activation", "=", "activation", ")", "\n", "# [B, 3d]", "\n", "with", "tf", ".", "variable_scope", "(", "\"fc3\"", ")", ":", "\n", "                ", "W_3", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "3", "*", "dim_k", ",", "3", "*", "dim_k", "]", ",", "\n", "initializer_type", "=", "self", ".", "initializer_type", ",", "name", "=", "'W_3'", ")", "\n", "b_3", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "3", "*", "dim_k", "]", ",", "name", "=", "'b_3'", ")", "\n", "self", ".", "h_s", "=", "activation", "(", "tf", ".", "nn", ".", "xw_plus_b", "(", "x", "=", "tf", ".", "concat", "(", "[", "v_s", "+", "q_s", ",", "self", ".", "h_p", "]", ",", "1", ")", ",", "\n", "weights", "=", "W_3", ",", "biases", "=", "b_3", ",", "name", "=", "'h_s'", ")", ")", "\n", "self", ".", "h_s", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "h_s", ",", "self", ".", "dropout_keep_prob", ")", "\n", "\n", "", "if", "is_trainable", ":", "\n", "                ", "with", "tf", ".", "name_scope", "(", "\"output_hie\"", ")", ":", "\n", "                    ", "W_out", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "3", "*", "dim_k", ",", "NUM_CLASSES", "]", ",", "\n", "name", "=", "'W_out'", ")", "\n", "b_out", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "NUM_CLASSES", "]", ",", "name", "=", "'b_out'", ")", "\n", "self", ".", "scores", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "self", ".", "h_s", ",", "W_out", ",", "b_out", ",", "name", "=", "\"scores_hie\"", ")", "# unnormalized scores", "\n", "\n", "", "", "if", "is_primary_model", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"optimization\"", ")", ":", "\n", "                    ", "self", ".", "_set_predictions_optimizer_and_loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.HieCoAtt._co_attention": [[1198, 1252], ["tensorflow.name_scope", "network.weight_variable", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "activation", "network.weight_variable", "network.weight_variable", "network.weight_variable", "network.weight_variable", "tensorflow.reshape", "tensorflow.reshape", "activation", "tensorflow.nn.softmax", "activation", "tensorflow.nn.softmax", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable"], ["", "", "", "", "def", "_co_attention", "(", "self", ",", "texts", ",", "images", ",", "image_n", ",", "is_trainable", ",", "level", ",", "activation", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "\"co-att\"", ")", ":", "\n", "# V:[B, N, image_dim] Q:[B, T, text_dim]", "\n", "# W_b:[B, text_dim, image_dim] # text_dim=image_dim=dim", "\n", "# affinity matrix =  relu(Q W V^T) #[B, T, N]", "\n", "            ", "W_b", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "self", ".", "dim_k", ",", "self", ".", "dim_k", "]", ",", "\n", "initializer_type", "=", "self", ".", "initializer_type", ",", "name", "=", "'W_b_%s'", "%", "level", ")", "\n", "\n", "# [B*T, dim]", "\n", "texts_", "=", "tf", ".", "reshape", "(", "texts", ",", "[", "-", "1", ",", "self", ".", "dim_k", "]", ")", "\n", "# [B*N, dim]", "\n", "images_", "=", "tf", ".", "reshape", "(", "images", ",", "[", "-", "1", ",", "self", ".", "dim_k", "]", ")", "\n", "\n", "# [B*T, dim] --> [B, T, D]", "\n", "Q_W_b", "=", "tf", ".", "reshape", "(", "tf", ".", "matmul", "(", "texts_", ",", "W_b", ")", ",", "[", "-", "1", ",", "TEXT_LENTH", ",", "self", ".", "dim_k", "]", ")", "\n", "\n", "# [batch_size,text_length,image_n] # [B, T, D]*[B, D, N]", "\n", "c", "=", "activation", "(", "tf", ".", "matmul", "(", "Q_W_b", ",", "tf", ".", "transpose", "(", "images", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", ")", ")", "\n", "\n", "# W_v: [B, k, dim], W_q: [B, k, dim], W_hv: [B, k], W_hq: [B, k]", "\n", "# set k = 512", "\n", "W_v", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "512", ",", "self", ".", "dim_k", "]", ",", "\n", "initializer_type", "=", "self", ".", "initializer_type", ",", "name", "=", "'W_v_%s'", "%", "level", ")", "\n", "W_q", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "512", ",", "self", ".", "dim_k", "]", ",", "\n", "initializer_type", "=", "self", ".", "initializer_type", ",", "name", "=", "'W_q_%s'", "%", "level", ")", "\n", "W_hv", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "512", ",", "1", "]", ",", "initializer_type", "=", "self", ".", "initializer_type", ",", "\n", "name", "=", "'W_hv_%s'", "%", "level", ")", "\n", "W_hq", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "512", ",", "1", "]", ",", "\n", "initializer_type", "=", "self", ".", "initializer_type", ",", "name", "=", "'W_hq_%s'", "%", "level", ")", "\n", "\n", "# [k,D] * [D, B*N] = [k, B*N] --> [B*N,k] --> [B,N,k]", "\n", "V_W_v", "=", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "tf", ".", "matmul", "(", "W_v", ",", "tf", ".", "transpose", "(", "images_", ")", ")", ")", ",", "[", "-", "1", ",", "image_n", ",", "512", "]", ")", "\n", "# [k,D] * [D, B*T] = [k, B*T] --> [B*T,k] --> [B,T,k]", "\n", "Q_W_q", "=", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "tf", ".", "matmul", "(", "W_q", ",", "tf", ".", "transpose", "(", "texts_", ")", ")", ")", ",", "[", "-", "1", ",", "TEXT_LENTH", ",", "512", "]", ")", "\n", "\n", "# [B,N,k]+ ([B,k,T]*[B,T,N]  = [B, k, N] --> [B,N,k])", "\n", "h_v", "=", "activation", "(", "V_W_v", "+", "tf", ".", "transpose", "(", "tf", ".", "matmul", "(", "tf", ".", "transpose", "(", "Q_W_q", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", ",", "c", ")", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", ")", "\n", "\n", "# [B*N,k] * [k, 1] = [B*N, 1] = [B,N, 1]", "\n", "att_v", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "reshape", "(", "tf", ".", "matmul", "(", "tf", ".", "reshape", "(", "h_v", ",", "[", "-", "1", ",", "512", "]", ")", ",", "W_hv", ")", ",", "[", "-", "1", ",", "image_n", ",", "1", "]", ")", ")", "\n", "\n", "# [B, k, T]", "\n", "# [B,T,k] +  [B, k, N] *[B, N, T]=[B,k,T] --> [B, T, k]", "\n", "\n", "h_q", "=", "activation", "(", "Q_W_q", "+", "tf", ".", "transpose", "(", "tf", ".", "matmul", "(", "tf", ".", "transpose", "(", "V_W_v", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", ",", "\n", "tf", ".", "transpose", "(", "c", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", ")", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", ")", "\n", "# [B*T,k] * [k, 1] = [B*T, 1] = [B,T, 1]", "\n", "att_q", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "reshape", "(", "tf", ".", "matmul", "(", "tf", ".", "reshape", "(", "h_q", ",", "[", "-", "1", ",", "512", "]", ")", ",", "W_hq", ")", ",", "[", "-", "1", ",", "TEXT_LENTH", ",", "1", "]", ")", ")", "\n", "\n", "# [B, d]?", "\n", "v", "=", "tf", ".", "nn", ".", "dropout", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "att_v", ",", "images", ")", ",", "axis", "=", "1", ")", ",", "self", ".", "dropout_keep_prob", ")", "\n", "q", "=", "tf", ".", "nn", ".", "dropout", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "att_q", ",", "texts", ")", ",", "axis", "=", "1", ")", ",", "self", ".", "dropout_keep_prob", ")", "\n", "\n", "", "return", "v", ",", "q", ",", "att_q", ",", "att_v", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.HieCoAtt._train_SGD_batch_step": [[1253, 1272], ["sess.run", "utils.text_batch_from_ids"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.text_batch_from_ids"], ["", "def", "_train_SGD_batch_step", "(", "self", ",", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_train", ",", "train_mode", "=", "True", ",", "\n", "batch_step", "=", "1", ")", ":", "\n", "        ", "S", ",", "_", ",", "loss_val", ",", "acc_val", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "train_summary_op", ",", "self", ".", "train_op", ",", "self", ".", "loss", ",", "self", ".", "accuracy", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "0.5", ",", "\n", "self", ".", "base_image_model", ".", "images_placeholder", ":", "batch_image", ",", "\n", "self", ".", "base_image_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "base_text_model", ".", "texts_placeholder", ":", "text_batch_from_ids", "(", "batch_ids", ",", "text_data", "=", "text_train", ")", ",", "\n", "self", ".", "base_text_model", ".", "embedding_dropout", ":", "0.3", ",", "\n", "self", ".", "base_text_model", ".", "embedding_noise_std", ":", "0.01", ",", "\n", "self", ".", "base_text_model", ".", "dropout_keep_prob", ":", "0.5", ",", "\n", "self", ".", "base_text_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "base_text_model", ".", "phase_train", ":", "train_mode", ",", "\n", "}", ")", "\n", "\n", "return", "S", ",", "loss_val", ",", "acc_val", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.HieCoAtt._validation_batch_step": [[1273, 1292], ["sess.run", "utils.text_batch_from_ids"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.text_batch_from_ids"], ["", "def", "_validation_batch_step", "(", "self", ",", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_val", ",", "train_mode", "=", "False", ",", "\n", "batch_step", "=", "1", ")", ":", "\n", "        ", "val_acc", "=", "sess", ".", "run", "(", "\n", "self", ".", "sum_accuracy", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "1.", ",", "\n", "self", ".", "base_image_model", ".", "images_placeholder", ":", "batch_image", ",", "\n", "self", ".", "base_image_model", ".", "train_mode", ":", "True", ",", "\n", "self", ".", "base_text_model", ".", "texts_placeholder", ":", "text_batch_from_ids", "(", "batch_ids", ",", "text_data", "=", "text_val", ")", ",", "\n", "self", ".", "base_text_model", ".", "embedding_dropout", ":", "0.", ",", "\n", "self", ".", "base_text_model", ".", "embedding_noise_std", ":", "0.", ",", "\n", "self", ".", "base_text_model", ".", "dropout_keep_prob", ":", "1.", ",", "\n", "self", ".", "base_text_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "base_text_model", ".", "phase_train", ":", "train_mode", ",", "\n", "}", ")", "\n", "\n", "return", "val_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_text_models.HieCoAtt._test_batch_step": [[1293, 1312], ["sess.run", "utils.text_batch_from_ids"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.text_batch_from_ids"], ["", "def", "_test_batch_step", "(", "self", ",", "sess", ",", "c_mat", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_test", ",", "\n", "train_mode", "=", "False", ")", ":", "\n", "        ", "pred", ",", "mat", ",", "test_acc", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "probabilities", ",", "c_mat", ",", "self", ".", "sum_accuracy", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "1.", ",", "\n", "self", ".", "base_image_model", ".", "images_placeholder", ":", "batch_image", ",", "\n", "self", ".", "base_image_model", ".", "train_mode", ":", "True", ",", "\n", "self", ".", "base_text_model", ".", "texts_placeholder", ":", "text_batch_from_ids", "(", "batch_ids", ",", "text_data", "=", "text_test", ")", ",", "\n", "self", ".", "base_text_model", ".", "embedding_dropout", ":", "0.", ",", "\n", "self", ".", "base_text_model", ".", "embedding_noise_std", ":", "0.", ",", "\n", "self", ".", "base_text_model", ".", "dropout_keep_prob", ":", "1.", ",", "\n", "self", ".", "base_text_model", ".", "train_mode", ":", "train_mode", ",", "\n", "self", ".", "base_text_model", ".", "phase_train", ":", "train_mode", ",", "\n", "}", ")", "\n", "\n", "return", "pred", ",", "mat", ",", "test_acc", "\n", "", "", ""]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.global_hyperparams.update_learning_rate_dict": [[140, 142], ["None"], "function", ["None"], ["def", "update_learning_rate_dict", "(", "model_type", ",", "learning_rate", ")", ":", "\n", "    ", "learning_rate_dict", "[", "model_type", "]", "=", "learning_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.global_hyperparams.update_batch_size_dict": [[144, 146], ["None"], "function", ["None"], ["", "def", "update_batch_size_dict", "(", "model_type", ",", "batch_size", ")", ":", "\n", "    ", "batch_size_dict", "[", "model_type", "]", "=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.global_hyperparams.update_training_epochs_dict": [[148, 150], ["None"], "function", ["None"], ["", "def", "update_training_epochs_dict", "(", "model_type", ",", "training_epochs", ")", ":", "\n", "    ", "training_epochs_dict", "[", "model_type", "]", "=", "training_epochs", "\n", "", ""]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network._get_variable": [[19, 37], ["tensorflow.get_variable", "tensorflow.contrib.layers.l2_regularizer"], "function", ["None"], ["def", "_get_variable", "(", "name", ",", "\n", "shape", ",", "\n", "initializer", ",", "\n", "weight_decay", "=", "0.0", ",", "\n", "dtype", "=", "'float'", ",", "\n", "trainable", "=", "True", ")", ":", "\n", "    ", "\"\"\"A little wrapper around tf.get_variable to do weight decay and add to resnet collection\"\"\"", "\n", "if", "weight_decay", ">", "0", ":", "\n", "        ", "regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "weight_decay", ")", "\n", "", "else", ":", "\n", "        ", "regularizer", "=", "None", "\n", "\n", "", "return", "tf", ".", "get_variable", "(", "name", ",", "\n", "shape", "=", "shape", ",", "\n", "initializer", "=", "initializer", ",", "\n", "dtype", "=", "dtype", ",", "\n", "regularizer", "=", "regularizer", ",", "\n", "trainable", "=", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable": [[39, 58], ["network._get_variable", "tensorflow.truncated_normal_initializer", "len", "tensorflow.contrib.layers.xavier_initializer", "ValueError", "math.sqrt", "len", "math.sqrt"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet._get_variable"], ["", "def", "weight_variable", "(", "is_trainable", ",", "shape", ",", "stddev", "=", "None", ",", "initializer_type", "=", "'normal'", ",", "name", "=", "''", ")", ":", "\n", "    ", "if", "stddev", "is", "None", ":", "\n", "        ", "if", "len", "(", "shape", ")", "==", "4", ":", "\n", "            ", "stddev", "=", "1", "/", "sqrt", "(", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "*", "shape", "[", "2", "]", ")", "\n", "", "elif", "len", "(", "shape", ")", "==", "2", ":", "\n", "            ", "stddev", "=", "1", "/", "sqrt", "(", "shape", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "stddev", "=", "0.1", "\n", "\n", "# initial = tf.truncated_normal(shape, stddev=stddev)", "\n", "", "", "if", "initializer_type", "==", "'normal'", ":", "\n", "        ", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "stddev", ")", "\n", "", "elif", "initializer_type", "==", "'xavier'", ":", "\n", "        ", "initializer", "=", "xavier_initializer", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown initializer type %s for weight variable\"", "%", "initializer_type", ")", "\n", "\n", "", "return", "_get_variable", "(", "name", "=", "'weight-'", "+", "name", ",", "shape", "=", "shape", ",", "initializer", "=", "initializer", ",", "weight_decay", "=", "WEIGHT_DECAY", ",", "\n", "trainable", "=", "is_trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable": [[60, 65], ["tensorflow.constant_initializer", "network._get_variable"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet._get_variable"], ["", "def", "bias_variable", "(", "is_trainable", ",", "shape", ",", "name", "=", "''", ")", ":", "\n", "# initial = tf.constant(0.1, shape=shape)", "\n", "    ", "initializer", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.1", ")", "\n", "return", "_get_variable", "(", "name", "=", "'bias_var-'", "+", "name", ",", "shape", "=", "shape", ",", "initializer", "=", "initializer", ",", "weight_decay", "=", "0.0", ",", "\n", "trainable", "=", "is_trainable", ")", "\n", "# return tf.Variable(initial, name='bias_var')", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d": [[68, 85], ["tensorflow.nn.conv2d", "tensorflow.contrib.layers.batch_norm"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.batch_norm"], ["", "def", "conv2d", "(", "x", ",", "W", ",", "strides", "=", "None", ",", "padding", "=", "'SAME'", ",", "isnorm", "=", "False", ",", "is_training", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Prepare a tf.nn.conv2d layer and return it\n    :param x: 4-D tensor, input to conv2d layer\n    :param W: 4-D tensor, filter for conv2d layer\n    :param strides: list of 4 ints, stride over batch, height, width, channel\n    :param padding: enum, 'SAME' or 'VALID'\n    :param isnorm: bool, whether to apply batch normalization\n    :param is_training: bool, whether in training mode.\n    :return: tf.nn.conv2d object, with x as input, W as filter\n    \"\"\"", "\n", "if", "strides", "is", "None", ":", "\n", "        ", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", "\n", "", "if", "isnorm", ":", "\n", "        ", "x", "=", "tf", ".", "contrib", ".", "layers", ".", "batch_norm", "(", "inputs", "=", "x", ",", "is_training", "=", "is_training", ")", "\n", "# x = tf_nn_batch_norm(input_tensor=x)", "\n", "", "return", "tf", ".", "nn", ".", "conv2d", "(", "input", "=", "x", ",", "filter", "=", "W", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_conv_activation": [[87, 96], ["tensorflow.layers.batch_normalization", "activation"], "function", ["None"], ["", "def", "batch_norm_conv_activation", "(", "inputs", ",", "is_training", ",", "activation", ",", "is_trainable", ")", ":", "\n", "    ", "\"\"\"Performs a batch normalization followed by activation.\"\"\"", "\n", "inputs", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "\n", "inputs", "=", "inputs", ",", "axis", "=", "3", ",", "\n", "momentum", "=", "_BATCH_NORM_DECAY", ",", "epsilon", "=", "_BATCH_NORM_EPSILON", ",", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "training", "=", "is_training", ",", "fused", "=", "True", ",", "trainable", "=", "is_trainable", ")", "\n", "if", "activation", "is", "not", "None", ":", "\n", "        ", "inputs", "=", "activation", "(", "inputs", ")", "\n", "", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_dense_activation": [[98, 121], ["tensorflow.layers.batch_normalization", "activation"], "function", ["None"], ["", "def", "batch_norm_dense_activation", "(", "inputs", ",", "is_training", ",", "activation", ",", "is_trainable", ")", ":", "\n", "    ", "\"\"\"Perform a batch normalization followed by activation.\n\n    Parameters\n    ----------\n    :param inputs: tensor, of shape [batch_size, layer_dimension]\n\n    :param is_training: bool, whether the model is in training mode\n\n    :param activation: one of TF's activation function\n\n    :param is_trainable: bool, whether the model is trainable\n\n    Returns\n    -------\n    bn_inputs: tensor, 'inputs' with batch norm and activation applied to it\n    \"\"\"", "\n", "bn_inputs", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "\n", "inputs", "=", "inputs", ",", "axis", "=", "1", ",", "\n", "momentum", "=", "_BATCH_NORM_DECAY", ",", "epsilon", "=", "_BATCH_NORM_EPSILON", ",", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "training", "=", "is_training", ",", "trainable", "=", "is_trainable", ")", "\n", "bn_inputs", "=", "activation", "(", "bn_inputs", ")", "\n", "return", "bn_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.standard_FC_layer": [[123, 141], ["network.get_initializer_type", "network.weight_variable", "network.bias_variable", "tensorflow.nn.dropout", "network.batch_norm_dense_activation", "activation", "tensorflow.nn.xw_plus_b", "tensorflow.nn.xw_plus_b"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.get_initializer_type", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_dense_activation"], ["", "def", "standard_FC_layer", "(", "inputs", ",", "input_dim", ",", "output_dim", ",", "use_batch_norm", ",", "activation", ",", "train_mode", ",", "is_trainable", ",", "\n", "dropout_keep_prob", ",", "name_suffix", ")", ":", "\n", "    ", "initializer_type", "=", "get_initializer_type", "(", "activation", ")", "\n", "W_I", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "input_dim", ",", "output_dim", "]", ",", "\n", "initializer_type", "=", "initializer_type", ",", "name", "=", "'W_%s'", "%", "name_suffix", ")", "\n", "b_I", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "output_dim", "]", ",", "name", "=", "'b_%s'", "%", "name_suffix", ")", "\n", "if", "use_batch_norm", ":", "\n", "        ", "output", "=", "batch_norm_dense_activation", "(", "inputs", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "x", "=", "inputs", ",", "\n", "weights", "=", "W_I", ",", "\n", "biases", "=", "b_I", ")", ",", "\n", "activation", "=", "activation", ",", "\n", "is_training", "=", "train_mode", ",", "\n", "is_trainable", "=", "is_trainable", ")", "\n", "", "else", ":", "\n", "        ", "output", "=", "activation", "(", "tf", ".", "nn", ".", "xw_plus_b", "(", "x", "=", "inputs", ",", "weights", "=", "W_I", ",", "biases", "=", "b_I", ")", ")", "\n", "\n", "", "output", "=", "tf", ".", "nn", ".", "dropout", "(", "output", ",", "dropout_keep_prob", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.standard_conv_layer": [[143, 156], ["network.get_initializer_type", "network.weight_variable", "network.bias_variable", "activation", "network.batch_norm_conv_activation", "network.conv2d", "network.conv2d"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.get_initializer_type", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_conv_activation", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d"], ["", "def", "standard_conv_layer", "(", "inputs", ",", "filter_shape", ",", "activation", ",", "use_batch_norm", ",", "train_mode", ",", "is_trainable", ",", "name_suffix", ")", ":", "\n", "    ", "initializer_type", "=", "get_initializer_type", "(", "activation", ")", "\n", "W_conv1", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "filter_shape", ",", "\n", "initializer_type", "=", "initializer_type", ",", "\n", "name", "=", "'W_%s'", "%", "name_suffix", ")", "\n", "b_conv1", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "512", "]", ",", "name", "=", "\"b_%s\"", "%", "name_suffix", ")", "\n", "if", "not", "use_batch_norm", ":", "\n", "        ", "conv_output", "=", "activation", "(", "conv2d", "(", "x", "=", "inputs", ",", "W", "=", "W_conv1", ")", "+", "b_conv1", ",", "name", "=", "'h_%s'", "%", "name_suffix", ")", "\n", "", "else", ":", "\n", "        ", "conv_output", "=", "batch_norm_conv_activation", "(", "inputs", "=", "conv2d", "(", "x", "=", "inputs", ",", "W", "=", "W_conv1", ")", "+", "b_conv1", ",", "\n", "is_training", "=", "train_mode", ",", "\n", "activation", "=", "activation", ",", "is_trainable", "=", "is_trainable", ")", "\n", "", "return", "conv_output", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.get_initializer_type": [[158, 160], ["None"], "function", ["None"], ["", "def", "get_initializer_type", "(", "activation", ")", ":", "\n", "    ", "return", "\"normal\"", "if", "activation", "==", "tf", ".", "nn", ".", "relu", "else", "\"xavier\"", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.tf_nn_batch_norm": [[162, 165], ["tensorflow.nn.moments", "tensorflow.nn.batch_normalization"], "function", ["None"], ["", "def", "tf_nn_batch_norm", "(", "input_tensor", ")", ":", "\n", "    ", "mean", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "input_tensor", ",", "[", "0", ",", "1", ",", "2", "]", ")", "\n", "return", "tf", ".", "nn", ".", "batch_normalization", "(", "input_tensor", ",", "mean", ",", "variance", ",", "None", ",", "None", ",", "1e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.max_pool": [[167, 173], ["tensorflow.nn.max_pool"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.max_pool"], ["", "def", "max_pool", "(", "x", ",", "ksize", "=", "None", ",", "strides", "=", "None", ",", "padding", "=", "'SAME'", ")", ":", "\n", "    ", "if", "ksize", "is", "None", ":", "\n", "        ", "ksize", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", "\n", "", "if", "strides", "is", "None", ":", "\n", "        ", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", "\n", "", "return", "tf", ".", "nn", ".", "max_pool", "(", "x", ",", "ksize", "=", "ksize", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.lr_norm": [[176, 178], ["tensorflow.nn.lrn"], "function", ["None"], ["", "def", "lr_norm", "(", "x", ",", "depth_radius", ",", "bias", "=", "1.0", ",", "alpha", "=", "0.001", "/", "9.0", ",", "beta", "=", "0.75", ")", ":", "\n", "    ", "return", "tf", ".", "nn", ".", "lrn", "(", "x", ",", "depth_radius", ",", "bias", "=", "bias", ",", "alpha", "=", "alpha", ",", "beta", "=", "beta", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.text_models.TextModel.__init__": [[34, 88], ["base_model.BaseModel.__init__", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder_with_default", "tensorflow.placeholder_with_default", "int", "tensorflow.reshape", "tensorflow.variable_scope", "tensorflow.Variable", "tensorflow.nn.embedding_lookup", "tensorflow.layers.dropout", "tensorflow.random_normal", "tensorflow.random_uniform", "tensorflow.shape", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__"], ["def", "__init__", "(", "self", ",", "model_name", ",", "is_trainable", ",", "\n", "form_embedding_matrix", "=", "True", ",", "is_primary_model", "=", "True", ",", "config", "=", "None", ",", "embed_size_multiplier", "=", "1.", ")", ":", "\n", "        ", "\"\"\"Calls BaseModel constructor, declares placeholders, embedding matrix lookup procedure.\n\n        Parameters\n        ----------\n        :param model_name: ModelName enum\n\n        :param is_trainable: bool, whether the model's weight params can be trained/modified\n\n        :param form_embedding_matrix: bool, whether to setup an embedding matrix and lookup architecture\n\n        :param is_primary_model: bool, whether to setup optimization variables for this model.\n            If it's embedding output is simply fed to some other image_text model, then it is False.\n\n        :param config: dict, containing configuration parameters\n\n        :param embed_size_multiplier: float, used to explicitly scale embedding_size\n        \"\"\"", "\n", "# Call the BaseModel constructor", "\n", "super", "(", "TextModel", ",", "self", ")", ".", "__init__", "(", "model_type", "=", "ModelType", ".", "text_only", ",", "model_name", "=", "model_name", ",", "\n", "is_primary_model", "=", "is_primary_model", ",", "config", "=", "config", ")", "\n", "\n", "# Placeholder for text data, shape: [batch_size, TEXT_LENGTH]", "\n", "self", ".", "texts_placeholder", "=", "tf", ".", "placeholder", "(", "\"int32\"", ",", "shape", "=", "[", "None", ",", "TEXT_LENTH", "]", ",", "name", "=", "'text_placeholder'", ")", "\n", "# Placeholder indicating whether model is training or validating/testing", "\n", "self", ".", "phase_train", "=", "tf", ".", "placeholder", "(", "tf", ".", "bool", ",", "name", "=", "'phase_train_placeholder'", ")", "\n", "# Placeholders for purpose of regularization", "\n", "self", ".", "embedding_dropout", "=", "tf", ".", "placeholder_with_default", "(", "0.", ",", "shape", "=", "[", "]", ",", "name", "=", "'embedding_dropout_placeholder'", ")", "\n", "self", ".", "embedding_noise_std", "=", "tf", ".", "placeholder_with_default", "(", "0.", ",", "shape", "=", "[", "]", ",", "name", "=", "'embedding_noise_placeholder'", ")", "\n", "\n", "# The embedding size is mentioned in global_hyperparams. User can explicitly scale it via embed_size_multiplier", "\n", "self", ".", "embedding_size", "=", "int", "(", "EMBED_SIZES", "*", "embed_size_multiplier", ")", "\n", "\n", "if", "form_embedding_matrix", ":", "\n", "# Embedding layer", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"embedding\"", ")", ":", "\n", "# Matrix with embedding for each word in vocab", "\n", "                ", "self", ".", "embedding_matrix", "=", "tf", ".", "Variable", "(", "\n", "trainable", "=", "is_trainable", ",", "\n", "initial_value", "=", "tf", ".", "random_uniform", "(", "[", "WORD_SIZES", ",", "self", ".", "embedding_size", "]", ",", "-", "0.5", ",", "0.5", ")", ")", "\n", "# Lookup to form embedding sequence for current text input", "\n", "self", ".", "embedded", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "embedding_matrix", ",", "self", ".", "texts_placeholder", ")", "\n", "# Add noise and dropout", "\n", "self", ".", "embedded_noise", "=", "self", ".", "embedded", "+", "tf", ".", "random_normal", "(", "shape", "=", "tf", ".", "shape", "(", "self", ".", "embedded", ")", ",", "\n", "stddev", "=", "self", ".", "embedding_noise_std", ")", "\n", "self", ".", "seq_embedded", "=", "tf", ".", "layers", ".", "dropout", "(", "self", ".", "embedded_noise", ",", "rate", "=", "0.", ",", "\n", "noise_shape", "=", "tf", ".", "shape", "(", "self", ".", "embedded", "[", ":", "-", "1", "]", "+", "[", "1", "]", ")", ")", "\n", "\n", "# input for convolution: 4D tensor: [batch_size, text_size, embedding_size, channel_size]", "\n", "", "self", ".", "x_text", "=", "tf", ".", "reshape", "(", "self", ".", "seq_embedded", ",", "[", "-", "1", ",", "TEXT_LENTH", ",", "self", ".", "embedding_size", ",", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embedding_matrix", ",", "self", ".", "embedded", ",", "self", ".", "seq_embedded", ",", "self", ".", "x_text", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.text_models.TextModel._train_helper_SGD": [[89, 159], ["sess.run", "range", "print", "print", "utils.right_align", "utils.right_align", "text_models.TextModel.early_stopping_procedure", "text_models.TextModel._train_SGD_loop", "text_models.TextModel._val_prediction_loop", "print", "max"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.right_align", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.right_align", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.early_stopping_procedure", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel._train_SGD_loop", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel._val_prediction_loop"], ["", "", "def", "_train_helper_SGD", "(", "self", ",", "sess", ",", "train_writer", ",", "train_ids", ",", "train_labels", ",", "train_texts", ",", "\n", "val_ids", ",", "val_labels", ",", "val_texts", ",", "iterator_train_init", ",", "next_element_train", ",", "iterator_val_init", ",", "\n", "next_element_val", ")", ":", "\n", "        ", "\"\"\"Helper function for train(), implementing the SGD steps over train & val data in arguments.\n\n        Parameters\n        ----------\n        :param sess: tf.Session() object\n\n        :param train_writer: tf.summary.FileWriter object, file writer for TensorBoard\n\n        :param train_ids: np.array of shape [NUM_TRAIN_SAMPLES] and type int, containing Chiebukuro question ids\n\n        :param train_labels: np.array of shape [NUM_TRAIN_SAMPLES, NUM_CLASSES] of type bool,\n            containing category labels\n\n        :param train_texts: np.array of shape [NUM_TRAIN_SAMPLES, TEXT_LENGTH] of type int\n\n        :param val_ids: np.array of shape [NUM_VAL_SAMPLES] and type int\n\n        :param val_labels: np.array of shape [NUM_VAL_SAMPLES, NUM_CLASSES] and type bool\n\n        :param val_texts: np.array of shape [NUM_VAL_SAMPLES, TEXT_LENGTH] and type int\n\n        :param iterator_train_init: tf.contrib.data.TFRecordDataset.Iterator.initializeer object for train data\n\n        :param next_element_train: tf operation, on run generates next batch (using iterator.get_next())\n\n        :param iterator_val_init: tf.contrib.data.TFRecordDataset.Iterator.initializeer object for validation data\n\n        :param next_element_val: tf operation, on run generates next batch (using iterator.get_next())\n        \"\"\"", "\n", "global_step", "=", "sess", ".", "run", "(", "self", ".", "global_step", ")", "\n", "\n", "# For RNN, all texts are right aligned", "\n", "if", "self", ".", "model_name", "==", "ModelName", ".", "text_rnn", ":", "\n", "            ", "train_texts", "=", "right_align", "(", "train_texts", ")", "\n", "val_texts", "=", "right_align", "(", "val_texts", ")", "\n", "\n", "# Variable for implementing early stopping and validation acc based learning rate decay", "\n", "", "val_acc_history", "=", "[", "]", "\n", "epochs_with_current_lrate", "=", "0", "\n", "min_increment", "=", "0.0002", "\n", "tolerable_decrease", "=", "0.0004", "\n", "\n", "training_epochs", "=", "training_epochs_dict", "[", "self", ".", "model_type", "]", "\n", "\n", "for", "epoch", "in", "range", "(", "training_epochs", ")", ":", "\n", "# Decay learning rate (if early_stopping_learning_rate=True) on basis of val acc history", "\n", "# And determine whether to early stop.", "\n", "            ", "early_stop", ",", "epochs_with_current_lrate", "=", "self", ".", "early_stopping_procedure", "(", "sess", ",", "\n", "epochs_with_current_lrate", ",", "\n", "val_acc_history", ",", "\n", "min_increment", ",", "tolerable_decrease", ")", "\n", "if", "early_stop", ":", "break", "\n", "\n", "# Running training GD for this epoch", "\n", "global_step", "=", "self", ".", "_train_SGD_loop", "(", "sess", ",", "train_texts", ",", "train_labels", ",", "global_step", ",", "train_writer", ")", "\n", "# Completed training for this epoch", "\n", "\n", "# Now performing validation", "\n", "self", ".", "_val_prediction_loop", "(", "sess", ",", "epoch", ",", "val_texts", ",", "val_labels", ",", "val_acc_history", ")", "\n", "\n", "print", "(", "'Previous Val Accs:'", ",", "val_acc_history", "[", "-", "10", ":", "]", ")", "\n", "epochs_with_current_lrate", "+=", "1", "\n", "\n", "# Completed all epochs", "\n", "", "print", "(", "'BEST VAL: '", ",", "max", "(", "val_acc_history", ")", ")", "\n", "print", "(", "\"Completed training %s model, with %d epochs, each with %d minibatches each of size %d\"", "\n", "%", "(", "self", ".", "model_name", ".", "name", ",", "training_epochs", "+", "1", ",", "global_step", "+", "1", ",", "self", ".", "batch_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.text_models.TextModel._train_SGD_loop": [[160, 182], ["utils.text_batch_generator", "print", "print", "range", "int", "utils.text_batch_generator.next", "text_models.TextModel._train_SGD_batch_step", "utils.update_train_batch", "sess.run", "len"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.text_batch_generator", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ResnetClf._train_SGD_batch_step", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.update_train_batch"], ["", "def", "_train_SGD_loop", "(", "self", ",", "sess", ",", "train_texts", ",", "train_labels", ",", "global_step", ",", "train_writer", ")", ":", "\n", "        ", "\"\"\"Mini-batch gradient descent over training data\"\"\"", "\n", "# Book-keeping vars", "\n", "total_batches", "=", "int", "(", "len", "(", "train_texts", ")", "/", "self", ".", "batch_size", ")", "+", "1", "\n", "total_epoch_acc_val", "=", "0.", "\n", "# gen yields the next text batch at each call of .next()", "\n", "gen", "=", "text_batch_generator", "(", "self", ".", "batch_size", ",", "train_texts", ",", "train_labels", ")", "\n", "\n", "print", "(", "\"*** TOTAL BATCHES: %d ***\"", "%", "total_batches", ")", "\n", "print", "(", "\"\\nCurrent learning rate: {}\"", ".", "format", "(", "sess", ".", "run", "(", "self", ".", "learning_rate", ")", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "total_batches", ")", ":", "\n", "            ", "batch_text", ",", "batch_label", "=", "gen", ".", "next", "(", ")", "\n", "# Run the SGD for current batch, and get the summary values, loss value, and accuracy value", "\n", "summary", ",", "loss_val", ",", "acc_val", "=", "self", ".", "_train_SGD_batch_step", "(", "sess", "=", "sess", ",", "batch_image", "=", "None", ",", "\n", "batch_label", "=", "batch_label", ",", "batch_ids", "=", "None", ",", "\n", "text_train", "=", "batch_text", ",", "batch_step", "=", "global_step", ")", "\n", "# Update book-keeping vars", "\n", "global_step", ",", "total_epoch_acc_val", "=", "update_train_batch", "(", "global_step", ",", "summary", ",", "loss_val", ",", "acc_val", ",", "\n", "train_writer", ",", "total_epoch_acc_val", ",", "\n", "batches_completed_this_epoch", "=", "(", "i", "+", "1", ")", ")", "\n", "", "return", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.text_models.TextModel._val_prediction_loop": [[183, 217], ["range", "utils.training_epoch_finish_routine", "val_acc_history.append", "text_models.TextModel._validation_batch_step", "utils.update_val_batch", "len", "len", "len", "float"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.training_epoch_finish_routine", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ResnetClf._validation_batch_step", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.update_val_batch"], ["", "def", "_val_prediction_loop", "(", "self", ",", "sess", ",", "epoch", ",", "val_texts", ",", "val_labels", ",", "val_acc_history", ")", ":", "\n", "        ", "\"\"\"Run prediction loop over batches from validation\n\n        Parameters\n        ----------\n        :param sess: tf.Session() object\n\n        :param epoch: int, the current epoch number\n\n        :param val_texts: np.array of shape [NUM_VAL_SAMPLES, TEXT_LENGTH] and type int\n\n        :param val_labels: np.array of shape [NUM_VAL_SAMPLES, NUM_CLASSES] and type bool\n\n        :param val_acc_history: list, containing floats indicating past validation accuracy values\n        \"\"\"", "\n", "# Book-keeping vars for validation", "\n", "num_val_batches", "=", "(", "len", "(", "val_texts", ")", "/", "batch_size_dict", "[", "self", ".", "model_type", "]", ")", "+", "1", "\n", "val_acc_sum", "=", "0.", "\n", "num_steps", "=", "0", "\n", "num_samples", "=", "0", "\n", "for", "i", "in", "range", "(", "num_val_batches", ")", ":", "\n", "            ", "batch", "=", "batch_size_dict", "[", "self", ".", "model_type", "]", "*", "i", "\n", "end", "=", "batch", "+", "batch_size_dict", "[", "self", ".", "model_type", "]", "\n", "if", "end", ">", "len", "(", "val_texts", ")", ":", "\n", "                ", "end", "=", "len", "(", "val_texts", ")", "\n", "", "num_samples", "+=", "(", "end", "-", "batch", ")", "\n", "val_acc", "=", "self", ".", "_validation_batch_step", "(", "sess", ",", "None", ",", "val_labels", "[", "batch", ":", "end", "]", ",", "None", ",", "val_texts", "[", "batch", ":", "end", "]", ",", "\n", "batch_step", "=", "num_steps", ",", "train_mode", "=", "False", ")", "\n", "val_acc_sum", ",", "num_steps", "=", "update_val_batch", "(", "num_steps", ",", "val_acc", ",", "val_acc_sum", ",", "num_val_batches", ")", "\n", "\n", "# num_samples = len(val_ids)", "\n", "", "training_epoch_finish_routine", "(", "sess", ",", "val_acc_sum", ",", "num_samples", ",", "self", ".", "train_logfile_name", ",", "\n", "self", ".", "checkpoint_dir", ",", "epoch", ",", "self", ".", "saver", ")", "\n", "val_acc_history", ".", "append", "(", "val_acc_sum", "/", "float", "(", "num_samples", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.text_models.TextModel._run_tests": [[218, 256], ["print", "tensorflow.contrib.metrics.confusion_matrix", "range", "utils.test_finish_routine", "utils.right_align", "tensorflow.argmax", "int", "text_models.TextModel._test_batch_step", "utils.update_test_batch", "float", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.test_finish_routine", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.right_align", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ResnetClf._test_batch_step", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.update_test_batch"], ["", "def", "_run_tests", "(", "self", ",", "sess", ",", "test_ids", ",", "test_labels", ",", "test_texts", ",", "iterator_test_init", ",", "next_element_test", ")", ":", "\n", "        ", "\"\"\"Run prediction loop over batches from test set\"\"\"", "\n", "print", "(", "\"\\nRunning test data through model ...\"", ")", "\n", "\n", "# Right align text data in case RNN model is used", "\n", "if", "self", ".", "model_name", "==", "ModelName", ".", "text_rnn", ":", "\n", "            ", "test_texts", "=", "right_align", "(", "test_texts", ")", "\n", "\n", "# Some required variables", "\n", "", "conf_matrix", "=", "None", "\n", "prediction", "=", "None", "\n", "test_accuracy_sum", "=", "0.", "\n", "c_mat", "=", "tf", ".", "contrib", ".", "metrics", ".", "confusion_matrix", "(", "self", ".", "predictions", ",", "tf", ".", "argmax", "(", "self", ".", "labels_placeholder", ",", "1", ")", ",", "\n", "num_classes", "=", "NUM_CLASSES", ")", "\n", "total_batches", "=", "int", "(", "len", "(", "test_labels", ")", "/", "batch_size_dict", "[", "self", ".", "model_type", "]", ")", "+", "1", "\n", "batch_num", "=", "0", "\n", "num_samples", "=", "0", "\n", "for", "i", "in", "range", "(", "total_batches", ")", ":", "\n", "            ", "batch", "=", "batch_size_dict", "[", "self", ".", "model_type", "]", "*", "i", "\n", "end", "=", "batch", "+", "batch_size_dict", "[", "self", ".", "model_type", "]", "\n", "# For the last batch", "\n", "if", "end", ">", "len", "(", "test_texts", ")", ":", "\n", "                ", "end", "=", "len", "(", "test_texts", ")", "\n", "\n", "", "num_samples", "+=", "(", "end", "-", "batch", ")", "\n", "pred", ",", "mat", ",", "test_acc", "=", "self", ".", "_test_batch_step", "(", "sess", ",", "c_mat", ",", "\n", "None", ",", "test_labels", "[", "batch", ":", "end", "]", ",", "None", ",", "test_texts", "[", "batch", ":", "end", "]", ")", "\n", "# Update all book-keeping variables", "\n", "conf_matrix", ",", "prediction", ",", "test_accuracy_sum", "=", "update_test_batch", "(", "batch_num", ",", "pred", ",", "mat", ",", "test_acc", ",", "conf_matrix", ",", "\n", "prediction", ",", "test_accuracy_sum", ",", "total_batches", ")", "\n", "batch_num", "+=", "1", "\n", "# Gather the original labels and predictions", "\n", "", "labels", ",", "predictions", "=", "test_finish_routine", "(", "test_labels", ",", "prediction", ")", "\n", "# Average over the summed accuracy", "\n", "test_accuracy", "=", "test_accuracy_sum", "/", "float", "(", "len", "(", "test_labels", ")", ")", "\n", "\n", "return", "test_accuracy", ",", "labels", ",", "predictions", ",", "conf_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.text_models.TextModel._run_validation_test": [[257, 276], ["range", "print", "int", "sess.run", "float", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "_run_validation_test", "(", "self", ",", "sess", ",", "val_ids", ",", "val_labels", ",", "val_texts", ",", "iterator_validation", ",", "next_element_val", ")", ":", "\n", "        ", "\"\"\"Run prediction over the validation set, using a pre-trained model\"\"\"", "\n", "val_acc_sum", "=", "0", "\n", "num_val_batches", "=", "int", "(", "len", "(", "val_texts", ")", "/", "batch_size_dict", "[", "self", ".", "model_type", "]", ")", "+", "1", "\n", "for", "i", "in", "range", "(", "num_val_batches", ")", ":", "\n", "            ", "batch", "=", "batch_size_dict", "[", "self", ".", "model_type", "]", "*", "i", "\n", "end", "=", "batch", "+", "batch_size_dict", "[", "self", ".", "model_type", "]", "\n", "if", "end", ">", "len", "(", "val_texts", ")", ":", "\n", "                ", "end", "=", "len", "(", "val_texts", ")", "\n", "", "val_acc", "=", "sess", ".", "run", "(", "self", ".", "sum_accuracy", ",", "feed_dict", "=", "{", "\n", "self", ".", "texts_placeholder", ":", "val_texts", "[", "batch", ":", "end", "]", ",", "\n", "self", ".", "labels_placeholder", ":", "val_labels", "[", "batch", ":", "end", "]", ",", "\n", "self", ".", "dropout_keep_prob", ":", "1.0", ",", "\n", "self", ".", "phase_train", ":", "False", "\n", "}", ")", "\n", "val_acc_sum", "+=", "val_acc", "\n", "\n", "", "val_acc", "=", "val_acc_sum", "/", "float", "(", "len", "(", "val_labels", ")", ")", "\n", "print", "(", "\"*** Validation Accuracy: %0.4f ***\"", "%", "val_acc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.text_models.TextModel._train_SGD_batch_step": [[277, 303], ["sess.run"], "methods", ["None"], ["", "def", "_train_SGD_batch_step", "(", "self", ",", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_train", ",", "train_mode", "=", "True", ",", "\n", "batch_step", "=", "1", ")", ":", "\n", "        ", "\"\"\"Run the tensorflow's computation graph for the current batch.\n\n        The train_op is computated, which is the optimization method over the weights.\n\n        Returns\n        -------\n        S: summary for tensorboard\n        loss_val: float, calculated loss value for this batch\n        acc_val: float, calculated accuracy value for this batch\n        \"\"\"", "\n", "_", "=", "batch_step", ",", "batch_image", ",", "batch_ids", "\n", "\n", "S", ",", "_", ",", "loss_val", ",", "acc_val", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "train_summary_op", ",", "self", ".", "train_op", ",", "self", ".", "loss", ",", "self", ".", "accuracy", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "texts_placeholder", ":", "text_train", ",", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "0.5", ",", "\n", "self", ".", "embedding_dropout", ":", "0.3", ",", "\n", "self", ".", "embedding_noise_std", ":", "0.01", ",", "\n", "self", ".", "phase_train", ":", "train_mode", "\n", "}", ")", "\n", "\n", "return", "S", ",", "loss_val", ",", "acc_val", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.text_models.TextModel._validation_batch_step": [[304, 322], ["sess.run"], "methods", ["None"], ["", "def", "_validation_batch_step", "(", "self", ",", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_val", ",", "train_mode", "=", "False", ",", "\n", "batch_step", "=", "1", ")", ":", "\n", "        ", "\"\"\"Run the tensorflow's computation graph for prediction on current batch\n\n        Returns\n        -------\n        val_acc: float, computed valdation accuracy over the current batch\n        \"\"\"", "\n", "_", "=", "batch_image", ",", "batch_ids", ",", "batch_step", "\n", "\n", "val_acc", "=", "sess", ".", "run", "(", "self", ".", "sum_accuracy", ",", "feed_dict", "=", "{", "\n", "self", ".", "texts_placeholder", ":", "text_val", ",", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "1.0", ",", "\n", "self", ".", "phase_train", ":", "train_mode", "\n", "}", ")", "\n", "\n", "return", "val_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.text_models.TextModel._test_batch_step": [[323, 334], ["sess.run"], "methods", ["None"], ["", "def", "_test_batch_step", "(", "self", ",", "sess", ",", "c_mat", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_test", ",", "\n", "train_mode", "=", "False", ")", ":", "\n", "        ", "_", "=", "batch_image", ",", "batch_ids", "\n", "pred", ",", "mat", ",", "test_acc", "=", "sess", ".", "run", "(", "[", "self", ".", "probabilities", ",", "c_mat", ",", "self", ".", "sum_accuracy", "]", ",", "feed_dict", "=", "{", "\n", "self", ".", "texts_placeholder", ":", "text_test", ",", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "1.0", ",", "\n", "self", ".", "phase_train", ":", "train_mode", "\n", "}", ")", "\n", "\n", "return", "pred", ",", "mat", ",", "test_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.text_models.TextCNN.__init__": [[342, 429], ["tensorflow.variable_scope", "text_models.TextModel.__init__", "isinstance", "enumerate", "sum", "tensorflow.concat", "tensorflow.reshape", "len", "len", "tensorflow.variable_scope", "tensorflow.nn.dropout", "len", "tensorflow.variable_scope", "network.weight_variable", "tensorflow.pad", "tensorflow.nn.conv2d", "utils.batch_norm", "activation", "tensorflow.nn.max_pool", "text_models.TextCNN.pooled_outputs.append", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.xw_plus_b", "text_models.TextCNN._set_predictions_optimizer_and_loss"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.batch_norm", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.max_pool", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._set_predictions_optimizer_and_loss"], ["def", "__init__", "(", "self", ",", "filter_sizes", "=", "(", "1", ",", "2", ",", "3", ")", ",", "num_filters", "=", "(", "128", ",", "256", ",", "256", ")", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "is_primary_model", "=", "True", ",", "is_trainable", "=", "True", ",", "embed_size_multiplier", "=", "1.", ")", ":", "\n", "        ", "\"\"\"Create an embedding matrix, a lookup procedure on it for text sequence input,\n            convoultion using multiple filter sizes, and final optimizations if is_primary_model=True.\n\n        Parameters\n        ----------\n        :param filter_sizes: tuple, containing the different filter sizes for convolution\n\n        :param num_filters: int or tuple, should be of same length as filter_sizes,\n            denoting the number of filter of each size. If int, it implies same number of filter for all sizes.\n\n        :param activation: activation function from tf.nn (only tf.nn.relu, tf.nn.tanh supported)\n\n        :param is_primary_model: bool, whether this model's output is used to perform the task\n\n        :param is_trainable: bool, whether parameters can be updated during training\n\n        :param embed_size_multiplier: float, factor with which to multiply default embedding size\n        \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "ModelName", ".", "text_cnn", ".", "name", ")", ":", "\n", "            ", "super", "(", "TextCNN", ",", "self", ")", ".", "__init__", "(", "model_name", "=", "ModelName", ".", "text_cnn", ",", "is_primary_model", "=", "is_primary_model", ",", "\n", "is_trainable", "=", "is_trainable", ",", "embed_size_multiplier", "=", "embed_size_multiplier", ")", "\n", "\n", "# Convert num_filters to list corresponding to number of filters for each filter size", "\n", "if", "isinstance", "(", "num_filters", ",", "int", ")", ":", "\n", "                ", "num_filters", "=", "[", "num_filters", "]", "*", "len", "(", "filter_sizes", ")", "\n", "\n", "", "assert", "len", "(", "num_filters", ")", "==", "len", "(", "filter_sizes", ")", "\n", "assert", "activation", "==", "tf", ".", "nn", ".", "relu", "or", "activation", "==", "tf", ".", "nn", ".", "tanh", "\n", "\n", "self", ".", "config", "=", "{", "\n", "'filter_sizes'", ":", "filter_sizes", ",", "\n", "'num_filters'", ":", "num_filters", ",", "\n", "'activation'", ":", "'relu'", "if", "activation", "==", "tf", ".", "nn", ".", "relu", "else", "'tanh'", "\n", "}", "\n", "# convolution + maxpool", "\n", "self", ".", "pooled_outputs", "=", "[", "]", "\n", "\n", "for", "i", ",", "filter_size", "in", "enumerate", "(", "filter_sizes", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"conv-maxpool-%s\"", "%", "filter_size", ")", ":", "\n", "# Convolution Layer", "\n", "                    ", "filter_shape", "=", "[", "filter_size", ",", "self", ".", "embedding_size", ",", "1", ",", "num_filters", "[", "i", "]", "]", "\n", "initializer_type", "=", "\"normal\"", "if", "activation", "==", "tf", ".", "nn", ".", "relu", "else", "\"xavier\"", "\n", "W_o", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "filter_shape", ",", "\n", "initializer_type", "=", "initializer_type", ",", "\n", "name", "=", "'W%d'", "%", "i", ")", "\n", "# pad to prevent dimension reduction", "\n", "twopadding", "=", "filter_size", "-", "1", "# (h+2p-f)/s + 1 = h #s=1 #same height padding", "\n", "top_padding", "=", "twopadding", "//", "2", "\n", "bottom_padding", "=", "twopadding", "-", "top_padding", "\n", "self", ".", "x_padded", "=", "tf", ".", "pad", "(", "self", ".", "x_text", ",", "[", "[", "0", ",", "0", "]", ",", "[", "top_padding", ",", "bottom_padding", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "# Do convolution + batch_norm + activation", "\n", "conv", "=", "tf", ".", "nn", ".", "conv2d", "(", "self", ".", "x_padded", ",", "W_o", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "'VALID'", ",", "name", "=", "\"conv\"", ")", "\n", "bn_conv", "=", "batch_norm", "(", "conv", ",", "num_filters", "[", "i", "]", ",", "self", ".", "phase_train", ")", "\n", "h", "=", "activation", "(", "bn_conv", ",", "\"activation\"", ")", "\n", "\n", "# Maxpooling over the outputs", "\n", "pooled", "=", "tf", ".", "nn", ".", "max_pool", "(", "\n", "h", ",", "\n", "ksize", "=", "[", "1", ",", "TEXT_LENTH", ",", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "padding", "=", "'VALID'", ",", "\n", "name", "=", "\"pool\"", ")", "\n", "\n", "self", ".", "pooled_outputs", ".", "append", "(", "pooled", ")", "\n", "\n", "# Combine all the pooled features", "\n", "", "", "self", ".", "final_embedding_dimension", "=", "sum", "(", "num_filters", ")", "\n", "self", ".", "h_pool", "=", "tf", ".", "concat", "(", "self", ".", "pooled_outputs", ",", "3", ")", "\n", "self", ".", "h_pool_flat", "=", "tf", ".", "reshape", "(", "self", ".", "h_pool", ",", "[", "-", "1", ",", "self", ".", "final_embedding_dimension", "]", ")", "\n", "\n", "# Add dropout", "\n", "with", "tf", ".", "variable_scope", "(", "\"dropout\"", ")", ":", "\n", "                ", "self", ".", "h_drop", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "h_pool_flat", ",", "self", ".", "dropout_keep_prob", ")", "\n", "\n", "", "if", "is_trainable", ":", "\n", "# Final (unnormalized) scores and predictions", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"output\"", ")", ":", "\n", "                    ", "W_o", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "\n", "shape", "=", "[", "self", ".", "final_embedding_dimension", ",", "NUM_CLASSES", "]", ",", "\n", "name", "=", "'W_o'", ",", "initializer_type", "=", "'xavier'", "if", "USE_MULTILABEL", "else", "'normal'", ")", "\n", "b_o", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "NUM_CLASSES", "]", ",", "name", "=", "'b_o'", ")", "\n", "self", ".", "scores", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "self", ".", "h_drop", ",", "W_o", ",", "b_o", ",", "name", "=", "\"scores\"", ")", "# unnormalized scores", "\n", "\n", "", "if", "self", ".", "is_primary_model", ":", "\n", "                    ", "self", ".", "_set_predictions_optimizer_and_loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.text_models.HieText.__init__": [[437, 536], ["tensorflow.variable_scope", "text_models.TextModel.__init__", "isinstance", "enumerate", "tensorflow.concat", "tensorflow.reduce_max", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.nn.dynamic_rnn", "tensorflow.concat", "tensorflow.concat", "tensorflow.reduce_mean", "tensorflow.contrib.rnn.DropoutWrapper", "tensorflow.variable_scope", "tensorflow.nn.dropout", "len", "tensorflow.name_scope", "network.weight_variable", "tensorflow.pad", "tensorflow.nn.conv2d", "utils.batch_norm", "text_models.HieText.activation", "text_models.HieText.conv_output.append", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.xw_plus_b", "text_models.HieText._set_predictions_optimizer_and_loss"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.batch_norm", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._set_predictions_optimizer_and_loss"], ["def", "__init__", "(", "self", ",", "is_primary_model", ",", "is_trainable", ",", "filter_sizes", "=", "(", "1", ",", "2", ",", "3", ")", ",", "num_filters", "=", "128", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "tanh", ")", ":", "\n", "        ", "\"\"\"Define the TF elements for HieCoAtt's text representation.\n\n        Parameters\n        ----------\n        :param filter_sizes: tuple, containing the different filter sizes for convolution\n\n        :param num_filters: int, number of filters of each size\n\n        :param activation: activation function from tf.nn (only tf.nn.relu, tf.nn.tanh supported)\n\n        :param is_primary_model: bool, whether this model's output is used to perform the task\n\n        :param is_trainable: bool, whether parameters can be updated during training\n        \"\"\"", "\n", "assert", "activation", "==", "tf", ".", "nn", ".", "relu", "or", "activation", "==", "tf", ".", "nn", ".", "tanh", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "initializer_type", "=", "'xavier'", "if", "self", ".", "activation", "==", "tf", ".", "nn", ".", "tanh", "else", "'normal'", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "ModelName", ".", "hie_text", ".", "name", ")", ":", "\n", "            ", "super", "(", "HieText", ",", "self", ")", ".", "__init__", "(", "model_name", "=", "ModelName", ".", "hie_text", ",", "is_primary_model", "=", "is_primary_model", ",", "\n", "is_trainable", "=", "is_trainable", ")", "\n", "\n", "# Convert num_filters to list corresponding to number of filters for each filter size", "\n", "if", "isinstance", "(", "num_filters", ",", "int", ")", ":", "\n", "                ", "num_filters", "=", "[", "num_filters", "]", "*", "len", "(", "filter_sizes", ")", "\n", "# Dimension of phrase level features should match dimension of word-level features", "\n", "# So, we need that num_filters matches EMBED_SIZES", "\n", "", "assert", "num_filters", "==", "EMBED_SIZES", "\n", "\n", "self", ".", "config", "=", "{", "\n", "'filter_sizes'", ":", "filter_sizes", ",", "\n", "'num_filters'", ":", "num_filters", ",", "\n", "'activation'", ":", "'relu'", "if", "self", ".", "activation", "==", "tf", ".", "nn", ".", "relu", "else", "'tanh'", "\n", "}", "\n", "\n", "# Shape fo self.word_level: [BATCH_SIZE, TEXT_LENGTH, EMBED_SIZES]", "\n", "self", ".", "word_level", "=", "self", ".", "seq_embedded", "\n", "\n", "# Convolution for phrase level", "\n", "self", ".", "conv_output", "=", "[", "]", "\n", "for", "i", ",", "filter_size", "in", "enumerate", "(", "filter_sizes", ")", ":", "\n", "                ", "with", "tf", ".", "name_scope", "(", "\"conv-%s\"", "%", "filter_size", ")", ":", "\n", "# Convolution Layer", "\n", "                    ", "filter_shape", "=", "[", "filter_size", ",", "EMBED_SIZES", ",", "1", ",", "num_filters", "[", "i", "]", "]", "\n", "W", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "filter_shape", ",", "\n", "initializer_type", "=", "self", ".", "initializer_type", ",", "\n", "name", "=", "'W%d'", "%", "i", ")", "\n", "twopadding", "=", "filter_size", "-", "1", "# (h+2p-f)/s + 1 = h #s=1 #same height padding", "\n", "top_padding", "=", "twopadding", "//", "2", "\n", "bottom_padding", "=", "twopadding", "-", "top_padding", "\n", "self", ".", "x_padded", "=", "tf", ".", "pad", "(", "self", ".", "x_text", ",", "[", "[", "0", ",", "0", "]", ",", "[", "top_padding", ",", "bottom_padding", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "conv", "=", "tf", ".", "nn", ".", "conv2d", "(", "self", ".", "x_padded", ",", "W", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "'VALID'", ",", "name", "=", "\"conv\"", ")", "\n", "bn_conv", "=", "batch_norm", "(", "conv", ",", "num_filters", "[", "i", "]", ",", "self", ".", "phase_train", ")", "\n", "h", "=", "self", ".", "activation", "(", "bn_conv", ",", "name", "=", "\"activation\"", ")", "\n", "self", ".", "conv_output", ".", "append", "(", "h", ")", "\n", "\n", "# Shape of full_conv_output: [BATCH_SIZE, TEXT_LENGTH, len(filter_sizes), num_filters]", "\n", "", "", "full_conv_output", "=", "tf", ".", "concat", "(", "self", ".", "conv_output", ",", "2", ")", "\n", "\n", "# Phrase level output shape: [BATCH_SIZE, TEXT_LENGTH, num_filters]", "\n", "self", ".", "phase_level", "=", "tf", ".", "reduce_max", "(", "full_conv_output", ",", "2", ")", "\n", "\n", "# Sentence Level", "\n", "lstm_cell", "=", "rnn", ".", "BasicLSTMCell", "(", "EMBED_SIZES", ")", "\n", "if", "self", ".", "dropout_keep_prob", "is", "not", "None", ":", "\n", "                ", "lstm_cell", "=", "rnn", ".", "DropoutWrapper", "(", "lstm_cell", ",", "\n", "output_keep_prob", "=", "self", ".", "dropout_keep_prob", ")", "\n", "", "self", ".", "lstm_outputs", ",", "states", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "lstm_cell", ",", "\n", "self", ".", "phase_level", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "# Sentence_level text output", "\n", "# [BATCH_SIZE, TEXT_LENGTH, num_filters]", "\n", "self", ".", "sentence_level", "=", "tf", ".", "concat", "(", "self", ".", "lstm_outputs", ",", "1", ")", "\n", "\n", "# Concatenate the different levels.", "\n", "# We tried the hierarchical approach in Lu et al., but it gave inferior results.", "\n", "self", ".", "final_text_embedding_spatial", "=", "tf", ".", "concat", "(", "values", "=", "(", "self", ".", "word_level", ",", "\n", "self", ".", "phase_level", ",", "\n", "self", ".", "sentence_level", ")", ",", "\n", "axis", "=", "-", "1", ")", "\n", "self", ".", "final_text_embedding", "=", "tf", ".", "reduce_mean", "(", "self", ".", "final_text_embedding_spatial", ",", "axis", "=", "1", ")", "\n", "# Add dropout", "\n", "with", "tf", ".", "variable_scope", "(", "\"dropout\"", ")", ":", "\n", "                ", "self", ".", "final_text_embedding", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "final_text_embedding", ",", "self", ".", "dropout_keep_prob", ")", "\n", "", "self", ".", "final_embedding_dimension", "=", "self", ".", "final_text_embedding", ".", "shape", "[", "1", "]", ".", "value", "\n", "\n", "if", "is_trainable", ":", "\n", "# Final (unnormalized) scores and predictions", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"output\"", ")", ":", "\n", "                    ", "W_o", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "\n", "shape", "=", "[", "self", ".", "final_embedding_dimension", ",", "NUM_CLASSES", "]", ",", "\n", "name", "=", "'W_o'", ",", "initializer_type", "=", "'xavier'", "if", "USE_MULTILABEL", "else", "'normal'", ")", "\n", "b_o", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "NUM_CLASSES", "]", ",", "name", "=", "'b_o'", ")", "\n", "self", ".", "scores", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "self", ".", "final_text_embedding", ",", "W_o", ",", "b_o", ",", "name", "=", "\"scores\"", ")", "\n", "\n", "", "if", "self", ".", "is_primary_model", ":", "\n", "                    ", "self", ".", "_set_predictions_optimizer_and_loss", "(", ")", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel.__init__": [[35, 48], ["tensorflow.placeholder", "tensorflow.reshape", "base_model.BaseModel.__init__", "base_model.BaseModel.__init__"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__"], ["def", "__init__", "(", "self", ",", "model_name", ",", "model_type", "=", "None", ",", "is_trainable", "=", "True", ",", "is_primary_model", "=", "True", ")", ":", "\n", "        ", "if", "model_type", "is", "None", ":", "\n", "            ", "super", "(", "ImageModel", ",", "self", ")", ".", "__init__", "(", "model_type", "=", "ModelType", ".", "image_only", ",", "model_name", "=", "model_name", ",", "\n", "is_trainable", "=", "is_trainable", ",", "is_primary_model", "=", "is_primary_model", ")", "\n", "", "else", ":", "\n", "            ", "super", "(", "ImageModel", ",", "self", ")", ".", "__init__", "(", "model_type", "=", "model_type", ",", "model_name", "=", "model_name", ",", "\n", "is_trainable", "=", "is_trainable", ",", "is_primary_model", "=", "is_primary_model", ")", "\n", "\n", "# placeholder for image data", "\n", "", "self", ".", "images_placeholder", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "shape", "=", "[", "None", ",", "IMAGE_PIXELS", "]", ",", "name", "=", "'images'", ")", "\n", "\n", "# input layer # 4D tensor: [batch_size, image_size, image_size, channel_size]", "\n", "self", ".", "x_image", "=", "tf", ".", "reshape", "(", "self", ".", "images_placeholder", ",", "[", "-", "1", ",", "IMAGE_SIZE", ",", "IMAGE_SIZE", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel.save_bottleneck_data": [[49, 51], ["None"], "methods", ["None"], ["", "def", "save_bottleneck_data", "(", "self", ",", "sess", ",", "layer_name", ",", "input_ids", ",", "input_labels", ",", "input_texts", ",", "output_filename", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel._train_helper_SGD": [[52, 94], ["range", "print", "image_models.ImageModel.early_stopping_procedure", "image_models.ImageModel._train_SGD_loop", "image_models.ImageModel._val_prediction_loop", "utils.training_epoch_finish_routine", "print", "print", "sess.run"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.early_stopping_procedure", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel._train_SGD_loop", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel._val_prediction_loop", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.training_epoch_finish_routine"], ["", "def", "_train_helper_SGD", "(", "self", ",", "sess", ",", "train_writer", ",", "train_ids", ",", "train_labels", ",", "train_texts", ",", "\n", "val_ids", ",", "val_labels", ",", "val_texts", ",", "iterator_train_init", ",", "next_element_train", ",", "iterator_val_init", ",", "\n", "next_element_val", ")", ":", "\n", "# Ignore texts", "\n", "        ", "batch_size", "=", "batch_size_dict", "[", "self", ".", "model_type", "]", "\n", "training_epochs", "=", "training_epochs_dict", "[", "self", ".", "model_type", "]", "\n", "\n", "# EARLY STOPPING VARS", "\n", "val_acc_history", "=", "[", "]", "\n", "epochs_with_current_lrate", "=", "0", "\n", "min_increment", "=", "0.0002", "\n", "tolerable_decrease", "=", "0.0004", "\n", "\n", "global_step", "=", "0", "\n", "for", "epoch", "in", "range", "(", "training_epochs", ")", ":", "\n", "# Decay learning rate if required", "\n", "            ", "early_stop", ",", "epochs_with_current_lrate", "=", "self", ".", "early_stopping_procedure", "(", "sess", ",", "\n", "epochs_with_current_lrate", ",", "\n", "val_acc_history", ",", "\n", "min_increment", ",", "tolerable_decrease", ")", "\n", "if", "early_stop", ":", "break", "\n", "\n", "# Running over full training data", "\n", "try", ":", "\n", "                ", "print", "(", "\"\\nCurrent learning rate: {}\"", ".", "format", "(", "sess", ".", "run", "(", "self", ".", "learning_rate", ")", ")", ")", "\n", "", "except", "TypeError", ":", "\n", "                ", "print", "(", "\"\\nCurrent learning rate: {}\"", ".", "format", "(", "self", ".", "learning_rate", ")", ")", "\n", "# Running training GD for this epoch", "\n", "", "global_step", "=", "self", ".", "_train_SGD_loop", "(", "sess", ",", "iterator_train_init", ",", "next_element_train", ",", "\n", "train_labels", ",", "None", ",", "train_writer", ",", "global_step", ")", "\n", "\n", "# Now performing validation", "\n", "num_val_samples", ",", "val_acc_sum", "=", "self", ".", "_val_prediction_loop", "(", "sess", ",", "iterator_val_init", ",", "\n", "next_element_val", ",", "val_labels", ",", "\n", "None", ",", "epoch", ")", "\n", "\n", "training_epoch_finish_routine", "(", "sess", ",", "val_acc_sum", ",", "num_val_samples", ",", "self", ".", "train_logfile_name", ",", "\n", "self", ".", "checkpoint_dir", ",", "epoch", ",", "self", ".", "saver", ")", "\n", "\n", "# Completed all epochs", "\n", "", "print", "(", "\"Completed training %s model, with %d epochs, each with %d minibatches each of size %d\"", "\n", "%", "(", "self", ".", "model_name", ".", "name", ",", "training_epochs", "+", "1", ",", "global_step", "+", "1", ",", "batch_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel._train_SGD_loop": [[95, 121], ["sess.run", "print", "int", "image_models.ImageModel._train_SGD_batch_step", "utils.update_train_batch", "sess.run", "len"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ResnetClf._train_SGD_batch_step", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.update_train_batch"], ["", "def", "_train_SGD_loop", "(", "self", ",", "sess", ",", "iterator_train_init", ",", "next_element_train", ",", "train_labels", ",", "text_train", ",", "\n", "train_writer", ",", "global_step", ")", ":", "\n", "        ", "\"\"\"Run the gradient descent loop over batches for this epoch\"\"\"", "\n", "# Initialize the iterator", "\n", "sess", ".", "run", "(", "iterator_train_init", ")", "\n", "# Initialize other book-keeping variables", "\n", "batch_size", "=", "batch_size_dict", "[", "self", ".", "model_type", "]", "\n", "total_batches", "=", "int", "(", "len", "(", "train_labels", ")", "/", "batch_size", ")", "+", "1", "\n", "batches_completed_this_epoch", "=", "0", "\n", "total_epoch_acc_val", "=", "0.", "\n", "print", "(", "\"*** TOTAL BATCHES: %d ***\"", "%", "total_batches", ")", "\n", "# Running over all mini-batches in this epoch", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "batch_image", ",", "_", ",", "batch_ids", "=", "sess", ".", "run", "(", "next_element_train", ")", "\n", "batches_completed_this_epoch", "+=", "1", "\n", "# Completed all minibatches in train set", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "\n", "", "S", ",", "loss_val", ",", "acc_val", "=", "self", ".", "_train_SGD_batch_step", "(", "sess", ",", "batch_image", ",", "train_labels", "[", "batch_ids", "]", ",", "\n", "batch_ids", ",", "text_train", ",", "batch_step", "=", "global_step", ")", "\n", "global_step", ",", "total_epoch_acc_val", "=", "update_train_batch", "(", "global_step", ",", "S", ",", "loss_val", ",", "acc_val", ",", "train_writer", ",", "\n", "total_epoch_acc_val", ",", "batches_completed_this_epoch", ")", "\n", "\n", "", "return", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel._val_prediction_loop": [[122, 146], ["print", "sess.run", "int", "image_models.ImageModel._validation_batch_step", "utils.update_val_batch", "len", "sess.run", "len"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ResnetClf._validation_batch_step", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.update_val_batch"], ["", "def", "_val_prediction_loop", "(", "self", ",", "sess", ",", "iterator_val_init", ",", "next_element_val", ",", "val_labels", ",", "text_val", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Run prediction over all batches in the validation set\"\"\"", "\n", "print", "(", "\"\\nRunning on validation data for epoch number %d\"", "%", "(", "epoch", "+", "1", ")", ")", "\n", "\n", "batch_size", "=", "batch_size_dict", "[", "self", ".", "model_type", "]", "\n", "total_batches", "=", "int", "(", "len", "(", "val_labels", ")", "/", "batch_size", ")", "+", "1", "\n", "\n", "# Initialize the iterator and other book-keeping vars", "\n", "sess", ".", "run", "(", "iterator_val_init", ")", "\n", "val_acc_sum", "=", "0", "\n", "num_steps", "=", "0", "\n", "num_val_samples", "=", "0", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "batch_image", ",", "_", ",", "batch_ids", "=", "sess", ".", "run", "(", "next_element_val", ")", "\n", "# Completed all minibatches in validation set", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "\n", "", "val_acc", "=", "self", ".", "_validation_batch_step", "(", "sess", ",", "batch_image", ",", "val_labels", "[", "batch_ids", "]", ",", "batch_ids", ",", "text_val", ",", "\n", "batch_step", "=", "num_steps", ")", "\n", "val_acc_sum", ",", "num_steps", "=", "update_val_batch", "(", "num_steps", ",", "val_acc", ",", "val_acc_sum", ",", "total_batches", ")", "\n", "num_val_samples", "+=", "len", "(", "batch_ids", ")", "\n", "", "return", "num_val_samples", ",", "val_acc_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel._run_tests": [[147, 178], ["print", "tensorflow.contrib.metrics.confusion_matrix", "sess.run", "float", "utils.test_finish_routine", "tensorflow.argmax", "image_models.ImageModel._test_batch_step", "utils.update_test_batch", "len", "len", "sess.run"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.test_finish_routine", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ResnetClf._test_batch_step", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.update_test_batch"], ["", "def", "_run_tests", "(", "self", ",", "sess", ",", "test_ids", ",", "test_labels", ",", "test_texts", ",", "iterator_test_init", ",", "next_element_test", ")", ":", "\n", "# Ignore texts", "\n", "        ", "_", "=", "test_texts", "\n", "print", "(", "\"\\nRunning test data through model ...\"", ")", "\n", "# Some required variables", "\n", "conf_matrix", "=", "None", "\n", "prediction", "=", "None", "\n", "test_accuracy", "=", "0.", "\n", "c_mat", "=", "tf", ".", "contrib", ".", "metrics", ".", "confusion_matrix", "(", "self", ".", "predictions", ",", "tf", ".", "argmax", "(", "self", ".", "labels_placeholder", ",", "1", ")", ",", "\n", "num_classes", "=", "NUM_CLASSES", ")", "\n", "total_batches", "=", "(", "len", "(", "test_labels", ")", "/", "batch_size_dict", "[", "self", ".", "model_type", "]", ")", "+", "1", "\n", "sess", ".", "run", "(", "iterator_test_init", ")", "\n", "batch_num", "=", "0", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "batch_image", ",", "_", ",", "batch_ids", "=", "sess", ".", "run", "(", "next_element_test", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "# Completed all minibatches in test set", "\n", "                ", "break", "\n", "\n", "", "pred", ",", "mat", ",", "test_acc", "=", "self", ".", "_test_batch_step", "(", "sess", ",", "c_mat", ",", "\n", "batch_image", ",", "test_labels", "[", "batch_ids", "]", ",", "batch_ids", ",", "text_test", "=", "None", ")", "\n", "\n", "conf_matrix", ",", "prediction", ",", "test_accuracy", "=", "update_test_batch", "(", "batch_num", ",", "pred", ",", "mat", ",", "test_acc", ",", "conf_matrix", ",", "prediction", ",", "test_accuracy", ",", "total_batches", ")", "\n", "batch_num", "+=", "1", "\n", "\n", "", "test_accuracy", "/=", "float", "(", "len", "(", "test_labels", ")", ")", "\n", "labels", ",", "results", "=", "test_finish_routine", "(", "test_labels", ",", "prediction", ")", "\n", "\n", "return", "test_accuracy", ",", "labels", ",", "results", ",", "conf_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel._run_validation_test": [[179, 198], ["sess.run", "len", "print", "int", "image_models.ImageModel._validation_batch_step", "utils.update_val_batch", "sess.run", "len", "float"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ResnetClf._validation_batch_step", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.update_val_batch"], ["", "def", "_run_validation_test", "(", "self", ",", "sess", ",", "val_ids", ",", "val_labels", ",", "val_texts", ",", "iterator_validation_init", ",", "next_element_val", ")", ":", "\n", "        ", "batch_size", "=", "batch_size_dict", "[", "self", ".", "model_type", "]", "\n", "total_batches", "=", "int", "(", "len", "(", "val_labels", ")", "/", "batch_size", ")", "+", "1", "\n", "\n", "sess", ".", "run", "(", "iterator_validation_init", ")", "\n", "\n", "val_acc_sum", "=", "0", "\n", "num_steps", "=", "0", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "batch_image", ",", "batch_label", ",", "batch_ids", "=", "sess", ".", "run", "(", "next_element_val", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "# Completed all minibatches in test set", "\n", "                ", "break", "\n", "", "val_acc", "=", "self", ".", "_validation_batch_step", "(", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "None", ",", "batch_step", "=", "num_steps", ")", "\n", "val_acc_sum", ",", "num_steps", "=", "update_val_batch", "(", "num_steps", ",", "val_acc", ",", "val_acc_sum", ",", "total_batches", ")", "\n", "\n", "", "num_samples", "=", "len", "(", "val_ids", ")", "\n", "print", "(", "\"*** Validation accuracy: %0.4f ***\"", "%", "(", "val_acc_sum", "/", "float", "(", "num_samples", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel._train_SGD_batch_step": [[199, 212], ["sess.run"], "methods", ["None"], ["", "def", "_train_SGD_batch_step", "(", "self", ",", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_train", ",", "train_mode", "=", "True", ",", "\n", "batch_step", "=", "1", ")", ":", "\n", "# ignore batch_ids & text_train", "\n", "        ", "_", ",", "_", "=", "batch_ids", ",", "text_train", "\n", "S", ",", "_", ",", "loss_val", ",", "acc_val", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "train_summary_op", ",", "self", ".", "train_op", ",", "self", ".", "loss", ",", "self", ".", "accuracy", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "images_placeholder", ":", "batch_image", ",", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "0.5", ",", "\n", "self", ".", "train_mode", ":", "train_mode", "\n", "}", ")", "\n", "return", "S", ",", "loss_val", ",", "acc_val", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel._validation_batch_step": [[213, 226], ["sess.run"], "methods", ["None"], ["", "def", "_validation_batch_step", "(", "self", ",", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_val", ",", "train_mode", "=", "True", ",", "\n", "batch_step", "=", "1", ")", ":", "\n", "# ignore batch_ids & text_train", "\n", "        ", "_", "=", "batch_ids", ",", "text_val", ",", "batch_step", "\n", "val_acc_step", "=", "sess", ".", "run", "(", "\n", "self", ".", "sum_accuracy", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "images_placeholder", ":", "batch_image", ",", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "1.0", ",", "\n", "self", ".", "train_mode", ":", "train_mode", "\n", "}", ")", "\n", "return", "val_acc_step", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageModel._test_batch_step": [[227, 239], ["sess.run"], "methods", ["None"], ["", "def", "_test_batch_step", "(", "self", ",", "sess", ",", "c_mat", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_test", ",", "train_mode", "=", "True", ")", ":", "\n", "# ignore batch_ids & text_test", "\n", "        ", "_", ",", "_", "=", "batch_ids", ",", "text_test", "\n", "pred", ",", "mat", ",", "test_acc", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "probabilities", ",", "c_mat", ",", "self", ".", "sum_accuracy", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "images_placeholder", ":", "batch_image", ",", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "1.0", ",", "\n", "self", ".", "train_mode", ":", "train_mode", "\n", "}", ")", "\n", "return", "pred", ",", "mat", ",", "test_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.Resnet.__init__": [[242, 280], ["resnet.inference", "tensorflow.reshape", "print", "image_models.ImageModel.__init__", "image_models.ImageModel.__init__", "int", "int", "paths.get_resnet_stored_filename", "tensorflow.global_variables_initializer", "tensorflow.global_variables", "tensorflow.train.Saver", "tensorflow.Session", "image_models.Resnet.restore_model_from_filename", "ValueError"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.inference", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.paths.get_resnet_stored_filename", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.restore_model_from_filename"], ["    ", "def", "__init__", "(", "self", ",", "train_last_block", ",", "restore", "=", "False", ",", "model_name", "=", "None", ",", "is_trainable", "=", "False", ")", ":", "\n", "        ", "if", "model_name", "is", "None", ":", "\n", "            ", "super", "(", "Resnet", ",", "self", ")", ".", "__init__", "(", "model_name", "=", "ModelName", ".", "resnet", ",", "is_trainable", "=", "is_trainable", ")", "\n", "", "else", ":", "\n", "            ", "super", "(", "Resnet", ",", "self", ")", ".", "__init__", "(", "model_name", "=", "model_name", ",", "is_trainable", "=", "is_trainable", ")", "\n", "\n", "", "self", ".", "bottleneck", "=", "True", "\n", "dim_m", "=", "int", "(", "IMAGE_SIZE", "/", "32", ")", "*", "int", "(", "IMAGE_SIZE", "/", "32", ")", "\n", "dim_d", "=", "512", "if", "not", "self", ".", "bottleneck", "else", "512", "*", "4", "\n", "\n", "if", "RESNET_LAYERS", "==", "50", ":", "\n", "            ", "num_blocks", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", "\n", "", "elif", "RESNET_LAYERS", "==", "101", ":", "\n", "            ", "num_blocks", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", "\n", "", "elif", "RESNET_LAYERS", "==", "152", ":", "\n", "            ", "num_blocks", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid value %d for RESNET_LAYERS\"", "%", "RESNET_LAYERS", ")", "\n", "\n", "", "_", ",", "self", ".", "avg_pool_representation", ",", "self", ".", "representation", ",", "self", ".", "representation_one_block_before", "=", "resnet", ".", "inference", "(", "\n", "self", ".", "images_placeholder", ",", "\n", "num_classes", "=", "1000", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "\n", "bottleneck", "=", "self", ".", "bottleneck", ",", "\n", "num_blocks", "=", "num_blocks", ",", "\n", "train_last_block", "=", "train_last_block", ")", "\n", "\n", "self", ".", "representation", "=", "tf", ".", "reshape", "(", "self", ".", "representation", ",", "shape", "=", "[", "-", "1", ",", "dim_m", "*", "dim_d", "]", ")", "\n", "\n", "if", "restore", ":", "\n", "            ", "resnet_ckpt_filename", "=", "get_resnet_stored_filename", "(", "file_type", "=", "'ckpt'", ",", "num_layers", "=", "RESNET_LAYERS", ")", "\n", "self", ".", "global_variable_init", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "vars_to_restore", "=", "tf", ".", "global_variables", "(", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "vars_to_restore", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "resnet_sess", ":", "\n", "                ", "self", ".", "restore_model_from_filename", "(", "resnet_sess", ",", "model_filename", "=", "resnet_ckpt_filename", ",", "saver", "=", "saver", ")", "\n", "\n", "", "", "print", "(", "\"Completed Resnet.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.Resnet.save_bottleneck_data": [[281, 283], ["None"], "methods", ["None"], ["", "def", "save_bottleneck_data", "(", "self", ",", "sess", ",", "layer_name", ",", "input_ids", ",", "input_labels", ",", "input_texts", ",", "output_filename", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageCNN.__init__": [[291, 355], ["image_models.ImageModel.__init__", "image_models.ImageCNN._set_predictions_optimizer_and_loss", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "network.max_pool", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "network.max_pool", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "network.max_pool", "tensorflow.variable_scope", "network.lr_norm", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "network.max_pool", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.reshape", "tensorflow.nn.relu", "tensorflow.nn.dropout", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.softmax", "network.conv2d", "network.conv2d", "network.conv2d", "network.conv2d", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._set_predictions_optimizer_and_loss", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.max_pool", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.max_pool", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.max_pool", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.lr_norm", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.max_pool", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d"], ["def", "__init__", "(", "self", ",", "is_trainable", "=", "True", ")", ":", "\n", "        ", "super", "(", "ImageCNN", ",", "self", ")", ".", "__init__", "(", "model_name", "=", "ModelName", ".", "image_cnn", ")", "\n", "\n", "# MODEL DEFINITION", "\n", "# ================================================================================", "\n", "# conv 1 # padding='SAME'", "\n", "with", "tf", ".", "variable_scope", "(", "'image_conv1'", ")", ":", "\n", "# [filter_size, filter_size, channel_size, num_filters]", "\n", "            ", "self", ".", "W_conv1", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "7", ",", "7", ",", "3", ",", "64", "]", ",", "stddev", "=", "5e-2", ")", "\n", "self", ".", "b_conv1", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "64", "]", ")", "\n", "self", ".", "h_conv1", "=", "tf", ".", "nn", ".", "relu", "(", "conv2d", "(", "self", ".", "x_image", ",", "self", ".", "W_conv1", ",", "is_training", "=", "self", ".", "train_mode", ")", "+", "self", ".", "b_conv1", ")", "\n", "# [128,128,64] -> [64,64,64] # ksize=[1,2,2,1], strides=[1,2,2,1]", "\n", "", "with", "tf", ".", "variable_scope", "(", "'image_pool1'", ")", ":", "\n", "            ", "self", ".", "h_pool1", "=", "max_pool", "(", "self", ".", "h_conv1", ")", "\n", "\n", "# conv2", "\n", "", "with", "tf", ".", "variable_scope", "(", "'image_conv2'", ")", ":", "\n", "            ", "self", ".", "W_conv2", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "7", ",", "7", ",", "64", ",", "128", "]", ",", "stddev", "=", "5e-2", ")", "\n", "self", ".", "b_conv2", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "128", "]", ")", "\n", "self", ".", "h_conv2", "=", "tf", ".", "nn", ".", "relu", "(", "conv2d", "(", "self", ".", "h_pool1", ",", "self", ".", "W_conv2", ",", "isnorm", "=", "False", ",", "\n", "is_training", "=", "self", ".", "train_mode", ")", "+", "self", ".", "b_conv2", ")", "\n", "# [64,64,128] -> [32,32,128]", "\n", "", "with", "tf", ".", "variable_scope", "(", "'image_pool2'", ")", ":", "\n", "            ", "self", ".", "h_pool2", "=", "max_pool", "(", "self", ".", "h_conv2", ")", "\n", "\n", "# conv 3 [32,32,128] -> [16,16,256]", "\n", "", "with", "tf", ".", "variable_scope", "(", "'image_conv3'", ")", ":", "\n", "            ", "self", ".", "W_conv3", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "5", ",", "5", ",", "128", ",", "256", "]", ",", "stddev", "=", "5e-2", ")", "\n", "self", ".", "b_conv3", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "256", "]", ")", "\n", "self", ".", "h_conv3", "=", "tf", ".", "nn", ".", "relu", "(", "conv2d", "(", "self", ".", "h_pool2", ",", "self", ".", "W_conv3", ",", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "isnorm", "=", "False", ",", "is_training", "=", "self", ".", "train_mode", ")", "+", "self", ".", "b_conv3", ")", "\n", "# [16,16,256] -> [8,8,256]", "\n", "", "with", "tf", ".", "variable_scope", "(", "'image_pool3'", ")", ":", "\n", "            ", "self", ".", "h_pool3", "=", "max_pool", "(", "self", ".", "h_conv3", ")", "\n", "# norm 3", "\n", "", "with", "tf", ".", "variable_scope", "(", "'image_norm3'", ")", ":", "\n", "            ", "self", ".", "h_norm3", "=", "lr_norm", "(", "self", ".", "h_pool3", ",", "4", ")", "\n", "\n", "# conv 4 [8,8,256] -> [2,2,512]", "\n", "", "with", "tf", ".", "variable_scope", "(", "'image_conv4'", ")", ":", "\n", "            ", "self", ".", "W_conv4", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "5", ",", "5", ",", "256", ",", "512", "]", ",", "stddev", "=", "5e-2", ")", "\n", "self", ".", "b_conv4", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "512", "]", ")", "\n", "self", ".", "h_conv4", "=", "tf", ".", "nn", ".", "relu", "(", "conv2d", "(", "self", ".", "h_norm3", ",", "self", ".", "W_conv4", ",", "strides", "=", "[", "1", ",", "4", ",", "4", ",", "1", "]", ",", "\n", "isnorm", "=", "False", ",", "is_training", "=", "self", ".", "train_mode", ")", "+", "self", ".", "b_conv4", ")", "\n", "# [2,2,512] -> [1,1,512]", "\n", "", "with", "tf", ".", "variable_scope", "(", "'image_pool4'", ")", ":", "\n", "            ", "self", ".", "h_pool4", "=", "max_pool", "(", "self", ".", "h_conv4", ")", "\n", "\n", "# fc", "\n", "", "with", "tf", ".", "variable_scope", "(", "'image_fc1'", ")", ":", "\n", "            ", "self", ".", "W_fc1", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "512", ",", "256", "]", ",", "stddev", "=", "0.04", ")", "\n", "self", ".", "b_fc1", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "256", "]", ")", "\n", "self", ".", "h_pool4_flat", "=", "tf", ".", "reshape", "(", "self", ".", "h_pool4", ",", "[", "-", "1", ",", "512", "]", ")", "\n", "self", ".", "h_fc1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "h_pool4_flat", ",", "self", ".", "W_fc1", ")", "+", "self", ".", "b_fc1", ")", "\n", "# dropout", "\n", "self", ".", "h_fc1_drop", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "h_fc1", ",", "self", ".", "dropout_keep_prob", ")", "\n", "# softmax", "\n", "", "with", "tf", ".", "variable_scope", "(", "'softmax'", ")", ":", "\n", "            ", "self", ".", "W_softmax", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "256", ",", "NUM_CLASSES", "]", ",", "stddev", "=", "0.01", ")", "\n", "self", ".", "b_softmax", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "NUM_CLASSES", "]", ")", "\n", "self", ".", "probabilities", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "self", ".", "h_fc1_drop", ",", "self", ".", "W_softmax", ")", "+", "self", ".", "b_softmax", ")", "\n", "\n", "# Finalize the predictions, the optimizing function, loss/accuracy stats etc.", "\n", "", "self", ".", "_set_predictions_optimizer_and_loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageCNN.save_bottleneck_data": [[356, 358], ["None"], "methods", ["None"], ["", "def", "save_bottleneck_data", "(", "self", ",", "sess", ",", "layer_name", ",", "input_ids", ",", "input_labels", ",", "input_texts", ",", "output_filename", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageCNNV2.__init__": [[363, 575], ["image_models.ImageModel.__init__", "int", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.variable_scope", "network.max_pool", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.variable_scope", "network.max_pool", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.variable_scope", "network.max_pool", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.variable_scope", "network.max_pool", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "network.batch_norm_conv_activation", "activation", "network.batch_norm_conv_activation", "activation", "network.batch_norm_conv_activation", "activation", "network.batch_norm_conv_activation", "activation", "network.batch_norm_conv_activation", "activation", "network.batch_norm_conv_activation", "activation", "network.batch_norm_conv_activation", "activation", "network.batch_norm_conv_activation", "activation", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "network.max_pool", "tensorflow.reshape", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.dropout", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.dropout", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.softmax", "print", "image_models.ImageCNNV2._set_predictions_optimizer_and_loss", "print", "network.batch_norm_dense_activation", "activation", "network.batch_norm_dense_activation", "tensorflow.nn.relu", "network.conv2d", "network.conv2d", "network.conv2d", "network.conv2d", "network.conv2d", "network.conv2d", "network.conv2d", "network.conv2d", "tensorflow.matmul", "network.conv2d", "network.conv2d", "network.conv2d", "network.conv2d", "network.conv2d", "network.conv2d", "network.conv2d", "network.conv2d", "tensorflow.nn.xw_plus_b", "tensorflow.matmul", "tensorflow.nn.xw_plus_b", "tensorflow.matmul"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.max_pool", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.max_pool", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.max_pool", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.max_pool", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_conv_activation", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_conv_activation", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_conv_activation", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_conv_activation", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_conv_activation", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_conv_activation", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_conv_activation", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_conv_activation", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.max_pool", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._set_predictions_optimizer_and_loss", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_dense_activation", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_dense_activation", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d"], ["def", "__init__", "(", "self", ",", "is_primary_model", "=", "True", ",", "is_trainable", "=", "True", ",", "train_last_layers", "=", "False", ")", ":", "\n", "        ", "model_name", "=", "ModelName", ".", "image_cnn_v2", "\n", "# with tf.variable_scope(model_name.name):", "\n", "super", "(", "ImageCNNV2", ",", "self", ")", ".", "__init__", "(", "model_name", "=", "model_name", ",", "is_primary_model", "=", "is_primary_model", ")", "\n", "\n", "last_pool_image_dim", "=", "int", "(", "IMAGE_SIZE", "/", "32", ")", "\n", "\n", "# MODEL CONFIG:", "\n", "self", ".", "config", "=", "{", "\n", "'USE_AVG_POOLING'", ":", "True", ",", "\n", "'IMAGE_SIZE'", ":", "IMAGE_SIZE", ",", "\n", "'activation'", ":", "tf", ".", "nn", ".", "relu", ",", "\n", "}", "\n", "\n", "activation", "=", "self", ".", "config", "[", "'activation'", "]", "\n", "\n", "# MODEL DEFINITION", "\n", "# ================================================================================", "\n", "# conv 1 # padding='SAME'", "\n", "# [IMG,IMG,3] -> [IMG,IMG,32]", "\n", "with", "tf", ".", "variable_scope", "(", "'image_conv1'", ")", ":", "\n", "# [filter_size, filter_size, channel_size, num_filters]", "\n", "            ", "W_conv1", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "7", ",", "7", ",", "3", ",", "32", "]", ")", "\n", "b_conv1", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "32", "]", ")", "\n", "if", "use_batch_norm", ":", "\n", "                ", "self", ".", "h_conv1", "=", "batch_norm_conv_activation", "(", "is_trainable", "=", "is_trainable", ",", "\n", "inputs", "=", "conv2d", "(", "x", "=", "self", ".", "x_image", ",", "W", "=", "W_conv1", ")", "+", "b_conv1", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "activation", "=", "activation", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "h_conv1", "=", "activation", "(", "conv2d", "(", "x", "=", "self", ".", "x_image", ",", "W", "=", "W_conv1", ")", "+", "b_conv1", ")", "\n", "\n", "# conv1-pool 1", "\n", "# [IMG,IMG,32] -> [IMG/2,IMG/2,32] # ksize=[1,2,2,1], strides=[1,2,2,1]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'image_pool1'", ")", ":", "\n", "            ", "self", ".", "h_pool1", "=", "max_pool", "(", "self", ".", "h_conv1", ")", "\n", "# # norm", "\n", "# with tf.variable_scope('image_norm1'):", "\n", "#     h_norm1 = lr_norm(self.h_pool1, 4)", "\n", "\n", "# conv2", "\n", "# [IMG/2,IMG/2,32] -> [IMG/2,IMG/2,64]", "\n", "", "with", "tf", ".", "variable_scope", "(", "'image_conv2'", ")", ":", "\n", "# [filter_size, filter_size, channel_size, num_filters]", "\n", "            ", "W_conv2", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "5", ",", "5", ",", "32", ",", "64", "]", ")", "\n", "b_conv2", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "64", "]", ")", "\n", "if", "use_batch_norm", ":", "\n", "                ", "self", ".", "h_conv2", "=", "batch_norm_conv_activation", "(", "is_trainable", "=", "is_trainable", ",", "\n", "inputs", "=", "conv2d", "(", "x", "=", "self", ".", "h_pool1", ",", "W", "=", "W_conv2", ")", "+", "b_conv2", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "activation", "=", "activation", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "h_conv2", "=", "activation", "(", "conv2d", "(", "x", "=", "self", ".", "h_pool1", ",", "W", "=", "W_conv2", ")", "+", "b_conv2", ")", "\n", "\n", "# conv3", "\n", "# [IMG/2,IMG/2,64] -> [IMG/2,IMG/2,64]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'image_conv3'", ")", ":", "\n", "# [filter_size, filter_size, channel_size, num_filters]", "\n", "            ", "W_conv3", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "5", ",", "5", ",", "64", ",", "64", "]", ")", "\n", "b_conv3", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "64", "]", ")", "\n", "if", "use_batch_norm", ":", "\n", "                ", "self", ".", "h_conv3", "=", "batch_norm_conv_activation", "(", "is_trainable", "=", "is_trainable", ",", "\n", "inputs", "=", "conv2d", "(", "x", "=", "self", ".", "h_conv2", ",", "W", "=", "W_conv3", ")", "+", "b_conv3", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "activation", "=", "activation", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "h_conv3", "=", "activation", "(", "conv2d", "(", "x", "=", "self", ".", "h_conv2", ",", "W", "=", "W_conv3", ")", "+", "b_conv3", ")", "\n", "\n", "# conv3-pool2", "\n", "# [IMG/2,IMG/2,64] -> [IMG/4,IMG/4,64]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'image_pool2'", ")", ":", "\n", "            ", "self", ".", "h_pool2", "=", "max_pool", "(", "self", ".", "h_conv3", ")", "\n", "\n", "# conv4", "\n", "# [IMG/4,IMG/4,64] -> [IMG/4,IMG/4,128]", "\n", "", "with", "tf", ".", "variable_scope", "(", "'image_conv4'", ")", ":", "\n", "# [filter_size, filter_size, channel_size, num_filters]", "\n", "            ", "W_conv4", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "3", ",", "3", ",", "64", ",", "128", "]", ")", "\n", "b_conv4", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "128", "]", ")", "\n", "if", "use_batch_norm", ":", "\n", "                ", "self", ".", "h_conv4", "=", "batch_norm_conv_activation", "(", "is_trainable", "=", "is_trainable", ",", "\n", "inputs", "=", "conv2d", "(", "x", "=", "self", ".", "h_pool2", ",", "W", "=", "W_conv4", ")", "+", "b_conv4", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "activation", "=", "activation", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "h_conv4", "=", "activation", "(", "conv2d", "(", "x", "=", "self", ".", "h_pool2", ",", "W", "=", "W_conv4", ")", "+", "b_conv4", ")", "\n", "\n", "# conv5", "\n", "# [IMG/4,IMG/4,128] -> [IMG/4,IMG/4,128]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'image_conv5'", ")", ":", "\n", "# [filter_size, filter_size, channel_size, num_filters]", "\n", "            ", "W_conv5", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "3", ",", "3", ",", "128", ",", "128", "]", ")", "\n", "b_conv5", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "128", "]", ")", "\n", "if", "use_batch_norm", ":", "\n", "                ", "self", ".", "h_conv5", "=", "batch_norm_conv_activation", "(", "is_trainable", "=", "is_trainable", ",", "\n", "inputs", "=", "conv2d", "(", "x", "=", "self", ".", "h_conv4", ",", "W", "=", "W_conv5", ")", "+", "b_conv5", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "activation", "=", "activation", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "h_conv5", "=", "activation", "(", "conv2d", "(", "x", "=", "self", ".", "h_conv4", ",", "W", "=", "W_conv5", ")", "+", "b_conv5", ")", "\n", "\n", "# conv5-pool3", "\n", "# [IMG/4,IMG/4,128] -> [IMG/8,IMG/8,128]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'image_pool3'", ")", ":", "\n", "            ", "self", ".", "h_pool3", "=", "max_pool", "(", "self", ".", "h_conv5", ")", "\n", "\n", "", "last_layers_trainable", "=", "is_trainable", "or", "train_last_layers", "\n", "\n", "# conv6", "\n", "# [IMG/8,IMG/8,128] -> [IMG/8,IMG/8,256]", "\n", "with", "tf", ".", "variable_scope", "(", "'image_conv6'", ")", ":", "\n", "# [filter_size, filter_size, channel_size, num_filters]", "\n", "            ", "W_conv6", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "3", ",", "3", ",", "128", ",", "256", "]", ")", "\n", "b_conv6", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "256", "]", ")", "\n", "if", "use_batch_norm", ":", "\n", "                ", "self", ".", "h_conv6", "=", "batch_norm_conv_activation", "(", "is_trainable", "=", "last_layers_trainable", ",", "\n", "inputs", "=", "conv2d", "(", "x", "=", "self", ".", "h_pool3", ",", "W", "=", "W_conv6", ")", "+", "b_conv6", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "activation", "=", "activation", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "h_conv6", "=", "activation", "(", "conv2d", "(", "x", "=", "self", ".", "h_pool3", ",", "W", "=", "W_conv6", ")", "+", "b_conv6", ")", "\n", "\n", "# conv7", "\n", "# [IMG/8,IMG/8,256] -> [IMG/8,IMG/8,256]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'image_conv7'", ")", ":", "\n", "# [filter_size, filter_size, channel_size, num_filters]", "\n", "            ", "W_conv7", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "3", ",", "3", ",", "256", ",", "256", "]", ")", "\n", "b_conv7", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "256", "]", ")", "\n", "if", "use_batch_norm", ":", "\n", "                ", "self", ".", "h_conv7", "=", "batch_norm_conv_activation", "(", "is_trainable", "=", "last_layers_trainable", ",", "\n", "inputs", "=", "conv2d", "(", "x", "=", "self", ".", "h_conv6", ",", "W", "=", "W_conv7", ")", "+", "b_conv7", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "activation", "=", "activation", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "h_conv7", "=", "activation", "(", "conv2d", "(", "x", "=", "self", ".", "h_conv6", ",", "W", "=", "W_conv7", ")", "+", "b_conv7", ")", "\n", "\n", "# conv7-pool4", "\n", "# [IMG/8,IMG/8,256] -> [IMG/16,IMG/16,256]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'image_pool4'", ")", ":", "\n", "            ", "self", ".", "h_pool4", "=", "max_pool", "(", "self", ".", "h_conv7", ")", "\n", "\n", "# conv8", "\n", "# [IMG/16,IMG/16,256] -> [IMG/16,IMG/16,512]", "\n", "", "with", "tf", ".", "variable_scope", "(", "'image_conv8'", ")", ":", "\n", "# [filter_size, filter_size, channel_size, num_filters]", "\n", "            ", "W_conv8", "=", "weight_variable", "(", "is_trainable", "=", "last_layers_trainable", ",", "shape", "=", "[", "3", ",", "3", ",", "256", ",", "512", "]", ")", "\n", "b_conv8", "=", "bias_variable", "(", "is_trainable", "=", "last_layers_trainable", ",", "shape", "=", "[", "512", "]", ")", "\n", "if", "use_batch_norm", ":", "\n", "                ", "self", ".", "h_conv8", "=", "batch_norm_conv_activation", "(", "is_trainable", "=", "last_layers_trainable", ",", "\n", "inputs", "=", "conv2d", "(", "x", "=", "self", ".", "h_pool4", ",", "W", "=", "W_conv8", ")", "+", "b_conv8", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "activation", "=", "activation", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "h_conv8", "=", "activation", "(", "conv2d", "(", "x", "=", "self", ".", "h_pool4", ",", "W", "=", "W_conv8", ")", "+", "b_conv8", ")", "\n", "\n", "", "", "if", "self", ".", "config", "[", "'USE_AVG_POOLING'", "]", ":", "\n", "# conv8-avgPool", "\n", "# [IMG/16, IMG/16, 512] -> [512]", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'image_avg_pool'", ")", ":", "\n", "                ", "self", ".", "h_pool5_flat", "=", "tf", ".", "reduce_mean", "(", "self", ".", "h_conv8", ",", "reduction_indices", "=", "[", "1", ",", "2", "]", ",", "name", "=", "\"avg_pool\"", ")", "\n", "", "", "else", ":", "\n", "# conv8-pool5", "\n", "# [IMG/16,IMG/16,512] -> [IMG/32,IMG/32,512]", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'image_pool5'", ")", ":", "\n", "                ", "self", ".", "h_pool5", "=", "max_pool", "(", "self", ".", "h_conv8", ")", "\n", "# Flatten last pool layer", "\n", "self", ".", "h_pool5_flat", "=", "tf", ".", "reshape", "(", "self", ".", "h_pool5", ",", "\n", "shape", "=", "[", "-", "1", ",", "last_pool_image_dim", "*", "last_pool_image_dim", "*", "512", "]", ",", "\n", "name", "=", "'h_pool5_flat'", ")", "\n", "\n", "", "", "if", "not", "self", ".", "config", "[", "'USE_AVG_POOLING'", "]", ":", "\n", "# FC0 [image_dim*image_dim*512] -> [512]", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'image_fc0'", ")", ":", "\n", "                ", "W_fc0", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "\n", "shape", "=", "[", "last_pool_image_dim", "*", "last_pool_image_dim", "*", "512", ",", "512", "]", ",", "\n", "name", "=", "'W_fc0'", ")", "\n", "b_fc0", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "512", "]", ",", "name", "=", "'b_fc0'", ")", "\n", "if", "use_batch_norm", ":", "\n", "                    ", "self", ".", "h_fc0", "=", "batch_norm_dense_activation", "(", "inputs", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "x", "=", "self", ".", "h_pool5_flat", ",", "\n", "weights", "=", "W_fc0", ",", "\n", "biases", "=", "b_fc0", ")", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "\n", "activation", "=", "activation", ",", "\n", "is_trainable", "=", "is_trainable", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "h_fc0", "=", "activation", "(", "tf", ".", "matmul", "(", "self", ".", "h_pool5_flat", ",", "W_fc0", ")", "+", "b_fc0", ")", "\n", "", "self", ".", "h_fc0_drop", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "h_fc0", ",", "self", ".", "dropout_keep_prob", ")", "\n", "", "last_layer", "=", "self", ".", "h_fc0_drop", "\n", "", "else", ":", "\n", "            ", "last_layer", "=", "self", ".", "h_pool5_flat", "\n", "\n", "", "if", "is_trainable", ":", "\n", "# FC1 [512] -> [256]", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'image_fc1'", ")", ":", "\n", "                ", "W_fc1", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "512", ",", "256", "]", ")", "\n", "b_fc1", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "256", "]", ")", "\n", "if", "use_batch_norm", ":", "\n", "                    ", "self", ".", "h_fc1", "=", "batch_norm_dense_activation", "(", "inputs", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "x", "=", "last_layer", ",", "\n", "weights", "=", "W_fc1", ",", "\n", "biases", "=", "b_fc1", ")", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "\n", "activation", "=", "activation", ",", "\n", "is_trainable", "=", "is_trainable", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "h_fc1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "last_layer", ",", "W_fc1", ")", "+", "b_fc1", ")", "\n", "# dropout", "\n", "", "self", ".", "h_fc1_drop", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "h_fc1", ",", "self", ".", "dropout_keep_prob", ")", "\n", "\n", "# Softmax", "\n", "", "with", "tf", ".", "variable_scope", "(", "'softmax'", ")", ":", "\n", "                ", "self", ".", "W_softmax", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "256", ",", "NUM_CLASSES", "]", ")", "\n", "self", ".", "b_softmax", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "NUM_CLASSES", "]", ")", "\n", "self", ".", "probabilities", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "self", ".", "h_fc1_drop", ",", "self", ".", "W_softmax", ")", "+", "self", ".", "b_softmax", ")", "\n", "\n", "# Finalize the predictions, the optimizing function, loss/accuracy stats etc.", "\n", "", "if", "self", ".", "is_primary_model", ":", "\n", "                ", "print", "(", "\"%s is a primary model, making optimizations\"", "%", "self", ".", "model_name", ".", "name", ")", "\n", "self", ".", "_set_predictions_optimizer_and_loss", "(", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"%s not primary model, skipping optimizations\"", "%", "self", ".", "model_name", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ImageCNNV2.save_bottleneck_data": [[576, 578], ["None"], "methods", ["None"], ["", "", "", "def", "save_bottleneck_data", "(", "self", ",", "sess", ",", "layer_name", ",", "input_ids", ",", "input_labels", ",", "input_texts", ",", "output_filename", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ResnetClf.restore_base_models": [[581, 590], ["paths.get_resnet_stored_filename", "tensorflow.train.Saver", "image_models.ResnetClf.restore_model_from_filename", "tensorflow.global_variables", "v.name.split"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.paths.get_resnet_stored_filename", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.restore_model_from_filename"], ["    ", "def", "restore_base_models", "(", "self", ",", "sess", ")", ":", "\n", "        ", "resnet_ckpt_filename", "=", "get_resnet_stored_filename", "(", "file_type", "=", "'ckpt'", ",", "num_layers", "=", "RESNET_LAYERS", ")", "\n", "# vars with name not matching current model and it's base text model will all be resnet vars", "\n", "vars_to_restore", "=", "[", "v", "for", "v", "in", "tf", ".", "global_variables", "(", ")", "\n", "if", "v", ".", "name", ".", "split", "(", "'/'", ")", "[", "0", "]", "!=", "self", ".", "model_name", ".", "name", "]", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "vars_to_restore", ")", "\n", "self", ".", "restore_model_from_filename", "(", "sess", ",", "model_filename", "=", "resnet_ckpt_filename", ",", "saver", "=", "saver", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ResnetClf.__init__": [[591, 627], ["image_models.Resnet.__init__", "tensorflow.variable_scope", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.nn.dropout", "tensorflow.variable_scope", "network.weight_variable", "network.bias_variable", "tensorflow.variable_scope", "image_models.ResnetClf._set_predictions_optimizer_and_loss", "network.batch_norm_dense_activation", "tensorflow.nn.relu", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.weight_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.bias_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._set_predictions_optimizer_and_loss", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.batch_norm_dense_activation"], ["", "def", "__init__", "(", "self", ",", "is_trainable", "=", "True", ")", ":", "\n", "        ", "self", ".", "model_name", "=", "ModelName", ".", "resnet_clf", "\n", "super", "(", "ResnetClf", ",", "self", ")", ".", "__init__", "(", "model_name", "=", "self", ".", "model_name", ",", "is_trainable", "=", "True", ",", "train_last_block", "=", "False", ")", "\n", "\n", "# self.base_image_model = Resnet(restore=False, is_trainable=False, train_last_block=False)", "\n", "self", ".", "resnet_representation", "=", "self", ".", "avg_pool_representation", "\n", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", "\n", "self", ".", "initializer_type", "=", "'normal'", "if", "activation", "==", "tf", ".", "nn", ".", "relu", "else", "'xavier'", "\n", "dim_D", "=", "2048", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "model_name", ".", "name", ")", ":", "\n", "# FC1 [dim_d] -> [512]", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'image_fc1'", ")", ":", "\n", "                ", "W_fc1", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "dim_D", ",", "512", "]", ",", "\n", "initializer_type", "=", "self", ".", "initializer_type", ",", "name", "=", "'W_fc1'", ")", "\n", "b_fc1", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "512", "]", ",", "name", "=", "'b_fc1'", ")", "\n", "\n", "if", "use_batch_norm", ":", "\n", "                    ", "h_fc1", "=", "batch_norm_dense_activation", "(", "inputs", "=", "tf", ".", "matmul", "(", "self", ".", "resnet_representation", ",", "W_fc1", ")", "+", "b_fc1", ",", "\n", "is_training", "=", "self", ".", "train_mode", ",", "activation", "=", "activation", ",", "\n", "is_trainable", "=", "is_trainable", ")", "\n", "", "else", ":", "\n", "                    ", "h_fc1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "resnet_representation", ",", "W_fc1", ")", "+", "b_fc1", ")", "\n", "", "h_fc1_drop", "=", "tf", ".", "nn", ".", "dropout", "(", "h_fc1", ",", "self", ".", "dropout_keep_prob", ")", "\n", "\n", "# Softmax", "\n", "", "with", "tf", ".", "variable_scope", "(", "'softmax'", ")", ":", "\n", "                ", "W_softmax", "=", "weight_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "512", ",", "NUM_CLASSES", "]", ",", "\n", "initializer_type", "=", "self", ".", "initializer_type", ")", "\n", "b_softmax", "=", "bias_variable", "(", "is_trainable", "=", "is_trainable", ",", "shape", "=", "[", "NUM_CLASSES", "]", ")", "\n", "self", ".", "scores", "=", "tf", ".", "matmul", "(", "h_fc1_drop", ",", "W_softmax", ")", "+", "b_softmax", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'optimization'", ")", ":", "\n", "# Finalize the predictions, the optimizing function, loss/accuracy stats etc.", "\n", "                ", "self", ".", "_set_predictions_optimizer_and_loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ResnetClf.save_bottleneck_data": [[628, 630], ["None"], "methods", ["None"], ["", "", "", "def", "save_bottleneck_data", "(", "self", ",", "sess", ",", "layer_name", ",", "input_ids", ",", "input_labels", ",", "input_texts", ",", "output_filename", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ResnetClf._train_SGD_batch_step": [[631, 648], ["sess.run"], "methods", ["None"], ["", "def", "_train_SGD_batch_step", "(", "self", ",", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_train", ",", "train_mode", "=", "True", ",", "\n", "batch_step", "=", "1", ")", ":", "\n", "# ignore batch_ids & text_train", "\n", "        ", "_", ",", "_", "=", "batch_ids", ",", "text_train", "\n", "\n", "S", ",", "_", ",", "loss_val", ",", "acc_val", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "train_summary_op", ",", "self", ".", "train_op", ",", "self", ".", "loss", ",", "self", ".", "accuracy", "]", ",", "\n", "feed_dict", "=", "{", "\n", "# self.base_image_model.images_placeholder: batch_image,", "\n", "# self.base_image_model.train_mode: train_mode,", "\n", "self", ".", "images_placeholder", ":", "batch_image", ",", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "0.5", ",", "\n", "self", ".", "train_mode", ":", "train_mode", "\n", "}", ")", "\n", "\n", "return", "S", ",", "loss_val", ",", "acc_val", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ResnetClf._validation_batch_step": [[649, 665], ["sess.run"], "methods", ["None"], ["", "def", "_validation_batch_step", "(", "self", ",", "sess", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_val", ",", "train_mode", "=", "False", ",", "\n", "batch_step", "=", "1", ")", ":", "\n", "# ignore batch_ids & text_train", "\n", "        ", "_", "=", "batch_ids", ",", "text_val", ",", "batch_step", "\n", "\n", "val_acc_step", "=", "sess", ".", "run", "(", "\n", "self", ".", "sum_accuracy", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "images_placeholder", ":", "batch_image", ",", "\n", "# self.base_image_model.train_mode: train_mode,", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "1.0", ",", "\n", "self", ".", "train_mode", ":", "train_mode", "\n", "}", ")", "\n", "\n", "return", "val_acc_step", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.image_models.ResnetClf._test_batch_step": [[666, 680], ["sess.run"], "methods", ["None"], ["", "def", "_test_batch_step", "(", "self", ",", "sess", ",", "c_mat", ",", "batch_image", ",", "batch_label", ",", "batch_ids", ",", "text_test", ",", "train_mode", "=", "False", ")", ":", "\n", "# ignore batch_ids & text_test", "\n", "        ", "_", ",", "_", "=", "batch_ids", ",", "text_test", "\n", "\n", "pred", ",", "mat", ",", "test_acc", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "probabilities", ",", "c_mat", ",", "self", ".", "sum_accuracy", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "images_placeholder", ":", "batch_image", ",", "\n", "# self.base_image_model.train_mode: train_mode,", "\n", "self", ".", "labels_placeholder", ":", "batch_label", ",", "\n", "self", ".", "dropout_keep_prob", ":", "1.0", ",", "\n", "self", ".", "train_mode", ":", "train_mode", "\n", "}", ")", "\n", "return", "pred", ",", "mat", ",", "test_acc", "\n", "", "", ""]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.paths.get_stored_checkpoint_filename": [[30, 33], ["str"], "function", ["None"], ["def", "get_stored_checkpoint_filename", "(", "model_type", ",", "model_name", ",", "date", ",", "num_epochs", ")", ":", "\n", "    ", "return", "results_directory", "+", "model_type", ".", "name", "+", "'/'", "+", "model_name", ".", "name", "+", "'/ckpt/'", "+", "date", "+", "'/'", "+", "str", "(", "num_epochs", ")", "+", "'epoch/model.ckpt'", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.paths.get_stored_metagraph_filename": [[35, 38], ["str"], "function", ["None"], ["", "def", "get_stored_metagraph_filename", "(", "model_type", ",", "model_name", ",", "date", ",", "num_epochs", ")", ":", "\n", "    ", "return", "results_directory", "+", "model_type", ".", "name", "+", "'/'", "+", "model_name", ".", "name", "+", "'/ckpt/'", "+", "date", "+", "'/'", "+", "str", "(", "num_epochs", ")", "+", "'epoch/model.ckpt.meta'", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.paths.get_bottleneck_data_subdirectory": [[40, 42], ["None"], "function", ["None"], ["", "def", "get_bottleneck_data_subdirectory", "(", "model_name", ")", ":", "\n", "    ", "return", "bottleneck_data_directory", "+", "model_name", ".", "name", "+", "'/'", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.paths.get_resnet_stored_filename": [[44, 48], ["ValueError"], "function", ["None"], ["", "def", "get_resnet_stored_filename", "(", "file_type", ",", "num_layers", "=", "152", ")", ":", "\n", "    ", "if", "file_type", "!=", "'meta'", "and", "file_type", "!=", "'ckpt'", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid file_type arg = %s, only 'meta' and 'ckpt' allowed\"", "%", "file_type", ")", "\n", "", "return", "resnet_model_prefix", "+", "'ResNet-L%d.%s'", "%", "(", "num_layers", ",", "file_type", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.run.parse_command_line_args": [[39, 92], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "vars", "bool", "bool", "bool", "bool", "argparse.ArgumentParser.parse_args", "print", "str", "list"], "function", ["None"], ["def", "parse_command_line_args", "(", ")", ":", "\n", "    ", "\"\"\" Parse command line arguments. All are optional, except that if test=1 & train=0,\n    then date and nepochs are required.\n\n    :return: list [str, bool, bool, str, str] containing model name, bools for whether to train & test, date string,\n        and number of epochs as string.\n    :raises ValueError: if test\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Use python <filename.py> -model <image_model_name here> '", "\n", "'-train <0/1 here> -test <0/1 here> -date <date here> '", "\n", "'-nepochs <int here>'", ")", "\n", "parser", ".", "add_argument", "(", "'-model'", ",", "help", "=", "'Name of model: only %s allowed for now. '", "\n", "'Default is \"%s\"'", "%", "(", "str", "(", "[", "mn", ".", "name", "for", "mn", "in", "list", "(", "ModelName", ")", "]", ")", ",", "\n", "ModelName", ".", "text_cnn", ".", "name", ")", ",", "\n", "type", "=", "str", ",", "required", "=", "False", ",", "default", "=", "ModelName", ".", "text_cnn", ".", "name", ")", "\n", "parser", ".", "add_argument", "(", "'-train'", ",", "help", "=", "'Boolean 0/1, whether to train from scratch. Default is 0'", ",", "\n", "type", "=", "int", ",", "required", "=", "False", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'-test'", ",", "help", "=", "'Boolean 0/1, whether to test the model. Default is 0'", ",", "\n", "type", "=", "int", ",", "required", "=", "False", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'-val'", ",", "help", "=", "'Boolean 0/1, whether to validate the model. Default is 0'", ",", "\n", "type", "=", "int", ",", "required", "=", "False", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'-retrain'", ",", "help", "=", "'Boolean 0/1, whether to retrain the model. Default is 0'", ",", "\n", "type", "=", "int", ",", "required", "=", "False", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'-date'", ",", "help", "=", "'date stamp of the folder storing the saved model'", ",", "\n", "type", "=", "str", ",", "required", "=", "False", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'-nepochs'", ",", "help", "=", "'number of epochs the trained model was ran'", ",", "\n", "type", "=", "int", ",", "required", "=", "False", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'-lrate'", ",", "help", "=", "'learning rate for the model, default is in global_hyperparams'", ",", "\n", "type", "=", "float", ",", "required", "=", "False", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'-tr_epochs'", ",", "help", "=", "'number of training epochs for model, default is in global_hyperparams'", ",", "\n", "type", "=", "int", ",", "required", "=", "False", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'-nlayers'", ",", "help", "=", "'Number of stacked att layers for att models'", ",", "\n", "type", "=", "int", ",", "required", "=", "False", ",", "default", "=", "1", ")", "\n", "\n", "args", "=", "vars", "(", "parser", ".", "parse_args", "(", ")", ")", "\n", "model_name", "=", "ModelName", "[", "args", "[", "'model'", "]", "]", "\n", "train_flag", "=", "bool", "(", "args", "[", "'train'", "]", ")", "\n", "test_flag", "=", "bool", "(", "args", "[", "'test'", "]", ")", "\n", "val_flag", "=", "bool", "(", "args", "[", "'val'", "]", ")", "\n", "retrain_flag", "=", "bool", "(", "args", "[", "'retrain'", "]", ")", "\n", "date", "=", "args", "[", "'date'", "]", "\n", "num_epochs", "=", "args", "[", "'nepochs'", "]", "\n", "learning_rate", "=", "args", "[", "'lrate'", "]", "\n", "training_epochs", "=", "args", "[", "'tr_epochs'", "]", "\n", "num_att_layers", "=", "args", "[", "'nlayers'", "]", "\n", "\n", "if", "(", "val_flag", "or", "test_flag", ")", "and", "(", "date", "is", "None", ")", ":", "\n", "        ", "print", "(", "\"WARNING: Date & Epochs not mentioned, loading from parameters mentioned in global_hyperparams.py file\"", ")", "\n", "date", "=", "best_date", "[", "model_name", "]", "\n", "num_epochs", "=", "best_epochs", "[", "model_name", "]", "\n", "\n", "", "return", "model_name", ",", "train_flag", ",", "test_flag", ",", "val_flag", ",", "retrain_flag", ",", "date", ",", "num_epochs", ",", "learning_rate", ",", "training_epochs", ",", "num_att_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.run.train_model": [[94, 103], ["utils.load_train_val_data", "classifier.train"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.load_train_val_data", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.train"], ["", "def", "train_model", "(", "classifier", ")", ":", "\n", "    ", "\"\"\" Train the given classifier model on the training data present in data_directory.\n\n    :param classifier: Object with class derived from BaseModel\n    :return: None\n    \"\"\"", "\n", "train_ids", ",", "train_labels", ",", "train_texts", ",", "val_ids", ",", "val_labels", ",", "val_texts", "=", "load_train_val_data", "(", "load_texts", "=", "(", "classifier", ".", "model_type", "!=", "ModelType", ".", "image_only", ")", ")", "\n", "classifier", ".", "train", "(", "train_ids", ",", "train_labels", ",", "train_texts", ",", "val_ids", ",", "val_labels", ",", "val_texts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.run.test_model": [[105, 115], ["utils.load_test_data", "classifier.test"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.load_test_data", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.test"], ["", "def", "test_model", "(", "classifier", ",", "date", ",", "num_epochs", ")", ":", "\n", "    ", "\"\"\" Restore the classifier from given data and number of epochs, and run on test set\n\n    :param classifier: Object with class derived from BaseModel\n    :param date: str, timestamp that is the name of the folder containing classifier's data\n    :param num_epochs: int, the epoch number from which checkpoint is to be retrieved.\n    :return: None\n    \"\"\"", "\n", "test_labels", ",", "test_ids", ",", "test_texts", "=", "load_test_data", "(", "load_texts", "=", "(", "classifier", ".", "model_type", "!=", "ModelType", ".", "image_only", ")", ")", "\n", "classifier", ".", "test", "(", "date", ",", "num_epochs", ",", "test_ids", ",", "test_labels", ",", "test_texts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.run.validate_model": [[117, 127], ["utils.load_val_data", "classifier.validation_test"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.load_val_data", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.validation_test"], ["", "def", "validate_model", "(", "classifier", ",", "date", ",", "num_epochs", ")", ":", "\n", "    ", "\"\"\" Restore the classifier from given data and number of epochs, and run on validation set\n\n    :param classifier: Object with class derived from BaseModel\n    :param date: str, timestamp that is the name of the folder containing classifier's data\n    :param num_epochs: int, the epoch number from which checkpoint is to be retrieved.\n    :return: None\n    \"\"\"", "\n", "val_labels", ",", "val_ids", ",", "val_texts", "=", "load_val_data", "(", "load_texts", "=", "(", "classifier", ".", "model_type", "!=", "ModelType", ".", "image_only", ")", ")", "\n", "classifier", ".", "validation_test", "(", "date", ",", "num_epochs", ",", "val_ids", ",", "val_labels", ",", "val_texts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.run.retrain_model": [[129, 140], ["utils.load_train_val_data", "classifier.retrain"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.load_train_val_data", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.retrain"], ["", "def", "retrain_model", "(", "classifier", ",", "date", ",", "num_epochs", ")", ":", "\n", "    ", "\"\"\" Restore the classifier from given data and number of epochs, and start retraining\n\n    :param classifier: Object with class derived from BaseModel\n    :param date: str, timestamp that is the name of the folder containing classifier's data\n    :param num_epochs: int, the epoch number from which checkpoint is to be retrieved.\n    :return: None\n    \"\"\"", "\n", "load_texts", "=", "not", "(", "classifier", ".", "model_type", "==", "ModelType", ".", "image_only", ")", "\n", "train_ids", ",", "train_labels", ",", "train_texts", ",", "val_ids", ",", "val_labels", ",", "val_texts", "=", "load_train_val_data", "(", "load_texts", ")", "\n", "classifier", ".", "retrain", "(", "date", ",", "num_epochs", ",", "train_ids", ",", "train_labels", ",", "train_texts", ",", "val_ids", ",", "val_labels", ",", "val_texts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.run.get_classifier_model": [[142, 183], ["text_models.TextCNN", "text_models.HieText", "image_models.ImageCNN", "image_models.ImageCNNV2", "image_models.Resnet", "image_models.ResnetClf", "image_text_models.EmbeddingConcatWithSemiFreeze", "image_text_models.StackedAttentionWithSemiFreezeCNN", "image_text_models.HieCoAtt", "image_text_models.AuxTaskModel", "ValueError"], "function", ["None"], ["", "def", "get_classifier_model", "(", "model_name", ",", "num_att_layers", ")", ":", "\n", "    ", "\"\"\" Given the model name, construct the corresponding BaseModel derived object and return it\n\n    :param model_name: ModelName enum (from global_hyperparams)\n    :param num_att_layers: int or None, number of attention layers to be used for SAN\n    :return: BaseModel derived class object\n    :raises: ValueError, if model_name in not a implemented classifier model\n    \"\"\"", "\n", "# Text Only Models", "\n", "if", "model_name", "==", "ModelName", ".", "text_cnn", ":", "\n", "        ", "classifier", "=", "text_models", ".", "TextCNN", "(", "filter_sizes", "=", "(", "1", ",", "2", ",", "3", ")", ",", "is_trainable", "=", "True", ")", "\n", "", "elif", "model_name", "==", "ModelName", ".", "hie_text", ":", "\n", "        ", "classifier", "=", "text_models", ".", "HieText", "(", "is_trainable", "=", "True", ",", "is_primary_model", "=", "True", ")", "\n", "\n", "# Image Only Models", "\n", "", "elif", "model_name", "==", "ModelName", ".", "image_cnn", ":", "\n", "        ", "classifier", "=", "image_models", ".", "ImageCNN", "(", "is_trainable", "=", "True", ")", "\n", "", "elif", "model_name", "==", "ModelName", ".", "image_cnn_v2", ":", "\n", "        ", "classifier", "=", "image_models", ".", "ImageCNNV2", "(", "is_trainable", "=", "True", ")", "\n", "", "elif", "model_name", "==", "ModelName", ".", "resnet", ":", "\n", "        ", "classifier", "=", "image_models", ".", "Resnet", "(", "is_trainable", "=", "True", ",", "train_last_block", "=", "False", ")", "\n", "", "elif", "model_name", "==", "ModelName", ".", "resnet_clf", ":", "\n", "        ", "classifier", "=", "image_models", ".", "ResnetClf", "(", "is_trainable", "=", "True", ")", "\n", "\n", "# Image Text Models", "\n", "", "elif", "model_name", "==", "ModelName", ".", "embedding_concat_semifreeze", ":", "\n", "        ", "classifier", "=", "image_text_models", ".", "EmbeddingConcatWithSemiFreeze", "(", "is_trainable", "=", "True", ")", "\n", "", "elif", "model_name", "==", "ModelName", ".", "stacked_attention_with_semi_freeze_cnn", ":", "\n", "        ", "classifier", "=", "image_text_models", ".", "StackedAttentionWithSemiFreezeCNN", "(", "nlayers", "=", "num_att_layers", ",", "\n", "is_trainable", "=", "True", ")", "\n", "", "elif", "model_name", "==", "ModelName", ".", "hie_co_att", ":", "\n", "        ", "classifier", "=", "image_text_models", ".", "HieCoAtt", "(", "is_primary_model", "=", "True", ",", "is_trainable", "=", "True", ")", "\n", "\n", "# Image-Text Novel Model", "\n", "", "elif", "model_name", "==", "ModelName", ".", "aux_task_model", ":", "\n", "        ", "classifier", "=", "image_text_models", ".", "AuxTaskModel", "(", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid model name=%s provided\"", "%", "model_name", ")", "\n", "\n", "", "return", "classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.run.main": [[185, 210], ["run.parse_command_line_args", "tensorflow.Graph().as_default", "run.get_classifier_model", "global_hyperparams.update_learning_rate_dict", "global_hyperparams.update_training_epochs_dict", "run.train_model", "run.test_model", "run.validate_model", "run.retrain_model", "tensorflow.Graph"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.run.parse_command_line_args", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.run.get_classifier_model", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.global_hyperparams.update_learning_rate_dict", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.global_hyperparams.update_training_epochs_dict", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.run.train_model", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.run.test_model", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.run.validate_model", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.run.retrain_model"], ["", "def", "main", "(", ")", ":", "\n", "\n", "# Get the parameter value from command line arguments", "\n", "    ", "model_name", ",", "train_flag", ",", "test_flag", ",", "val_flag", ",", "retrain_flag", ",", "date", ",", "num_epochs", ",", "learning_rate", ",", "training_epochs", ",", "num_att_layers", "=", "parse_command_line_args", "(", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "classifier", "=", "get_classifier_model", "(", "model_name", ",", "num_att_layers", ")", "\n", "\n", "# Override values of learning rate and training epochs if explicitly specified by the user", "\n", "if", "learning_rate", "is", "not", "None", ":", "\n", "            ", "update_learning_rate_dict", "(", "classifier", ".", "model_type", ",", "learning_rate", ")", "\n", "", "if", "training_epochs", "is", "not", "None", ":", "\n", "            ", "update_training_epochs_dict", "(", "classifier", ".", "model_type", ",", "training_epochs", ")", "\n", "\n", "# Carry out requested action using the classifier", "\n", "", "if", "train_flag", ":", "\n", "            ", "train_model", "(", "classifier", ")", "\n", "", "if", "test_flag", ":", "\n", "            ", "test_model", "(", "classifier", ",", "date", ",", "num_epochs", ")", "\n", "", "if", "val_flag", ":", "\n", "            ", "validate_model", "(", "classifier", ",", "date", ",", "num_epochs", ")", "\n", "", "if", "retrain_flag", ":", "\n", "            ", "retrain_model", "(", "classifier", ",", "date", ",", "num_epochs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.__init__": [[25, 119], ["object.__init__", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "ValueError"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__"], ["def", "__init__", "(", "self", ",", "model_type", ",", "model_name", ",", "is_trainable", "=", "True", ",", "is_primary_model", "=", "True", ",", "config", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        :param model_type: ModelType Enum\n\n        :param model_name: ModelName Enum\n\n        :param is_trainable: bool, whether weights can be updated\n\n        :param is_primary_model: bool, whether this model's output will be used for the final task\n\n        :param config: dict, containing various parameter name-value pairs. Used for writing config file.\n        \"\"\"", "\n", "super", "(", "BaseModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model_type", "=", "model_type", "\n", "self", ".", "model_name", "=", "model_name", "\n", "self", ".", "batch_size", "=", "batch_size_dict", "[", "model_type", "]", "\n", "\n", "# Directories for book-keeping", "\n", "if", "model_type", "==", "ModelType", ".", "image_only", ":", "\n", "            ", "self", ".", "results_subdirectory", "=", "image_results_subdirectory", "\n", "", "elif", "model_type", "==", "ModelType", ".", "text_only", ":", "\n", "            ", "self", ".", "results_subdirectory", "=", "text_results_subdirectory", "\n", "", "elif", "model_type", "==", "ModelType", ".", "image_text", ":", "\n", "            ", "self", ".", "results_subdirectory", "=", "image_text_results_subdirectory", "\n", "", "elif", "model_type", "==", "ModelType", ".", "answerer", ":", "\n", "            ", "self", ".", "results_subdirectory", "=", "answerer_results_subdirectory", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Error: Ill-defined model type %s'", "%", "model_type", ")", "\n", "\n", "", "self", ".", "config", "=", "config", "\n", "self", ".", "model_type_config", "=", "{", "\n", "'batch_size'", ":", "batch_size_dict", "[", "self", ".", "model_type", "]", ",", "\n", "'learning_rate'", ":", "learning_rate_dict", "[", "self", ".", "model_type", "]", ",", "\n", "}", "\n", "\n", "# Decide the learning rate config", "\n", "if", "scale_learning_rate", ":", "\n", "            ", "self", ".", "model_type_config", "[", "'scale_epochs_dict'", "]", "=", "scale_epochs_dict", "[", "self", ".", "model_type", "]", "\n", "self", ".", "model_type_config", "[", "'scale_factors_dict'", "]", "=", "scale_factors_dict", "[", "self", ".", "model_type", "]", "\n", "", "if", "decay_learning_rate", ":", "\n", "            ", "self", ".", "model_type_config", "[", "'DECAY_STEP_LEARNING_RATE'", "]", "=", "DECAY_STEP_LEARNING_RATE", "\n", "self", ".", "model_type_config", "[", "'DECAY_RATE_LEARNING_RATE'", "]", "=", "DECAY_RATE_LEARNING_RATE", "\n", "\n", "# Other config params", "\n", "", "if", "self", ".", "model_type", "==", "ModelType", ".", "image_text", ":", "\n", "            ", "self", ".", "model_type_config", "[", "'best_date'", "]", "=", "best_date", "\n", "self", ".", "model_type_config", "[", "'best_epochs'", "]", "=", "best_epochs", "\n", "", "if", "self", ".", "model_type", "!=", "ModelType", ".", "text_only", ":", "\n", "            ", "self", ".", "model_type_config", "[", "'IMAGE_SIZE'", "]", "=", "IMAGE_SIZE", "\n", "", "if", "self", ".", "model_type", "!=", "ModelType", ".", "image_only", ":", "\n", "            ", "self", ".", "model_type_config", "[", "'TEXT_LENGTH'", "]", "=", "TEXT_LENTH", "\n", "self", ".", "model_type_config", "[", "'EMBED_SIZES'", "]", "=", "EMBED_SIZES", "\n", "\n", "", "self", ".", "trainable", "=", "is_trainable", "\n", "self", ".", "is_primary_model", "=", "is_primary_model", "\n", "\n", "# Book-keeping directories", "\n", "self", ".", "train_log_dir", "=", "self", ".", "results_subdirectory", "+", "self", ".", "model_name", ".", "name", "+", "train_log_directory_suffix", "\n", "self", ".", "checkpoint_dir", "=", "self", ".", "results_subdirectory", "+", "self", ".", "model_name", ".", "name", "+", "checkpoint_directory_suffix", "\n", "self", ".", "test_log_dir", "=", "self", ".", "results_subdirectory", "+", "self", ".", "model_name", ".", "name", "+", "test_log_directory_suffix", "\n", "self", ".", "train_logfile_name", "=", "self", ".", "train_log_dir", "+", "\"out.tsv\"", "\n", "\n", "# Placeholders", "\n", "self", ".", "train_mode", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "bool", ",", "name", "=", "'train_mode_placeholder'", ")", "\n", "self", ".", "labels_placeholder", "=", "tf", ".", "placeholder", "(", "dtype", "=", "\"float\"", ",", "shape", "=", "[", "None", ",", "NUM_CLASSES", "]", ",", "name", "=", "'labels_placeholder'", ")", "\n", "self", ".", "dropout_keep_prob", "=", "tf", ".", "placeholder", "(", "dtype", "=", "\"float\"", ",", "name", "=", "'dropout_keep_prob_placeholder'", ")", "\n", "\n", "# Global step for optimizer", "\n", "self", ".", "global_step", "=", "None", "\n", "\n", "# Output probabilities, predictions tensors and loss scalar", "\n", "self", ".", "scores", "=", "None", "\n", "self", ".", "probabilities", "=", "None", "\n", "self", ".", "predictions", "=", "None", "\n", "self", ".", "loss", "=", "None", "\n", "\n", "# Optimization", "\n", "self", ".", "learning_rate", "=", "learning_rate_dict", "[", "self", ".", "model_type", "]", "*", "(", "batch_size_dict", "[", "self", ".", "model_type", "]", "/", "256.", ")", "\n", "self", ".", "optimizer", "=", "None", "\n", "self", ".", "train_op", "=", "None", "\n", "\n", "# Accuracy stats", "\n", "self", ".", "accuracy", "=", "None", "\n", "self", ".", "sum_accuracy", "=", "None", "\n", "self", ".", "acc_summary", "=", "None", "\n", "self", ".", "loss_summary", "=", "None", "\n", "\n", "# Model save & restore, tensorboard", "\n", "self", ".", "saver", "=", "None", "\n", "self", ".", "global_variable_init", "=", "None", "\n", "self", ".", "train_summary_op", "=", "None", "\n", "self", ".", "train_writer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.train": [[120, 177], ["tensorflow.train.Saver", "tensorflow.global_variables_initializer", "base_model.BaseModel._train_setup", "base_model.BaseModel._train_helper_SGD", "print", "base_model.BaseModel.saver.save", "print", "base_model.BaseModel.close", "utils.get_dataset_iterator_from_tfrecords", "utils.get_dataset_iterator_from_tfrecords", "utils.get_dataset_iterator_from_tfrecords.get_next", "utils.get_dataset_iterator_from_tfrecords.get_next", "base_model.BaseModel.restore_model_from_filename", "base_model.BaseModel.restore_base_models", "tensorflow.global_variables"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._train_setup", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._train_helper_SGD", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.get_dataset_iterator_from_tfrecords", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.get_dataset_iterator_from_tfrecords", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.restore_model_from_filename", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.restore_base_models"], ["", "def", "train", "(", "self", ",", "train_ids", ",", "train_labels", ",", "train_texts", ",", "val_ids", ",", "val_labels", ",", "val_texts", ",", "retrain_model_filename", "=", "None", ")", ":", "\n", "        ", "\"\"\" Train the model on given data, saving model checkpoints and log files.\n\n        Parameters\n        ----------\n        :param train_ids: np.array, self-explanatory\n\n        :param train_labels: np.array\n\n        :param train_texts: np.array of np.arrays\n\n        :param val_ids: np.array\n\n        :param val_labels: np.array\n\n        :param val_texts: np.array of np.arrays\n\n        :param retrain_model_filename: str, if None, model is trained from scratch, else this param states where the\n            ckpt file resides, and model is further trained from that ckpt\n        \"\"\"", "\n", "if", "self", ".", "model_type", "!=", "ModelType", ".", "text_only", ":", "\n", "            ", "iterator_train", "=", "get_dataset_iterator_from_tfrecords", "(", "data_type", "=", "'train'", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "model_type", "=", "self", ".", "model_type", ")", "\n", "iterator_val", "=", "get_dataset_iterator_from_tfrecords", "(", "data_type", "=", "'validation'", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "model_type", "=", "self", ".", "model_type", ")", "\n", "\n", "iterator_train_init", "=", "iterator_train", ".", "initializer", "\n", "iterator_val_init", "=", "iterator_val", ".", "initializer", "\n", "next_element_train", "=", "iterator_train", ".", "get_next", "(", ")", "\n", "next_element_val", "=", "iterator_val", ".", "get_next", "(", ")", "\n", "", "else", ":", "\n", "            ", "iterator_train_init", ",", "next_element_train", ",", "iterator_val_init", ",", "next_element_val", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "\n", "", "vars_to_restore", "=", "[", "var", "for", "var", "in", "tf", ".", "global_variables", "(", ")", "]", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "vars_to_restore", ")", "\n", "self", ".", "global_variable_init", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "\n", "sess", "=", "self", ".", "_train_setup", "(", "train_ids", ",", "val_ids", ",", "batch_size", "=", "batch_size_dict", "[", "self", ".", "model_type", "]", ")", "\n", "\n", "if", "retrain_model_filename", "is", "not", "None", ":", "\n", "            ", "self", ".", "restore_model_from_filename", "(", "sess", ",", "model_filename", "=", "retrain_model_filename", ",", "saver", "=", "saver", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "restore_base_models", "(", "sess", ")", "\n", "\n", "", "self", ".", "_train_helper_SGD", "(", "sess", ",", "self", ".", "train_writer", ",", "train_ids", ",", "train_labels", ",", "\n", "train_texts", ",", "val_ids", ",", "val_labels", ",", "val_texts", ",", "iterator_train_init", ",", "next_element_train", ",", "\n", "iterator_val_init", ",", "next_element_val", ")", "\n", "\n", "# Final global save", "\n", "print", "(", "\"\\nSaving final model .ckpt file ...\"", ")", "\n", "_", "=", "self", ".", "saver", ".", "save", "(", "sess", ",", "self", ".", "checkpoint_dir", "+", "\"model.ckpt\"", ")", "\n", "print", "(", "\"Done saving final model .ckpt file.\"", ")", "\n", "\n", "# Close tensorflow session", "\n", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.test": [[178, 218], ["print", "print", "tensorflow.global_variables", "tensorflow.train.Saver", "utils.get_dataset_iterator_from_tfrecords", "utils.get_dataset_iterator_from_tfrecords.get_next", "os.path.exists", "os.makedirs", "tensorflow.Session", "base_model.BaseModel.restore_model", "base_model.BaseModel._run_tests", "base_model.BaseModel._write_results_to_file", "len"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.get_dataset_iterator_from_tfrecords", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.restore_model", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._run_tests", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._write_results_to_file"], ["", "def", "test", "(", "self", ",", "date", ",", "num_epochs", ",", "test_ids", ",", "test_labels", ",", "test_texts", ")", ":", "\n", "        ", "\"\"\"Run prediction on test set mini-batches\n\n        Parameters\n        ----------\n        :param date: str, folder name (timestamp) from which to retrieve pre-trained model\n\n        :param num_epochs: int, the number of epochs for the pre-trained model\n\n        :param test_ids: np.array of shape = [test_size], contain question ids in test set\n\n        :param test_labels: np.array of shape = [test_size, NUM_CLASSES]\n\n        :param test_texts: np.array of shape = [test_size, TEXT_LENGTH]\n        \"\"\"", "\n", "print", "(", "\"\\nStarting to test %s model\"", "%", "self", ".", "model_name", ".", "name", ")", "\n", "print", "(", "\"Test Data size: %d\"", "%", "len", "(", "test_ids", ")", ")", "\n", "\n", "# For image+text data, we use tf.dataset, while for text-only, we use simple iteration over loaded data.", "\n", "if", "self", ".", "model_type", "!=", "ModelType", ".", "text_only", ":", "\n", "            ", "iterator_test", "=", "get_dataset_iterator_from_tfrecords", "(", "data_type", "=", "'test'", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "model_type", "=", "self", ".", "model_type", ")", "\n", "iterator_test_init", "=", "iterator_test", ".", "initializer", "\n", "next_element_test", "=", "iterator_test", ".", "get_next", "(", ")", "\n", "", "else", ":", "\n", "            ", "iterator_test", ",", "iterator_test_init", ",", "next_element_test", "=", "None", ",", "None", ",", "None", "\n", "\n", "", "vars_to_restore", "=", "tf", ".", "global_variables", "(", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "vars_to_restore", ")", "\n", "\n", "# Make directory to write results to", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "test_log_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "test_log_dir", ")", "\n", "\n", "", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "self", ".", "restore_model", "(", "sess", ",", "date", ",", "num_epochs", ",", "saver", ")", "\n", "# Run the tests and get accuracy, predicted labels, confusion matrix etc.", "\n", "test_accuracy", ",", "labels", ",", "results", ",", "conf_matrix", "=", "self", ".", "_run_tests", "(", "sess", ",", "test_ids", ",", "test_labels", ",", "test_texts", ",", "\n", "iterator_test_init", ",", "next_element_test", ")", "\n", "self", ".", "_write_results_to_file", "(", "conf_matrix", ",", "date", ",", "labels", ",", "results", ",", "test_ids", ",", "test_accuracy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.retrain": [[219, 228], ["print", "paths.get_stored_checkpoint_filename", "base_model.BaseModel.train"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.paths.get_stored_checkpoint_filename", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.train"], ["", "", "def", "retrain", "(", "self", ",", "date", ",", "num_epochs", ",", "train_ids", ",", "train_labels", ",", "train_texts", ",", "val_ids", ",", "val_labels", ",", "val_texts", ")", ":", "\n", "        ", "\"\"\" Load a pre-trained model, and start retraining it.\"\"\"", "\n", "print", "(", "\"\\nStarting to retrain %s model\\n\"", "%", "self", ".", "model_name", ".", "name", ")", "\n", "# This is the name under which the model usually gets stored", "\n", "model_filename", "=", "get_stored_checkpoint_filename", "(", "model_type", "=", "self", ".", "model_type", ",", "\n", "model_name", "=", "self", ".", "model_name", ",", "date", "=", "date", ",", "num_epochs", "=", "num_epochs", ")", "\n", "# Start retraining", "\n", "self", ".", "train", "(", "train_ids", ",", "train_labels", ",", "train_texts", ",", "val_ids", ",", "val_labels", ",", "val_texts", ",", "\n", "retrain_model_filename", "=", "model_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._train_helper_SGD": [[229, 234], ["None"], "methods", ["None"], ["", "def", "_train_helper_SGD", "(", "self", ",", "sess", ",", "train_writer", ",", "train_ids", ",", "train_labels", ",", "train_texts", ",", "\n", "val_ids", ",", "val_labels", ",", "val_texts", ",", "iterator_train_init", ",", "next_element_train", ",", "iterator_val_init", ",", "\n", "next_element_val", ")", ":", "\n", "        ", "\"\"\"Abstract method \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._run_tests": [[235, 238], ["None"], "methods", ["None"], ["", "def", "_run_tests", "(", "self", ",", "sess", ",", "test_ids", ",", "test_labels", ",", "test_texts", ",", "iterator_test_init", ",", "next_element_test", ")", ":", "\n", "        ", "\"\"\"Abstract method \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._write_results_to_file": [[239, 264], ["print", "print", "print", "open", "open", "xrange", "handle2.write", "len", "handle1.write", "handle2.write", "str", "str", "str", "str().rjust", "str"], "methods", ["None"], ["", "def", "_write_results_to_file", "(", "self", ",", "conf_matrix", ",", "date", ",", "labels", ",", "results", ",", "test_ids", ",", "test_accuracy", ")", ":", "\n", "        ", "\"\"\"Write two files: test_logits.tsv and test_result.tsv.\n\n        The first file will contain the predictions for each sample,\n\n        The second will have the confusion matrix for the categories and final accuracy.\n        \"\"\"", "\n", "print", "(", "'\\nWriting results to file ...'", ")", "\n", "\n", "with", "open", "(", "self", ".", "test_log_dir", "+", "'test_logits.tsv'", ",", "'w'", ")", "as", "handle1", ",", "open", "(", "self", ".", "results_subdirectory", "+", "self", ".", "model_name", ".", "name", "+", "'/train/'", "+", "date", "+", "'/test_result.tsv'", ",", "\n", "'w'", ")", "as", "handle2", ":", "\n", "            ", "if", "conf_matrix", "is", "not", "None", ":", "\n", "                ", "for", "row", "in", "conf_matrix", ":", "\n", "                    ", "r", "=", "''", "\n", "for", "col", "in", "row", ":", "\n", "                        ", "r", "=", "r", "+", "str", "(", "col", ")", ".", "rjust", "(", "4", ")", "+", "','", "\n", "", "handle2", ".", "write", "(", "r", "+", "'\\n'", ")", "\n", "", "", "for", "i", "in", "xrange", "(", "len", "(", "labels", ")", ")", ":", "\n", "                ", "o", "=", "'\\t'", ".", "join", "(", "[", "str", "(", "test_ids", "[", "i", "]", ")", ",", "str", "(", "labels", "[", "i", "]", ")", ",", "str", "(", "results", "[", "i", "]", ")", "]", ")", "\n", "handle1", ".", "write", "(", "o", "+", "'\\n'", ")", "\n", "", "handle2", ".", "write", "(", "\"test accuracy = %g\"", "%", "test_accuracy", ")", "\n", "\n", "", "print", "(", "'Done writing results to file\\n'", ")", "\n", "print", "(", "'\\n***Test Accuracy = %g***\\n'", "%", "test_accuracy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._set_predictions_optimizer_and_loss": [[265, 354], ["tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.global_variables", "tensorflow.train.Saver", "tensorflow.summary.merge", "print", "tensorflow.nn.sigmoid", "tensorflow.round", "tensorflow.nn.softmax", "tensorflow.argmax", "tensorflow.Variable", "tensorflow.variable_scope", "tensorflow.train.exponential_decay", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.control_dependencies", "tensorflow.variable_scope", "tensorflow.summary.FileWriter", "tensorflow.reduce_mean", "int", "tensorflow.train.piecewise_constant", "tensorflow.train.AdamOptimizer", "base_model.BaseModel.optimizer.compute_gradients", "base_model.BaseModel.optimizer.apply_gradients", "base_model.BaseModel.optimizer.minimize", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.reduce_all", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.get_default_graph", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.reduce_mean", "int", "tensorflow.cast", "tensorflow.Variable", "tensorflow.train.RMSPropOptimizer", "ValueError", "tensorflow.trainable_variables", "tensorflow.device", "tensorflow.argmax", "tensorflow.cast", "tensorflow.cast", "tensorflow.equal", "tensorflow.cast", "tensorflow.cast", "tensorflow.log", "tensorflow.clip_by_value", "tensorflow.clip_by_value"], "methods", ["None"], ["", "def", "_set_predictions_optimizer_and_loss", "(", "self", ")", ":", "\n", "        ", "if", "USE_MULTILABEL", ":", "\n", "            ", "self", ".", "probabilities", "=", "tf", ".", "nn", ".", "sigmoid", "(", "self", ".", "scores", ",", "name", "=", "\"probabilities\"", ")", "\n", "self", ".", "predictions", "=", "tf", ".", "round", "(", "self", ".", "probabilities", ",", "name", "=", "\"predictions\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "probabilities", "=", "tf", ".", "nn", ".", "softmax", "(", "self", ".", "scores", ",", "name", "=", "\"probabilities\"", ")", "\n", "self", ".", "predictions", "=", "tf", ".", "argmax", "(", "self", ".", "probabilities", ",", "1", ",", "name", "=", "\"predictions\"", ")", "\n", "\n", "", "if", "self", ".", "trainable", ":", "\n", "            ", "self", ".", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "dtype", "=", "tf", ".", "int32", ",", "trainable", "=", "False", ",", "name", "=", "'global_step'", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"loss\"", ")", ":", "\n", "            ", "if", "USE_MULTILABEL", ":", "\n", "# Calculate sigmoid cross-entropy loss", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "labels", "=", "self", ".", "labels_placeholder", ",", "\n", "logits", "=", "self", ".", "scores", ")", ")", "\n", "", "else", ":", "\n", "# Calculate mean cross-entropy loss", "\n", "                ", "self", ".", "loss", "=", "-", "tf", ".", "reduce_mean", "(", "self", ".", "labels_placeholder", "*", "tf", ".", "log", "(", "tf", ".", "clip_by_value", "(", "self", ".", "probabilities", ",", "\n", "1e-10", ",", "1.0", ")", ")", ")", "\n", "\n", "", "", "if", "decay_learning_rate", ":", "\n", "            ", "self", ".", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "self", ".", "learning_rate", ",", "self", ".", "global_step", ",", "\n", "DECAY_STEP_LEARNING_RATE", ",", "DECAY_RATE_LEARNING_RATE", ",", "\n", "staircase", "=", "True", ")", "\n", "", "elif", "scale_learning_rate", ":", "\n", "            ", "initial_learning_rate", "=", "self", ".", "learning_rate", "\n", "batches_per_epoch", "=", "int", "(", "NUM_IMAGES", "[", "'train'", "]", "/", "batch_size_dict", "[", "self", ".", "model_type", "]", ")", "\n", "# Multiply the learning rate by 0.5 at 2, 4, 80, and 90 epochs.", "\n", "boundaries", "=", "[", "\n", "int", "(", "batches_per_epoch", "*", "epoch", ")", "for", "epoch", "in", "scale_epochs_dict", "[", "self", ".", "model_type", "]", "]", "\n", "values", "=", "[", "\n", "initial_learning_rate", "*", "scale", "for", "scale", "in", "scale_factors_dict", "[", "self", ".", "model_type", "]", "]", "\n", "self", ".", "learning_rate", "=", "tf", ".", "train", ".", "piecewise_constant", "(", "\n", "tf", ".", "cast", "(", "self", ".", "global_step", ",", "tf", ".", "int32", ")", ",", "boundaries", ",", "values", ")", "\n", "\n", "", "elif", "early_stopping_learning_rate", ":", "\n", "            ", "self", ".", "learning_rate", "=", "tf", ".", "Variable", "(", "self", ".", "learning_rate", ",", "trainable", "=", "False", ",", "name", "=", "'learning_rate_var'", ")", "\n", "\n", "", "if", "self", ".", "model_type", "!=", "ModelType", ".", "image_only", ":", "\n", "            ", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ",", "scope", "=", "self", ".", "model_name", ".", "name", ")", "\n", "", "else", ":", "\n", "            ", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "\n", "", "with", "tf", ".", "control_dependencies", "(", "update_ops", ")", ":", "\n", "# Define Training procedure", "\n", "            ", "if", "OPTIMIZER", "==", "OptimizerType", ".", "adam", ":", "\n", "                ", "self", ".", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "learning_rate", ")", "\n", "", "elif", "OPTIMIZER", "==", "OptimizerType", ".", "rms_optimizer", ":", "\n", "                ", "self", ".", "optimizer", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "learning_rate", "=", "self", ".", "learning_rate", ",", "\n", "momentum", "=", "OPTIMIZER_MOMENTUM", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Invalid value for OPTIMIZER var\"", ")", "\n", "\n", "", "if", "USE_GRADIENT_CLIPPING", ":", "\n", "# gradient clipping", "\n", "                ", "gvs", "=", "self", ".", "optimizer", ".", "compute_gradients", "(", "self", ".", "loss", ",", "tf", ".", "trainable_variables", "(", ")", ")", "\n", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "                    ", "clipped_gvs", "=", "[", "(", "tf", ".", "clip_by_value", "(", "grad", ",", "-", "10.0", ",", "10.0", ")", ",", "var", ")", "for", "grad", ",", "var", "in", "gvs", "if", "grad", "is", "not", "None", "]", "\n", "", "self", ".", "train_op", "=", "self", ".", "optimizer", ".", "apply_gradients", "(", "clipped_gvs", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "train_op", "=", "self", ".", "optimizer", ".", "minimize", "(", "self", ".", "loss", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "\n", "# Calculate Accuracy", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"accuracy\"", ")", ":", "\n", "            ", "if", "not", "USE_MULTILABEL", ":", "\n", "                ", "self", ".", "correct_predictions", "=", "tf", ".", "equal", "(", "self", ".", "predictions", ",", "tf", ".", "argmax", "(", "self", ".", "labels_placeholder", ",", "1", ")", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "self", ".", "correct_predictions", ",", "\"float\"", ")", ",", "name", "=", "\"accuracy\"", ")", "\n", "self", ".", "sum_accuracy", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "cast", "(", "self", ".", "correct_predictions", ",", "\"float\"", ")", ",", "name", "=", "\"sum_accuracy\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "correct_predictions", "=", "tf", ".", "reduce_all", "(", "tf", ".", "equal", "(", "self", ".", "predictions", ",", "self", ".", "labels_placeholder", ")", ",", "axis", "=", "1", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "self", ".", "correct_predictions", ",", "\"float\"", ")", ",", "name", "=", "'accuracy'", ")", "\n", "self", ".", "sum_accuracy", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "cast", "(", "self", ".", "correct_predictions", ",", "\"float\"", ")", ",", "name", "=", "\"sum_accuracy\"", ")", "\n", "\n", "# Summaries for loss and accuracy", "\n", "", "", "self", ".", "loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "\"loss\"", ",", "self", ".", "loss", ")", "\n", "self", ".", "acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "\"accuracy\"", ",", "self", ".", "accuracy", ")", "\n", "\n", "vars_to_restore", "=", "tf", ".", "global_variables", "(", ")", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "vars_to_restore", ",", "max_to_keep", "=", "None", ")", "\n", "\n", "# Train Summaries at Tensorboard", "\n", "self", ".", "train_summary_op", "=", "tf", ".", "summary", ".", "merge", "(", "[", "self", ".", "loss_summary", ",", "self", ".", "acc_summary", "]", ")", "\n", "\n", "# Define the file writer for tensorboard", "\n", "if", "self", ".", "is_primary_model", ":", "\n", "            ", "self", ".", "train_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "self", ".", "train_log_dir", "+", "\"train_tensorboard\"", ",", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "", "print", "(", "'Completed %s object construction.'", "%", "self", ".", "model_name", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.restore_mid_training": [[355, 370], ["tensorflow.train.Saver", "tensorflow.global_variables_initializer", "paths.get_stored_checkpoint_filename", "base_model.BaseModel.restore_model_from_filename", "tensorflow.global_variables"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.paths.get_stored_checkpoint_filename", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.restore_model_from_filename"], ["", "def", "restore_mid_training", "(", "self", ",", "sess", ",", "num_epochs", ")", ":", "\n", "        ", "\"\"\"Used to restore a pre-trained model while training - specifically when validation accuracy has decreased,\n            and we retore the best model so far, and run training with reduced learning rate.\n\n        Parameters\n        ----------\n        :param sess: tf.Session() object\n\n        :param num_epochs: int, the best model's epoch number\n        \"\"\"", "\n", "vars_to_restore", "=", "[", "var", "for", "var", "in", "tf", ".", "global_variables", "(", ")", "if", "'learning_rate_var'", "not", "in", "var", ".", "name", "]", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "vars_to_restore", ")", "\n", "self", ".", "global_variable_init", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "model_filename", "=", "get_stored_checkpoint_filename", "(", "self", ".", "model_type", ",", "self", ".", "model_name", ",", "TIME_STAMP", ",", "num_epochs", ")", "\n", "self", ".", "restore_model_from_filename", "(", "sess", ",", "model_filename", "=", "model_filename", ",", "saver", "=", "saver", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.restore_model": [[371, 392], ["paths.get_stored_checkpoint_filename", "base_model.BaseModel.restore_model_from_filename"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.paths.get_stored_checkpoint_filename", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.restore_model_from_filename"], ["", "def", "restore_model", "(", "self", ",", "sess", ",", "date", ",", "num_epochs", ",", "saver", "=", "None", ")", ":", "\n", "        ", "\"\"\"Instantiate a tf.train.Saver object and restore saved model at model_filename through it\n\n        Parameters\n        ----------\n        :param sess: tensorflow.Session object, current open session\n\n        :param date: str, folder name timestamp where the model is stored\n\n        :param num_epochs: int or str, the epoch number from which model is to be restored\n\n        :param saver: tf.train.Saver() object\n\n        Returns\n        -------\n        :return: None, the weights in current session are restored from the ckpt file\n        \"\"\"", "\n", "# This is the name under which the model usually gets stored", "\n", "model_filename", "=", "get_stored_checkpoint_filename", "(", "model_type", "=", "self", ".", "model_type", ",", "\n", "model_name", "=", "self", ".", "model_name", ",", "date", "=", "date", ",", "num_epochs", "=", "num_epochs", ")", "\n", "self", ".", "restore_model_from_filename", "(", "sess", ",", "model_filename", "=", "model_filename", ",", "saver", "=", "saver", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.restore_model_from_filename": [[393, 416], ["print", "tensorflow.train.Saver.restore", "print", "tensorflow.global_variables", "tensorflow.train.Saver"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "restore_model_from_filename", "(", "sess", ",", "model_filename", ",", "saver", "=", "None", ")", ":", "\n", "        ", "\"\"\"Instantiate a tf.train.Saver object and restore saved model at model_filename through it\n\n        Parameters\n        ----------\n        :param sess: tensorflow.Session object, current open session\n\n        :param model_filename: str, the name under which the model usually gets stored\n\n        :param saver: tf.train.Saver() object\n\n        Returns\n        -------\n        :return: None, the weights in current session are restored from the ckpt file\n        \"\"\"", "\n", "print", "(", "\"\\nRestoring model from %s ...\"", "%", "model_filename", ")", "\n", "if", "saver", "is", "None", ":", "\n", "            ", "vars_to_restore", "=", "tf", ".", "global_variables", "(", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "vars_to_restore", ")", "\n", "\n", "", "saver", ".", "restore", "(", "sess", ",", "model_filename", ")", "\n", "print", "(", "\"Done restoring model.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._train_setup": [[417, 446], ["os.makedirs", "base_model.BaseModel._write_config_file", "print", "print", "print", "print", "tensorflow.Session", "print", "tensorflow.Session.run", "print", "len", "len", "int", "len"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._write_config_file"], ["", "def", "_train_setup", "(", "self", ",", "train_ids", ",", "val_ids", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Setup training by printing preliminary information, making reqd directories, initializing tf session,\n        and making required log file. Return the tf.Session object and opened log file handle.\n        P.S: Please remember to close the returned sess handle, the code structure was not apt for a \"with\" clause.\n        :param train_ids: np.array of ints\n        :param val_ids: np.array of ints\n        :param batch_size: int\n        :return: [tf.Session() object, file_handle]\n        \"\"\"", "\n", "# Make directory to store checkpoints.", "\n", "os", ".", "makedirs", "(", "self", ".", "checkpoint_dir", ")", "\n", "\n", "self", ".", "_write_config_file", "(", ")", "\n", "\n", "print", "(", "'\\nStarting to train %s model'", "%", "self", ".", "model_name", ".", "name", ")", "\n", "\n", "# Print stats", "\n", "print", "(", "\"Total train samples: %d\"", "%", "len", "(", "train_ids", ")", ")", "\n", "print", "(", "\"Batch Size: %d, Num batches: %d\"", "%", "(", "batch_size", ",", "int", "(", "len", "(", "train_ids", ")", "/", "batch_size", ")", ")", ")", "\n", "print", "(", "\"Total validation samples: %d\"", "%", "len", "(", "val_ids", ")", ")", "\n", "\n", "# Session: launch the graph", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "# Initialize all variables", "\n", "print", "(", "\"Running global variable init\"", ")", "\n", "sess", ".", "run", "(", "self", ".", "global_variable_init", ")", "\n", "print", "(", "\"Done running global variable init\"", ")", "\n", "return", "sess", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.validation_test": [[447, 463], ["tensorflow.global_variables", "tensorflow.train.Saver", "tensorflow.global_variables_initializer", "utils.get_dataset_iterator_from_tfrecords", "utils.get_dataset_iterator_from_tfrecords.get_next", "tensorflow.Session", "base_model.BaseModel.restore_model", "base_model.BaseModel._run_validation_test"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.get_dataset_iterator_from_tfrecords", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.restore_model", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._run_validation_test"], ["", "def", "validation_test", "(", "self", ",", "date", ",", "num_epochs", ",", "val_ids", ",", "val_labels", ",", "val_texts", ")", ":", "\n", "        ", "if", "self", ".", "model_type", "!=", "ModelType", ".", "text_only", ":", "\n", "            ", "iterator_validation", "=", "get_dataset_iterator_from_tfrecords", "(", "data_type", "=", "'validation'", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "model_type", "=", "self", ".", "model_type", ")", "\n", "iterator_validation_init", "=", "iterator_validation", ".", "initializer", "\n", "next_element_val", "=", "iterator_validation", ".", "get_next", "(", ")", "\n", "", "else", ":", "\n", "            ", "iterator_validation_init", ",", "next_element_val", "=", "None", ",", "None", "\n", "\n", "", "vars_to_restore", "=", "tf", ".", "global_variables", "(", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "vars_to_restore", ")", "\n", "self", ".", "global_variable_init", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "self", ".", "restore_model", "(", "sess", ",", "date", ",", "num_epochs", ",", "saver", ")", "\n", "self", ".", "_run_validation_test", "(", "sess", ",", "val_ids", ",", "val_labels", ",", "val_texts", ",", "iterator_validation_init", ",", "next_element_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._run_validation_test": [[464, 466], ["None"], "methods", ["None"], ["", "", "def", "_run_validation_test", "(", "self", ",", "sess", ",", "val_ids", ",", "val_labels", ",", "val_texts", ",", "iterator_validation", ",", "next_element_val", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel._write_config_file": [[467, 479], ["open", "global_hyperparams.global_config.iteritems", "handle.write", "base_model.BaseModel.model_type_config.iteritems", "handle.write", "handle.write", "base_model.BaseModel.config.iteritems", "handle.write", "handle.write"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.iteritems", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.iteritems", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.iteritems"], ["", "def", "_write_config_file", "(", "self", ")", ":", "\n", "        ", "\"\"\"Write the configuration file for the model\"\"\"", "\n", "with", "open", "(", "self", ".", "checkpoint_dir", "+", "\"config\"", ",", "\"w\"", ")", "as", "handle", ":", "\n", "            ", "for", "key", ",", "value", "in", "global_config", ".", "iteritems", "(", ")", ":", "\n", "                ", "handle", ".", "write", "(", "\"%-25s %-s\\n\"", "%", "(", "key", ",", "value", ")", ")", "\n", "", "if", "self", ".", "config", "is", "not", "None", ":", "\n", "                ", "handle", ".", "write", "(", "\"\\n#----------------------------- MODEL CONFIG -----------------------------#\\n\"", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "config", ".", "iteritems", "(", ")", ":", "\n", "                    ", "handle", ".", "write", "(", "\"%-25s %-s\\n\"", "%", "(", "key", ",", "value", ")", ")", "\n", "", "", "handle", ".", "write", "(", "\"\\n#--------------------------- MODEL TYPE CONFIG ---------------------------#\\n\"", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "model_type_config", ".", "iteritems", "(", ")", ":", "\n", "                ", "handle", ".", "write", "(", "\"%-25s %-s\\n\"", "%", "(", "key", ",", "value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.restore_base_models": [[480, 483], ["None"], "methods", ["None"], ["", "", "", "def", "restore_base_models", "(", "self", ",", "sess", ")", ":", "\n", "# TODO: Make abstact and implement for all models", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.early_stopping_procedure": [[485, 524], ["numpy.argmax", "base_model.BaseModel.restore_mid_training", "len", "base_model.BaseModel.learning_rate.assign().eval", "base_model.BaseModel.learning_rate.assign().eval", "numpy.argmax", "base_model.BaseModel.restore_mid_training", "base_model.BaseModel.learning_rate.assign().eval", "len", "base_model.BaseModel.learning_rate.assign", "base_model.BaseModel.learning_rate.assign", "max", "base_model.BaseModel.learning_rate.assign"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.restore_mid_training", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.base_model.BaseModel.restore_mid_training"], ["", "def", "early_stopping_procedure", "(", "self", ",", "sess", ",", "epochs_with_current_lrate", ",", "val_acc_history", ",", "min_increment", ",", "\n", "tolerable_decrease", ")", ":", "\n", "        ", "\"\"\"Implement procedure for decaying learning rate acc to validation accuracy history\n\n        Parameters\n        ----------\n        :param sess: tf.Session() object\n\n        :param epochs_with_current_lrate: int, number of epochs completed with current learning rate\n\n        :param val_acc_history: list of floats, containing validation accuracies of all completed epochs\n\n        :param min_increment: float, minimum increment over validation accuracy viewed as significant\n\n        :param tolerable_decrease: float, tolerable amount of decrease in val acc, otherwise learning rate is tanked.\n\n        Returns\n        -------\n        :return: bool, whether the model should early stop on account of no val acc increase, or not.\n        \"\"\"", "\n", "# Decay learning rate if required", "\n", "if", "early_stopping_learning_rate", ":", "\n", "            ", "if", "epochs_with_current_lrate", ">=", "3", "and", "val_acc_history", "[", "-", "1", "]", "<", "(", "val_acc_history", "[", "-", "3", "]", "+", "min_increment", ")", ":", "\n", "                ", "best_epoch", "=", "np", ".", "argmax", "(", "val_acc_history", ")", "\n", "self", ".", "restore_mid_training", "(", "sess", "=", "sess", ",", "num_epochs", "=", "best_epoch", ")", "\n", "if", "len", "(", "val_acc_history", ")", ">=", "8", "and", "val_acc_history", "[", "-", "1", "]", "<", "(", "val_acc_history", "[", "-", "8", "]", "+", "min_increment", ")", ":", "\n", "                    ", "self", ".", "learning_rate", ".", "assign", "(", "self", ".", "learning_rate", "/", "10.", ")", ".", "eval", "(", "session", "=", "sess", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "learning_rate", ".", "assign", "(", "self", ".", "learning_rate", "/", "2.", ")", ".", "eval", "(", "session", "=", "sess", ")", "\n", "", "epochs_with_current_lrate", "=", "0", "\n", "", "elif", "epochs_with_current_lrate", ">=", "1", "and", "(", "max", "(", "val_acc_history", ")", "-", "val_acc_history", "[", "-", "1", "]", ")", ">", "tolerable_decrease", ":", "\n", "                ", "best_epoch", "=", "np", ".", "argmax", "(", "val_acc_history", ")", "\n", "self", ".", "restore_mid_training", "(", "sess", "=", "sess", ",", "num_epochs", "=", "best_epoch", ")", "\n", "self", ".", "learning_rate", ".", "assign", "(", "self", ".", "learning_rate", "/", "2.", ")", ".", "eval", "(", "session", "=", "sess", ")", "\n", "\n", "# The var early_stop_bool=True for early stopping if we have more than 15 epochs,", "\n", "# And less than min_increment over last ten epochs", "\n", "", "", "early_stop_bool", "=", "(", "len", "(", "val_acc_history", ")", ">", "15", ")", "and", "(", "val_acc_history", "[", "-", "1", "]", "<", "(", "val_acc_history", "[", "-", "10", "]", "+", "min_increment", ")", ")", "\n", "return", "early_stop_bool", ",", "epochs_with_current_lrate", "\n", "", "", ""]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.load_train_val_data": [[26, 81], ["print", "numpy.load", "print", "numpy.load", "print", "numpy.load", "numpy.load", "print", "print", "numpy.load", "numpy.load", "utils.resize_input", "utils.resize_input", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.resize_input", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.resize_input"], ["def", "load_train_val_data", "(", "load_texts", "=", "True", ")", ":", "\n", "    ", "\"\"\"Read files from data_directory and return np arrays for train labels and ids & validation labels & ids.\n\n    Parameters\n    ----------\n    :param load_texts: bool, whether to load text data, or just return None for it\n\n    Returns\n    -------\n    train_ids: array-like, of shape [NUM_TRAIN_QUESTIONS] containing Chiebukuro question ids\n\n    train_labels: array-like, of shape [NUM_TRAIN_QUESTIONS, NUM_CLASSES]\n\n    train_texts: array-like, of shape [NUM_TRAIN_QUESTIONS, TEXT_LENGTH]\n\n    val_ids: array-like, of shape [NUM_VAL_QUESTIONS] containing Chiebukuro question ids\n\n    val_labels: array-like, of shape [NUM_VAL_QUESTIONS, NUM_CLASSES]\n\n    val_texts: array-like, of shape [NUM_VAL_QUESTIONS, TEXT_LENGTH]\n    \"\"\"", "\n", "print", "(", "\"\\nLoading training & validation data ...\"", ")", "\n", "train_ids", "=", "np", ".", "load", "(", "data_directory", "+", "'train_ids%s.npy'", "%", "(", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "\n", "print", "(", "\"Loaded train ids\"", ")", "\n", "val_ids", "=", "np", ".", "load", "(", "data_directory", "+", "'val_ids%s.npy'", "%", "(", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "\n", "print", "(", "\"Loaded val ids\"", ")", "\n", "\n", "train_labels", "=", "np", ".", "load", "(", "data_directory", "+", "'train_label_ext%d%s%s%s.npy'", "\n", "%", "(", "NUM_CLASSES", ",", "'_2014'", "if", "USE_2014_DATA", "else", "''", ",", "'_ml'", "if", "USE_MULTILABEL", "else", "''", ",", "\n", "'_merged'", "if", "USE_MERGED_LABELS", "else", "''", ")", ")", "\n", "val_labels", "=", "np", ".", "load", "(", "data_directory", "+", "'val_label_ext%d%s%s%s.npy'", "\n", "%", "(", "NUM_CLASSES", ",", "'_2014'", "if", "USE_2014_DATA", "else", "''", ",", "'_ml'", "if", "USE_MULTILABEL", "else", "''", ",", "\n", "'_merged'", "if", "USE_MERGED_LABELS", "else", "''", ")", ")", "\n", "print", "(", "\"Done loading labels\"", ")", "\n", "\n", "if", "TEXT_LENTH", "==", "155", ":", "\n", "        ", "train_texts", "=", "np", ".", "load", "(", "data_directory", "+", "'train155.npy'", ")", "if", "load_texts", "else", "None", "\n", "val_texts", "=", "np", ".", "load", "(", "data_directory", "+", "'val155.npy'", ")", "if", "load_texts", "else", "None", "\n", "", "elif", "TEXT_LENTH", "==", "160", ":", "\n", "        ", "if", "USE_TRUNC_VOCAB", ":", "\n", "            ", "train_texts", "=", "np", ".", "load", "(", "data_directory", "+", "'train160_trunc%s.npy'", "%", "(", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "if", "load_texts", "else", "None", "\n", "val_texts", "=", "np", ".", "load", "(", "data_directory", "+", "'val160_trunc%s.npy'", "%", "(", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "if", "load_texts", "else", "None", "\n", "", "else", ":", "\n", "            ", "train_texts", "=", "np", ".", "load", "(", "data_directory", "+", "'train160%s.npy'", "%", "(", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "if", "load_texts", "else", "None", "\n", "val_texts", "=", "np", ".", "load", "(", "data_directory", "+", "'val160%s.npy'", "%", "(", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "if", "load_texts", "else", "None", "\n", "", "", "else", ":", "\n", "        ", "train_texts", "=", "resize_input", "(", "np", ".", "load", "(", "data_directory", "+", "'train.npy'", ")", ",", "TEXT_LENTH", ")", "if", "load_texts", "else", "None", "\n", "val_texts", "=", "resize_input", "(", "np", ".", "load", "(", "data_directory", "+", "'val.npy'", ")", ",", "TEXT_LENTH", ")", "if", "load_texts", "else", "None", "\n", "\n", "", "print", "(", "\"Done loading training & validation data.\"", ")", "\n", "return", "train_ids", ",", "train_labels", ",", "train_texts", ",", "val_ids", ",", "val_labels", ",", "val_texts", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.load_test_data": [[83, 112], ["print", "numpy.load", "numpy.load", "print", "numpy.load", "utils.resize_input", "numpy.load", "numpy.load", "numpy.load"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.resize_input"], ["", "def", "load_test_data", "(", "load_texts", "=", "True", ")", ":", "\n", "    ", "\"\"\"Read files from data_directory and return np arrays for test labels and ids.\n\n    Parameters\n    ----------\n    :param load_texts: bool, whether to load text data, or just return None for it\n    \"\"\"", "\n", "print", "(", "\"\\nLoading test data ...\"", ")", "\n", "test_labels", "=", "np", ".", "load", "(", "data_directory", "+", "'test_label_ext%d%s%s%s.npy'", "\n", "%", "(", "NUM_CLASSES", ",", "'_2014'", "if", "USE_2014_DATA", "else", "''", ",", "'_ml'", "if", "USE_MULTILABEL", "else", "''", ",", "\n", "'_merged'", "if", "USE_MERGED_LABELS", "else", "''", ")", ")", "\n", "\n", "test_ids", "=", "np", ".", "load", "(", "data_directory", "+", "'test_ids%s.npy'", "%", "(", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "\n", "\n", "test_texts", "=", "None", "\n", "if", "load_texts", ":", "\n", "        ", "if", "TEXT_LENTH", "==", "155", ":", "\n", "            ", "test_texts", "=", "np", ".", "load", "(", "data_directory", "+", "'test155.npy'", ")", "\n", "", "elif", "TEXT_LENTH", "==", "160", ":", "\n", "            ", "if", "USE_TRUNC_VOCAB", ":", "\n", "                ", "test_texts", "=", "np", ".", "load", "(", "data_directory", "+", "'test160_trunc%s.npy'", "%", "(", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "\n", "", "else", ":", "\n", "                ", "test_texts", "=", "np", ".", "load", "(", "data_directory", "+", "'test160%s.npy'", "%", "(", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "test_texts", "=", "resize_input", "(", "np", ".", "load", "(", "data_directory", "+", "'test%s.npy'", "%", "(", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", ",", "\n", "TEXT_LENTH", ")", "\n", "\n", "", "", "print", "(", "\"Done loading test data.\"", ")", "\n", "return", "test_labels", ",", "test_ids", ",", "test_texts", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.load_val_data": [[114, 145], ["print", "numpy.load", "print", "numpy.load", "print", "print", "numpy.load", "utils.resize_input", "numpy.load", "numpy.load", "numpy.load"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.resize_input"], ["", "def", "load_val_data", "(", "load_texts", "=", "True", ")", ":", "\n", "    ", "\"\"\"Read files from data_directory and return np arrays for test labels and ids.\n\n    Parameters\n    ----------\n    :param load_texts: bool, whether to load text data, or just return None for it\n    \"\"\"", "\n", "print", "(", "\"\\nLoading val data ...\"", ")", "\n", "val_labels", "=", "np", ".", "load", "(", "data_directory", "+", "'val_label_ext%d%s%s%s.npy'", "\n", "%", "(", "NUM_CLASSES", ",", "'_2014'", "if", "USE_2014_DATA", "else", "''", ",", "'_ml'", "if", "USE_MULTILABEL", "else", "''", ",", "\n", "'_merged'", "if", "USE_MERGED_LABELS", "else", "''", ")", ")", "\n", "print", "(", "\"Done loading val labels\"", ")", "\n", "\n", "val_ids", "=", "np", ".", "load", "(", "data_directory", "+", "'val_ids%s.npy'", "%", "(", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "\n", "print", "(", "\"Done loading val ids\"", ")", "\n", "\n", "val_texts", "=", "None", "\n", "if", "load_texts", ":", "\n", "        ", "if", "TEXT_LENTH", "==", "155", ":", "\n", "            ", "val_texts", "=", "np", ".", "load", "(", "data_directory", "+", "'val155.npy'", ")", "\n", "", "elif", "TEXT_LENTH", "==", "160", ":", "\n", "            ", "if", "USE_TRUNC_VOCAB", ":", "\n", "                ", "val_texts", "=", "np", ".", "load", "(", "data_directory", "+", "'val160_trunc%s.npy'", "%", "(", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "\n", "", "else", ":", "\n", "                ", "val_texts", "=", "np", ".", "load", "(", "data_directory", "+", "'val160%s.npy'", "%", "(", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "val_texts", "=", "resize_input", "(", "np", ".", "load", "(", "data_directory", "+", "'val%s.npy'", "%", "(", "'_2014'", "if", "USE_2014_DATA", "else", "''", ")", ")", ",", "\n", "TEXT_LENTH", ")", "\n", "\n", "", "", "print", "(", "\"Done loading val data.\"", ")", "\n", "return", "val_labels", ",", "val_ids", ",", "val_texts", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.right_align": [[147, 157], ["numpy.zeros", "numpy.argmax", "range", "numpy.shape", "numpy.shape", "numpy.where", "numpy.shape"], "function", ["None"], ["", "def", "right_align", "(", "sequence", ")", ":", "\n", "    ", "right_aligned_seq", "=", "np", ".", "zeros", "(", "np", ".", "shape", "(", "sequence", ")", ")", "\n", "lengths", "=", "np", ".", "argmax", "(", "sequence", "==", "0", ",", "axis", "=", "1", ")", "\n", "\n", "lengths", "[", "np", ".", "where", "(", "lengths", "==", "0", ")", "]", "=", "TEXT_LENTH", "\n", "\n", "cols", "=", "np", ".", "shape", "(", "sequence", ")", "[", "1", "]", "\n", "for", "row", "in", "range", "(", "np", ".", "shape", "(", "sequence", ")", "[", "0", "]", ")", ":", "\n", "        ", "right_aligned_seq", "[", "row", "]", "[", "cols", "-", "lengths", "[", "row", "]", ":", "cols", "]", "=", "sequence", "[", "row", "]", "[", "0", ":", "lengths", "[", "row", "]", "]", "\n", "", "return", "right_aligned_seq", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils._train_image_preprocess": [[159, 180], ["tensorflow.image.random_flip_left_right", "tensorflow.clip_by_value", "tensorflow.subtract", "tensorflow.multiply", "utils._make_image_tensor", "numpy.random.randint", "tensorflow.image.random_brightness", "tensorflow.image.random_saturation", "tensorflow.image.random_hue", "tensorflow.image.random_contrast", "tensorflow.image.random_brightness", "tensorflow.image.random_contrast", "tensorflow.image.random_saturation", "tensorflow.image.random_hue"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils._make_image_tensor"], ["", "def", "_train_image_preprocess", "(", "image", ",", "label_tensor", ",", "arr_idx", ")", ":", "\n", "    ", "seed", "=", "12345", "\n", "image", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "image", ",", "seed", "=", "seed", ")", "\n", "\n", "if", "np", ".", "random", ".", "randint", "(", "2", ")", "==", "0", ":", "\n", "        ", "image", "=", "tf", ".", "image", ".", "random_brightness", "(", "image", ",", "max_delta", "=", "32.", "/", "255.", ",", "seed", "=", "seed", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_saturation", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ",", "seed", "=", "seed", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_hue", "(", "image", ",", "max_delta", "=", "0.032", ",", "seed", "=", "seed", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_contrast", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ",", "seed", "=", "seed", ")", "\n", "", "else", ":", "\n", "        ", "image", "=", "tf", ".", "image", ".", "random_brightness", "(", "image", ",", "max_delta", "=", "32.", "/", "255.", ",", "seed", "=", "seed", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_contrast", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ",", "seed", "=", "seed", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_saturation", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ",", "seed", "=", "seed", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_hue", "(", "image", ",", "max_delta", "=", "0.032", ",", "seed", "=", "seed", ")", "\n", "\n", "# Make sure the image is still in [0, 1]", "\n", "", "image", "=", "tf", ".", "clip_by_value", "(", "image", ",", "0.0", ",", "1.0", ")", "\n", "# Convert to [-1, 1]", "\n", "image", "=", "tf", ".", "subtract", "(", "image", ",", "0.5", ")", "\n", "image", "=", "tf", ".", "multiply", "(", "image", ",", "2.0", ")", "\n", "return", "_make_image_tensor", "(", "image", ",", "label_tensor", ",", "arr_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils._eval_image_preprocess": [[182, 189], ["tensorflow.clip_by_value", "tensorflow.subtract", "tensorflow.multiply", "utils._make_image_tensor"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils._make_image_tensor"], ["", "def", "_eval_image_preprocess", "(", "image", ",", "label_tensor", ",", "arr_idx", ")", ":", "\n", "# Make sure the image is still in [0, 1]", "\n", "    ", "image", "=", "tf", ".", "clip_by_value", "(", "image", ",", "0.0", ",", "1.0", ")", "\n", "# Convert to [-1, 1]", "\n", "image", "=", "tf", ".", "subtract", "(", "image", ",", "0.5", ")", "\n", "image", "=", "tf", ".", "multiply", "(", "image", ",", "2.0", ")", "\n", "return", "_make_image_tensor", "(", "image", ",", "label_tensor", ",", "arr_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils._vis_image_preprocess": [[191, 195], ["tensorflow.clip_by_value", "utils._make_image_tensor"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils._make_image_tensor"], ["", "def", "_vis_image_preprocess", "(", "image", ",", "label_tensor", ",", "arr_idx", ")", ":", "\n", "# Make sure the image is still in [0, 1]", "\n", "    ", "image", "=", "tf", ".", "clip_by_value", "(", "image", ",", "0.0", ",", "1.0", ")", "\n", "return", "_make_image_tensor", "(", "image", ",", "label_tensor", ",", "arr_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils._make_image_tensor": [[197, 199], ["tensorflow.reshape"], "function", ["None"], ["", "def", "_make_image_tensor", "(", "image", ",", "label_tensor", ",", "arr_idx", ")", ":", "\n", "    ", "return", "tf", ".", "reshape", "(", "image", ",", "shape", "=", "[", "IMAGE_SIZE", "*", "IMAGE_SIZE", "*", "3", "]", ")", ",", "label_tensor", ",", "arr_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils._parse": [[201, 221], ["tensorflow.parse_single_example", "tensorflow.cast", "utils._parse_function", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.cast", "tensorflow.cast"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils._parse_function"], ["", "def", "_parse", "(", "example_proto", ")", ":", "\n", "    ", "\"\"\"Parses the tfrecord files, returns the image encoding string, the label as int, and idx name of sample\"\"\"", "\n", "features", "=", "{", "\n", "'image/arr_idx'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "int64", ")", ",", "\n", "'image/encoded'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ",", "default_value", "=", "''", ")", "\n", "}", "\n", "\n", "if", "not", "USE_2014_DATA", ":", "\n", "        ", "features", "[", "'image/class/label'", "]", "=", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "int64", ")", "\n", "\n", "", "parsed_features", "=", "tf", ".", "parse_single_example", "(", "example_proto", ",", "features", ")", "\n", "\n", "arr_idx", "=", "tf", ".", "cast", "(", "parsed_features", "[", "'image/arr_idx'", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "if", "USE_2014_DATA", ":", "\n", "        ", "label", "=", "tf", ".", "cast", "(", "0", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "", "else", ":", "\n", "        ", "label", "=", "tf", ".", "cast", "(", "parsed_features", "[", "'image/class/label'", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "", "encoded_image", "=", "parsed_features", "[", "\"image/encoded\"", "]", "\n", "image_scaled", ",", "label_tensor", ",", "arr_idx", "=", "_parse_function", "(", "encoded_image", ",", "label", ",", "arr_idx", ")", "\n", "return", "image_scaled", ",", "label_tensor", ",", "arr_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils._parse_function": [[223, 230], ["tensorflow.image.decode_jpeg", "tensorflow.image.convert_image_dtype", "tensorflow.image.resize_images", "tensorflow.one_hot"], "function", ["None"], ["", "def", "_parse_function", "(", "encoded_image", ",", "label", ",", "arr_idx", ")", ":", "\n", "    ", "image_decoded", "=", "tf", ".", "image", ".", "decode_jpeg", "(", "encoded_image", ",", "channels", "=", "3", ")", "\n", "# This will convert to float values in [0, 1]", "\n", "image_scaled", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "image_decoded", ",", "tf", ".", "float32", ")", "\n", "image_scaled", "=", "tf", ".", "image", ".", "resize_images", "(", "image_scaled", ",", "[", "IMAGE_SIZE", ",", "IMAGE_SIZE", "]", ")", "\n", "label_tensor", "=", "tf", ".", "one_hot", "(", "indices", "=", "label", ",", "depth", "=", "NUM_CLASSES", ",", "dtype", "=", "tf", ".", "int32", ",", "name", "=", "'label_tensor'", ")", "\n", "return", "image_scaled", ",", "label_tensor", ",", "arr_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.get_dataset_iterator_from_tfrecords": [[232, 274], ["tensorflow.contrib.data.TFRecordDataset", "dataset.map.map", "dataset.map.batch", "dataset.map.make_initializable_iterator", "dataset.map.shuffle", "dataset.map.map", "ValueError", "dataset.map.map", "dataset.map.map", "range", "range"], "function", ["None"], ["", "def", "get_dataset_iterator_from_tfrecords", "(", "data_type", ",", "model_type", ",", "batch_size", ",", "vis", "=", "False", ")", ":", "\n", "# ignore unused arg. TODO: Remove model_type arg", "\n", "    ", "_", "=", "model_type", "\n", "train_files_num", "=", "1024", "if", "not", "USE_2014_DATA", "else", "256", "\n", "val_test_files_num", "=", "128", "if", "not", "USE_2014_DATA", "else", "32", "\n", "if", "data_type", "==", "'validation'", "or", "data_type", "==", "'test'", ":", "\n", "        ", "filenames", "=", "[", "\"../tf_data_with_idx%s/%s-%05d-of-00%s%d\"", "\n", "%", "(", "'_2014'", "if", "USE_2014_DATA", "else", "''", ",", "\n", "data_type", ",", "itr", ",", "'0'", "if", "USE_2014_DATA", "else", "''", ",", "\n", "val_test_files_num", ")", "for", "itr", "in", "range", "(", "val_test_files_num", ")", "]", "\n", "", "elif", "data_type", "==", "'train'", ":", "\n", "        ", "filenames", "=", "[", "\"../tf_data_with_idx%s/%s-%05d-of-0%s%d\"", "\n", "%", "(", "'_2014'", "if", "USE_2014_DATA", "else", "''", ",", "\n", "data_type", ",", "itr", ",", "'0'", "if", "USE_2014_DATA", "else", "''", ",", "\n", "train_files_num", ")", "for", "itr", "in", "range", "(", "train_files_num", ")", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Incorrect data_type=%s in parse_tfrecrods\"", "%", "data_type", ")", "\n", "\n", "", "dataset", "=", "tf", ".", "contrib", ".", "data", ".", "TFRecordDataset", "(", "filenames", ")", "\n", "\n", "if", "USE_2014_DATA", ":", "\n", "        ", "buffer_size", "=", "3000", "\n", "", "else", ":", "\n", "        ", "buffer_size", "=", "10000", "\n", "\n", "", "if", "data_type", "==", "'train'", ":", "\n", "        ", "dataset", "=", "dataset", ".", "shuffle", "(", "buffer_size", "=", "buffer_size", ",", "seed", "=", "12345", ")", "\n", "\n", "", "dataset", "=", "dataset", ".", "map", "(", "_parse", ",", "num_threads", "=", "batch_size", ",", "output_buffer_size", "=", "batch_size", "*", "2", ")", "\n", "if", "data_type", "==", "'train'", ":", "\n", "        ", "dataset", "=", "dataset", ".", "map", "(", "_train_image_preprocess", ",", "num_threads", "=", "batch_size", ",", "output_buffer_size", "=", "batch_size", "*", "2", ")", "\n", "", "else", ":", "\n", "        ", "if", "not", "vis", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "_eval_image_preprocess", ",", "num_threads", "=", "batch_size", ",", "output_buffer_size", "=", "batch_size", "*", "2", ")", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "_vis_image_preprocess", ",", "num_threads", "=", "batch_size", ",", "output_buffer_size", "=", "batch_size", "*", "2", ")", "\n", "\n", "", "", "dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "\n", "iterator", "=", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "return", "iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.get_dataset_iterator_from_tfrecords_answerer": [[276, 304], ["tensorflow.contrib.data.TFRecordDataset", "dataset.shuffle.map", "dataset.shuffle.map", "dataset.shuffle.batch", "dataset.shuffle.make_initializable_iterator", "dataset.shuffle.shuffle", "ValueError", "range", "range"], "function", ["None"], ["", "def", "get_dataset_iterator_from_tfrecords_answerer", "(", "data_type", ",", "batch_size", ")", ":", "\n", "    ", "train_files_num", "=", "128", "\n", "val_test_files_num", "=", "16", "\n", "if", "data_type", "==", "'validation'", "or", "data_type", "==", "'test'", ":", "\n", "        ", "filenames", "=", "[", "\"../tf_data_with_idx_answerer/%s-%05d-of-000%d\"", "\n", "%", "(", "data_type", ",", "itr", ",", "val_test_files_num", ")", "for", "itr", "in", "range", "(", "val_test_files_num", ")", "]", "\n", "", "elif", "data_type", "==", "'train'", ":", "\n", "        ", "filenames", "=", "[", "\"../tf_data_with_idx_answerer/%s-%05d-of-00%d\"", "\n", "%", "(", "data_type", ",", "itr", ",", "train_files_num", ")", "for", "itr", "in", "range", "(", "train_files_num", ")", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Incorrect data_type=%s in parse_tfrecrods\"", "%", "data_type", ")", "\n", "\n", "", "dataset", "=", "tf", ".", "contrib", ".", "data", ".", "TFRecordDataset", "(", "filenames", ")", "\n", "\n", "buffer_size", "=", "1500", "\n", "\n", "if", "data_type", "==", "'train'", ":", "\n", "        ", "dataset", "=", "dataset", ".", "shuffle", "(", "buffer_size", "=", "buffer_size", ",", "seed", "=", "12345", ")", "\n", "\n", "", "dataset", "=", "dataset", ".", "map", "(", "_parse", ",", "num_threads", "=", "batch_size", ",", "output_buffer_size", "=", "batch_size", "*", "2", ")", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "_eval_image_preprocess", ",", "num_threads", "=", "batch_size", ",", "output_buffer_size", "=", "batch_size", "*", "2", ")", "\n", "\n", "dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "\n", "iterator", "=", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "return", "iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.get_coco_dataset_iterator_from_tfrecords": [[306, 319], ["tensorflow.contrib.data.TFRecordDataset", "dataset.batch.map", "dataset.batch.map", "dataset.batch.batch", "dataset.batch.make_initializable_iterator", "range"], "function", ["None"], ["", "def", "get_coco_dataset_iterator_from_tfrecords", "(", "batch_size", ")", ":", "\n", "    ", "files_num", "=", "8", "\n", "filenames", "=", "[", "\"../tf_data_with_idx_coco2/coco-0000%d-of-0000%d\"", "%", "(", "itr", ",", "files_num", ")", "for", "itr", "in", "range", "(", "files_num", ")", "]", "\n", "\n", "dataset", "=", "tf", ".", "contrib", ".", "data", ".", "TFRecordDataset", "(", "filenames", ")", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "_parse", ",", "num_threads", "=", "batch_size", ",", "output_buffer_size", "=", "batch_size", "*", "2", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "_eval_image_preprocess", ",", "num_threads", "=", "batch_size", ",", "output_buffer_size", "=", "batch_size", "*", "2", ")", "\n", "\n", "dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "iterator", "=", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "return", "iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.longest": [[321, 323], ["max", "len"], "function", ["None"], ["", "def", "longest", "(", "input_list", ")", ":", "\n", "    ", "return", "max", "(", "len", "(", "element", ")", "for", "element", "in", "input_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.resize_input": [[325, 327], ["global_hyperparams.TEXT_LENTH", "global_hyperparams.TEXT_LENTH", "global_hyperparams.TEXT_LENTH", "global_hyperparams.TEXT_LENTH"], "function", ["None"], ["", "def", "resize_input", "(", "np_array", ",", "size", ")", ":", "\n", "    ", "return", "np_array", "[", ":", ",", ":", "size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.text_batch_generator": [[329, 339], ["numpy.random.permutation", "xrange", "range", "len", "len", "batch_text.append", "batch_labels.append", "numpy.asarray", "numpy.asarray"], "function", ["None"], ["", "def", "text_batch_generator", "(", "batch_size", ",", "text_data", ",", "label_data", ")", ":", "\n", "    ", "indices", "=", "np", ".", "random", ".", "permutation", "(", "range", "(", "len", "(", "text_data", ")", ")", ")", "\n", "for", "i", "in", "xrange", "(", "0", ",", "len", "(", "text_data", ")", ",", "batch_size", ")", ":", "\n", "        ", "ind", "=", "indices", "[", "i", ":", "i", "+", "batch_size", "]", "\n", "batch_text", "=", "[", "]", "\n", "batch_labels", "=", "[", "]", "\n", "for", "j", "in", "ind", ":", "\n", "            ", "batch_text", ".", "append", "(", "text_data", "[", "j", "]", ")", "\n", "batch_labels", ".", "append", "(", "label_data", "[", "j", "]", ")", "\n", "", "yield", "np", ".", "asarray", "(", "batch_text", ")", ",", "np", ".", "asarray", "(", "batch_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.text_batch_from_ids": [[341, 343], ["numpy.asarray"], "function", ["None"], ["", "", "def", "text_batch_from_ids", "(", "ids", ",", "text_data", ")", ":", "\n", "    ", "return", "np", ".", "asarray", "(", "text_data", "[", "ids", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.batch_norm": [[345, 362], ["tensorflow.variable_scope", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.nn.moments", "tensorflow.train.ExponentialMovingAverage", "tensorflow.cond", "tensorflow.nn.batch_normalization", "tensorflow.constant", "tensorflow.constant", "tf.train.ExponentialMovingAverage.apply", "tensorflow.control_dependencies", "tensorflow.identity", "tensorflow.identity", "tf.train.ExponentialMovingAverage.average", "tf.train.ExponentialMovingAverage.average"], "function", ["None"], ["", "def", "batch_norm", "(", "x", ",", "n_out", ",", "phase_train", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'bn'", ")", ":", "\n", "        ", "beta", "=", "tf", ".", "Variable", "(", "tf", ".", "constant", "(", "0.0", ",", "shape", "=", "[", "n_out", "]", ")", ",", "name", "=", "'beta'", ",", "trainable", "=", "True", ")", "\n", "gamma", "=", "tf", ".", "Variable", "(", "tf", ".", "constant", "(", "1.0", ",", "shape", "=", "[", "n_out", "]", ")", ",", "name", "=", "'gamma'", ",", "trainable", "=", "True", ")", "\n", "batch_mean", ",", "batch_var", "=", "tf", ".", "nn", ".", "moments", "(", "x", ",", "[", "0", ",", "1", ",", "2", "]", ",", "name", "=", "'moments'", ")", "\n", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "0.5", ")", "\n", "\n", "def", "mean_var_with_update", "(", ")", ":", "\n", "            ", "ema_apply_op", "=", "ema", ".", "apply", "(", "[", "batch_mean", ",", "batch_var", "]", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "ema_apply_op", "]", ")", ":", "\n", "                ", "return", "tf", ".", "identity", "(", "batch_mean", ")", ",", "tf", ".", "identity", "(", "batch_var", ")", "\n", "\n", "", "", "mean", ",", "var", "=", "tf", ".", "cond", "(", "phase_train", ",", "\n", "mean_var_with_update", ",", "\n", "lambda", ":", "(", "ema", ".", "average", "(", "batch_mean", ")", ",", "ema", ".", "average", "(", "batch_var", ")", ")", ")", "\n", "normed", "=", "tf", ".", "nn", ".", "batch_normalization", "(", "x", ",", "mean", ",", "var", ",", "beta", ",", "gamma", ",", "1e-5", ")", "\n", "", "return", "normed", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.mono_init": [[364, 369], ["numpy.zeros", "range"], "function", ["None"], ["", "def", "mono_init", "(", "img", ",", "img_size", ")", ":", "\n", "    ", "new_img", "=", "np", ".", "zeros", "(", "(", "img_size", ",", "img_size", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "        ", "new_img", "[", ":", ",", ":", ",", "i", "]", "=", "img", "\n", "", "return", "new_img", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.la_init": [[371, 376], ["numpy.zeros", "range"], "function", ["None"], ["", "def", "la_init", "(", "img", ",", "img_size", ")", ":", "\n", "    ", "new_img", "=", "np", ".", "zeros", "(", "(", "img_size", ",", "img_size", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "        ", "new_img", "[", ":", ",", ":", ",", "i", "]", "=", "img", "[", ":", ",", ":", ",", "0", "]", "\n", "", "return", "new_img", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.image_reader": [[378, 400], ["range", "numpy.asarray", "len", "len", "numpy.array", "la_init.reshape", "str", "numpy.array", "len", "utils.mono_init", "PIL.Image.open().resize", "print", "sys.exit", "utils.la_init", "PIL.Image.open"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.mono_init", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.la_init"], ["", "def", "image_reader", "(", "data_dir", ",", "name_list", ",", "image_size", ")", ":", "\n", "    ", "Image", ".", "MAX_IMAGE_PIXELS", "=", "None", "\n", "return_image", "=", "[", "None", "]", "*", "len", "(", "name_list", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "name_list", ")", ")", ":", "\n", "        ", "file_name", "=", "str", "(", "name_list", "[", "i", "]", ")", "+", "\".jpg\"", "\n", "try", ":", "\n", "            ", "img", "=", "np", ".", "array", "(", "Image", ".", "open", "(", "data_dir", "+", "file_name", ",", "\"r\"", ")", ".", "resize", "(", "(", "image_size", ",", "image_size", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "except", "AttributeError", "as", "e", ":", "\n", "            ", "print", "(", "\"Encountered exception while reading images:\"", ",", "e", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n", "", "img", "=", "np", ".", "array", "(", "img", "/", "255.0", ")", "\n", "if", "len", "(", "img", ".", "shape", ")", "!=", "3", ":", "\n", "            ", "img", "=", "mono_init", "(", "img", ",", "image_size", ")", "\n", "", "if", "img", ".", "shape", "[", "2", "]", "==", "4", ":", "\n", "            ", "img", "=", "img", "[", ":", ",", ":", ",", ":", "3", "]", "\n", "", "elif", "img", ".", "shape", "[", "2", "]", "==", "2", ":", "\n", "            ", "img", "=", "la_init", "(", "img", ",", "image_size", ")", "\n", "", "img", "=", "img", ".", "reshape", "(", "image_size", "*", "image_size", "*", "3", ")", "\n", "return_image", "[", "i", "]", "=", "img", "\n", "", "return_image", "=", "np", ".", "asarray", "(", "return_image", ")", "\n", "return", "return_image", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.image_batch_generator": [[402, 414], ["numpy.random.permutation", "range", "range", "len", "utils.image_reader", "len", "batch_name.append", "batch_labels.append", "numpy.asarray", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.image_reader"], ["", "def", "image_batch_generator", "(", "images_directory", ",", "batch_size", ",", "name_data", ",", "label_data", ",", "image_size", "=", "128", ")", ":", "\n", "    ", "indices", "=", "np", ".", "random", ".", "permutation", "(", "range", "(", "len", "(", "name_data", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "name_data", ")", ",", "batch_size", ")", ":", "\n", "        ", "ind", "=", "indices", "[", "i", ":", "i", "+", "batch_size", "]", "\n", "batch_name", "=", "[", "]", "\n", "batch_labels", "=", "[", "]", "\n", "for", "j", "in", "ind", ":", "\n", "            ", "batch_name", ".", "append", "(", "name_data", "[", "j", "]", ")", "\n", "batch_labels", ".", "append", "(", "label_data", "[", "j", "]", ")", "\n", "", "batch_image", "=", "image_reader", "(", "images_directory", ",", "\n", "batch_name", ",", "image_size", ")", "\n", "yield", "np", ".", "asarray", "(", "batch_image", ")", ",", "np", ".", "asarray", "(", "batch_labels", ")", ",", "ind", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.update_train_batch": [[416, 428], ["train_writer.add_summary", "utils._print_batch_stats", "print", "float"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils._print_batch_stats"], ["", "", "def", "update_train_batch", "(", "global_step", ",", "S", ",", "loss_val", ",", "acc_val", ",", "train_writer", ",", "total_epoch_acc_val", ",", "\n", "batches_completed_this_epoch", ")", ":", "\n", "# S: train_summary", "\n", "    ", "total_epoch_acc_val", "+=", "acc_val", "\n", "if", "global_step", "%", "20", "==", "0", ":", "\n", "        ", "_print_batch_stats", "(", "global_step", ",", "loss_val", ",", "acc_val", ")", "\n", "if", "global_step", "%", "100", "==", "0", ":", "\n", "            ", "print", "(", "\"Training accuracy till mini-batch %d: %0.4f\"", "%", "\n", "(", "batches_completed_this_epoch", ",", "total_epoch_acc_val", "/", "float", "(", "batches_completed_this_epoch", ")", ")", ")", "\n", "", "", "train_writer", ".", "add_summary", "(", "S", ",", "global_step", ")", "\n", "global_step", "+=", "1", "\n", "return", "global_step", ",", "total_epoch_acc_val", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.update_val_batch": [[430, 436], ["print"], "function", ["None"], ["", "def", "update_val_batch", "(", "num_steps", ",", "val_acc", ",", "val_acc_sum", ",", "total_batches", ")", ":", "\n", "    ", "val_acc_sum", "+=", "val_acc", "\n", "num_steps", "+=", "1", "\n", "if", "num_steps", "%", "50", "==", "0", ":", "\n", "        ", "print", "(", "\"Completed %d validation batches of %d batches\"", "%", "(", "num_steps", ",", "total_batches", ")", ")", "\n", "", "return", "val_acc_sum", ",", "num_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.update_test_batch": [[438, 451], ["numpy.vstack", "print"], "function", ["None"], ["", "def", "update_test_batch", "(", "batch_num", ",", "pred", ",", "mat", ",", "test_acc", ",", "conf_matrix", ",", "prediction", ",", "test_accuracy", ",", "total_batches", ")", ":", "\n", "    ", "if", "batch_num", "==", "0", ":", "\n", "        ", "new_conf_matrix", "=", "mat", "\n", "new_prediction", "=", "pred", "\n", "", "else", ":", "\n", "        ", "if", "batch_num", "%", "50", "==", "0", ":", "\n", "            ", "print", "(", "\"Completed %d test batches of %d batches\"", "%", "(", "batch_num", ",", "total_batches", ")", ")", "\n", "", "new_conf_matrix", "=", "conf_matrix", "+", "mat", "\n", "new_prediction", "=", "np", ".", "vstack", "(", "(", "prediction", ",", "pred", ")", ")", "\n", "\n", "", "new_test_accuracy", "=", "test_accuracy", "+", "test_acc", "\n", "\n", "return", "new_conf_matrix", ",", "new_prediction", ",", "new_test_accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.training_epoch_finish_routine": [[453, 463], ["os.mkdir", "saver.save", "print", "float", "open", "handle.write", "handle.flush", "str", "str", "str"], "function", ["None"], ["", "def", "training_epoch_finish_routine", "(", "sess", ",", "val_acc_sum", ",", "num_samples", ",", "train_logfile_name", ",", "checkpoint_dir", ",", "epoch", ",", "saver", ")", ":", "\n", "    ", "val_acc", "=", "val_acc_sum", "/", "float", "(", "num_samples", ")", "\n", "with", "open", "(", "train_logfile_name", ",", "\"a+\"", ")", "as", "handle", ":", "\n", "        ", "handle", ".", "write", "(", "\"validation\\t\"", "+", "str", "(", "val_acc", ")", "+", "\"\\n\"", ")", "\n", "handle", ".", "flush", "(", ")", "\n", "\n", "", "os", ".", "mkdir", "(", "checkpoint_dir", "+", "str", "(", "epoch", ")", "+", "'epoch'", ")", "\n", "_", "=", "saver", ".", "save", "(", "sess", ",", "checkpoint_dir", "+", "str", "(", "epoch", ")", "+", "'epoch/model.ckpt'", ")", "\n", "\n", "print", "(", "\"\\nCompleted training epoch number %d with Validation Accuracy %0.4f\"", "%", "(", "epoch", "+", "1", ",", "val_acc", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils.test_finish_routine": [[465, 470], ["print", "numpy.argmax", "numpy.argmax"], "function", ["None"], ["", "def", "test_finish_routine", "(", "test_labels", ",", "prediction", ")", ":", "\n", "    ", "print", "(", "\"\\nCompleted test data evaluation.\"", ")", "\n", "labels", "=", "np", ".", "argmax", "(", "test_labels", ",", "1", ")", "\n", "results", "=", "np", ".", "argmax", "(", "prediction", ",", "1", ")", "\n", "return", "labels", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.utils._print_batch_stats": [[472, 475], ["datetime.datetime.now().strftime", "print", "datetime.datetime.now"], "function", ["None"], ["", "def", "_print_batch_stats", "(", "global_step", ",", "loss_val", ",", "acc_val", ")", ":", "\n", "    ", "time_str", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%y%m%d%H%M'", ")", "\n", "print", "(", "\"{}: step {:5d}, loss {:8.6f}, acc {:6.4f}\"", ".", "format", "(", "time_str", ",", "global_step", ",", "loss_val", ",", "acc_val", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2.inference": [[39, 110], ["config.Config", "tensorflow.convert_to_tensor", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.variable_scope", "resnet2.conv", "resnet2.bn_no_train", "activation", "tensorflow.variable_scope", "resnet2._max_pool", "resnet2.stack", "tensorflow.variable_scope", "resnet2.stack", "tensorflow.variable_scope", "resnet2.stack", "tensorflow.variable_scope", "resnet2.stack"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2.bn_no_train", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet._max_pool", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.stack", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.stack", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.stack", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.stack"], ["def", "inference", "(", "x", ",", "is_training", ",", "\n", "num_classes", "=", "1000", ",", "\n", "num_blocks", "=", "None", ",", "# defaults to 50-layer network", "\n", "use_bias", "=", "False", ",", "# defaults to using batch norm", "\n", "bottleneck", "=", "True", ",", "\n", "train_last_block", "=", "False", ")", ":", "\n", "    ", "if", "num_blocks", "is", "None", ":", "\n", "        ", "num_blocks", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", "\n", "", "c", "=", "Config", "(", ")", "\n", "c", "[", "'bottleneck'", "]", "=", "bottleneck", "\n", "c", "[", "'is_training'", "]", "=", "tf", ".", "convert_to_tensor", "(", "is_training", ",", "\n", "dtype", "=", "'bool'", ",", "\n", "name", "=", "'is_training'", ")", "\n", "c", "[", "'ksize'", "]", "=", "3", "\n", "c", "[", "'stride'", "]", "=", "1", "\n", "c", "[", "'use_bias'", "]", "=", "use_bias", "\n", "c", "[", "'fc_units_out'", "]", "=", "num_classes", "\n", "c", "[", "'num_blocks'", "]", "=", "num_blocks", "\n", "c", "[", "'stack_stride'", "]", "=", "2", "\n", "\n", "image_size", "=", "tf", ".", "app", ".", "flags", ".", "FLAGS", ".", "input_size", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", ",", "image_size", ",", "image_size", ",", "3", "]", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'scale1'", ")", ":", "\n", "        ", "c", "[", "'conv_filters_out'", "]", "=", "64", "\n", "c", "[", "'ksize'", "]", "=", "7", "\n", "c", "[", "'stride'", "]", "=", "2", "\n", "x", "=", "conv", "(", "x", ",", "c", ")", "\n", "x", "=", "bn_no_train", "(", "x", ",", "c", ")", "\n", "x", "=", "activation", "(", "x", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'scale2'", ")", ":", "\n", "        ", "x", "=", "_max_pool", "(", "x", ",", "ksize", "=", "3", ",", "stride", "=", "2", ")", "\n", "c", "[", "'num_blocks'", "]", "=", "num_blocks", "[", "0", "]", "\n", "c", "[", "'stack_stride'", "]", "=", "1", "\n", "c", "[", "'block_filters_internal'", "]", "=", "64", "\n", "x", "=", "stack", "(", "x", ",", "c", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'scale3'", ")", ":", "\n", "        ", "c", "[", "'num_blocks'", "]", "=", "num_blocks", "[", "1", "]", "\n", "c", "[", "'block_filters_internal'", "]", "=", "128", "\n", "assert", "c", "[", "'stack_stride'", "]", "==", "2", "\n", "x", "=", "stack", "(", "x", ",", "c", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'scale4'", ")", ":", "\n", "        ", "c", "[", "'num_blocks'", "]", "=", "num_blocks", "[", "2", "]", "\n", "c", "[", "'block_filters_internal'", "]", "=", "256", "\n", "x", "=", "stack", "(", "x", ",", "c", ")", "\n", "\n", "", "representation_one_block_before", "=", "x", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'scale5'", ")", ":", "\n", "        ", "c", "[", "'num_blocks'", "]", "=", "num_blocks", "[", "3", "]", "\n", "c", "[", "'block_filters_internal'", "]", "=", "512", "\n", "x", "=", "stack", "(", "x", ",", "c", ",", "conv_training", "=", "train_last_block", ",", "is_training", "=", "is_training", ")", "\n", "\n", "", "my_represnetation", "=", "x", "\n", "\n", "# post-net", "\n", "x", "=", "tf", ".", "reduce_mean", "(", "x", ",", "reduction_indices", "=", "[", "1", ",", "2", "]", ",", "name", "=", "\"avg_pool\"", ")", "\n", "\n", "# Use vectors after average pooling as representation vectors", "\n", "representation", "=", "x", "\n", "# print(\"Representaion:\", representation)", "\n", "\n", "# NEVER NEED THIS", "\n", "# if (num_classes is not None):", "\n", "#     with tf.variable_scope('fc'):", "\n", "#         x = fc(x, c)", "\n", "\n", "return", "None", ",", "representation", ",", "my_represnetation", ",", "representation_one_block_before", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2._imagenet_preprocess": [[162, 168], ["tensorflow.split", "tensorflow.concat"], "function", ["None"], ["", "def", "_imagenet_preprocess", "(", "rgb", ")", ":", "\n", "    ", "\"\"\"Changes RGB [0,1] valued image to BGR [0,255] with mean subtracted.\"\"\"", "\n", "red", ",", "green", ",", "blue", "=", "tf", ".", "split", "(", "3", ",", "3", ",", "rgb", "*", "255.0", ")", "\n", "bgr", "=", "tf", ".", "concat", "(", "3", ",", "[", "blue", ",", "green", ",", "red", "]", ")", "\n", "bgr", "-=", "IMAGENET_MEAN_BGR", "\n", "return", "bgr", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2.loss": [[170, 181], ["tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.get_collection", "tensorflow.add_n", "tensorflow.scalar_summary"], "function", ["None"], ["", "def", "loss", "(", "logits", ",", "labels", ")", ":", "\n", "    ", "cross_entropy", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", ",", "labels", ")", "\n", "cross_entropy_mean", "=", "tf", ".", "reduce_mean", "(", "cross_entropy", ")", "\n", "\n", "regularization_losses", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", "\n", "\n", "loss_", "=", "tf", ".", "add_n", "(", "[", "cross_entropy_mean", "]", "+", "regularization_losses", ")", "\n", "# noinspection PyUnresolvedReferences", "\n", "tf", ".", "scalar_summary", "(", "'loss'", ",", "loss_", ")", "\n", "\n", "return", "loss_", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2.stack": [[183, 190], ["range", "tensorflow.variable_scope", "resnet2.block"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.block"], ["", "def", "stack", "(", "x", ",", "c", ",", "conv_training", "=", "False", ",", "is_training", "=", "TF_FALSE", ")", ":", "\n", "    ", "for", "n", "in", "range", "(", "c", "[", "'num_blocks'", "]", ")", ":", "\n", "        ", "s", "=", "c", "[", "'stack_stride'", "]", "if", "n", "==", "0", "else", "1", "\n", "c", "[", "'block_stride'", "]", "=", "s", "\n", "with", "tf", ".", "variable_scope", "(", "'block%d'", "%", "(", "n", "+", "1", ")", ")", ":", "\n", "            ", "x", "=", "block", "(", "x", ",", "c", ",", "conv_training", "=", "conv_training", ",", "is_training", "=", "is_training", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2.block": [[192, 270], ["activation", "bn_no_train.get_shape", "tensorflow.variable_scope", "tensorflow.variable_scope", "resnet2.conv", "activation", "tensorflow.variable_scope", "resnet2.conv", "activation", "tensorflow.variable_scope", "resnet2.conv", "tensorflow.variable_scope", "resnet2.conv", "activation", "tensorflow.variable_scope", "resnet2.conv", "resnet2.conv", "resnet2.bn", "resnet2.bn_no_train", "resnet2.bn", "resnet2.bn_no_train", "resnet2.bn", "resnet2.bn_no_train", "resnet2.bn", "resnet2.bn_no_train", "resnet2.bn", "resnet2.bn_no_train", "resnet2.bn", "resnet2.bn_no_train"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.bn", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2.bn_no_train", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.bn", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2.bn_no_train", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.bn", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2.bn_no_train", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.bn", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2.bn_no_train", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.bn", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2.bn_no_train", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.bn", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2.bn_no_train"], ["", "def", "block", "(", "x", ",", "c", ",", "conv_training", ",", "is_training", ")", ":", "\n", "    ", "filters_in", "=", "x", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "\n", "# Note: filters_out isn't how many filters are outputed.", "\n", "# That is the case when bottleneck=False but when bottleneck is", "\n", "# True, filters_internal*4 filters are outputted. filters_internal is how many filters", "\n", "# the 3x3 convs output internally.", "\n", "m", "=", "4", "if", "c", "[", "'bottleneck'", "]", "else", "1", "\n", "filters_out", "=", "m", "*", "c", "[", "'block_filters_internal'", "]", "\n", "\n", "shortcut", "=", "x", "# branch 1", "\n", "\n", "c", "[", "'conv_filters_out'", "]", "=", "c", "[", "'block_filters_internal'", "]", "\n", "\n", "# tf.convert_to_tensor(is_training,", "\n", "#                      dtype='bool',", "\n", "#                      name='is_training')", "\n", "if", "c", "[", "'bottleneck'", "]", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'a'", ")", ":", "\n", "            ", "c", "[", "'ksize'", "]", "=", "1", "\n", "c", "[", "'stride'", "]", "=", "c", "[", "'block_stride'", "]", "\n", "x", "=", "conv", "(", "x", ",", "c", ",", "is_training", "=", "conv_training", ")", "\n", "if", "conv_training", ":", "\n", "                ", "x", "=", "bn", "(", "x", ",", "c", ",", "is_training", "=", "is_training", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "bn_no_train", "(", "x", ",", "c", ")", "\n", "", "x", "=", "activation", "(", "x", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'b'", ")", ":", "\n", "            ", "x", "=", "conv", "(", "x", ",", "c", ",", "is_training", "=", "conv_training", ")", "\n", "if", "conv_training", ":", "\n", "                ", "x", "=", "bn", "(", "x", ",", "c", ",", "is_training", "=", "is_training", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "bn_no_train", "(", "x", ",", "c", ")", "\n", "", "x", "=", "activation", "(", "x", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'c'", ")", ":", "\n", "            ", "c", "[", "'conv_filters_out'", "]", "=", "filters_out", "\n", "c", "[", "'ksize'", "]", "=", "1", "\n", "assert", "c", "[", "'stride'", "]", "==", "1", "\n", "x", "=", "conv", "(", "x", ",", "c", ",", "is_training", "=", "conv_training", ")", "\n", "if", "conv_training", ":", "\n", "                ", "x", "=", "bn", "(", "x", ",", "c", ",", "is_training", "=", "is_training", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "bn_no_train", "(", "x", ",", "c", ")", "\n", "", "", "", "else", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'A'", ")", ":", "\n", "            ", "c", "[", "'stride'", "]", "=", "c", "[", "'block_stride'", "]", "\n", "assert", "c", "[", "'ksize'", "]", "==", "3", "\n", "x", "=", "conv", "(", "x", ",", "c", ",", "is_training", "=", "conv_training", ")", "\n", "if", "conv_training", ":", "\n", "                ", "x", "=", "bn", "(", "x", ",", "c", ",", "is_training", "=", "is_training", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "bn_no_train", "(", "x", ",", "c", ")", "\n", "", "x", "=", "activation", "(", "x", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'B'", ")", ":", "\n", "            ", "c", "[", "'conv_filters_out'", "]", "=", "filters_out", "\n", "assert", "c", "[", "'ksize'", "]", "==", "3", "\n", "assert", "c", "[", "'stride'", "]", "==", "1", "\n", "x", "=", "conv", "(", "x", ",", "c", ",", "is_training", "=", "conv_training", ")", "\n", "if", "conv_training", ":", "\n", "                ", "x", "=", "bn", "(", "x", ",", "c", ",", "is_training", "=", "is_training", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "bn_no_train", "(", "x", ",", "c", ")", "\n", "\n", "", "", "", "with", "tf", ".", "variable_scope", "(", "'shortcut'", ")", ":", "\n", "        ", "if", "filters_out", "!=", "filters_in", "or", "c", "[", "'block_stride'", "]", "!=", "1", ":", "\n", "            ", "c", "[", "'ksize'", "]", "=", "1", "\n", "c", "[", "'stride'", "]", "=", "c", "[", "'block_stride'", "]", "\n", "c", "[", "'conv_filters_out'", "]", "=", "filters_out", "\n", "shortcut", "=", "conv", "(", "shortcut", ",", "c", ",", "is_training", "=", "conv_training", ")", "\n", "if", "conv_training", ":", "\n", "                ", "shortcut", "=", "bn", "(", "shortcut", ",", "c", ",", "is_training", "=", "is_training", ")", "\n", "", "else", ":", "\n", "                ", "shortcut", "=", "bn_no_train", "(", "shortcut", ",", "c", ")", "\n", "\n", "", "", "", "return", "activation", "(", "x", "+", "shortcut", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2.bn": [[320, 369], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.cond", "tensorflow.nn.moments", "tensorflow.assign", "tensorflow.assign", "tensorflow.nn.batch_normalization", "x.get_shape().as_list", "tensorflow.control_dependencies", "tensorflow.nn.batch_normalization", "tensorflow.truncated_normal_initializer", "tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "x.get_shape"], "function", ["None"], ["", "def", "bn", "(", "x", ",", "c", ",", "is_training", ")", ":", "\n", "# x_shape = x.get_shape()", "\n", "# params_shape = x_shape[-1:]", "\n", "# if c['use_bias']:", "\n", "#     bias = _get_variable('bias', params_shape,", "\n", "#                          initializer=tf.zeros_initializer)", "\n", "#     return x + bias", "\n", "\n", "    ", "def", "bn_train", "(", ")", ":", "\n", "        ", "batch_mean", ",", "batch_var", "=", "tf", ".", "nn", ".", "moments", "(", "x", ",", "axes", "=", "[", "0", ",", "1", ",", "2", "]", ")", "\n", "train_mean", "=", "tf", ".", "assign", "(", "\n", "pop_mean", ",", "pop_mean", "*", "BN_DECAY", "+", "batch_mean", "*", "(", "1", "-", "BN_DECAY", ")", ")", "\n", "train_var", "=", "tf", ".", "assign", "(", "\n", "pop_var", ",", "pop_var", "*", "BN_DECAY", "+", "batch_var", "*", "(", "1", "-", "BN_DECAY", ")", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "train_mean", ",", "train_var", "]", ")", ":", "\n", "            ", "return", "tf", ".", "nn", ".", "batch_normalization", "(", "\n", "x", ",", "batch_mean", ",", "batch_var", ",", "beta", ",", "gamma", ",", "BN_EPSILON", ")", "\n", "\n", "", "", "def", "bn_inference", "(", ")", ":", "\n", "        ", "return", "tf", ".", "nn", ".", "batch_normalization", "(", "\n", "x", ",", "pop_mean", ",", "pop_var", ",", "beta", ",", "gamma", ",", "BN_EPSILON", ")", "\n", "\n", "", "dim", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "beta", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "'beta'", ",", "\n", "shape", "=", "[", "dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.0", ")", "\n", ")", "\n", "gamma", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "'gamma'", ",", "\n", "shape", "=", "[", "dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.1", ")", "\n", ")", "\n", "pop_mean", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "'moving_mean'", ",", "\n", "shape", "=", "[", "dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "pop_var", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "'moving_variance'", ",", "\n", "shape", "=", "[", "dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "\n", "return", "tf", ".", "cond", "(", "is_training", ",", "bn_train", ",", "bn_inference", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2.bn_no_train": [[370, 422], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "resnet2.bn.bn_inference"], "function", ["None"], ["", "def", "bn_no_train", "(", "x", ",", "c", ")", ":", "\n", "# x_shape = x.get_shape()", "\n", "# params_shape = x_shape[-1:]", "\n", "# if c['use_bias']:", "\n", "#     bias = _get_variable('bias', params_shape,", "\n", "#                          initializer=tf.zeros_initializer)", "\n", "#     return x + bias", "\n", "\n", "# def bn_train():", "\n", "#     batch_mean, batch_var = tf.nn.moments(x, axes=[0, 1, 2])", "\n", "#     train_mean = tf.assign(", "\n", "#         pop_mean, pop_mean * BN_DECAY + batch_mean * (1 - BN_DECAY))", "\n", "#     train_var = tf.assign(", "\n", "#         pop_var, pop_var * BN_DECAY + batch_var * (1 - BN_DECAY))", "\n", "#     with tf.control_dependencies([train_mean, train_var]):", "\n", "#         return tf.nn.batch_normalization(", "\n", "#             x, batch_mean, batch_var, beta, gamma, BN_EPSILON)", "\n", "\n", "    ", "def", "bn_inference", "(", ")", ":", "\n", "        ", "return", "tf", ".", "nn", ".", "batch_normalization", "(", "\n", "x", ",", "pop_mean", ",", "pop_var", ",", "beta", ",", "gamma", ",", "BN_EPSILON", ")", "\n", "\n", "", "dim", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "\n", "beta", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "'beta'", ",", "\n", "shape", "=", "[", "dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.0", ")", ",", "\n", "trainable", "=", "False", "\n", ")", "\n", "gamma", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "'gamma'", ",", "\n", "shape", "=", "[", "dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.1", ")", ",", "\n", "trainable", "=", "False", "\n", ")", "\n", "pop_mean", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "'moving_mean'", ",", "\n", "shape", "=", "[", "dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "pop_var", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "'moving_variance'", ",", "\n", "shape", "=", "[", "dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "\n", "return", "bn_inference", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2._get_variable": [[441, 462], ["tensorflow.get_variable", "tensorflow.contrib.layers.l2_regularizer"], "function", ["None"], ["", "def", "_get_variable", "(", "name", ",", "\n", "shape", ",", "\n", "initializer", ",", "\n", "weight_decay", "=", "0.0", ",", "\n", "dtype", "=", "'float'", ",", "\n", "trainable", "=", "True", ")", ":", "\n", "    ", "\"A little wrapper around tf.get_variable to do weight decay and add to\"", "\n", "\"resnet collection\"", "\n", "if", "weight_decay", ">", "0", ":", "\n", "        ", "regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "weight_decay", ")", "\n", "", "else", ":", "\n", "        ", "regularizer", "=", "None", "\n", "", "collections", "=", "[", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "RESNET_VARIABLES", "]", "\n", "\n", "return", "tf", ".", "get_variable", "(", "name", ",", "\n", "shape", "=", "shape", ",", "\n", "initializer", "=", "initializer", ",", "\n", "dtype", "=", "dtype", ",", "\n", "regularizer", "=", "regularizer", ",", "\n", "collections", "=", "collections", ",", "\n", "trainable", "=", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2.conv": [[464, 479], ["tensorflow.truncated_normal_initializer", "resnet2._get_variable", "tensorflow.nn.conv2d", "x.get_shape"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet._get_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d"], ["", "def", "conv", "(", "x", ",", "c", ",", "is_training", "=", "False", ")", ":", "\n", "    ", "ksize", "=", "c", "[", "'ksize'", "]", "\n", "stride", "=", "c", "[", "'stride'", "]", "\n", "filters_out", "=", "c", "[", "'conv_filters_out'", "]", "\n", "\n", "filters_in", "=", "x", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "shape", "=", "[", "ksize", ",", "ksize", ",", "filters_in", ",", "filters_out", "]", "\n", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "CONV_WEIGHT_STDDEV", ")", "\n", "weights", "=", "_get_variable", "(", "'weights'", ",", "\n", "shape", "=", "shape", ",", "\n", "dtype", "=", "'float'", ",", "\n", "initializer", "=", "initializer", ",", "\n", "weight_decay", "=", "CONV_WEIGHT_DECAY", ",", "\n", "trainable", "=", "is_training", ")", "\n", "return", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "weights", ",", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet2._max_pool": [[481, 486], ["tensorflow.nn.max_pool"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.max_pool"], ["", "def", "_max_pool", "(", "x", ",", "ksize", "=", "3", ",", "stride", "=", "2", ")", ":", "\n", "    ", "return", "tf", ".", "nn", ".", "max_pool", "(", "x", ",", "\n", "ksize", "=", "[", "1", ",", "ksize", ",", "ksize", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", ",", "\n", "padding", "=", "'SAME'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__init__": [[8, 13], ["config.Config.Scope", "FLAGS.__dict__[].iteritems"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.iteritems"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "root", "=", "self", ".", "Scope", "(", "''", ")", "\n", "for", "k", ",", "v", "in", "FLAGS", ".", "__dict__", "[", "'__flags'", "]", ".", "iteritems", "(", ")", ":", "\n", "            ", "root", "[", "k", "]", "=", "v", "\n", "", "self", ".", "stack", "=", "[", "root", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.iteritems": [[14, 16], ["config.Config.to_dict().iteritems", "config.Config.to_dict"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.iteritems", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.to_dict"], ["", "def", "iteritems", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "to_dict", "(", ")", ".", "iteritems", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.to_dict": [[17, 27], ["config.Config._pop_stale", "range", "len"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config._pop_stale"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "self", ".", "_pop_stale", "(", ")", "\n", "out", "=", "{", "}", "\n", "# Work backwards from the flags to top fo the stack", "\n", "# overwriting keys that were found earlier.", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "stack", ")", ")", ":", "\n", "            ", "cs", "=", "self", ".", "stack", "[", "-", "i", "]", "\n", "for", "name", "in", "cs", ":", "\n", "                ", "out", "[", "name", "]", "=", "cs", "[", "name", "]", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config._pop_stale": [[28, 35], ["tensorflow.get_variable_scope", "top.contains", "config.Config.stack.pop"], "methods", ["None"], ["", "def", "_pop_stale", "(", "self", ")", ":", "\n", "        ", "var_scope_name", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "top", "=", "self", ".", "stack", "[", "0", "]", "\n", "while", "not", "top", ".", "contains", "(", "var_scope_name", ")", ":", "\n", "# We aren't in this scope anymore", "\n", "            ", "self", ".", "stack", ".", "pop", "(", "0", ")", "\n", "top", "=", "self", ".", "stack", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__getitem__": [[36, 45], ["config.Config._pop_stale", "range", "KeyError", "len"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config._pop_stale"], ["", "", "def", "__getitem__", "(", "self", ",", "name", ")", ":", "\n", "        ", "self", ".", "_pop_stale", "(", ")", "\n", "# Recursively extract value", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "stack", ")", ")", ":", "\n", "            ", "cs", "=", "self", ".", "stack", "[", "i", "]", "\n", "if", "name", "in", "cs", ":", "\n", "                ", "return", "cs", "[", "name", "]", "\n", "\n", "", "", "raise", "KeyError", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.set_default": [[46, 49], ["None"], "methods", ["None"], ["", "def", "set_default", "(", "self", ",", "name", ",", "value", ")", ":", "\n", "        ", "if", "not", "name", "in", "self", ":", "\n", "            ", "self", "[", "name", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__contains__": [[50, 57], ["config.Config._pop_stale", "range", "len"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config._pop_stale"], ["", "", "def", "__contains__", "(", "self", ",", "name", ")", ":", "\n", "        ", "self", ".", "_pop_stale", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "stack", ")", ")", ":", "\n", "            ", "cs", "=", "self", ".", "stack", "[", "i", "]", "\n", "if", "name", "in", "cs", ":", "\n", "                ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config.__setitem__": [[58, 69], ["config.Config._pop_stale", "config.Config.contains", "tensorflow.get_variable_scope", "config.Config.Scope", "config.Config.stack.insert"], "methods", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.config.Config._pop_stale"], ["", "def", "__setitem__", "(", "self", ",", "name", ",", "value", ")", ":", "\n", "        ", "self", ".", "_pop_stale", "(", ")", "\n", "top", "=", "self", ".", "stack", "[", "0", "]", "\n", "var_scope_name", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "assert", "top", ".", "contains", "(", "var_scope_name", ")", "\n", "\n", "if", "top", ".", "name", "!=", "var_scope_name", ":", "\n", "            ", "top", "=", "self", ".", "Scope", "(", "var_scope_name", ")", "\n", "self", ".", "stack", ".", "insert", "(", "0", ",", "top", ")", "\n", "\n", "", "top", "[", "name", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.inference": [[33, 102], ["config.Config", "tensorflow.convert_to_tensor", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.variable_scope", "resnet.conv", "resnet.bn", "activation", "tensorflow.variable_scope", "resnet._max_pool", "resnet.stack", "tensorflow.variable_scope", "resnet.stack", "tensorflow.variable_scope", "resnet.stack", "tensorflow.variable_scope", "resnet.stack", "tensorflow.variable_scope", "resnet.fc"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.bn", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet._max_pool", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.stack", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.stack", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.stack", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.stack", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.fc"], ["def", "inference", "(", "x", ",", "is_training", ",", "\n", "num_classes", "=", "1000", ",", "\n", "num_blocks", "=", "None", ",", "# defaults to 50-layer network", "\n", "use_bias", "=", "False", ",", "# defaults to using batch norm", "\n", "bottleneck", "=", "True", ")", ":", "\n", "    ", "if", "num_blocks", "is", "None", ":", "\n", "        ", "num_blocks", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", "\n", "", "c", "=", "Config", "(", ")", "\n", "c", "[", "'bottleneck'", "]", "=", "bottleneck", "\n", "c", "[", "'is_training'", "]", "=", "tf", ".", "convert_to_tensor", "(", "is_training", ",", "\n", "dtype", "=", "'bool'", ",", "\n", "name", "=", "'is_training'", ")", "\n", "c", "[", "'ksize'", "]", "=", "3", "\n", "c", "[", "'stride'", "]", "=", "1", "\n", "c", "[", "'use_bias'", "]", "=", "use_bias", "\n", "c", "[", "'fc_units_out'", "]", "=", "num_classes", "\n", "c", "[", "'num_blocks'", "]", "=", "num_blocks", "\n", "c", "[", "'stack_stride'", "]", "=", "2", "\n", "\n", "image_size", "=", "tf", ".", "app", ".", "flags", ".", "FLAGS", ".", "input_size", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", ",", "image_size", ",", "image_size", ",", "3", "]", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'scale1'", ")", ":", "\n", "        ", "c", "[", "'conv_filters_out'", "]", "=", "64", "\n", "c", "[", "'ksize'", "]", "=", "7", "\n", "c", "[", "'stride'", "]", "=", "2", "\n", "x", "=", "conv", "(", "x", ",", "c", ")", "\n", "x", "=", "bn", "(", "x", ",", "c", ")", "\n", "x", "=", "activation", "(", "x", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'scale2'", ")", ":", "\n", "        ", "x", "=", "_max_pool", "(", "x", ",", "ksize", "=", "3", ",", "stride", "=", "2", ")", "\n", "c", "[", "'num_blocks'", "]", "=", "num_blocks", "[", "0", "]", "\n", "c", "[", "'stack_stride'", "]", "=", "1", "\n", "c", "[", "'block_filters_internal'", "]", "=", "64", "\n", "x", "=", "stack", "(", "x", ",", "c", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'scale3'", ")", ":", "\n", "        ", "c", "[", "'num_blocks'", "]", "=", "num_blocks", "[", "1", "]", "\n", "c", "[", "'block_filters_internal'", "]", "=", "128", "\n", "assert", "c", "[", "'stack_stride'", "]", "==", "2", "\n", "x", "=", "stack", "(", "x", ",", "c", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'scale4'", ")", ":", "\n", "        ", "c", "[", "'num_blocks'", "]", "=", "num_blocks", "[", "2", "]", "\n", "c", "[", "'block_filters_internal'", "]", "=", "256", "\n", "x", "=", "stack", "(", "x", ",", "c", ")", "\n", "\n", "", "representation_one_block_before", "=", "x", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'scale5'", ")", ":", "\n", "        ", "c", "[", "'num_blocks'", "]", "=", "num_blocks", "[", "3", "]", "\n", "c", "[", "'block_filters_internal'", "]", "=", "512", "\n", "x", "=", "stack", "(", "x", ",", "c", ")", "\n", "\n", "", "my_represnetation", "=", "x", "\n", "\n", "# post-net", "\n", "x", "=", "tf", ".", "reduce_mean", "(", "x", ",", "reduction_indices", "=", "[", "1", ",", "2", "]", ",", "name", "=", "\"avg_pool\"", ")", "\n", "\n", "# Use vectors after average pooling as representation vectors", "\n", "representation", "=", "x", "\n", "# print(\"Representaion:\", representation)", "\n", "\n", "if", "num_classes", "is", "not", "None", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'fc'", ")", ":", "\n", "            ", "x", "=", "fc", "(", "x", ",", "c", ")", "\n", "\n", "", "", "return", "x", ",", "representation", ",", "my_represnetation", ",", "representation_one_block_before", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.inference_small": [[106, 120], ["config.Config", "tensorflow.convert_to_tensor", "resnet.inference_small_config"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.inference_small_config"], ["", "def", "inference_small", "(", "x", ",", "\n", "is_training", ",", "\n", "num_blocks", "=", "3", ",", "# 6n+2 total weight layers will be used.", "\n", "use_bias", "=", "False", ",", "# defaults to using batch norm", "\n", "num_classes", "=", "10", ")", ":", "\n", "    ", "c", "=", "Config", "(", ")", "\n", "c", "[", "'is_training'", "]", "=", "tf", ".", "convert_to_tensor", "(", "is_training", ",", "\n", "dtype", "=", "'bool'", ",", "\n", "name", "=", "'is_training'", ")", "\n", "c", "[", "'use_bias'", "]", "=", "use_bias", "\n", "c", "[", "'fc_units_out'", "]", "=", "num_classes", "\n", "c", "[", "'num_blocks'", "]", "=", "num_blocks", "\n", "c", "[", "'num_classes'", "]", "=", "num_classes", "\n", "inference_small_config", "(", "x", ",", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.inference_small_config": [[121, 152], ["tensorflow.reduce_mean", "tensorflow.variable_scope", "resnet.conv", "resnet.bn", "activation", "resnet.stack", "tensorflow.variable_scope", "resnet.stack", "tensorflow.variable_scope", "resnet.stack", "tensorflow.variable_scope", "resnet.fc"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.bn", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.stack", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.stack", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.stack", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.fc"], ["", "def", "inference_small_config", "(", "x", ",", "c", ")", ":", "\n", "    ", "c", "[", "'bottleneck'", "]", "=", "False", "\n", "c", "[", "'ksize'", "]", "=", "3", "\n", "c", "[", "'stride'", "]", "=", "1", "\n", "with", "tf", ".", "variable_scope", "(", "'scale1'", ")", ":", "\n", "        ", "c", "[", "'conv_filters_out'", "]", "=", "16", "\n", "c", "[", "'block_filters_internal'", "]", "=", "16", "\n", "c", "[", "'stack_stride'", "]", "=", "1", "\n", "x", "=", "conv", "(", "x", ",", "c", ")", "\n", "x", "=", "bn", "(", "x", ",", "c", ")", "\n", "x", "=", "activation", "(", "x", ")", "\n", "x", "=", "stack", "(", "x", ",", "c", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'scale2'", ")", ":", "\n", "        ", "c", "[", "'block_filters_internal'", "]", "=", "32", "\n", "c", "[", "'stack_stride'", "]", "=", "2", "\n", "x", "=", "stack", "(", "x", ",", "c", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'scale3'", ")", ":", "\n", "        ", "c", "[", "'block_filters_internal'", "]", "=", "64", "\n", "c", "[", "'stack_stride'", "]", "=", "2", "\n", "x", "=", "stack", "(", "x", ",", "c", ")", "\n", "\n", "# post-net", "\n", "", "x", "=", "tf", ".", "reduce_mean", "(", "x", ",", "reduction_indices", "=", "[", "1", ",", "2", "]", ",", "name", "=", "\"avg_pool\"", ")", "\n", "\n", "if", "c", "[", "'num_classes'", "]", "!=", "None", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'fc'", ")", ":", "\n", "            ", "x", "=", "fc", "(", "x", ",", "c", ")", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet._imagenet_preprocess": [[154, 160], ["tensorflow.split", "tensorflow.concat"], "function", ["None"], ["", "def", "_imagenet_preprocess", "(", "rgb", ")", ":", "\n", "    ", "\"\"\"Changes RGB [0,1] valued image to BGR [0,255] with mean subtracted.\"\"\"", "\n", "red", ",", "green", ",", "blue", "=", "tf", ".", "split", "(", "3", ",", "3", ",", "rgb", "*", "255.0", ")", "\n", "bgr", "=", "tf", ".", "concat", "(", "3", ",", "[", "blue", ",", "green", ",", "red", "]", ")", "\n", "bgr", "-=", "IMAGENET_MEAN_BGR", "\n", "return", "bgr", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.loss": [[162, 172], ["tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.get_collection", "tensorflow.add_n", "tensorflow.scalar_summary"], "function", ["None"], ["", "def", "loss", "(", "logits", ",", "labels", ")", ":", "\n", "    ", "cross_entropy", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", ",", "labels", ")", "\n", "cross_entropy_mean", "=", "tf", ".", "reduce_mean", "(", "cross_entropy", ")", "\n", "\n", "regularization_losses", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", "\n", "\n", "loss_", "=", "tf", ".", "add_n", "(", "[", "cross_entropy_mean", "]", "+", "regularization_losses", ")", "\n", "tf", ".", "scalar_summary", "(", "'loss'", ",", "loss_", ")", "\n", "\n", "return", "loss_", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.stack": [[174, 181], ["range", "tensorflow.variable_scope", "resnet.block"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.block"], ["", "def", "stack", "(", "x", ",", "c", ")", ":", "\n", "    ", "for", "n", "in", "range", "(", "c", "[", "'num_blocks'", "]", ")", ":", "\n", "        ", "s", "=", "c", "[", "'stack_stride'", "]", "if", "n", "==", "0", "else", "1", "\n", "c", "[", "'block_stride'", "]", "=", "s", "\n", "with", "tf", ".", "variable_scope", "(", "'block%d'", "%", "(", "n", "+", "1", ")", ")", ":", "\n", "            ", "x", "=", "block", "(", "x", ",", "c", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.block": [[183, 240], ["activation", "bn.get_shape", "tensorflow.variable_scope", "tensorflow.variable_scope", "resnet.conv", "resnet.bn", "activation", "tensorflow.variable_scope", "resnet.conv", "resnet.bn", "activation", "tensorflow.variable_scope", "resnet.conv", "resnet.bn", "tensorflow.variable_scope", "resnet.conv", "resnet.bn", "activation", "tensorflow.variable_scope", "resnet.conv", "resnet.bn", "resnet.conv", "resnet.bn"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.bn", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.bn", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.bn", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.bn", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.bn", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.conv", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.bn"], ["", "def", "block", "(", "x", ",", "c", ")", ":", "\n", "    ", "filters_in", "=", "x", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "\n", "# Note: filters_out isn't how many filters are outputed.", "\n", "# That is the case when bottleneck=False but when bottleneck is", "\n", "# True, filters_internal*4 filters are outputted. filters_internal is how many filters", "\n", "# the 3x3 convs output internally.", "\n", "m", "=", "4", "if", "c", "[", "'bottleneck'", "]", "else", "1", "\n", "filters_out", "=", "m", "*", "c", "[", "'block_filters_internal'", "]", "\n", "\n", "shortcut", "=", "x", "# branch 1", "\n", "\n", "c", "[", "'conv_filters_out'", "]", "=", "c", "[", "'block_filters_internal'", "]", "\n", "\n", "if", "c", "[", "'bottleneck'", "]", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'a'", ")", ":", "\n", "            ", "c", "[", "'ksize'", "]", "=", "1", "\n", "c", "[", "'stride'", "]", "=", "c", "[", "'block_stride'", "]", "\n", "x", "=", "conv", "(", "x", ",", "c", ")", "\n", "x", "=", "bn", "(", "x", ",", "c", ")", "\n", "x", "=", "activation", "(", "x", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'b'", ")", ":", "\n", "            ", "x", "=", "conv", "(", "x", ",", "c", ")", "\n", "x", "=", "bn", "(", "x", ",", "c", ")", "\n", "x", "=", "activation", "(", "x", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'c'", ")", ":", "\n", "            ", "c", "[", "'conv_filters_out'", "]", "=", "filters_out", "\n", "c", "[", "'ksize'", "]", "=", "1", "\n", "assert", "c", "[", "'stride'", "]", "==", "1", "\n", "x", "=", "conv", "(", "x", ",", "c", ")", "\n", "x", "=", "bn", "(", "x", ",", "c", ")", "\n", "", "", "else", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'A'", ")", ":", "\n", "            ", "c", "[", "'stride'", "]", "=", "c", "[", "'block_stride'", "]", "\n", "assert", "c", "[", "'ksize'", "]", "==", "3", "\n", "x", "=", "conv", "(", "x", ",", "c", ")", "\n", "x", "=", "bn", "(", "x", ",", "c", ")", "\n", "x", "=", "activation", "(", "x", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'B'", ")", ":", "\n", "            ", "c", "[", "'conv_filters_out'", "]", "=", "filters_out", "\n", "assert", "c", "[", "'ksize'", "]", "==", "3", "\n", "assert", "c", "[", "'stride'", "]", "==", "1", "\n", "x", "=", "conv", "(", "x", ",", "c", ")", "\n", "x", "=", "bn", "(", "x", ",", "c", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'shortcut'", ")", ":", "\n", "        ", "if", "filters_out", "!=", "filters_in", "or", "c", "[", "'block_stride'", "]", "!=", "1", ":", "\n", "            ", "c", "[", "'ksize'", "]", "=", "1", "\n", "c", "[", "'stride'", "]", "=", "c", "[", "'block_stride'", "]", "\n", "c", "[", "'conv_filters_out'", "]", "=", "filters_out", "\n", "shortcut", "=", "conv", "(", "shortcut", ",", "c", ")", "\n", "shortcut", "=", "bn", "(", "shortcut", ",", "c", ")", "\n", "\n", "", "", "return", "activation", "(", "x", "+", "shortcut", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.bn": [[290, 338], ["x.get_shape", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.cond", "resnet._get_variable", "tensorflow.nn.moments", "tensorflow.assign", "tensorflow.assign", "tensorflow.nn.batch_normalization", "x.get_shape().as_list", "tensorflow.control_dependencies", "tensorflow.nn.batch_normalization", "tensorflow.truncated_normal_initializer", "tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "x.get_shape"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet._get_variable"], ["", "def", "bn", "(", "x", ",", "c", ")", ":", "\n", "    ", "x_shape", "=", "x", ".", "get_shape", "(", ")", "\n", "params_shape", "=", "x_shape", "[", "-", "1", ":", "]", "\n", "if", "c", "[", "'use_bias'", "]", ":", "\n", "        ", "bias", "=", "_get_variable", "(", "'bias'", ",", "params_shape", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", ")", "\n", "return", "x", "+", "bias", "\n", "\n", "", "def", "bn_train", "(", ")", ":", "\n", "        ", "batch_mean", ",", "batch_var", "=", "tf", ".", "nn", ".", "moments", "(", "x", ",", "axes", "=", "[", "0", ",", "1", ",", "2", "]", ")", "\n", "train_mean", "=", "tf", ".", "assign", "(", "\n", "pop_mean", ",", "pop_mean", "*", "BN_DECAY", "+", "batch_mean", "*", "(", "1", "-", "BN_DECAY", ")", ")", "\n", "train_var", "=", "tf", ".", "assign", "(", "\n", "pop_var", ",", "pop_var", "*", "BN_DECAY", "+", "batch_var", "*", "(", "1", "-", "BN_DECAY", ")", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "train_mean", ",", "train_var", "]", ")", ":", "\n", "            ", "return", "tf", ".", "nn", ".", "batch_normalization", "(", "\n", "x", ",", "batch_mean", ",", "batch_var", ",", "beta", ",", "gamma", ",", "BN_EPSILON", ")", "\n", "\n", "", "", "def", "bn_inference", "(", ")", ":", "\n", "        ", "return", "tf", ".", "nn", ".", "batch_normalization", "(", "\n", "x", ",", "pop_mean", ",", "pop_var", ",", "beta", ",", "gamma", ",", "BN_EPSILON", ")", "\n", "\n", "", "dim", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "beta", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "'beta'", ",", "\n", "shape", "=", "[", "dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.0", ")", "\n", ")", "\n", "gamma", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "'gamma'", ",", "\n", "shape", "=", "[", "dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.1", ")", "\n", ")", "\n", "pop_mean", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "'moving_mean'", ",", "\n", "shape", "=", "[", "dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "pop_var", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "'moving_variance'", ",", "\n", "shape", "=", "[", "dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "return", "tf", ".", "cond", "(", "c", "[", "'is_training'", "]", ",", "bn_train", ",", "bn_inference", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.fc": [[340, 355], ["tensorflow.truncated_normal_initializer", "resnet._get_variable", "resnet._get_variable", "tensorflow.nn.xw_plus_b", "tf.nn.xw_plus_b.get_shape"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet._get_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet._get_variable"], ["", "def", "fc", "(", "x", ",", "c", ")", ":", "\n", "    ", "num_units_in", "=", "x", ".", "get_shape", "(", ")", "[", "1", "]", "\n", "num_units_out", "=", "c", "[", "'fc_units_out'", "]", "\n", "weights_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "\n", "stddev", "=", "FC_WEIGHT_STDDEV", ")", "\n", "\n", "weights", "=", "_get_variable", "(", "'weights'", ",", "\n", "shape", "=", "[", "num_units_in", ",", "num_units_out", "]", ",", "\n", "initializer", "=", "weights_initializer", ",", "\n", "weight_decay", "=", "FC_WEIGHT_STDDEV", ")", "\n", "biases", "=", "_get_variable", "(", "'biases'", ",", "\n", "shape", "=", "[", "num_units_out", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", ")", "\n", "x", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "x", ",", "weights", ",", "biases", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet._get_variable": [[357, 378], ["tensorflow.get_variable", "tensorflow.contrib.layers.l2_regularizer"], "function", ["None"], ["", "def", "_get_variable", "(", "name", ",", "\n", "shape", ",", "\n", "initializer", ",", "\n", "weight_decay", "=", "0.0", ",", "\n", "dtype", "=", "'float'", ",", "\n", "trainable", "=", "True", ")", ":", "\n", "    ", "\"A little wrapper around tf.get_variable to do weight decay and add to\"", "\n", "\"resnet collection\"", "\n", "if", "weight_decay", ">", "0", ":", "\n", "        ", "regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "weight_decay", ")", "\n", "", "else", ":", "\n", "        ", "regularizer", "=", "None", "\n", "", "collections", "=", "[", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "RESNET_VARIABLES", "]", "\n", "\n", "return", "tf", ".", "get_variable", "(", "name", ",", "\n", "shape", "=", "shape", ",", "\n", "initializer", "=", "initializer", ",", "\n", "dtype", "=", "dtype", ",", "\n", "regularizer", "=", "regularizer", ",", "\n", "collections", "=", "collections", ",", "\n", "trainable", "=", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet.conv": [[380, 394], ["tensorflow.truncated_normal_initializer", "resnet._get_variable", "tensorflow.nn.conv2d", "x.get_shape"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet._get_variable", "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.conv2d"], ["", "def", "conv", "(", "x", ",", "c", ")", ":", "\n", "    ", "ksize", "=", "c", "[", "'ksize'", "]", "\n", "stride", "=", "c", "[", "'stride'", "]", "\n", "filters_out", "=", "c", "[", "'conv_filters_out'", "]", "\n", "\n", "filters_in", "=", "x", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "shape", "=", "[", "ksize", ",", "ksize", ",", "filters_in", ",", "filters_out", "]", "\n", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "CONV_WEIGHT_STDDEV", ")", "\n", "weights", "=", "_get_variable", "(", "'weights'", ",", "\n", "shape", "=", "shape", ",", "\n", "dtype", "=", "'float'", ",", "\n", "initializer", "=", "initializer", ",", "\n", "weight_decay", "=", "CONV_WEIGHT_DECAY", ")", "\n", "return", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "weights", ",", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.resnet.resnet._max_pool": [[396, 401], ["tensorflow.nn.max_pool"], "function", ["home.repos.pwc.inspect_result.avikalp7_VQAtoCQA.src.network.max_pool"], ["", "def", "_max_pool", "(", "x", ",", "ksize", "=", "3", ",", "stride", "=", "2", ")", ":", "\n", "    ", "return", "tf", ".", "nn", ".", "max_pool", "(", "x", ",", "\n", "ksize", "=", "[", "1", ",", "ksize", ",", "ksize", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", ",", "\n", "padding", "=", "'SAME'", ")", "\n", "", ""]]}