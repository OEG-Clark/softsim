{"home.repos.pwc.inspect_result.matthewmatero_melt.None.main.MetricsCallback.__init__": [[15, 18], ["pytorch_lightning.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.PositionalFeedForward.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "metrics", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.None.main.MetricsCallback.on_validation_end": [[19, 21], ["main.MetricsCallback.metrics.append"], "methods", ["None"], ["", "def", "on_validation_end", "(", "self", ",", "trainer", ",", "pl_module", ")", ":", "\n", "        ", "self", ".", "metrics", ".", "append", "(", "trainer", ".", "callback_metrics", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.None.main.get_args": [[22, 43], ["test_tube.HyperOptArgumentParser", "os.getcwd", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "model.add_model_specific_args"], "function", ["home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder.MeLT.add_model_specific_args"], ["", "", "def", "get_args", "(", "model", ")", ":", "\n", "\n", "    ", "parent_parser", "=", "HyperOptArgumentParser", "(", "strategy", "=", "'random_search'", ",", "add_help", "=", "False", ")", "\n", "\n", "root_dir", "=", "os", ".", "getcwd", "(", ")", "\n", "\n", "parent_parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "default", "=", "'default'", ",", "choices", "=", "(", "'default'", ",", "'test'", ",", "'param_search'", ")", ",", "help", "=", "'Toggle train/test/search modes'", ")", "\n", "parent_parser", ".", "add_argument", "(", "'--save-path'", ",", "type", "=", "str", ",", "default", "=", "'/data/mmatero/melt/models'", ",", "help", "=", "'directory to save models'", ")", "\n", "parent_parser", ".", "add_argument", "(", "'--checkpoint'", ",", "type", "=", "str", ",", "default", "=", "'2'", ",", "help", "=", "\"file of saved checkpoint\"", ")", "\n", "parent_parser", ".", "add_argument", "(", "'--version'", ",", "type", "=", "str", ",", "default", "=", "'1492'", ",", "help", "=", "\"version number of checkpoint\"", ")", "\n", "parent_parser", ".", "add_argument", "(", "'--gpus'", ",", "type", "=", "str", ",", "default", "=", "'0,1,2'", ",", "help", "=", "'GPU IDs as CSV'", ")", "\n", "parent_parser", ".", "add_argument", "(", "'--distributed-backend'", ",", "type", "=", "str", ",", "default", "=", "'dp'", ",", "choices", "=", "(", "'dp'", ",", "'ddp'", ",", "'ddp2'", ")", ",", "help", "=", "\"distributed processing protocol\"", ")", "\n", "parent_parser", ".", "add_argument", "(", "'--use_16bit'", ",", "dest", "=", "'use_16bit'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use 16bit precision'", ")", "\n", "parent_parser", ".", "add_argument", "(", "'--num_trials'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'number of trials for param search'", ")", "\n", "\n", "# helpful debugging", "\n", "parent_parser", ".", "add_argument", "(", "'--fast_dev_run'", ",", "dest", "=", "'fast_dev_run'", ",", "action", "=", "'store_true'", ",", "help", "=", "'debug a full train/test/val loop'", ")", "\n", "parent_parser", ".", "add_argument", "(", "'--track_grad_norm'", ",", "dest", "=", "'track_grad_norm'", ",", "action", "=", "'store_true'", ",", "help", "=", "'toggles grad norm tracking'", ")", "\n", "\n", "parser", "=", "model", ".", "add_model_specific_args", "(", "parent_parser", ",", "root_dir", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.None.main.run_model": [[44, 92], ["pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.Trainer", "modeling.encoder.MeLT", "print", "modeling.encoder.MeLT.load_from_checkpoint", "random.seed", "torch.manual_seed", "torch.manual_seed", "pl.Trainer.fit", "pl.Trainer.test", "pl.Trainer.test", "len", "gpus.split"], "function", ["None"], ["", "def", "run_model", "(", "hparams", ",", "gpus", "=", "None", ")", ":", "\n", "# Default train/test loop from scratch", "\n", "    ", "if", "hparams", ".", "mode", "==", "'default'", ":", "\n", "        ", "model", "=", "MeLT", "(", "hparams", ")", "\n", "\n", "# Load in pretrained model", "\n", "", "if", "hparams", ".", "mode", "==", "'test'", ":", "\n", "        ", "version_path", "=", "hparams", ".", "save_path", "+", "'/lightning_logs/version_'", "+", "hparams", ".", "version", "\n", "checkpoint_path", "=", "version_path", "+", "'/checkpoints/epoch='", "+", "hparams", ".", "checkpoint", "+", "'.ckpt'", "\n", "\n", "meta_path", "=", "version_path", "+", "'/meta_tags.csv'", "\n", "print", "(", "f'Loading model from {checkpoint_path}'", ")", "\n", "model", "=", "MeLT", ".", "load_from_checkpoint", "(", "checkpoint_path", ",", "tags_csv", "=", "meta_path", ")", "\n", "\n", "if", "hparams", ".", "max_msg_seq_dev", "!=", "model", ".", "max_msg_dev", ":", "\n", "            ", "model", ".", "max_msg_dev", "=", "hparams", ".", "max_msg_seq_dev", "\n", "model", ".", "hparams", ".", "max_msg_seq_dev", "=", "hparams", ".", "max_msg_seq_dev", "\n", "\n", "", "", "if", "hparams", ".", "seed", "is", "not", "None", ":", "\n", "        ", "random", ".", "seed", "(", "hparams", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "hparams", ".", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "", "early_stop_callback", "=", "EarlyStopping", "(", "\n", "monitor", "=", "'val_loss'", ",", "\n", "min_delta", "=", "0.00005", ",", "\n", "patience", "=", "3", ",", "\n", "verbose", "=", "False", ",", "\n", "mode", "=", "'min'", "\n", ")", "\n", "\n", "# Set model setup config", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "default_save_path", "=", "hparams", ".", "save_path", ",", "\n", "gpus", "=", "len", "(", "gpus", ".", "split", "(", "','", ")", ")", "if", "gpus", "else", "hparams", ".", "gpus", ",", "\n", "distributed_backend", "=", "hparams", ".", "distributed_backend", ",", "\n", "use_amp", "=", "hparams", ".", "use_16bit", ",", "\n", "max_nb_epochs", "=", "hparams", ".", "epochs", ",", "\n", "#gradient_clip_val=.25,", "\n", "track_grad_norm", "=", "(", "2", "if", "hparams", ".", "track_grad_norm", "else", "-", "1", ")", ",", "\n", "early_stop_callback", "=", "early_stop_callback", ")", "\n", "\n", "# only train model in default, run test for default and test configs", "\n", "#if hparams.mode == 'default':", "\n", "if", "hparams", ".", "mode", "==", "'default'", ":", "\n", "        ", "trainer", ".", "fit", "(", "model", ")", "\n", "trainer", ".", "test", "(", ")", "\n", "", "elif", "hparams", ".", "mode", "==", "'test'", ":", "\n", "        ", "trainer", ".", "test", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.None.main.objective": [[93, 111], ["pytorch_lightning.callbacks.ModelCheckpoint", "main.MetricsCallback", "pytorch_lightning.Trainer", "modeling.encoder.MeLT", "pl.Trainer.fit", "os.path.join", "optuna.integration.PyTorchLightningPruningCallback", "len", "gpus.split"], "function", ["None"], ["", "", "def", "objective", "(", "trial", ",", "gpus", "=", "None", ")", ":", "\n", "# unique file names", "\n", "    ", "checkpoint_callback", "=", "pl", ".", "callbacks", ".", "ModelCheckpoint", "(", "\n", "os", ".", "path", ".", "join", "(", "hparams", ".", "save_path", ",", "'trial_{}'", ".", "format", "(", "trial", ".", "number", ")", ",", "'{epoch}'", ")", ",", "monitor", "=", "'val_loss'", ")", "\n", "\n", "# save metrics from each validation step", "\n", "metrics_callback", "=", "MetricsCallback", "(", ")", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "logger", "=", "False", ",", "\n", "checkpoint_callback", "=", "checkpoint_callback", ",", "\n", "max_nb_epochs", "=", "hparams", ".", "epochs", ",", "\n", "gpus", "=", "len", "(", "gpus", ".", "split", "(", "','", ")", ")", "if", "gpus", "else", "hparams", ".", "gpus", ",", "\n", "callbacks", "=", "[", "metrics_callback", "]", ",", "\n", "early_stop_callback", "=", "PyTorchLightningPruningCallback", "(", "trial", ",", "monitor", "=", "'val_loss'", ")", ")", "\n", "# setup model", "\n", "model", "=", "MeLT", "(", "hparams", ",", "trial", ")", "\n", "trainer", ".", "fit", "(", "model", ")", "\n", "\n", "return", "metrics_callback", ".", "metrics", "[", "-", "1", "]", "[", "'val_loss'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder.MeLT.__init__": [[28, 82], ["pytorch_lightning.LightningModule.__init__", "torch.ModuleList", "torch.ModuleList", "modeling.neural.PositionalEncoding", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "torch.MSELoss", "torch.MSELoss", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "trial.suggest_loguniform", "trial.suggest_uniform", "encoder.MeLT.bert_layers.parameters", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "transformers.DistilBertModel", "transformers.AutoModel.from_config", "modeling.encoder_layers.TransformerEncoderLayer", "transformers.DistilBertConfig", "transformers.AutoConfig.from_pretrained", "range"], "methods", ["home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.PositionalFeedForward.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ",", "trial", "=", "None", ")", ":", "\n", "        ", "super", "(", "MeLT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hparams", "=", "hparams", "\n", "self", ".", "seed", "=", "self", ".", "hparams", ".", "seed", "\n", "self", ".", "mask_rate", "=", "self", ".", "hparams", ".", "mask_rate", "\n", "self", ".", "num_trans_layers", "=", "self", ".", "hparams", ".", "tlayers", "\n", "self", ".", "max_msg_train", "=", "self", ".", "hparams", ".", "max_msg_seq", "\n", "self", ".", "max_msg_dev", "=", "self", ".", "hparams", ".", "max_msg_seq_dev", "\n", "\n", "self", ".", "extract_layer", "=", "self", ".", "hparams", ".", "extract_layer", "\n", "self", ".", "load_bert", "=", "self", ".", "hparams", ".", "load_bert", "\n", "\n", "self", ".", "freeze_bert", "=", "True", "# always freeze during PT, FT scrpt will toggle after importing model", "\n", "\n", "self", ".", "pretraining", "=", "self", ".", "hparams", ".", "pretrain", "\n", "\n", "self", ".", "model_dim", "=", "self", ".", "hparams", ".", "dmodel", "\n", "self", ".", "ff_dim", "=", "self", ".", "hparams", ".", "dff", "\n", "self", ".", "inter_heads", "=", "self", ".", "hparams", ".", "num_heads", "\n", "\n", "self", ".", "dropout", "=", "self", ".", "hparams", ".", "dropout", "\n", "self", ".", "learn_rate", "=", "self", ".", "hparams", ".", "lr", "\n", "self", ".", "batch_size", "=", "self", ".", "hparams", ".", "bs", "\n", "self", ".", "epochs", "=", "self", ".", "hparams", ".", "epochs", "\n", "self", ".", "max_seq_len", "=", "self", ".", "hparams", ".", "max_seq_len", "\n", "self", ".", "emb_size", "=", "self", ".", "hparams", ".", "embed_dim", "\n", "\n", "# params to tune", "\n", "if", "trial", ":", "\n", "            ", "self", ".", "hparams", ".", "lr", "=", "trial", ".", "suggest_loguniform", "(", "'lr'", ",", "low", "=", "5e-4", ",", "high", "=", "4e-1", ")", "\n", "self", ".", "hparams", ".", "reg", "=", "trial", ".", "suggest_uniform", "(", "'reg'", ",", "low", "=", "1e-4", ",", "high", "=", "1", ")", "\n", "\n", "\n", "", "if", "self", ".", "load_bert", ":", "\n", "            ", "if", "self", ".", "bert_model", "==", "'distilbert-base-uncased'", ":", "\n", "                ", "self", ".", "bert_layers", "=", "DistilBertModel", "(", "DistilBertConfig", "(", "n_layers", "=", "6", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "bert_layers", "=", "AutoModel", ".", "from_config", "(", "AutoConfig", ".", "from_pretrained", "(", "'distilroberta-base'", ")", ")", "\n", "\n", "# freeze bert layers", "\n", "", "", "if", "self", ".", "freeze_bert", ":", "\n", "            ", "for", "param", "in", "self", ".", "bert_layers", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "self", ".", "trans_layers", "=", "nn", ".", "ModuleList", "(", "[", "TransformerEncoderLayer", "(", "self", ".", "model_dim", ",", "self", ".", "inter_heads", ",", "self", ".", "ff_dim", ",", "self", ".", "dropout", ")", "for", "i", "in", "range", "(", "self", ".", "num_trans_layers", ")", "]", ")", "\n", "self", ".", "pos_emb", "=", "PositionalEncoding", "(", "self", ".", "dropout", ",", "self", ".", "emb_size", ",", "max_len", "=", "512", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "self", ".", "model_dim", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "self", ".", "emb_size", ",", "self", ".", "emb_size", ")", "\n", "\n", "self", ".", "loss_func", "=", "nn", ".", "MSELoss", "(", "reduction", "=", "'mean'", ")", "\n", "\n", "# define mask and pad vectors for grouping function", "\n", "self", ".", "mask_vec", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "self", ".", "emb_size", ")", ")", "\n", "self", ".", "pad_vec", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "self", ".", "emb_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder.MeLT.forward": [[83, 151], ["torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "attn_mask.to.to.reshape", "attn_mask.to.reshape.view().expand", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum().view().expand", "torch.sum().view().expand", "torch.sum().view().expand", "torch.sum().view().expand", "encoder.MeLT.pos_emb", "encoder.MeLT.dense", "encoder.MeLT.loss_func", "modeling.neural.batch_by_usr_no_mask", "new_batch.type().to.type().to.type().to", "attn_mask.to.to.to", "encoder.MeLT.pos_emb", "enumerate", "encoder.MeLT.layer_norm", "encoder.MeLT.bert_layers", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "modeling.neural.batch_by_usr", "modeling.neural.calc_avg_preds", "trans_layer", "encoder.MeLT.layer_norm", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "encoder.MeLT.loss_func", "trans_layer", "attn_mask.to.reshape.view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "new_batch.type().to.type().to.type", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "valid_msgs.float", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "avg_msg_reps[].view"], "methods", ["home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.batch_by_usr_no_mask", "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.batch_by_usr", "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.calc_avg_preds"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "attn_mask", ",", "usr_id", ",", "max_msg_len", ")", ":", "\n", "        ", "\"\"\"\n            Forward pass of the MeLT\n        \"\"\"", "\n", "\n", "if", "self", ".", "load_bert", ":", "\n", "# extract BERT emb for each message(batch_size=num_msg)", "\n", "            ", "inputs", "=", "torch", ".", "reshape", "(", "inputs", ",", "(", "inputs", ".", "shape", "[", "0", "]", "*", "inputs", ".", "shape", "[", "1", "]", ",", "inputs", ".", "shape", "[", "2", "]", ")", ")", "\n", "msg_attn_mask", "=", "attn_mask", ".", "reshape", "(", "attn_mask", ".", "shape", "[", "0", "]", "*", "attn_mask", ".", "shape", "[", "1", "]", ",", "attn_mask", ".", "shape", "[", "2", "]", ")", "\n", "bert_emb", "=", "self", ".", "bert_layers", "(", "inputs", ",", "msg_attn_mask", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "bert_emb", "=", "inputs", "# assume someone is passing the word embeds with attn mask", "\n", "\n", "# generate msg representations and group by user_id", "\n", "", "pooler", "=", "(", "bert_emb", "*", "msg_attn_mask", ".", "view", "(", "bert_emb", ".", "shape", "[", "0", "]", ",", "bert_emb", ".", "shape", "[", "1", "]", ",", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "768", ")", ")", "\n", "avg_msg_reps", "=", "torch", ".", "sum", "(", "pooler", ",", "dim", "=", "1", ")", "/", "torch", ".", "sum", "(", "msg_attn_mask", ",", "dim", "=", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand", "(", "-", "1", ",", "768", ")", "\n", "valid_msgs", "=", "~", "(", "avg_msg_reps", "!=", "avg_msg_reps", ")", "# detects nans from avging over messages with entirely 0 attn mask", "\n", "avg_msg_reps", "[", "avg_msg_reps", "!=", "avg_msg_reps", "]", "=", "0", "# remove nans", "\n", "\n", "if", "self", ".", "pretraining", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "# just grouping and normalizing, don't need to calc grads", "\n", "# normalize", "\n", "                ", "mean", "=", "torch", ".", "sum", "(", "avg_msg_reps", "*", "valid_msgs", ".", "float", "(", ")", ",", "axis", "=", "0", ")", "/", "torch", ".", "sum", "(", "valid_msgs", ",", "axis", "=", "0", ")", "\n", "std", "=", "torch", ".", "sqrt", "(", "torch", ".", "mean", "(", "torch", ".", "pow", "(", "torch", ".", "abs", "(", "avg_msg_reps", "[", "valid_msgs", "]", ".", "view", "(", "-", "1", ",", "self", ".", "emb_size", ")", "-", "mean", ")", ",", "2", ")", ",", "axis", "=", "0", ")", ")", "\n", "avg_msg_reps", "=", "(", "avg_msg_reps", "-", "mean", ")", "/", "std", "\n", "avg_msg_reps", "[", "~", "valid_msgs", "]", "=", "0", "# make fake msgs easier to filter", "\n", "\n", "usr_batch", "=", "batch_by_usr", "(", "avg_msg_reps", ",", "usr_id", ",", "self", ".", "pad_vec", ",", "self", ".", "mask_vec", ",", "max_msg_len", ",", "self", ".", "mask_rate", ")", "\n", "new_batch", ",", "new_attn_mask", ",", "(", "masked_msgs", ",", "mask_unmasked", ")", ",", "(", "labels", ",", "unmasked_labels", ")", ",", "ord_uid", "=", "usr_batch", "\n", "\n", "avg_preds", "=", "calc_avg_preds", "(", "new_batch", ",", "masked_msgs", ",", "new_attn_mask", ",", "mask_unmasked", ")", "\n", "\n", "# add in positional encodings", "\n", "", "data", "=", "self", ".", "pos_emb", "(", "new_batch", ")", "\n", "\n", "# pass sequence of message vectors to transformer layers", "\n", "for", "trans_layer", "in", "self", ".", "van_layers", ":", "\n", "                ", "data", "=", "trans_layer", "(", "data", ",", "new_attn_mask", ")", "\n", "\n", "# get predictions and calculate loss", "\n", "", "output", "=", "self", ".", "dense", "(", "self", ".", "layer_norm", "(", "data", ")", ")", "\n", "preds", "=", "output", "[", "masked_msgs", "]", "\n", "loss", "=", "self", ".", "loss_func", "(", "preds", ",", "labels", ")", "\n", "\n", "# filter out preds/labels for messages that were \"masked\" but 10% chance of being untouched", "\n", "preds2", "=", "output", "[", "~", "mask_unmasked", "&", "masked_msgs", "]", "\n", "labels2", "=", "labels", "[", "~", "unmasked_labels", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "# just metric comparisons", "\n", "                ", "avg_loss", "=", "self", ".", "loss_func", "(", "avg_preds", ",", "labels2", ")", "\n", "\n", "", "return", "loss", ",", "preds2", ",", "labels2", ",", "(", "avg_preds", ",", "avg_loss", ")", ",", "(", "output", ",", "ord_uid", ",", "attn_mask", ")", ",", "(", "masked_msgs", ",", "mask_unmasked", ")", "\n", "", "else", ":", "\n", "            ", "new_batch", ",", "attn_mask", ",", "ordered_uid", "=", "batch_by_usr_no_mask", "(", "avg_msg_reps", ",", "usr_id", ",", "self", ".", "pad_vec", ",", "max_num_msgs", "=", "max_msg_len", ")", "\n", "\n", "# weird bug where tenors weren't auto put to GPU", "\n", "new_batch", "=", "new_batch", ".", "type", "(", "torch", ".", "FloatTensor", ")", ".", "to", "(", "bert_emb", ".", "device", ")", "\n", "attn_mask", "=", "attn_mask", ".", "to", "(", "bert_emb", ".", "device", ")", "\n", "\n", "data", "=", "self", ".", "pos_emb", "(", "new_batch", ")", "\n", "\n", "for", "idx", ",", "trans_layer", "in", "enumerate", "(", "self", ".", "van_layers", ")", ":", "\n", "                ", "data", "=", "trans_layer", "(", "data", ",", "attn_mask", ")", "\n", "if", "self", ".", "extract_layer", "==", "idx", ":", "\n", "                    ", "break", "\n", "\n", "", "", "data", "=", "self", ".", "layer_norm", "(", "data", ")", "\n", "return", "(", "data", ",", "ordered_uid", ",", "attn_mask", ",", "new_batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder.MeLT.configure_optimizers": [[152, 159], ["torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "encoder.MeLT.parameters"], "methods", ["None"], ["", "", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n            Defines otpimizers\n        \"\"\"", "\n", "\n", "opt", "=", "torch", ".", "optim", ".", "AdamW", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "hparams", ".", "lr", ",", "weight_decay", "=", "self", ".", "hparams", ".", "reg", ")", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder.MeLT.optimizer_step": [[160, 174], ["optimizer.step", "optimizer.zero_grad", "min", "float"], "methods", ["None"], ["", "def", "optimizer_step", "(", "self", ",", "epoch_nb", ",", "batch_nb", ",", "optimizer", ",", "optimizer_i", ",", "opt_closure", ")", ":", "\n", "        ", "\"\"\"\n            Set warmup step scheduler for pre-training routine\n\n            LR is linearly scaled for the first 2000 steps. \n        \"\"\"", "\n", "if", "self", ".", "pretraining", ":", "\n", "            ", "if", "self", ".", "trainer", ".", "global_step", "<", "2000", ":", "\n", "                ", "lr_scale", "=", "min", "(", "1.", ",", "float", "(", "self", ".", "trainer", ".", "global_step", "+", "1", ")", "/", "2000.", ")", "\n", "for", "pg", "in", "optimizer", ".", "param_groups", ":", "\n", "                    ", "pg", "[", "'lr'", "]", "=", "lr_scale", "*", "self", ".", "hparams", ".", "lr", "\n", "\n", "", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder.MeLT.training_step": [[175, 189], ["encoder.MeLT.", "loss.unsqueeze.unsqueeze.unsqueeze", "aloss.unsqueeze.unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "\"\"\"\n            Called inside Lightnings train.fit()\n        \"\"\"", "\n", "input_ids", ",", "attn_mask", ",", "usr_id", "=", "batch", "[", "0", "]", ",", "batch", "[", "1", "]", ",", "batch", "[", "2", "]", "\n", "loss", ",", "_", ",", "_", ",", "(", "apreds", ",", "aloss", ")", ",", "_", ",", "_", "=", "self", "(", "input_ids", ",", "attn_mask", ",", "usr_id", ",", "self", ".", "max_msg_train", ")", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "            ", "loss", "=", "loss", ".", "unsqueeze", "(", "0", ")", "\n", "aloss", "=", "aloss", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# tensorboard logger", "\n", "", "tb_logs", "=", "{", "'train_loss'", ":", "loss", ",", "'avg_loss'", ":", "aloss", "}", "\n", "\n", "return", "{", "'loss'", ":", "loss", ",", "'avg_loss'", ":", "aloss", ",", "'log'", ":", "tb_logs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder.MeLT.validation_step": [[190, 208], ["encoder.MeLT.", "modeling.neural.metrics", "modeling.neural.metrics.pop", "score.unsqueeze", "modeling.neural.metrics.values", "zip", "modeling.neural.metrics.keys"], "methods", ["home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.metrics"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ",", "dataloader_idx", ")", ":", "\n", "        ", "\"\"\"\n            Called for each batch in validation set\n        \"\"\"", "\n", "input_ids", ",", "attn_mask", ",", "usr_id", "=", "batch", "[", "0", "]", ",", "batch", "[", "1", "]", ",", "batch", "[", "2", "]", "\n", "loss_names", "=", "[", "'seen_user'", ",", "'unseen_user'", "]", "\n", "\n", "loss", ",", "output", ",", "labels", ",", "(", "avg_preds", ",", "avg_loss", ")", ",", "_", ",", "_", "=", "self", "(", "input_ids", ",", "attn_mask", ",", "usr_id", ",", "self", ".", "max_msg_dev", ")", "\n", "other_data", "=", "{", "'apred'", ":", "avg_preds", ",", "'aloss'", ":", "avg_loss", "}", "\n", "scores_dict", "=", "metrics", "(", "loss", ",", "output", ",", "loss_names", "[", "dataloader_idx", "]", ",", "labels", ",", "other_data", ")", "\n", "\n", "# in DP mode make sure if result is scalar, there's another dim in the beginning", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "            ", "scores", "=", "[", "score", ".", "unsqueeze", "(", "0", ")", "for", "score", "in", "scores_dict", ".", "values", "(", ")", "]", "\n", "scores_dict", "=", "{", "key", ":", "value", "for", "key", ",", "value", "in", "zip", "(", "scores_dict", ".", "keys", "(", ")", ",", "scores", ")", "}", "\n", "scores_dict", ".", "pop", "(", "'seen_usr'", ",", "None", ")", "# seen_usr is moved to val_loss", "\n", "\n", "", "return", "scores_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder.MeLT.validation_epoch_end": [[209, 230], ["dataset[].keys", "len", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "\"\"\"\n            Gathers results at end of validation loop\n        \"\"\"", "\n", "tqdm_dict", "=", "{", "}", "\n", "for", "dataset", "in", "outputs", ":", "\n", "            ", "num_batches", "=", "0", "\n", "for", "metric_name", "in", "dataset", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "                ", "total", "=", "0", "\n", "\n", "for", "output", "in", "dataset", ":", "\n", "                    ", "val", "=", "output", "[", "metric_name", "]", "\n", "# average across each GPU per batch", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "                        ", "val", "=", "torch", ".", "mean", "(", "val", ")", "\n", "", "total", "+=", "val", "\n", "\n", "", "tqdm_dict", "[", "metric_name", "]", "=", "total", "/", "len", "(", "dataset", ")", "# avg over all batches", "\n", "\n", "", "", "result", "=", "{", "'progress_bar'", ":", "tqdm_dict", ",", "'log'", ":", "tqdm_dict", ",", "'seen_user'", ":", "tqdm_dict", "[", "'seen_user'", "]", ",", "'unseen_user'", ":", "tqdm_dict", "[", "'unseen_user'", "]", "}", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder.MeLT.test_step": [[231, 233], ["encoder.MeLT.validation_step"], "methods", ["home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder.MeLT.validation_step"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_idx", ",", "dataloader_idx", ")", ":", "\n", "        ", "return", "self", ".", "validation_step", "(", "batch", ",", "batch_idx", ",", "dataloader_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder.MeLT.test_epoch_end": [[234, 236], ["encoder.MeLT.validation_epoch_end"], "methods", ["home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder.MeLT.validation_epoch_end"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "return", "self", ".", "validation_epoch_end", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder.MeLT.train_dataloader": [[237, 242], ["dataloader_v2"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n            Train dataset of tweets\n        \"\"\"", "\n", "return", "dataloader_v2", "(", "'twitter_train'", ",", "self", ".", "hparams", ".", "max_seq_len", ",", "self", ".", "hparams", ".", "bs", ",", "self", ".", "hparams", ".", "max_msg_seq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder.MeLT.val_dataloader": [[243, 250], ["dataloader_v2", "dataloader_v2"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n            validation dataset(s). Secondary FB dataset was used to explore domain transfer, not used in final publication\n        \"\"\"", "\n", "d1", "=", "dataloader_v2", "(", "'twitter_dev'", ",", "self", ".", "hparams", ".", "max_seq_len", ",", "self", ".", "hparams", ".", "bs", ",", "self", ".", "hparams", ".", "max_msg_seq_dev", ")", "\n", "d2", "=", "dataloader_v2", "(", "'fb_dev'", ",", "self", ".", "hparams", ".", "max_seq_len", ",", "self", ".", "hparams", ".", "bs", ",", "self", ".", "hparams", ".", "max_msg_seq_dev", ")", "\n", "return", "[", "d1", ",", "d2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder.MeLT.test_dataloader": [[251, 258], ["dataloader_v2", "dataloader_v2"], "methods", ["None"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n            test dataset(s). Secondary FB dataset was used to explore domain transfer, not used in final publication\n        \"\"\"", "\n", "d1", "=", "dataloader_v2", "(", "'twitter_test'", ",", "self", ".", "hparams", ".", "max_seq_len", ",", "self", ".", "hparams", ".", "bs", ",", "self", ".", "hparams", ".", "max_msg_seq_dev", ")", "\n", "d2", "=", "dataloader_v2", "(", "'fb_test'", ",", "self", ".", "hparams", ".", "max_seq_len", ",", "self", ".", "hparams", ".", "bs", ",", "self", ".", "hparams", ".", "max_msg_seq_dev", ")", "\n", "return", "[", "d1", ",", "d2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder.MeLT.add_model_specific_args": [[261, 295], ["test_tube.HyperOptArgumentParser", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument", "test_tube.HyperOptArgumentParser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ",", "root_dir", ")", ":", "\n", "        ", "\"\"\"\n            parameters defined here are available through self.model_params\n        \"\"\"", "\n", "\n", "parser", "=", "HyperOptArgumentParser", "(", "parents", "=", "[", "parent_parser", "]", ")", "\n", "\n", "# BERT related parameters", "\n", "parser", ".", "add_argument", "(", "'--bert_model'", ",", "default", "=", "'distilbert-base-uncased'", ",", "type", "=", "str", ",", "help", "=", "\"config bert base or large\"", ")", "\n", "\n", "# encoder params", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "default", "=", "1337", ",", "type", "=", "int", ",", "help", "=", "\"random seed\"", ")", "\n", "parser", ".", "add_argument", "(", "'--tlayers'", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "\"num transformer layers on top of BERT\"", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "\"total num of epochs\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"droprate throughout model\"", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "default", "=", "1e-5", ",", "type", "=", "float", ",", "help", "=", "\"intiial learning rate\"", ")", "\n", "parser", ".", "add_argument", "(", "'--reg'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"L2 reg applied to optimizer\"", ")", "\n", "parser", ".", "add_argument", "(", "'--bs'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "help", "=", "\"minibatch size\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max_seq_len'", ",", "default", "=", "50", ",", "type", "=", "int", ",", "help", "=", "\"max number of input tokens for model\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dmodel'", ",", "default", "=", "768", ",", "type", "=", "int", ",", "help", "=", "\"dimension size of transformer representations\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dff'", ",", "default", "=", "2048", ",", "type", "=", "int", ",", "help", "=", "\"dimension size of FFNN layers\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_heads'", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"num of inter attn heads\"", ")", "\n", "parser", ".", "add_argument", "(", "'--mask_rate'", ",", "default", "=", "15", ",", "type", "=", "int", ",", "help", "=", "\"% of msgs to mask for upper transformer layer\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max_msg_seq'", ",", "default", "=", "40", ",", "type", "=", "int", ",", "help", "=", "\"maximum message vectors to append to the seq\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max_msg_seq_dev'", ",", "default", "=", "20", ",", "type", "=", "int", ",", "help", "=", "\"maximum message vectors to append to the seq in dev/test\"", ")", "\n", "parser", ".", "add_argument", "(", "'--embed_dim'", ",", "default", "=", "768", ",", "type", "=", "int", ",", "help", "=", "\"Size of embedding dimension for model\"", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrain'", ",", "default", "=", "True", ",", "type", "=", "bool", ",", "help", "=", "\"Toggle pretraining objective\"", ")", "\n", "parser", ".", "add_argument", "(", "'--extract_layer'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "\"Select layer to extract embeddings from. Count starts at 0\"", ")", "\n", "parser", ".", "add_argument", "(", "'--load_bert'", ",", "default", "=", "True", ",", "type", "=", "bool", ",", "help", "=", "\"Toggle loading in HF layers\"", ")", "\n", "parser", ".", "add_argument", "(", "'--apply_loss'", ",", "default", "=", "True", ",", "type", "=", "bool", ",", "help", "=", "\"Calculate loss if running as single module\"", ")", "\n", "parser", ".", "add_argument", "(", "'--freeze_bert'", ",", "default", "=", "True", ",", "type", "=", "bool", ",", "help", "=", "\"Freeze underlying word level model\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.attn.MultiHeadedAttn.__init__": [[16, 33], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.PositionalFeedForward.__init__"], ["def", "__init__", "(", "self", ",", "num_heads", ",", "model_dim", ",", "dropout", "=", "0.1", ",", "use_final_linear", "=", "True", ")", ":", "\n", "        ", "super", "(", "MultiHeadedAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "model_dim", "%", "num_heads", "==", "0", "\n", "self", ".", "dim_per_head", "=", "model_dim", "//", "num_heads", "\n", "self", ".", "model_dim", "=", "model_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "\n", "self", ".", "linear_keys", "=", "nn", ".", "Linear", "(", "model_dim", ",", "num_heads", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "linear_vals", "=", "nn", ".", "Linear", "(", "model_dim", ",", "num_heads", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "model_dim", ",", "num_heads", "*", "self", ".", "dim_per_head", ")", "\n", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "use_final_linear", "=", "use_final_linear", "\n", "if", "self", ".", "use_final_linear", ":", "\n", "            ", "self", ".", "final_linear", "=", "nn", ".", "Linear", "(", "model_dim", ",", "model_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.attn.MultiHeadedAttn.forward": [[34, 138], ["shape.size", "shape.size", "attn.MultiHeadedAttn.MultiHeadedAttn.size", "attn.MultiHeadedAttn.MultiHeadedAttn.forward.shape"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "key", ",", "val", ",", "query", ",", "mask", "=", "None", ",", "layer_cache", "=", "None", ",", "dtype", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compute attention over context\n\n        Args:\n            key (FloatTensor): set of key_len key vectors ([batch, key_len, dim])\n            value (FloatTensor): set of key_len value vectors ([batch, key_len, dim])\n            query (FloatTensor): set of key_len query vectors ([batch, key_len, dim])\n            mask (BooleanTensor): binary mask indicating which keys have non-zero attn ([batch, query_len, key_len])\n\n        Returns:\n            (FloatTensor, FloatTensor):\n\n            * output context vectors [batch, query_len, dim]\n            * one of the attn vectors [batch, query_len, key_len]\n        \"\"\"", "\n", "\n", "batch_size", "=", "key", ".", "size", "(", "0", ")", "\n", "dim_per_head", "=", "self", ".", "dim_per_head", "\n", "num_heads", "=", "self", ".", "num_heads", "\n", "key_len", "=", "key", ".", "size", "(", "1", ")", "\n", "query_len", "=", "query", ".", "size", "(", "1", ")", "\n", "\n", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\" projection \"\"\"", "\n", "return", "x", ".", "view", "(", "batch_size", ",", "-", "1", ",", "num_heads", ",", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\" compute context \"\"\"", "\n", "return", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "num_heads", "*", "dim_per_head", ")", "\n", "\n", "", "if", "layer_cache", "is", "not", "None", ":", "\n", "            ", "if", "dtype", "==", "\"self\"", ":", "\n", "                ", "query", ",", "key", ",", "value", "=", "self", ".", "linear_query", "(", "query", ")", ",", "self", ".", "linear_keys", "(", "query", ")", ",", "self", ".", "linear_values", "(", "query", ")", "\n", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "\n", "if", "layer_cache", "is", "not", "None", ":", "\n", "                    ", "device", "=", "key", ".", "device", "\n", "if", "layer_cache", "[", "\"self_keys\"", "]", "is", "not", "None", ":", "\n", "                        ", "key", "=", "torch", ".", "cat", "(", "\n", "(", "layer_cache", "[", "\"self_keys\"", "]", ".", "to", "(", "device", ")", ",", "key", ")", ",", "\n", "dim", "=", "2", ")", "\n", "", "if", "layer_cache", "[", "\"self_values\"", "]", "is", "not", "None", ":", "\n", "                        ", "value", "=", "torch", ".", "cat", "(", "\n", "(", "layer_cache", "[", "\"self_values\"", "]", ".", "to", "(", "device", ")", ",", "value", ")", ",", "\n", "dim", "=", "2", ")", "\n", "", "layer_cache", "[", "\"self_keys\"", "]", "=", "key", "\n", "layer_cache", "[", "\"self_values\"", "]", "=", "value", "\n", "", "", "elif", "dtype", "==", "\"context\"", ":", "\n", "                ", "query", "=", "self", ".", "linear_query", "(", "query", ")", "\n", "if", "layer_cache", "is", "not", "None", ":", "\n", "                    ", "if", "layer_cache", "[", "\"memory_keys\"", "]", "is", "None", ":", "\n", "                        ", "key", ",", "value", "=", "self", ".", "linear_keys", "(", "key", ")", ",", "self", ".", "linear_values", "(", "value", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "", "else", ":", "\n", "                        ", "key", ",", "value", "=", "layer_cache", "[", "\"memory_keys\"", "]", ",", "layer_cache", "[", "\"memory_values\"", "]", "\n", "", "layer_cache", "[", "\"memory_keys\"", "]", "=", "key", "\n", "layer_cache", "[", "\"memory_values\"", "]", "=", "value", "\n", "", "else", ":", "\n", "                    ", "key", ",", "value", "=", "self", ".", "linear_keys", "(", "key", ")", ",", "self", ".", "linear_values", "(", "value", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "", "", "", "else", ":", "\n", "            ", "key", "=", "self", ".", "linear_keys", "(", "key", ")", "\n", "val", "=", "self", ".", "linear_vals", "(", "val", ")", "\n", "query", "=", "self", ".", "linear_query", "(", "query", ")", "\n", "\n", "key", "=", "shape", "(", "key", ")", "\n", "val", "=", "shape", "(", "val", ")", "\n", "\n", "", "query", "=", "shape", "(", "query", ")", "\n", "\n", "key_len", "=", "key", ".", "size", "(", "2", ")", "\n", "query_len", "=", "query", ".", "size", "(", "2", ")", "\n", "\n", "# calculate and scale scores", "\n", "query", "=", "query", "/", "math", ".", "sqrt", "(", "dim_per_head", ")", "\n", "scores", "=", "torch", ".", "matmul", "(", "query", ",", "key", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "~", "mask", "# mask fill replaces where mask == 1", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "scores", ")", "\n", "mask", "=", "mask", ".", "to", "(", "scores", ".", "get_device", "(", ")", ")", "\n", "scores", "=", "scores", ".", "masked_fill", "(", "mask", ",", "-", "1e18", ")", "\n", "\n", "# apply attn dropout and compute vectors", "\n", "", "attn", "=", "self", ".", "softmax", "(", "scores", ")", "\n", "drop_attn", "=", "self", ".", "drop", "(", "attn", ")", "\n", "\n", "if", "self", ".", "use_final_linear", ":", "\n", "            ", "context", "=", "unshape", "(", "torch", ".", "matmul", "(", "drop_attn", ",", "val", ")", ")", "\n", "output", "=", "self", ".", "final_linear", "(", "context", ")", "\n", "return", "output", "\n", "", "else", ":", "\n", "            ", "context", "=", "torch", ".", "matmul", "(", "drop_attn", ",", "val", ")", "\n", "return", "context", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder_layers.TransformerEncoderLayer.__init__": [[24, 30], ["torch.Module.__init__", "modeling.attn.MultiHeadedAttn", "modeling.neural.PositionalFeedForward", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.PositionalFeedForward.__init__"], ["def", "__init__", "(", "self", ",", "model_dim", ",", "nheads", ",", "ff_dim", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "TransformerEncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "MultiHeadedAttn", "(", "nheads", ",", "model_dim", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "feed_forward", "=", "PositionalFeedForward", "(", "model_dim", ",", "ff_dim", ",", "dropout", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "model_dim", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.encoder_layers.TransformerEncoderLayer.forward": [[31, 48], ["encoder_layers.TransformerEncoderLayer.layer_norm", "mask.unsqueeze.unsqueeze.unsqueeze", "encoder_layers.TransformerEncoderLayer.self_attn", "encoder_layers.TransformerEncoderLayer.feed_forward", "encoder_layers.TransformerEncoderLayer.drop"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        Transformer forward pass\n\n        Args:\n            inputs (FloatTensor): [batch_size, src_len, model_dim]\n            mask (LongTensor): [batch_size, src_len]\n        Returns:\n            (FloatTensor):\n\n            * outputs [batch_size, src_len, model_dim]\n        \"\"\"", "\n", "input_norm", "=", "self", ".", "layer_norm", "(", "inputs", ")", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "context", "=", "self", ".", "self_attn", "(", "input_norm", ",", "input_norm", ",", "input_norm", ",", "mask", "=", "mask", ")", "\n", "out", "=", "self", ".", "drop", "(", "context", ")", "+", "inputs", "\n", "return", "self", ".", "feed_forward", "(", "out", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.PositionalEncoding.__init__": [[306, 318], ["torch.Module.__init__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "pos_embed.unsqueeze.unsqueeze.unsqueeze", "neural.PositionalEncoding.register_buffer", "torch.Dropout", "torch.Dropout", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "math.log"], "methods", ["home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.PositionalFeedForward.__init__"], ["def", "__init__", "(", "self", ",", "dropout", ",", "dim", ",", "max_len", "=", "5000", ")", ":", "\n", "        ", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "pos_embed", "=", "torch", ".", "zeros", "(", "max_len", ",", "dim", ")", "\n", "position", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "unsqueeze", "(", "1", ")", "\n", "div_term", "=", "torch", ".", "exp", "(", "(", "torch", ".", "arange", "(", "0", ",", "dim", ",", "2", ",", "dtype", "=", "torch", ".", "float", ")", "*", "-", "(", "math", ".", "log", "(", "10000.0", ")", "/", "dim", ")", ")", ")", "\n", "\n", "pos_embed", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", ".", "float", "(", ")", "*", "div_term", ")", "\n", "pos_embed", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", ".", "float", "(", ")", "*", "div_term", ")", "\n", "pos_embed", "=", "pos_embed", ".", "unsqueeze", "(", "0", ")", "\n", "self", ".", "register_buffer", "(", "'pos_embed'", ",", "pos_embed", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.PositionalEncoding.forward": [[319, 328], ["neural.PositionalEncoding.dropout", "math.sqrt", "neural.PositionalEncoding.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "emb", ",", "step", "=", "None", ")", ":", "\n", "        ", "emb", "=", "emb", "*", "math", ".", "sqrt", "(", "self", ".", "dim", ")", "\n", "if", "step", ":", "\n", "            ", "emb", "=", "emb", "+", "self", ".", "pos_embed", "[", ":", ",", "step", "]", "[", ":", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "            ", "emb", "=", "emb", "+", "self", ".", "pos_embed", "[", ":", ",", ":", "emb", ".", "size", "(", "1", ")", "]", "\n", "\n", "", "emb", "=", "self", ".", "dropout", "(", "emb", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.PositionalEncoding.get_emb": [[329, 331], ["emb.size"], "methods", ["None"], ["", "def", "get_emb", "(", "self", ",", "emb", ")", ":", "\n", "        ", "return", "self", ".", "pos_embed", "[", ":", ",", ":", "emb", ".", "size", "(", "1", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.PositionalFeedForward.__init__": [[342, 350], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.PositionalFeedForward.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "ff_dim", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "PositionalFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer1", "=", "nn", ".", "Linear", "(", "input_dim", ",", "ff_dim", ")", "\n", "self", ".", "layer2", "=", "nn", ".", "Linear", "(", "ff_dim", ",", "input_dim", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "input_dim", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "drop1", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "drop2", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.PositionalFeedForward.forward": [[351, 356], ["neural.PositionalFeedForward.drop1", "neural.PositionalFeedForward.drop2", "neural.PositionalFeedForward.relu", "neural.PositionalFeedForward.layer2", "neural.PositionalFeedForward.layer1", "neural.PositionalFeedForward.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "layer1_out", "=", "self", ".", "drop1", "(", "self", ".", "relu", "(", "self", ".", "layer1", "(", "self", ".", "layer_norm", "(", "inputs", ")", ")", ")", ")", "\n", "layer2_out", "=", "self", ".", "drop2", "(", "self", ".", "layer2", "(", "layer1_out", ")", ")", "\n", "residual", "=", "layer2_out", "+", "inputs", "\n", "return", "residual", "\n", "", "", ""]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.metrics": [[11, 45], ["preds.cpu().numpy().astype.cpu().numpy().astype", "labels.cpu().numpy().astype.cpu().numpy().astype", "neural.calc_corr", "torch.tensor().to", "torch.tensor().to", "other_data[].cpu().numpy().astype", "neural.calc_corr", "torch.tensor().to", "torch.tensor().to", "score_dict.keys", "preds.cpu().numpy().astype.cpu().numpy", "labels.cpu().numpy().astype.cpu().numpy", "torch.tensor", "torch.tensor", "other_data[].cpu().numpy", "torch.tensor", "torch.tensor", "preds.cpu().numpy().astype.cpu", "labels.cpu().numpy().astype.cpu", "other_data[].cpu"], "function", ["home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.calc_corr", "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.calc_corr"], ["def", "metrics", "(", "loss", ",", "preds", ",", "metric_name", ",", "labels", "=", "None", ",", "other_data", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n        Determines the values of any desired metrics(Perplexity, F1, etc)\n        Currently returns MSE loss, Correlation, and Avg prediction loss/corr\n\n        args:\n            loss: from forward pass\n            preds: from forward pass\n            metric_name: Toggle between seen/unseen users\n            labels: target message for prediction\n            other_data: dictionary of other data to calculate metrics on\n        outputs:\n            results: dictionary of metrics and values\n    \"\"\"", "\n", "\n", "preds", "=", "preds", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "float", ")", "\n", "labels", "=", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "float", ")", "\n", "corr", "=", "calc_corr", "(", "labels", ",", "preds", ")", "\n", "\n", "corr_metric", "=", "metric_name", "+", "'_corr'", "\n", "\n", "# build score dictionary", "\n", "score_dict", "=", "{", "metric_name", ":", "loss", ",", "corr_metric", ":", "torch", ".", "tensor", "(", "corr", ")", ".", "to", "(", "loss", ".", "device", ")", "}", "\n", "\n", "if", "other_data", ":", "\n", "        ", "apreds", "=", "other_data", "[", "'apred'", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "float", ")", "\n", "aloss", "=", "other_data", "[", "'aloss'", "]", "\n", "acorr", "=", "calc_corr", "(", "labels", ",", "apreds", ")", "\n", "score_dict", "[", "metric_name", "+", "'_acorr'", "]", "=", "torch", ".", "tensor", "(", "acorr", ")", ".", "to", "(", "aloss", ".", "device", ")", "\n", "\n", "", "if", "'seen_user'", "in", "score_dict", ".", "keys", "(", ")", ":", "\n", "        ", "score_dict", "[", "'val_loss'", "]", "=", "score_dict", "[", "'seen_user'", "]", "# need val_loss present for saving", "\n", "\n", "", "return", "score_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.calc_sim": [[46, 60], ["numpy.transpose", "numpy.transpose", "sklearn.metrics.pairwise.cosine_similarity"], "function", ["None"], ["", "def", "calc_sim", "(", "labels", ",", "preds", ")", ":", "\n", "    ", "\"\"\"\n        Calculates cosine similaritiy between predicted message vector(s) and ground truth vector(s)\n\n        args:\n            labels: sequence of message vectors selected for masking\n            predS: output predictions for selected messages\n        outputs:\n            similaritiy: cosine similaritiy between all message predictions\n    \"\"\"", "\n", "labels", "=", "np", ".", "transpose", "(", "labels", ")", "\n", "preds", "=", "np", ".", "transpose", "(", "preds", ")", "\n", "\n", "return", "cosine_similarity", "(", "std_labels", ",", "std_preds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.calc_corr": [[61, 81], ["range", "numpy.mean", "numpy.std", "numpy.std", "numpy.mean", "avg_corr_obs.append", "numpy.mean", "numpy.mean", "scipy.stats.pearsonr"], "function", ["None"], ["", "def", "calc_corr", "(", "labels", ",", "preds", ")", ":", "\n", "    ", "\"\"\"\n        Calculaties pearson correlation between predicted message vector(s) and ground truth vector(s)\n\n        args:\n            labels: sequence of message vectors selected for masking\n            predS: output predictions for selected messages\n        outputs:\n            corr: average correlation across all message predictions\n    \"\"\"", "\n", "\n", "preds", "=", "(", "preds", "-", "np", ".", "mean", "(", "preds", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", ")", "/", "np", ".", "std", "(", "preds", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "labels", "=", "(", "labels", "-", "np", ".", "mean", "(", "preds", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", ")", "/", "np", ".", "std", "(", "preds", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "\n", "avg_corr_obs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "labels", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "corr", "=", "np", ".", "mean", "(", "pearsonr", "(", "preds", "[", "i", "]", ",", "labels", "[", "i", "]", ")", "[", "0", "]", ")", "\n", "avg_corr_obs", ".", "append", "(", "corr", ")", "\n", "\n", "", "return", "np", ".", "mean", "(", "avg_corr_obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.calc_avg_preds": [[82, 113], ["torch.tensor", "torch.tensor", "enumerate", "cat_tensors.to", "range", "range", "torch.sum", "torch.sum", "neural.cat_tensors", "usr[].cpu().data.numpy", "usr_real_msgs.append", "torch.Tensor", "torch.Tensor", "usr_masked_msgs[].item", "usr_attn_mask[].item", "usr_masked_msgs.to", "usr_masked_unmasked_msgs.to", "numpy.mean", "usr[].cpu"], "function", ["home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.cat_tensors"], ["", "def", "calc_avg_preds", "(", "usr_batches", ",", "msg_mask", ",", "attn_mask", ",", "msg_unmasked", ")", ":", "\n", "    ", "\"\"\"\n        Calculate average message vector of user sequence ignoring masked messages. Used as baseline\n        predictor\n\n        args:\n            usr_batches: sequences of user messages. shape=[num_usr, num_msgs, embed_dim]\n            msg_mask: boolean tensor set to 1 where a message is selected for masking. Used to ignore message in average calculation\n            attn_mask: boolean tensor set to 1 where a message is real and 0 whee pad. Used to ignore pad tokens in average calculation\n            msg_unmasked: boolean tensor set to 1 where a message is selected for masking but is left alone (10% chance)\n        output:\n            avg_preds: collection of average predictions per user sequence. shape=[num_usr, embed_dim]\n    \"\"\"", "\n", "new_avg_preds", "=", "torch", ".", "tensor", "(", "[", "]", ")", "\n", "\n", "for", "idx", ",", "usr", "in", "enumerate", "(", "usr_batches", ")", ":", "\n", "        ", "usr_masked_msgs", "=", "msg_mask", "[", "idx", "]", "\n", "usr_masked_unmasked_msgs", "=", "msg_unmasked", "[", "idx", "]", "# masked msgs that 10% don't actually get masked", "\n", "usr_attn_mask", "=", "attn_mask", "[", "idx", "]", "\n", "usr_real_msgs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "usr", ".", "shape", "[", "0", "]", ")", ":", "\n", "# if msg is a real one (non-mask and non-pad)", "\n", "            ", "if", "usr_masked_msgs", "[", "i", "]", ".", "item", "(", ")", "==", "False", "and", "usr_attn_mask", "[", "i", "]", ".", "item", "(", ")", "==", "True", ":", "\n", "                ", "msg_vec", "=", "usr", "[", "i", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "usr_real_msgs", ".", "append", "(", "msg_vec", ")", "\n", "\n", "# use avg prediction for as many masked msg in usr seq", "\n", "", "", "for", "_", "in", "range", "(", "torch", ".", "sum", "(", "usr_masked_msgs", ".", "to", "(", "dtype", "=", "torch", ".", "long", ")", "-", "usr_masked_unmasked_msgs", ".", "to", "(", "dtype", "=", "torch", ".", "long", ")", ")", ")", ":", "\n", "            ", "new_avg_preds", "=", "cat_tensors", "(", "new_avg_preds", ",", "torch", ".", "Tensor", "(", "np", ".", "mean", "(", "usr_real_msgs", ",", "axis", "=", "0", ")", ")", ")", "\n", "\n", "", "", "return", "new_avg_preds", ".", "to", "(", "usr_batches", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.cat_tensors": [[115, 123], ["torch.cat.detach", "tensor2.unsqueeze", "torch.cat", "torch.cat", "tensor2.unsqueeze"], "function", ["None"], ["", "def", "cat_tensors", "(", "tensor1", ",", "tensor2", ")", ":", "\n", "    ", "if", "tensor1", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "        ", "tensor1", "=", "tensor2", ".", "unsqueeze", "(", "0", ")", "\n", "", "else", ":", "\n", "        ", "tensor1", "=", "torch", ".", "cat", "(", "(", "tensor1", ",", "tensor2", ".", "unsqueeze", "(", "0", ")", ")", ",", "0", ")", "\n", "\n", "", "tensor1", ".", "detach", "(", ")", "\n", "return", "tensor1", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.batch_by_usr": [[124, 245], ["dict", "usr_id.reshape.reshape", "enumerate", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "dict.items", "torch.BoolTensor", "torch.BoolTensor", "torch.BoolTensor", "torch.BoolTensor", "torch.BoolTensor", "torch.BoolTensor", "torch.BoolTensor", "torch.BoolTensor", "str", "len", "torch.Tensor().type", "torch.Tensor().type", "numpy.random.randint", "enumerate", "range", "torch.BoolTensor.append", "unmasked.append", "neural.cat_tensors", "torch.BoolTensor.append", "dict.keys", "usr_id[].item", "neural.cat_tensors", "any", "neural.cat_tensors", "usr_msgs.append", "neural.cat_tensors", "usr_msgs.append", "usr_masks.append", "usr_masks_unswapped.append", "torch.isnan().item", "torch.isnan().item", "torch.sum().item", "torch.sum().item", "torch.unsqueeze", "torch.unsqueeze", "len", "torch.Tensor", "torch.Tensor", "usr_masks.append", "usr_masks_unswapped.append", "torch.BoolTensor.append", "neural.cat_tensors", "numpy.random.randint", "usr_masks.append", "usr_masks_unswapped.append", "pad_vec.clone().detach", "numpy.random.randint", "torch.isnan", "torch.isnan", "torch.sum", "torch.sum", "mask_vec.clone().detach", "usr_masks_unswapped.pop", "usr_masks_unswapped.append", "torch.BoolTensor.pop", "torch.BoolTensor.append", "pad_vec.clone", "torch.sum", "torch.sum", "numpy.random.randint", "mask_vec.clone"], "function", ["home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.cat_tensors", "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.cat_tensors", "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.cat_tensors", "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.cat_tensors", "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.cat_tensors"], ["", "def", "batch_by_usr", "(", "batch", ",", "usr_id", ",", "pad_vec", ",", "mask_vec", ",", "max_num_msgs", "=", "512", ",", "mask_rate", "=", "15", ")", ":", "\n", "        ", "\"\"\"\n            Organizes message vectors by their user_id. Selects which messages to be masked and builds\n            the attn_mask & other boolean sequences.\n\n            args:\n                batch: collection of message vectors shape=[msg_num, emb_dim]\n                usr_id: ordered list of user_ids (assumption: matches order of msg's)\n                pad_vec: encoder embedding for a pad token\n                mask_vec: encoder embedding for a mask token\n                max_num_msgs: hard cut off for message sequence length per user(default=512)\n                mask_rate: percent of messages to mask per user\n            outputs:\n                msg_batch: grouped msg vectors shape==[num_user, max_num_msgs, emb_dim]\n                unpadded: a boolean mask of real messages vs pad tokens\n                inverse_mask: a boolean mask highlighting which messages are selected for masking\n                labels: selected messages to be masked\n        \"\"\"", "\n", "\n", "# Groups msg vectors by user_id", "\n", "msg_seq_by_usr", "=", "dict", "(", ")", "\n", "usr_id", "=", "usr_id", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "for", "idx", ",", "msg_vec", "in", "enumerate", "(", "batch", ")", ":", "\n", "            ", "uid", "=", "str", "(", "usr_id", "[", "idx", "]", ".", "item", "(", ")", ")", "\n", "\n", "if", "torch", ".", "isnan", "(", "torch", ".", "sum", "(", "msg_vec", ")", ")", ".", "item", "(", ")", "==", "True", "or", "torch", ".", "sum", "(", "msg_vec", ")", ".", "item", "(", ")", "==", "0", ":", "\n", "                ", "continue", "# skip the fake padded messages from batching", "\n", "", "try", ":", "\n", "                ", "msg_seq_by_usr", "[", "uid", "]", "=", "cat_tensors", "(", "msg_seq_by_usr", "[", "uid", "]", ",", "msg_vec", ")", "\n", "", "except", "KeyError", ":", "\n", "                ", "msg_seq_by_usr", "[", "uid", "]", "=", "torch", ".", "unsqueeze", "(", "msg_vec", ",", "0", ")", "\n", "\n", "\n", "# initialize output variables", "\n", "", "", "msg_batch", "=", "torch", ".", "Tensor", "(", "[", "]", ")", "\n", "labels", "=", "torch", ".", "Tensor", "(", "[", "]", ")", "\n", "unpadded", "=", "[", "]", "\n", "inverse", "=", "[", "]", "\n", "unmasked", "=", "[", "]", "\n", "unmasked_labels", "=", "[", "]", "\n", "\n", "# perform masking and padding to user sequences", "\n", "for", "k", ",", "v", "in", "msg_seq_by_usr", ".", "items", "(", ")", ":", "\n", "            ", "usr_msgs", "=", "[", "]", "\n", "usr_masks", "=", "[", "]", "# binary mask for if a message was selected for masking or not ", "\n", "usr_masks_unswapped", "=", "[", "]", "# binary mask for if a message was \"masked\" but not actually", "\n", "msg_seq_len", "=", "len", "(", "v", ")", "\n", "\n", "if", "msg_seq_len", "<", "max_num_msgs", ":", "\n", "                ", "pad_amt", "=", "max_num_msgs", "-", "len", "(", "v", ")", "\n", "upper_bound", "=", "msg_seq_len", "\n", "", "else", ":", "\n", "                ", "pad_amt", "=", "0", "\n", "upper_bound", "=", "max_num_msgs", "\n", "\n", "\n", "", "masked_seq", "=", "torch", ".", "Tensor", "(", "[", "]", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "\n", "# uniform likelihood of 0-100 for length of user's sequence", "\n", "usr_masked_idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "101", ",", "upper_bound", ")", "\n", "\n", "# each user gets at least 1 message masked", "\n", "if", "not", "any", "(", "e", "<", "mask_rate", "for", "e", "in", "usr_masked_idx", ")", ":", "\n", "                ", "usr_masked_idx", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "upper_bound", ")", "]", "=", "-", "1", "\n", "\n", "", "for", "idx", ",", "msg", "in", "enumerate", "(", "v", ")", ":", "\n", "# if user hit cap then stop adding", "\n", "                ", "if", "idx", ">=", "max_num_msgs", ":", "\n", "                    ", "break", "\n", "\n", "# apply masking to actual sequence and gen atn_masks", "\n", "# if msg is selected for mask 3 options", "\n", "# 1. just mask it (80%)", "\n", "# 2. replace with random msg (10%)", "\n", "# 3. don't mask it (10%)", "\n", "", "if", "usr_masked_idx", "[", "idx", "]", "<", "mask_rate", ":", "\n", "                    ", "usr_masks", ".", "append", "(", "1", ")", "\n", "usr_masks_unswapped", ".", "append", "(", "0", ")", "\n", "unmasked_labels", ".", "append", "(", "0", ")", "\n", "\n", "labels", "=", "cat_tensors", "(", "labels", ",", "msg", ")", "# label is always original message", "\n", "\n", "mask_option", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "101", ")", "\n", "\n", "if", "mask_option", "<", "10", ":", "\n", "                        ", "msg", "=", "batch", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "batch", ".", "shape", "[", "0", "]", ")", "]", "\n", "", "elif", "mask_option", ">", "20", ":", "\n", "                        ", "msg", "=", "mask_vec", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "# 10-20 is for leaving msg as is", "\n", "                        ", "usr_masks_unswapped", ".", "pop", "(", ")", "\n", "usr_masks_unswapped", ".", "append", "(", "1", ")", "\n", "unmasked_labels", ".", "pop", "(", ")", "\n", "unmasked_labels", ".", "append", "(", "1", ")", "\n", "\n", "", "", "else", ":", "\n", "                    ", "usr_masks", ".", "append", "(", "0", ")", "\n", "usr_masks_unswapped", ".", "append", "(", "0", ")", "\n", "\n", "", "masked_seq", "=", "cat_tensors", "(", "masked_seq", ",", "msg", ")", "# masked seq gets mask, original, or random msg", "\n", "usr_msgs", ".", "append", "(", "1", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "pad_amt", ")", ":", "\n", "                ", "masked_seq", "=", "cat_tensors", "(", "masked_seq", ",", "pad_vec", ".", "clone", "(", ")", ".", "detach", "(", ")", ")", "\n", "usr_msgs", ".", "append", "(", "0", ")", "\n", "usr_masks", ".", "append", "(", "0", ")", "\n", "usr_masks_unswapped", ".", "append", "(", "0", ")", "\n", "\n", "# stack inverse mask ", "\n", "", "inverse", ".", "append", "(", "usr_masks", ")", "\n", "unmasked", ".", "append", "(", "usr_masks_unswapped", ")", "\n", "msg_batch", "=", "cat_tensors", "(", "msg_batch", ",", "masked_seq", ")", "\n", "unpadded", ".", "append", "(", "usr_msgs", ")", "\n", "\n", "", "unpadded", "=", "torch", ".", "BoolTensor", "(", "unpadded", ")", "\n", "inverse", "=", "torch", ".", "BoolTensor", "(", "inverse", ")", "\n", "fake_masks", "=", "torch", ".", "BoolTensor", "(", "unmasked", ")", "\n", "unmasked_labels", "=", "torch", ".", "BoolTensor", "(", "unmasked_labels", ")", "\n", "\n", "# batch, attn_mask, masked_msgs, labels, ordered_usr_id", "\n", "return", "msg_batch", ",", "unpadded", ",", "(", "inverse", ",", "fake_masks", ")", ",", "(", "labels", ",", "unmasked_labels", ")", ",", "msg_seq_by_usr", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.batch_by_usr_no_mask": [[246, 296], ["dict", "usr_id.reshape.reshape", "enumerate", "torch.Tensor().type", "torch.Tensor().type", "dict.items", "torch.BoolTensor", "torch.BoolTensor", "str", "len", "torch.Tensor", "torch.Tensor", "enumerate", "range", "neural.cat_tensors", "torch.BoolTensor.append", "dict.keys", "usr_id[].item", "neural.cat_tensors", "torch.Tensor", "torch.Tensor", "neural.cat_tensors", "usr_mask.append", "neural.cat_tensors", "usr_mask.append", "torch.unsqueeze", "torch.unsqueeze", "len", "pad_vec.clone().detach", "pad_vec.clone"], "function", ["home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.cat_tensors", "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.cat_tensors", "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.cat_tensors", "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.neural.cat_tensors"], ["", "def", "batch_by_usr_no_mask", "(", "batch", ",", "usr_id", ",", "pad_vec", ",", "max_num_msgs", "=", "512", ")", ":", "\n", "    ", "\"\"\"\n        Same as batch_by_usr without the masking logic. Used when not pre-training (e.g. fine-tuning) where we do not\n        want to mask since we are not doing the MLM task.\n    \"\"\"", "\n", "\n", "# Groups msg vectors by user_id", "\n", "msg_seq_by_usr", "=", "dict", "(", ")", "\n", "usr_id", "=", "usr_id", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "for", "idx", ",", "msg_vec", "in", "enumerate", "(", "batch", ")", ":", "\n", "        ", "uid", "=", "str", "(", "usr_id", "[", "idx", "]", ".", "item", "(", ")", ")", "\n", "try", ":", "\n", "            ", "msg_seq_by_usr", "[", "uid", "]", "=", "cat_tensors", "(", "msg_seq_by_usr", "[", "uid", "]", ",", "msg_vec", ")", "#torch.cat( (msg_seq_by_usr[uid], msg_vec.unsqueeze(0)), 0)", "\n", "", "except", "KeyError", ":", "\n", "            ", "msg_seq_by_usr", "[", "uid", "]", "=", "torch", ".", "unsqueeze", "(", "msg_vec", ",", "0", ")", "\n", "\n", "# initialize output variables", "\n", "", "", "msg_batch", "=", "torch", ".", "Tensor", "(", "[", "]", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "attn_mask", "=", "[", "]", "\n", "\n", "# perform padding to user sequences", "\n", "for", "k", ",", "v", "in", "msg_seq_by_usr", ".", "items", "(", ")", ":", "\n", "        ", "usr_mask", "=", "[", "]", "# mask out pad vectors from real ones for attn", "\n", "msg_seq_len", "=", "len", "(", "v", ")", "\n", "usr_seq", "=", "torch", ".", "Tensor", "(", "[", "]", ")", "\n", "\n", "if", "msg_seq_len", "<", "max_num_msgs", ":", "\n", "            ", "pad_amt", "=", "max_num_msgs", "-", "len", "(", "v", ")", "\n", "", "else", ":", "\n", "            ", "pad_amt", "=", "0", "\n", "\n", "", "for", "idx", ",", "msg", "in", "enumerate", "(", "v", ")", ":", "\n", "# if user hit cap then stop adding", "\n", "            ", "if", "idx", ">=", "max_num_msgs", ":", "\n", "                ", "break", "\n", "\n", "", "usr_seq", "=", "cat_tensors", "(", "usr_seq", ",", "msg", ")", "\n", "usr_mask", ".", "append", "(", "1", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "pad_amt", ")", ":", "\n", "            ", "usr_seq", "=", "cat_tensors", "(", "usr_seq", ",", "pad_vec", ".", "clone", "(", ")", ".", "detach", "(", ")", ")", "\n", "usr_mask", ".", "append", "(", "0", ")", "\n", "\n", "", "msg_batch", "=", "cat_tensors", "(", "msg_batch", ",", "usr_seq", ")", "\n", "attn_mask", ".", "append", "(", "usr_mask", ")", "\n", "\n", "", "attn_mask", "=", "torch", ".", "BoolTensor", "(", "attn_mask", ")", "\n", "\n", "return", "msg_batch", ",", "attn_mask", ",", "msg_seq_by_usr", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.data_handler.open_data": [[24, 49], ["sqlalchemy.engine.url.URL", "sqlalchemy.create_engine", "sqlalchemy.create_engine.connect", "print", "engine.connect.execute", "pandas.DataFrame", "conn.execute.keys", "print", "engine.connect.close", "conn.execute.fetchall", "pd.DataFrame.message.notnull"], "function", ["None"], ["def", "open_data", "(", "table", ")", ":", "\n", "    ", "\"\"\"\n        Opens connection to HuLM DB and generates a pd.DataFrame\n        from selected tables\n\n        note: Currently only supports small facebook data\n    \"\"\"", "\n", "\n", "myDB", "=", "URL", "(", "drivername", "=", "'mysql'", ",", "host", "=", "'localhost'", ",", "\n", "database", "=", "'HuLM'", ",", "query", "=", "{", "'read_default_file'", ":", "'~/.my.cnf'", ",", "'charset'", ":", "'utf8mb4'", "}", ")", "\n", "engine", "=", "create_engine", "(", "myDB", ",", "encoding", "=", "'latin1'", ")", "\n", "conn", "=", "engine", ".", "connect", "(", ")", "\n", "\n", "print", "(", "'Fetching data...'", ")", "\n", "\n", "select", "=", "conn", ".", "execute", "(", "'select user_id, message_id, message, updated_time from '", "+", "table", "+", "' order by user_id, updated_time'", ")", "\n", "df", "=", "pd", ".", "DataFrame", "(", "select", ".", "fetchall", "(", ")", ")", "\n", "df", ".", "columns", "=", "select", ".", "keys", "(", ")", "\n", "\n", "df", "=", "df", "[", "df", ".", "message", ".", "notnull", "(", ")", "]", "\n", "\n", "print", "(", "f'data load from {table} complete'", ")", "\n", "\n", "conn", ".", "close", "(", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.data_handler.transform_usr_data": [[52, 139], ["time.time", "print", "RobertaTokenizerFast.from_pretrained.batch_encode_plus", "print", "df.to_numpy", "print", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "torch.tensor.copy().items", "numpy.array", "numpy.array", "numpy.array", "print", "print", "print", "torch.tensor", "torch.tensor", "torch.tensor", "print", "transformers.DistilBertTokenizerFast.from_pretrained", "transformers.RobertaTokenizerFast.from_pretrained", "RobertaTokenizerFast.from_pretrained.encode_plus", "df[].values.tolist", "str", "list", "list", "list", "len", "msgs_by_usr[].append", "attn_mask_by_usr[].append", "usr_list[].append", "range", "torch.tensor.copy", "len", "torch.tensor.values", "torch.tensor.values", "collections.defaultdict.values", "time.time", "time.time", "int", "len", "k.split", "range", "time.time", "str", "msgs_by_usr[].append", "attn_mask_by_usr[].append", "usr_list[].append", "int", "data_handler.transform_usr_data.tokenize"], "function", ["None"], ["", "def", "transform_usr_data", "(", "df", ",", "max_seq_len", ",", "msg_seq_len", "=", "5", ",", "bert_type", "=", "'distilbert-base-uncased'", ")", ":", "\n", "    ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'START TOKENIZATION...'", ")", "\n", "\n", "if", "bert_type", "==", "'distilbert-base-uncased'", ":", "\n", "        ", "tokenizer", "=", "DistilBertTokenizerFast", ".", "from_pretrained", "(", "bert_type", ")", "\n", "", "else", ":", "# distil-roberta version", "\n", "        ", "tokenizer", "=", "RobertaTokenizerFast", ".", "from_pretrained", "(", "'distilroberta-base'", ")", "\n", "\n", "", "def", "tokenize", "(", "data", ")", ":", "\n", "        ", "return", "tokenizer", ".", "encode_plus", "(", "data", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "max_seq_len", ",", "pad_to_max_length", "=", "True", ",", "truncation_strategy", "=", "'longest_first'", ")", "\n", "\n", "", "all_tokens", "=", "tokenizer", ".", "batch_encode_plus", "(", "df", "[", "'message'", "]", ".", "values", ".", "tolist", "(", ")", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "max_seq_len", ",", "pad_to_max_length", "=", "True", ",", "truncation_strategy", "=", "'longest_first'", ")", "\n", "print", "(", "'BATCH_ENCODE  %s ----'", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "df", "[", "'input_ids'", "]", "=", "all_tokens", "[", "'input_ids'", "]", "\n", "df", "[", "'attention_mask'", "]", "=", "all_tokens", "[", "'attention_mask'", "]", "\n", "\n", "df_np", "=", "df", ".", "to_numpy", "(", ")", "\n", "print", "(", "\"--- end HF tokenizer %s ---\"", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "\n", "# gather messages by usr_id", "\n", "msgs_by_usr", "=", "defaultdict", "(", "list", ")", "\n", "attn_mask_by_usr", "=", "defaultdict", "(", "list", ")", "\n", "usr_list", "=", "defaultdict", "(", "list", ")", "\n", "for", "usr_msg", "in", "df_np", ":", "\n", "#usr_id, msg_id, msg, timestamp, tokenized = usr_msg", "\n", "        ", "usr_id", ",", "msg_id", ",", "msg", ",", "timestamp", ",", "input_ids", ",", "att_mask", "=", "usr_msg", "\n", "usr_id", "=", "str", "(", "usr_id", ")", "\n", "\n", "if", "len", "(", "msgs_by_usr", "[", "usr_id", "]", ")", "<", "msg_seq_len", ":", "\n", "            ", "msgs_by_usr", "[", "usr_id", "]", ".", "append", "(", "input_ids", ")", "\n", "attn_mask_by_usr", "[", "usr_id", "]", ".", "append", "(", "att_mask", ")", "\n", "usr_list", "[", "usr_id", "]", ".", "append", "(", "int", "(", "usr_id", ")", ")", "\n", "", "else", ":", "# treat usrs with more than max msgs as separate users", "\n", "            ", "for", "num", "in", "range", "(", "1", ",", "100", ")", ":", "\n", "                ", "alt_id", "=", "usr_id", "+", "'_'", "+", "str", "(", "num", ")", "\n", "# alternate ID for user is tracked up to max if exists", "\n", "if", "alt_id", "in", "msgs_by_usr", ".", "keys", "(", ")", "and", "len", "(", "msgs_by_usr", "[", "alt_id", "]", ")", "<", "msg_seq_len", ":", "\n", "                    ", "msgs_by_usr", "[", "alt_id", "]", ".", "append", "(", "input_ids", ")", "\n", "attn_mask_by_usr", "[", "alt_id", "]", ".", "append", "(", "att_mask", ")", "\n", "usr_list", "[", "alt_id", "]", ".", "append", "(", "int", "(", "alt_id", ")", ")", "\n", "break", "\n", "", "elif", "alt_id", "not", "in", "msgs_by_usr", ".", "keys", "(", ")", ":", "# add alternate ID for user", "\n", "                    ", "msgs_by_usr", "[", "alt_id", "]", ".", "append", "(", "input_ids", ")", "\n", "attn_mask_by_usr", "[", "alt_id", "]", ".", "append", "(", "att_mask", ")", "\n", "usr_list", "[", "alt_id", "]", ".", "append", "(", "int", "(", "alt_id", ")", ")", "\n", "break", "# only create the 1 proxy user we need, don't loop all", "\n", "\n", "# ensure all \"users\" have padded sequence to msg_seq_len so tensor is not jagged", "\n", "", "", "", "", "for", "k", ",", "v", "in", "msgs_by_usr", ".", "copy", "(", ")", ".", "items", "(", ")", ":", "\n", "        ", "if", "len", "(", "v", ")", "<", "msg_seq_len", ":", "\n", "            ", "missing_amt", "=", "msg_seq_len", "-", "len", "(", "msgs_by_usr", "[", "k", "]", ")", "\n", "# get most recent messages if usr is over the max", "\n", "# case wehre they are under is not handled as max should always equal min user msgs", "\n", "if", "'_'", "in", "k", ":", "\n", "                ", "orig_id", ",", "alt_ver", "=", "k", ".", "split", "(", "'_'", ")", "\n", "if", "int", "(", "alt_ver", ")", ">", "1", ":", "\n", "                    ", "recent_id", "=", "orig_id", "+", "'_'", "+", "str", "(", "int", "(", "alt_ver", ")", "-", "1", ")", "\n", "", "else", ":", "\n", "                    ", "recent_id", "=", "orig_id", "\n", "\n", "", "msgs_by_usr", "[", "k", "]", "=", "msgs_by_usr", "[", "recent_id", "]", "[", "-", "missing_amt", ":", "]", "+", "msgs_by_usr", "[", "k", "]", "\n", "attn_mask_by_usr", "[", "k", "]", "=", "attn_mask_by_usr", "[", "recent_id", "]", "[", "-", "missing_amt", ":", "]", "+", "attn_mask_by_usr", "[", "k", "]", "\n", "usr_list", "[", "k", "]", "=", "missing_amt", "*", "[", "int", "(", "k", ")", "]", "+", "usr_list", "[", "k", "]", "\n", "", "else", ":", "\n", "                ", "for", "_", "in", "range", "(", "missing_amt", ")", ":", "\n", "                    ", "fake_msg", "=", "'[PAD]'", "\n", "tokenized", "=", "tokenize", "(", "fake_msg", ")", "\n", "tokenized", "[", "'attention_mask'", "]", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "msgs_by_usr", "[", "k", "]", ".", "append", "(", "input_ids", ")", "\n", "attn_mask_by_usr", "[", "k", "]", ".", "append", "(", "att_mask", ")", "\n", "usr_list", "[", "k", "]", ".", "append", "(", "int", "(", "k", ")", ")", "\n", "\n", "", "", "", "", "attn_mask_by_usr", "=", "np", ".", "array", "(", "list", "(", "attn_mask_by_usr", ".", "values", "(", ")", ")", ")", "\n", "msgs_by_usr", "=", "np", ".", "array", "(", "list", "(", "msgs_by_usr", ".", "values", "(", ")", ")", ")", "\n", "usr_ids", "=", "np", ".", "array", "(", "list", "(", "usr_list", ".", "values", "(", ")", ")", ")", "\n", "\n", "print", "(", "'attnusr: '", ",", "attn_mask_by_usr", ".", "shape", ")", "\n", "print", "(", "'msgusr: '", ",", "msgs_by_usr", ".", "shape", ")", "\n", "print", "(", "'usrids: '", ",", "usr_ids", ".", "shape", ")", "\n", "\n", "msgs_by_usr", "=", "torch", ".", "tensor", "(", "msgs_by_usr", ")", "\n", "attn_mask_by_usr", "=", "torch", ".", "tensor", "(", "attn_mask_by_usr", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "usr_ids", "=", "torch", ".", "tensor", "(", "usr_ids", ")", "\n", "\n", "print", "(", "\"--- total %s seconds ---\"", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "return", "msgs_by_usr", ",", "attn_mask_by_usr", ",", "usr_ids", "#, usr_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.data_handler.dataloader": [[141, 153], ["data_handler.open_data", "data_handler.transform_usr_data", "torch.utils.data.TensorDataset", "torch.utils.data.DataLoader", "torch.utils.data.distributed.DistributedSampler"], "function", ["home.repos.pwc.inspect_result.matthewmatero_melt.modeling.data_handler.open_data", "home.repos.pwc.inspect_result.matthewmatero_melt.modeling.data_handler.transform_usr_data"], ["", "def", "dataloader", "(", "table", ",", "max_seq_len", ",", "batch_size", ",", "msg_seq_len", "=", "20", ",", "use_ddp", "=", "False", ")", ":", "\n", "    ", "df", "=", "open_data", "(", "table", ")", "\n", "padded", ",", "attn_mask", ",", "usr_id", "=", "transform_usr_data", "(", "df", ",", "max_seq_len", ",", "msg_seq_len", ")", "\n", "\n", "dataset", "=", "TensorDataset", "(", "padded", ",", "attn_mask", ",", "usr_id", ")", "# no labels", "\n", "\n", "if", "use_ddp", ":", "\n", "        ", "train_sampler", "=", "DistributedSampler", "(", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "train_sampler", "=", "None", "\n", "\n", "", "return", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ",", "sampler", "=", "train_sampler", ",", "num_workers", "=", "-", "1", ")", "\n", "\n"]]}