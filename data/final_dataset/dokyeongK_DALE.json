{"home.repos.pwc.inspect_result.dokyeongK_DALE.test.test_DALEGAN.main": [[7, 28], ["model.VisualAttentionNetwork.VisualAttentionNetwork", "torch.load", "VisualAttentionNetwork.VisualAttentionNetwork.load_state_dict", "model.EnhancementNet.EnhancementNet", "torch.load", "EnhancementNet.EnhancementNet.load_state_dict", "data.dataset_DALE.DALETest", "torch.utils.data.DataLoader", "VisualAttentionNetwork.VisualAttentionNetwork.cuda", "EnhancementNet.EnhancementNet.cuda", "test_DALEGAN.test"], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.train.training_EN.test"], ["def", "main", "(", ")", ":", "\n", "    ", "benchmark", "=", "[", "'datasets__DICM'", ",", "'datasets__LIME'", ",", "'datasets__MEF'", ",", "'datasets__NPE'", ",", "'dark_face'", "]", "\n", "test_data_root", "=", "'D:\\data\\DALE/benchmark/'", "+", "benchmark", "[", "4", "]", "\n", "model_root", "=", "'../checkpoint/'", "\n", "test_result_root_dir", "=", "'../EN_TEST/'", "\n", "\n", "VAN", "=", "VisualAttentionNetwork", ".", "VisualAttentionNetwork", "(", ")", "# LessNet_Update.LessNet()#AttentionNet.AttenteionNet(stride=1)", "\n", "state_dict1", "=", "torch", ".", "load", "(", "model_root", "+", "'visual_attention_network_model.pth'", ")", "\n", "VAN", ".", "load_state_dict", "(", "state_dict1", ")", "\n", "\n", "EN", "=", "EnhancementNet", ".", "EnhancementNet", "(", ")", "\n", "state_dict2", "=", "torch", ".", "load", "(", "model_root", "+", "'DALEGAN_model.pth'", ")", "\n", "EN", ".", "load_state_dict", "(", "state_dict2", ")", "\n", "\n", "test_data", "=", "dataset_DALE", ".", "DALETest", "(", "test_data_root", ")", "\n", "loader_test", "=", "DataLoader", "(", "test_data", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "\n", "VAN", ".", "cuda", "(", ")", "\n", "EN", ".", "cuda", "(", ")", "\n", "\n", "test", "(", "loader_test", ",", "VAN", ",", "EN", ",", "test_result_root_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.test.test_DALEGAN.test": [[30, 44], ["VAN.eval", "EN.eval", "enumerate", "testImg.cuda.cuda", "torch.no_grad", "VAN", "EN", "train.train_utils.tensor2im", "train.train_utils.save_images", "img_name[].split"], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.tensor2im", "home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.save_images"], ["", "def", "test", "(", "loader_test", ",", "VAN", ",", "EN", ",", "root_dir", ")", ":", "\n", "    ", "VAN", ".", "eval", "(", ")", "\n", "EN", ".", "eval", "(", ")", "\n", "\n", "for", "itr", ",", "data", "in", "enumerate", "(", "loader_test", ")", ":", "\n", "        ", "testImg", ",", "img_name", "=", "data", "[", "0", "]", ",", "data", "[", "1", "]", "\n", "testImg", "=", "testImg", ".", "cuda", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "visual_attention_map", "=", "VAN", "(", "testImg", ")", "\n", "enhance_result", "=", "EN", "(", "testImg", ",", "visual_attention_map", ")", "\n", "enhance_result_img", "=", "train_utils", ".", "tensor2im", "(", "enhance_result", ")", "\n", "result_save_dir", "=", "root_dir", "+", "'enhance'", "+", "img_name", "[", "0", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "(", "'.jpg'", ")", "\n", "train_utils", ".", "save_images", "(", "enhance_result_img", ",", "result_save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.test.test_DALE.main": [[7, 28], ["model.VisualAttentionNetwork.VisualAttentionNetwork", "torch.load", "VisualAttentionNetwork.VisualAttentionNetwork.load_state_dict", "model.EnhancementNet.EnhancementNet", "torch.load", "EnhancementNet.EnhancementNet.load_state_dict", "data.dataset_DALE.DALETest", "torch.utils.data.DataLoader", "VisualAttentionNetwork.VisualAttentionNetwork.cuda", "EnhancementNet.EnhancementNet.cuda", "test_DALE.test"], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.train.training_EN.test"], ["def", "main", "(", ")", ":", "\n", "    ", "benchmark", "=", "[", "'datasets__DICM'", ",", "'datasets__LIME'", ",", "'datasets__MEF'", ",", "'datasets__NPE'", "]", "\n", "test_data_root", "=", "'D:\\data\\DALE/benchmark/'", "+", "benchmark", "[", "0", "]", "\n", "model_root", "=", "'../checkpoint/'", "\n", "test_result_root_dir", "=", "'../EN_TEST/'", "\n", "\n", "VAN", "=", "VisualAttentionNetwork", ".", "VisualAttentionNetwork", "(", ")", "\n", "state_dict1", "=", "torch", ".", "load", "(", "model_root", "+", "'VAN.pth'", ")", "\n", "VAN", ".", "load_state_dict", "(", "state_dict1", ")", "\n", "\n", "EN", "=", "EnhancementNet", ".", "EnhancementNet", "(", ")", "\n", "state_dict2", "=", "torch", ".", "load", "(", "model_root", "+", "'EN.pth'", ")", "\n", "EN", ".", "load_state_dict", "(", "state_dict2", ")", "\n", "\n", "test_data", "=", "dataset_DALE", ".", "DALETest", "(", "test_data_root", ")", "\n", "loader_test", "=", "DataLoader", "(", "test_data", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "\n", "VAN", ".", "cuda", "(", ")", "\n", "EN", ".", "cuda", "(", ")", "\n", "\n", "test", "(", "loader_test", ",", "VAN", ",", "EN", ",", "test_result_root_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.test.test_DALE.test": [[29, 43], ["VAN.eval", "EN.eval", "enumerate", "testImg.cuda.cuda", "torch.no_grad", "VAN", "EN", "train.train_utils.tensor2im", "train.train_utils.save_images", "img_name[].split"], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.tensor2im", "home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.save_images"], ["", "def", "test", "(", "loader_test", ",", "VAN", ",", "EN", ",", "root_dir", ")", ":", "\n", "    ", "VAN", ".", "eval", "(", ")", "\n", "EN", ".", "eval", "(", ")", "\n", "\n", "for", "itr", ",", "data", "in", "enumerate", "(", "loader_test", ")", ":", "\n", "        ", "testImg", ",", "img_name", "=", "data", "[", "0", "]", ",", "data", "[", "1", "]", "\n", "testImg", "=", "testImg", ".", "cuda", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "visual_attention_map", "=", "VAN", "(", "testImg", ")", "\n", "enhance_result", "=", "EN", "(", "testImg", ",", "visual_attention_map", ")", "\n", "enhance_result_img", "=", "train_utils", ".", "tensor2im", "(", "enhance_result", ")", "\n", "result_save_dir", "=", "root_dir", "+", "'enhance'", "+", "img_name", "[", "0", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "(", "'.png'", ")", "\n", "train_utils", ".", "save_images", "(", "enhance_result_img", ",", "result_save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.test.test_visual_attention_map.main": [[7, 24], ["model.VisualAttentionNetwork.VisualAttentionNetwork", "torch.load", "VisualAttentionNetwork.VisualAttentionNetwork.load_state_dict", "data.dataset_DALE.DALETest", "torch.utils.data.DataLoader", "VisualAttentionNetwork.VisualAttentionNetwork.cuda", "test_visual_attention_map.test"], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.train.training_EN.test"], ["def", "main", "(", ")", ":", "\n", "\n", "# test_data_root = 'D:\\data\\LessNet\\/enhance_test'", "\n", "    ", "test_data_root", "=", "'D:\\data\\DarkPair\\ExDark\\Bicycle'", "\n", "model_root", "=", "'../checkpoint/'", "\n", "test_result_root_dir", "=", "'../VAN_TEST/'", "\n", "\n", "# model_LessNet = LessNet.LessNet(stride=1)", "\n", "VisualAttentioNNet", "=", "VisualAttentionNetwork", ".", "VisualAttentionNetwork", "(", ")", "#LessNet_Update.LessNet()#AttentionNet.AttenteionNet(stride=1)", "\n", "state_dict", "=", "torch", ".", "load", "(", "model_root", "+", "'VAN.pth'", ")", "\n", "VisualAttentioNNet", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "test_data", "=", "dataset_DALE", ".", "DALETest", "(", "test_data_root", ")", "\n", "loader_test", "=", "DataLoader", "(", "test_data", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "\n", "VisualAttentioNNet", ".", "cuda", "(", ")", "\n", "test", "(", "loader_test", ",", "VisualAttentioNNet", ",", "test_result_root_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.test.test_visual_attention_map.test": [[25, 42], ["visualAttentionNet.eval", "enumerate", "testImg.cuda.cuda", "torch.no_grad", "visualAttentionNet", "train.train_utils.tensor2im", "train.train_utils.tensor2im", "train.train_utils.save_images", "train.train_utils.save_images", "fileName[].split", "fileName[].split"], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.tensor2im", "home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.tensor2im", "home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.save_images", "home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.save_images"], ["", "def", "test", "(", "loader_test", ",", "visualAttentionNet", ",", "root_dir", ")", ":", "\n", "    ", "visualAttentionNet", ".", "eval", "(", ")", "\n", "for", "itr", ",", "data", "in", "enumerate", "(", "loader_test", ")", ":", "\n", "        ", "testImg", ",", "fileName", "=", "data", "[", "0", "]", ",", "data", "[", "1", "]", "\n", "testImg", "=", "testImg", ".", "cuda", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "test_attention_result", "=", "visualAttentionNet", "(", "testImg", ")", "\n", "\n", "test_recon_result_img", "=", "train_utils", ".", "tensor2im", "(", "test_attention_result", ")", "\n", "norm_input_img", "=", "train_utils", ".", "tensor2im", "(", "testImg", "+", "test_attention_result", ")", "\n", "\n", "recon_save_dir", "=", "root_dir", "+", "'visual_attention_map_'", "+", "fileName", "[", "0", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "(", "'.png'", ")", "\n", "recon_save_dir2", "=", "root_dir", "+", "'sum_'", "+", "fileName", "[", "0", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "(", "'.png'", ")", "\n", "\n", "train_utils", ".", "save_images", "(", "test_recon_result_img", ",", "recon_save_dir", ")", "\n", "train_utils", ".", "save_images", "(", "norm_input_img", ",", "recon_save_dir2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.common.MeanShift.__init__": [[15, 23], ["torch.Conv2d.__init__", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "common.MeanShift.weight.data.div_", "common.MeanShift.bias.data.div_", "torch.Tensor.view", "torch.Tensor.view", "torch.Tensor.view", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "rgb_range", ",", "rgb_mean", ",", "rgb_std", ",", "sign", "=", "-", "1", ")", ":", "\n", "        ", "super", "(", "MeanShift", ",", "self", ")", ".", "__init__", "(", "3", ",", "3", ",", "kernel_size", "=", "1", ")", "\n", "std", "=", "torch", ".", "Tensor", "(", "rgb_std", ")", "\n", "self", ".", "weight", ".", "data", "=", "torch", ".", "eye", "(", "3", ")", ".", "view", "(", "3", ",", "3", ",", "1", ",", "1", ")", "\n", "self", ".", "weight", ".", "data", ".", "div_", "(", "std", ".", "view", "(", "3", ",", "1", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "bias", ".", "data", "=", "sign", "*", "rgb_range", "*", "torch", ".", "Tensor", "(", "rgb_mean", ")", "\n", "self", ".", "bias", ".", "data", ".", "div_", "(", "std", ")", "\n", "self", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.common.BasicBlock.__init__": [[25, 36], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Sequential.__init__", "conv", "m.append", "m.append", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "conv", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "bias", "=", "False", ",", "\n", "bn", "=", "True", ",", "act", "=", "nn", ".", "ReLU", "(", "True", ")", ")", ":", "\n", "\n", "        ", "m", "=", "[", "conv", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "bias", "=", "bias", ")", "]", "\n", "if", "bn", ":", "\n", "            ", "m", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", ")", "\n", "", "if", "act", "is", "not", "None", ":", "\n", "            ", "m", ".", "append", "(", "act", ")", "\n", "\n", "", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", "*", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.common.ResBlock.__init__": [[38, 51], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "modules_body.append", "conv", "modules_body.append", "modules_body.append", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "conv", ",", "n_feat", ",", "kernel_size", ",", "\n", "bias", "=", "True", ",", "bn", "=", "False", ",", "act", "=", "nn", ".", "ReLU", "(", "True", ")", ",", "res_scale", "=", "1", ")", ":", "\n", "\n", "        ", "super", "(", "ResBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "modules_body", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "            ", "modules_body", ".", "append", "(", "conv", "(", "n_feat", ",", "n_feat", ",", "kernel_size", ",", "bias", "=", "bias", ")", ")", "\n", "if", "bn", ":", "modules_body", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "n_feat", ")", ")", "\n", "if", "i", "==", "0", ":", "modules_body", ".", "append", "(", "act", ")", "\n", "\n", "", "self", ".", "body", "=", "nn", ".", "Sequential", "(", "*", "modules_body", ")", "\n", "self", ".", "res_scale", "=", "res_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.common.ResBlock.forward": [[52, 57], ["common.ResBlock.body().mul", "common.ResBlock.body"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "res", "=", "self", ".", "body", "(", "x", ")", ".", "mul", "(", "self", ".", "res_scale", ")", "\n", "res", "+=", "x", "\n", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.common.Upsampler.__init__": [[59, 77], ["torch.Sequential.__init__", "range", "int", "modules.append", "modules.append", "modules.append", "modules.append", "math.log", "conv", "torch.PixelShuffle", "torch.PixelShuffle", "torch.PixelShuffle", "modules.append", "modules.append", "conv", "torch.PixelShuffle", "torch.PixelShuffle", "torch.PixelShuffle", "modules.append", "modules.append", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "act", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "act"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "conv", ",", "scale", ",", "n_feat", ",", "bn", "=", "False", ",", "act", "=", "False", ",", "bias", "=", "True", ")", ":", "\n", "\n", "        ", "modules", "=", "[", "]", "\n", "if", "(", "scale", "&", "(", "scale", "-", "1", ")", ")", "==", "0", ":", "# Is scale = 2^n?", "\n", "            ", "for", "_", "in", "range", "(", "int", "(", "math", ".", "log", "(", "scale", ",", "2", ")", ")", ")", ":", "\n", "                ", "modules", ".", "append", "(", "conv", "(", "n_feat", ",", "4", "*", "n_feat", ",", "3", ",", "bias", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "PixelShuffle", "(", "2", ")", ")", "\n", "if", "bn", ":", "modules", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "n_feat", ")", ")", "\n", "if", "act", ":", "modules", ".", "append", "(", "act", "(", ")", ")", "\n", "", "", "elif", "scale", "==", "3", ":", "\n", "            ", "modules", ".", "append", "(", "conv", "(", "n_feat", ",", "9", "*", "n_feat", ",", "3", ",", "bias", ")", ")", "\n", "modules", ".", "append", "(", "nn", ".", "PixelShuffle", "(", "3", ")", ")", "\n", "if", "bn", ":", "modules", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "n_feat", ")", ")", "\n", "if", "act", ":", "modules", ".", "append", "(", "act", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "super", "(", "Upsampler", ",", "self", ")", ".", "__init__", "(", "*", "modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.common.default_conv": [[9, 13], ["torch.Conv2d"], "function", ["None"], ["def", "default_conv", "(", "in_channelss", ",", "out_channels", ",", "kernel_size", ",", "bias", "=", "True", ")", ":", "\n", "    ", "return", "nn", ".", "Conv2d", "(", "\n", "in_channelss", ",", "out_channels", ",", "kernel_size", ",", "\n", "padding", "=", "(", "kernel_size", "//", "2", ")", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.EnhancementNet.EnhancementNet.__init__": [[9, 29], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "model.Residual_Block_Enhance", "model.Residual_Block_Enhance", "model.Residual_Block_Enhance", "model.SELayer", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "EnhancementNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "feature_num", "=", "64", "\n", "\n", "self", ".", "res_input_conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "6", ",", "64", ",", "3", ",", "1", ",", "1", ")", "# 6", "\n", ")", "\n", "\n", "self", ".", "residual_group1", "=", "BasicBlocks", ".", "Residual_Block_Enhance", "(", "64", ",", "64", ",", "3", ")", "\n", "\n", "self", ".", "residual_group2", "=", "BasicBlocks", ".", "Residual_Block_Enhance", "(", "64", ",", "64", ",", "2", ")", "\n", "\n", "self", ".", "residual_group3", "=", "BasicBlocks", ".", "Residual_Block_Enhance", "(", "64", ",", "64", ",", "1", ")", "\n", "\n", "self", ".", "se", "=", "BasicBlocks", ".", "SELayer", "(", "192", ")", "\n", "\n", "self", ".", "conv_block", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "192", ",", "64", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "3", ",", "3", ",", "1", ",", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.EnhancementNet.EnhancementNet.forward": [[34, 45], ["EnhancementNet.EnhancementNet.res_input_conv", "EnhancementNet.EnhancementNet.residual_group1", "EnhancementNet.EnhancementNet.residual_group2", "EnhancementNet.EnhancementNet.residual_group3", "EnhancementNet.EnhancementNet.se", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "EnhancementNet.EnhancementNet.conv_block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "attention", ")", ":", "\n", "\n", "        ", "res_input", "=", "self", ".", "res_input_conv", "(", "torch", ".", "cat", "(", "[", "x", ",", "attention", "]", ",", "1", ")", ")", "\n", "res1", "=", "self", ".", "residual_group1", "(", "res_input", ")", "\n", "res2", "=", "self", ".", "residual_group2", "(", "res1", ")", "\n", "res3", "=", "self", ".", "residual_group3", "(", "res2", ")", "\n", "group_cat", "=", "self", ".", "se", "(", "torch", ".", "cat", "(", "[", "res1", ",", "res2", ",", "res3", "]", ",", "1", ")", ")", "\n", "\n", "output", "=", "self", ".", "conv_block", "(", "group_cat", ")", "+", "attention", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.EnhancementNet.Discriminator.__init__": [[48, 91], ["torch.Module.__init__", "int", "range", "min", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "numpy.ceil", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "min", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "norm_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "num_input_channels", "=", "3", "\n", "kw", "=", "4", "\n", "padw", "=", "int", "(", "np", ".", "ceil", "(", "(", "kw", "-", "1", ")", "/", "2", ")", ")", "\n", "ndf", "=", "48", "\n", "use_bias", "=", "False", "\n", "use_sigmoid", "=", "False", "\n", "\n", "norm_layer", "=", "spectral_norm", "# spectral_norm# nn.InstanceNorm2d(ndf)", "\n", "# norm_layer = nn.InstanceNorm2d", "\n", "\n", "sequence", "=", "[", "norm_layer", "(", "nn", ".", "Conv2d", "(", "num_input_channels", ",", "ndf", ",", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ")", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "]", "\n", "\n", "nf_mult", "=", "1", "\n", "n_layers", "=", "2", "########", "\n", "\n", "for", "n", "in", "range", "(", "1", ",", "n_layers", ")", ":", "\n", "            ", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "norm_layer", "(", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "\n", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n_layers", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "norm_layer", "(", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "\n", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ")", ",", "\n", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "sequence", "+=", "[", "norm_layer", "(", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult", ",", "1", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ")", ")", "]", "\n", "\n", "if", "use_sigmoid", ":", "\n", "            ", "sequence", "+=", "[", "nn", ".", "Sigmoid", "(", ")", "]", "\n", "\n", "", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.EnhancementNet.Discriminator.forward": [[92, 97], ["EnhancementNet.Discriminator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# features = self.features(x)", "\n", "# output = self.classifier(features.view(features.size(0), -1))", "\n", "        ", "output", "=", "self", ".", "model", "(", "x", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks._Conv_Block.__init__": [[6, 13], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "_Conv_Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "in1", "=", "nn", ".", "BatchNorm2d", "(", "64", ",", "affine", "=", "True", ")", "\n", "self", ".", "relu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "in2", "=", "nn", ".", "BatchNorm2d", "(", "64", ",", "affine", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks._Conv_Block.forward": [[14, 19], ["BasicBlocks._Conv_Block.relu", "BasicBlocks._Conv_Block.in2", "BasicBlocks._Conv_Block.in1", "BasicBlocks._Conv_Block.conv2", "BasicBlocks._Conv_Block.conv1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity_data", "=", "x", "\n", "output", "=", "self", ".", "relu", "(", "self", ".", "in1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "output", "=", "self", ".", "in2", "(", "self", ".", "conv2", "(", "output", ")", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks.CALayer.__init__": [[21, 31], ["torch.Module.__init__", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ",", "reduction", "=", "16", ")", ":", "\n", "        ", "super", "(", "CALayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# global average pooling: feature --> point", "\n", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "# feature channel downscale and upscale --> channel weight", "\n", "self", ".", "conv_du", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "channel", ",", "channel", "//", "reduction", ",", "1", ",", "padding", "=", "0", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "channel", "//", "reduction", ",", "channel", ",", "1", ",", "padding", "=", "0", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks.CALayer.forward": [[33, 37], ["BasicBlocks.CALayer.avg_pool", "BasicBlocks.CALayer.conv_du"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "y", "=", "self", ".", "avg_pool", "(", "x", ")", "\n", "y", "=", "self", ".", "conv_du", "(", "y", ")", "\n", "return", "x", "*", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks.SALayer.__init__": [[39, 49], ["torch.Module.__init__", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ",", "reduction", "=", "16", ")", ":", "\n", "        ", "super", "(", "SALayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# global average pooling: feature --> point", "\n", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "# feature channel downscale and upscale --> channel weight", "\n", "self", ".", "conv_du", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "channel", ",", "channel", ",", "1", ",", "padding", "=", "0", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "#####LeakyReLU", "\n", "nn", ".", "Conv2d", "(", "channel", ",", "1", ",", "1", ",", "padding", "=", "0", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks.SALayer.forward": [[51, 54], ["BasicBlocks.SALayer.conv_du"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "y", "=", "self", ".", "conv_du", "(", "x", ")", "\n", "return", "x", "*", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks.SELayer.__init__": [[57, 65], ["torch.Module.__init__", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ",", "reduction", "=", "16", ")", ":", "\n", "        ", "super", "(", "SELayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "channel", ",", "channel", "//", "reduction", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "channel", "//", "reduction", ",", "channel", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks.SELayer.forward": [[67, 72], ["x.size", "BasicBlocks.SELayer.avg_pool().view", "BasicBlocks.SELayer.fc().view", "BasicBlocks.SELayer.expand_as", "BasicBlocks.SELayer.avg_pool", "BasicBlocks.SELayer.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "b", ",", "c", ",", "_", ",", "_", "=", "x", ".", "size", "(", ")", "\n", "y", "=", "self", ".", "avg_pool", "(", "x", ")", ".", "view", "(", "b", ",", "c", ")", "\n", "y", "=", "self", ".", "fc", "(", "y", ")", ".", "view", "(", "b", ",", "c", ",", "1", ",", "1", ")", "\n", "return", "x", "*", "y", ".", "expand_as", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks.Residual_Block_New.__init__": [[74, 83], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "BasicBlocks.SELayer"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_num", ",", "out_num", ",", "dilation_factor", ")", ":", "\n", "        ", "super", "(", "Residual_Block_New", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "(", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_num", ",", "out_channels", "=", "out_num", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "dilation_factor", ",", "dilation", "=", "dilation_factor", ",", "groups", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "self", ".", "in1", "=", "nn", ".", "BatchNorm2d", "(", "out_num", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "conv2", "=", "(", "nn", ".", "Conv2d", "(", "in_channels", "=", "out_num", ",", "out_channels", "=", "out_num", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "dilation_factor", ",", "dilation", "=", "dilation_factor", ",", "groups", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "self", ".", "in2", "=", "nn", ".", "BatchNorm2d", "(", "out_num", ")", "\n", "self", ".", "se", "=", "SELayer", "(", "channel", "=", "out_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks.Residual_Block_New.forward": [[84, 93], ["BasicBlocks.Residual_Block_New.relu", "BasicBlocks.Residual_Block_New.conv2", "BasicBlocks.Residual_Block_New.se", "BasicBlocks.Residual_Block_New.conv1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity_data", "=", "x", "\n", "output", "=", "self", ".", "relu", "(", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "output", "=", "(", "self", ".", "conv2", "(", "output", ")", ")", "\n", "\n", "#USE SE BLOCK", "\n", "se", "=", "self", ".", "se", "(", "output", ")", "\n", "output", "=", "se", "+", "identity_data", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks.Residual_Block_Enhance.__init__": [[95, 104], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "BasicBlocks.SELayer"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_num", ",", "out_num", ",", "dilation_factor", ")", ":", "\n", "        ", "super", "(", "Residual_Block_Enhance", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "(", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_num", ",", "out_channels", "=", "out_num", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "dilation_factor", ",", "dilation", "=", "dilation_factor", ",", "groups", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "self", ".", "in1", "=", "nn", ".", "BatchNorm2d", "(", "out_num", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "conv2", "=", "(", "nn", ".", "Conv2d", "(", "in_channels", "=", "out_num", ",", "out_channels", "=", "out_num", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "dilation_factor", ",", "dilation", "=", "dilation_factor", ",", "groups", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "self", ".", "in2", "=", "nn", ".", "BatchNorm2d", "(", "out_num", ")", "\n", "self", ".", "se", "=", "SELayer", "(", "channel", "=", "out_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks.Residual_Block_Enhance.forward": [[105, 114], ["BasicBlocks.Residual_Block_Enhance.relu", "BasicBlocks.Residual_Block_Enhance.conv2", "BasicBlocks.Residual_Block_Enhance.se", "BasicBlocks.Residual_Block_Enhance.conv1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity_data", "=", "x", "\n", "output", "=", "self", ".", "relu", "(", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "output", "=", "(", "self", ".", "conv2", "(", "output", ")", ")", "\n", "\n", "#USE SE BLOCK", "\n", "se", "=", "self", ".", "se", "(", "output", ")", "\n", "output", "=", "se", "+", "identity_data", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks.Residual_Block.__init__": [[116, 125], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "BasicBlocks.SELayer"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Residual_Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "(", "nn", ".", "Conv2d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "2", ",", "dilation", "=", "2", ",", "groups", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "self", ".", "in1", "=", "nn", ".", "InstanceNorm2d", "(", "64", ",", "affine", "=", "True", ")", "\n", "# self.relu = nn.LeakyReLU(0.2, inplace=True)", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "(", "nn", ".", "Conv2d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "2", ",", "dilation", "=", "2", ",", "groups", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "self", ".", "in2", "=", "nn", ".", "InstanceNorm2d", "(", "64", ",", "affine", "=", "True", ")", "\n", "self", ".", "se", "=", "SELayer", "(", "channel", "=", "64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks.Residual_Block.forward": [[126, 134], ["BasicBlocks.Residual_Block.relu", "BasicBlocks.Residual_Block.in2", "BasicBlocks.Residual_Block.se", "BasicBlocks.Residual_Block.in1", "BasicBlocks.Residual_Block.conv2", "BasicBlocks.Residual_Block.conv1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity_data", "=", "x", "\n", "output", "=", "self", ".", "relu", "(", "self", ".", "in1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "output", "=", "self", ".", "in2", "(", "self", ".", "conv2", "(", "output", ")", ")", "\n", "#USE SE BLOCK", "\n", "se", "=", "self", ".", "se", "(", "output", ")", "\n", "output", "=", "se", "+", "identity_data", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks.make_dense.__init__": [[136, 139], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["      ", "def", "__init__", "(", "self", ",", "nChannels", ",", "growthRate", ",", "kernel_size", "=", "3", ")", ":", "\n", "        ", "super", "(", "make_dense", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "nChannels", ",", "growthRate", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", ",", "bias", "=", "False", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks.make_dense.forward": [[139, 143], ["torch.relu", "torch.relu", "torch.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "BasicBlocks.make_dense.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "conv", "(", "x", ")", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x", ",", "out", ")", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks.RDB.__init__": [[146, 156], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "BasicBlocks.SELayer", "modules.append", "BasicBlocks.make_dense"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["      ", "def", "__init__", "(", "self", ",", "nChannels", "=", "64", ",", "nDenselayer", "=", "5", ",", "growthRate", "=", "16", ")", ":", "\n", "        ", "super", "(", "RDB", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nChannels_", "=", "nChannels", "\n", "modules", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nDenselayer", ")", ":", "\n", "            ", "modules", ".", "append", "(", "make_dense", "(", "nChannels_", ",", "growthRate", ")", ")", "\n", "nChannels_", "+=", "growthRate", "\n", "", "self", ".", "dense_layers", "=", "nn", ".", "Sequential", "(", "*", "modules", ")", "\n", "self", ".", "conv_1x1", "=", "nn", ".", "Conv2d", "(", "nChannels_", ",", "nChannels", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "se", "=", "SELayer", "(", "nChannels", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.BasicBlocks.RDB.forward": [[156, 161], ["BasicBlocks.RDB.dense_layers", "BasicBlocks.RDB.conv_1x1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "dense_layers", "(", "x", ")", "\n", "out", "=", "self", ".", "conv_1x1", "(", "out", ")", "\n", "out", "=", "(", "out", ")", "+", "x", "\n", "return", "out", "", "", "", ""]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.VisualAttentionNetwork.VisualAttentionNetwork.__init__": [[7, 53], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "VisualAttentionNetwork.DownSample", "torch.Sequential", "torch.Sequential", "torch.Sequential", "VisualAttentionNetwork.DownSample", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "VisualAttentionNetwork.UpSample", "torch.Sequential", "torch.Sequential", "torch.Sequential", "VisualAttentionNetwork.UpSample", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "model.Residual_Block_New", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "model.Residual_Block_New", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "model.Residual_Block_New", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "model.Residual_Block_New", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "model.Residual_Block_New", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "model.Residual_Block_New"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "VisualAttentionNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "feature_num", "=", "64", "\n", "\n", "self", ".", "res_input_conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "3", ",", "1", ",", "1", ")", "# 6", "\n", ")", "\n", "\n", "self", ".", "res_encoder1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "1", ")", ",", "\n", "BasicBlocks", ".", "Residual_Block_New", "(", "64", ",", "64", ",", "3", ")", ",", "\n", ")", "\n", "\n", "self", ".", "down1", "=", "DownSample", "(", "64", ")", "\n", "\n", "self", ".", "res_encoder2", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "1", ")", ",", "\n", "BasicBlocks", ".", "Residual_Block_New", "(", "128", ",", "128", ",", "2", ")", ",", "\n", ")", "\n", "\n", "self", ".", "down2", "=", "DownSample", "(", "128", ")", "\n", "\n", "self", ".", "res_encoder3", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "1", ")", ",", "\n", "BasicBlocks", ".", "Residual_Block_New", "(", "256", ",", "256", ",", "1", ")", ",", "\n", ")", "\n", "\n", "self", ".", "res_decoder3", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "1", ")", ",", "\n", "BasicBlocks", ".", "Residual_Block_New", "(", "256", ",", "256", ",", "1", ")", ",", "\n", ")", "\n", "self", ".", "up2", "=", "UpSample", "(", "256", ")", "\n", "\n", "self", ".", "res_decoder2", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "256", ",", "128", ",", "1", ")", ",", "\n", "BasicBlocks", ".", "Residual_Block_New", "(", "128", ",", "128", ",", "2", ")", ",", "\n", ")", "\n", "self", ".", "up1", "=", "UpSample", "(", "128", ")", "\n", "\n", "self", ".", "res_decoder1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "128", ",", "64", ",", "1", ")", ",", "\n", "BasicBlocks", ".", "Residual_Block_New", "(", "64", ",", "64", ",", "3", ")", ",", "\n", ")", "\n", "\n", "self", ".", "res_final", "=", "nn", ".", "Conv2d", "(", "64", ",", "3", ",", "3", ",", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.VisualAttentionNetwork.VisualAttentionNetwork.forward": [[56, 78], ["VisualAttentionNetwork.VisualAttentionNetwork.res_input_conv", "VisualAttentionNetwork.VisualAttentionNetwork.res_encoder1", "VisualAttentionNetwork.VisualAttentionNetwork.down1", "VisualAttentionNetwork.VisualAttentionNetwork.res_encoder2", "VisualAttentionNetwork.VisualAttentionNetwork.down2", "VisualAttentionNetwork.VisualAttentionNetwork.res_encoder3", "VisualAttentionNetwork.VisualAttentionNetwork.up2", "VisualAttentionNetwork.VisualAttentionNetwork.up1", "VisualAttentionNetwork.VisualAttentionNetwork.res_final", "VisualAttentionNetwork.VisualAttentionNetwork.res_decoder3", "VisualAttentionNetwork.VisualAttentionNetwork.res_decoder2", "VisualAttentionNetwork.VisualAttentionNetwork.res_decoder1", "VisualAttentionNetwork.VisualAttentionNetwork.size", "VisualAttentionNetwork.VisualAttentionNetwork.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "only_attention_output", "=", "False", ")", ":", "\n", "        ", "res_input", "=", "self", ".", "res_input_conv", "(", "x", ")", "\n", "\n", "encoder1", "=", "self", ".", "res_encoder1", "(", "res_input", ")", "\n", "encoder1_down", "=", "self", ".", "down1", "(", "encoder1", ")", "\n", "#", "\n", "encoder2", "=", "self", ".", "res_encoder2", "(", "encoder1_down", ")", "\n", "encoder2_down", "=", "self", ".", "down2", "(", "encoder2", ")", "\n", "\n", "encoder3", "=", "self", ".", "res_encoder3", "(", "encoder2_down", ")", "\n", "\n", "decoder3", "=", "self", ".", "res_decoder3", "(", "encoder3", ")", "+", "encoder3", "\n", "decoder3", "=", "self", ".", "up2", "(", "decoder3", ",", "output_size", "=", "encoder2", ".", "size", "(", ")", ")", "\n", "\n", "decoder2", "=", "self", ".", "res_decoder2", "(", "decoder3", ")", "+", "encoder2", "\n", "decoder2", "=", "self", ".", "up1", "(", "decoder2", ",", "output_size", "=", "encoder1", ".", "size", "(", ")", ")", "\n", "\n", "decoder1", "=", "self", ".", "res_decoder1", "(", "decoder2", ")", "+", "encoder1", "\n", "\n", "output", "=", "self", ".", "res_final", "(", "decoder1", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.VisualAttentionNetwork.DownSample.__init__": [[80, 87], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", ":", "\n", "        ", "super", "(", "DownSample", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "in_channels", ",", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", ")", "\n", "# self.conv2 = nn.Conv2d(in_channels, stride*in_channels, kernel_size, stride=1, padding=(kernel_size - 1) // 2)", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "in_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", ")", "\n", "\n", "self", ".", "avg_pool", "=", "nn", ".", "AvgPool2d", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.VisualAttentionNetwork.DownSample.forward": [[88, 92], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "VisualAttentionNetwork.DownSample.conv1", "VisualAttentionNetwork.DownSample.conv2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "conv2", "(", "out", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.VisualAttentionNetwork.UpSample.__init__": [[95, 100], ["torch.Module.__init__", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", ":", "\n", "        ", "super", "(", "UpSample", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "deconv", "=", "nn", ".", "ConvTranspose2d", "(", "in_channels", ",", "in_channels", ",", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "1", ")", "\n", "# self.conv = nn.Conv2d(in_channels, in_channels // stride, kernel_size, stride=1, padding=(kernel_size - 1) // 2)", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "in_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.model.VisualAttentionNetwork.UpSample.forward": [[101, 105], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "VisualAttentionNetwork.UpSample.deconv", "VisualAttentionNetwork.UpSample.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "output_size", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "deconv", "(", "x", ",", "output_size", "=", "output_size", ")", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "conv", "(", "out", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.training_GAN.visdom_loss": [[25, 37], ["loss_data[].append", "loss_data[].append", "visdom.line", "numpy.stack", "numpy.array", "dict", "len", "numpy.array"], "function", ["None"], ["def", "visdom_loss", "(", "visdom", ",", "loss_step", ",", "loss_dict", ")", ":", "\n", "    ", "loss_data", "[", "'X'", "]", ".", "append", "(", "loss_step", ")", "\n", "loss_data", "[", "'Y'", "]", ".", "append", "(", "[", "loss_dict", "[", "k", "]", "for", "k", "in", "loss_data", "[", "'legend_U'", "]", "]", ")", "\n", "visdom", ".", "line", "(", "\n", "X", "=", "np", ".", "stack", "(", "[", "np", ".", "array", "(", "loss_data", "[", "'X'", "]", ")", "]", "*", "len", "(", "loss_data", "[", "'legend_U'", "]", ")", ",", "1", ")", ",", "\n", "Y", "=", "np", ".", "array", "(", "loss_data", "[", "'Y'", "]", ")", ",", "\n", "win", "=", "1", ",", "\n", "opts", "=", "dict", "(", "xlabel", "=", "'Step'", ",", "\n", "ylabel", "=", "'Loss'", ",", "\n", "title", "=", "'Training loss'", ",", "\n", "legend", "=", "loss_data", "[", "'legend_U'", "]", ")", ",", "\n", "update", "=", "'append'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.training_GAN.visdom_image": [[39, 45], ["enumerate", "train.train_utils.tensor2im", "visdom.image", "train_utils.tensor2im.transpose", "dict"], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.tensor2im"], ["", "def", "visdom_image", "(", "img_dict", ",", "window", ")", ":", "\n", "    ", "\"\"\"VISDOM\uc5d0 \uc774\ubbf8\uc9c0\ub4e4 \ub744\uc6b0\ub294 \uc5ed\ud560\"\"\"", "\n", "for", "idx", ",", "key", "in", "enumerate", "(", "img_dict", ")", ":", "\n", "        ", "win", "=", "window", "+", "idx", "\n", "tensor_img", "=", "train_utils", ".", "tensor2im", "(", "img_dict", "[", "key", "]", ".", "data", ")", "\n", "visdom", ".", "image", "(", "tensor_img", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ",", "opts", "=", "dict", "(", "title", "=", "key", ")", ",", "win", "=", "win", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.training_GAN.test": [[46, 64], ["model_AttentionNet.eval", "enumerate", "testImg.cuda.cuda", "torch.no_grad", "torch.no_grad", "model_AttentionNet", "train.train_utils.tensor2im", "train.train_utils.save_images", "fileName[].split"], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.tensor2im", "home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.save_images"], ["", "", "def", "test", "(", "args", ",", "loader_test", ",", "model_AttentionNet", ",", "epoch", ",", "root_dir", ")", ":", "\n", "    ", "\"\"\"Not Implement Yet\"\"\"", "\n", "model_AttentionNet", ".", "eval", "(", ")", "\n", "\n", "for", "itr", ",", "data", "in", "enumerate", "(", "loader_test", ")", ":", "\n", "        ", "testImg", ",", "fileName", "=", "data", "[", "0", "]", ",", "data", "[", "1", "]", "\n", "if", "args", ".", "cuda", ":", "\n", "            ", "testImg", "=", "testImg", ".", "cuda", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "test_result", "=", "model_AttentionNet", "(", "testImg", ")", "\n", "\n", "# Normalization to origin image \ud544\uc694!", "\n", "test_result_img", "=", "train_utils", ".", "tensor2im", "(", "test_result", ")", "\n", "\n", "result_save_dir", "=", "root_dir", "+", "fileName", "[", "0", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "(", "'_epoch_{}_itr_{}.png'", ".", "format", "(", "epoch", ",", "itr", ")", ")", "\n", "\n", "train_utils", ".", "save_images", "(", "test_result_img", ",", "result_save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.training_GAN.main": [[65, 218], ["print", "data.dataset_DALE.DALETrainGlobal", "torch.utils.data.DataLoader", "print", "model.VisualAttentionNetwork.AttentionNet2", "torch.load", "torch.load", "VAN.cuda.load_state_dict", "model.EnhancementNet.EnhancementNet", "model.EnhancementNet.Discriminator", "torch.load", "torch.load", "EnhanceNetG.cuda.load_state_dict", "filter", "sum", "print", "filter", "sum", "print", "print", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "print", "print", "range", "EnhanceNetG.cuda.parameters", "EnhanceNetD.cuda.parameters", "list", "list", "print", "VAN.cuda.cuda", "EnhanceNetG.cuda.cuda", "EnhanceNetD.cuda.cuda", "EnhanceNetG.cuda.train", "EnhanceNetD.cuda.train", "enumerate", "print", "numpy.prod", "numpy.prod", "EnhanceNetG.cuda.parameters", "EnhanceNetD.cuda.parameters", "torch.optim.Adam.zero_grad", "VAN.cuda.", "EnhanceNetG.cuda.detach", "loss_D.backward", "torch.optim.Adam.step", "EnhanceNetD.cuda.parameters", "train.train_utils.save_checkpoint", "train.train_utils.save_checkpoint", "p.size", "p.size", "low_light_img.cuda.cuda", "ground_truth_img.cuda.cuda", "gt_Attention_img.cuda.cuda", "torch.mean", "torch.mean", "p.data.clamp_", "torch.optim.Adam.zero_grad", "EnhanceNetG.cuda.", "L2_loss", "total_loss.backward", "torch.optim.Adam.step", "print", "training_GAN.visdom_loss", "collections.OrderedDict", "training_GAN.visdom_image", "EnhanceNetG.cuda.", "torch.mean", "torch.mean", "EnhanceNetD.cuda.", "Perceptual_loss", "TvLoss", "L2_loss.item", "tv_loss.item", "p_loss.item", "loss_G.item", "loss_D.item", "torch.no_grad", "torch.no_grad", "PIL.open", "torchvision.transforms.Compose", "transforms.Compose.unsqueeze", "val_image.cuda.cuda", "EnhanceNetD.cuda.", "torch.mean", "torch.mean", "len", "VAN.cuda.eval", "EnhanceNetG.cuda.eval", "EnhanceNetG.cuda.", "torchvision.transforms.ToTensor", "transforms.Compose."], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.save_checkpoint", "home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.save_checkpoint", "home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.visdom_loss", "home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.visdom_image"], ["", "", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "\"\"\"Main Function : Data Loading -> Model Building -> Set Optimization -> Training\"\"\"", "\n", "# Setting Important Arguments #", "\n", "args", ".", "cuda", "=", "True", "\n", "args", ".", "epochs", "=", "200", "\n", "args", ".", "lr", "=", "1e-5", "\n", "args", ".", "batch_size", "=", "5", "\n", "# Setting Important Path #", "\n", "train_data_root", "=", "'D:\\data\\DALE/'", "\n", "model_save_root_dir", "=", "'D:\\Pytorch_code\\DALE/checkpoint/'", "\n", "model_root", "=", "'../checkpoint/DALEGAN/'", "\n", "\n", "# Setting Important Traning Variable #", "\n", "VISUALIZATION_STEP", "=", "50", "\n", "SAVE_STEP", "=", "1", "\n", "\n", "print", "(", "\"DALE => Data Loading\"", ")", "\n", "\n", "train_data", "=", "dataset_DALE", ".", "DALETrainGlobal", "(", "train_data_root", ",", "args", ")", "\n", "loader_train", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "\n", "print", "(", "\"DALE => Model Building\"", ")", "\n", "VAN", "=", "VisualAttentionNetwork", ".", "AttentionNet2", "(", ")", "\n", "state_dict1", "=", "torch", ".", "load", "(", "model_root", "+", "'visual_attention_network_model.pth'", ")", "\n", "VAN", ".", "load_state_dict", "(", "state_dict1", ")", "\n", "\n", "EnhanceNetG", "=", "EnhancementNet", ".", "EnhancementNet", "(", ")", "\n", "EnhanceNetD", "=", "EnhancementNet", ".", "Discriminator", "(", ")", "\n", "\n", "state_dict2", "=", "torch", ".", "load", "(", "model_root", "+", "'enhance_GAN.pth'", ")", "\n", "EnhanceNetG", ".", "load_state_dict", "(", "state_dict2", ")", "\n", "\n", "EnhancementNet_parameters", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "EnhanceNetG", ".", "parameters", "(", ")", ")", "\n", "\n", "params1", "=", "sum", "(", "[", "np", ".", "prod", "(", "p", ".", "size", "(", ")", ")", "for", "p", "in", "EnhancementNet_parameters", "]", ")", "\n", "\n", "print", "(", "\"Parameters | Discriminator \"", ",", "params1", ")", "\n", "\n", "discriminator_parameters", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "EnhanceNetD", ".", "parameters", "(", ")", ")", "\n", "params", "=", "sum", "(", "[", "np", ".", "prod", "(", "p", ".", "size", "(", ")", ")", "for", "p", "in", "discriminator_parameters", "]", ")", "\n", "\n", "print", "(", "\"Parameters | Discriminator \"", ",", "params", ")", "\n", "\n", "print", "(", "\"DALE => Set Optimization\"", ")", "\n", "optG", "=", "torch", ".", "optim", ".", "Adam", "(", "list", "(", "EnhanceNetG", ".", "parameters", "(", ")", ")", ",", "lr", "=", "args", ".", "lr", ",", "betas", "=", "(", "0.5", ",", "0.999", ")", ")", "\n", "optD", "=", "torch", ".", "optim", ".", "Adam", "(", "list", "(", "EnhanceNetD", ".", "parameters", "(", ")", ")", ",", "lr", "=", "args", ".", "lr", ",", "betas", "=", "(", "0.5", ",", "0.999", ")", ",", "\n", "weight_decay", "=", "0", ")", "\n", "\n", "print", "(", "\"DALE => Setting GPU\"", ")", "\n", "if", "args", ".", "cuda", ":", "\n", "        ", "print", "(", "\"DALE => Use GPU\"", ")", "\n", "VAN", "=", "VAN", ".", "cuda", "(", ")", "\n", "EnhanceNetG", "=", "EnhanceNetG", ".", "cuda", "(", ")", "\n", "EnhanceNetD", "=", "EnhanceNetD", ".", "cuda", "(", ")", "\n", "\n", "", "print", "(", "\"DALE => Training\"", ")", "\n", "\n", "loss_step", "=", "0", "\n", "\n", "for", "epoch", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "\n", "        ", "EnhanceNetG", ".", "train", "(", ")", "\n", "EnhanceNetD", ".", "train", "(", ")", "\n", "for", "itr", ",", "data", "in", "enumerate", "(", "loader_train", ")", ":", "\n", "            ", "low_light_img", ",", "ground_truth_img", ",", "gt_Attention_img", ",", "file_name", "=", "data", "[", "0", "]", ",", "data", "[", "1", "]", ",", "data", "[", "2", "]", ",", "data", "[", "3", "]", "\n", "if", "args", ".", "cuda", ":", "\n", "                ", "low_light_img", "=", "low_light_img", ".", "cuda", "(", ")", "\n", "ground_truth_img", "=", "ground_truth_img", ".", "cuda", "(", ")", "\n", "gt_Attention_img", "=", "gt_Attention_img", ".", "cuda", "(", ")", "\n", "\n", "", "optD", ".", "zero_grad", "(", ")", "\n", "\n", "\n", "attention_result", "=", "VAN", "(", "low_light_img", ")", "\n", "enhance_result", "=", "EnhanceNetG", "(", "low_light_img", ",", "attention_result", ")", ".", "detach", "(", ")", "\n", "\n", "loss_D", "=", "-", "torch", ".", "mean", "(", "EnhanceNetD", "(", "ground_truth_img", ")", ")", "+", "torch", ".", "mean", "(", "EnhanceNetD", "(", "enhance_result", ")", ")", "\n", "\n", "loss_D", ".", "backward", "(", ")", "\n", "optD", ".", "step", "(", ")", "\n", "\n", "for", "p", "in", "EnhanceNetD", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "clamp_", "(", "-", "0.01", ",", "0.01", ")", "\n", "\n", "", "if", "itr", "%", "5", "==", "0", ":", "\n", "\n", "                ", "optG", ".", "zero_grad", "(", ")", "\n", "enhance_result", "=", "EnhanceNetG", "(", "low_light_img", ",", "attention_result", ")", "\n", "loss_G", "=", "-", "torch", ".", "mean", "(", "EnhanceNetG", "(", "enhance_result", ")", ")", "*", "0.5", "\n", "\n", "e_loss", "=", "L2_loss", "(", "enhance_result", ",", "ground_truth_img", ")", "\n", "p_loss", "=", "Perceptual_loss", "(", "enhance_result", ",", "ground_truth_img", ")", "*", "10", "\n", "tv_loss", "=", "TvLoss", "(", "enhance_result", ")", "*", "5", "\n", "\n", "total_loss", "=", "p_loss", "+", "e_loss", "+", "tv_loss", "+", "loss_G", "\n", "\n", "total_loss", ".", "backward", "(", ")", "\n", "optG", ".", "step", "(", ")", "\n", "\n", "", "if", "itr", "!=", "0", "and", "itr", "%", "VISUALIZATION_STEP", "==", "0", ":", "\n", "                ", "print", "(", "\"Epoch[{}/{}]({}/{}): \"", "\n", "\"e_loss : {:.6f}, \"", "\n", "\"tv_loss : {:.6f}, \"", "\n", "\"p_loss : {:.6f}\"", ".", "format", "(", "epoch", ",", "args", ".", "epochs", ",", "itr", ",", "len", "(", "loader_train", ")", ",", "e_loss", ",", "tv_loss", ",", "p_loss", ")", ")", "\n", "\n", "# VISDOM LOSS GRAPH #", "\n", "\n", "loss_dict", "=", "{", "\n", "'e_loss'", ":", "e_loss", ".", "item", "(", ")", ",", "\n", "'tv_loss'", ":", "tv_loss", ".", "item", "(", ")", ",", "\n", "'p_loss'", ":", "p_loss", ".", "item", "(", ")", ",", "\n", "'g_loss'", ":", "loss_G", ".", "item", "(", ")", ",", "\n", "'d_loss'", ":", "loss_D", ".", "item", "(", ")", "\n", "# 'recon_loss': recon_loss.item()", "\n", "}", "\n", "\n", "visdom_loss", "(", "visdom", ",", "loss_step", ",", "loss_dict", ")", "\n", "\n", "# VISDOM VISUALIZATION # -> tensor to numpy => list ('title_name', img_tensor)", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "val_image", "=", "Image", ".", "open", "(", "'../validation/15.jpg'", ")", "\n", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "\n", "val_image", "=", "transform", "(", "(", "val_image", ")", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "val_image", "=", "val_image", ".", "cuda", "(", ")", "\n", "val_attention", "=", "VAN", ".", "eval", "(", ")", "(", "val_image", ")", "\n", "val_result", "=", "EnhanceNetG", ".", "eval", "(", ")", "(", "val_image", ",", "val_attention", ")", "\n", "\n", "", "img_list", "=", "OrderedDict", "(", "\n", "[", "(", "'input'", ",", "low_light_img", ")", ",", "\n", "(", "'output'", ",", "enhance_result", ")", ",", "\n", "(", "'attention_output'", ",", "attention_result", ")", ",", "\n", "(", "'gt_Attention_img'", ",", "gt_Attention_img", ")", ",", "\n", "(", "'ground_truth'", ",", "ground_truth_img", ")", ",", "\n", "(", "'val_result'", ",", "val_result", ")", ",", "\n", "(", "'val_sum'", ",", "val_attention", "+", "val_image", ")", "]", ")", "\n", "\n", "visdom_image", "(", "img_dict", "=", "img_list", ",", "window", "=", "10", ")", "\n", "\n", "loss_step", "=", "loss_step", "+", "1", "\n", "\n", "", "", "print", "(", "\"DALE => Testing\"", ")", "\n", "\n", "if", "epoch", "%", "SAVE_STEP", "==", "0", ":", "\n", "            ", "train_utils", ".", "save_checkpoint", "(", "EnhanceNetG", ",", "epoch", ",", "model_save_root_dir", "+", "'DALEGAN/'", ")", "\n", "train_utils", ".", "save_checkpoint", "(", "EnhanceNetD", ",", "epoch", ",", "model_save_root_dir", "+", "'DALE_Discriminator/'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.training_VAN.visdom_loss": [[25, 37], ["loss_data[].append", "loss_data[].append", "visdom.line", "numpy.stack", "numpy.array", "dict", "len", "numpy.array"], "function", ["None"], ["def", "visdom_loss", "(", "visdom", ",", "loss_step", ",", "loss_dict", ")", ":", "\n", "    ", "loss_data", "[", "'X'", "]", ".", "append", "(", "loss_step", ")", "\n", "loss_data", "[", "'Y'", "]", ".", "append", "(", "[", "loss_dict", "[", "k", "]", "for", "k", "in", "loss_data", "[", "'legend_U'", "]", "]", ")", "\n", "visdom", ".", "line", "(", "\n", "X", "=", "np", ".", "stack", "(", "[", "np", ".", "array", "(", "loss_data", "[", "'X'", "]", ")", "]", "*", "len", "(", "loss_data", "[", "'legend_U'", "]", ")", ",", "1", ")", ",", "\n", "Y", "=", "np", ".", "array", "(", "loss_data", "[", "'Y'", "]", ")", ",", "\n", "win", "=", "1", ",", "\n", "opts", "=", "dict", "(", "xlabel", "=", "'Step'", ",", "\n", "ylabel", "=", "'Loss'", ",", "\n", "title", "=", "'Training loss'", ",", "\n", "legend", "=", "loss_data", "[", "'legend_U'", "]", ")", ",", "\n", "update", "=", "'append'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.training_VAN.visdom_image": [[39, 44], ["enumerate", "train.train_utils.tensor2im", "visdom.image", "train_utils.tensor2im.transpose", "dict"], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.tensor2im"], ["", "def", "visdom_image", "(", "img_dict", ",", "window", ")", ":", "\n", "    ", "for", "idx", ",", "key", "in", "enumerate", "(", "img_dict", ")", ":", "\n", "        ", "win", "=", "window", "+", "idx", "\n", "tensor_img", "=", "train_utils", ".", "tensor2im", "(", "img_dict", "[", "key", "]", ".", "data", ")", "\n", "visdom", ".", "image", "(", "tensor_img", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ",", "opts", "=", "dict", "(", "title", "=", "key", ")", ",", "win", "=", "win", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.training_VAN.test": [[45, 57], ["model_AttentionNet.eval", "enumerate", "testImg.cuda.cuda", "torch.no_grad", "torch.no_grad", "model_AttentionNet", "train.train_utils.tensor2im", "train.train_utils.save_images", "fileName[].split"], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.tensor2im", "home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.save_images"], ["", "", "def", "test", "(", "args", ",", "loader_test", ",", "model_AttentionNet", ",", "epoch", ",", "root_dir", ")", ":", "\n", "    ", "model_AttentionNet", ".", "eval", "(", ")", "\n", "for", "itr", ",", "data", "in", "enumerate", "(", "loader_test", ")", ":", "\n", "        ", "testImg", ",", "fileName", "=", "data", "[", "0", "]", ",", "data", "[", "1", "]", "\n", "if", "args", ".", "cuda", ":", "\n", "            ", "testImg", "=", "testImg", ".", "cuda", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "test_result", "=", "model_AttentionNet", "(", "testImg", ")", "\n", "test_result_img", "=", "train_utils", ".", "tensor2im", "(", "test_result", ")", "\n", "result_save_dir", "=", "root_dir", "+", "fileName", "[", "0", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "(", "'_epoch_{}_itr_{}.png'", ".", "format", "(", "epoch", ",", "itr", ")", ")", "\n", "train_utils", ".", "save_images", "(", "test_result_img", ",", "result_save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.training_VAN.main": [[58, 168], ["print", "data.dataset_DALE.DALETrain", "torch.utils.data.DataLoader", "print", "model.VisualAttentionNetwork.VisualAttentionNetwork", "print", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ExponentialLR", "print", "print", "range", "list", "print", "VisualAttentionNet.cuda.cuda", "VisualAttentionNet.cuda.train", "enumerate", "print", "VisualAttentionNet.cuda.parameters", "torch.optim.Adam.zero_grad", "VisualAttentionNet.cuda.", "L1_loss", "total_loss.backward", "torch.optim.Adam.step", "train.train_utils.save_checkpoint", "low_light_img.cuda.cuda", "ground_truth_img.cuda.cuda", "gt_Attention_img.cuda.cuda", "Perceptual_loss", "lr_scheduler.ExponentialLR.step", "print", "print", "training_VAN.visdom_loss", "collections.OrderedDict", "training_VAN.visdom_image", "lr_scheduler.ExponentialLR.get_last_lr", "L1_loss.item", "p_loss.item", "torch.no_grad", "torch.no_grad", "PIL.open", "torchvision.transforms.Compose", "transforms.Compose.unsqueeze", "val_image.cuda.cuda", "len", "VisualAttentionNet.cuda.eval", "torchvision.transforms.ToTensor", "transforms.Compose."], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.save_checkpoint", "home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.visdom_loss", "home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.visdom_image"], ["", "", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "\"\"\"Main Function : Data Loading -> Model Building -> Set Optimization -> Training\"\"\"", "\n", "# Setting Important Arguments #", "\n", "args", ".", "cuda", "=", "True", "\n", "args", ".", "epochs", "=", "200", "\n", "args", ".", "lr", "=", "1e-5", "\n", "args", ".", "batch_size", "=", "8", "\n", "\n", "# Setting Important Path #", "\n", "train_data_root", "=", "'D:\\data\\DALE/TRAIN/'", "\n", "model_save_root_dir", "=", "'D:\\Pytorch_code\\DALE/checkpoint/DALE_VAN/'", "\n", "model_root", "=", "'../checkpoint/DALE/'", "\n", "\n", "# Setting Important Traning Variable #", "\n", "VISUALIZATION_STEP", "=", "10", "\n", "SAVE_STEP", "=", "1", "\n", "\n", "print", "(", "\"DALE => Data Loading\"", ")", "\n", "\n", "train_data", "=", "dataset_DALE", ".", "DALETrain", "(", "train_data_root", ",", "args", ")", "\n", "loader_train", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "\n", "print", "(", "\"DALE => Model Building\"", ")", "\n", "VisualAttentionNet", "=", "VisualAttentionNetwork", ".", "VisualAttentionNetwork", "(", ")", "\n", "\n", "print", "(", "\"DALE => Set Optimization\"", ")", "\n", "optG", "=", "torch", ".", "optim", ".", "Adam", "(", "list", "(", "VisualAttentionNet", ".", "parameters", "(", ")", ")", ",", "lr", "=", "args", ".", "lr", ",", "betas", "=", "(", "0.5", ",", "0.999", ")", ")", "\n", "\n", "scheduler", "=", "lr_scheduler", ".", "ExponentialLR", "(", "optG", ",", "gamma", "=", "0.99", ")", "\n", "\n", "\n", "print", "(", "\"DALE => Setting GPU\"", ")", "\n", "if", "args", ".", "cuda", ":", "\n", "        ", "print", "(", "\"DALE => Use GPU\"", ")", "\n", "VisualAttentionNet", "=", "VisualAttentionNet", ".", "cuda", "(", ")", "\n", "", "print", "(", "\"DALE => Training\"", ")", "\n", "\n", "loss_step", "=", "0", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", ")", ":", "\n", "\n", "        ", "VisualAttentionNet", ".", "train", "(", ")", "\n", "\n", "for", "itr", ",", "data", "in", "enumerate", "(", "loader_train", ")", ":", "\n", "            ", "low_light_img", ",", "ground_truth_img", ",", "gt_Attention_img", ",", "file_name", "=", "data", "[", "0", "]", ",", "data", "[", "1", "]", ",", "data", "[", "2", "]", ",", "data", "[", "3", "]", "\n", "if", "args", ".", "cuda", ":", "\n", "                ", "low_light_img", "=", "low_light_img", ".", "cuda", "(", ")", "\n", "ground_truth_img", "=", "ground_truth_img", ".", "cuda", "(", ")", "\n", "gt_Attention_img", "=", "gt_Attention_img", ".", "cuda", "(", ")", "\n", "\n", "", "optG", ".", "zero_grad", "(", ")", "\n", "\n", "attention_result", "=", "VisualAttentionNet", "(", "low_light_img", ")", "\n", "\n", "mse_loss", "=", "L1_loss", "(", "attention_result", ",", "gt_Attention_img", ")", "\n", "p_loss", "=", "Perceptual_loss", "(", "attention_result", ",", "gt_Attention_img", ")", "*", "10", "\n", "\n", "total_loss", "=", "p_loss", "+", "mse_loss", "\n", "\n", "total_loss", ".", "backward", "(", ")", "\n", "optG", ".", "step", "(", ")", "\n", "\n", "if", "epoch", ">", "100", "and", "itr", "==", "0", ":", "\n", "                ", "scheduler", ".", "step", "(", ")", "\n", "print", "(", "scheduler", ".", "get_last_lr", "(", ")", ")", "\n", "\n", "", "if", "itr", "!=", "0", "and", "itr", "%", "VISUALIZATION_STEP", "==", "0", ":", "\n", "                ", "print", "(", "\"Epoch[{}/{}]({}/{}): \"", "\n", "\"mse_loss : {:.6f}, \"", "\n", "\"p_loss : {:.6f}\"", ".", "format", "(", "epoch", ",", "args", ".", "epochs", ",", "itr", ",", "len", "(", "loader_train", ")", ",", "mse_loss", ",", "p_loss", ")", ")", "\n", "\n", "# VISDOM LOSS GRAPH #", "\n", "loss_dict", "=", "{", "\n", "'mse_loss'", ":", "mse_loss", ".", "item", "(", ")", ",", "\n", "'p_loss'", ":", "p_loss", ".", "item", "(", ")", ",", "\n", "}", "\n", "\n", "visdom_loss", "(", "visdom", ",", "loss_step", ",", "loss_dict", ")", "\n", "\n", "# VISDOM VISUALIZATION # -> tensor to numpy => list ('title_name', img_tensor)", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "val_image", "=", "Image", ".", "open", "(", "'../validation/15.jpg'", ")", "\n", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "\n", "val_image", "=", "transform", "(", "(", "val_image", ")", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "val_image", "=", "val_image", ".", "cuda", "(", ")", "\n", "\n", "val_attention", "=", "VisualAttentionNet", ".", "eval", "(", ")", "(", "val_image", ")", "\n", "\n", "", "img_list", "=", "OrderedDict", "(", "\n", "[", "(", "'input'", ",", "low_light_img", ")", ",", "\n", "(", "'attention_output'", ",", "attention_result", ")", ",", "\n", "(", "'gt_Attention_img'", ",", "gt_Attention_img", ")", ",", "\n", "(", "'batch_sum'", ",", "attention_result", "+", "low_light_img", ")", ",", "\n", "(", "'ground_truth'", ",", "ground_truth_img", ")", ",", "\n", "(", "'val_attention'", ",", "val_attention", ")", ",", "\n", "(", "'val_sum'", ",", "val_image", "+", "val_attention", ")", "\n", "]", ")", "\n", "\n", "visdom_image", "(", "img_dict", "=", "img_list", ",", "window", "=", "10", ")", "\n", "loss_step", "=", "loss_step", "+", "1", "\n", "\n", "", "", "print", "(", "\"DALE => Testing\"", ")", "\n", "if", "epoch", "%", "SAVE_STEP", "==", "0", ":", "\n", "            ", "train_utils", ".", "save_checkpoint", "(", "VisualAttentionNet", ",", "epoch", ",", "model_save_root_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.adjust_learning_rate": [[7, 11], ["None"], "function", ["None"], ["def", "adjust_learning_rate", "(", "epoch", ",", "opt", ")", ":", "\n", "    ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"", "\n", "lr", "=", "opt", ".", "lr", "*", "(", "opt", ".", "gamma", "**", "(", "(", "epoch", "%", "opt", ".", "epochs", ")", "//", "opt", ".", "lr_decay", ")", ")", "\n", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.save_checkpoint": [[12, 19], ["print", "torch.save", "model.state_dict"], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.adversarial.Adversarial.state_dict"], ["", "def", "save_checkpoint", "(", "model", ",", "epoch", ",", "root_dir", ")", ":", "#model_out_path", "\n", "    ", "\"\"\"\n    :param path: model \uc800\uc7a5 \uba85 Pull Path\n    \"\"\"", "\n", "print", "(", "\"LessNet => Saving Model\"", ")", "\n", "model_out_path", "=", "\"tunning_low_part_epoch_{}.pth\"", ".", "format", "(", "epoch", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "root_dir", "+", "model_out_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.save_images": [[20, 29], ["Image.fromarray.save", "numpy.reshape", "PIL.Image.fromarray", "PIL.Image.fromarray"], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save"], ["", "def", "save_images", "(", "img_numpy", ",", "img_path", ")", ":", "\n", "    ", "\"\"\"train \uacb0\uacfc \uc774\ubbf8\uc9c0 \uc800\uc7a5 \ud568\uc218\"\"\"", "\n", "image_pil", "=", "None", "\n", "if", "img_numpy", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "        ", "img_numpy", "=", "np", ".", "reshape", "(", "img_numpy", ",", "(", "img_numpy", ".", "shape", "[", "0", "]", ",", "img_numpy", ".", "shape", "[", "1", "]", ")", ")", "\n", "image_pil", "=", "Image", ".", "fromarray", "(", "img_numpy", ",", "'L'", ")", "\n", "", "else", ":", "\n", "        ", "image_pil", "=", "Image", ".", "fromarray", "(", "img_numpy", ")", "\n", "", "image_pil", ".", "save", "(", "img_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.tensor2im": [[30, 36], ["torchvision.utils.make_grid().detach().cpu().float().numpy", "numpy.clip", "np.clip.astype", "numpy.transpose", "torchvision.utils.make_grid().detach().cpu().float", "torchvision.utils.make_grid().detach().cpu", "torchvision.utils.make_grid().detach", "torchvision.utils.make_grid"], "function", ["None"], ["", "def", "tensor2im", "(", "image_tensor", ",", "imtype", "=", "np", ".", "uint8", ")", ":", "\n", "# image_tensor = torch.clamp(image_tensor, min=0.0, max=1.0)", "\n", "    ", "image_numpy", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "image_tensor", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "\n", "image_numpy", "=", "np", ".", "transpose", "(", "image_numpy", ",", "(", "1", ",", "2", ",", "0", ")", ")", "*", "255", "\n", "image_numpy", "=", "np", ".", "clip", "(", "image_numpy", ",", "0", ",", "255", ")", "\n", "return", "image_numpy", ".", "astype", "(", "imtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.save_results_RGB": [[37, 42], ["result[].data.mul", "result[].data.mul.byte().permute().cpu().numpy", "scipy.imsave", "result[].data.mul.byte().permute().cpu", "result[].data.mul.byte().permute", "result[].data.mul.byte"], "function", ["None"], ["", "def", "save_results_RGB", "(", "result", ",", "filename", ")", ":", "\n", "    ", "filename", "=", "filename", "\n", "normalized", "=", "result", "[", "0", "]", ".", "data", ".", "mul", "(", "255", "/", "255", ")", "\n", "ndarr", "=", "normalized", ".", "byte", "(", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "misc", ".", "imsave", "(", "'{}.png'", ".", "format", "(", "filename", ")", ",", "ndarr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.quantize": [[43, 46], ["img.mul().clamp().round().div", "img.mul().clamp().round", "img.mul().clamp", "img.mul"], "function", ["None"], ["", "def", "quantize", "(", "img", ",", "rgb_range", ")", ":", "\n", "    ", "pixel_range", "=", "255", "/", "rgb_range", "\n", "return", "img", ".", "mul", "(", "pixel_range", ")", ".", "clamp", "(", "0", ",", "255", ")", ".", "round", "(", ")", ".", "div", "(", "pixel_range", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.training_EN.visdom_loss": [[25, 37], ["loss_data[].append", "loss_data[].append", "visdom.line", "numpy.stack", "numpy.array", "dict", "len", "numpy.array"], "function", ["None"], ["def", "visdom_loss", "(", "visdom", ",", "loss_step", ",", "loss_dict", ")", ":", "\n", "    ", "loss_data", "[", "'X'", "]", ".", "append", "(", "loss_step", ")", "\n", "loss_data", "[", "'Y'", "]", ".", "append", "(", "[", "loss_dict", "[", "k", "]", "for", "k", "in", "loss_data", "[", "'legend_U'", "]", "]", ")", "\n", "visdom", ".", "line", "(", "\n", "X", "=", "np", ".", "stack", "(", "[", "np", ".", "array", "(", "loss_data", "[", "'X'", "]", ")", "]", "*", "len", "(", "loss_data", "[", "'legend_U'", "]", ")", ",", "1", ")", ",", "\n", "Y", "=", "np", ".", "array", "(", "loss_data", "[", "'Y'", "]", ")", ",", "\n", "win", "=", "1", ",", "\n", "opts", "=", "dict", "(", "xlabel", "=", "'Step'", ",", "\n", "ylabel", "=", "'Loss'", ",", "\n", "title", "=", "'Training loss'", ",", "\n", "legend", "=", "loss_data", "[", "'legend_U'", "]", ")", ",", "\n", "update", "=", "'append'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.training_EN.visdom_image": [[39, 44], ["enumerate", "train.train_utils.tensor2im", "visdom.image", "train_utils.tensor2im.transpose", "dict"], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.tensor2im"], ["", "def", "visdom_image", "(", "img_dict", ",", "window", ")", ":", "\n", "    ", "for", "idx", ",", "key", "in", "enumerate", "(", "img_dict", ")", ":", "\n", "        ", "win", "=", "window", "+", "idx", "\n", "tensor_img", "=", "train_utils", ".", "tensor2im", "(", "img_dict", "[", "key", "]", ".", "data", ")", "\n", "visdom", ".", "image", "(", "tensor_img", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ",", "opts", "=", "dict", "(", "title", "=", "key", ")", ",", "win", "=", "win", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.training_EN.test": [[45, 57], ["model_AttentionNet.eval", "enumerate", "testImg.cuda.cuda", "torch.no_grad", "torch.no_grad", "model_AttentionNet", "train.train_utils.tensor2im", "train.train_utils.save_images", "fileName[].split"], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.tensor2im", "home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.save_images"], ["", "", "def", "test", "(", "args", ",", "loader_test", ",", "model_AttentionNet", ",", "epoch", ",", "root_dir", ")", ":", "\n", "    ", "model_AttentionNet", ".", "eval", "(", ")", "\n", "for", "itr", ",", "data", "in", "enumerate", "(", "loader_test", ")", ":", "\n", "        ", "testImg", ",", "fileName", "=", "data", "[", "0", "]", ",", "data", "[", "1", "]", "\n", "if", "args", ".", "cuda", ":", "\n", "            ", "testImg", "=", "testImg", ".", "cuda", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "test_result", "=", "model_AttentionNet", "(", "testImg", ")", "\n", "test_result_img", "=", "train_utils", ".", "tensor2im", "(", "test_result", ")", "\n", "result_save_dir", "=", "root_dir", "+", "fileName", "[", "0", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "(", "'_epoch_{}_itr_{}.png'", ".", "format", "(", "epoch", ",", "itr", ")", ")", "\n", "train_utils", ".", "save_images", "(", "test_result_img", ",", "result_save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.training_EN.main": [[58, 183], ["print", "data.dataset_DALE.DALETrain", "torch.utils.data.DataLoader", "print", "model.VisualAttentionNetwork.VisualAttentionNetwork", "torch.load", "torch.load", "VisualAttentionNet.cuda.load_state_dict", "model.EnhancementNet.EnhancementNet", "print", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ExponentialLR", "filter", "sum", "print", "print", "print", "range", "list", "EnhanceNet.cuda.parameters", "print", "VisualAttentionNet.cuda.cuda", "EnhanceNet.cuda.cuda", "EnhanceNet.cuda.train", "enumerate", "print", "EnhanceNet.cuda.parameters", "numpy.prod", "torch.optim.Adam.zero_grad", "VisualAttentionNet.cuda.", "EnhanceNet.cuda.", "L2_loss", "total_loss.backward", "torch.optim.Adam.step", "train.train_utils.save_checkpoint", "p.size", "low_light_img.cuda.cuda", "ground_truth_img.cuda.cuda", "gt_Attention_img.cuda.cuda", "VisualAttentionNet.detach", "Perceptual_loss", "TvLoss", "lr_scheduler.ExponentialLR.step", "print", "print", "training_EN.visdom_loss", "collections.OrderedDict", "training_EN.visdom_image", "lr_scheduler.ExponentialLR.get_last_lr", "L2_loss.item", "tv_loss.item", "p_loss.item", "torch.no_grad", "torch.no_grad", "PIL.open", "torchvision.transforms.Compose", "transforms.Compose.unsqueeze", "val_image.cuda.cuda", "len", "VisualAttentionNet.cuda.eval", "EnhanceNet.cuda.eval", "torchvision.transforms.ToTensor", "transforms.Compose."], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.train.train_utils.save_checkpoint", "home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.visdom_loss", "home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.visdom_image"], ["", "", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "args", ".", "cuda", "=", "True", "\n", "args", ".", "epochs", "=", "200", "\n", "args", ".", "lr", "=", "1e-5", "\n", "args", ".", "batch_size", "=", "4", "\n", "\n", "# Setting Important Path #", "\n", "train_data_root", "=", "'D:\\data\\DALE/TRAIN/'", "\n", "model_save_root_dir", "=", "'../checkpoint/DALE/'", "\n", "model_root", "=", "'../checkpoint/'", "\n", "\n", "# Setting Important Traning Variable #", "\n", "VISUALIZATION_STEP", "=", "50", "\n", "SAVE_STEP", "=", "1", "\n", "\n", "print", "(", "\"DALE => Data Loading\"", ")", "\n", "\n", "train_data", "=", "dataset_DALE", ".", "DALETrain", "(", "train_data_root", ",", "args", ")", "\n", "loader_train", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "\n", "print", "(", "\"DALE => Model Building\"", ")", "\n", "VisualAttentionNet", "=", "VisualAttentionNetwork", ".", "VisualAttentionNetwork", "(", ")", "\n", "\n", "state_dict", "=", "torch", ".", "load", "(", "model_root", "+", "'VAN.pth'", ")", "\n", "VisualAttentionNet", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "EnhanceNet", "=", "EnhancementNet", ".", "EnhancementNet", "(", ")", "\n", "\n", "print", "(", "\"DALE => Set Optimization\"", ")", "\n", "optG", "=", "torch", ".", "optim", ".", "Adam", "(", "list", "(", "EnhanceNet", ".", "parameters", "(", ")", ")", ",", "lr", "=", "args", ".", "lr", ",", "betas", "=", "(", "0.5", ",", "0.999", ")", ")", "\n", "\n", "scheduler", "=", "lr_scheduler", ".", "ExponentialLR", "(", "optG", ",", "gamma", "=", "0.99", ")", "\n", "\n", "model_EnhanceNet_parameters", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "EnhanceNet", ".", "parameters", "(", ")", ")", "\n", "\n", "params1", "=", "sum", "(", "[", "np", ".", "prod", "(", "p", ".", "size", "(", ")", ")", "for", "p", "in", "model_EnhanceNet_parameters", "]", ")", "\n", "\n", "print", "(", "\"Parameters | \"", ",", "params1", ")", "\n", "\n", "print", "(", "\"DALE => Setting GPU\"", ")", "\n", "if", "args", ".", "cuda", ":", "\n", "        ", "print", "(", "\"DALE => Use GPU\"", ")", "\n", "VisualAttentionNet", "=", "VisualAttentionNet", ".", "cuda", "(", ")", "\n", "EnhanceNet", "=", "EnhanceNet", ".", "cuda", "(", ")", "\n", "", "print", "(", "\"DALE => Training\"", ")", "\n", "\n", "loss_step", "=", "0", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", ")", ":", "\n", "\n", "        ", "EnhanceNet", ".", "train", "(", ")", "\n", "\n", "for", "itr", ",", "data", "in", "enumerate", "(", "loader_train", ")", ":", "\n", "            ", "low_light_img", ",", "ground_truth_img", ",", "gt_Attention_img", ",", "file_name", "=", "data", "[", "0", "]", ",", "data", "[", "1", "]", ",", "data", "[", "2", "]", ",", "data", "[", "3", "]", "\n", "if", "args", ".", "cuda", ":", "\n", "                ", "low_light_img", "=", "low_light_img", ".", "cuda", "(", ")", "\n", "ground_truth_img", "=", "ground_truth_img", ".", "cuda", "(", ")", "\n", "gt_Attention_img", "=", "gt_Attention_img", ".", "cuda", "(", ")", "\n", "\n", "", "optG", ".", "zero_grad", "(", ")", "\n", "\n", "attention_result", "=", "VisualAttentionNet", "(", "low_light_img", ")", "\n", "enhance_result", "=", "EnhanceNet", "(", "low_light_img", ",", "attention_result", ".", "detach", "(", ")", ")", "\n", "\n", "mse_loss", "=", "L2_loss", "(", "enhance_result", ",", "ground_truth_img", ")", "\n", "p_loss", "=", "Perceptual_loss", "(", "enhance_result", ",", "ground_truth_img", ")", "*", "50", "\n", "tv_loss", "=", "TvLoss", "(", "enhance_result", ")", "*", "20", "\n", "\n", "total_loss", "=", "p_loss", "+", "mse_loss", "+", "tv_loss", "\n", "\n", "total_loss", ".", "backward", "(", ")", "\n", "optG", ".", "step", "(", ")", "\n", "\n", "if", "epoch", ">", "100", "and", "itr", "==", "0", ":", "\n", "                ", "scheduler", ".", "step", "(", ")", "\n", "print", "(", "scheduler", ".", "get_last_lr", "(", ")", ")", "\n", "\n", "", "if", "itr", "!=", "0", "and", "itr", "%", "VISUALIZATION_STEP", "==", "0", ":", "\n", "                ", "print", "(", "\"Epoch[{}/{}]({}/{}): \"", "\n", "\"mse_loss : {:.6f}, \"", "\n", "\"tv_loss : {:.6f}, \"", "\n", "\"p_loss : {:.6f}\"", ".", "format", "(", "epoch", ",", "args", ".", "epochs", ",", "itr", ",", "len", "(", "loader_train", ")", ",", "mse_loss", ",", "tv_loss", ",", "p_loss", ")", ")", "\n", "# VISDOM LOSS GRAPH #", "\n", "\n", "loss_dict", "=", "{", "\n", "'mse_loss'", ":", "mse_loss", ".", "item", "(", ")", ",", "\n", "'tv_loss'", ":", "tv_loss", ".", "item", "(", ")", ",", "\n", "'p_loss'", ":", "p_loss", ".", "item", "(", ")", ",", "\n", "}", "\n", "\n", "visdom_loss", "(", "visdom", ",", "loss_step", ",", "loss_dict", ")", "\n", "\n", "# VISDOM VISUALIZATION # -> tensor to numpy => list ('title_name', img_tensor)", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "val_image", "=", "Image", ".", "open", "(", "'../validation/15.jpg'", ")", "\n", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "# transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))", "\n", "]", ")", "\n", "\n", "val_image", "=", "transform", "(", "(", "val_image", ")", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "val_image", "=", "val_image", ".", "cuda", "(", ")", "\n", "\n", "val_attention", "=", "VisualAttentionNet", ".", "eval", "(", ")", "(", "val_image", ")", "\n", "val_result", "=", "EnhanceNet", ".", "eval", "(", ")", "(", "val_image", ",", "val_attention", ")", "\n", "\n", "", "img_list", "=", "OrderedDict", "(", "\n", "[", "(", "'input'", ",", "low_light_img", ")", ",", "\n", "(", "'output'", ",", "enhance_result", ")", ",", "\n", "(", "'attention_output'", ",", "attention_result", ")", ",", "\n", "(", "'gt_Attention_img'", ",", "gt_Attention_img", ")", ",", "\n", "(", "'batch_sum'", ",", "attention_result", "+", "low_light_img", ")", ",", "\n", "(", "'ground_truth'", ",", "ground_truth_img", ")", ",", "\n", "(", "'val_result'", ",", "val_result", ")", "]", ")", "\n", "\n", "visdom_image", "(", "img_dict", "=", "img_list", ",", "window", "=", "10", ")", "\n", "\n", "loss_step", "=", "loss_step", "+", "1", "\n", "\n", "", "", "print", "(", "\"DALE => Testing\"", ")", "\n", "if", "epoch", "%", "SAVE_STEP", "==", "0", ":", "\n", "            ", "train_utils", ".", "save_checkpoint", "(", "EnhanceNet", ",", "epoch", ",", "model_save_root_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.tensor2im": [[4, 10], ["torchvision.utils.make_grid().detach().cpu().float().numpy", "numpy.clip", "np.clip.astype", "numpy.transpose", "torchvision.utils.make_grid().detach().cpu().float", "torchvision.utils.make_grid().detach().cpu", "torchvision.utils.make_grid().detach", "torchvision.utils.make_grid"], "function", ["None"], ["def", "tensor2im", "(", "image_tensor", ",", "imtype", "=", "np", ".", "uint8", ")", ":", "\n", "# image_tensor = torch.clamp(image_tensor, min=0.0, max=1.0)", "\n", "    ", "image_numpy", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "image_tensor", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "\n", "image_numpy", "=", "np", ".", "transpose", "(", "image_numpy", ",", "(", "1", ",", "2", ",", "0", ")", ")", "*", "255", "\n", "image_numpy", "=", "np", ".", "clip", "(", "image_numpy", ",", "0", ",", "255", ")", "\n", "return", "image_numpy", ".", "astype", "(", "imtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.visdom_loss": [[11, 23], ["loss_data[].append", "loss_data[].append", "visdom.line", "numpy.stack", "numpy.array", "dict", "len", "numpy.array"], "function", ["None"], ["", "def", "visdom_loss", "(", "visdom", ",", "loss_step", ",", "loss_dict", ")", ":", "\n", "    ", "loss_data", "[", "'X'", "]", ".", "append", "(", "loss_step", ")", "\n", "loss_data", "[", "'Y'", "]", ".", "append", "(", "[", "loss_dict", "[", "k", "]", "for", "k", "in", "loss_data", "[", "'legend_U'", "]", "]", ")", "\n", "visdom", ".", "line", "(", "\n", "X", "=", "np", ".", "stack", "(", "[", "np", ".", "array", "(", "loss_data", "[", "'X'", "]", ")", "]", "*", "len", "(", "loss_data", "[", "'legend_U'", "]", ")", ",", "1", ")", ",", "\n", "Y", "=", "np", ".", "array", "(", "loss_data", "[", "'Y'", "]", ")", ",", "\n", "win", "=", "1", ",", "\n", "opts", "=", "dict", "(", "xlabel", "=", "'Step'", ",", "\n", "ylabel", "=", "'Loss'", ",", "\n", "title", "=", "'Training loss'", ",", "\n", "legend", "=", "loss_data", "[", "'legend_U'", "]", ")", ",", "\n", "update", "=", "'append'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.visdom_image": [[25, 30], ["enumerate", "visdom_utils.tensor2im", "visdom.image", "tensor2im.transpose", "dict"], "function", ["home.repos.pwc.inspect_result.dokyeongK_DALE.train.visdom_utils.tensor2im"], ["", "def", "visdom_image", "(", "img_dict", ",", "window", ")", ":", "\n", "    ", "for", "idx", ",", "key", "in", "enumerate", "(", "img_dict", ")", ":", "\n", "        ", "win", "=", "window", "+", "idx", "\n", "tensor_img", "=", "tensor2im", "(", "img_dict", "[", "key", "]", ".", "data", ")", "\n", "visdom", ".", "image", "(", "tensor_img", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ",", "opts", "=", "dict", "(", "title", "=", "key", ")", ",", "win", "=", "win", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_utils.get_patch_low_light": [[5, 19], ["random.randrange", "random.randrange", "low_light.crop", "ground_truth.crop"], "function", ["None"], ["def", "get_patch_low_light", "(", "low_light", ",", "ground_truth", ",", "patch_size", ")", ":", "\n", "#\uc218\uc815\ud574\uc57c\ud568", "\n", "    ", "height", ",", "width", "=", "low_light", ".", "size", "[", "1", "]", ",", "low_light", ".", "size", "[", "0", "]", "\n", "\n", "ix", "=", "random", ".", "randrange", "(", "0", ",", "width", "-", "patch_size", "+", "1", ")", "\n", "iy", "=", "random", ".", "randrange", "(", "0", ",", "height", "-", "patch_size", "+", "1", ")", "\n", "\n", "# \uac00\ub85c\uc2dc\uc791\uc810, \uc138\ub85c\uc2dc\uc791\uc810, \uac00\ub85c\ubc94\uc704, \uc138\ub85c\ubc94\uc704", "\n", "crop_area", "=", "(", "ix", ",", "iy", ",", "ix", "+", "patch_size", ",", "iy", "+", "patch_size", ")", "\n", "\n", "low_light_img", "=", "low_light", ".", "crop", "(", "crop_area", ")", "\n", "ground_truth_img", "=", "ground_truth", ".", "crop", "(", "crop_area", ")", "\n", "\n", "return", "low_light_img", ",", "ground_truth_img", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_utils.get_patch_low_light_global": [[20, 41], ["random.randrange", "random.randrange", "random.randint", "low_light.crop", "ground_truth.crop", "ground_truth.crop", "PIL.ImageEnhance.Brightness", "ImageEnhance.Brightness.enhance", "ground_truth.crop", "random.randint"], "function", ["None"], ["", "def", "get_patch_low_light_global", "(", "low_light", ",", "ground_truth", ",", "patch_size", ")", ":", "\n", "#\uc218\uc815\ud574\uc57c\ud568", "\n", "    ", "height", ",", "width", "=", "low_light", ".", "size", "[", "1", "]", ",", "low_light", ".", "size", "[", "0", "]", "\n", "\n", "ix", "=", "random", ".", "randrange", "(", "0", ",", "width", "-", "patch_size", "+", "1", ")", "\n", "iy", "=", "random", ".", "randrange", "(", "0", ",", "height", "-", "patch_size", "+", "1", ")", "\n", "\n", "# \uac00\ub85c\uc2dc\uc791\uc810, \uc138\ub85c\uc2dc\uc791\uc810, \uac00\ub85c\ubc94\uc704, \uc138\ub85c\ubc94\uc704", "\n", "crop_area", "=", "(", "ix", ",", "iy", ",", "ix", "+", "patch_size", ",", "iy", "+", "patch_size", ")", "\n", "select_num", "=", "random", ".", "randint", "(", "1", ",", "2", ")", "\n", "if", "select_num", "==", "1", ":", "\n", "        ", "low_light_img", "=", "low_light", ".", "crop", "(", "crop_area", ")", "\n", "ground_truth_img", "=", "ground_truth", ".", "crop", "(", "crop_area", ")", "\n", "", "else", ":", "\n", "        ", "illumination", "=", "random", ".", "randint", "(", "1", ",", "10", ")", "*", "0.1", "\n", "low_light_img", "=", "ground_truth", ".", "crop", "(", "crop_area", ")", "\n", "global_illumination_Image", "=", "ImageEnhance", ".", "Brightness", "(", "low_light_img", ")", "\n", "low_light_img", "=", "global_illumination_Image", ".", "enhance", "(", "illumination", ")", "\n", "ground_truth_img", "=", "ground_truth", ".", "crop", "(", "crop_area", ")", "\n", "\n", "", "return", "low_light_img", ",", "ground_truth_img", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_utils.augmentation_low_light": [[43, 64], ["random.randint", "low_light.transpose.rotate", "ground_truth.transpose.rotate", "low_light.transpose.transpose", "ground_truth.transpose.transpose", "low_light.transpose.transpose", "ground_truth.transpose.transpose", "random.random", "random.random", "random.random"], "function", ["None"], ["", "def", "augmentation_low_light", "(", "low_light", ",", "ground_truth", ",", "args", ")", ":", "\n", "    ", "rotate", "=", "args", ".", "augment_rotate", "==", "0", "and", "random", ".", "random", "(", ")", "<", "0.5", "\n", "augment_T2B", "=", "args", ".", "augment_T2B", "==", "0", "and", "random", ".", "random", "(", ")", "<", "0.5", "\n", "augment_L2R", "=", "args", ".", "augment_L2R", "==", "0", "and", "random", ".", "random", "(", ")", "<", "0.5", "\n", "\n", "if", "rotate", ":", "\n", "        ", "i", "=", "random", ".", "randint", "(", "0", ",", "3", ")", "# 1\ubd80\ud130 100 \uc0ac\uc774\uc758 \uc784\uc758\uc758 \uc815\uc218", "\n", "rotate_list", "=", "[", "90", ",", "180", ",", "-", "90", ",", "-", "180", "]", "\n", "low_light", "=", "low_light", ".", "rotate", "(", "rotate_list", "[", "i", "]", ")", "\n", "ground_truth", "=", "ground_truth", ".", "rotate", "(", "rotate_list", "[", "i", "]", ")", "\n", "\n", "\n", "", "if", "augment_T2B", ":", "\n", "        ", "low_light", "=", "low_light", ".", "transpose", "(", "Image", ".", "FLIP_TOP_BOTTOM", ")", "\n", "ground_truth", "=", "ground_truth", ".", "transpose", "(", "Image", ".", "FLIP_TOP_BOTTOM", ")", "\n", "\n", "", "if", "augment_L2R", ":", "\n", "        ", "low_light", "=", "low_light", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "ground_truth", "=", "ground_truth", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "\n", "", "return", "low_light", ",", "ground_truth", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_utils.get_patch_sr": [[65, 93], ["int", "random.randrange", "random.randrange", "random.randrange", "random.randrange", "low_light_image.crop", "low_light_ground_truth_image.crop", "hr_image.crop", "hr_image.crop"], "function", ["None"], ["", "def", "get_patch_sr", "(", "low_light_image", ",", "low_light_ground_truth_image", ",", "hr_image", ",", "patch_size", ",", "scale", ")", ":", "\n", "\n", "    ", "hr_height", ",", "hr_width", "=", "hr_image", ".", "size", "[", "1", "]", ",", "hr_image", ".", "size", "[", "0", "]", "\n", "lr_height", ",", "lr_width", "=", "low_light_image", ".", "size", "[", "1", "]", ",", "low_light_image", ".", "size", "[", "0", "]", "\n", "\n", "hr_patch_size", "=", "(", "int", ")", "(", "scale", "*", "patch_size", ")", "# 128", "\n", "lr_patch_size", "=", "patch_size", "\n", "\n", "lr_x", "=", "random", ".", "randrange", "(", "0", ",", "lr_width", "-", "lr_patch_size", "+", "1", ")", "\n", "lr_y", "=", "random", ".", "randrange", "(", "0", ",", "lr_height", "-", "lr_patch_size", "+", "1", ")", "\n", "\n", "hr_x", "=", "lr_x", "*", "scale", "\n", "hr_y", "=", "lr_y", "*", "scale", "\n", "\n", "target_hr_x", "=", "random", ".", "randrange", "(", "0", ",", "hr_width", "-", "hr_patch_size", "+", "1", ")", "\n", "target_hr_y", "=", "random", ".", "randrange", "(", "0", ",", "hr_height", "-", "hr_patch_size", "+", "1", ")", "\n", "\n", "lr_crop_area", "=", "(", "lr_x", ",", "lr_y", ",", "lr_x", "+", "lr_patch_size", ",", "lr_y", "+", "lr_patch_size", ")", "\n", "hr_crop_area", "=", "(", "hr_x", ",", "hr_y", ",", "hr_x", "+", "hr_patch_size", ",", "hr_y", "+", "hr_patch_size", ")", "\n", "target_hr_crop_area", "=", "(", "target_hr_x", ",", "target_hr_y", ",", "target_hr_x", "+", "hr_patch_size", ",", "target_hr_y", "+", "hr_patch_size", ")", "\n", "\n", "lr_patch", "=", "low_light_image", ".", "crop", "(", "lr_crop_area", ")", "\n", "lr_gt_patch", "=", "low_light_ground_truth_image", ".", "crop", "(", "lr_crop_area", ")", "\n", "hr_patch", "=", "hr_image", ".", "crop", "(", "hr_crop_area", ")", "\n", "# lr_patch = hr_patch.resize((patch_size, patch_size), Image.BICUBIC)", "\n", "hr_target_patch", "=", "hr_image", ".", "crop", "(", "target_hr_crop_area", ")", "\n", "\n", "return", "lr_patch", ",", "lr_gt_patch", ",", "hr_patch", ",", "hr_target_patch", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_utils.augmentation_sr": [[94, 121], ["random.randint", "lr_patch.transpose.rotate", "lr_gt_patch.transpose.rotate", "hr_patch.transpose.rotate", "hr_target_patch.transpose.rotate", "lr_patch.transpose.transpose", "lr_gt_patch.transpose.transpose", "hr_patch.transpose.transpose", "hr_target_patch.transpose.transpose", "lr_patch.transpose.transpose", "lr_gt_patch.transpose.transpose", "hr_patch.transpose.transpose", "hr_target_patch.transpose.transpose", "random.random", "random.random", "random.random"], "function", ["None"], ["", "def", "augmentation_sr", "(", "lr_patch", ",", "lr_gt_patch", ",", "hr_patch", ",", "hr_target_patch", ",", "args", ")", ":", "\n", "    ", "rotate", "=", "args", ".", "augment_rotate", "==", "0", "and", "random", ".", "random", "(", ")", "<", "0.5", "\n", "augment_T2B", "=", "args", ".", "augment_T2B", "==", "0", "and", "random", ".", "random", "(", ")", "<", "0.5", "\n", "augment_L2R", "=", "args", ".", "augment_L2R", "==", "0", "and", "random", ".", "random", "(", ")", "<", "0.5", "\n", "\n", "if", "rotate", ":", "\n", "        ", "i", "=", "random", ".", "randint", "(", "0", ",", "3", ")", "# 1\ubd80\ud130 100 \uc0ac\uc774\uc758 \uc784\uc758\uc758 \uc815\uc218", "\n", "rotate_list", "=", "[", "90", ",", "180", ",", "-", "90", ",", "-", "180", "]", "\n", "lr_patch", "=", "lr_patch", ".", "rotate", "(", "rotate_list", "[", "i", "]", ")", "\n", "lr_gt_patch", "=", "lr_gt_patch", ".", "rotate", "(", "rotate_list", "[", "i", "]", ")", "\n", "hr_patch", "=", "hr_patch", ".", "rotate", "(", "rotate_list", "[", "i", "]", ")", "\n", "hr_target_patch", "=", "hr_target_patch", ".", "rotate", "(", "rotate_list", "[", "i", "]", ")", "\n", "\n", "\n", "", "if", "augment_T2B", ":", "\n", "        ", "lr_patch", "=", "lr_patch", ".", "transpose", "(", "Image", ".", "FLIP_TOP_BOTTOM", ")", "\n", "lr_gt_patch", "=", "lr_gt_patch", ".", "transpose", "(", "Image", ".", "FLIP_TOP_BOTTOM", ")", "\n", "hr_patch", "=", "hr_patch", ".", "transpose", "(", "Image", ".", "FLIP_TOP_BOTTOM", ")", "\n", "hr_target_patch", "=", "hr_target_patch", ".", "transpose", "(", "Image", ".", "FLIP_TOP_BOTTOM", ")", "\n", "\n", "", "if", "augment_L2R", ":", "\n", "        ", "lr_patch", "=", "lr_patch", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "lr_gt_patch", "=", "lr_gt_patch", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "hr_patch", "=", "hr_patch", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "hr_target_patch", "=", "hr_target_patch", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "\n", "", "return", "lr_patch", ",", "lr_gt_patch", ",", "hr_patch", ",", "hr_target_patch", "", "", ""]], "home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_DALE.DALETrain.__init__": [[10, 33], ["os.listdir", "os.listdir", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root_dir", ",", "args", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            1) root directory -> D:\\data\\LessNet\\TRAIN\\\n            2) arguments -> args\n        \"\"\"", "\n", "self", ".", "low_light_dir", "=", "root_dir", "+", "'SuperPixel'", "\n", "self", ".", "ground_truth_dir", "=", "root_dir", "+", "'GT'", "\n", "self", ".", "low_light_img_list", "=", "os", ".", "listdir", "(", "root_dir", "+", "'SuperPixel'", ")", "\n", "self", ".", "ground_truth_img_list", "=", "os", ".", "listdir", "(", "root_dir", "+", "'GT'", ")", "\n", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "\n", "]", ")", "\n", "\n", "self", ".", "transform2", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", "\n", "]", ")", "\n", "\n", "# patch_size : default == 128", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "patch_size", "=", "240", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_DALE.DALETrain.__len__": [[35, 37], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "low_light_img_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_DALE.DALETrain.__getitem__": [[38, 72], ["PIL.open", "PIL.open", "data.dataset_utils.get_patch_low_light", "data.dataset_utils.augmentation_low_light", "numpy.asarray().astype", "numpy.asarray().astype", "numpy.clip().astype", "dataset_DALE.DALETrain.transform2", "dataset_DALE.DALETrain.transform2", "dataset_DALE.DALETrain.transform2", "os.path.join", "os.path.join", "numpy.asarray", "numpy.asarray", "numpy.clip"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_utils.get_patch_low_light", "home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_utils.augmentation_low_light"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"\n        Get a random pair of image crops.\n        It returns a tuple of float tensors with shape [3, height, width].\n        They represent RGB images with pixel values in [0, 1] range.\n        :return: Low-light image, Ground-truth image tensor\n        \"\"\"", "\n", "low_light_name", ",", "ground_truth_name", "=", "self", ".", "low_light_img_list", "[", "idx", "]", ",", "self", ".", "ground_truth_img_list", "[", "idx", "]", "\n", "\n", "low_light_image", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "low_light_dir", ",", "low_light_name", ")", ")", "\n", "ground_truth_image", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "ground_truth_dir", ",", "ground_truth_name", ")", ")", "\n", "\n", "# Get crop image", "\n", "low_light_patch", ",", "ground_truth_patch", "=", "utils", ".", "get_patch_low_light", "(", "low_light_image", ",", "ground_truth_image", ",", "self", ".", "patch_size", ")", "\n", "\n", "# Get augmented image", "\n", "low_light_patch", ",", "ground_truth_patch", "=", "utils", ".", "augmentation_low_light", "(", "low_light_patch", ",", "ground_truth_patch", ",", "self", ".", "args", ")", "\n", "# Get the image buffer as ndarray", "\n", "\n", "buffer1", "=", "np", ".", "asarray", "(", "low_light_patch", ")", ".", "astype", "(", "np", ".", "long", ")", "\n", "\n", "buffer2", "=", "np", ".", "asarray", "(", "ground_truth_patch", ")", ".", "astype", "(", "np", ".", "long", ")", "\n", "\n", "# Subtract image2 from image1", "\n", "\n", "attention_patch", "=", "np", ".", "clip", "(", "buffer2", "-", "buffer1", ",", "0", ",", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "# Convert to tensor", "\n", "low_light_tensor", "=", "self", ".", "transform2", "(", "low_light_patch", ")", "\n", "ground_truth_tensor", "=", "self", ".", "transform2", "(", "ground_truth_patch", ")", "\n", "attention_tensor", "=", "self", ".", "transform2", "(", "attention_patch", ")", "\n", "\n", "\n", "return", "low_light_tensor", ",", "ground_truth_tensor", ",", "attention_tensor", ",", "ground_truth_name", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_DALE.DALETrainGlobal.__init__": [[74, 92], ["os.listdir", "os.listdir", "torchvision.transforms.Compose", "torchvision.transforms.ToTensor"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root_dir", ",", "args", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            1) root directory -> D:\\data\\LessNet\\TRAIN\\\n            2) arguments -> args\n        \"\"\"", "\n", "self", ".", "low_light_dir", "=", "root_dir", "+", "'SuperPixel'", "\n", "self", ".", "ground_truth_dir", "=", "root_dir", "+", "'GT'", "\n", "self", ".", "low_light_img_list", "=", "os", ".", "listdir", "(", "root_dir", "+", "'SuperPixel'", ")", "\n", "self", ".", "ground_truth_img_list", "=", "os", ".", "listdir", "(", "root_dir", "+", "'GT'", ")", "\n", "\n", "self", ".", "transform2", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", "\n", "]", ")", "\n", "\n", "# patch_size : default == 128", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "patch_size", "=", "240", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_DALE.DALETrainGlobal.__len__": [[94, 96], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "low_light_img_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_DALE.DALETrainGlobal.__getitem__": [[97, 125], ["PIL.open", "PIL.open", "data.dataset_utils.get_patch_low_light_global", "data.dataset_utils.augmentation_low_light", "numpy.asarray", "numpy.asarray", "dataset_DALE.DALETrainGlobal.transform2", "dataset_DALE.DALETrainGlobal.transform2", "dataset_DALE.DALETrainGlobal.transform2", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_utils.get_patch_low_light_global", "home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_utils.augmentation_low_light"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "low_light_name", ",", "ground_truth_name", "=", "self", ".", "low_light_img_list", "[", "idx", "]", ",", "self", ".", "ground_truth_img_list", "[", "idx", "]", "\n", "\n", "low_light_image", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "low_light_dir", ",", "low_light_name", ")", ")", "\n", "ground_truth_image", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "ground_truth_dir", ",", "ground_truth_name", ")", ")", "\n", "\n", "# Get crop image", "\n", "low_light_patch", ",", "ground_truth_patch", "=", "utils", ".", "get_patch_low_light_global", "(", "low_light_image", ",", "ground_truth_image", ",", "self", ".", "patch_size", ")", "\n", "\n", "# Get augmented image", "\n", "low_light_patch", ",", "ground_truth_patch", "=", "utils", ".", "augmentation_low_light", "(", "low_light_patch", ",", "ground_truth_patch", ",", "self", ".", "args", ")", "\n", "# Get the image buffer as ndarray", "\n", "\n", "buffer1", "=", "np", ".", "asarray", "(", "low_light_patch", ")", "\n", "\n", "buffer2", "=", "np", ".", "asarray", "(", "ground_truth_patch", ")", "\n", "\n", "# Subtract image2 from image1", "\n", "\n", "attention_patch", "=", "buffer2", "-", "buffer1", "\n", "\n", "# Convert to tensor", "\n", "low_light_tensor", "=", "self", ".", "transform2", "(", "low_light_patch", ")", "\n", "ground_truth_tensor", "=", "self", ".", "transform2", "(", "ground_truth_patch", ")", "\n", "attention_tensor", "=", "self", ".", "transform2", "(", "attention_patch", ")", "\n", "\n", "return", "low_light_tensor", ",", "ground_truth_tensor", ",", "attention_tensor", ",", "ground_truth_name", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_DALE.DALETest.__init__": [[128, 138], ["os.listdir", "torchvision.transforms.Compose", "torchvision.transforms.ToTensor"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root_dir", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            1) root directory -> D:\\data\\LessNet\\TEST\\\n            2) arguments -> args\n        \"\"\"", "\n", "self", ".", "root_dir", "=", "root_dir", "\n", "self", ".", "test_img_list", "=", "os", ".", "listdir", "(", "root_dir", ")", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_DALE.DALETest.__len__": [[140, 142], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "test_img_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.data.dataset_DALE.DALETest.__getitem__": [[143, 155], ["PIL.open", "dataset_DALE.DALETest.transform", "os.path.join"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"\n        Get a test image tensor.\n        It returns a tuple of float tensors with shape [3, height, width].\n        They represent RGB images with pixel values in [0, 1] range.\n        :return: test image tensor, file name\n        \"\"\"", "\n", "test_img_name", "=", "self", ".", "test_img_list", "[", "idx", "]", "\n", "# Open Image", "\n", "test_image", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "test_img_name", ")", ")", "\n", "test_image_tensor", "=", "self", ".", "transform", "(", "test_image", ")", "\n", "return", "test_image_tensor", ",", "test_img_name", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.ploss.PerceptualLoss.__init__": [[24, 33], ["torch.Module.__init__", "torchvision.models.vgg.vgg16().cuda", "torch.Sequential().eval", "ploss.PerceptualLoss.loss_network.parameters", "torch.L1Loss", "torchvision.models.vgg.vgg16", "torch.Sequential", "list"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "PerceptualLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "vgg", "=", "vgg16", "(", "pretrained", "=", "True", ")", ".", "cuda", "(", ")", "\n", "self", ".", "loss_network", "=", "nn", ".", "Sequential", "(", "*", "list", "(", "vgg", ".", "features", ")", "[", ":", "16", "]", ")", ".", "eval", "(", ")", "\n", "for", "param", "in", "self", ".", "loss_network", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "l1_loss", "=", "nn", ".", "L1Loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.ploss.PerceptualLoss.normalize_batch": [[34, 39], ["batch.new_tensor().view", "batch.new_tensor().view", "batch.new_tensor", "batch.new_tensor"], "methods", ["None"], ["", "def", "normalize_batch", "(", "self", ",", "batch", ")", ":", "\n", "# Normalize batch using ImageNet mean and std", "\n", "        ", "mean", "=", "batch", ".", "new_tensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", "\n", "std", "=", "batch", ".", "new_tensor", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", "\n", "return", "(", "batch", "-", "mean", ")", "/", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.ploss.PerceptualLoss.forward": [[40, 48], ["ploss.PerceptualLoss.l1_loss", "ploss.PerceptualLoss.loss_network", "ploss.PerceptualLoss.loss_network", "ploss.PerceptualLoss.normalize_batch", "ploss.PerceptualLoss.normalize_batch"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.ploss.PerceptualLoss.normalize_batch", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.ploss.PerceptualLoss.normalize_batch"], ["", "def", "forward", "(", "self", ",", "out_images", ",", "target_images", ")", ":", "\n", "\n", "        ", "loss", "=", "self", ".", "l1_loss", "(", "\n", "self", ".", "loss_network", "(", "self", ".", "normalize_batch", "(", "out_images", ")", ")", ",", "\n", "self", ".", "loss_network", "(", "self", ".", "normalize_batch", "(", "target_images", ")", ")", "\n", ")", "\n", "\n", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.timer.__init__": [[21, 24], ["utility.timer.tic"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.timer.tic"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "acc", "=", "0", "\n", "self", ".", "tic", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.timer.tic": [[25, 27], ["time.time"], "methods", ["None"], ["", "def", "tic", "(", "self", ")", ":", "\n", "        ", "self", ".", "t0", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.timer.toc": [[28, 30], ["time.time"], "methods", ["None"], ["", "def", "toc", "(", "self", ")", ":", "\n", "        ", "return", "time", ".", "time", "(", ")", "-", "self", ".", "t0", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.timer.hold": [[31, 33], ["utility.timer.toc"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.timer.toc"], ["", "def", "hold", "(", "self", ")", ":", "\n", "        ", "self", ".", "acc", "+=", "self", ".", "toc", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.timer.release": [[34, 39], ["None"], "methods", ["None"], ["", "def", "release", "(", "self", ")", ":", "\n", "        ", "ret", "=", "self", ".", "acc", "\n", "self", ".", "acc", "=", "0", "\n", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.timer.reset": [[40, 42], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "acc", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.__init__": [[45, 80], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "datetime.datetime.now().strftime", "utility.checkpoint.__init__._make_dir"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "ok", "=", "True", "\n", "self", ".", "log", "=", "torch", ".", "Tensor", "(", ")", "\n", "now", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d-%H:%M:%S'", ")", "\n", "\n", "if", "args", ".", "load", "==", "'.'", ":", "\n", "            ", "if", "args", ".", "save", "==", "'.'", ":", "args", ".", "save", "=", "now", "\n", "self", ".", "dir", "=", "'../experiment/'", "+", "args", ".", "save", "\n", "", "else", ":", "\n", "            ", "self", ".", "dir", "=", "'../experiment/'", "+", "args", ".", "load", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "dir", ")", ":", "\n", "                ", "args", ".", "load", "=", "'.'", "\n", "", "else", ":", "\n", "                ", "self", ".", "log", "=", "torch", ".", "load", "(", "self", ".", "dir", "+", "'/psnr_log.pt'", ")", "\n", "print", "(", "'Continue from epoch {}...'", ".", "format", "(", "len", "(", "self", ".", "log", ")", ")", ")", "\n", "\n", "", "", "if", "args", ".", "reset", ":", "\n", "            ", "os", ".", "system", "(", "'rm -rf '", "+", "self", ".", "dir", ")", "\n", "args", ".", "load", "=", "'.'", "\n", "\n", "", "def", "_make_dir", "(", "path", ")", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "os", ".", "makedirs", "(", "path", ")", "\n", "\n", "", "_make_dir", "(", "self", ".", "dir", ")", "\n", "_make_dir", "(", "self", ".", "dir", "+", "'/model'", ")", "\n", "_make_dir", "(", "self", ".", "dir", "+", "'/results'", ")", "\n", "\n", "open_type", "=", "'a'", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "dir", "+", "'/log.txt'", ")", "else", "'w'", "\n", "self", ".", "log_file", "=", "open", "(", "self", ".", "dir", "+", "'/log.txt'", ",", "open_type", ")", "\n", "with", "open", "(", "self", ".", "dir", "+", "'/config.txt'", ",", "open_type", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "now", "+", "'\\n\\n'", ")", "\n", "for", "arg", "in", "vars", "(", "args", ")", ":", "\n", "                ", "f", ".", "write", "(", "'{}: {}\\n'", ".", "format", "(", "arg", ",", "getattr", "(", "args", ",", "arg", ")", ")", ")", "\n", "", "f", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save": [[81, 91], ["trainer.model.save", "trainer.loss.save", "trainer.loss.plot_loss", "utility.checkpoint.plot_psnr", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.join", "trainer.optimizer.state_dict", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.plot_psnr", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.adversarial.Adversarial.state_dict"], ["", "", "def", "save", "(", "self", ",", "trainer", ",", "epoch", ",", "is_best", "=", "False", ")", ":", "\n", "        ", "trainer", ".", "model", ".", "save", "(", "self", ".", "dir", ",", "epoch", ",", "is_best", "=", "is_best", ")", "\n", "trainer", ".", "loss", ".", "save", "(", "self", ".", "dir", ")", "\n", "trainer", ".", "loss", ".", "plot_loss", "(", "self", ".", "dir", ",", "epoch", ")", "\n", "\n", "self", ".", "plot_psnr", "(", "epoch", ")", "\n", "torch", ".", "save", "(", "self", ".", "log", ",", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "'psnr_log.pt'", ")", ")", "\n", "torch", ".", "save", "(", "\n", "trainer", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "'optimizer.pt'", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.add_log": [[93, 95], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "add_log", "(", "self", ",", "log", ")", ":", "\n", "        ", "self", ".", "log", "=", "torch", ".", "cat", "(", "[", "self", ".", "log", ",", "log", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.write_log": [[96, 102], ["print", "utility.checkpoint.log_file.write", "utility.checkpoint.log_file.close", "open"], "methods", ["None"], ["", "def", "write_log", "(", "self", ",", "log", ",", "refresh", "=", "False", ")", ":", "\n", "        ", "print", "(", "log", ")", "\n", "self", ".", "log_file", ".", "write", "(", "log", "+", "'\\n'", ")", "\n", "if", "refresh", ":", "\n", "            ", "self", ".", "log_file", ".", "close", "(", ")", "\n", "self", ".", "log_file", "=", "open", "(", "self", ".", "dir", "+", "'/log.txt'", ",", "'a'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.done": [[103, 105], ["utility.checkpoint.log_file.close"], "methods", ["None"], ["", "", "def", "done", "(", "self", ")", ":", "\n", "        ", "self", ".", "log_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.plot_psnr": [[106, 123], ["numpy.linspace", "matplotlib.figure", "matplotlib.figure", "matplotlib.title", "matplotlib.title", "enumerate", "matplotlib.legend", "matplotlib.legend", "matplotlib.xlabel", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.ylabel", "matplotlib.grid", "matplotlib.grid", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.close", "matplotlib.close", "matplotlib.plot", "matplotlib.plot", "utility.checkpoint.log[].numpy"], "methods", ["None"], ["", "def", "plot_psnr", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "axis", "=", "np", ".", "linspace", "(", "1", ",", "epoch", ",", "epoch", ")", "\n", "label", "=", "'SR on {}'", ".", "format", "(", "self", ".", "args", ".", "data_test", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "title", "(", "label", ")", "\n", "for", "idx_scale", ",", "scale", "in", "enumerate", "(", "self", ".", "args", ".", "scale", ")", ":", "\n", "            ", "plt", ".", "plot", "(", "\n", "axis", ",", "\n", "self", ".", "log", "[", ":", ",", "idx_scale", "]", ".", "numpy", "(", ")", ",", "\n", "label", "=", "'Scale {}'", ".", "format", "(", "scale", ")", "\n", ")", "\n", "", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "xlabel", "(", "'Epochs'", ")", "\n", "plt", ".", "ylabel", "(", "'PSNR'", ")", "\n", "plt", ".", "grid", "(", "True", ")", "\n", "plt", ".", "savefig", "(", "'{}/test_{}.pdf'", ".", "format", "(", "self", ".", "dir", ",", "self", ".", "args", ".", "data_test", ")", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.checkpoint.save_results": [[124, 131], ["zip", "v[].data.mul", "v[].data.mul.byte().permute().cpu().numpy", "scipy.imsave", "v[].data.mul.byte().permute().cpu", "v[].data.mul.byte().permute", "v[].data.mul.byte"], "methods", ["None"], ["", "def", "save_results", "(", "self", ",", "filename", ",", "save_list", ",", "scale", ")", ":", "\n", "        ", "filename", "=", "'{}/results/{}_x{}_'", ".", "format", "(", "self", ".", "dir", ",", "filename", ",", "scale", ")", "\n", "postfix", "=", "(", "'SR'", ",", "'LR'", ",", "'HR'", ")", "\n", "for", "v", ",", "p", "in", "zip", "(", "save_list", ",", "postfix", ")", ":", "\n", "            ", "normalized", "=", "v", "[", "0", "]", ".", "data", ".", "mul", "(", "255", "/", "self", ".", "args", ".", "rgb_range", ")", "\n", "ndarr", "=", "normalized", ".", "byte", "(", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "misc", ".", "imsave", "(", "'{}{}.png'", ".", "format", "(", "filename", ",", "p", ")", ",", "ndarr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.quantize": [[133, 136], ["img.mul().clamp().round().div", "img.mul().clamp().round", "img.mul().clamp", "img.mul"], "function", ["None"], ["", "", "", "def", "quantize", "(", "img", ",", "rgb_range", ")", ":", "\n", "    ", "pixel_range", "=", "255", "/", "rgb_range", "\n", "return", "img", ".", "mul", "(", "pixel_range", ")", ".", "clamp", "(", "0", ",", "255", ")", ".", "round", "(", ")", ".", "div", "(", "pixel_range", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.calc_psnr_pixsh": [[138, 154], ["sr.data.div", "hr.data.div", "range", "range", "valid.pow().mean", "valid.pow", "math.log10", "math.log10"], "function", ["None"], ["", "def", "calc_psnr_pixsh", "(", "sr", ",", "hr", ",", "scale", ",", "rgb_range", ",", "benchmark", "=", "True", ")", ":", "\n", "    ", "psnr", "=", "0", "\n", "# diff = (sr - hr).data.div(rgb_range)", "\n", "sr", ".", "data", ".", "div", "(", "rgb_range", ")", "\n", "hr", ".", "data", ".", "div", "(", "rgb_range", ")", "\n", "\n", "shave", "=", "scale", "+", "6", "\n", "sr", "=", "sr", "[", ":", ",", ":", ",", "shave", ":", "-", "shave", ",", "shave", ":", "-", "shave", "]", "\n", "for", "i", "in", "range", "(", "2", "*", "shave", "-", "1", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "2", "*", "shave", "-", "1", ")", ":", "\n", "            ", "valid", "=", "(", "sr", "-", "hr", "[", ":", ",", ":", ",", "i", ":", "-", "2", "*", "shave", "+", "i", ",", "j", ":", "-", "2", "*", "shave", "+", "j", "]", ")", "\n", "mse", "=", "valid", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "if", "psnr", "<", "-", "10", "*", "math", ".", "log10", "(", "mse", ")", ":", "\n", "                ", "psnr", "=", "-", "10", "*", "math", ".", "log10", "(", "mse", ")", "\n", "\n", "", "", "", "return", "psnr", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.calc_psnr": [[156, 174], ["valid.pow().mean", "math.log10", "diff.sum.size", "diff.sum.new", "diff.sum.mul_().div_", "diff.sum.sum", "valid.pow", "diff.sum.mul_"], "function", ["None"], ["", "def", "calc_psnr", "(", "sr", ",", "hr", ",", "scale", ",", "rgb_range", ",", "benchmark", "=", "False", ")", ":", "\n", "    ", "diff", "=", "(", "sr", "-", "hr", ")", ".", "data", ".", "div", "(", "rgb_range", ")", "\n", "if", "benchmark", ":", "\n", "        ", "shave", "=", "scale", "\n", "if", "diff", ".", "size", "(", "1", ")", ">", "1", ":", "\n", "            ", "convert", "=", "diff", ".", "new", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "convert", "[", "0", ",", "0", ",", "0", ",", "0", "]", "=", "65.738", "\n", "convert", "[", "0", ",", "1", ",", "0", ",", "0", "]", "=", "129.057", "\n", "convert", "[", "0", ",", "2", ",", "0", ",", "0", "]", "=", "25.064", "\n", "diff", ".", "mul_", "(", "convert", ")", ".", "div_", "(", "256", ")", "\n", "diff", "=", "diff", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "", "", "else", ":", "\n", "        ", "shave", "=", "scale", "+", "6", "\n", "\n", "", "valid", "=", "diff", "[", ":", ",", ":", ",", "shave", ":", "-", "shave", ",", "shave", ":", "-", "shave", "]", "\n", "mse", "=", "valid", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "\n", "return", "-", "10", "*", "math", ".", "log10", "(", "mse", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.make_optimizer": [[176, 196], ["filter", "optimizer_function", "my_model.parameters"], "function", ["None"], ["", "def", "make_optimizer", "(", "args", ",", "my_model", ")", ":", "\n", "    ", "trainable", "=", "filter", "(", "lambda", "x", ":", "x", ".", "requires_grad", ",", "my_model", ".", "parameters", "(", ")", ")", "\n", "\n", "if", "args", ".", "optimizer", "==", "'SGD'", ":", "\n", "        ", "optimizer_function", "=", "optim", ".", "SGD", "\n", "kwargs", "=", "{", "'momentum'", ":", "args", ".", "momentum", "}", "\n", "", "elif", "args", ".", "optimizer", "==", "'ADAM'", ":", "\n", "        ", "optimizer_function", "=", "optim", ".", "Adam", "\n", "kwargs", "=", "{", "\n", "'betas'", ":", "(", "args", ".", "beta1", ",", "args", ".", "beta2", ")", ",", "\n", "'eps'", ":", "args", ".", "epsilon", "\n", "}", "\n", "", "elif", "args", ".", "optimizer", "==", "'RMSprop'", ":", "\n", "        ", "optimizer_function", "=", "optim", ".", "RMSprop", "\n", "kwargs", "=", "{", "'eps'", ":", "args", ".", "epsilon", "}", "\n", "\n", "", "kwargs", "[", "'lr'", "]", "=", "args", ".", "lr", "\n", "kwargs", "[", "'weight_decay'", "]", "=", "args", ".", "weight_decay", "\n", "\n", "return", "optimizer_function", "(", "trainable", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.utility.make_scheduler": [[198, 216], ["torch.StepLR", "args.decay_type.find", "args.decay_type.split", "list.pop", "list", "torch.MultiStepLR", "map", "int"], "function", ["None"], ["", "def", "make_scheduler", "(", "args", ",", "my_optimizer", ")", ":", "\n", "    ", "if", "args", ".", "decay_type", "==", "'step'", ":", "\n", "        ", "scheduler", "=", "lrs", ".", "StepLR", "(", "\n", "my_optimizer", ",", "\n", "step_size", "=", "args", ".", "lr_decay", ",", "\n", "gamma", "=", "args", ".", "gamma", "\n", ")", "\n", "", "elif", "args", ".", "decay_type", ".", "find", "(", "'step'", ")", ">=", "0", ":", "\n", "        ", "milestones", "=", "args", ".", "decay_type", ".", "split", "(", "'_'", ")", "\n", "milestones", ".", "pop", "(", "0", ")", "\n", "milestones", "=", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "milestones", ")", ")", "\n", "scheduler", "=", "lrs", ".", "MultiStepLR", "(", "\n", "my_optimizer", ",", "\n", "milestones", "=", "milestones", ",", "\n", "gamma", "=", "args", ".", "gamma", "\n", ")", "\n", "\n", "", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.tvloss.TVLoss.__init__": [[6, 9], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "TVLoss_weight", "=", "1", ")", ":", "\n", "        ", "super", "(", "TVLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "TVLoss_weight", "=", "TVLoss_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.tvloss.TVLoss.forward": [[10, 19], ["tvloss.TVLoss._tensor_size", "tvloss.TVLoss._tensor_size", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "x.size", "x.size", "x.size", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.tvloss.TVLoss._tensor_size", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.tvloss.TVLoss._tensor_size"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "batch_size", "=", "x", ".", "size", "(", ")", "[", "0", "]", "\n", "h_x", "=", "x", ".", "size", "(", ")", "[", "2", "]", "\n", "w_x", "=", "x", ".", "size", "(", ")", "[", "3", "]", "\n", "count_h", "=", "self", ".", "_tensor_size", "(", "x", "[", ":", ",", ":", ",", "1", ":", ",", ":", "]", ")", "\n", "count_w", "=", "self", ".", "_tensor_size", "(", "x", "[", ":", ",", ":", ",", ":", ",", "1", ":", "]", ")", "\n", "h_tv", "=", "torch", ".", "pow", "(", "(", "x", "[", ":", ",", ":", ",", "1", ":", ",", ":", "]", "-", "x", "[", ":", ",", ":", ",", ":", "h_x", "-", "1", ",", ":", "]", ")", ",", "2", ")", ".", "sum", "(", ")", "\n", "w_tv", "=", "torch", ".", "pow", "(", "(", "x", "[", ":", ",", ":", ",", ":", ",", "1", ":", "]", "-", "x", "[", ":", ",", ":", ",", ":", ",", ":", "w_x", "-", "1", "]", ")", ",", "2", ")", ".", "sum", "(", ")", "\n", "return", "self", ".", "TVLoss_weight", "*", "2", "*", "(", "h_tv", "/", "count_h", "+", "w_tv", "/", "count_w", ")", "/", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.tvloss.TVLoss._tensor_size": [[20, 22], ["t.size", "t.size", "t.size"], "methods", ["None"], ["", "def", "_tensor_size", "(", "self", ",", "t", ")", ":", "\n", "        ", "return", "t", ".", "size", "(", ")", "[", "1", "]", "*", "t", ".", "size", "(", ")", "[", "2", "]", "*", "t", ".", "size", "(", ")", "[", "3", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.adversarial.Adversarial.__init__": [[10, 14], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "gan_type", ")", ":", "\n", "        ", "super", "(", "Adversarial", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "gan_type", "=", "gan_type", "\n", "self", ".", "gan_k", "=", "args", ".", "gan_k", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.adversarial.Adversarial.forward": [[15, 52], ["fake.detach", "range", "model.discriminator", "fake.detach", "adversarial.Adversarial.gan_type.find", "adversarial.Adversarial.gan_type.find", "model.discriminator.parameters", "model.discriminator.mean", "adversarial.Adversarial.gan_type.find", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "model.discriminator", "gradients.view.view.view", "gradients.view.view.norm", "p.data.clamp_", "fake.detach.data.new().uniform_", "fake.detach.mul", "real.mul", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "gradients.view.view.size", "gradients.view.norm.sub().pow().mean", "fake.detach.data.new", "model.discriminator.sum", "gradients.view.norm.sub().pow", "fake.size", "gradients.view.norm.sub"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "fake", ",", "real", ",", "discriminator", ")", ":", "\n", "        ", "fake_detach", "=", "fake", ".", "detach", "(", ")", "\n", "\n", "self", ".", "loss", "=", "0", "\n", "for", "_", "in", "range", "(", "self", ".", "gan_k", ")", ":", "\n", "            ", "d_fake", "=", "fake", ".", "detach", "(", ")", "\n", "d_real", "=", "real", "\n", "if", "self", ".", "gan_type", ".", "find", "(", "'WGAN'", ")", ">=", "0", ":", "\n", "                ", "loss_d", "=", "(", "d_fake", "-", "d_real", ")", ".", "mean", "(", ")", "\n", "if", "self", ".", "gan_type", ".", "find", "(", "'GP'", ")", ">=", "0", ":", "\n", "                    ", "epsilon", "=", "Variable", "(", "\n", "fake_detach", ".", "data", ".", "new", "(", "fake", ".", "size", "(", "0", ")", ",", "1", ",", "1", ",", "1", ")", ".", "uniform_", "(", ")", ",", "\n", "requires_grad", "=", "False", "\n", ")", "\n", "hat", "=", "fake_detach", ".", "mul", "(", "1", "-", "epsilon", ")", "+", "real", ".", "mul", "(", "epsilon", ")", "\n", "hat", ".", "requires_grad", "=", "True", "\n", "d_hat", "=", "discriminator", "(", "hat", ")", "\n", "gradients", "=", "torch", ".", "autograd", ".", "grad", "(", "\n", "outputs", "=", "d_hat", ".", "sum", "(", ")", ",", "inputs", "=", "hat", ",", "\n", "retain_graph", "=", "True", ",", "create_graph", "=", "True", ",", "only_inputs", "=", "True", "\n", ")", "[", "0", "]", "\n", "gradients", "=", "gradients", ".", "view", "(", "gradients", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "gradient_norm", "=", "gradients", ".", "norm", "(", "2", ",", "dim", "=", "1", ")", "\n", "gradient_penalty", "=", "10", "*", "gradient_norm", ".", "sub", "(", "1", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "loss_d", "+=", "gradient_penalty", "\n", "\n", "", "", "if", "self", ".", "gan_type", "==", "'WGAN'", ":", "\n", "                ", "for", "p", "in", "discriminator", ".", "parameters", "(", ")", ":", "\n", "                    ", "p", ".", "data", ".", "clamp_", "(", "-", "1", ",", "1", ")", "\n", "\n", "", "", "", "self", ".", "loss", "/=", "self", ".", "gan_k", "\n", "\n", "d_fake_for_g", "=", "discriminator", "(", "fake", ")", "\n", "if", "self", ".", "gan_type", ".", "find", "(", "'WGAN'", ")", ">=", "0", ":", "\n", "            ", "loss_g", "=", "-", "d_fake_for_g", ".", "mean", "(", ")", "\n", "\n", "", "return", "loss_g", ",", "loss_d", "#####", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.adversarial.Adversarial.state_dict": [[53, 58], ["adversarial.Adversarial.discriminator.state_dict", "adversarial.Adversarial.optimizer.state_dict", "dict"], "methods", ["home.repos.pwc.inspect_result.dokyeongK_DALE.loss.adversarial.Adversarial.state_dict", "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.adversarial.Adversarial.state_dict"], ["", "def", "state_dict", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "state_discriminator", "=", "self", ".", "discriminator", ".", "state_dict", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "state_optimizer", "=", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "\n", "return", "dict", "(", "**", "state_discriminator", ",", "**", "state_optimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.adversarial.Adversarial.bce": [[59, 66], ["torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits"], "methods", ["None"], ["", "def", "bce", "(", "self", ",", "real", ",", "fake", ")", ":", "\n", "        ", "label_real", "=", "torch", ".", "ones_like", "(", "real", ")", "\n", "label_fake", "=", "torch", ".", "zeros_like", "(", "fake", ")", "\n", "bce_real", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "real", ",", "label_real", ")", "\n", "bce_fake", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "fake", ",", "label_fake", ")", "\n", "bce_loss", "=", "bce_real", "+", "bce_fake", "\n", "return", "bce_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.__init__": [[4, 6], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.dokyeongK_DALE.loss.__init__.loss.get_loss": [[7, 33], ["print", "__init__.loss.args.loss.split", "print", "loss.split", "my_loss.append", "len", "my_loss.append", "torch.MSELoss", "torch.L1Loss", "float"], "methods", ["None"], ["", "def", "get_loss", "(", "self", ")", ":", "\n", "        ", "print", "(", "'Preparing loss function...'", ")", "\n", "\n", "my_loss", "=", "[", "]", "\n", "losslist", "=", "self", ".", "args", ".", "loss", ".", "split", "(", "'+'", ")", "\n", "for", "loss", "in", "losslist", ":", "\n", "            ", "weight", ",", "loss_type", "=", "loss", ".", "split", "(", "'*'", ")", "\n", "if", "loss_type", "==", "'MSE'", ":", "\n", "                ", "loss_function", "=", "nn", ".", "MSELoss", "(", ")", "\n", "", "elif", "loss_type", "==", "'L1'", ":", "\n", "                ", "loss_function", "=", "nn", ".", "L1Loss", "(", ")", "\n", "\n", "", "my_loss", ".", "append", "(", "{", "\n", "'type'", ":", "loss_type", ",", "\n", "'weight'", ":", "float", "(", "weight", ")", ",", "\n", "'function'", ":", "loss_function", "}", ")", "\n", "\n", "", "if", "len", "(", "losslist", ")", ">", "1", ":", "\n", "            ", "my_loss", ".", "append", "(", "{", "\n", "'type'", ":", "'Total'", ",", "\n", "'weight'", ":", "0", ",", "\n", "'function'", ":", "None", "}", ")", "\n", "\n", "", "print", "(", "my_loss", ")", "\n", "\n", "return", "my_loss", "\n", "\n"]]}