{"home.repos.pwc.inspect_result.deepmind_leo.None.config.get_data_config": [[96, 104], ["None"], "function", ["None"], ["def", "get_data_config", "(", ")", ":", "\n", "  ", "config", "=", "{", "}", "\n", "config", "[", "\"data_path\"", "]", "=", "FLAGS", ".", "data_path", "\n", "config", "[", "\"dataset_name\"", "]", "=", "FLAGS", ".", "dataset_name", "\n", "config", "[", "\"embedding_crop\"", "]", "=", "FLAGS", ".", "embedding_crop", "\n", "config", "[", "\"train_on_val\"", "]", "=", "FLAGS", ".", "train_on_val", "\n", "config", "[", "\"total_examples_per_class\"", "]", "=", "600", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.config.get_inner_model_config": [[106, 121], ["None"], "function", ["None"], ["", "def", "get_inner_model_config", "(", ")", ":", "\n", "  ", "\"\"\"Returns the config used to initialize LEO model.\"\"\"", "\n", "config", "=", "{", "}", "\n", "config", "[", "\"inner_unroll_length\"", "]", "=", "FLAGS", ".", "inner_unroll_length", "\n", "config", "[", "\"finetuning_unroll_length\"", "]", "=", "FLAGS", ".", "finetuning_unroll_length", "\n", "config", "[", "\"num_latents\"", "]", "=", "FLAGS", ".", "num_latents", "\n", "config", "[", "\"inner_lr_init\"", "]", "=", "FLAGS", ".", "inner_lr_init", "\n", "config", "[", "\"finetuning_lr_init\"", "]", "=", "FLAGS", ".", "finetuning_lr_init", "\n", "config", "[", "\"dropout_rate\"", "]", "=", "FLAGS", ".", "dropout_rate", "\n", "config", "[", "\"kl_weight\"", "]", "=", "FLAGS", ".", "kl_weight", "\n", "config", "[", "\"encoder_penalty_weight\"", "]", "=", "FLAGS", ".", "encoder_penalty_weight", "\n", "config", "[", "\"l2_penalty_weight\"", "]", "=", "FLAGS", ".", "l2_penalty_weight", "\n", "config", "[", "\"orthogonality_penalty_weight\"", "]", "=", "FLAGS", ".", "orthogonality_penalty_weight", "\n", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.config.get_outer_model_config": [[123, 137], ["None"], "function", ["None"], ["", "def", "get_outer_model_config", "(", ")", ":", "\n", "  ", "\"\"\"Returns the outer config file for N-way K-shot classification tasks.\"\"\"", "\n", "config", "=", "{", "}", "\n", "config", "[", "\"num_classes\"", "]", "=", "FLAGS", ".", "num_classes", "\n", "config", "[", "\"num_tr_examples_per_class\"", "]", "=", "FLAGS", ".", "num_tr_examples_per_class", "\n", "config", "[", "\"num_val_examples_per_class\"", "]", "=", "FLAGS", ".", "num_val_examples_per_class", "\n", "config", "[", "\"metatrain_batch_size\"", "]", "=", "FLAGS", ".", "metatrain_batch_size", "\n", "config", "[", "\"metavalid_batch_size\"", "]", "=", "FLAGS", ".", "metavalid_batch_size", "\n", "config", "[", "\"metatest_batch_size\"", "]", "=", "FLAGS", ".", "metatest_batch_size", "\n", "config", "[", "\"num_steps_limit\"", "]", "=", "FLAGS", ".", "num_steps_limit", "\n", "config", "[", "\"outer_lr\"", "]", "=", "FLAGS", ".", "outer_lr", "\n", "config", "[", "\"gradient_threshold\"", "]", "=", "FLAGS", ".", "gradient_threshold", "\n", "config", "[", "\"gradient_norm_threshold\"", "]", "=", "FLAGS", ".", "gradient_norm_threshold", "\n", "return", "config", "\n", "", ""]], "home.repos.pwc.inspect_result.deepmind_leo.None.runner._clip_gradients": [[44, 56], ["tensorflow.clip_by_value", "tensorflow.clip_by_norm"], "function", ["None"], ["def", "_clip_gradients", "(", "gradients", ",", "gradient_threshold", ",", "gradient_norm_threshold", ")", ":", "\n", "  ", "\"\"\"Clips gradients by value and then by norm.\"\"\"", "\n", "if", "gradient_threshold", ">", "0", ":", "\n", "    ", "gradients", "=", "[", "\n", "tf", ".", "clip_by_value", "(", "g", ",", "-", "gradient_threshold", ",", "gradient_threshold", ")", "\n", "for", "g", "in", "gradients", "\n", "]", "\n", "", "if", "gradient_norm_threshold", ">", "0", ":", "\n", "    ", "gradients", "=", "[", "\n", "tf", ".", "clip_by_norm", "(", "g", ",", "gradient_norm_threshold", ")", "for", "g", "in", "gradients", "\n", "]", "\n", "", "return", "gradients", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.runner._construct_validation_summaries": [[58, 61], ["tensorflow.summary.scalar", "tensorflow.summary.scalar"], "function", ["None"], ["", "def", "_construct_validation_summaries", "(", "metavalid_loss", ",", "metavalid_accuracy", ")", ":", "\n", "  ", "tf", ".", "summary", ".", "scalar", "(", "\"metavalid_loss\"", ",", "metavalid_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"metavalid_valid_accuracy\"", ",", "metavalid_accuracy", ")", "\n", "# The summaries are passed implicitly by TensorFlow.", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.runner._construct_training_summaries": [[64, 73], ["tensorflow.summary.scalar", "tensorflow.summary.scalar", "six.moves.zip", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "v.name.split"], "function", ["None"], ["", "def", "_construct_training_summaries", "(", "metatrain_loss", ",", "metatrain_accuracy", ",", "\n", "model_grads", ",", "model_vars", ")", ":", "\n", "  ", "tf", ".", "summary", ".", "scalar", "(", "\"metatrain_loss\"", ",", "metatrain_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"metatrain_valid_accuracy\"", ",", "metatrain_accuracy", ")", "\n", "for", "g", ",", "v", "in", "zip", "(", "model_grads", ",", "model_vars", ")", ":", "\n", "    ", "histogram_name", "=", "v", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", "\n", "tf", ".", "summary", ".", "histogram", "(", "histogram_name", ",", "v", ")", "\n", "histogram_name", "=", "\"gradient/{}\"", ".", "format", "(", "histogram_name", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "histogram_name", ",", "g", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.runner._construct_examples_batch": [[75, 83], ["data.DataProvider", "data.DataProvider.get_batch", "utils.unpack_data", "config.get_data_config"], "function", ["home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider.get_batch", "home.repos.pwc.inspect_result.deepmind_leo.None.utils.unpack_data", "home.repos.pwc.inspect_result.deepmind_leo.None.config.get_data_config"], ["", "", "def", "_construct_examples_batch", "(", "batch_size", ",", "split", ",", "num_classes", ",", "\n", "num_tr_examples_per_class", ",", "\n", "num_val_examples_per_class", ")", ":", "\n", "  ", "data_provider", "=", "data", ".", "DataProvider", "(", "split", ",", "config", ".", "get_data_config", "(", ")", ")", "\n", "examples_batch", "=", "data_provider", ".", "get_batch", "(", "batch_size", ",", "num_classes", ",", "\n", "num_tr_examples_per_class", ",", "\n", "num_val_examples_per_class", ")", "\n", "return", "utils", ".", "unpack_data", "(", "examples_batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.runner._construct_loss_and_accuracy": [[85, 97], ["functools.partial", "tensorflow.map_fn", "tensorflow.reduce_mean", "tensorflow.reduce_mean"], "function", ["None"], ["", "def", "_construct_loss_and_accuracy", "(", "inner_model", ",", "inputs", ",", "is_meta_training", ")", ":", "\n", "  ", "\"\"\"Returns batched loss and accuracy of the model ran on the inputs.\"\"\"", "\n", "call_fn", "=", "functools", ".", "partial", "(", "\n", "inner_model", ".", "__call__", ",", "is_meta_training", "=", "is_meta_training", ")", "\n", "per_instance_loss", ",", "per_instance_accuracy", "=", "tf", ".", "map_fn", "(", "\n", "call_fn", ",", "\n", "inputs", ",", "\n", "dtype", "=", "(", "tf", ".", "float32", ",", "tf", ".", "float32", ")", ",", "\n", "back_prop", "=", "is_meta_training", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "per_instance_loss", ")", "\n", "accuracy", "=", "tf", ".", "reduce_mean", "(", "per_instance_accuracy", ")", "\n", "return", "loss", ",", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.runner.construct_graph": [[99, 153], ["config.get_inner_model_config", "tensorflow.logging.info", "model.LEO", "runner._construct_examples_batch", "runner._construct_loss_and_accuracy", "model.LEO.grads_and_vars", "tensorflow.cond", "runner._clip_gradients", "runner._construct_training_summaries", "tensorflow.train.AdamOptimizer", "tensorflow.train.get_or_create_global_step", "tf.train.AdamOptimizer.apply_gradients", "config.get_data_config", "tensorflow.logging.info", "runner._construct_examples_batch", "runner._construct_loss_and_accuracy", "runner._construct_examples_batch", "runner._construct_loss_and_accuracy", "runner._construct_validation_summaries", "tensorflow.is_nan", "list", "tensorflow.zeros_like", "six.moves.zip"], "function", ["home.repos.pwc.inspect_result.deepmind_leo.None.config.get_inner_model_config", "home.repos.pwc.inspect_result.deepmind_leo.None.runner._construct_examples_batch", "home.repos.pwc.inspect_result.deepmind_leo.None.runner._construct_loss_and_accuracy", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.grads_and_vars", "home.repos.pwc.inspect_result.deepmind_leo.None.runner._clip_gradients", "home.repos.pwc.inspect_result.deepmind_leo.None.runner._construct_training_summaries", "home.repos.pwc.inspect_result.deepmind_leo.None.config.get_data_config", "home.repos.pwc.inspect_result.deepmind_leo.None.runner._construct_examples_batch", "home.repos.pwc.inspect_result.deepmind_leo.None.runner._construct_loss_and_accuracy", "home.repos.pwc.inspect_result.deepmind_leo.None.runner._construct_examples_batch", "home.repos.pwc.inspect_result.deepmind_leo.None.runner._construct_loss_and_accuracy", "home.repos.pwc.inspect_result.deepmind_leo.None.runner._construct_validation_summaries"], ["", "def", "construct_graph", "(", "outer_model_config", ")", ":", "\n", "  ", "\"\"\"Constructs the optimization graph.\"\"\"", "\n", "inner_model_config", "=", "config", ".", "get_inner_model_config", "(", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"inner_model_config: {}\"", ".", "format", "(", "inner_model_config", ")", ")", "\n", "leo", "=", "model", ".", "LEO", "(", "inner_model_config", ",", "use_64bits_dtype", "=", "False", ")", "\n", "\n", "num_classes", "=", "outer_model_config", "[", "\"num_classes\"", "]", "\n", "num_tr_examples_per_class", "=", "outer_model_config", "[", "\"num_tr_examples_per_class\"", "]", "\n", "metatrain_batch", "=", "_construct_examples_batch", "(", "\n", "outer_model_config", "[", "\"metatrain_batch_size\"", "]", ",", "\"train\"", ",", "num_classes", ",", "\n", "num_tr_examples_per_class", ",", "\n", "outer_model_config", "[", "\"num_val_examples_per_class\"", "]", ")", "\n", "metatrain_loss", ",", "metatrain_accuracy", "=", "_construct_loss_and_accuracy", "(", "\n", "leo", ",", "metatrain_batch", ",", "True", ")", "\n", "\n", "metatrain_gradients", ",", "metatrain_variables", "=", "leo", ".", "grads_and_vars", "(", "metatrain_loss", ")", "\n", "\n", "# Avoids NaNs in summaries.", "\n", "metatrain_loss", "=", "tf", ".", "cond", "(", "tf", ".", "is_nan", "(", "metatrain_loss", ")", ",", "\n", "lambda", ":", "tf", ".", "zeros_like", "(", "metatrain_loss", ")", ",", "\n", "lambda", ":", "metatrain_loss", ")", "\n", "\n", "metatrain_gradients", "=", "_clip_gradients", "(", "\n", "metatrain_gradients", ",", "outer_model_config", "[", "\"gradient_threshold\"", "]", ",", "\n", "outer_model_config", "[", "\"gradient_norm_threshold\"", "]", ")", "\n", "\n", "_construct_training_summaries", "(", "metatrain_loss", ",", "metatrain_accuracy", ",", "\n", "metatrain_gradients", ",", "metatrain_variables", ")", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "\n", "learning_rate", "=", "outer_model_config", "[", "\"outer_lr\"", "]", ")", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "\n", "list", "(", "zip", "(", "metatrain_gradients", ",", "metatrain_variables", ")", ")", ",", "global_step", ")", "\n", "\n", "data_config", "=", "config", ".", "get_data_config", "(", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"data_config: {}\"", ".", "format", "(", "data_config", ")", ")", "\n", "total_examples_per_class", "=", "data_config", "[", "\"total_examples_per_class\"", "]", "\n", "metavalid_batch", "=", "_construct_examples_batch", "(", "\n", "outer_model_config", "[", "\"metavalid_batch_size\"", "]", ",", "\"val\"", ",", "num_classes", ",", "\n", "num_tr_examples_per_class", ",", "\n", "total_examples_per_class", "-", "num_tr_examples_per_class", ")", "\n", "metavalid_loss", ",", "metavalid_accuracy", "=", "_construct_loss_and_accuracy", "(", "\n", "leo", ",", "metavalid_batch", ",", "False", ")", "\n", "\n", "metatest_batch", "=", "_construct_examples_batch", "(", "\n", "outer_model_config", "[", "\"metatest_batch_size\"", "]", ",", "\"test\"", ",", "num_classes", ",", "\n", "num_tr_examples_per_class", ",", "\n", "total_examples_per_class", "-", "num_tr_examples_per_class", ")", "\n", "_", ",", "metatest_accuracy", "=", "_construct_loss_and_accuracy", "(", "\n", "leo", ",", "metatest_batch", ",", "False", ")", "\n", "_construct_validation_summaries", "(", "metavalid_loss", ",", "metavalid_accuracy", ")", "\n", "\n", "return", "(", "train_op", ",", "global_step", ",", "metatrain_accuracy", ",", "metavalid_accuracy", ",", "\n", "metatest_accuracy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.runner.run_training_loop": [[155, 204], ["config.get_outer_model_config", "tensorflow.logging.info", "runner.construct_graph", "tensorflow.train.MonitoredTrainingSession", "sess.run", "utils.evaluate_and_average", "tensorflow.logging.info", "sess.run", "tensorflow.gfile.Open", "pickle.dump", "utils.evaluate_and_average", "tensorflow.logging.info", "tensorflow.logging.info", "os.path.join", "utils.copy_checkpoint"], "function", ["home.repos.pwc.inspect_result.deepmind_leo.None.config.get_outer_model_config", "home.repos.pwc.inspect_result.deepmind_leo.None.runner.construct_graph", "home.repos.pwc.inspect_result.deepmind_leo.None.utils.evaluate_and_average", "home.repos.pwc.inspect_result.deepmind_leo.None.utils.evaluate_and_average", "home.repos.pwc.inspect_result.deepmind_leo.None.utils.copy_checkpoint"], ["", "def", "run_training_loop", "(", "checkpoint_path", ")", ":", "\n", "  ", "\"\"\"Runs the training loop, either saving a checkpoint or evaluating it.\"\"\"", "\n", "outer_model_config", "=", "config", ".", "get_outer_model_config", "(", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"outer_model_config: {}\"", ".", "format", "(", "outer_model_config", ")", ")", "\n", "(", "train_op", ",", "global_step", ",", "metatrain_accuracy", ",", "metavalid_accuracy", ",", "\n", "metatest_accuracy", ")", "=", "construct_graph", "(", "outer_model_config", ")", "\n", "\n", "num_steps_limit", "=", "outer_model_config", "[", "\"num_steps_limit\"", "]", "\n", "best_metavalid_accuracy", "=", "0.", "\n", "\n", "with", "tf", ".", "train", ".", "MonitoredTrainingSession", "(", "\n", "checkpoint_dir", "=", "checkpoint_path", ",", "\n", "save_summaries_steps", "=", "FLAGS", ".", "checkpoint_steps", ",", "\n", "log_step_count_steps", "=", "FLAGS", ".", "checkpoint_steps", ",", "\n", "save_checkpoint_steps", "=", "FLAGS", ".", "checkpoint_steps", ",", "\n", "summary_dir", "=", "checkpoint_path", ")", "as", "sess", ":", "\n", "    ", "if", "not", "FLAGS", ".", "evaluation_mode", ":", "\n", "      ", "global_step_ev", "=", "sess", ".", "run", "(", "global_step", ")", "\n", "while", "global_step_ev", "<", "num_steps_limit", ":", "\n", "        ", "if", "global_step_ev", "%", "FLAGS", ".", "checkpoint_steps", "==", "0", ":", "\n", "# Just after saving checkpoint, calculate accuracy 10 times and save", "\n", "# the best checkpoint for early stopping.", "\n", "          ", "metavalid_accuracy_ev", "=", "utils", ".", "evaluate_and_average", "(", "\n", "sess", ",", "metavalid_accuracy", ",", "10", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"Step: {} meta-valid accuracy: {}\"", ".", "format", "(", "\n", "global_step_ev", ",", "metavalid_accuracy_ev", ")", ")", "\n", "\n", "if", "metavalid_accuracy_ev", ">", "best_metavalid_accuracy", ":", "\n", "            ", "utils", ".", "copy_checkpoint", "(", "checkpoint_path", ",", "global_step_ev", ",", "\n", "metavalid_accuracy_ev", ")", "\n", "best_metavalid_accuracy", "=", "metavalid_accuracy_ev", "\n", "\n", "", "", "_", ",", "global_step_ev", ",", "metatrain_accuracy_ev", "=", "sess", ".", "run", "(", "\n", "[", "train_op", ",", "global_step", ",", "metatrain_accuracy", "]", ")", "\n", "if", "global_step_ev", "%", "(", "FLAGS", ".", "checkpoint_steps", "//", "2", ")", "==", "0", ":", "\n", "          ", "tf", ".", "logging", ".", "info", "(", "\"Step: {} meta-train accuracy: {}\"", ".", "format", "(", "\n", "global_step_ev", ",", "metatrain_accuracy_ev", ")", ")", "\n", "", "", "", "else", ":", "\n", "      ", "assert", "not", "FLAGS", ".", "checkpoint_steps", "\n", "num_metatest_estimates", "=", "(", "\n", "10000", "//", "outer_model_config", "[", "\"metatest_batch_size\"", "]", ")", "\n", "\n", "test_accuracy", "=", "utils", ".", "evaluate_and_average", "(", "sess", ",", "metatest_accuracy", ",", "\n", "num_metatest_estimates", ")", "\n", "\n", "tf", ".", "logging", ".", "info", "(", "\"Metatest accuracy: %f\"", ",", "test_accuracy", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "\n", "os", ".", "path", ".", "join", "(", "checkpoint_path", ",", "\"test_accuracy\"", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "test_accuracy", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.runner.main": [[206, 209], ["runner.run_training_loop"], "function", ["home.repos.pwc.inspect_result.deepmind_leo.None.runner.run_training_loop"], ["", "", "", "", "def", "main", "(", "argv", ")", ":", "\n", "  ", "del", "argv", "# Unused.", "\n", "run_training_loop", "(", "FLAGS", ".", "checkpoint_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.LEOTest.setUp": [[151, 158], ["super().setUp", "model_test._random_problem_instance", "model_test.get_test_config", "model.LEO", "model_test.LEOTest.addCleanup"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model_test.LEOTest.setUp", "home.repos.pwc.inspect_result.deepmind_leo.None.model_test._random_problem_instance", "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.get_test_config"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "LEOTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "self", ".", "_problem", "=", "_random_problem_instance", "(", "5", ",", "7", ",", "4", ")", "\n", "# This doesn\"t call any function, so doesn't need the mocks to be started.", "\n", "self", ".", "_config", "=", "get_test_config", "(", ")", "\n", "self", ".", "_leo", "=", "model", ".", "LEO", "(", "config", "=", "self", ".", "_config", ")", "\n", "self", ".", "addCleanup", "(", "mock", ".", "patch", ".", "stopall", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.LEOTest.test_instantiate_leo": [[159, 166], ["model_test.LEOTest._leo.encoder", "model_test.LEOTest.assertEqual", "model_test.LEOTest.session", "sess.run"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.encoder"], ["", "@", "mockify_everything", "\n", "def", "test_instantiate_leo", "(", "self", ")", ":", "\n", "    ", "encoder_output", "=", "self", ".", "_leo", ".", "encoder", "(", "5", ",", "7", ")", "\n", "with", "self", ".", "session", "(", ")", "as", "sess", ":", "\n", "      ", "encoder_output_ev", "=", "sess", ".", "run", "(", "encoder_output", ")", "\n", "\n", "", "self", ".", "assertEqual", "(", "encoder_output_ev", ",", "5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.LEOTest.test_inner_loop_adaptation": [[167, 191], ["data.ProblemInstance", "model_test.LEOTest._leo", "model_test.LEOTest.session", "sess.run", "model_test.LEOTest.assertAllClose", "constant_float64", "tensorflow.constant", "tensorflow.global_variables_initializer", "sess.run"], "methods", ["None"], ["", "@", "mockify_everything", "\n", "def", "test_inner_loop_adaptation", "(", "self", ")", ":", "\n", "    ", "problem_instance", "=", "data", ".", "ProblemInstance", "(", "\n", "tr_input", "=", "constant_float64", "(", "[", "[", "[", "4.", "]", "]", "]", ")", ",", "\n", "tr_output", "=", "tf", ".", "constant", "(", "[", "[", "[", "0", "]", "]", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "tr_info", "=", "[", "]", ",", "\n", "val_input", "=", "[", "]", ",", "\n", "val_output", "=", "[", "]", ",", "\n", "val_info", "=", "[", "]", ",", "\n", ")", "\n", "# encoder = decoder = id", "\n", "# predict returns classifier_weights**2 * inputs = latents**2 * inputs", "\n", "# loss = id = inputs*latents", "\n", "# dl/dlatent = 2 * latent * inputs", "\n", "# 4 -> 4 - 0.1 * 2 * 4 * 4 = 0.8", "\n", "# 0.8 -> 0.8 - 0.1 * 2 * 0.8 * 4 = 0.16", "\n", "# 0.16 -> 0.16 - 0.1 * 2 * 0.16 * 4 = 0.032", "\n", "\n", "# is_meta_training=False disables kl and encoder penalties", "\n", "adapted_parameters", ",", "_", "=", "self", ".", "_leo", "(", "problem_instance", ",", "is_meta_training", "=", "False", ")", "\n", "\n", "with", "self", ".", "session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "sess", ".", "run", "(", "adapted_parameters", ")", ",", "0.032", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.LEOTest.test_map_input": [[192, 228], ["tensorflow.map_fn", "constant_float64", "tensorflow.constant", "constant_float64", "constant_float64", "tensorflow.constant", "constant_float64", "constant_float64", "tensorflow.constant", "constant_float64", "constant_float64", "tensorflow.constant", "constant_float64", "tensorflow.stack", "model_test.LEOTest.session", "sess.run", "sess.run", "model_test.LEOTest.assertGreater", "six.moves.zip", "tensorflow.global_variables_initializer", "abs"], "methods", ["None"], ["", "", "@", "mockify_everything", "\n", "def", "test_map_input", "(", "self", ")", ":", "\n", "    ", "problem", "=", "[", "\n", "constant_float64", "(", "[", "[", "[", "5.", "]", "]", "]", ")", ",", "# tr_input", "\n", "tf", ".", "constant", "(", "[", "[", "[", "0", "]", "]", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "# tr_output", "\n", "constant_float64", "(", "[", "[", "[", "0", "]", "]", "]", ")", ",", "# tr_info", "\n", "constant_float64", "(", "[", "[", "[", "0.", "]", "]", "]", ")", ",", "# val_input", "\n", "tf", ".", "constant", "(", "[", "[", "[", "0", "]", "]", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "# val_output", "\n", "constant_float64", "(", "[", "[", "[", "0", "]", "]", "]", ")", ",", "# val_info", "\n", "]", "\n", "another_problem", "=", "[", "\n", "constant_float64", "(", "[", "[", "[", "4.", "]", "]", "]", ")", ",", "\n", "tf", ".", "constant", "(", "[", "[", "[", "0", "]", "]", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "constant_float64", "(", "[", "[", "[", "0", "]", "]", "]", ")", ",", "\n", "constant_float64", "(", "[", "[", "[", "0.", "]", "]", "]", ")", ",", "\n", "tf", ".", "constant", "(", "[", "[", "[", "0", "]", "]", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "constant_float64", "(", "[", "[", "[", "0", "]", "]", "]", ")", ",", "\n", "]", "\n", "# first dimension (list): diffent input kind (tr_input, val_output, etc.)", "\n", "# second dim: different problems; this has to be a tensor dim for map_fn", "\n", "# to split over it.", "\n", "# next three: (1, 1, 1)", "\n", "\n", "# map_fn cannot receive structured inputs (namedtuples).", "\n", "ins", "=", "[", "\n", "tf", ".", "stack", "(", "[", "in1", ",", "in2", "]", ")", "\n", "for", "in1", ",", "in2", "in", "zip", "(", "problem", ",", "another_problem", ")", "\n", "]", "\n", "\n", "two_adapted_params", ",", "_", "=", "tf", ".", "map_fn", "(", "\n", "self", ".", "_leo", ".", "__call__", ",", "ins", ",", "dtype", "=", "(", "tf", ".", "float64", ",", "tf", ".", "float64", ")", ")", "\n", "\n", "with", "self", ".", "session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output1", ",", "output2", "=", "sess", ".", "run", "(", "two_adapted_params", ")", "\n", "self", ".", "assertGreater", "(", "abs", "(", "output1", "-", "output2", ")", ",", "1e-3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.LEOTest.test_setting_is_meta_training": [[229, 235], ["model_test.LEOTest._leo", "model_test.LEOTest.assertTrue", "model_test.LEOTest._leo", "model_test.LEOTest.assertFalse"], "methods", ["None"], ["", "", "@", "mockify_everything", "\n", "def", "test_setting_is_meta_training", "(", "self", ")", ":", "\n", "    ", "self", ".", "_leo", "(", "self", ".", "_problem", ",", "is_meta_training", "=", "True", ")", "\n", "self", ".", "assertTrue", "(", "self", ".", "_leo", ".", "is_meta_training", ")", "\n", "self", ".", "_leo", "(", "self", ".", "_problem", ",", "is_meta_training", "=", "False", ")", "\n", "self", ".", "assertFalse", "(", "self", ".", "_leo", ".", "is_meta_training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.LEOTest.test_finetuning_improves_loss": [[236, 252], ["model_test.mockify_everything", "model_test.LEOTest._leo", "model_test.LEOTest._leo.forward_encoder", "model_test.LEOTest._leo.leo_inner_loop", "tensorflow.reduce_mean", "model_test.LEOTest._leo.finetuning_inner_loop", "tensorflow.reduce_mean", "model_test.LEOTest.session", "sess.run", "sess.run", "model_test.LEOTest.assertGreater", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model_test.mockify_everything", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.forward_encoder", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.leo_inner_loop", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.finetuning_inner_loop"], ["", "@", "mockify_everything", "(", "mock_finetuning", "=", "False", ")", "\n", "def", "test_finetuning_improves_loss", "(", "self", ")", ":", "\n", "# Create graph", "\n", "    ", "self", ".", "_leo", "(", "self", ".", "_problem", ")", "\n", "\n", "latents", ",", "_", "=", "self", ".", "_leo", ".", "forward_encoder", "(", "self", ".", "_problem", ")", "\n", "leo_loss", ",", "adapted_classifier_weights", ",", "_", "=", "self", ".", "_leo", ".", "leo_inner_loop", "(", "\n", "self", ".", "_problem", ",", "latents", ")", "\n", "leo_loss", "=", "tf", ".", "reduce_mean", "(", "leo_loss", ")", "\n", "finetuning_loss", ",", "_", "=", "self", ".", "_leo", ".", "finetuning_inner_loop", "(", "\n", "self", ".", "_problem", ",", "leo_loss", ",", "adapted_classifier_weights", ")", "\n", "finetuning_loss", "=", "tf", ".", "reduce_mean", "(", "finetuning_loss", ")", "\n", "with", "self", ".", "session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "leo_loss_ev", ",", "finetuning_loss_ev", "=", "sess", ".", "run", "(", "[", "leo_loss", ",", "finetuning_loss", "]", ")", "\n", "self", ".", "assertGreater", "(", "leo_loss_ev", "-", "1e-3", ",", "finetuning_loss_ev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.LEOTest.test_gradients_dont_flow_through_input": [[253, 260], ["model_test.LEOTest._leo", "model_test.LEOTest._leo.forward_encoder", "tensorflow.gradients", "model_test.LEOTest.assertIsNone"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.forward_encoder"], ["", "", "@", "mockify_everything", "\n", "def", "test_gradients_dont_flow_through_input", "(", "self", ")", ":", "\n", "# Create graph", "\n", "    ", "self", ".", "_leo", "(", "self", ".", "_problem", ")", "\n", "latents", ",", "_", "=", "self", ".", "_leo", ".", "forward_encoder", "(", "self", ".", "_problem", ")", "\n", "grads", "=", "tf", ".", "gradients", "(", "self", ".", "_problem", ".", "tr_input", ",", "latents", ")", "\n", "self", ".", "assertIsNone", "(", "grads", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.LEOTest.test_inferring_embedding_dim": [[261, 265], ["model_test.LEOTest._leo", "model_test.LEOTest.assertEqual"], "methods", ["None"], ["", "@", "mockify_everything", "\n", "def", "test_inferring_embedding_dim", "(", "self", ")", ":", "\n", "    ", "self", ".", "_leo", "(", "self", ".", "_problem", ")", "\n", "self", ".", "assertEqual", "(", "self", ".", "_leo", ".", "embedding_dim", ",", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.LEOTest.test_variable_creation": [[266, 283], ["model_test.mockify_everything", "model_test.LEOTest._leo", "sonnet.get_variables_in_scope", "model_test.LEOTest.assertNotEmpty", "sonnet.get_variables_in_scope", "model_test.LEOTest.assertNotEmpty", "sonnet.get_variables_in_scope", "model_test.LEOTest.assertNotEmpty", "sonnet.get_variables_in_scope", "model_test.LEOTest.assertNotEmpty", "sonnet.get_variables_in_scope", "model_test.LEOTest.assertNotEmpty", "model_test.LEOTest.assertSameElements"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model_test.mockify_everything"], ["", "@", "mockify_everything", "(", "mock_encdec", "=", "False", ",", "mock_finetuning", "=", "False", ")", "\n", "def", "test_variable_creation", "(", "self", ")", ":", "\n", "    ", "self", ".", "_leo", "(", "self", ".", "_problem", ")", "\n", "encoder_variables", "=", "snt", ".", "get_variables_in_scope", "(", "\"leo/encoder\"", ")", "\n", "self", ".", "assertNotEmpty", "(", "encoder_variables", ")", "\n", "relation_network_variables", "=", "snt", ".", "get_variables_in_scope", "(", "\n", "\"leo/relation_network\"", ")", "\n", "self", ".", "assertNotEmpty", "(", "relation_network_variables", ")", "\n", "decoder_variables", "=", "snt", ".", "get_variables_in_scope", "(", "\"leo/decoder\"", ")", "\n", "self", ".", "assertNotEmpty", "(", "decoder_variables", ")", "\n", "inner_lr", "=", "snt", ".", "get_variables_in_scope", "(", "\"leo/leo_inner\"", ")", "\n", "self", ".", "assertNotEmpty", "(", "inner_lr", ")", "\n", "finetuning_lr", "=", "snt", ".", "get_variables_in_scope", "(", "\"leo/finetuning\"", ")", "\n", "self", ".", "assertNotEmpty", "(", "finetuning_lr", ")", "\n", "self", ".", "assertSameElements", "(", "\n", "encoder_variables", "+", "relation_network_variables", "+", "decoder_variables", "+", "\n", "inner_lr", "+", "finetuning_lr", ",", "self", ".", "_leo", ".", "trainable_variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.LEOTest.test_graph_construction": [[284, 286], ["model_test.LEOTest._leo"], "methods", ["None"], ["", "def", "test_graph_construction", "(", "self", ")", ":", "\n", "    ", "self", ".", "_leo", "(", "self", ".", "_problem", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.LEOTest.test_possibly_sample": [[287, 307], ["model_test.LEOTest._leo", "model_test.LEOTest._leo.possibly_sample", "model_test.LEOTest._leo", "model_test.LEOTest._leo.possibly_sample", "model_test.LEOTest.session", "sess.run", "sess.run", "model_test.LEOTest.assertAllClose", "model_test.LEOTest.assertGreater", "sess.run", "model_test.LEOTest.assertNotEqual", "model_test.LEOTest.assertEqual", "abs", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.possibly_sample", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.possibly_sample"], ["", "def", "test_possibly_sample", "(", "self", ")", ":", "\n", "# Embedding dimension has to be divisible by 2 here.", "\n", "    ", "self", ".", "_leo", "(", "self", ".", "_problem", ",", "is_meta_training", "=", "True", ")", "\n", "train_samples", ",", "train_kl", "=", "self", ".", "_leo", ".", "possibly_sample", "(", "self", ".", "_problem", ".", "tr_input", ")", "\n", "\n", "self", ".", "_leo", "(", "self", ".", "_problem", ",", "is_meta_training", "=", "False", ")", "\n", "test_samples", ",", "test_kl", "=", "self", ".", "_leo", ".", "possibly_sample", "(", "self", ".", "_problem", ".", "tr_input", ")", "\n", "\n", "with", "self", ".", "session", "(", ")", "as", "sess", ":", "\n", "      ", "train_samples_ev1", ",", "test_samples_ev1", "=", "sess", ".", "run", "(", "\n", "[", "train_samples", ",", "test_samples", "]", ")", "\n", "train_samples_ev2", ",", "test_samples_ev2", "=", "sess", ".", "run", "(", "\n", "[", "train_samples", ",", "test_samples", "]", ")", "\n", "\n", "self", ".", "assertAllClose", "(", "test_samples_ev1", ",", "test_samples_ev2", ")", "\n", "self", ".", "assertGreater", "(", "abs", "(", "np", ".", "sum", "(", "train_samples_ev1", "-", "train_samples_ev2", ")", ")", ",", "1.", ")", "\n", "\n", "train_kl_ev", ",", "test_kl_ev", "=", "sess", ".", "run", "(", "[", "train_kl", ",", "test_kl", "]", ")", "\n", "self", ".", "assertNotEqual", "(", "train_kl_ev", ",", "0.", ")", "\n", "self", ".", "assertEqual", "(", "test_kl_ev", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.LEOTest.test_different_shapes": [[308, 314], ["model_test._random_problem_instance", "model_test.LEOTest._leo", "model_test.LEOTest.assertRaises", "model_test.LEOTest._leo"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model_test._random_problem_instance"], ["", "", "def", "test_different_shapes", "(", "self", ")", ":", "\n", "    ", "problem_instance2", "=", "_random_problem_instance", "(", "5", ",", "6", ",", "13", ")", "\n", "\n", "self", ".", "_leo", "(", "self", ".", "_problem", ")", "\n", "with", "self", ".", "assertRaises", "(", "AssertionError", ")", ":", "\n", "      ", "self", ".", "_leo", "(", "problem_instance2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.LEOTest.test_encoder_penalty": [[315, 331], ["model_test.LEOTest._leo", "model_test.LEOTest._leo.forward_encoder", "model_test.LEOTest._leo.leo_inner_loop", "model_test.LEOTest._leo", "model_test.LEOTest._leo.leo_inner_loop", "model_test.LEOTest.session", "sess.run", "sess.run", "model_test.LEOTest.assertGreater", "model_test.LEOTest.assertLess", "tensorflow.initializers.global_variables"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.forward_encoder", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.leo_inner_loop", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.leo_inner_loop"], ["", "", "def", "test_encoder_penalty", "(", "self", ")", ":", "\n", "    ", "self", ".", "_leo", "(", "self", ".", "_problem", ")", "# Sets is_meta_training", "\n", "latents", ",", "_", "=", "self", ".", "_leo", ".", "forward_encoder", "(", "self", ".", "_problem", ")", "\n", "_", ",", "_", ",", "train_encoder_penalty", "=", "self", ".", "_leo", ".", "leo_inner_loop", "(", "\n", "self", ".", "_problem", ",", "latents", ")", "\n", "\n", "self", ".", "_leo", "(", "self", ".", "_problem", ",", "is_meta_training", "=", "False", ")", "\n", "_", ",", "_", ",", "test_encoder_penalty", "=", "self", ".", "_leo", ".", "leo_inner_loop", "(", "\n", "self", ".", "_problem", ",", "latents", ")", "\n", "\n", "with", "self", ".", "session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "initializers", ".", "global_variables", "(", ")", ")", "\n", "train_encoder_penalty_ev", ",", "test_encoder_penalty_ev", "=", "sess", ".", "run", "(", "\n", "[", "train_encoder_penalty", ",", "test_encoder_penalty", "]", ")", "\n", "self", ".", "assertGreater", "(", "train_encoder_penalty_ev", ",", "1e-3", ")", "\n", "self", ".", "assertLess", "(", "test_encoder_penalty_ev", ",", "1e-7", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.LEOTest.test_construct_float32_leo_graph": [[332, 336], ["model.LEO", "model_test._random_problem_instance", "model.LEO."], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model_test._random_problem_instance"], ["", "", "def", "test_construct_float32_leo_graph", "(", "self", ")", ":", "\n", "    ", "leo", "=", "model", ".", "LEO", "(", "use_64bits_dtype", "=", "False", ",", "config", "=", "self", ".", "_config", ")", "\n", "problem_instance_32_bits", "=", "_random_problem_instance", "(", "use_64bits_dtype", "=", "False", ")", "\n", "leo", "(", "problem_instance_32_bits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.get_test_config": [[36, 51], ["None"], "function", ["None"], ["def", "get_test_config", "(", ")", ":", "\n", "  ", "\"\"\"Returns the config used to initialize LEO model.\"\"\"", "\n", "config", "=", "{", "}", "\n", "config", "[", "\"inner_unroll_length\"", "]", "=", "3", "\n", "config", "[", "\"finetuning_unroll_length\"", "]", "=", "4", "\n", "config", "[", "\"inner_lr_init\"", "]", "=", "0.1", "\n", "config", "[", "\"finetuning_lr_init\"", "]", "=", "0.2", "\n", "config", "[", "\"num_latents\"", "]", "=", "1", "\n", "config", "[", "\"dropout_rate\"", "]", "=", "0.3", "\n", "config", "[", "\"kl_weight\"", "]", "=", "0.01", "\n", "config", "[", "\"encoder_penalty_weight\"", "]", "=", "0.01", "\n", "config", "[", "\"l2_penalty_weight\"", "]", "=", "0.01", "\n", "config", "[", "\"orthogonality_penalty_weight\"", "]", "=", "0.01", "\n", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test.mockify_everything": [[53, 124], ["functools.wraps", "model_test.mockify_everything.inner_decorator"], "function", ["None"], ["", "def", "mockify_everything", "(", "test_function", "=", "None", ",", "\n", "mock_finetuning", "=", "True", ",", "\n", "mock_encdec", "=", "True", ")", ":", "\n", "  ", "\"\"\"Mockifies most of the LEO\"s model functions to behave as identity.\"\"\"", "\n", "\n", "def", "inner_decorator", "(", "f", ")", ":", "\n", "    ", "@", "functools", ".", "wraps", "(", "f", ")", "\n", "def", "mockified", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "      ", "identity_mapping", "=", "lambda", "unused_self", ",", "inp", ",", "*", "args", ":", "tf", ".", "identity", "(", "inp", ")", "\n", "mock_encoder", "=", "mock", ".", "patch", ".", "object", "(", "\n", "model", ".", "LEO", ",", "\"encoder\"", ",", "new", "=", "identity_mapping", ")", "\n", "mock_relation_network", "=", "mock", ".", "patch", ".", "object", "(", "\n", "model", ".", "LEO", ",", "\"relation_network\"", ",", "new", "=", "identity_mapping", ")", "\n", "mock_decoder", "=", "mock", ".", "patch", ".", "object", "(", "\n", "model", ".", "LEO", ",", "\"decoder\"", ",", "new", "=", "identity_mapping", ")", "\n", "mock_average", "=", "mock", ".", "patch", ".", "object", "(", "\n", "model", ".", "LEO", ",", "\"average_codes_per_class\"", ",", "new", "=", "identity_mapping", ")", "\n", "mock_loss", "=", "mock", ".", "patch", ".", "object", "(", "model", ".", "LEO", ",", "\"loss_fn\"", ",", "new", "=", "identity_mapping", ")", "\n", "\n", "float64_zero", "=", "constant_float64", "(", "0.", ")", "\n", "def", "identity_sample_fn", "(", "unused_self", ",", "inp", ",", "*", "unused_args", ",", "**", "unused_kwargs", ")", ":", "\n", "        ", "return", "inp", ",", "float64_zero", "\n", "\n", "", "def", "mock_sample_with_split", "(", "unused_self", ",", "inp", ",", "*", "unused_args", ",", "\n", "**", "unused_kwargs", ")", ":", "\n", "        ", "out", "=", "tf", ".", "split", "(", "inp", ",", "2", ",", "axis", "=", "-", "1", ")", "[", "0", "]", "\n", "return", "out", ",", "float64_zero", "\n", "\n", "# When not mocking relation net, it will double the latents.", "\n", "", "mock_sample", "=", "mock", ".", "patch", ".", "object", "(", "\n", "model", ".", "LEO", ",", "\n", "\"possibly_sample\"", ",", "\n", "new", "=", "identity_sample_fn", "if", "mock_encdec", "else", "mock_sample_with_split", ")", "\n", "\n", "def", "dummy_predict", "(", "unused_self", ",", "inputs", ",", "classifier_weights", ")", ":", "\n", "        ", "return", "inputs", "*", "classifier_weights", "**", "2", "\n", "\n", "", "mock_predict", "=", "mock", ".", "patch", ".", "object", "(", "model", ".", "LEO", ",", "\"predict\"", ",", "new", "=", "dummy_predict", ")", "\n", "\n", "mock_decoder_regularizer", "=", "mock", ".", "patch", ".", "object", "(", "\n", "model", ".", "LEO", ",", "\"_decoder_orthogonality_reg\"", ",", "new", "=", "float64_zero", ")", "\n", "\n", "all_mocks", "=", "[", "mock_average", ",", "mock_loss", ",", "mock_predict", ",", "mock_sample", "]", "\n", "if", "mock_encdec", ":", "\n", "        ", "all_mocks", ".", "extend", "(", "[", "\n", "mock_encoder", ",", "\n", "mock_relation_network", ",", "\n", "mock_decoder", ",", "\n", "mock_decoder_regularizer", ",", "\n", "]", ")", "\n", "", "if", "mock_finetuning", ":", "\n", "        ", "mock_finetuning_inner", "=", "mock", ".", "patch", ".", "object", "(", "\n", "model", ".", "LEO", ",", "\n", "\"finetuning_inner_loop\"", ",", "\n", "new", "=", "lambda", "unused_self", ",", "d", ",", "l", ",", "adapted", ":", "(", "adapted", ",", "float64_zero", ")", ")", "\n", "all_mocks", ".", "append", "(", "mock_finetuning_inner", ")", "\n", "\n", "", "for", "m", "in", "all_mocks", ":", "\n", "        ", "m", ".", "start", "(", ")", "\n", "\n", "", "f", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "for", "m", "in", "all_mocks", ":", "\n", "        ", "m", ".", "stop", "(", ")", "\n", "\n", "", "", "return", "mockified", "\n", "\n", "", "if", "test_function", ":", "\n", "# Decorator called with no arguments, so the function is passed", "\n", "    ", "return", "inner_decorator", "(", "test_function", ")", "\n", "", "return", "inner_decorator", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model_test._random_problem_instance": [[126, 147], ["tensorflow.constant", "tensorflow.constant", "data.ProblemInstance", "numpy.random.random", "numpy.random.randint"], "function", ["None"], ["", "def", "_random_problem_instance", "(", "num_classes", "=", "7", ",", "\n", "num_examples_per_class", "=", "5", ",", "\n", "embedding_dim", "=", "17", ",", "use_64bits_dtype", "=", "True", ")", ":", "\n", "  ", "inputs_dtype", "=", "tf", ".", "float64", "if", "use_64bits_dtype", "else", "tf", ".", "float32", "\n", "inputs", "=", "tf", ".", "constant", "(", "\n", "np", ".", "random", ".", "random", "(", "(", "num_classes", ",", "num_examples_per_class", ",", "embedding_dim", ")", ")", ",", "\n", "dtype", "=", "inputs_dtype", ")", "\n", "outputs_dtype", "=", "tf", ".", "int64", "if", "use_64bits_dtype", "else", "tf", ".", "int32", "\n", "outputs", "=", "tf", ".", "constant", "(", "\n", "np", ".", "random", ".", "randint", "(", "\n", "low", "=", "0", ",", "\n", "high", "=", "num_classes", ",", "\n", "size", "=", "(", "num_classes", ",", "num_examples_per_class", ",", "1", ")", ")", ",", "dtype", "=", "outputs_dtype", ")", "\n", "problem", "=", "data", ".", "ProblemInstance", "(", "\n", "tr_input", "=", "inputs", ",", "\n", "val_input", "=", "inputs", ",", "\n", "tr_info", "=", "inputs", ",", "\n", "tr_output", "=", "outputs", ",", "\n", "val_output", "=", "outputs", ",", "\n", "val_info", "=", "inputs", ")", "\n", "return", "problem", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.data.StrEnum.__str__": [[42, 44], ["None"], "methods", ["None"], ["def", "__str__", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.data.StrEnum.__repr__": [[45, 47], ["data.StrEnum.__str__"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.data.StrEnum.__str__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "__str__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider.__init__": [[71, 78], ["data.MetaSplit", "data.DataProvider._check_config", "data.DataProvider._index_data", "data.DataProvider._load_data"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider._check_config", "home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider._index_data", "home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider._load_data"], ["def", "__init__", "(", "self", ",", "dataset_split", ",", "config", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "self", ".", "_dataset_split", "=", "MetaSplit", "(", "dataset_split", ")", "\n", "self", ".", "_config", "=", "config", "\n", "self", ".", "_verbose", "=", "verbose", "\n", "self", ".", "_check_config", "(", ")", "\n", "\n", "self", ".", "_index_data", "(", "self", ".", "_load_data", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider._check_config": [[79, 89], ["data.MetaDataset", "data.EmbeddingCrop"], "methods", ["None"], ["", "def", "_check_config", "(", "self", ")", ":", "\n", "    ", "\"\"\"Checks configuration arguments of constructor.\"\"\"", "\n", "self", ".", "_config", "[", "\"dataset_name\"", "]", "=", "MetaDataset", "(", "self", ".", "_config", "[", "\"dataset_name\"", "]", ")", "\n", "self", ".", "_config", "[", "\"embedding_crop\"", "]", "=", "EmbeddingCrop", "(", "\n", "self", ".", "_config", "[", "\"embedding_crop\"", "]", ")", "\n", "if", "self", ".", "_config", "[", "\"dataset_name\"", "]", "==", "MetaDataset", ".", "TIERED", ":", "\n", "      ", "error_message", "=", "\"embedding_crop: {} not supported for {}\"", ".", "format", "(", "\n", "self", ".", "_config", "[", "\"embedding_crop\"", "]", ",", "self", ".", "_config", "[", "\"dataset_name\"", "]", ")", "\n", "assert", "self", ".", "_config", "[", "\n", "\"embedding_crop\"", "]", "==", "EmbeddingCrop", ".", "CENTER", ",", "error_message", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider._load_data": [[90, 110], ["data.DataProvider._load", "tensorflow.gfile.Open", "data.DataProvider._load", "tensorflow.logging.info", "data.DataProvider._get_full_pickle_path", "tensorflow.gfile.Open", "numpy.concatenate", "str", "data.DataProvider._get_full_pickle_path", "tensorflow.logging.info", "tensorflow.logging.info", "str", "str", "numpy.shape", "six.iteritems"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider._load", "home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider._load", "home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider._get_full_pickle_path", "home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider._get_full_pickle_path"], ["", "", "def", "_load_data", "(", "self", ")", ":", "\n", "    ", "\"\"\"Loads data into memory and caches .\"\"\"", "\n", "raw_data", "=", "self", ".", "_load", "(", "\n", "tf", ".", "gfile", ".", "Open", "(", "self", ".", "_get_full_pickle_path", "(", "self", ".", "_dataset_split", ")", ",", "\"rb\"", ")", ")", "\n", "if", "self", ".", "_dataset_split", "==", "MetaSplit", ".", "TRAIN", "and", "self", ".", "_config", "[", "\"train_on_val\"", "]", ":", "\n", "      ", "valid_data", "=", "self", ".", "_load", "(", "\n", "tf", ".", "gfile", ".", "Open", "(", "self", ".", "_get_full_pickle_path", "(", "MetaSplit", ".", "VALID", ")", ",", "\"rb\"", ")", ")", "\n", "for", "key", "in", "valid_data", ":", "\n", "        ", "if", "self", ".", "_verbose", ":", "\n", "          ", "tf", ".", "logging", ".", "info", "(", "str", "(", "[", "key", ",", "raw_data", "[", "key", "]", ".", "shape", "]", ")", ")", "\n", "", "raw_data", "[", "key", "]", "=", "np", ".", "concatenate", "(", "[", "raw_data", "[", "key", "]", ",", "\n", "valid_data", "[", "key", "]", "]", ",", "axis", "=", "0", ")", "\n", "if", "self", ".", "_verbose", ":", "\n", "          ", "tf", ".", "logging", ".", "info", "(", "str", "(", "[", "key", ",", "raw_data", "[", "key", "]", ".", "shape", "]", ")", ")", "\n", "\n", "", "", "", "if", "self", ".", "_verbose", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "\n", "str", "(", "[", "(", "k", ",", "np", ".", "shape", "(", "v", ")", ")", "for", "k", ",", "v", "in", "six", ".", "iteritems", "(", "raw_data", ")", "]", ")", ")", "\n", "\n", "", "return", "raw_data", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider._load": [[111, 117], ["pickle.load", "pickle.load"], "methods", ["None"], ["", "def", "_load", "(", "self", ",", "opened_file", ")", ":", "\n", "    ", "if", "six", ".", "PY2", ":", "\n", "      ", "result", "=", "pickle", ".", "load", "(", "opened_file", ")", "\n", "", "else", ":", "\n", "      ", "result", "=", "pickle", ".", "load", "(", "opened_file", ",", "encoding", "=", "\"latin1\"", ")", "# pylint: disable=unexpected-keyword-arg", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider._index_data": [[118, 139], ["collections.OrderedDict", "collections.OrderedDict", "enumerate", "data.DataProvider._check_data_index", "collections.OrderedDict", "k.split", "data.DataProvider._all_class_images[].append", "tensorflow.logging.info", "image_file.split", "str", "numpy.array", "six.iteritems", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider._check_data_index"], ["", "def", "_index_data", "(", "self", ",", "raw_data", ")", ":", "\n", "    ", "\"\"\"Builds an index of images embeddings by class.\"\"\"", "\n", "self", ".", "_all_class_images", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "self", ".", "_image_embedding", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "i", ",", "k", "in", "enumerate", "(", "raw_data", "[", "\"keys\"", "]", ")", ":", "\n", "      ", "_", ",", "class_label", ",", "image_file", "=", "k", ".", "split", "(", "\"-\"", ")", "\n", "image_file_class_label", "=", "image_file", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "assert", "class_label", "==", "image_file_class_label", "\n", "self", ".", "_image_embedding", "[", "image_file", "]", "=", "raw_data", "[", "\"embeddings\"", "]", "[", "i", "]", "\n", "if", "class_label", "not", "in", "self", ".", "_all_class_images", ":", "\n", "        ", "self", ".", "_all_class_images", "[", "class_label", "]", "=", "[", "]", "\n", "", "self", ".", "_all_class_images", "[", "class_label", "]", ".", "append", "(", "image_file", ")", "\n", "\n", "", "self", ".", "_check_data_index", "(", "raw_data", ")", "\n", "\n", "self", ".", "_all_class_images", "=", "collections", ".", "OrderedDict", "(", "[", "\n", "(", "k", ",", "np", ".", "array", "(", "v", ")", ")", "for", "k", ",", "v", "in", "six", ".", "iteritems", "(", "self", ".", "_all_class_images", ")", "\n", "]", ")", "\n", "if", "self", ".", "_verbose", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "str", "(", "[", "len", "(", "raw_data", ")", ",", "len", "(", "self", ".", "_all_class_images", ")", ",", "\n", "len", "(", "self", ".", "_image_embedding", ")", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider._check_data_index": [[140, 157], ["list", "set", "len", "len", "data.DataProvider._all_class_images.keys", "len", "len", "len", "min", "set", "len", "data.DataProvider._all_class_images.values"], "methods", ["None"], ["", "", "def", "_check_data_index", "(", "self", ",", "raw_data", ")", ":", "\n", "    ", "\"\"\"Performs checks of the data index and image counts per class.\"\"\"", "\n", "n", "=", "raw_data", "[", "\"keys\"", "]", ".", "shape", "[", "0", "]", "\n", "error_message", "=", "\"{} != {}\"", ".", "format", "(", "len", "(", "self", ".", "_image_embedding", ")", ",", "n", ")", "\n", "assert", "len", "(", "self", ".", "_image_embedding", ")", "==", "n", ",", "error_message", "\n", "error_message", "=", "\"{} != {}\"", ".", "format", "(", "raw_data", "[", "\"embeddings\"", "]", ".", "shape", "[", "0", "]", ",", "n", ")", "\n", "assert", "raw_data", "[", "\"embeddings\"", "]", ".", "shape", "[", "0", "]", "==", "n", ",", "error_message", "\n", "\n", "all_class_folders", "=", "list", "(", "self", ".", "_all_class_images", ".", "keys", "(", ")", ")", "\n", "error_message", "=", "\"no duplicate class names\"", "\n", "assert", "len", "(", "set", "(", "all_class_folders", ")", ")", "==", "len", "(", "all_class_folders", ")", ",", "error_message", "\n", "image_counts", "=", "set", "(", "[", "len", "(", "class_images", ")", "\n", "for", "class_images", "in", "self", ".", "_all_class_images", ".", "values", "(", ")", "]", ")", "\n", "error_message", "=", "(", "\"len(image_counts) should have at least one element but \"", "\n", "\"is: {}\"", ")", ".", "format", "(", "image_counts", ")", "\n", "assert", "len", "(", "image_counts", ")", ">=", "1", ",", "error_message", "\n", "assert", "min", "(", "image_counts", ")", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider._get_full_pickle_path": [[158, 168], ["os.path.join", "str", "str", "tensorflow.logging.info"], "methods", ["None"], ["", "def", "_get_full_pickle_path", "(", "self", ",", "split_name", ")", ":", "\n", "    ", "full_pickle_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "_config", "[", "\"data_path\"", "]", ",", "\n", "str", "(", "self", ".", "_config", "[", "\"dataset_name\"", "]", ")", ",", "\n", "str", "(", "self", ".", "_config", "[", "\"embedding_crop\"", "]", ")", ",", "\n", "\"{}_embeddings.pkl\"", ".", "format", "(", "split_name", ")", ")", "\n", "if", "self", ".", "_verbose", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "\"get_one_emb_instance: folder_path: {}\"", ".", "format", "(", "\n", "full_pickle_path", ")", ")", "\n", "", "return", "full_pickle_path", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider.get_instance": [[169, 251], ["tensorflow.py_func", "tensorflow.nn.l2_normalize", "tensorflow.regex_replace", "tensorflow.split", "tensorflow.split", "tensorflow.split", "list", "random.shuffle", "enumerate", "numpy.array", "numpy.array", "numpy.array", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.control_dependencies", "tensorflow.identity", "tensorflow.identity", "data.DataProvider._all_class_images.keys", "len", "len", "numpy.random.choice", "image_paths.append", "class_ids.append", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "data.DataProvider._check_labels", "len", "len"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider._check_labels"], ["", "def", "get_instance", "(", "self", ",", "num_classes", ",", "tr_size", ",", "val_size", ")", ":", "\n", "    ", "\"\"\"Samples a random N-way K-shot classification problem instance.\n\n    Args:\n      num_classes: N in N-way classification.\n      tr_size: K in K-shot; number of training examples per class.\n      val_size: number of validation examples per class.\n\n    Returns:\n      A tuple with 6 Tensors with the following shapes:\n      - tr_input: (num_classes, tr_size, NDIM): training image embeddings.\n      - tr_output: (num_classes, tr_size, 1): training image labels.\n      - tr_info: (num_classes, tr_size): training image file names.\n      - val_input: (num_classes, val_size, NDIM): validation image embeddings.\n      - val_output: (num_classes, val_size, 1): validation image labels.\n      - val_input: (num_classes, val_size): validation image file names.\n    \"\"\"", "\n", "\n", "def", "_build_one_instance_py", "(", ")", ":", "\n", "      ", "\"\"\"Builds a random problem instance using data from specified classes.\"\"\"", "\n", "class_list", "=", "list", "(", "self", ".", "_all_class_images", ".", "keys", "(", ")", ")", "\n", "sample_count", "=", "(", "tr_size", "+", "val_size", ")", "\n", "shuffled_folders", "=", "class_list", "[", ":", "]", "\n", "random", ".", "shuffle", "(", "shuffled_folders", ")", "\n", "shuffled_folders", "=", "shuffled_folders", "[", ":", "num_classes", "]", "\n", "error_message", "=", "\"len(shuffled_folders) {} is not num_classes: {}\"", ".", "format", "(", "\n", "len", "(", "shuffled_folders", ")", ",", "num_classes", ")", "\n", "assert", "len", "(", "shuffled_folders", ")", "==", "num_classes", ",", "error_message", "\n", "image_paths", "=", "[", "]", "\n", "class_ids", "=", "[", "]", "\n", "embeddings", "=", "self", ".", "_image_embedding", "\n", "for", "class_id", ",", "class_name", "in", "enumerate", "(", "shuffled_folders", ")", ":", "\n", "        ", "all_images", "=", "self", ".", "_all_class_images", "[", "class_name", "]", "\n", "all_images", "=", "np", ".", "random", ".", "choice", "(", "all_images", ",", "sample_count", ",", "replace", "=", "False", ")", "\n", "error_message", "=", "\"{} == {} failed\"", ".", "format", "(", "len", "(", "all_images", ")", ",", "sample_count", ")", "\n", "assert", "len", "(", "all_images", ")", "==", "sample_count", ",", "error_message", "\n", "image_paths", ".", "append", "(", "all_images", ")", "\n", "class_ids", ".", "append", "(", "[", "[", "class_id", "]", "]", "*", "sample_count", ")", "\n", "\n", "", "label_array", "=", "np", ".", "array", "(", "class_ids", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "if", "self", ".", "_verbose", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "label_array", ".", "shape", ")", "\n", "", "if", "self", ".", "_verbose", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "label_array", ".", "shape", ")", "\n", "", "path_array", "=", "np", ".", "array", "(", "image_paths", ")", "\n", "if", "self", ".", "_verbose", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "path_array", ".", "shape", ")", "\n", "", "if", "self", ".", "_verbose", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "path_array", ".", "shape", ")", "\n", "", "embedding_array", "=", "np", ".", "array", "(", "[", "[", "embeddings", "[", "image_path", "]", "\n", "for", "image_path", "in", "class_paths", "]", "\n", "for", "class_paths", "in", "path_array", "]", ")", "\n", "if", "self", ".", "_verbose", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "embedding_array", ".", "shape", ")", "\n", "", "return", "embedding_array", ",", "label_array", ",", "path_array", "\n", "\n", "", "output_list", "=", "tf", ".", "py_func", "(", "_build_one_instance_py", ",", "[", "]", ",", "\n", "[", "tf", ".", "float32", ",", "tf", ".", "int32", ",", "tf", ".", "string", "]", ")", "\n", "instance_input", ",", "instance_output", ",", "instance_info", "=", "output_list", "\n", "instance_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "instance_input", ",", "axis", "=", "-", "1", ")", "\n", "instance_info", "=", "tf", ".", "regex_replace", "(", "instance_info", ",", "\"\\x00*\"", ",", "\"\"", ")", "\n", "\n", "if", "self", ".", "_verbose", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "\"input_batch: {} \"", ".", "format", "(", "instance_input", ".", "shape", ")", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"output_batch: {} \"", ".", "format", "(", "instance_output", ".", "shape", ")", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"info_batch: {} \"", ".", "format", "(", "instance_info", ".", "shape", ")", ")", "\n", "\n", "", "split_sizes", "=", "[", "tr_size", ",", "val_size", "]", "\n", "tr_input", ",", "val_input", "=", "tf", ".", "split", "(", "instance_input", ",", "split_sizes", ",", "axis", "=", "1", ")", "\n", "tr_output", ",", "val_output", "=", "tf", ".", "split", "(", "instance_output", ",", "split_sizes", ",", "axis", "=", "1", ")", "\n", "tr_info", ",", "val_info", "=", "tf", ".", "split", "(", "instance_info", ",", "split_sizes", ",", "axis", "=", "1", ")", "\n", "if", "self", ".", "_verbose", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "\"tr_output: {} \"", ".", "format", "(", "tr_output", ")", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"val_output: {}\"", ".", "format", "(", "val_output", ")", ")", "\n", "\n", "", "with", "tf", ".", "control_dependencies", "(", "\n", "self", ".", "_check_labels", "(", "num_classes", ",", "tr_size", ",", "val_size", ",", "\n", "tr_output", ",", "val_output", ")", ")", ":", "\n", "      ", "tr_output", "=", "tf", ".", "identity", "(", "tr_output", ")", "\n", "val_output", "=", "tf", ".", "identity", "(", "val_output", ")", "\n", "\n", "", "return", "tr_input", ",", "tr_output", ",", "tr_info", ",", "val_input", ",", "val_output", ",", "val_info", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider.get_batch": [[252, 300], ["data.DataProvider.get_instance", "tensorflow.train.shuffle_batch", "ProblemInstance", "tensorflow.logging.info"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider.get_instance"], ["", "def", "get_batch", "(", "self", ",", "batch_size", ",", "num_classes", ",", "tr_size", ",", "val_size", ",", "\n", "num_threads", "=", "10", ")", ":", "\n", "    ", "\"\"\"Returns a batch of random N-way K-shot classification problem instances.\n\n    Args:\n      batch_size: number of problem instances in the batch.\n      num_classes: N in N-way classification.\n      tr_size: K in K-shot; number of training examples per class.\n      val_size: number of validation examples per class.\n      num_threads: number of threads used to sample problem instances in\n      parallel.\n\n    Returns:\n      A ProblemInstance of Tensors with the following shapes:\n      - tr_input: (batch_size, num_classes, tr_size, NDIM): training image\n      embeddings.\n      - tr_output: (batch_size, num_classes, tr_size, 1): training image\n      labels.\n      - tr_info: (batch_size, num_classes, tr_size): training image file\n      names.\n      - val_input: (batch_size, num_classes, val_size, NDIM): validation\n      image embeddings.\n      - val_output: (batch_size, num_classes, val_size, 1): validation\n      image labels.\n      - val_info: (batch_size, num_classes, val_size): validation image\n      file names.\n    \"\"\"", "\n", "if", "self", ".", "_verbose", ":", "\n", "      ", "num_threads", "=", "1", "\n", "", "one_instance", "=", "self", ".", "get_instance", "(", "num_classes", ",", "tr_size", ",", "val_size", ")", "\n", "\n", "tr_data_size", "=", "(", "num_classes", ",", "tr_size", ")", "\n", "val_data_size", "=", "(", "num_classes", ",", "val_size", ")", "\n", "task_batch", "=", "tf", ".", "train", ".", "shuffle_batch", "(", "one_instance", ",", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "1000", ",", "min_after_dequeue", "=", "0", ",", "\n", "enqueue_many", "=", "False", ",", "\n", "shapes", "=", "[", "tr_data_size", "+", "(", "NDIM", ",", ")", ",", "\n", "tr_data_size", "+", "(", "1", ",", ")", ",", "\n", "tr_data_size", ",", "\n", "val_data_size", "+", "(", "NDIM", ",", ")", ",", "\n", "val_data_size", "+", "(", "1", ",", ")", ",", "\n", "val_data_size", "]", ",", "\n", "num_threads", "=", "num_threads", ")", "\n", "\n", "if", "self", ".", "_verbose", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "task_batch", ")", "\n", "\n", "", "return", "ProblemInstance", "(", "*", "task_batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.data.DataProvider._check_labels": [[301, 311], ["tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.assert_equal", "tensorflow.assert_equal", "tensorflow.to_int32", "tensorflow.to_int32"], "methods", ["None"], ["", "def", "_check_labels", "(", "self", ",", "num_classes", ",", "tr_size", ",", "val_size", ",", "\n", "tr_output", ",", "val_output", ")", ":", "\n", "    ", "correct_label_sum", "=", "(", "num_classes", "*", "(", "num_classes", "-", "1", ")", ")", "//", "2", "\n", "tr_label_sum", "=", "tf", ".", "reduce_sum", "(", "tr_output", ")", "/", "tr_size", "\n", "val_label_sum", "=", "tf", ".", "reduce_sum", "(", "val_output", ")", "/", "val_size", "\n", "all_label_asserts", "=", "[", "\n", "tf", ".", "assert_equal", "(", "tf", ".", "to_int32", "(", "tr_label_sum", ")", ",", "correct_label_sum", ")", ",", "\n", "tf", ".", "assert_equal", "(", "tf", ".", "to_int32", "(", "val_label_sum", ")", ",", "correct_label_sum", ")", ",", "\n", "]", "\n", "return", "all_label_asserts", "\n", "", "", ""]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.__init__": [[59, 79], ["sonnet.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.__init__"], ["def", "__init__", "(", "self", ",", "config", "=", "None", ",", "use_64bits_dtype", "=", "True", ",", "name", "=", "\"leo\"", ")", ":", "\n", "    ", "super", "(", "LEO", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "self", ".", "_float_dtype", "=", "tf", ".", "float64", "if", "use_64bits_dtype", "else", "tf", ".", "float32", "\n", "self", ".", "_int_dtype", "=", "tf", ".", "int64", "if", "use_64bits_dtype", "else", "tf", ".", "int32", "\n", "\n", "self", ".", "_inner_unroll_length", "=", "config", "[", "\"inner_unroll_length\"", "]", "\n", "self", ".", "_finetuning_unroll_length", "=", "config", "[", "\"finetuning_unroll_length\"", "]", "\n", "self", ".", "_inner_lr_init", "=", "config", "[", "\"inner_lr_init\"", "]", "\n", "self", ".", "_finetuning_lr_init", "=", "config", "[", "\"finetuning_lr_init\"", "]", "\n", "self", ".", "_num_latents", "=", "config", "[", "\"num_latents\"", "]", "\n", "self", ".", "_dropout_rate", "=", "config", "[", "\"dropout_rate\"", "]", "\n", "\n", "self", ".", "_kl_weight", "=", "config", "[", "\"kl_weight\"", "]", "# beta", "\n", "self", ".", "_encoder_penalty_weight", "=", "config", "[", "\"encoder_penalty_weight\"", "]", "# gamma", "\n", "self", ".", "_l2_penalty_weight", "=", "config", "[", "\"l2_penalty_weight\"", "]", "# lambda_1", "\n", "# lambda_2", "\n", "self", ".", "_orthogonality_penalty_weight", "=", "config", "[", "\"orthogonality_penalty_weight\"", "]", "\n", "\n", "assert", "self", ".", "_inner_unroll_length", ">", "0", ",", "(", "\"Positive unroll length is necessary\"", "\n", "\" to create the graph\"", ")", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO._build": [[81, 128], ["isinstance", "model.LEO.save_problem_instance_stats", "model.LEO.forward_encoder", "model.LEO.leo_inner_loop", "model.LEO.finetuning_inner_loop", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "data_module.ProblemInstance.ProblemInstance"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.save_problem_instance_stats", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.forward_encoder", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.leo_inner_loop", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.finetuning_inner_loop"], ["", "def", "_build", "(", "self", ",", "data", ",", "is_meta_training", "=", "True", ")", ":", "\n", "    ", "\"\"\"Connects the LEO module to the graph, creating the variables.\n\n    Args:\n      data: A data_module.ProblemInstance constaining Tensors with the\n          following shapes:\n          - tr_input: (N, K, dim)\n          - tr_output: (N, K, 1)\n          - tr_info: (N, K)\n          - val_input: (N, K_valid, dim)\n          - val_output: (N, K_valid, 1)\n          - val_info: (N, K_valid)\n            where N is the number of classes (as in N-way) and K and the and\n            K_valid are numbers of training and validation examples within a\n            problem instance correspondingly (as in K-shot), and dim is the\n            dimensionality of the embedding.\n      is_meta_training: A boolean describing whether we run in the training\n        mode.\n\n    Returns:\n      Tensor with the inner validation loss of LEO (include both adaptation in\n      the latent space and finetuning).\n    \"\"\"", "\n", "if", "isinstance", "(", "data", ",", "list", ")", ":", "\n", "      ", "data", "=", "data_module", ".", "ProblemInstance", "(", "*", "data", ")", "\n", "", "self", ".", "is_meta_training", "=", "is_meta_training", "\n", "self", ".", "save_problem_instance_stats", "(", "data", ".", "tr_input", ")", "\n", "\n", "latents", ",", "kl", "=", "self", ".", "forward_encoder", "(", "data", ")", "\n", "tr_loss", ",", "adapted_classifier_weights", ",", "encoder_penalty", "=", "self", ".", "leo_inner_loop", "(", "\n", "data", ",", "latents", ")", "\n", "\n", "val_loss", ",", "val_accuracy", "=", "self", ".", "finetuning_inner_loop", "(", "\n", "data", ",", "tr_loss", ",", "adapted_classifier_weights", ")", "\n", "\n", "val_loss", "+=", "self", ".", "_kl_weight", "*", "kl", "\n", "val_loss", "+=", "self", ".", "_encoder_penalty_weight", "*", "encoder_penalty", "\n", "# The l2 regularization is is already added to the graph when constructing", "\n", "# the snt.Linear modules. We pass the orthogonality regularizer separately,", "\n", "# because it is not used in self.grads_and_vars.", "\n", "regularization_penalty", "=", "(", "\n", "self", ".", "_l2_regularization", "+", "self", ".", "_decoder_orthogonality_reg", ")", "\n", "\n", "batch_val_loss", "=", "tf", ".", "reduce_mean", "(", "val_loss", ")", "\n", "batch_val_accuracy", "=", "tf", ".", "reduce_mean", "(", "val_accuracy", ")", "\n", "\n", "return", "batch_val_loss", "+", "regularization_penalty", ",", "batch_val_accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.leo_inner_loop": [[129, 151], ["model.LEO.forward_decoder", "six.moves.range", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.gradients", "model.LEO.forward_decoder", "tensorflow.losses.mean_squared_error", "tensorflow.cast", "tensorflow.constant", "tensorflow.constant_initializer", "tensorflow.stop_gradient"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.forward_decoder", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.forward_decoder"], ["", "@", "snt", ".", "reuse_variables", "\n", "def", "leo_inner_loop", "(", "self", ",", "data", ",", "latents", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"leo_inner\"", ")", ":", "\n", "      ", "inner_lr", "=", "tf", ".", "get_variable", "(", "\n", "\"lr\"", ",", "[", "1", ",", "1", ",", "self", ".", "_num_latents", "]", ",", "\n", "dtype", "=", "self", ".", "_float_dtype", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "self", ".", "_inner_lr_init", ")", ")", "\n", "", "starting_latents", "=", "latents", "\n", "loss", ",", "_", "=", "self", ".", "forward_decoder", "(", "data", ",", "latents", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "_inner_unroll_length", ")", ":", "\n", "      ", "loss_grad", "=", "tf", ".", "gradients", "(", "loss", ",", "latents", ")", "# dLtrain/dz", "\n", "latents", "-=", "inner_lr", "*", "loss_grad", "[", "0", "]", "\n", "loss", ",", "classifier_weights", "=", "self", ".", "forward_decoder", "(", "data", ",", "latents", ")", "\n", "\n", "", "if", "self", ".", "is_meta_training", ":", "\n", "      ", "encoder_penalty", "=", "tf", ".", "losses", ".", "mean_squared_error", "(", "\n", "labels", "=", "tf", ".", "stop_gradient", "(", "latents", ")", ",", "predictions", "=", "starting_latents", ")", "\n", "encoder_penalty", "=", "tf", ".", "cast", "(", "encoder_penalty", ",", "self", ".", "_float_dtype", ")", "\n", "", "else", ":", "\n", "      ", "encoder_penalty", "=", "tf", ".", "constant", "(", "0.", ",", "self", ".", "_float_dtype", ")", "\n", "\n", "", "return", "loss", ",", "classifier_weights", ",", "encoder_penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.finetuning_inner_loop": [[152, 169], ["six.moves.range", "model.LEO.calculate_inner_loss", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.gradients", "model.LEO.calculate_inner_loss", "tensorflow.constant_initializer"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.calculate_inner_loss", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.calculate_inner_loss"], ["", "@", "snt", ".", "reuse_variables", "\n", "def", "finetuning_inner_loop", "(", "self", ",", "data", ",", "leo_loss", ",", "classifier_weights", ")", ":", "\n", "    ", "tr_loss", "=", "leo_loss", "\n", "with", "tf", ".", "variable_scope", "(", "\"finetuning\"", ")", ":", "\n", "      ", "finetuning_lr", "=", "tf", ".", "get_variable", "(", "\n", "\"lr\"", ",", "[", "1", ",", "1", ",", "self", ".", "embedding_dim", "]", ",", "\n", "dtype", "=", "self", ".", "_float_dtype", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "self", ".", "_finetuning_lr_init", ")", ")", "\n", "", "for", "_", "in", "range", "(", "self", ".", "_finetuning_unroll_length", ")", ":", "\n", "      ", "loss_grad", "=", "tf", ".", "gradients", "(", "tr_loss", ",", "classifier_weights", ")", "\n", "classifier_weights", "-=", "finetuning_lr", "*", "loss_grad", "[", "0", "]", "\n", "tr_loss", ",", "_", "=", "self", ".", "calculate_inner_loss", "(", "data", ".", "tr_input", ",", "data", ".", "tr_output", ",", "\n", "classifier_weights", ")", "\n", "\n", "", "val_loss", ",", "val_accuracy", "=", "self", ".", "calculate_inner_loss", "(", "\n", "data", ".", "val_input", ",", "data", ".", "val_output", ",", "classifier_weights", ")", "\n", "return", "val_loss", ",", "val_accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.forward_encoder": [[170, 177], ["model.LEO.encoder", "model.LEO.relation_network", "model.LEO.average_codes_per_class", "model.LEO.possibly_sample"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.encoder", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.relation_network", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.average_codes_per_class", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.possibly_sample"], ["", "@", "snt", ".", "reuse_variables", "\n", "def", "forward_encoder", "(", "self", ",", "data", ")", ":", "\n", "    ", "encoder_outputs", "=", "self", ".", "encoder", "(", "data", ".", "tr_input", ")", "\n", "relation_network_outputs", "=", "self", ".", "relation_network", "(", "encoder_outputs", ")", "\n", "latent_dist_params", "=", "self", ".", "average_codes_per_class", "(", "relation_network_outputs", ")", "\n", "latents", ",", "kl", "=", "self", ".", "possibly_sample", "(", "latent_dist_params", ")", "\n", "return", "latents", ",", "kl", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.forward_decoder": [[178, 190], ["model.LEO.decoder", "numpy.sqrt", "model.LEO.possibly_sample", "model.LEO.calculate_inner_loss"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.decoder", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.possibly_sample", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.calculate_inner_loss"], ["", "@", "snt", ".", "reuse_variables", "\n", "def", "forward_decoder", "(", "self", ",", "data", ",", "latents", ")", ":", "\n", "    ", "weights_dist_params", "=", "self", ".", "decoder", "(", "latents", ")", "\n", "# Default to glorot_initialization and not stddev=1.", "\n", "fan_in", "=", "self", ".", "embedding_dim", ".", "value", "\n", "fan_out", "=", "self", ".", "num_classes", ".", "value", "\n", "stddev_offset", "=", "np", ".", "sqrt", "(", "2.", "/", "(", "fan_out", "+", "fan_in", ")", ")", "\n", "classifier_weights", ",", "_", "=", "self", ".", "possibly_sample", "(", "weights_dist_params", ",", "\n", "stddev_offset", "=", "stddev_offset", ")", "\n", "tr_loss", ",", "_", "=", "self", ".", "calculate_inner_loss", "(", "data", ".", "tr_input", ",", "data", ".", "tr_output", ",", "\n", "classifier_weights", ")", "\n", "return", "tr_loss", ",", "classifier_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.encoder": [[191, 205], ["tensorflow.variable_scope", "tensorflow.nn.dropout", "tensorflow.contrib.layers.l2_regularizer", "tensorflow.initializers.glorot_uniform", "sonnet.Linear", "sonnet.BatchApply"], "methods", ["None"], ["", "@", "snt", ".", "reuse_variables", "\n", "def", "encoder", "(", "self", ",", "inputs", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"encoder\"", ")", ":", "\n", "      ", "after_dropout", "=", "tf", ".", "nn", ".", "dropout", "(", "inputs", ",", "rate", "=", "self", ".", "dropout_rate", ")", "\n", "regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "self", ".", "_l2_penalty_weight", ")", "\n", "initializer", "=", "tf", ".", "initializers", ".", "glorot_uniform", "(", "dtype", "=", "self", ".", "_float_dtype", ")", "\n", "encoder_module", "=", "snt", ".", "Linear", "(", "\n", "self", ".", "_num_latents", ",", "\n", "use_bias", "=", "False", ",", "\n", "regularizers", "=", "{", "\"w\"", ":", "regularizer", "}", ",", "\n", "initializers", "=", "{", "\"w\"", ":", "initializer", "}", ",", "\n", ")", "\n", "outputs", "=", "snt", ".", "BatchApply", "(", "encoder_module", ")", "(", "after_dropout", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.relation_network": [[206, 231], ["tensorflow.variable_scope", "tensorflow.contrib.layers.l2_regularizer", "tensorflow.initializers.glorot_uniform", "sonnet.nets.MLP", "tensorflow.reshape", "tensorflow.tile", "tensorflow.tile", "tensorflow.concat", "tensorflow.reduce_mean", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.expand_dims", "sonnet.BatchApply"], "methods", ["None"], ["", "", "@", "snt", ".", "reuse_variables", "\n", "def", "relation_network", "(", "self", ",", "inputs", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"relation_network\"", ")", ":", "\n", "      ", "regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "self", ".", "_l2_penalty_weight", ")", "\n", "initializer", "=", "tf", ".", "initializers", ".", "glorot_uniform", "(", "dtype", "=", "self", ".", "_float_dtype", ")", "\n", "relation_network_module", "=", "snt", ".", "nets", ".", "MLP", "(", "\n", "[", "2", "*", "self", ".", "_num_latents", "]", "*", "3", ",", "\n", "use_bias", "=", "False", ",", "\n", "regularizers", "=", "{", "\"w\"", ":", "regularizer", "}", ",", "\n", "initializers", "=", "{", "\"w\"", ":", "initializer", "}", ",", "\n", ")", "\n", "total_num_examples", "=", "self", ".", "num_examples_per_class", "*", "self", ".", "num_classes", "\n", "inputs", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "total_num_examples", ",", "self", ".", "_num_latents", "]", ")", "\n", "\n", "left", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "inputs", ",", "1", ")", ",", "[", "1", ",", "total_num_examples", ",", "1", "]", ")", "\n", "right", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "inputs", ",", "0", ")", ",", "[", "total_num_examples", ",", "1", ",", "1", "]", ")", "\n", "concat_codes", "=", "tf", ".", "concat", "(", "[", "left", ",", "right", "]", ",", "axis", "=", "-", "1", ")", "\n", "outputs", "=", "snt", ".", "BatchApply", "(", "relation_network_module", ")", "(", "concat_codes", ")", "\n", "outputs", "=", "tf", ".", "reduce_mean", "(", "outputs", ",", "axis", "=", "1", ")", "\n", "# 2 * latents, because we are returning means and variances of a Gaussian", "\n", "outputs", "=", "tf", ".", "reshape", "(", "outputs", ",", "[", "self", ".", "num_classes", ",", "\n", "self", ".", "num_examples_per_class", ",", "\n", "2", "*", "self", ".", "_num_latents", "]", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.decoder": [[232, 249], ["tensorflow.variable_scope", "tensorflow.contrib.layers.l2_regularizer", "model.get_orthogonality_regularizer", "tensorflow.initializers.glorot_uniform", "sonnet.Linear", "get_orthogonality_regularizer.", "sonnet.BatchApply"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model.get_orthogonality_regularizer"], ["", "", "@", "snt", ".", "reuse_variables", "\n", "def", "decoder", "(", "self", ",", "inputs", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"decoder\"", ")", ":", "\n", "      ", "l2_regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "self", ".", "_l2_penalty_weight", ")", "\n", "orthogonality_reg", "=", "get_orthogonality_regularizer", "(", "\n", "self", ".", "_orthogonality_penalty_weight", ")", "\n", "initializer", "=", "tf", ".", "initializers", ".", "glorot_uniform", "(", "dtype", "=", "self", ".", "_float_dtype", ")", "\n", "# 2 * embedding_dim, because we are returning means and variances", "\n", "decoder_module", "=", "snt", ".", "Linear", "(", "\n", "2", "*", "self", ".", "embedding_dim", ",", "\n", "use_bias", "=", "False", ",", "\n", "regularizers", "=", "{", "\"w\"", ":", "l2_regularizer", "}", ",", "\n", "initializers", "=", "{", "\"w\"", ":", "initializer", "}", ",", "\n", ")", "\n", "outputs", "=", "snt", ".", "BatchApply", "(", "decoder_module", ")", "(", "inputs", ")", "\n", "self", ".", "_orthogonality_reg", "=", "orthogonality_reg", "(", "decoder_module", ".", "w", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.average_codes_per_class": [[250, 255], ["tensorflow.reduce_mean", "tensorflow.tile"], "methods", ["None"], ["", "", "def", "average_codes_per_class", "(", "self", ",", "codes", ")", ":", "\n", "    ", "codes", "=", "tf", ".", "reduce_mean", "(", "codes", ",", "axis", "=", "1", ",", "keep_dims", "=", "True", ")", "# K dimension", "\n", "# Keep the shape (N, K, *)", "\n", "codes", "=", "tf", ".", "tile", "(", "codes", ",", "[", "1", ",", "self", ".", "num_examples_per_class", ",", "1", "]", ")", "\n", "return", "codes", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.possibly_sample": [[256, 268], ["tensorflow.split", "tensorflow.exp", "tensorflow.maximum", "tensorflow_probability.distributions.Normal", "tensorflow_probability.distributions.Normal.sample", "model.LEO.kl_divergence", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.kl_divergence"], ["", "def", "possibly_sample", "(", "self", ",", "distribution_params", ",", "stddev_offset", "=", "0.", ")", ":", "\n", "    ", "means", ",", "unnormalized_stddev", "=", "tf", ".", "split", "(", "distribution_params", ",", "2", ",", "axis", "=", "-", "1", ")", "\n", "stddev", "=", "tf", ".", "exp", "(", "unnormalized_stddev", ")", "\n", "stddev", "-=", "(", "1.", "-", "stddev_offset", ")", "\n", "stddev", "=", "tf", ".", "maximum", "(", "stddev", ",", "1e-10", ")", "\n", "distribution", "=", "tfp", ".", "distributions", ".", "Normal", "(", "loc", "=", "means", ",", "scale", "=", "stddev", ")", "\n", "if", "not", "self", ".", "is_meta_training", ":", "\n", "      ", "return", "means", ",", "tf", ".", "constant", "(", "0.", ",", "dtype", "=", "self", ".", "_float_dtype", ")", "\n", "\n", "", "samples", "=", "distribution", ".", "sample", "(", ")", "\n", "kl_divergence", "=", "self", ".", "kl_divergence", "(", "samples", ",", "distribution", ")", "\n", "return", "samples", ",", "kl_divergence", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.kl_divergence": [[269, 275], ["tensorflow_probability.distributions.Normal", "tensorflow.reduce_mean", "tensorflow.zeros_like", "tensorflow.ones_like", "normal_distribution.log_prob", "tensorflow_probability.distributions.Normal.log_prob"], "methods", ["None"], ["", "def", "kl_divergence", "(", "self", ",", "samples", ",", "normal_distribution", ")", ":", "\n", "    ", "random_prior", "=", "tfp", ".", "distributions", ".", "Normal", "(", "\n", "loc", "=", "tf", ".", "zeros_like", "(", "samples", ")", ",", "scale", "=", "tf", ".", "ones_like", "(", "samples", ")", ")", "\n", "kl", "=", "tf", ".", "reduce_mean", "(", "\n", "normal_distribution", ".", "log_prob", "(", "samples", ")", "-", "random_prior", ".", "log_prob", "(", "samples", ")", ")", "\n", "return", "kl", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.predict": [[276, 286], ["tensorflow.nn.dropout", "tensorflow.einsum", "tensorflow.reduce_mean"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "inputs", ",", "weights", ")", ":", "\n", "    ", "after_dropout", "=", "tf", ".", "nn", ".", "dropout", "(", "inputs", ",", "rate", "=", "self", ".", "dropout_rate", ")", "\n", "# This is 3-dimensional equivalent of a matrix product, where we sum over", "\n", "# the last (embedding_dim) dimension. We get [N, K, N, K] tensor as output.", "\n", "per_image_predictions", "=", "tf", ".", "einsum", "(", "\"ijk,lmk->ijlm\"", ",", "after_dropout", ",", "weights", ")", "\n", "\n", "# Predictions have shape [N, K, N]: for each image ([N, K] of them), what", "\n", "# is the probability of a given class (N)?", "\n", "predictions", "=", "tf", ".", "reduce_mean", "(", "per_image_predictions", ",", "axis", "=", "-", "1", ")", "\n", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.calculate_inner_loss": [[287, 295], ["model.LEO.predict", "tensorflow.argmax", "tensorflow.contrib.metrics.accuracy", "tensorflow.squeeze", "model.LEO.loss_fn"], "methods", ["home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.predict", "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.loss_fn"], ["", "def", "calculate_inner_loss", "(", "self", ",", "inputs", ",", "true_outputs", ",", "classifier_weights", ")", ":", "\n", "    ", "model_outputs", "=", "self", ".", "predict", "(", "inputs", ",", "classifier_weights", ")", "\n", "model_predictions", "=", "tf", ".", "argmax", "(", "\n", "model_outputs", ",", "-", "1", ",", "output_type", "=", "self", ".", "_int_dtype", ")", "\n", "accuracy", "=", "tf", ".", "contrib", ".", "metrics", ".", "accuracy", "(", "model_predictions", ",", "\n", "tf", ".", "squeeze", "(", "true_outputs", ",", "axis", "=", "-", "1", ")", ")", "\n", "\n", "return", "self", ".", "loss_fn", "(", "model_outputs", ",", "true_outputs", ")", ",", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.save_problem_instance_stats": [[296, 312], ["instance.get_shape", "hasattr", "hasattr", "hasattr"], "methods", ["None"], ["", "def", "save_problem_instance_stats", "(", "self", ",", "instance", ")", ":", "\n", "    ", "num_classes", ",", "num_examples_per_class", ",", "embedding_dim", "=", "instance", ".", "get_shape", "(", ")", "\n", "if", "hasattr", "(", "self", ",", "\"num_classes\"", ")", ":", "\n", "      ", "assert", "self", ".", "num_classes", "==", "num_classes", ",", "(", "\n", "\"Given different number of classes (N in N-way) in consecutive runs.\"", ")", "\n", "", "if", "hasattr", "(", "self", ",", "\"num_examples_per_class\"", ")", ":", "\n", "      ", "assert", "self", ".", "num_examples_per_class", "==", "num_examples_per_class", ",", "(", "\n", "\"Given different number of examples (K in K-shot) in consecutive\"", "\n", "\"runs.\"", ")", "\n", "", "if", "hasattr", "(", "self", ",", "\"embedding_dim\"", ")", ":", "\n", "      ", "assert", "self", ".", "embedding_dim", "==", "embedding_dim", ",", "(", "\n", "\"Given different embedding dimension in consecutive runs.\"", ")", "\n", "\n", "", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_examples_per_class", "=", "num_examples_per_class", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.dropout_rate": [[313, 316], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dropout_rate", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_dropout_rate", "if", "self", ".", "is_meta_training", "else", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.loss_fn": [[317, 323], ["tensorflow.squeeze", "tensorflow.one_hot", "tensorflow.nn.softmax_cross_entropy_with_logits_v2"], "methods", ["None"], ["", "def", "loss_fn", "(", "self", ",", "model_outputs", ",", "original_classes", ")", ":", "\n", "    ", "original_classes", "=", "tf", ".", "squeeze", "(", "original_classes", ",", "axis", "=", "-", "1", ")", "\n", "# Tensorflow doesn't handle second order gradients of a sparse_softmax yet.", "\n", "one_hot_outputs", "=", "tf", ".", "one_hot", "(", "original_classes", ",", "depth", "=", "self", ".", "num_classes", ")", "\n", "return", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "one_hot_outputs", ",", "logits", "=", "model_outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO.grads_and_vars": [[324, 361], ["tensorflow.gradients", "tensorflow.logical_or", "tensorflow.cond", "tensorflow.is_nan", "tensorflow.reduce_any", "tensorflow.zeros_like", "six.moves.zip", "tensorflow.reduce_any", "tensorflow.gradients", "tensorflow.is_nan"], "methods", ["None"], ["", "def", "grads_and_vars", "(", "self", ",", "metatrain_loss", ")", ":", "\n", "    ", "\"\"\"Computes gradients of metatrain_loss, avoiding NaN.\n\n    Uses a fixed penalty of 1e-4 to enforce only the l2 regularization (and not\n    minimize the loss) when metatrain_loss or any of its gradients with respect\n    to trainable_vars are NaN. In practice, this approach pulls the variables\n    back into a feasible region of the space when the loss or its gradients are\n    not defined.\n\n    Args:\n      metatrain_loss: A tensor with the LEO meta-training loss.\n\n    Returns:\n      A tuple with:\n        metatrain_gradients: A list of gradient tensors.\n        metatrain_variables: A list of variables for this LEO model.\n    \"\"\"", "\n", "metatrain_variables", "=", "self", ".", "trainable_variables", "\n", "metatrain_gradients", "=", "tf", ".", "gradients", "(", "metatrain_loss", ",", "metatrain_variables", ")", "\n", "\n", "nan_loss_or_grad", "=", "tf", ".", "logical_or", "(", "\n", "tf", ".", "is_nan", "(", "metatrain_loss", ")", ",", "\n", "tf", ".", "reduce_any", "(", "[", "tf", ".", "reduce_any", "(", "tf", ".", "is_nan", "(", "g", ")", ")", "\n", "for", "g", "in", "metatrain_gradients", "]", ")", ")", "\n", "\n", "regularization_penalty", "=", "(", "\n", "1e-4", "/", "self", ".", "_l2_penalty_weight", "*", "self", ".", "_l2_regularization", ")", "\n", "zero_or_regularization_gradients", "=", "[", "\n", "g", "if", "g", "is", "not", "None", "else", "tf", ".", "zeros_like", "(", "v", ")", "\n", "for", "v", ",", "g", "in", "zip", "(", "tf", ".", "gradients", "(", "regularization_penalty", ",", "\n", "metatrain_variables", ")", ",", "metatrain_variables", ")", "]", "\n", "\n", "metatrain_gradients", "=", "tf", ".", "cond", "(", "nan_loss_or_grad", ",", "\n", "lambda", ":", "zero_or_regularization_gradients", ",", "\n", "lambda", ":", "metatrain_gradients", ",", "strict", "=", "True", ")", "\n", "\n", "return", "metatrain_gradients", ",", "metatrain_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO._l2_regularization": [[362, 367], ["tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.get_collection"], "methods", ["None"], ["", "@", "property", "\n", "def", "_l2_regularization", "(", "self", ")", ":", "\n", "    ", "return", "tf", ".", "cast", "(", "\n", "tf", ".", "reduce_sum", "(", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", ")", ",", "\n", "dtype", "=", "self", ".", "_float_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.LEO._decoder_orthogonality_reg": [[368, 371], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_decoder_orthogonality_reg", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_orthogonality_reg", "\n", "", "", ""]], "home.repos.pwc.inspect_result.deepmind_leo.None.model.get_orthogonality_regularizer": [[35, 54], ["tensorflow.name_scope", "tensorflow.matmul", "tensorflow.eye", "tensorflow.reduce_mean", "tensorflow.multiply", "tensorflow.norm", "tensorflow.matmul", "correlation_matrix.get_shape().as_list", "tensorflow.squared_difference", "tensorflow.cast", "correlation_matrix.get_shape"], "function", ["None"], ["def", "get_orthogonality_regularizer", "(", "orthogonality_penalty_weight", ")", ":", "\n", "  ", "\"\"\"Returns the orthogonality regularizer.\"\"\"", "\n", "def", "orthogonality", "(", "weight", ")", ":", "\n", "    ", "\"\"\"Calculates the layer-wise penalty encouraging orthogonality.\"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "None", ",", "\"orthogonality\"", ",", "[", "weight", "]", ")", "as", "name", ":", "\n", "      ", "w2", "=", "tf", ".", "matmul", "(", "weight", ",", "weight", ",", "transpose_b", "=", "True", ")", "\n", "wn", "=", "tf", ".", "norm", "(", "weight", ",", "ord", "=", "2", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "+", "1e-32", "\n", "correlation_matrix", "=", "w2", "/", "tf", ".", "matmul", "(", "wn", ",", "wn", ",", "transpose_b", "=", "True", ")", "\n", "matrix_size", "=", "correlation_matrix", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "base_dtype", "=", "weight", ".", "dtype", ".", "base_dtype", "\n", "identity", "=", "tf", ".", "eye", "(", "matrix_size", ",", "dtype", "=", "base_dtype", ")", "\n", "weight_corr", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "squared_difference", "(", "correlation_matrix", ",", "identity", ")", ")", "\n", "return", "tf", ".", "multiply", "(", "\n", "tf", ".", "cast", "(", "orthogonality_penalty_weight", ",", "base_dtype", ")", ",", "\n", "weight_corr", ",", "\n", "name", "=", "name", ")", "\n", "\n", "", "", "return", "orthogonality", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.utils.unpack_data": [[31, 36], ["isinstance", "list"], "function", ["None"], ["def", "unpack_data", "(", "problem_instance", ")", ":", "\n", "  ", "\"\"\"Map data.ProblemInstance to a list of Tensors, to process with map_fn.\"\"\"", "\n", "if", "isinstance", "(", "problem_instance", ",", "data", ".", "ProblemInstance", ")", ":", "\n", "    ", "return", "list", "(", "problem_instance", ")", "\n", "", "return", "problem_instance", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.utils.copy_checkpoint": [[38, 67], ["os.path.join", "os.path.join", "utils._is_previous_accuracy_better", "os.path.join", "tensorflow.gfile.Glob", "os.path.join", "tf.gfile.Glob.append", "utils._save_files_in_tmp_directory", "os.path.join", "tensorflow.gfile.Exists", "tensorflow.gfile.Rename", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.Open", "f.write", "tensorflow.gfile.DeleteRecursively"], "function", ["home.repos.pwc.inspect_result.deepmind_leo.None.utils._is_previous_accuracy_better", "home.repos.pwc.inspect_result.deepmind_leo.None.utils._save_files_in_tmp_directory"], ["", "def", "copy_checkpoint", "(", "checkpoint_path", ",", "global_step", ",", "accuracy", ")", ":", "\n", "  ", "\"\"\"Copies the checkpoint to a separate directory.\"\"\"", "\n", "tmp_checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "checkpoint_path", ",", "\"tmp_best_checkpoint\"", ")", "\n", "best_checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "checkpoint_path", ",", "\"best_checkpoint\"", ")", "\n", "if", "_is_previous_accuracy_better", "(", "best_checkpoint_path", ",", "accuracy", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "\"Not copying the checkpoint: there is a better one from \"", "\n", "\"before a preemption.\"", ")", "\n", "return", "\n", "\n", "", "checkpoint_regex", "=", "os", ".", "path", ".", "join", "(", "checkpoint_path", ",", "\n", "\"model.ckpt-{}.*\"", ".", "format", "(", "global_step", ")", ")", "\n", "checkpoint_files", "=", "tf", ".", "gfile", ".", "Glob", "(", "checkpoint_regex", ")", "\n", "graph_file", "=", "os", ".", "path", ".", "join", "(", "checkpoint_path", ",", "\"graph.pbtxt\"", ")", "\n", "checkpoint_files", ".", "append", "(", "graph_file", ")", "\n", "\n", "_save_files_in_tmp_directory", "(", "tmp_checkpoint_path", ",", "checkpoint_files", ",", "accuracy", ")", "\n", "\n", "new_checkpoint_index_file", "=", "os", ".", "path", ".", "join", "(", "tmp_checkpoint_path", ",", "\"checkpoint\"", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "new_checkpoint_index_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "f", ".", "write", "(", "\"model_checkpoint_path: \\\"{}/model.ckpt-{}\\\"\\n\"", ".", "format", "(", "\n", "best_checkpoint_path", ",", "global_step", ")", ")", "\n", "\n", "# We first copy the better checkpoint to a temporary directory, and only", "\n", "# when it's created move it to avoid inconsistent state when job is preempted", "\n", "# when copying the checkpoint.", "\n", "", "if", "tf", ".", "gfile", ".", "Exists", "(", "best_checkpoint_path", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "best_checkpoint_path", ")", "\n", "", "tf", ".", "gfile", ".", "Rename", "(", "tmp_checkpoint_path", ",", "best_checkpoint_path", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"Copied new best checkpoint with accuracy %.5f\"", ",", "accuracy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.utils._save_files_in_tmp_directory": [[69, 93], ["tensorflow.gfile.Exists", "tensorflow.gfile.MkDir", "utils._save_files_in_tmp_directory.dump_in_best_checkpoint_path"], "function", ["None"], ["", "def", "_save_files_in_tmp_directory", "(", "tmp_checkpoint_path", ",", "checkpoint_files", ",", "\n", "accuracy", ")", ":", "\n", "  ", "\"\"\"Saves the checkpoint files and accuracy in a temporary directory.\"\"\"", "\n", "\n", "if", "tf", ".", "gfile", ".", "Exists", "(", "tmp_checkpoint_path", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "\"The temporary directory exists, because job was preempted \"", "\n", "\"before it managed to move it. We're removing it.\"", ")", "\n", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "tmp_checkpoint_path", ")", "\n", "", "tf", ".", "gfile", ".", "MkDir", "(", "tmp_checkpoint_path", ")", "\n", "\n", "def", "dump_in_best_checkpoint_path", "(", "obj", ",", "filename", ")", ":", "\n", "    ", "full_path", "=", "os", ".", "path", ".", "join", "(", "tmp_checkpoint_path", ",", "filename", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "full_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "      ", "pickle", ".", "dump", "(", "obj", ",", "f", ")", "\n", "\n", "", "", "for", "file_", "in", "checkpoint_files", ":", "\n", "    ", "just_filename", "=", "file_", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "tf", ".", "gfile", ".", "Copy", "(", "\n", "file_", ",", "\n", "os", ".", "path", ".", "join", "(", "tmp_checkpoint_path", ",", "just_filename", ")", ",", "\n", "overwrite", "=", "False", ")", "\n", "", "dump_in_best_checkpoint_path", "(", "config", ".", "get_inner_model_config", "(", ")", ",", "\"inner_config\"", ")", "\n", "dump_in_best_checkpoint_path", "(", "config", ".", "get_outer_model_config", "(", ")", ",", "\"outer_config\"", ")", "\n", "dump_in_best_checkpoint_path", "(", "accuracy", ",", "\"accuracy\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.utils._is_previous_accuracy_better": [[95, 104], ["os.path.join", "tensorflow.gfile.Exists", "tensorflow.gfile.Open", "pickle.load"], "function", ["None"], ["", "def", "_is_previous_accuracy_better", "(", "best_checkpoint_path", ",", "accuracy", ")", ":", "\n", "  ", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "best_checkpoint_path", ")", ":", "\n", "    ", "return", "False", "\n", "\n", "", "previous_accuracy_file", "=", "os", ".", "path", ".", "join", "(", "best_checkpoint_path", ",", "\"accuracy\"", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "previous_accuracy_file", ",", "\"rb\"", ")", "as", "f", ":", "\n", "    ", "previous_accuracy", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "return", "previous_accuracy", ">", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.deepmind_leo.None.utils.evaluate_and_average": [[106, 110], ["session.run", "sum", "six.moves.range"], "function", ["None"], ["", "def", "evaluate_and_average", "(", "session", ",", "tensor", ",", "num_estimates", ")", ":", "\n", "  ", "tensor_value_estimates", "=", "[", "session", ".", "run", "(", "tensor", ")", "for", "_", "in", "range", "(", "num_estimates", ")", "]", "\n", "average_tensor_value", "=", "sum", "(", "tensor_value_estimates", ")", "/", "num_estimates", "\n", "return", "average_tensor_value", "\n", "", ""]]}