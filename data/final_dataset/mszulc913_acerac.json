{"home.repos.pwc.inspect_result.mszulc913_acerac.acerac.tf_utils.kronecker_prod": [[7, 21], ["tensorflow.linalg.LinearOperatorFullMatrix", "tensorflow.linalg.LinearOperatorFullMatrix", "tensorflow.linalg.LinearOperatorKronecker().to_dense", "tensorflow.linalg.LinearOperatorKronecker"], "function", ["None"], ["def", "kronecker_prod", "(", "x", ":", "Union", "[", "tf", ".", "Tensor", ",", "np", ".", "array", "]", ",", "y", ":", "Union", "[", "tf", ".", "Tensor", ",", "np", ".", "array", "]", ")", "->", "tf", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes Kronecker product between x and y.\n\n    Args:\n        x: First tensor.\n        y: Second tensor.\n\n    Returns:\n        Product of x and y.\n    \"\"\"", "\n", "operator_1", "=", "tf", ".", "linalg", ".", "LinearOperatorFullMatrix", "(", "x", ")", "\n", "operator_2", "=", "tf", ".", "linalg", ".", "LinearOperatorFullMatrix", "(", "y", ")", "\n", "prod", "=", "tf", ".", "linalg", ".", "LinearOperatorKronecker", "(", "[", "operator_1", ",", "operator_2", "]", ")", ".", "to_dense", "(", ")", "\n", "return", "prod", "\n", "", ""]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner.__init__": [[63, 135], ["runners.Runner._log_dir.mkdir", "runners._get_env", "runners._get_env", "logger.CSVLogger", "runners.Runner._save_parameters", "runners._get_agent", "runners.Runner._env.reset", "pathlib.Path", "pathlib.Path", "tensorflow.summary.create_file_writer", "tensorflow.summary.create_file_writer.set_as_default", "range", "str", "datetime.datetime.now().strftime", "datetime.datetime.now().strftime", "datetime.datetime.now", "datetime.datetime.now"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners._get_env", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners._get_env", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._save_parameters", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners._get_agent"], ["def", "__init__", "(", "\n", "self", ",", "environment_name", ":", "str", ",", "algorithm", ":", "str", "=", "'acer'", ",", "algorithm_parameters", ":", "Optional", "[", "dict", "]", "=", "None", ",", "\n", "num_parallel_envs", ":", "int", "=", "5", ",", "evaluate_time_steps_interval", ":", "int", "=", "1500", ",", "\n", "num_evaluation_runs", ":", "int", "=", "5", ",", "log_dir", ":", "str", "=", "'logs/'", ",", "max_time_steps", ":", "int", "=", "-", "1", ",", "\n", "record_end", ":", "bool", "=", "True", ",", "experiment_name", ":", "str", "=", "None", ",", "asynchronous", ":", "bool", "=", "True", ",", "\n", "log_tensorboard", ":", "bool", "=", "True", ",", "do_checkpoint", ":", "bool", "=", "True", ",", "record_time_steps", ":", "int", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"Trains and evaluates the agent.\n\n        Args:\n            environment_name: Name of the gym's environment to be used.\n            algorithm: Algorithm name, one of the following: ['acer', 'acerac']\n            algorithm_parameters: Dictionary with the parameters of the algorithm.\n            num_parallel_envs: Number of parallel environments to be used.\n            evaluate_time_steps_interval: Number of time steps between evaluation runs, -1 if\n                no evaluation should be conducted.\n            num_evaluation_runs: Number of episodes per one evaluation.\n            log_dir: Logging directory.\n            max_time_steps: Maximum number of training time steps.\n            record_end: True if video should be recorded after training.\n            experiment_name: A string that is included in the name of the log directory\n            asynchronous: True to use concurrent envs.\n            log_tensorboard: True to create TensorBoard logs.\n            do_checkpoint: True to save checkpoints over the training.\n        \"\"\"", "\n", "self", ".", "_elapsed_time_measure", "=", "0", "\n", "self", ".", "_time_step", "=", "0", "\n", "self", ".", "_done_episodes", "=", "0", "\n", "self", ".", "_next_evaluation_timestamp", "=", "0", "\n", "self", ".", "_next_record_timestamp", "=", "0", "\n", "self", ".", "_n_envs", "=", "num_parallel_envs", "\n", "self", ".", "_evaluate_time_steps_interval", "=", "evaluate_time_steps_interval", "\n", "self", ".", "_num_evaluation_runs", "=", "num_evaluation_runs", "\n", "self", ".", "_max_time_steps", "=", "max_time_steps", "\n", "self", ".", "_log_tensorboard", "=", "log_tensorboard", "\n", "self", ".", "_do_checkpoint", "=", "do_checkpoint", "\n", "self", ".", "_env_name", "=", "environment_name", "\n", "if", "experiment_name", ":", "\n", "            ", "self", ".", "_log_dir", "=", "Path", "(", "\n", "f\"{log_dir}/{environment_name}_{algorithm}_{experiment_name}\"", "\n", "f\"_{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_log_dir", "=", "Path", "(", "\n", "f\"{log_dir}/{environment_name}_{algorithm}_{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"", "\n", ")", "\n", "", "self", ".", "_log_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "self", ".", "_record_end", "=", "record_end", "\n", "self", ".", "_record_time_steps", "=", "record_time_steps", "\n", "self", ".", "_env", "=", "_get_env", "(", "environment_name", ",", "num_parallel_envs", ",", "asynchronous", ")", "\n", "self", ".", "_evaluate_env", "=", "_get_env", "(", "environment_name", ",", "num_evaluation_runs", ",", "asynchronous", ")", "\n", "\n", "self", ".", "_done_steps_in_a_episode", "=", "[", "0", "]", "*", "self", ".", "_n_envs", "\n", "self", ".", "_returns", "=", "[", "0", "]", "*", "self", ".", "_n_envs", "\n", "self", ".", "_rewards", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "_n_envs", ")", "]", "\n", "\n", "dummy_env", "=", "self", ".", "_env", ".", "env_fns", "[", "0", "]", "(", ")", "\n", "self", ".", "_max_steps_in_episode", "=", "dummy_env", ".", "spec", ".", "max_episode_steps", "\n", "\n", "if", "self", ".", "_log_tensorboard", ":", "\n", "            ", "tensor_board_writer", "=", "tf", ".", "summary", ".", "create_file_writer", "(", "str", "(", "self", ".", "_log_dir", ")", ")", "\n", "tensor_board_writer", ".", "set_as_default", "(", ")", "\n", "\n", "", "self", ".", "_csv_logger", "=", "CSVLogger", "(", "\n", "self", ".", "_log_dir", "/", "'results.csv'", ",", "\n", "keys", "=", "[", "'time_step'", ",", "'eval_return_mean'", ",", "'eval_std_mean'", "]", "\n", ")", "\n", "\n", "self", ".", "_save_parameters", "(", "algorithm_parameters", ")", "\n", "self", ".", "_agent", "=", "_get_agent", "(", "algorithm", ",", "algorithm_parameters", ",", "dummy_env", ".", "observation_space", ",", "dummy_env", ".", "action_space", ")", "\n", "self", ".", "_current_obs", "=", "self", ".", "_env", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner.run": [[136, 161], ["runners.Runner._csv_logger.close", "runners.Runner._is_time_to_evaluate", "runners.Runner._is_time_to_record", "time.time", "runners.Runner._step", "runners.Runner._agent.save_experience", "runners.Runner._agent.learn", "runners.Runner._record_video", "runners.Runner._evaluate", "runners.Runner._record_video", "time.time", "runners.Runner._save_results", "runners.Runner._save_checkpoint"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.CSVLogger.close", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._is_time_to_evaluate", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._is_time_to_record", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._step", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC.save_experience", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER.learn", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._record_video", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._evaluate", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._record_video", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._save_results", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._save_checkpoint"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "\"\"\"Performs training. If 'evaluate' is True, evaluation of the policy is performed. During the evaluation\n        policy that is being optimized is used without exploration.\n        \"\"\"", "\n", "while", "self", ".", "_max_time_steps", "==", "-", "1", "or", "self", ".", "_time_step", "<=", "self", ".", "_max_time_steps", ":", "\n", "\n", "            ", "if", "self", ".", "_is_time_to_evaluate", "(", ")", ":", "\n", "                ", "self", ".", "_evaluate", "(", ")", "\n", "if", "self", ".", "_time_step", "!=", "0", ":", "\n", "                    ", "self", ".", "_save_results", "(", ")", "\n", "if", "self", ".", "_do_checkpoint", ":", "\n", "                        ", "self", ".", "_save_checkpoint", "(", ")", "\n", "\n", "", "", "", "if", "self", ".", "_is_time_to_record", "(", ")", ":", "\n", "                ", "self", ".", "_record_video", "(", ")", "\n", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "experience", "=", "self", ".", "_step", "(", ")", "\n", "self", ".", "_agent", ".", "save_experience", "(", "experience", ")", "\n", "self", ".", "_agent", ".", "learn", "(", ")", "\n", "self", ".", "_elapsed_time_measure", "+=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "\n", "", "self", ".", "_csv_logger", ".", "close", "(", ")", "\n", "if", "self", ".", "_record_end", ":", "\n", "            ", "self", ".", "_record_video", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._save_results": [[162, 165], ["runners.Runner._csv_logger.dump", "logging.info"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.CSVLogger.dump"], ["", "", "def", "_save_results", "(", "self", ")", ":", "\n", "        ", "self", ".", "_csv_logger", ".", "dump", "(", ")", "\n", "logging", ".", "info", "(", "f\"saved evaluation results in {self._log_dir}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._step": [[166, 215], ["runners.Runner._agent.predict_action", "runners.Runner._env.step", "range", "numpy.array", "rewards.append", "experience.append", "runners.Runner._rewards[].append", "runners.Runner._measure_time", "logging.info", "tensorflow.name_scope", "tensorflow.summary.histogram", "tensorflow.summary.scalar", "tensorflow.summary.scalar"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseACERAgent.predict_action", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._measure_time"], ["", "def", "_step", "(", "self", ")", "->", "List", "[", "Tuple", "[", "Union", "[", "int", ",", "float", "]", ",", "np", ".", "array", ",", "float", ",", "float", ",", "bool", ",", "bool", "]", "]", ":", "\n", "        ", "actions", ",", "policies", "=", "self", ".", "_agent", ".", "predict_action", "(", "self", ".", "_current_obs", ")", "\n", "steps", "=", "self", ".", "_env", ".", "step", "(", "actions", ")", "\n", "rewards", "=", "[", "]", "\n", "experience", "=", "[", "]", "\n", "old_obs", "=", "self", ".", "_current_obs", "\n", "self", ".", "_current_obs", "=", "steps", "[", "0", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "_n_envs", ")", ":", "\n", "# 'is_done' from Gym does not take into account maximum number of steps in a single episode constraint", "\n", "            ", "self", ".", "_time_step", "+=", "1", "\n", "if", "self", ".", "_time_step", "%", "Runner", ".", "MEASURE_TIME_TIME_STEPS", "==", "0", ":", "\n", "                ", "self", ".", "_measure_time", "(", ")", "\n", "\n", "", "rewards", ".", "append", "(", "steps", "[", "1", "]", "[", "i", "]", ")", "\n", "self", ".", "_done_steps_in_a_episode", "[", "i", "]", "+=", "1", "\n", "is_done_gym", "=", "steps", "[", "2", "]", "[", "i", "]", "\n", "is_maximum_number_of_steps_reached", "=", "self", ".", "_max_steps_in_episode", "is", "not", "None", "and", "self", ".", "_max_steps_in_episode", "==", "self", ".", "_done_steps_in_a_episode", "[", "i", "]", "\n", "\n", "is_done", "=", "is_done_gym", "and", "not", "is_maximum_number_of_steps_reached", "\n", "is_end", "=", "is_done", "or", "is_maximum_number_of_steps_reached", "\n", "\n", "reward", "=", "steps", "[", "1", "]", "[", "i", "]", "\n", "experience", ".", "append", "(", "\n", "(", "actions", "[", "i", "]", ",", "old_obs", "[", "i", "]", ",", "self", ".", "_current_obs", "[", "i", "]", ",", "reward", ",", "policies", "[", "i", "]", ",", "is_done", ",", "is_end", ")", "\n", ")", "\n", "\n", "self", ".", "_returns", "[", "i", "]", "+=", "steps", "[", "1", "]", "[", "i", "]", "\n", "self", ".", "_rewards", "[", "i", "]", ".", "append", "(", "steps", "[", "1", "]", "[", "i", "]", ")", "\n", "\n", "if", "is_end", ":", "\n", "                ", "self", ".", "_done_episodes", "+=", "1", "\n", "\n", "logging", ".", "info", "(", "f\"finished episode {self._done_episodes}, \"", "\n", "f\"return: {self._returns[i]}, \"", "\n", "f\"total time steps done: {self._time_step}\"", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'rewards'", ")", ":", "\n", "                    ", "tf", ".", "summary", ".", "histogram", "(", "'rewards'", ",", "self", ".", "_rewards", "[", "i", "]", ",", "self", ".", "_done_episodes", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'return'", ",", "self", ".", "_returns", "[", "i", "]", ",", "self", ".", "_done_episodes", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'episode length'", ",", "self", ".", "_done_steps_in_a_episode", "[", "i", "]", ",", "self", ".", "_done_episodes", ")", "\n", "\n", "", "self", ".", "_returns", "[", "i", "]", "=", "0", "\n", "self", ".", "_rewards", "[", "i", "]", "=", "[", "]", "\n", "self", ".", "_done_steps_in_a_episode", "[", "i", "]", "=", "0", "\n", "\n", "", "", "self", ".", "_current_obs", "=", "np", ".", "array", "(", "self", ".", "_current_obs", ")", "\n", "return", "experience", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._evaluate": [[216, 252], ["runners.Runner._evaluate_env.reset", "numpy.mean", "numpy.std", "runners.Runner._csv_logger.log_values", "all", "runners.Runner._agent.predict_action", "runners.Runner._evaluate_env.step", "range", "tensorflow.name_scope", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "logging.info"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.Logger.log_values", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseACERAgent.predict_action"], ["", "def", "_evaluate", "(", "self", ")", ":", "\n", "        ", "self", ".", "_next_evaluation_timestamp", "+=", "self", ".", "_evaluate_time_steps_interval", "\n", "\n", "returns", "=", "[", "0", "]", "*", "self", ".", "_num_evaluation_runs", "\n", "envs_finished", "=", "[", "False", "]", "*", "self", ".", "_num_evaluation_runs", "\n", "time_step", "=", "0", "\n", "current_obs", "=", "self", ".", "_evaluate_env", ".", "reset", "(", ")", "\n", "\n", "while", "not", "all", "(", "envs_finished", ")", ":", "\n", "            ", "time_step", "+=", "1", "\n", "actions", ",", "_", "=", "self", ".", "_agent", ".", "predict_action", "(", "current_obs", ",", "is_deterministic", "=", "True", ")", "\n", "steps", "=", "self", ".", "_evaluate_env", ".", "step", "(", "actions", ")", "\n", "current_obs", "=", "steps", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_evaluation_runs", ")", ":", "\n", "                ", "if", "not", "envs_finished", "[", "i", "]", ":", "\n", "                    ", "returns", "[", "i", "]", "+=", "steps", "[", "1", "]", "[", "i", "]", "\n", "\n", "is_done_gym", "=", "steps", "[", "2", "]", "[", "i", "]", "\n", "is_maximum_number_of_steps_reached", "=", "self", ".", "_max_steps_in_episode", "is", "not", "None", "and", "self", ".", "_max_steps_in_episode", "==", "time_step", "\n", "\n", "is_end", "=", "is_done_gym", "or", "is_maximum_number_of_steps_reached", "\n", "envs_finished", "[", "i", "]", "=", "is_end", "\n", "if", "is_end", ":", "\n", "                        ", "logging", ".", "info", "(", "f\"evaluation run, \"", "\n", "f\"return: {returns[i]}\"", ")", "\n", "\n", "", "", "", "", "mean_returns", "=", "np", ".", "mean", "(", "returns", ")", "\n", "std_returns", "=", "np", ".", "std", "(", "returns", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'rewards'", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "'evaluation_return_mean'", ",", "mean_returns", ",", "self", ".", "_time_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'evaluation_return_std'", ",", "std_returns", ",", "self", ".", "_time_step", ")", "\n", "\n", "", "self", ".", "_csv_logger", ".", "log_values", "(", "\n", "{", "'time_step'", ":", "self", ".", "_time_step", ",", "'eval_return_mean'", ":", "mean_returns", ",", "'eval_std_mean'", ":", "std_returns", "}", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._record_video": [[254, 280], ["logging.info", "gym.wrappers.Monitor", "numpy.array", "gym.wrappers.Monitor.close", "logging.info", "gym.make", "runners.Runner._agent.predict_action", "gym.wrappers.Monitor.step", "numpy.array", "logging.error", "gym.wrappers.Monitor.reset", "str"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.CSVLogger.close", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseACERAgent.predict_action"], ["", "def", "_record_video", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_record_time_steps", ":", "\n", "            ", "self", ".", "_next_record_timestamp", "+=", "self", ".", "_record_time_steps", "\n", "", "logging", ".", "info", "(", "f\"saving video...\"", ")", "\n", "try", ":", "\n", "            ", "env", "=", "wrappers", ".", "Monitor", "(", "gym", ".", "make", "(", "self", ".", "_env_name", ")", ",", "self", ".", "_log_dir", "/", "f'video-{self._time_step}'", ",", "\n", "force", "=", "True", ",", "video_callable", "=", "lambda", "x", ":", "True", ")", "\n", "is_end", "=", "False", "\n", "time_step", "=", "0", "\n", "current_obs", "=", "np", ".", "array", "(", "[", "env", ".", "reset", "(", ")", "]", ")", "\n", "\n", "while", "not", "is_end", ":", "\n", "                ", "time_step", "+=", "1", "\n", "actions", ",", "_", "=", "self", ".", "_agent", ".", "predict_action", "(", "current_obs", ",", "is_deterministic", "=", "True", ")", "\n", "steps", "=", "env", ".", "step", "(", "actions", "[", "0", "]", ")", "\n", "current_obs", "=", "np", ".", "array", "(", "[", "steps", "[", "0", "]", "]", ")", "\n", "is_done_gym", "=", "steps", "[", "2", "]", "\n", "is_maximum_number_of_steps_reached", "=", "self", ".", "_max_steps_in_episode", "is", "not", "None", "and", "self", ".", "_max_steps_in_episode", "==", "time_step", "\n", "\n", "is_end", "=", "is_done_gym", "or", "is_maximum_number_of_steps_reached", "\n", "\n", "", "env", ".", "close", "(", ")", "\n", "logging", ".", "info", "(", "f\"saved video in {str(self._log_dir / f'video-{self._time_step}')}\"", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "logging", ".", "error", "(", "f\"Error while recording the video. Make sure you've got proper drivers\"", "\n", "f\"and libraries installed (i.e ffmpeg). Error message:\\n {e}\"", ")", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._is_time_to_evaluate": [[282, 284], ["None"], "methods", ["None"], ["", "", "def", "_is_time_to_evaluate", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_evaluate_time_steps_interval", "!=", "-", "1", "and", "self", ".", "_time_step", ">=", "self", ".", "_next_evaluation_timestamp", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._is_time_to_record": [[285, 287], ["None"], "methods", ["None"], ["", "def", "_is_time_to_record", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_record_time_steps", "is", "not", "None", "and", "self", ".", "_time_step", ">=", "self", ".", "_next_record_timestamp", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._measure_time": [[288, 296], ["tensorflow.name_scope", "tensorflow.summary.scalar"], "methods", ["None"], ["", "def", "_measure_time", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "'acer'", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "\n", "'time steps per second'", ",", "\n", "Runner", ".", "MEASURE_TIME_TIME_STEPS", "/", "self", ".", "_elapsed_time_measure", ",", "\n", "self", ".", "_time_step", "\n", ")", "\n", "", "self", ".", "_elapsed_time_measure", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._save_parameters": [[297, 300], ["open", "json.dump", "str"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.CSVLogger.dump"], ["", "def", "_save_parameters", "(", "self", ",", "algorithm_parameters", ":", "dict", ")", ":", "\n", "        ", "with", "open", "(", "str", "(", "self", ".", "_log_dir", "/", "'parameters.json'", ")", ",", "'wt'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "algorithm_parameters", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner._save_checkpoint": [[301, 315], ["checkpoint_dir.mkdir", "runners.Runner._agent.save", "logging.info", "open", "json.dump", "str", "str"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseACERAgent.save", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.CSVLogger.dump"], ["", "", "def", "_save_checkpoint", "(", "self", ")", ":", "\n", "        ", "checkpoint_dir", "=", "self", ".", "_log_dir", "/", "'checkpoint'", "\n", "checkpoint_dir", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "\n", "runner_dump", "=", "{", "\n", "'time_step'", ":", "self", ".", "_time_step", ",", "\n", "'done_episodes'", ":", "self", ".", "_done_episodes", ",", "\n", "}", "\n", "with", "open", "(", "str", "(", "checkpoint_dir", "/", "'runner.json'", ")", ",", "'wt'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "runner_dump", ",", "f", ")", "\n", "\n", "", "self", ".", "_agent", ".", "save", "(", "checkpoint_dir", "/", "'model'", ")", "\n", "\n", "logging", ".", "info", "(", "f\"saved checkpoint in '{str(checkpoint_dir)}'\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners._get_agent": [[33, 44], ["None"], "function", ["None"], ["def", "_get_agent", "(", "\n", "algorithm", ":", "str", ",", "parameters", ":", "Optional", "[", "dict", "]", ",", "observations_space", ":", "gym", ".", "Space", ",", "\n", "actions_space", ":", "gym", ".", "Space", "\n", ")", "->", "BaseACERAgent", ":", "\n", "    ", "if", "not", "parameters", ":", "\n", "        ", "parameters", "=", "{", "}", "\n", "\n", "", "if", "algorithm", "not", "in", "ALGOS", ":", "\n", "        ", "raise", "NotImplemented", "\n", "\n", "", "return", "ALGOS", "[", "algorithm", "]", "(", "observations_space", "=", "observations_space", ",", "actions_space", "=", "actions_space", ",", "**", "parameters", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners._get_env": [[46, 57], ["utils.is_atari", "gym.vector.make", "gym.wrappers.AtariPreprocessing", "gym.vector.AsyncVectorEnv", "gym.vector.SyncVectorEnv", "gym.make", "range"], "function", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.utils.is_atari"], ["", "def", "_get_env", "(", "env_id", ":", "str", ",", "num_parallel_envs", ":", "int", ",", "asynchronous", ":", "bool", "=", "True", ")", "->", "gym", ".", "vector", ".", "AsyncVectorEnv", ":", "\n", "    ", "if", "is_atari", "(", "env_id", ")", ":", "\n", "        ", "def", "get_env_fn", "(", ")", ":", "\n", "            ", "return", "wrappers", ".", "AtariPreprocessing", "(", "\n", "gym", ".", "make", "(", "env_id", ")", ",", "\n", ")", "\n", "", "builders", "=", "[", "get_env_fn", "for", "_", "in", "range", "(", "num_parallel_envs", ")", "]", "\n", "env", "=", "gym", ".", "vector", ".", "AsyncVectorEnv", "(", "builders", ")", "if", "asynchronous", "else", "gym", ".", "vector", ".", "SyncVectorEnv", "(", "builders", ")", "\n", "", "else", ":", "\n", "        ", "env", "=", "gym", ".", "vector", ".", "make", "(", "env_id", ",", "num_envs", "=", "num_parallel_envs", ",", "asynchronous", "=", "asynchronous", ")", "\n", "", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.Logger.__init__": [[10, 19], ["collections.defaultdict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "keys", ":", "List", "[", "str", "]", ")", ":", "\n", "        ", "\"\"\"Collects key-values pairs.\n        This logged automatically appends additional key-value pair: timestamp of the event.\n\n        Args:\n            keys: List of keys (strings) to be logged.\n        \"\"\"", "\n", "self", ".", "_data", "=", "defaultdict", "(", "dict", ")", "\n", "self", ".", "_keys", "=", "keys", "+", "[", "'timestamp'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.Logger.log_values": [[20, 33], ["collections.OrderedDict", "datetime.datetime.now().strftime", "logger.Logger._store_log", "key_values.get", "datetime.datetime.now"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.CSVLogger._store_log", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.MultiReplayBuffer.get"], ["", "def", "log_values", "(", "self", ",", "key_values", ":", "Dict", "[", "str", ",", "Any", "]", ")", ":", "\n", "        ", "\"\"\"Stores single data row.\n        Values outside of the list defined in the constructor are omitted.\n\n        Args:\n            key_values: Dictionary with keys and values to be stored.\n        \"\"\"", "\n", "stored_row", "=", "OrderedDict", "(", ")", "\n", "for", "key", "in", "self", ".", "_keys", ":", "\n", "            ", "stored_row", "[", "key", "]", "=", "key_values", ".", "get", "(", "key", ")", "\n", "\n", "", "stored_row", "[", "'timestamp'", "]", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ")", "\n", "self", ".", "_store_log", "(", "stored_row", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.Logger._store_log": [[34, 37], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_store_log", "(", "self", ",", "key_values", ":", "Dict", "[", "str", ",", "Any", "]", ")", ":", "\n", "        ", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.CSVLogger.__init__": [[41, 53], ["logger.Logger.__init__", "open", "csv.writer", "logger.CSVLogger._writer.writerow", "str"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER.__init__"], ["    ", "def", "__init__", "(", "self", ",", "file_path", ":", "Path", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Logs data into csv file.\n        IMPORTANT: close() method has to be called at the end of the run.\n\n        Args:\n            file_path: Path to the log file.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_file", "=", "open", "(", "str", "(", "file_path", ")", ",", "'wt'", ")", "\n", "self", ".", "_file_path", "=", "file_path", "\n", "self", ".", "_writer", "=", "csv", ".", "writer", "(", "self", ".", "_file", ",", "delimiter", "=", "','", ")", "\n", "self", ".", "_writer", ".", "writerow", "(", "self", ".", "_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.CSVLogger._store_log": [[54, 57], ["list", "logger.CSVLogger._writer.writerow", "key_values.values"], "methods", ["None"], ["", "def", "_store_log", "(", "self", ",", "key_values", ":", "OrderedDict", ")", ":", "\n", "        ", "row", "=", "list", "(", "key_values", ".", "values", "(", ")", ")", "\n", "self", ".", "_writer", ".", "writerow", "(", "row", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.CSVLogger.dump": [[58, 63], ["logger.CSVLogger._file.close", "open", "csv.writer", "str"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.CSVLogger.close"], ["", "def", "dump", "(", "self", ")", ":", "\n", "        ", "\"\"\"Appends collected data at the end of currently opened file.\"\"\"", "\n", "self", ".", "_file", ".", "close", "(", ")", "\n", "self", ".", "_file", "=", "open", "(", "str", "(", "self", ".", "_file_path", ")", ",", "'a+t'", ")", "\n", "self", ".", "_writer", "=", "csv", ".", "writer", "(", "self", ".", "_file", ",", "delimiter", "=", "','", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.CSVLogger.close": [[64, 67], ["logger.CSVLogger._file.close"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.CSVLogger.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "\"\"\"Closes opened file.\"\"\"", "\n", "self", ".", "_file", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer.__init__": [[17, 38], ["replay_buffer.ReplayBuffer._init_field", "replay_buffer.ReplayBuffer._init_field", "replay_buffer.ReplayBuffer._init_field", "replay_buffer.ReplayBuffer._init_field", "replay_buffer.ReplayBuffer._init_field", "replay_buffer.ReplayBuffer._init_field", "replay_buffer.ReplayBuffer._init_field", "replay_buffer.BufferFieldSpec", "replay_buffer.BufferFieldSpec", "replay_buffer.BufferFieldSpec", "replay_buffer.BufferFieldSpec"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._init_field", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._init_field", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._init_field", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._init_field", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._init_field", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._init_field", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._init_field"], ["    ", "def", "__init__", "(", "self", ",", "max_size", ":", "int", ",", "action_spec", ":", "BufferFieldSpec", ",", "obs_spec", ":", "BufferFieldSpec", ")", ":", "\n", "        ", "\"\"\"Stores trajectories.\n\n        Each of the samples stored in the buffer has the same probability of being drawn.\n\n        Args:\n            max_size: Maximum number of entries to be stored in the buffer - only newest entries are stored.\n            action_spec: BufferFieldSpec with actions space specification.\n            obs_spec: BufferFieldSpec with observations space specification.\n        \"\"\"", "\n", "self", ".", "_max_size", "=", "max_size", "\n", "self", ".", "_current_size", "=", "0", "\n", "self", ".", "_pointer", "=", "0", "\n", "\n", "self", ".", "_actions", "=", "self", ".", "_init_field", "(", "action_spec", ")", "\n", "self", ".", "_obs", "=", "self", ".", "_init_field", "(", "obs_spec", ")", "\n", "self", ".", "_obs_next", "=", "self", ".", "_init_field", "(", "obs_spec", ")", "\n", "self", ".", "_rewards", "=", "self", ".", "_init_field", "(", "BufferFieldSpec", "(", "(", ")", ",", "np", ".", "float32", ")", ")", "\n", "self", ".", "_policies", "=", "self", ".", "_init_field", "(", "BufferFieldSpec", "(", "(", ")", ",", "np", ".", "float32", ")", ")", "\n", "self", ".", "_dones", "=", "self", ".", "_init_field", "(", "BufferFieldSpec", "(", "(", ")", ",", "bool", ")", ")", "\n", "self", ".", "_ends", "=", "self", ".", "_init_field", "(", "BufferFieldSpec", "(", "(", ")", ",", "bool", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._init_field": [[39, 42], ["numpy.zeros"], "methods", ["None"], ["", "def", "_init_field", "(", "self", ",", "field_spec", ":", "BufferFieldSpec", ")", ":", "\n", "        ", "shape", "=", "(", "self", ".", "_max_size", ",", "*", "field_spec", ".", "shape", ")", "\n", "return", "np", ".", "zeros", "(", "shape", "=", "shape", ",", "dtype", "=", "field_spec", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer.put": [[43, 69], ["replay_buffer.ReplayBuffer._move_pointer", "replay_buffer.ReplayBuffer._update_size"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._move_pointer", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._update_size"], ["", "def", "put", "(", "\n", "self", ",", "action", ":", "Union", "[", "int", ",", "float", ",", "list", "]", ",", "observation", ":", "np", ".", "array", ",", "next_observation", ":", "np", ".", "array", ",", "\n", "reward", ":", "float", ",", "policy", ":", "float", ",", "is_done", ":", "bool", ",", "end", ":", "bool", "\n", ")", ":", "\n", "        ", "\"\"\"Stores one experience tuple in the buffer.\n\n        Args:\n            action: Performed action.\n            observation: State in which action was performed.\n            next_observation: Next state.\n            reward: Earned reward.\n            policy: Probability/probability density of executing stored action.\n            is_done: True if episode ended and was not terminated by reaching\n                the maximum number of steps per episode.\n            end: True if episode ended.\n        \"\"\"", "\n", "self", ".", "_actions", "[", "self", ".", "_pointer", "]", "=", "action", "\n", "self", ".", "_obs", "[", "self", ".", "_pointer", "]", "=", "observation", "\n", "self", ".", "_obs_next", "[", "self", ".", "_pointer", "]", "=", "next_observation", "\n", "self", ".", "_rewards", "[", "self", ".", "_pointer", "]", "=", "reward", "\n", "self", ".", "_policies", "[", "self", ".", "_pointer", "]", "=", "policy", "\n", "self", ".", "_dones", "[", "self", ".", "_pointer", "]", "=", "is_done", "\n", "self", ".", "_ends", "[", "self", ".", "_pointer", "]", "=", "end", "\n", "\n", "self", ".", "_move_pointer", "(", ")", "\n", "self", ".", "_update_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._move_pointer": [[70, 75], ["None"], "methods", ["None"], ["", "def", "_move_pointer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_pointer", "+", "1", "==", "self", ".", "_max_size", ":", "\n", "            ", "self", ".", "_pointer", "=", "0", "\n", "", "else", ":", "\n", "            ", "self", ".", "_pointer", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._update_size": [[76, 78], ["numpy.min"], "methods", ["None"], ["", "", "def", "_update_size", "(", "self", ")", ":", "\n", "        ", "self", ".", "_current_size", "=", "np", ".", "min", "(", "[", "self", ".", "_current_size", "+", "1", ",", "self", ".", "_max_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer.get": [[79, 104], ["replay_buffer.ReplayBuffer._sample_random_index", "replay_buffer.ReplayBuffer._get_indices", "replay_buffer.ReplayBuffer._fetch_batch", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._sample_random_index", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._get_indices", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._fetch_batch"], ["", "def", "get", "(", "self", ",", "trajectory_len", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "Tuple", "[", "Dict", "[", "str", ",", "np", ".", "array", "]", ",", "int", "]", ":", "\n", "        ", "\"\"\"Samples random trajectory. Trajectory length is truncated to the 'trajectory_len' value.\n        If trajectory length is not provided, whole episode is fetched. If trajectory is shorter than\n        'trajectory_len', trajectory is truncated to one episode only.\n\n        Returns:\n            Tuple with dictionary with truncated experience trajectory and first index (always zero in the case of\n            this type of a buffer)\n        \"\"\"", "\n", "if", "self", ".", "_current_size", "==", "0", ":", "\n", "# empty buffer", "\n", "            ", "return", "(", "{", "\n", "\"actions\"", ":", "np", ".", "array", "(", "[", "]", ")", ",", "\n", "\"observations\"", ":", "np", ".", "array", "(", "[", "]", ")", ",", "\n", "\"rewards\"", ":", "np", ".", "array", "(", "[", "]", ")", ",", "\n", "\"next_observations\"", ":", "np", ".", "array", "(", "[", "]", ")", ",", "\n", "\"policies\"", ":", "np", ".", "array", "(", "[", "]", ")", ",", "\n", "\"dones\"", ":", "np", ".", "array", "(", "[", "]", ")", ",", "\n", "\"ends\"", ":", "np", ".", "array", "(", "[", "]", ")", "\n", "}", ",", "-", "1", ")", "\n", "", "sample_index", "=", "self", ".", "_sample_random_index", "(", ")", "\n", "start_index", ",", "end_index", "=", "self", ".", "_get_indices", "(", "sample_index", ",", "trajectory_len", ")", "\n", "\n", "batch", "=", "self", ".", "_fetch_batch", "(", "end_index", ",", "sample_index", ",", "start_index", ")", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._fetch_batch": [[105, 131], ["None"], "methods", ["None"], ["", "def", "_fetch_batch", "(", "self", ",", "end_index", ":", "int", ",", "sample_index", ":", "int", ",", "start_index", ":", "int", ")", "->", "Tuple", "[", "Dict", "[", "str", ",", "np", ".", "array", "]", ",", "int", "]", ":", "\n", "\n", "        ", "middle_index", "=", "sample_index", "-", "start_index", "if", "sample_index", ">=", "start_index", "else", "self", ".", "_max_size", "-", "start_index", "+", "sample_index", "\n", "if", "start_index", ">=", "end_index", ":", "\n", "            ", "buffer_slice", "=", "np", ".", "r_", "[", "0", ":", "end_index", ",", "start_index", ":", "self", ".", "_max_size", "]", "\n", "", "else", ":", "\n", "            ", "buffer_slice", "=", "np", ".", "r_", "[", "start_index", ":", "end_index", "]", "\n", "\n", "", "actions", "=", "self", ".", "_actions", "[", "buffer_slice", "]", "\n", "observations", "=", "self", ".", "_obs", "[", "buffer_slice", "]", "\n", "rewards", "=", "self", ".", "_rewards", "[", "buffer_slice", "]", "\n", "next_observations", "=", "self", ".", "_obs_next", "[", "buffer_slice", "]", "\n", "policies", "=", "self", ".", "_policies", "[", "buffer_slice", "]", "\n", "done", "=", "self", ".", "_dones", "[", "buffer_slice", "]", "\n", "end", "=", "self", ".", "_ends", "[", "buffer_slice", "]", "\n", "\n", "return", "(", "{", "\n", "\"actions\"", ":", "actions", ",", "\n", "\"observations\"", ":", "observations", ",", "\n", "\"rewards\"", ":", "rewards", ",", "\n", "\"next_observations\"", ":", "next_observations", ",", "\n", "\"policies\"", ":", "policies", ",", "\n", "\"dones\"", ":", "done", ",", "\n", "\"ends\"", ":", "end", "\n", "}", ",", "middle_index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._get_indices": [[132, 150], ["None"], "methods", ["None"], ["", "def", "_get_indices", "(", "self", ",", "sample_index", ":", "int", ",", "trajectory_len", ":", "int", ")", "->", "Tuple", "[", "int", ",", "int", "]", ":", "\n", "        ", "start_index", "=", "sample_index", "\n", "end_index", "=", "sample_index", "+", "1", "\n", "current_length", "=", "1", "\n", "while", "True", ":", "\n", "            ", "if", "end_index", "==", "self", ".", "_max_size", ":", "\n", "                ", "if", "self", ".", "_pointer", "==", "0", ":", "\n", "                    ", "break", "\n", "", "else", ":", "\n", "                    ", "end_index", "=", "0", "\n", "continue", "\n", "", "", "if", "end_index", "==", "self", ".", "_pointer", "or", "self", ".", "_ends", "[", "end_index", "-", "1", "]", "or", "(", "trajectory_len", "and", "current_length", "==", "trajectory_len", ")", ":", "\n", "                ", "break", "\n", "", "end_index", "+=", "1", "\n", "current_length", "+=", "1", "\n", "", "return", "start_index", ",", "end_index", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._sample_random_index": [[151, 154], ["numpy.random.randint"], "methods", ["None"], ["", "def", "_sample_random_index", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"Uniformly samples one index from the buffer.\"\"\"", "\n", "return", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "self", ".", "_current_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer.size": [[155, 163], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "size", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"Returns number of steps stored in the buffer.\n\n        Returns:\n            Size of buffer.\n        \"\"\"", "\n", "return", "self", ".", "_current_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer.__repr__": [[164, 166], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"{self.__class__.__name__}(max_size={self._max_size})\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.PrevReplayBuffer.__init__": [[170, 183], ["replay_buffer.ReplayBuffer.__init__", "replay_buffer.PrevReplayBuffer._init_field"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER.__init__", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._init_field"], ["    ", "def", "__init__", "(", "self", ",", "max_size", ":", "int", ",", "action_spec", ":", "BufferFieldSpec", ",", "obs_spec", ":", "BufferFieldSpec", ")", ":", "\n", "        ", "\"\"\"Extends ReplayBuffer to fetch one experience tuple before selected index.\n        If selected index indicates first time step in a episode, no additional tuples are attached.\n        Policies buffer is replaced to store data in same specification as actions\n        (used in algorithms with autocorrelated actions).\n\n        Args:\n            max_size: Maximum number of entries to be stored in the buffer - only newest entries are stored.\n            action_spec: BufferFieldSpec with actions space specification.\n            obs_spec: BufferFieldSpec with observations space specification.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "max_size", ",", "action_spec", ",", "obs_spec", ")", "\n", "self", ".", "_policies", "=", "self", ".", "_init_field", "(", "action_spec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.PrevReplayBuffer.get": [[184, 210], ["replay_buffer.PrevReplayBuffer._sample_random_index", "replay_buffer.PrevReplayBuffer._get_indices", "replay_buffer.PrevReplayBuffer._fetch_batch", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._sample_random_index", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._get_indices", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.ReplayBuffer._fetch_batch"], ["", "def", "get", "(", "self", ",", "trajectory_len", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "Tuple", "[", "Dict", "[", "str", ",", "np", ".", "array", "]", ",", "int", "]", ":", "\n", "        ", "if", "self", ".", "_current_size", "==", "0", ":", "\n", "# empty buffer", "\n", "            ", "return", "(", "{", "\n", "\"actions\"", ":", "np", ".", "array", "(", "[", "]", ")", ",", "\n", "\"observations\"", ":", "np", ".", "array", "(", "[", "]", ")", ",", "\n", "\"rewards\"", ":", "np", ".", "array", "(", "[", "]", ")", ",", "\n", "\"next_observations\"", ":", "np", ".", "array", "(", "[", "]", ")", ",", "\n", "\"policies\"", ":", "np", ".", "array", "(", "[", "]", ")", ",", "\n", "\"dones\"", ":", "np", ".", "array", "(", "[", "]", ")", ",", "\n", "\"ends\"", ":", "np", ".", "array", "(", "[", "]", ")", "\n", "}", ",", "-", "1", ")", "\n", "\n", "", "start", "=", "sample_index", "=", "self", ".", "_sample_random_index", "(", ")", "\n", "trajectory_len_adjusted", "=", "trajectory_len", "\n", "if", "self", ".", "_pointer", "!=", "sample_index", ":", "\n", "            ", "if", "sample_index", ">", "0", "and", "not", "self", ".", "_ends", "[", "sample_index", "-", "1", "]", ":", "\n", "                ", "start", "=", "sample_index", "-", "1", "\n", "trajectory_len_adjusted", "=", "trajectory_len", "+", "1", "\n", "", "elif", "self", ".", "_current_size", "==", "self", ".", "_max_size", "and", "sample_index", "==", "0", "and", "not", "self", ".", "_ends", "[", "-", "1", "]", ":", "\n", "                ", "start", "=", "self", ".", "_max_size", "-", "1", "\n", "trajectory_len_adjusted", "=", "trajectory_len", "+", "1", "\n", "\n", "", "", "start_index", ",", "end_index", "=", "self", ".", "_get_indices", "(", "start", ",", "trajectory_len_adjusted", ")", "\n", "batch", "=", "self", ".", "_fetch_batch", "(", "end_index", ",", "sample_index", ",", "start_index", ")", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.MultiReplayBuffer.__init__": [[214, 230], ["issubclass", "buffer_class", "int", "range"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "max_size", ":", "int", ",", "num_buffers", ":", "int", ",", "action_spec", ":", "BufferFieldSpec", ",", "\n", "obs_spec", ":", "BufferFieldSpec", ",", "buffer_class", ":", "type", "=", "ReplayBuffer", ")", ":", "\n", "        ", "\"\"\"Encapsulates ReplayBuffers from multiple environments.\n\n        Args:\n            max_size: Maximum number of entries to be stored in the buffer - only newest entries are stored.\n            action_spec: BufferFieldSpec with actions space specification.\n            obs_spec: BufferFieldSpec with observations space specification.\n            buffer_class: Class of a buffer to be created.\n        \"\"\"", "\n", "self", ".", "_n_buffers", "=", "num_buffers", "\n", "self", ".", "_max_size", "=", "max_size", "\n", "\n", "assert", "issubclass", "(", "buffer_class", ",", "ReplayBuffer", ")", ",", "\"Buffer class should derive from ReplayBuffer\"", "\n", "\n", "self", ".", "_buffers", "=", "[", "buffer_class", "(", "int", "(", "max_size", "/", "num_buffers", ")", ",", "action_spec", ",", "obs_spec", ")", "for", "_", "in", "range", "(", "num_buffers", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.MultiReplayBuffer.put": [[231, 243], ["zip", "len", "buffer.put", "len"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.MultiReplayBuffer.put"], ["", "def", "put", "(", "self", ",", "steps", ":", "List", "[", "Tuple", "[", "Union", "[", "int", ",", "float", ",", "list", "]", ",", "np", ".", "array", ",", "float", ",", "np", ".", "array", ",", "bool", ",", "bool", "]", "]", ")", ":", "\n", "        ", "\"\"\"Stores experience in the buffers. Accepts list of steps.\n\n        Args:\n            steps: List of steps, each of step Tuple consists of: action, observation, reward,\n                next_observation, policy, is_done flag, end flag. See ReplayBuffer.put() for format description.\n        \"\"\"", "\n", "assert", "len", "(", "steps", ")", "==", "self", ".", "_n_buffers", ",", "f\"'steps' list should provide one step (experience) for every buffer\"", "f\"(found: {len(steps)} steps, expected: {self._n_buffers}\"", "\n", "\n", "for", "buffer", ",", "step", "in", "zip", "(", "self", ".", "_buffers", ",", "steps", ")", ":", "\n", "            ", "buffer", ".", "put", "(", "*", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.MultiReplayBuffer.get": [[244, 264], ["len", "len", "buffer.get", "buffer.get", "zip"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.MultiReplayBuffer.get", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.MultiReplayBuffer.get"], ["", "", "def", "get", "(", "self", ",", "trajectories_lens", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ")", "->", "List", "[", "Tuple", "[", "Dict", "[", "str", ",", "Union", "[", "np", ".", "array", ",", "list", "]", "]", ",", "int", "]", "]", ":", "\n", "        ", "\"\"\"Samples trajectory from every buffer.\n\n        Args:\n            trajectories_lens: List of maximum lengths of trajectory to be fetched from corresponding buffer.\n\n        Returns:\n            List of sampled trajectories from every buffer, see specific buffer class's .get()\n            for detailed format description.\n        \"\"\"", "\n", "assert", "trajectories_lens", "is", "None", "or", "len", "(", "trajectories_lens", ")", "==", "self", ".", "_n_buffers", ",", "f\"'steps' list should provide one step (experience) for every buffer\"", "f\" (found: {len(trajectories_lens)} steps, expected: {self._n_buffers}\"", "\n", "\n", "if", "trajectories_lens", ":", "\n", "            ", "samples", "=", "[", "buffer", ".", "get", "(", "trajectory_len", ")", "for", "buffer", ",", "trajectory_len", "in", "zip", "(", "self", ".", "_buffers", ",", "trajectories_lens", ")", "]", "\n", "", "else", ":", "\n", "            ", "samples", "=", "[", "buffer", ".", "get", "(", ")", "for", "buffer", "in", "self", ".", "_buffers", "]", "\n", "\n", "", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.MultiReplayBuffer.size": [[265, 272], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "size", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "\"\"\"\n        Returns:\n            List of buffers' sizes.\n        \"\"\"", "\n", "return", "[", "buffer", ".", "size", "for", "buffer", "in", "self", ".", "_buffers", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.MultiReplayBuffer.n_buffers": [[273, 280], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_buffers", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Returns:\n            Number of instantiated buffers.\n        \"\"\"", "\n", "return", "self", ".", "_n_buffers", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.MultiReplayBuffer.__repr__": [[281, 283], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"{self.__class__.__name__}(max_size={self._max_size})\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.MultiReplayBuffer.save": [[284, 293], ["open", "pickle.dump"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.logger.CSVLogger.dump"], ["", "def", "save", "(", "self", ",", "path", ":", "str", ")", ":", "\n", "        ", "\"\"\"Dumps the buffer to the disk.\n\n        Args:\n            path: File path to the new file.\n        \"\"\"", "\n", "\n", "with", "open", "(", "path", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.MultiReplayBuffer.load": [[294, 304], ["open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.MultiReplayBuffer.load"], ["", "", "@", "staticmethod", "\n", "def", "load", "(", "path", ":", "str", ")", "->", "MultiReplayBuffer", ":", "\n", "        ", "\"\"\"Loads the buffer from the disk.\n\n        Args:\n            path: Path where the buffer was stored.\n        \"\"\"", "\n", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "buffer", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "return", "buffer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.run.main": [[97, 135], ["parser.parse_args", "parser.parse_known_args", "len", "parameters.pop", "parameters.pop", "parameters.pop", "parameters.pop", "parameters.pop", "parameters.pop", "parameters.pop", "parameters.pop", "parameters.pop", "parameters.pop", "parameters.pop", "runners.Runner", "runners.Runner.run", "print", "str", "vars().items", "vars", "vars"], "function", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.runners.Runner.run"], ["def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "cmd_parameters", ",", "unknown_args", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "if", "len", "(", "unknown_args", ")", ":", "\n", "        ", "print", "(", "\"Not recognized arguments: \"", ",", "str", "(", "vars", "(", "unknown_args", ")", ")", ")", "\n", "return", "\n", "\n", "", "parameters", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "vars", "(", "cmd_parameters", ")", ".", "items", "(", ")", "if", "v", "is", "not", "None", "}", "\n", "parameters", ".", "pop", "(", "'env_name'", ")", "\n", "evaluate_time_steps_interval", "=", "parameters", ".", "pop", "(", "'evaluate_time_steps_interval'", ")", "\n", "num_evaluation_runs", "=", "parameters", ".", "pop", "(", "'num_evaluation_runs'", ")", "\n", "max_time_steps", "=", "parameters", ".", "pop", "(", "'max_time_steps'", ")", "\n", "no_checkpoint", "=", "parameters", ".", "pop", "(", "'no_checkpoint'", ")", "\n", "no_tensorboard", "=", "parameters", ".", "pop", "(", "'no_tensorboard'", ")", "\n", "record_time_steps", "=", "parameters", ".", "pop", "(", "'record_time_steps'", ",", "None", ")", "\n", "experiment_name", "=", "parameters", ".", "pop", "(", "'experiment_name'", ")", "\n", "algorithm", "=", "parameters", ".", "pop", "(", "'algo'", ")", "\n", "log_dir", "=", "parameters", ".", "pop", "(", "'log_dir'", ")", "\n", "synchronous", "=", "parameters", ".", "pop", "(", "'synchronous'", ")", "\n", "\n", "runner", "=", "Runner", "(", "\n", "environment_name", "=", "cmd_parameters", ".", "env_name", ",", "\n", "algorithm", "=", "algorithm", ",", "\n", "algorithm_parameters", "=", "parameters", ",", "\n", "num_parallel_envs", "=", "cmd_parameters", ".", "num_parallel_envs", ",", "\n", "log_dir", "=", "log_dir", ",", "\n", "max_time_steps", "=", "max_time_steps", ",", "\n", "num_evaluation_runs", "=", "num_evaluation_runs", ",", "\n", "evaluate_time_steps_interval", "=", "evaluate_time_steps_interval", ",", "\n", "experiment_name", "=", "experiment_name", ",", "\n", "asynchronous", "=", "not", "synchronous", ",", "\n", "log_tensorboard", "=", "not", "no_tensorboard", ",", "\n", "do_checkpoint", "=", "not", "no_checkpoint", ",", "\n", "record_time_steps", "=", "record_time_steps", "\n", ")", "\n", "\n", "runner", ".", "run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.utils.normc_initializer": [[8, 15], ["numpy.random.randn", "tensorflow.constant", "numpy.sqrt", "numpy.square().sum", "numpy.square"], "function", ["None"], ["def", "normc_initializer", "(", ")", ":", "\n", "    ", "\"\"\"Normalized column initializer.\"\"\"", "\n", "def", "_initializer", "(", "shape", ",", "dtype", "=", "None", ",", "partition_info", "=", "None", ")", ":", "\n", "        ", "out", "=", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", "\n", "out", "*=", "1", "/", "np", ".", "sqrt", "(", "np", ".", "square", "(", "out", ")", ".", "sum", "(", "axis", "=", "0", ",", "keepdims", "=", "True", ")", ")", "\n", "return", "tf", ".", "constant", "(", "out", ",", "dtype", "=", "dtype", ")", "\n", "", "return", "_initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.utils.flatten_experience": [[17, 43], ["numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate"], "function", ["None"], ["", "def", "flatten_experience", "(", "\n", "experience_batches", ":", "List", "[", "Tuple", "[", "Dict", "[", "str", ",", "Union", "[", "np", ".", "array", ",", "list", "]", "]", ",", "int", "]", "]", "\n", ")", "->", "Tuple", "[", "np", ".", "array", ",", "np", ".", "array", ",", "np", ".", "array", ",", "np", ".", "array", ",", "np", ".", "array", ",", "np", ".", "array", "]", ":", "\n", "    ", "\"\"\"Parses experience from the buffers (from dictionaries) into matrices that can be feed into\n    neural network in a single pass.\n\n    Args:\n        experience_batches: List of dictionaries with trajectories.\n\n    Returns:\n        Tuple with matrices:\n            * batch [batch_size, observations_dim] of observations,\n            * batch [batch_size, observations_dim] of 'next' observations,\n            * batch [batch_size, actions_dim] of actions,\n            * batch [batch_size, observations_dim] of policies (probabilities or probability densities),\n            * batch [batch_size, actions_dim] of rewards,\n            * batch [batch_size, actions_dim] of boolean values indicating end of an episode.\n    \"\"\"", "\n", "observations", "=", "np", ".", "concatenate", "(", "[", "batch", "[", "0", "]", "[", "'observations'", "]", "for", "batch", "in", "experience_batches", "]", ",", "axis", "=", "0", ")", "\n", "next_observations", "=", "np", ".", "concatenate", "(", "[", "batch", "[", "0", "]", "[", "'next_observations'", "]", "for", "batch", "in", "experience_batches", "]", ",", "axis", "=", "0", ")", "\n", "actions", "=", "np", ".", "concatenate", "(", "[", "batch", "[", "0", "]", "[", "'actions'", "]", "for", "batch", "in", "experience_batches", "]", ",", "axis", "=", "0", ")", "\n", "policies", "=", "np", ".", "concatenate", "(", "[", "batch", "[", "0", "]", "[", "'policies'", "]", "for", "batch", "in", "experience_batches", "]", ",", "axis", "=", "0", ")", "\n", "rewards", "=", "np", ".", "concatenate", "(", "[", "batch", "[", "0", "]", "[", "'rewards'", "]", "for", "batch", "in", "experience_batches", "]", ",", "axis", "=", "0", ")", "\n", "dones", "=", "np", ".", "concatenate", "(", "[", "batch", "[", "0", "]", "[", "'dones'", "]", "for", "batch", "in", "experience_batches", "]", ",", "axis", "=", "0", ")", "\n", "\n", "return", "observations", ",", "next_observations", ",", "actions", ",", "policies", ",", "rewards", ",", "dones", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.utils.is_atari": [[45, 57], ["[].split", "gym.envs.registry.all", "env_spec.entry_point.split"], "function", ["None"], ["", "def", "is_atari", "(", "env_id", ":", "str", ")", "->", "bool", ":", "\n", "    ", "\"\"\"Checks if environments is of Atari type.\n\n    Args:\n        env_id: Name (id) of the environment.\n\n    Returns:\n        True if its is Atari environment.\n    \"\"\"", "\n", "env_spec", "=", "[", "env", "for", "env", "in", "gym", ".", "envs", ".", "registry", ".", "all", "(", ")", "if", "env", ".", "id", "==", "env_id", "]", "[", "0", "]", "\n", "env_type", "=", "env_spec", ".", "entry_point", ".", "split", "(", "':'", ")", "[", "0", "]", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", "\n", "return", "env_type", "==", "'atari'", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.utils.get_env_variables": [[59, 88], ["type", "type", "numpy.maximum", "numpy.abs"], "function", ["None"], ["", "def", "get_env_variables", "(", "env", ":", "gym", ".", "Env", ")", "->", "Tuple", "[", "float", ",", "int", ",", "int", ",", "bool", ",", "int", "]", ":", "\n", "    ", "\"\"\"Returns OpenAI Gym environment characteristics.\n\n    Args:\n        env: gym.Env object.\n\n    Returns:\n        Tuple with:\n            * scale of a single action if action's space is continuous, 1 otherwise\n            (scale is defined as t, where action can be from interval [-t, t]);\n            * dimension of a single action vector;\n            * dimension of a single observation vector;\n            * boolean value indicating continuous actions space;\n            * maximum number of steps in a single episode.\n    \"\"\"", "\n", "if", "type", "(", "env", ".", "observation_space", ")", "==", "gym", ".", "spaces", ".", "discrete", ".", "Discrete", ":", "\n", "        ", "observations_dim", "=", "env", ".", "observation_space", ".", "n", "\n", "", "else", ":", "\n", "        ", "observations_dim", "=", "env", ".", "observation_space", ".", "shape", "[", "0", "]", "\n", "", "if", "type", "(", "env", ".", "action_space", ")", "==", "gym", ".", "spaces", ".", "discrete", ".", "Discrete", ":", "\n", "        ", "continuous", "=", "False", "\n", "actions_dim", "=", "env", ".", "action_space", ".", "n", "\n", "action_scale", "=", "1", "\n", "", "else", ":", "\n", "        ", "continuous", "=", "True", "\n", "actions_dim", "=", "env", ".", "action_space", ".", "shape", "[", "0", "]", "\n", "action_scale", "=", "np", ".", "maximum", "(", "env", ".", "action_space", ".", "high", ",", "np", ".", "abs", "(", "env", ".", "action_space", ".", "low", ")", ")", "\n", "", "max_steps_in_episode", "=", "env", ".", "spec", ".", "max_episode_steps", "\n", "return", "action_scale", ",", "actions_dim", ",", "observations_dim", ",", "continuous", ",", "max_steps_in_episode", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor.__init__": [[25, 58], ["super().__init__", "base.BaseActor._hidden_layers.extend", "base.BaseActor._hidden_layers.append", "type", "len", "base.BaseActor._hidden_layers.extend", "models.mlp.build_mlp_network", "tensorflow.keras.layers.Dense", "models.cnn.build_cnn_network", "utils.normc_initializer"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER.__init__", "home.repos.pwc.inspect_result.mszulc913_acerac.models.mlp.build_mlp_network", "home.repos.pwc.inspect_result.mszulc913_acerac.models.cnn.build_cnn_network", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.utils.normc_initializer"], ["    ", "def", "__init__", "(", "\n", "self", ",", "observations_space", ":", "gym", ".", "Space", ",", "actions_space", ":", "gym", ".", "Space", ",", "layers", ":", "Optional", "[", "Tuple", "[", "int", "]", "]", ",", "\n", "beta_penalty", ":", "float", ",", "tf_time_step", ":", "tf", ".", "Variable", ",", "*", "args", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Abstract Actor.\n\n        Args:\n            observations_dim: Dimension of the observations space.\n            layers: List of hidden layers sizes, eg: for a neural network with two layers with 10 and 20 hidden units\n                pass [10, 20].\n            beta_penalty: Penalty coefficient. In the discrete case, actor is penalized for too\n                confident actions (no exploration), in the continuous case it is penalized for producing actions\n                that are out of the allowed boundaries.\n            tf_time_step: Time step as a TensorFlow variable, required for TensorBoard summaries.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "_hidden_layers", "=", "[", "]", "\n", "\n", "if", "type", "(", "actions_space", ")", "==", "gym", ".", "spaces", ".", "discrete", ".", "Discrete", ":", "\n", "            ", "actions_dim", "=", "actions_space", ".", "n", "\n", "", "else", ":", "\n", "            ", "actions_dim", "=", "actions_space", ".", "shape", "[", "0", "]", "\n", "\n", "", "if", "len", "(", "observations_space", ".", "shape", ")", ">", "1", ":", "\n", "            ", "self", ".", "_hidden_layers", ".", "extend", "(", "build_cnn_network", "(", ")", ")", "\n", "", "self", ".", "_hidden_layers", ".", "extend", "(", "build_mlp_network", "(", "layers_sizes", "=", "layers", ")", ")", "\n", "\n", "self", ".", "_hidden_layers", ".", "append", "(", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "actions_dim", ",", "kernel_initializer", "=", "utils", ".", "normc_initializer", "(", ")", ")", ")", "\n", "\n", "self", ".", "actions_dim", "=", "actions_dim", "\n", "self", ".", "beta_penalty", "=", "beta_penalty", "\n", "self", ".", "_tf_time_step", "=", "tf_time_step", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor._forward": [[59, 64], ["layer"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "observations", ":", "np", ".", "array", ")", "->", "tf", ".", "Tensor", ":", "\n", "        ", "x", "=", "self", ".", "_hidden_layers", "[", "0", "]", "(", "observations", ")", "\n", "for", "layer", "in", "self", ".", "_hidden_layers", "[", "1", ":", "]", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor.action_dtype": [[65, 69], ["None"], "methods", ["None"], ["", "@", "property", "\n", "@", "abstractmethod", "\n", "def", "action_dtype", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns data type of the actions (TensorFlow).\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor.action_dtype_np": [[70, 74], ["None"], "methods", ["None"], ["", "@", "property", "\n", "@", "abstractmethod", "\n", "def", "action_dtype_np", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns data type of the actions (Numpy).\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor.prob": [[75, 86], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "prob", "(", "self", ",", "observations", ":", "np", ".", "array", ",", "actions", ":", "np", ".", "array", ")", "->", "tf", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes probabilities (or probability densities in the continuous case) and log probabilities.\n\n        Args:\n            observations: Batch [batch_size, observations_dim] of observations.\n            actions: Batch [batch_size, actions_dim] of actions.\n\n        Returns:\n             Tensor [batch_size, actions_dim, 2] with computed probabilities (densities) and logarithms.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor.act": [[87, 99], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "act", "(", "self", ",", "observations", ":", "np", ".", "array", ",", "**", "kwargs", ")", "->", "Tuple", "[", "tf", ".", "Tensor", ",", "tf", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Samples actions and computes their probabilities (or probability densities in the continuous case).\n\n        Args:\n            observations: Batch [batch_size, observations_dim] of observations.\n\n        Returns:\n            Tuple with two Tensors:\n                * actions [batch_size, actions_dim],\n                * probabilities/densities [batch_size, 1].\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor.act_deterministic": [[100, 110], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "act_deterministic", "(", "self", ",", "observations", ":", "np", ".", "array", ",", "**", "kwargs", ")", "->", "tf", ".", "Tensor", ":", "\n", "        ", "\"\"\"Samples actions without exploration noise.\n\n        Args:\n            observations: Batch [batch_size, observations_dim] of observations.\n\n        Returns:\n            Tensor with actions [batch_size, actions_dim].\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseCritic.__init__": [[113, 133], ["super().__init__", "base.BaseCritic._hidden_layers.extend", "tensorflow.keras.layers.Dense", "len", "base.BaseCritic._hidden_layers.extend", "models.mlp.build_mlp_network", "models.cnn.build_cnn_network", "utils.normc_initializer"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER.__init__", "home.repos.pwc.inspect_result.mszulc913_acerac.models.mlp.build_mlp_network", "home.repos.pwc.inspect_result.mszulc913_acerac.models.cnn.build_cnn_network", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.utils.normc_initializer"], ["    ", "def", "__init__", "(", "\n", "self", ",", "observations_space", ":", "gym", ".", "Space", ",", "layers", ":", "Optional", "[", "Tuple", "[", "int", "]", "]", ",", "\n", "tf_time_step", ":", "tf", ".", "Variable", ",", "*", "args", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Abstract Critic.\n\n        Args:\n            observations_dim: Dimension of the observations space.\n            layers: List of hidden layers sizes, eg: for a neural network with two layers with 10 and 20 hidden units\n                pass [10, 20].\n            tf_time_step: Time step as TensorFlow variable, required for TensorBoard summaries.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_hidden_layers", "=", "[", "]", "\n", "if", "len", "(", "observations_space", ".", "shape", ")", ">", "1", ":", "\n", "            ", "self", ".", "_hidden_layers", ".", "extend", "(", "build_cnn_network", "(", ")", ")", "\n", "\n", "", "self", ".", "_hidden_layers", ".", "extend", "(", "build_mlp_network", "(", "layers_sizes", "=", "layers", ")", ")", "\n", "self", ".", "_v", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "1", ",", "kernel_initializer", "=", "utils", ".", "normc_initializer", "(", ")", ")", "\n", "self", ".", "_tf_time_step", "=", "tf_time_step", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseCritic.call": [[134, 136], ["base.BaseCritic.value"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseCritic.value"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "None", ",", "mask", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "value", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseCritic.value": [[137, 153], ["base.BaseCritic._v", "layer"], "methods", ["None"], ["", "def", "value", "(", "self", ",", "observations", ":", "tf", ".", "Tensor", ",", "**", "kwargs", ")", "->", "tf", ".", "Tensor", ":", "\n", "        ", "\"\"\"Calculates value function for given observations.\n\n        Args:\n            observations: Batch [batch_size, observations_dim] of observations.\n\n        Returns:\n            Tensor [batch_size, 1] with value function estimations.\n        \"\"\"", "\n", "x", "=", "self", ".", "_hidden_layers", "[", "0", "]", "(", "observations", ")", "\n", "for", "layer", "in", "self", ".", "_hidden_layers", "[", "1", ":", "]", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "\n", "", "value", "=", "self", ".", "_v", "(", "x", ")", "\n", "\n", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.Critic.__init__": [[157, 163], ["base.BaseCritic.__init__"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "observations_space", ":", "gym", ".", "Space", ",", "layers", ":", "Optional", "[", "Tuple", "[", "int", "]", "]", ",", "\n", "tf_time_step", ":", "tf", ".", "Variable", ",", "*", "args", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Critic that outputs single value.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "observations_space", ",", "layers", ",", "tf_time_step", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.Critic.loss": [[164, 180], ["base.Critic.value", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.math.multiply", "tensorflow.reduce_mean"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseCritic.value"], ["", "def", "loss", "(", "self", ",", "observations", ":", "np", ".", "array", ",", "d", ":", "np", ".", "array", ")", "->", "tf", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes Critic's loss.\n\n        Args:\n            observations: Batch [batch_size, observations_dim] of observations.\n            d: Batch [batch_size, 1] of gradient update coefficient (summation term in the Equation (9)) from\n                the paper (1)).\n        \"\"\"", "\n", "\n", "value", "=", "self", ".", "value", "(", "observations", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "math", ".", "multiply", "(", "value", ",", "d", ")", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'critic'", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "'batch_value_mean'", ",", "tf", ".", "reduce_mean", "(", "value", ")", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'batch_loss'", ",", "loss", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.CategoricalActor.__init__": [[185, 189], ["base.BaseActor.__init__"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER.__init__"], ["    ", "def", "__init__", "(", "self", ",", "observations_space", ":", "gym", ".", "Space", ",", "actions_space", ":", "gym", ".", "Space", ",", "layers", ":", "Optional", "[", "Tuple", "[", "int", "]", "]", ",", "\n", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Actor for discrete actions spaces. Uses Categorical Distribution to sample actions.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "observations_space", ",", "actions_space", ",", "layers", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.CategoricalActor.action_dtype": [[190, 193], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_dtype", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "dtypes", ".", "int32", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.CategoricalActor.action_dtype_np": [[194, 197], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_dtype_np", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "int32", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.CategoricalActor.loss": [[198, 225], ["base.CategoricalActor._forward", "tensorflow.divide", "tensorflow.nn.log_softmax", "tensorflow.expand_dims", "tensorflow_probability.distributions.Categorical", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.gather_nd", "tensorflow.scalar_mul", "tensorflow.name_scope", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.square", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.maximum", "tensorflow.math.multiply", "tensorflow_probability.distributions.Categorical.entropy", "tensorflow.abs"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor._forward"], ["", "def", "loss", "(", "self", ",", "observations", ":", "tf", ".", "Tensor", ",", "actions", ":", "tf", ".", "Tensor", ",", "d", ":", "tf", ".", "Tensor", ")", "->", "tf", ".", "Tensor", ":", "\n", "        ", "logits", "=", "self", ".", "_forward", "(", "observations", ")", "\n", "\n", "logits_div", "=", "tf", ".", "divide", "(", "logits", ",", "10", ")", "\n", "log_probs", "=", "tf", ".", "nn", ".", "log_softmax", "(", "logits_div", ")", "\n", "action_log_probs", "=", "tf", ".", "expand_dims", "(", "\n", "tf", ".", "gather_nd", "(", "log_probs", ",", "actions", ",", "batch_dims", "=", "1", ")", ",", "\n", "axis", "=", "1", "\n", ")", "\n", "dist", "=", "tfp", ".", "distributions", ".", "Categorical", "(", "logits_div", ")", "\n", "\n", "penalty", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "scalar_mul", "(", "\n", "self", ".", "beta_penalty", ",", "\n", "tf", ".", "square", "(", "tf", ".", "maximum", "(", "0.0", ",", "tf", ".", "abs", "(", "logits", ")", "-", "20", ")", ")", "\n", ")", ",", "\n", "axis", "=", "1", ",", "\n", "keepdims", "=", "True", "\n", ")", "\n", "total_loss", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "math", ".", "multiply", "(", "action_log_probs", ",", "d", ")", "+", "penalty", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'actor'", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "'batch_entropy_mean'", ",", "tf", ".", "reduce_mean", "(", "dist", ".", "entropy", "(", ")", ")", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'batch_loss'", ",", "total_loss", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'batch_penalty_mean'", ",", "tf", ".", "reduce_mean", "(", "penalty", ")", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "\n", "", "return", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.CategoricalActor.prob": [[226, 233], ["tensorflow.divide", "tensorflow.nn.softmax", "tensorflow.nn.log_softmax", "tensorflow.gather_nd", "tensorflow.gather_nd", "base.CategoricalActor._forward"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor._forward"], ["", "def", "prob", "(", "self", ",", "observations", ":", "tf", ".", "Tensor", ",", "actions", ":", "tf", ".", "Tensor", ")", "->", "Tuple", "[", "tf", ".", "Tensor", ",", "tf", ".", "Tensor", "]", ":", "\n", "        ", "logits", "=", "tf", ".", "divide", "(", "self", ".", "_forward", "(", "observations", ")", ",", "10", ")", "\n", "probs", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "log_probs", "=", "tf", ".", "nn", ".", "log_softmax", "(", "logits", ")", "\n", "action_probs", "=", "tf", ".", "gather_nd", "(", "probs", ",", "actions", ",", "batch_dims", "=", "1", ")", "\n", "action_log_probs", "=", "tf", ".", "gather_nd", "(", "log_probs", ",", "actions", ",", "batch_dims", "=", "1", ")", "\n", "return", "action_probs", ",", "action_log_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.CategoricalActor.act": [[234, 247], ["tensorflow.divide", "tensorflow.nn.softmax", "tensorflow.nn.log_softmax", "tensorflow.random.categorical", "tensorflow.gather_nd", "base.CategoricalActor._forward", "tensorflow.name_scope", "tensorflow.summary.histogram", "tensorflow.squeeze"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor._forward"], ["", "@", "tf", ".", "function", "\n", "def", "act", "(", "self", ",", "observations", ":", "tf", ".", "Tensor", ",", "**", "kwargs", ")", "->", "Tuple", "[", "tf", ".", "Tensor", ",", "tf", ".", "Tensor", "]", ":", "\n", "\n", "        ", "logits", "=", "tf", ".", "divide", "(", "self", ".", "_forward", "(", "observations", ")", ",", "10", ")", "\n", "probs", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "log_probs", "=", "tf", ".", "nn", ".", "log_softmax", "(", "logits", ")", "\n", "\n", "actions", "=", "tf", ".", "random", ".", "categorical", "(", "log_probs", ",", "num_samples", "=", "1", ",", "dtype", "=", "tf", ".", "dtypes", ".", "int32", ")", "\n", "actions_probs", "=", "tf", ".", "gather_nd", "(", "probs", ",", "actions", ",", "batch_dims", "=", "1", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'actor'", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "histogram", "(", "'action'", ",", "actions", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "", "return", "tf", ".", "squeeze", "(", "actions", ",", "axis", "=", "[", "1", "]", ")", ",", "actions_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.CategoricalActor.act_deterministic": [[248, 256], ["tensorflow.divide", "tensorflow.nn.softmax", "tensorflow.argmax", "base.CategoricalActor._forward"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor._forward"], ["", "@", "tf", ".", "function", "\n", "def", "act_deterministic", "(", "self", ",", "observations", ":", "tf", ".", "Tensor", ",", "**", "kwargs", ")", "->", "tf", ".", "Tensor", ":", "\n", "        ", "\"\"\"Produces most probable action\"\"\"", "\n", "logits", "=", "tf", ".", "divide", "(", "self", ".", "_forward", "(", "observations", ")", ",", "10", ")", "\n", "probs", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "\n", "actions", "=", "tf", ".", "argmax", "(", "probs", ",", "axis", "=", "1", ")", "\n", "return", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.GaussianActor.__init__": [[260, 285], ["base.BaseActor.__init__", "tensorflow.constant", "tensorflow.constant", "tensorflow.math.log", "tensorflow.math.log"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "observations_space", ":", "gym", ".", "Space", ",", "actions_space", ":", "gym", ".", "Space", ",", "layers", ":", "Optional", "[", "Tuple", "[", "int", "]", "]", ",", "\n", "beta_penalty", ":", "float", ",", "actions_bound", ":", "float", ",", "std", ":", "float", "=", "None", ",", "*", "args", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Actor for continuous actions space. Uses MultiVariate Gaussian Distribution as policy distribution.\n\n        Args:\n            observations_dim: Dimension of the observations space.\n            layers: List of hidden layer sizes.\n            beta_penalty: Penalty for too confident actions coefficient.\n            actions_bound: Upper (lower == '-actions_bound') bound of allowed actions.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "observations_space", ",", "actions_space", ",", "layers", ",", "beta_penalty", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "_actions_bound", "=", "actions_bound", "\n", "\n", "if", "std", ":", "\n", "            ", "self", ".", "log_std", "=", "tf", ".", "constant", "(", "\n", "tf", ".", "math", ".", "log", "(", "[", "std", "]", "*", "actions_space", ".", "shape", "[", "0", "]", ")", ",", "\n", "name", "=", "\"actor_std\"", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "log_std", "=", "tf", ".", "constant", "(", "\n", "tf", ".", "math", ".", "log", "(", "0.4", "*", "actions_bound", ")", ",", "\n", "name", "=", "\"actor_std\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.GaussianActor.action_dtype": [[287, 290], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "action_dtype", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "dtypes", ".", "float32", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.GaussianActor.action_dtype_np": [[291, 294], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_dtype_np", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "float32", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.GaussianActor.loss": [[295, 324], ["base.GaussianActor._forward", "tensorflow_probability.distributions.MultivariateNormalDiag", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow_probability.distributions.MultivariateNormalDiag.entropy", "tensorflow.reduce_mean", "tensorflow_probability.distributions.MultivariateNormalDiag.log_prob", "tensorflow.scalar_mul", "tensorflow.name_scope", "range", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.exp", "tensorflow.square", "tensorflow.summary.scalar", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.maximum", "tensorflow.math.multiply", "tensorflow.exp", "tensorflow.abs"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor._forward"], ["", "def", "loss", "(", "self", ",", "observations", ":", "np", ".", "array", ",", "actions", ":", "np", ".", "array", ",", "d", ":", "np", ".", "array", ")", "->", "tf", ".", "Tensor", ":", "\n", "        ", "mean", "=", "self", ".", "_forward", "(", "observations", ")", "\n", "dist", "=", "tfp", ".", "distributions", ".", "MultivariateNormalDiag", "(", "\n", "loc", "=", "mean", ",", "\n", "scale_diag", "=", "tf", ".", "exp", "(", "self", ".", "log_std", ")", "\n", ")", "\n", "\n", "action_log_probs", "=", "tf", ".", "expand_dims", "(", "dist", ".", "log_prob", "(", "actions", ")", ",", "axis", "=", "1", ")", "\n", "\n", "bounds_penalty", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "scalar_mul", "(", "\n", "self", ".", "beta_penalty", ",", "\n", "tf", ".", "square", "(", "tf", ".", "maximum", "(", "0.0", ",", "tf", ".", "abs", "(", "mean", ")", "-", "self", ".", "_actions_bound", ")", ")", "\n", ")", ",", "\n", "axis", "=", "1", ",", "\n", "keepdims", "=", "True", "\n", ")", "\n", "entropy", "=", "dist", ".", "entropy", "(", ")", "\n", "\n", "total_loss", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "math", ".", "multiply", "(", "action_log_probs", ",", "d", ")", "+", "bounds_penalty", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'actor'", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "actions_dim", ")", ":", "\n", "                ", "tf", ".", "summary", ".", "scalar", "(", "f'std_{i}'", ",", "tf", ".", "exp", "(", "self", ".", "log_std", "[", "i", "]", ")", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "'batch_loss'", ",", "total_loss", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'batch_bounds_penalty_mean'", ",", "tf", ".", "reduce_mean", "(", "bounds_penalty", ")", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'batch_entropy_mean'", ",", "tf", ".", "reduce_mean", "(", "entropy", ")", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "\n", "", "return", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.GaussianActor.prob": [[325, 333], ["base.GaussianActor._forward", "tensorflow_probability.distributions.MultivariateNormalDiag", "tensorflow_probability.distributions.MultivariateNormalDiag.prob", "tensorflow_probability.distributions.MultivariateNormalDiag.log_prob", "tensorflow.exp"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor._forward", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.NoiseGaussianActor.prob"], ["", "def", "prob", "(", "self", ",", "observations", ":", "tf", ".", "Tensor", ",", "actions", ":", "tf", ".", "Tensor", ")", "->", "Tuple", "[", "tf", ".", "Tensor", ",", "tf", ".", "Tensor", "]", ":", "\n", "        ", "mean", "=", "self", ".", "_forward", "(", "observations", ")", "\n", "dist", "=", "tfp", ".", "distributions", ".", "MultivariateNormalDiag", "(", "\n", "loc", "=", "mean", ",", "\n", "scale_diag", "=", "tf", ".", "exp", "(", "self", ".", "log_std", ")", "\n", ")", "\n", "\n", "return", "dist", ".", "prob", "(", "actions", ")", ",", "dist", ".", "log_prob", "(", "actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.GaussianActor.act": [[334, 350], ["base.GaussianActor._forward", "tensorflow_probability.distributions.MultivariateNormalDiag", "tensorflow_probability.distributions.MultivariateNormalDiag.sample", "tensorflow_probability.distributions.MultivariateNormalDiag.prob", "tensorflow.name_scope", "tensorflow.summary.scalar", "tensorflow.exp", "tensorflow.reduce_mean"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor._forward", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.NoiseGaussianActor.prob"], ["", "@", "tf", ".", "function", "\n", "def", "act", "(", "self", ",", "observations", ":", "tf", ".", "Tensor", ",", "**", "kwargs", ")", "->", "Tuple", "[", "tf", ".", "Tensor", ",", "tf", ".", "Tensor", "]", ":", "\n", "        ", "mean", "=", "self", ".", "_forward", "(", "observations", ")", "\n", "\n", "dist", "=", "tfp", ".", "distributions", ".", "MultivariateNormalDiag", "(", "\n", "loc", "=", "mean", ",", "\n", "scale_diag", "=", "tf", ".", "exp", "(", "self", ".", "log_std", ")", "\n", ")", "\n", "\n", "actions", "=", "dist", ".", "sample", "(", "dtype", "=", "self", ".", "dtype", ")", "\n", "actions_probs", "=", "dist", ".", "prob", "(", "actions", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'actor'", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "f'batch_action_mean'", ",", "tf", ".", "reduce_mean", "(", "actions", ")", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "\n", "", "return", "actions", ",", "actions_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.GaussianActor.act_deterministic": [[351, 356], ["base.GaussianActor._forward"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor._forward"], ["", "@", "tf", ".", "function", "\n", "def", "act_deterministic", "(", "self", ",", "observations", ":", "tf", ".", "Tensor", ",", "**", "kwargs", ")", "->", "tf", ".", "Tensor", ":", "\n", "        ", "\"\"\"Returns mean of the Gaussian distribution.\"\"\"", "\n", "mean", "=", "self", ".", "_forward", "(", "observations", ")", "\n", "return", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseACERAgent.__init__": [[359, 418], ["tensorflow.Variable", "tuple", "tuple", "tensorflow.Variable", "tensorflow.Variable", "base.BaseACERAgent._init_actor", "base.BaseACERAgent._init_critic", "base.BaseACERAgent._init_replay_buffer", "tensorflow.data.Dataset.from_generator().prefetch", "tensorflow.keras.optimizers.Adam", "tensorflow.keras.optimizers.Adam", "type", "tensorflow.data.Dataset.from_generator"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER._init_actor", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER._init_critic", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC._init_replay_buffer"], ["    ", "def", "__init__", "(", "\n", "self", ",", "observations_space", ":", "gym", ".", "Space", ",", "actions_space", ":", "gym", ".", "Space", ",", "actor_layers", ":", "Optional", "[", "Tuple", "[", "int", "]", "]", ",", "\n", "critic_layers", ":", "Tuple", "[", "int", "]", ",", "gamma", ":", "int", "=", "0.99", ",", "actor_beta_penalty", ":", "float", "=", "0.001", ",", "\n", "std", ":", "Optional", "[", "float", "]", "=", "None", ",", "memory_size", ":", "int", "=", "1e6", ",", "num_parallel_envs", ":", "int", "=", "1", ",", "\n", "batches_per_env", ":", "int", "=", "256", ",", "c", ":", "int", "=", "1", ",", "learning_starts", ":", "int", "=", "1000", ",", "actor_lr", ":", "float", "=", "1e-5", ",", "\n", "actor_adam_beta1", ":", "float", "=", "0.9", ",", "actor_adam_beta2", ":", "float", "=", "0.999", ",", "actor_adam_epsilon", ":", "float", "=", "1e-7", ",", "\n", "critic_lr", ":", "float", "=", "1e-5", ",", "critic_adam_beta1", ":", "float", "=", "0.9", ",", "critic_adam_beta2", ":", "float", "=", "0.999", ",", "\n", "critic_adam_epsilon", ":", "float", "=", "1e-7", ",", "time_step", ":", "int", "=", "1", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Abstract Actor-Critic with Experience Replay.\"\"\"", "\n", "\n", "self", ".", "_tf_time_step", "=", "tf", ".", "Variable", "(", "\n", "initial_value", "=", "time_step", ",", "name", "=", "'tf_time_step'", ",", "dtype", "=", "tf", ".", "dtypes", ".", "int64", ",", "trainable", "=", "False", "\n", ")", "\n", "self", ".", "_observations_space", "=", "observations_space", "\n", "self", ".", "_actions_space", "=", "actions_space", "\n", "self", ".", "_std", "=", "std", "\n", "self", ".", "_actor_beta_penalty", "=", "actor_beta_penalty", "\n", "self", ".", "_c", "=", "c", "\n", "self", ".", "_learning_starts", "=", "learning_starts", "\n", "self", ".", "_actor_layers", "=", "tuple", "(", "actor_layers", ")", "\n", "self", ".", "_critic_layers", "=", "tuple", "(", "critic_layers", ")", "\n", "self", ".", "_gamma", "=", "gamma", "\n", "self", ".", "_batches_per_env", "=", "batches_per_env", "\n", "self", ".", "_time_step", "=", "0", "\n", "self", ".", "_num_parallel_envs", "=", "num_parallel_envs", "\n", "\n", "self", ".", "_actor_gradient_norm_median", "=", "tf", ".", "Variable", "(", "initial_value", "=", "1.0", ",", "trainable", "=", "False", ")", "\n", "self", ".", "_critic_gradient_norm_median", "=", "tf", ".", "Variable", "(", "initial_value", "=", "1.0", ",", "trainable", "=", "False", ")", "\n", "\n", "if", "type", "(", "actions_space", ")", "==", "gym", ".", "spaces", ".", "Discrete", ":", "\n", "            ", "self", ".", "_is_discrete", "=", "True", "\n", "self", ".", "_actions_bound", "=", "0", "\n", "", "else", ":", "\n", "            ", "self", ".", "_is_discrete", "=", "False", "\n", "self", ".", "_actions_bound", "=", "actions_space", ".", "high", "\n", "\n", "", "self", ".", "_actor", "=", "self", ".", "_init_actor", "(", ")", "\n", "self", ".", "_critic", "=", "self", ".", "_init_critic", "(", ")", "\n", "\n", "self", ".", "_init_replay_buffer", "(", "memory_size", ")", "\n", "self", ".", "_data_loader", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "\n", "self", ".", "_experience_replay_generator", ",", "\n", "(", "tf", ".", "dtypes", ".", "float32", ",", "tf", ".", "dtypes", ".", "float32", ",", "self", ".", "_actor", ".", "action_dtype", ",", "tf", ".", "dtypes", ".", "float32", ",", "tf", ".", "dtypes", ".", "float32", ",", "\n", "tf", ".", "dtypes", ".", "float32", ",", "self", ".", "_actor", ".", "action_dtype", ",", "tf", ".", "dtypes", ".", "bool", ",", "tf", ".", "dtypes", ".", "int32", ")", "\n", ")", ".", "prefetch", "(", "2", ")", "\n", "\n", "self", ".", "_actor_optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "\n", "lr", "=", "actor_lr", ",", "\n", "beta_1", "=", "actor_adam_beta1", ",", "\n", "beta_2", "=", "actor_adam_beta2", ",", "\n", "epsilon", "=", "actor_adam_epsilon", "\n", ")", "\n", "\n", "self", ".", "_critic_optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "\n", "lr", "=", "critic_lr", ",", "\n", "beta_1", "=", "critic_adam_beta1", ",", "\n", "beta_2", "=", "critic_adam_beta2", ",", "\n", "epsilon", "=", "critic_adam_epsilon", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseACERAgent._init_replay_buffer": [[420, 431], ["replay_buffer.MultiReplayBuffer", "type", "replay_buffer.BufferFieldSpec", "replay_buffer.BufferFieldSpec"], "methods", ["None"], ["", "def", "_init_replay_buffer", "(", "self", ",", "memory_size", ":", "int", ")", ":", "\n", "        ", "if", "type", "(", "self", ".", "_actions_space", ")", "==", "gym", ".", "spaces", ".", "Discrete", ":", "\n", "            ", "actions_shape", "=", "(", "1", ",", ")", "\n", "", "else", ":", "\n", "            ", "actions_shape", "=", "self", ".", "_actions_space", ".", "shape", "\n", "\n", "", "self", ".", "_memory", "=", "MultiReplayBuffer", "(", "\n", "action_spec", "=", "BufferFieldSpec", "(", "shape", "=", "actions_shape", ",", "dtype", "=", "self", ".", "_actor", ".", "action_dtype_np", ")", ",", "\n", "obs_spec", "=", "BufferFieldSpec", "(", "shape", "=", "self", ".", "_observations_space", ".", "shape", ",", "dtype", "=", "self", ".", "_observations_space", ".", "dtype", ")", ",", "\n", "max_size", "=", "memory_size", ",", "\n", "num_buffers", "=", "self", ".", "_num_parallel_envs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseACERAgent.save_experience": [[433, 444], ["len", "base.BaseACERAgent._tf_time_step.assign_add", "base.BaseACERAgent._memory.put", "len"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.MultiReplayBuffer.put"], ["", "def", "save_experience", "(", "\n", "self", ",", "steps", ":", "List", "[", "Tuple", "[", "Union", "[", "int", ",", "float", ",", "list", "]", ",", "np", ".", "array", ",", "float", ",", "np", ".", "array", ",", "bool", ",", "bool", "]", "]", "\n", ")", ":", "\n", "        ", "\"\"\"Stores gathered experiences in a replay buffer. Accepts list of steps.\n\n        Args:\n            steps: List of steps, see ReplayBuffer.put() for a detailed format description.\n        \"\"\"", "\n", "self", ".", "_time_step", "+=", "len", "(", "steps", ")", "\n", "self", ".", "_tf_time_step", ".", "assign_add", "(", "len", "(", "steps", ")", ")", "\n", "self", ".", "_memory", ".", "put", "(", "steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseACERAgent.predict_action": [[445, 464], ["tensorflow.convert_to_tensor", "base.BaseACERAgent._actor.act", "base.BaseACERAgent._actor.act_deterministic().numpy", "actions.numpy", "policies.numpy", "base.BaseACERAgent._actor.act_deterministic"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.NoiseGaussianActor.act", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.GaussianActor.act_deterministic"], ["", "def", "predict_action", "(", "\n", "self", ",", "observations", ":", "np", ".", "array", ",", "is_deterministic", ":", "bool", "=", "False", "\n", ")", "->", "Tuple", "[", "np", ".", "array", ",", "Optional", "[", "np", ".", "array", "]", "]", ":", "\n", "        ", "\"\"\"Predicts actions for given observations. Performs forward pass with BaseActor network.\n\n        Args:\n            observations: Batch [batch_size, observations_dim] of observations vectors.\n            is_deterministic: True if actions without exploration noise should be returned.\n\n        Returns:\n            Tuple of sampled actions and corresponding probabilities (probability densities) if action was sampled\n                from the distribution, None otherwise.\n        \"\"\"", "\n", "tf_obs", "=", "tf", ".", "convert_to_tensor", "(", "observations", ")", "\n", "if", "is_deterministic", ":", "\n", "            ", "return", "self", ".", "_actor", ".", "act_deterministic", "(", "tf_obs", ")", ".", "numpy", "(", ")", ",", "None", "\n", "", "else", ":", "\n", "            ", "actions", ",", "policies", "=", "self", ".", "_actor", ".", "act", "(", "tf_obs", ")", "\n", "return", "actions", ".", "numpy", "(", ")", ",", "policies", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseACERAgent._experience_replay_generator": [[465, 487], ["base.BaseACERAgent._fetch_offline_batch", "utils.flatten_experience", "len"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER._fetch_offline_batch", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.utils.flatten_experience"], ["", "", "def", "_experience_replay_generator", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "offline_batch", "=", "self", ".", "_fetch_offline_batch", "(", ")", "\n", "\n", "obs_flatten", ",", "obs_next_flatten", ",", "actions_flatten", ",", "policies_flatten", ",", "rewards_flatten", ",", "dones_flatten", "=", "utils", ".", "flatten_experience", "(", "offline_batch", ")", "\n", "\n", "lengths", "=", "[", "len", "(", "batch", "[", "0", "]", "[", "'observations'", "]", ")", "for", "batch", "in", "offline_batch", "]", "\n", "\n", "first_obs", "=", "[", "batch", "[", "0", "]", "[", "'observations'", "]", "[", "0", "]", "for", "batch", "in", "offline_batch", "]", "\n", "first_actions", "=", "[", "batch", "[", "0", "]", "[", "'actions'", "]", "[", "0", "]", "for", "batch", "in", "offline_batch", "]", "\n", "\n", "yield", "(", "\n", "obs_flatten", ",", "\n", "obs_next_flatten", ",", "\n", "actions_flatten", ",", "\n", "policies_flatten", ",", "\n", "rewards_flatten", ",", "\n", "first_obs", ",", "\n", "first_actions", ",", "\n", "dones_flatten", ",", "\n", "lengths", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseACERAgent._fetch_offline_batch": [[489, 492], ["None"], "methods", ["None"], ["", "", "@", "abstractmethod", "\n", "def", "_fetch_offline_batch", "(", "self", ")", "->", "List", "[", "Tuple", "[", "Dict", "[", "str", ",", "Union", "[", "np", ".", "array", ",", "list", "]", "]", ",", "int", "]", "]", ":", "\n", "        ", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseACERAgent.learn": [[493, 496], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "learn", "(", "self", ")", ":", "\n", "        ", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseACERAgent._init_actor": [[497, 500], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_init_actor", "(", "self", ")", "->", "BaseActor", ":", "\n", "        ", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseACERAgent._init_critic": [[501, 504], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_init_critic", "(", "self", ")", "->", "BaseCritic", ":", "\n", "        ", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseACERAgent.save": [[505, 514], ["str", "str", "str", "base.BaseACERAgent._actor.save_weights", "base.BaseACERAgent._critic.save_weights", "base.BaseACERAgent._memory.save"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseACERAgent.save"], ["", "def", "save", "(", "self", ",", "path", ":", "Path", ",", "**", "kwargs", ")", ":", "\n", "        ", "actor_path", "=", "str", "(", "path", "/", "'actor.tf'", ")", "\n", "critic_path", "=", "str", "(", "path", "/", "'critic.tf'", ")", "\n", "buffer_path", "=", "str", "(", "path", "/", "'buffer.pkl'", ")", "\n", "\n", "self", ".", "_actor", ".", "save_weights", "(", "actor_path", ",", "overwrite", "=", "True", ")", "\n", "self", ".", "_critic", ".", "save_weights", "(", "critic_path", ",", "overwrite", "=", "True", ")", "\n", "\n", "self", ".", "_memory", ".", "save", "(", "buffer_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.NoiseGaussianActor.__init__": [[57, 72], ["algos.base.GaussianActor.__init__", "tensorflow_probability.distributions.MultivariateNormalDiag", "acerac.NoiseGaussianActor._sample_noise", "tensorflow.ones", "tensorflow.exp"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER.__init__", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.NoiseGaussianActor._sample_noise"], ["def", "__init__", "(", "\n", "self", ",", "observations_space", ":", "gym", ".", "Space", ",", "actions_space", ":", "gym", ".", "Space", ",", "layers", ":", "Optional", "[", "Tuple", "[", "int", "]", "]", ",", "\n", "beta_penalty", ":", "float", ",", "actions_bound", ":", "float", ",", "tau", ":", "int", "=", "2", ",", "alpha", ":", "float", "=", "0.8", ",", "\n", "num_parallel_envs", ":", "int", "=", "1", ",", "*", "args", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "observations_space", ",", "actions_space", ",", "layers", ",", "beta_penalty", ",", "actions_bound", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "_num_parallel_envs", "=", "num_parallel_envs", "\n", "self", ".", "_tau", "=", "tau", "\n", "self", ".", "_alpha", "=", "alpha", "\n", "self", ".", "_noise_dist", "=", "tfp", ".", "distributions", ".", "MultivariateNormalDiag", "(", "\n", "scale_diag", "=", "tf", ".", "exp", "(", "self", ".", "log_std", ")", ",", "\n", ")", "\n", "self", ".", "_last_noise", "=", "self", ".", "_sample_noise", "(", ")", "\n", "self", ".", "_noise_init_mask", "=", "tf", ".", "ones", "(", "shape", "=", "(", "self", ".", "_num_parallel_envs", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.NoiseGaussianActor._init_noise_buffer": [[73, 78], ["collections.deque", "range", "collections.deque.append", "acerac.NoiseGaussianActor._noise_dist.sample"], "methods", ["None"], ["", "def", "_init_noise_buffer", "(", "self", ")", ":", "\n", "        ", "buffer", "=", "deque", "(", "maxlen", "=", "self", ".", "_tau", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "_tau", ")", ":", "\n", "            ", "buffer", ".", "append", "(", "self", ".", "_noise_dist", ".", "sample", "(", ")", ")", "\n", "", "return", "buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.NoiseGaussianActor._sample_noise": [[79, 81], ["acerac.NoiseGaussianActor._noise_dist.sample"], "methods", ["None"], ["", "def", "_sample_noise", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_noise_dist", ".", "sample", "(", "sample_shape", "=", "(", "self", ".", "_num_parallel_envs", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.NoiseGaussianActor.update_ends": [[82, 85], ["tensorflow.cast"], "methods", ["None"], ["", "def", "update_ends", "(", "self", ",", "ends", ":", "np", ".", "array", ")", ":", "\n", "        ", "\"\"\"Updates noise buffers at the end of an episode.\"\"\"", "\n", "self", ".", "_noise_init_mask", "=", "tf", ".", "cast", "(", "ends", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.NoiseGaussianActor.prob": [[86, 93], ["acerac.NoiseGaussianActor._forward", "tensorflow_probability.distributions.MultivariateNormalDiag", "tensorflow_probability.distributions.MultivariateNormalDiag.prob", "tensorflow_probability.distributions.MultivariateNormalDiag.log_prob", "tensorflow.exp"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor._forward", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.NoiseGaussianActor.prob"], ["", "def", "prob", "(", "self", ",", "observations", ":", "tf", ".", "Tensor", ",", "actions", ":", "tf", ".", "Tensor", ")", "->", "Tuple", "[", "tf", ".", "Tensor", ",", "tf", ".", "Tensor", "]", ":", "\n", "        ", "mean", "=", "self", ".", "_forward", "(", "observations", ")", "\n", "dist", "=", "tfp", ".", "distributions", ".", "MultivariateNormalDiag", "(", "\n", "scale_diag", "=", "tf", ".", "exp", "(", "self", ".", "log_std", ")", "\n", ")", "\n", "\n", "return", "dist", ".", "prob", "(", "actions", "-", "mean", ")", ",", "dist", ".", "log_prob", "(", "actions", "-", "mean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.NoiseGaussianActor.act": [[94, 106], ["acerac.NoiseGaussianActor._forward", "acerac.NoiseGaussianActor._sample_noise", "tensorflow.zeros_like", "tensorflow.sqrt", "tensorflow.square"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseActor._forward", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.NoiseGaussianActor._sample_noise"], ["", "@", "tf", ".", "function", "\n", "def", "act", "(", "self", ",", "observations", ":", "tf", ".", "Tensor", ",", "**", "kwargs", ")", "->", "Tuple", "[", "tf", ".", "Tensor", ",", "tf", ".", "Tensor", "]", ":", "\n", "        ", "mean", "=", "self", ".", "_forward", "(", "observations", ")", "\n", "\n", "noise_init", "=", "self", ".", "_sample_noise", "(", ")", "\n", "noise_cont", "=", "self", ".", "_alpha", "*", "self", ".", "_last_noise", "+", "tf", ".", "sqrt", "(", "1", "-", "tf", ".", "square", "(", "self", ".", "_alpha", ")", ")", "*", "noise_init", "\n", "noise", "=", "noise_init", "*", "self", ".", "_noise_init_mask", "+", "noise_cont", "*", "(", "1", "-", "self", ".", "_noise_init_mask", ")", "\n", "self", ".", "_last_noise", "=", "noise", "\n", "self", ".", "_noise_init_mask", "=", "tf", ".", "zeros_like", "(", "self", ".", "_noise_init_mask", ")", "\n", "\n", "actions", "=", "mean", "+", "noise", "\n", "return", "actions", ",", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC.__init__": [[109, 141], ["algos.base.BaseACERAgent.__init__", "tensorflow.linalg.diag", "acerac.ACERAC._init_inverse_covariance_matrices", "tensorflow.data.Dataset.from_generator().prefetch", "tensorflow.square", "tensorflow.exp", "tensorflow.data.Dataset.from_generator"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER.__init__", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC._init_inverse_covariance_matrices"], ["    ", "def", "__init__", "(", "\n", "self", ",", "observations_space", ":", "gym", ".", "Space", ",", "actions_space", ":", "gym", ".", "Space", ",", "actor_layers", ":", "Optional", "[", "Tuple", "[", "int", "]", "]", ",", "\n", "critic_layers", ":", "Optional", "[", "Tuple", "[", "int", "]", "]", ",", "b", ":", "float", "=", "3", ",", "tau", ":", "int", "=", "2", ",", "alpha", ":", "int", "=", "None", ",", "*", "args", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Actor-Critic with Experience Replay and Autocorrelated Cctions.\n\n        Args:\n            observations_space: Observations' vectors Space.\n            actions_space: Actions' vectors Space.\n            actor_layers: Number of units in Actor's hidden layers.\n            critic_layers: Number of units in Critic's hidden layers.\n            b: Density ratio truncating coefficient.\n            tau: Update window size.\n            alpha: Autocorrelation degree.\n        \"\"\"", "\n", "\n", "self", ".", "_tau", "=", "tau", "\n", "self", ".", "_alpha", "=", "alpha", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "observations_space", ",", "actions_space", ",", "actor_layers", ",", "critic_layers", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_b", "=", "b", "\n", "\n", "self", ".", "_cov_matrix", "=", "tf", ".", "linalg", ".", "diag", "(", "tf", ".", "square", "(", "tf", ".", "exp", "(", "self", ".", "_actor", ".", "log_std", ")", ")", ")", "\n", "\n", "self", ".", "_init_inverse_covariance_matrices", "(", ")", "\n", "\n", "self", ".", "_data_loader", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "\n", "self", ".", "_experience_replay_generator", ",", "\n", "(", "tf", ".", "dtypes", ".", "float32", ",", "tf", ".", "dtypes", ".", "float32", ",", "self", ".", "_actor", ".", "action_dtype", ",", "self", ".", "_actor", ".", "action_dtype", ",", "tf", ".", "dtypes", ".", "float32", ",", "\n", "tf", ".", "dtypes", ".", "bool", ",", "tf", ".", "dtypes", ".", "int32", ",", "tf", ".", "dtypes", ".", "bool", ",", "\n", "tf", ".", "dtypes", ".", "float32", ",", "self", ".", "_actor", ".", "action_dtype", ",", "self", ".", "_actor", ".", "action_dtype", ")", "\n", ")", ".", "prefetch", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC._init_inverse_covariance_matrices": [[142, 156], ["range", "tensorflow.ragged.constant().to_tensor", "tensorflow.ragged.constant().to_tensor", "acerac.get_lambda_0", "acerac.get_lambda_1", "tf_utils.kronecker_prod", "tf_utils.kronecker_prod", "tensorflow.linalg.inv", "tensorflow.linalg.inv", "lam0_c_prod_invs.append", "lam1_c_prod_invs.append", "tensorflow.linalg.inv.numpy", "tensorflow.linalg.inv.numpy", "tensorflow.ragged.constant", "tensorflow.ragged.constant"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.get_lambda_0", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.get_lambda_1", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.tf_utils.kronecker_prod", "home.repos.pwc.inspect_result.mszulc913_acerac.acerac.tf_utils.kronecker_prod"], ["", "def", "_init_inverse_covariance_matrices", "(", "self", ")", ":", "\n", "        ", "lam0_c_prod_invs", "=", "[", "]", "\n", "lam1_c_prod_invs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "self", ".", "_tau", ")", ":", "\n", "            ", "lam0", "=", "get_lambda_0", "(", "i", ",", "self", ".", "_alpha", ")", "\n", "lam1", "=", "get_lambda_1", "(", "i", ",", "self", ".", "_alpha", ")", "\n", "lam0_c_prod", "=", "tf_utils", ".", "kronecker_prod", "(", "lam0", ",", "self", ".", "_cov_matrix", ")", "\n", "lam1_c_prod", "=", "tf_utils", ".", "kronecker_prod", "(", "lam1", ",", "self", ".", "_cov_matrix", ")", "\n", "inv0", "=", "tf", ".", "linalg", ".", "inv", "(", "lam0_c_prod", ")", "\n", "inv1", "=", "tf", ".", "linalg", ".", "inv", "(", "lam1_c_prod", ")", "\n", "lam0_c_prod_invs", ".", "append", "(", "inv0", ".", "numpy", "(", ")", ")", "\n", "lam1_c_prod_invs", ".", "append", "(", "inv1", ".", "numpy", "(", ")", ")", "\n", "", "self", ".", "_lam1_c_prod_invs", "=", "tf", ".", "ragged", ".", "constant", "(", "lam1_c_prod_invs", ")", ".", "to_tensor", "(", ")", "\n", "self", ".", "_lam0_c_prod_invs", "=", "tf", ".", "ragged", ".", "constant", "(", "lam0_c_prod_invs", ")", ".", "to_tensor", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC._init_replay_buffer": [[157, 169], ["replay_buffer.MultiReplayBuffer", "type", "replay_buffer.BufferFieldSpec", "replay_buffer.BufferFieldSpec"], "methods", ["None"], ["", "def", "_init_replay_buffer", "(", "self", ",", "memory_size", ":", "int", ")", ":", "\n", "        ", "if", "type", "(", "self", ".", "_actions_space", ")", "==", "gym", ".", "spaces", ".", "Discrete", ":", "\n", "            ", "actions_shape", "=", "(", "1", ",", ")", "\n", "", "else", ":", "\n", "            ", "actions_shape", "=", "self", ".", "_actions_space", ".", "shape", "\n", "\n", "", "self", ".", "_memory", "=", "MultiReplayBuffer", "(", "\n", "action_spec", "=", "BufferFieldSpec", "(", "shape", "=", "actions_shape", ",", "dtype", "=", "self", ".", "_actor", ".", "action_dtype_np", ")", ",", "\n", "obs_spec", "=", "BufferFieldSpec", "(", "shape", "=", "self", ".", "_observations_space", ".", "shape", ",", "dtype", "=", "self", ".", "_observations_space", ".", "dtype", ")", ",", "\n", "max_size", "=", "memory_size", ",", "\n", "num_buffers", "=", "self", ".", "_num_parallel_envs", ",", "\n", "buffer_class", "=", "PrevReplayBuffer", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC._init_actor": [[171, 179], ["acerac.NoiseGaussianActor"], "methods", ["None"], ["", "def", "_init_actor", "(", "self", ")", "->", "BaseActor", ":", "\n", "        ", "if", "self", ".", "_is_discrete", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "return", "NoiseGaussianActor", "(", "\n", "self", ".", "_observations_space", ",", "self", ".", "_actions_space", ",", "self", ".", "_actor_layers", ",", "\n", "self", ".", "_actor_beta_penalty", ",", "self", ".", "_actions_bound", ",", "self", ".", "_tau", ",", "self", ".", "_alpha", ",", "self", ".", "_num_parallel_envs", ",", "\n", "self", ".", "_std", ",", "self", ".", "_tf_time_step", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC._init_critic": [[181, 183], ["algos.base.Critic"], "methods", ["None"], ["", "", "def", "_init_critic", "(", "self", ")", "->", "Critic", ":", "\n", "        ", "return", "Critic", "(", "self", ".", "_observations_space", ",", "self", ".", "_critic_layers", ",", "self", ".", "_tf_time_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC.save_experience": [[184, 190], ["super().save_experience", "acerac.ACERAC._actor.update_ends", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC.save_experience", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.NoiseGaussianActor.update_ends"], ["", "def", "save_experience", "(", "self", ",", "steps", ":", "List", "[", "\n", "Tuple", "[", "Union", "[", "int", ",", "float", ",", "list", "]", ",", "np", ".", "array", ",", "np", ".", "array", ",", "np", ".", "array", ",", "bool", ",", "bool", "]", "\n", "]", ")", ":", "\n", "        ", "super", "(", ")", ".", "save_experience", "(", "steps", ")", "\n", "\n", "self", ".", "_actor", ".", "update_ends", "(", "np", ".", "array", "(", "[", "[", "step", "[", "5", "]", "]", "for", "step", "in", "steps", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC.learn": [[191, 195], ["acerac.ACERAC._data_loader.take", "acerac.ACERAC._learn_from_experience_batch"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER._learn_from_experience_batch"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_time_step", ">", "self", ".", "_learning_starts", ":", "\n", "            ", "for", "batch", "in", "self", ".", "_data_loader", ".", "take", "(", "self", ".", "_c", ")", ":", "\n", "                ", "self", ".", "_learn_from_experience_batch", "(", "*", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC._learn_from_experience_batch": [[196, 301], ["tensorflow.function", "tensorflow.cast", "acerac.ACERAC._get_c_invs", "acerac.ACERAC._get_prev_noise", "tape.gradient", "zip", "acerac.ACERAC._actor_optimizer.apply_gradients", "tape.gradient", "zip", "acerac.ACERAC._critic_optimizer.apply_gradients", "tensorflow.expand_dims", "tensorflow.GradientTape", "acerac.ACERAC._actor.act_deterministic", "tensorflow.split", "tensorflow.slice", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.repeat", "tensorflow.repeat", "tensorflow.repeat", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "acerac.ACERAC._compute_soft_truncated_density_ratio", "tensorflow.math.cumprod", "tensorflow.math.cumsum", "tensorflow.repeat", "tensorflow.tile", "tensorflow.matmul", "tensorflow.scalar_mul", "tensorflow.matmul", "tensorflow.name_scope", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.name_scope", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.squeeze", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.sequence_mask", "tensorflow.sequence_mask", "tensorflow.name_scope", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.expand_dims", "tensorflow.squeeze", "tensorflow.transpose", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.square", "tensorflow.squeeze", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "acerac.ACERAC._critic.value", "tensorflow.cast", "tensorflow.range", "tensorflow.reduce_mean", "tensorflow.reduce_max", "tensorflow.ones_like", "tensorflow.range", "tensorflow.pow", "tensorflow.expand_dims", "tensorflow.squeeze", "tensorflow.cast", "tensorflow.maximum", "tensorflow.stop_gradient", "tensorflow.reduce_mean", "tensorflow.concat", "tensorflow.cast", "tensorflow.squeeze", "tensorflow.squeeze", "tensorflow.stop_gradient", "tensorflow.abs"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC._get_c_invs", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC._get_prev_noise", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.GaussianActor.act_deterministic", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC._compute_soft_truncated_density_ratio", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseCritic.value"], ["", "", "", "@", "tf", ".", "function", "(", "experimental_relax_shapes", "=", "True", ")", "\n", "def", "_learn_from_experience_batch", "(", "\n", "self", ",", "obs", ":", "tf", ".", "Tensor", ",", "obs_next", ":", "tf", ".", "Tensor", ",", "actions", ":", "tf", ".", "Tensor", ",", "\n", "old_means", ":", "tf", ".", "Tensor", ",", "rewards", ":", "tf", ".", "Tensor", ",", "dones", ":", "tf", ".", "Tensor", ",", "\n", "lengths", ":", "tf", ".", "Tensor", ",", "is_prev_noise", ":", "tf", ".", "Tensor", ",", "\n", "prev_obs", ":", "tf", ".", "Tensor", ",", "prev_actions", ":", "tf", ".", "Tensor", ",", "prev_means", ":", "tf", ".", "Tensor", "\n", ")", ":", "\n", "        ", "\"\"\"Performs single learning step.\n        Padded tensors are used here and final results are masked out with zeros\"\"\"", "\n", "\n", "is_prev_noise_mask", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "is_prev_noise", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "\n", "c_invs", "=", "self", ".", "_get_c_invs", "(", "actions", ",", "is_prev_noise_mask", ")", "\n", "eta_repeated", ",", "mu_repeated", "=", "self", ".", "_get_prev_noise", "(", "actions", ",", "is_prev_noise_mask", ",", "prev_actions", ",", "prev_means", ",", "prev_obs", ")", "\n", "\n", "with", "tf", ".", "GradientTape", "(", "persistent", "=", "True", ")", "as", "tape", ":", "\n", "            ", "means", "=", "self", ".", "_actor", ".", "act_deterministic", "(", "obs", ")", "\n", "values", ",", "values_next", "=", "tf", ".", "split", "(", "tf", ".", "squeeze", "(", "self", ".", "_critic", ".", "value", "(", "tf", ".", "concat", "(", "[", "obs", ",", "obs_next", "]", ",", "axis", "=", "0", ")", ")", ")", ",", "2", ")", "\n", "values_next", "=", "values_next", "*", "(", "1", "-", "tf", ".", "cast", "(", "dones", ",", "tf", ".", "float32", ")", ")", "\n", "values_first", "=", "tf", ".", "slice", "(", "values", ",", "[", "0", ",", "0", "]", ",", "[", "actions", ".", "shape", "[", "0", "]", ",", "1", "]", ")", "\n", "\n", "actions_flatten", "=", "tf", ".", "reshape", "(", "actions", ",", "(", "actions", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "means_flatten", "=", "tf", ".", "reshape", "(", "means", ",", "(", "actions", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "old_means_flatten", "=", "tf", ".", "reshape", "(", "old_means", ",", "(", "actions", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n", "actions_repeated", "=", "tf", ".", "repeat", "(", "tf", ".", "expand_dims", "(", "actions_flatten", ",", "axis", "=", "1", ")", ",", "self", ".", "_tau", ",", "axis", "=", "1", ")", "\n", "means_repeated", "=", "tf", ".", "repeat", "(", "tf", ".", "expand_dims", "(", "means_flatten", ",", "axis", "=", "1", ")", ",", "self", ".", "_tau", ",", "axis", "=", "1", ")", "\n", "old_means_repeated", "=", "tf", ".", "repeat", "(", "tf", ".", "expand_dims", "(", "old_means_flatten", ",", "axis", "=", "1", ")", ",", "self", ".", "_tau", ",", "axis", "=", "1", ")", "\n", "\n", "# 1, 2, ..., n trajectories mask over repeated action tensors", "\n", "actions_mask", "=", "tf", ".", "expand_dims", "(", "\n", "tf", ".", "sequence_mask", "(", "\n", "tf", ".", "range", "(", "actions", ".", "shape", "[", "2", "]", ",", "actions_repeated", ".", "shape", "[", "2", "]", "+", "actions", ".", "shape", "[", "2", "]", ",", "actions", ".", "shape", "[", "2", "]", ")", ",", "\n", "actions_repeated", ".", "shape", "[", "2", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", ",", "\n", "axis", "=", "0", "\n", ")", "\n", "\n", "# trajectories shorter than tau mask", "\n", "zeros_mask", "=", "tf", ".", "expand_dims", "(", "tf", ".", "sequence_mask", "(", "lengths", ",", "maxlen", "=", "self", ".", "_tau", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "2", ")", "\n", "\n", "actions_mu_diff_current", "=", "tf", ".", "expand_dims", "(", "\n", "(", "actions_repeated", "-", "means_repeated", "-", "eta_repeated", ")", "*", "zeros_mask", "*", "actions_mask", ",", "\n", "axis", "=", "2", "\n", ")", "\n", "actions_mu_diff_old", "=", "tf", ".", "expand_dims", "(", "\n", "(", "actions_repeated", "-", "old_means_repeated", "-", "mu_repeated", ")", "*", "zeros_mask", "*", "actions_mask", ",", "\n", "axis", "=", "2", "\n", ")", "\n", "density_ratio", "=", "self", ".", "_compute_soft_truncated_density_ratio", "(", "\n", "actions_mu_diff_current", ",", "actions_mu_diff_old", ",", "c_invs", "\n", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'acerac'", ")", ":", "\n", "                ", "tf", ".", "summary", ".", "scalar", "(", "'mean_density_ratio'", ",", "tf", ".", "reduce_mean", "(", "density_ratio", ")", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'max_density_ratio'", ",", "tf", ".", "reduce_max", "(", "density_ratio", ")", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "\n", "", "gamma_coeffs", "=", "tf", ".", "math", ".", "cumprod", "(", "tf", ".", "ones_like", "(", "rewards", ")", "*", "self", ".", "_gamma", ",", "exclusive", "=", "True", ",", "axis", "=", "1", ")", "\n", "td_rewards", "=", "tf", ".", "math", ".", "cumsum", "(", "rewards", "*", "gamma_coeffs", ",", "axis", "=", "1", ")", "\n", "\n", "values_first_repeated", "=", "tf", ".", "repeat", "(", "values_first", ",", "self", ".", "_tau", ",", "1", ")", "\n", "pows", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "1", ",", "self", ".", "_tau", "+", "1", ")", ",", "axis", "=", "0", ")", ",", "[", "actions", ".", "shape", "[", "0", "]", ",", "1", "]", ")", "\n", "td", "=", "(", "-", "values_first_repeated", "\n", "+", "td_rewards", "\n", "+", "tf", ".", "pow", "(", "self", ".", "_gamma", ",", "tf", ".", "cast", "(", "pows", ",", "tf", ".", "float32", ")", ")", "*", "values_next", ")", "\n", "\n", "d", "=", "td", "*", "density_ratio", "*", "tf", ".", "squeeze", "(", "zeros_mask", ")", "# remove artifacts from cumsum and cumprod", "\n", "\n", "c_mu", "=", "tf", ".", "matmul", "(", "c_invs", ",", "tf", ".", "transpose", "(", "actions_mu_diff_current", ",", "[", "0", ",", "1", ",", "3", ",", "2", "]", ")", ")", "\n", "c_mu_d", "=", "c_mu", "*", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "d", ",", "axis", "=", "2", ")", ",", "3", ")", "\n", "\n", "c_mu_mean", "=", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "squeeze", "(", "c_mu_d", ")", ",", "axis", "=", "1", ")", "/", "tf", ".", "expand_dims", "(", "tf", ".", "cast", "(", "lengths", ",", "tf", ".", "float32", ")", ",", "1", ")", ")", "\n", "\n", "bounds_penalty", "=", "tf", ".", "scalar_mul", "(", "\n", "self", ".", "_actor", ".", "beta_penalty", ",", "\n", "tf", ".", "square", "(", "tf", ".", "maximum", "(", "0.0", ",", "tf", ".", "abs", "(", "means", ")", "-", "self", ".", "_actions_bound", ")", ")", "\n", ")", "\n", "bounds_penalty", "=", "tf", ".", "squeeze", "(", "zeros_mask", ")", "*", "tf", ".", "reduce_sum", "(", "\n", "bounds_penalty", ",", "\n", "axis", "=", "2", "\n", ")", "\n", "\n", "bounds_penalty", "=", "tf", ".", "reduce_sum", "(", "bounds_penalty", ",", "axis", "=", "1", ")", "/", "tf", ".", "cast", "(", "lengths", ",", "tf", ".", "float32", ")", "\n", "actor_loss", "=", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "means_flatten", ",", "axis", "=", "1", ")", ",", "tf", ".", "expand_dims", "(", "tf", ".", "stop_gradient", "(", "c_mu_mean", ")", ",", "axis", "=", "2", ")", ")", "\n", "actor_loss", "=", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "squeeze", "(", "actor_loss", ")", ")", "+", "tf", ".", "reduce_mean", "(", "bounds_penalty", ")", "\n", "\n", "d_mean", "=", "tf", ".", "reduce_sum", "(", "d", ",", "axis", "=", "1", ")", "/", "tf", ".", "cast", "(", "lengths", ",", "tf", ".", "float32", ")", "\n", "critic_loss", "=", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "squeeze", "(", "values_first", ")", "*", "tf", ".", "stop_gradient", "(", "d_mean", ")", ")", "\n", "\n", "", "grads_actor", "=", "tape", ".", "gradient", "(", "actor_loss", ",", "self", ".", "_actor", ".", "trainable_variables", ")", "\n", "grads_var_actor", "=", "zip", "(", "grads_actor", ",", "self", ".", "_actor", ".", "trainable_variables", ")", "\n", "self", ".", "_actor_optimizer", ".", "apply_gradients", "(", "grads_var_actor", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'actor'", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "f'batch_actor_loss'", ",", "actor_loss", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "f'batch_bounds_penalty'", ",", "tf", ".", "reduce_mean", "(", "bounds_penalty", ")", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "\n", "", "grads_critic", "=", "tape", ".", "gradient", "(", "critic_loss", ",", "self", ".", "_critic", ".", "trainable_variables", ")", "\n", "grads_var_critic", "=", "zip", "(", "grads_critic", ",", "self", ".", "_critic", ".", "trainable_variables", ")", "\n", "self", ".", "_critic_optimizer", ".", "apply_gradients", "(", "grads_var_critic", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'critic'", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "f'batch_critic_loss'", ",", "critic_loss", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "f'batch_value_mean'", ",", "tf", ".", "reduce_mean", "(", "values", ")", ",", "step", "=", "self", ".", "_tf_time_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC._compute_soft_truncated_density_ratio": [[302, 315], ["tensorflow.matmul", "tensorflow.matmul", "tensorflow.squeeze", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.exp", "tensorflow.tanh"], "methods", ["None"], ["", "", "def", "_compute_soft_truncated_density_ratio", "(", "\n", "self", ",", "actions_mu_diff_current", ":", "tf", ".", "Tensor", ",", "actions_mu_diff_old", ":", "tf", ".", "Tensor", ",", "c_invs", ":", "tf", ".", "Tensor", "\n", ")", ":", "\n", "        ", "exp_current", "=", "tf", ".", "matmul", "(", "\n", "tf", ".", "matmul", "(", "actions_mu_diff_current", ",", "c_invs", ")", ",", "\n", "tf", ".", "transpose", "(", "actions_mu_diff_current", ",", "[", "0", ",", "1", ",", "3", ",", "2", "]", ")", "\n", ")", "\n", "exp_old", "=", "tf", ".", "matmul", "(", "\n", "tf", ".", "matmul", "(", "actions_mu_diff_old", ",", "c_invs", ")", ",", "\n", "tf", ".", "transpose", "(", "actions_mu_diff_old", ",", "[", "0", ",", "1", ",", "3", ",", "2", "]", ")", "\n", ")", "\n", "density_ratio", "=", "tf", ".", "squeeze", "(", "tf", ".", "exp", "(", "-", "0.5", "*", "exp_current", "+", "0.5", "*", "exp_old", ")", ")", "\n", "return", "tf", ".", "tanh", "(", "density_ratio", "/", "self", ".", "_b", ")", "*", "self", ".", "_b", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC._get_prev_noise": [[316, 339], ["acerac.ACERAC._actor.act_deterministic", "tensorflow.pow", "tensorflow.expand_dims", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.repeat", "tensorflow.repeat", "tensorflow.tile", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.range", "tensorflow.repeat", "tensorflow.repeat"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.GaussianActor.act_deterministic"], ["", "def", "_get_prev_noise", "(", "self", ",", "actions", ":", "tf", ".", "Tensor", ",", "is_prev_noise_mask", ":", "tf", ".", "Tensor", ",", "prev_actions", ":", "tf", ".", "Tensor", ",", "\n", "prev_means", ":", "tf", ".", "Tensor", ",", "prev_obs", ":", "tf", ".", "Tensor", ")", "->", "Tuple", "[", "tf", ".", "Tensor", ",", "tf", ".", "Tensor", "]", ":", "\n", "        ", "current_prev_means", "=", "self", ".", "_actor", ".", "act_deterministic", "(", "prev_obs", ")", "\n", "alpha_coeffs", "=", "tf", ".", "pow", "(", "\n", "self", ".", "_alpha", ",", "\n", "tf", ".", "tile", "(", "tf", ".", "range", "(", "1", ",", "self", ".", "_tau", "+", "1", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "(", "prev_actions", ".", "shape", "[", "0", "]", ",", ")", ")", "\n", ")", "\n", "alpha_coeffs", "=", "tf", ".", "expand_dims", "(", "alpha_coeffs", ",", "axis", "=", "1", ")", "\n", "mu_diff", "=", "(", "prev_actions", "-", "prev_means", ")", "*", "is_prev_noise_mask", "\n", "eta_diff", "=", "(", "prev_actions", "-", "current_prev_means", ")", "*", "is_prev_noise_mask", "\n", "mu", "=", "tf", ".", "reshape", "(", "tf", ".", "repeat", "(", "mu_diff", ",", "self", ".", "_tau", ",", "axis", "=", "0", ")", "*", "alpha_coeffs", ",", "(", "actions", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "eta", "=", "tf", ".", "reshape", "(", "tf", ".", "repeat", "(", "eta_diff", ",", "self", ".", "_tau", ",", "axis", "=", "0", ")", "*", "alpha_coeffs", ",", "(", "actions", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "mu_repeated", "=", "tf", ".", "repeat", "(", "\n", "tf", ".", "expand_dims", "(", "mu", ",", "axis", "=", "1", ")", ",", "\n", "self", ".", "_tau", ",", "\n", "axis", "=", "1", "\n", ")", "\n", "eta_repeated", "=", "tf", ".", "repeat", "(", "\n", "tf", ".", "expand_dims", "(", "eta", ",", "axis", "=", "1", ")", ",", "\n", "self", ".", "_tau", ",", "\n", "axis", "=", "1", "\n", ")", "\n", "return", "eta_repeated", ",", "mu_repeated", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC._get_c_invs": [[340, 347], ["tensorflow.expand_dims", "tensorflow.tile", "tensorflow.tile", "tensorflow.reshape", "tensorflow.repeat"], "methods", ["None"], ["", "def", "_get_c_invs", "(", "self", ",", "actions", ":", "tf", ".", "Tensor", ",", "is_prev_noise_mask", ":", "tf", ".", "Tensor", ")", "->", "tf", ".", "Tensor", ":", "\n", "        ", "is_prev_noise_mask_repeated", "=", "tf", ".", "expand_dims", "(", "tf", ".", "repeat", "(", "is_prev_noise_mask", ",", "self", ".", "_tau", ",", "axis", "=", "0", ")", ",", "1", ")", "\n", "c_invs_0", "=", "tf", ".", "tile", "(", "self", ".", "_lam0_c_prod_invs", ",", "(", "actions", ".", "shape", "[", "0", "]", ",", "1", ",", "1", ")", ")", "\n", "c_invs_1", "=", "tf", ".", "tile", "(", "self", ".", "_lam1_c_prod_invs", ",", "(", "actions", ".", "shape", "[", "0", "]", ",", "1", ",", "1", ")", ")", "\n", "c_invs", "=", "c_invs_1", "*", "is_prev_noise_mask_repeated", "+", "c_invs_0", "*", "(", "1", "-", "is_prev_noise_mask_repeated", ")", "\n", "c_invs", "=", "tf", ".", "reshape", "(", "c_invs", ",", "(", "actions", ".", "shape", "[", "0", "]", ",", "self", ".", "_tau", ",", "c_invs", ".", "shape", "[", "2", "]", ",", "-", "1", ")", ")", "\n", "return", "c_invs", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC._fetch_offline_batch": [[348, 353], ["batch.extend", "range", "acerac.ACERAC._memory.get", "range"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.MultiReplayBuffer.get"], ["", "def", "_fetch_offline_batch", "(", "self", ")", "->", "List", "[", "Tuple", "[", "Dict", "[", "str", ",", "Union", "[", "np", ".", "array", ",", "list", "]", "]", ",", "int", "]", "]", ":", "\n", "        ", "trajectory_lens", "=", "[", "[", "self", ".", "_tau", "for", "_", "in", "range", "(", "self", ".", "_num_parallel_envs", ")", "]", "for", "_", "in", "range", "(", "self", ".", "_batches_per_env", ")", "]", "\n", "batch", "=", "[", "]", "\n", "[", "batch", ".", "extend", "(", "self", ".", "_memory", ".", "get", "(", "trajectories", ")", ")", "for", "trajectories", "in", "trajectory_lens", "]", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.ACERAC._experience_replay_generator": [[354, 406], ["acerac.ACERAC._fetch_offline_batch", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER._fetch_offline_batch"], ["", "def", "_experience_replay_generator", "(", "self", ")", ":", "\n", "        ", "\"\"\"Generates flat batches (matrices) with trajectories.\n        All tensors are padded with zeros to match self._tau number of experience tuples in a single trajectory.\n        Trajectories are returned in a shape of [batch, self._tau, <obs/actions/etc shape>]\n        \"\"\"", "\n", "while", "True", ":", "\n", "            ", "offline_batches", "=", "self", ".", "_fetch_offline_batch", "(", ")", "\n", "obs", "=", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "offline_batches", ")", ",", "self", ".", "_tau", ",", "self", ".", "_observations_space", ".", "shape", "[", "0", "]", ")", ")", "\n", "obs_next", "=", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "offline_batches", ")", ",", "self", ".", "_tau", ",", "self", ".", "_observations_space", ".", "shape", "[", "0", "]", ")", ")", "\n", "actions", "=", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "offline_batches", ")", ",", "self", ".", "_tau", ",", "self", ".", "_actions_space", ".", "shape", "[", "0", "]", ")", ")", "\n", "rewards", "=", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "offline_batches", ")", ",", "self", ".", "_tau", ")", ")", "\n", "means", "=", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "offline_batches", ")", ",", "self", ".", "_tau", ",", "self", ".", "_actions_space", ".", "shape", "[", "0", "]", ")", ")", "\n", "dones", "=", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "offline_batches", ")", ",", "self", ".", "_tau", ")", ")", "\n", "lengths", "=", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "offline_batches", ")", ")", ")", "\n", "is_prev_noise", "=", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "offline_batches", ")", ")", ")", "\n", "\n", "prev_obs", "=", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "offline_batches", ")", ",", "self", ".", "_observations_space", ".", "shape", "[", "0", "]", ")", ")", "\n", "prev_actions", "=", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "offline_batches", ")", ",", "self", ".", "_actions_space", ".", "shape", "[", "0", "]", ")", ")", "\n", "prev_means", "=", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "offline_batches", ")", ",", "self", ".", "_actions_space", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "for", "i", ",", "batch_and_first_index", "in", "enumerate", "(", "offline_batches", ")", ":", "\n", "                ", "batch", ",", "first_index", "=", "batch_and_first_index", "\n", "obs", "[", "i", "*", "self", ".", "_tau", ":", ",", ":", "len", "(", "batch", "[", "'observations'", "]", "[", "first_index", ":", "]", ")", ",", ":", "]", "=", "batch", "[", "'observations'", "]", "[", "first_index", ":", "]", "\n", "obs_next", "[", "i", "*", "self", ".", "_tau", ":", ",", ":", "len", "(", "batch", "[", "'next_observations'", "]", "[", "first_index", ":", "]", ")", ",", ":", "]", "=", "batch", "[", "'next_observations'", "]", "[", "first_index", ":", "]", "\n", "actions", "[", "i", "*", "self", ".", "_tau", ":", ",", ":", "len", "(", "batch", "[", "'actions'", "]", "[", "first_index", ":", "]", ")", ",", ":", "]", "=", "batch", "[", "'actions'", "]", "[", "first_index", ":", "]", "\n", "means", "[", "i", "*", "self", ".", "_tau", ":", ",", ":", "len", "(", "batch", "[", "'policies'", "]", "[", "first_index", ":", "]", ")", ",", ":", "]", "=", "batch", "[", "'policies'", "]", "[", "first_index", ":", "]", "\n", "rewards", "[", "i", "*", "self", ".", "_tau", ":", ",", ":", "len", "(", "batch", "[", "'rewards'", "]", "[", "first_index", ":", "]", ")", "]", "=", "batch", "[", "'rewards'", "]", "[", "first_index", ":", "]", "\n", "dones", "[", "i", "*", "self", ".", "_tau", ":", ",", ":", "len", "(", "batch", "[", "'dones'", "]", "[", "first_index", ":", "]", ")", "]", "=", "batch", "[", "'dones'", "]", "[", "first_index", ":", "]", "\n", "is_prev_noise", "[", "i", "]", "=", "first_index", "\n", "lengths", "[", "i", "]", "=", "len", "(", "batch", "[", "'observations'", "]", "[", "first_index", ":", "]", ")", "\n", "prev_obs", "[", "i", ",", ":", "]", "=", "batch", "[", "'observations'", "]", "[", "0", "]", "\n", "prev_actions", "[", "i", ",", ":", "]", "=", "batch", "[", "'actions'", "]", "[", "0", "]", "\n", "prev_means", "[", "i", ",", ":", "]", "=", "batch", "[", "'policies'", "]", "[", "0", "]", "\n", "\n", "", "yield", "(", "\n", "obs", ",", "\n", "obs_next", ",", "\n", "actions", ",", "\n", "means", ",", "\n", "rewards", ",", "\n", "dones", ",", "\n", "lengths", ",", "\n", "is_prev_noise", ",", "\n", "prev_obs", ",", "\n", "prev_actions", ",", "\n", "prev_means", ",", "\n", ")", ""]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.get_lambda_1": [[20, 35], ["numpy.zeros", "range", "range", "abs"], "function", ["None"], ["def", "get_lambda_1", "(", "n", ":", "int", ",", "alpha", ":", "float", ")", "->", "np", ".", "array", ":", "\n", "    ", "\"\"\"Computes Lambda^n_1 matrix.\n\n    Args:\n        n: Size of a (square) matrix.\n        alpha: Autocorrelation degree.\n\n    Returns:\n        Lambda^n_1 matrix.\n    \"\"\"", "\n", "lam", "=", "np", ".", "zeros", "(", "shape", "=", "(", "n", "+", "1", ",", "n", "+", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "n", "+", "1", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "i", ",", "n", "+", "1", ")", ":", "\n", "            ", "lam", "[", "i", "]", "[", "j", "]", "=", "lam", "[", "j", "]", "[", "i", "]", "=", "alpha", "**", "abs", "(", "i", "-", "j", ")", "-", "alpha", "**", "(", "i", "+", "j", "+", "2", ")", "\n", "", "", "return", "lam", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.get_lambda_0": [[37, 52], ["numpy.zeros", "range", "range", "abs"], "function", ["None"], ["", "def", "get_lambda_0", "(", "n", ":", "int", ",", "alpha", ":", "float", ")", "->", "np", ".", "array", ":", "\n", "    ", "\"\"\"Computes Lambda^n_0 matrix.\n\n    Args:\n        n: Size of a (square) matrix.\n        alpha: Autocorrelation degree.\n\n    Returns:\n        Lambda^n_1 matrix\n    \"\"\"", "\n", "lam", "=", "np", ".", "zeros", "(", "shape", "=", "(", "n", "+", "1", ",", "n", "+", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "n", "+", "1", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "i", ",", "n", "+", "1", ")", ":", "\n", "            ", "lam", "[", "i", "]", "[", "j", "]", "=", "lam", "[", "j", "]", "[", "i", "]", "=", "alpha", "**", "abs", "(", "i", "-", "j", ")", "\n", "", "", "return", "lam", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER.__init__": [[24, 33], ["algos.base.BaseACERAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "observations_space", ":", "gym", ".", "Space", ",", "actions_space", ":", "gym", ".", "Space", ",", "actor_layers", ":", "Optional", "[", "Tuple", "[", "int", "]", "]", ",", "\n", "critic_layers", ":", "Optional", "[", "Tuple", "[", "int", "]", "]", ",", "lam", ":", "float", "=", "0.1", ",", "b", ":", "float", "=", "3", ",", "*", "args", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Actor-Critic with Experience Replay.\"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "observations_space", ",", "actions_space", ",", "actor_layers", ",", "critic_layers", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_lam", "=", "lam", "\n", "self", ".", "_b", "=", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER._init_actor": [[34, 44], ["algos.base.CategoricalActor", "algos.base.GaussianActor"], "methods", ["None"], ["", "def", "_init_actor", "(", "self", ")", "->", "BaseActor", ":", "\n", "        ", "if", "self", ".", "_is_discrete", ":", "\n", "            ", "return", "CategoricalActor", "(", "\n", "self", ".", "_observations_space", ",", "self", ".", "_actions_space", ",", "self", ".", "_actor_layers", ",", "\n", "self", ".", "_actor_beta_penalty", ",", "self", ".", "_tf_time_step", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "GaussianActor", "(", "\n", "self", ".", "_observations_space", ",", "self", ".", "_actions_space", ",", "self", ".", "_actor_layers", ",", "\n", "self", ".", "_actor_beta_penalty", ",", "self", ".", "_actions_bound", ",", "self", ".", "_std", ",", "self", ".", "_tf_time_step", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER._init_critic": [[46, 48], ["algos.base.Critic"], "methods", ["None"], ["", "", "def", "_init_critic", "(", "self", ")", "->", "Critic", ":", "\n", "        ", "return", "Critic", "(", "self", ".", "_observations_space", ",", "self", ".", "_critic_layers", ",", "self", ".", "_tf_time_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER.learn": [[49, 58], ["acer.ACER._data_loader.take", "acer.ACER._learn_from_experience_batch"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER._learn_from_experience_batch"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Performs experience replay learning. Experience trajectory is sampled from every replay buffer once, thus\n        single backwards pass batch consists of 'num_parallel_envs' trajectories. Learning starts after\n        self._learning_starts time steps.\n        \"\"\"", "\n", "if", "self", ".", "_time_step", ">", "self", ".", "_learning_starts", ":", "\n", "            ", "for", "batch", "in", "self", ".", "_data_loader", ".", "take", "(", "self", ".", "_c", ")", ":", "\n", "                ", "self", ".", "_learn_from_experience_batch", "(", "*", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER._learn_from_experience_batch": [[59, 114], ["tensorflow.function", "tensorflow.RaggedTensor.from_row_lengths", "tensorflow.squeeze", "tensorflow.split", "tensorflow.expand_dims", "tensorflow.math.divide", "tensorflow.squeeze", "tensorflow.sequence_mask", "tensorflow.math.cumprod", "tensorflow.ragged.boolean_mask", "tensorflow.gather_nd", "tensorflow.stop_gradient", "acer.ACER._backward_pass", "tensorflow.split", "tensorflow.squeeze", "tensorflow.reduce_mean", "acer.ACER._critic.value", "tensorflow.squeeze", "acer.ACER._actor.prob", "tensorflow.squeeze", "tensorflow.squeeze", "tensorflow.gather", "tensorflow.squeeze.row_lengths", "tensorflow.squeeze.to_tensor", "tensorflow.minimum", "tensorflow.ones_like().to_tensor", "tensorflow.ragged.boolean_mask", "tensorflow.expand_dims", "tensorflow.reduce_sum", "acer.ACER._actor.prob", "tensorflow.name_scope", "tensorflow.summary.scalar", "tensorflow.range", "acer.ACER._critic.value", "tensorflow.cast", "tensorflow.math.cumprod", "tensorflow.reduce_sum", "tensorflow.ones_like"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER._backward_pass", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseCritic.value", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.NoiseGaussianActor.prob", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acerac.NoiseGaussianActor.prob", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.BaseCritic.value"], ["", "", "", "@", "tf", ".", "function", "(", "experimental_relax_shapes", "=", "True", ")", "\n", "def", "_learn_from_experience_batch", "(", "\n", "self", ",", "obs", ",", "obs_next", ",", "actions", ",", "old_policies", ",", "\n", "rewards", ",", "first_obs", ",", "first_actions", ",", "dones", ",", "lengths", "\n", ")", ":", "\n", "        ", "\"\"\"Backward pass with a single batch of experience.\n\n        Every experience replay requires sequence of experiences with random length, thus we have to use\n        ragged tensors here.\n        TODO: truncate random lengths\n\n        See Equation (8) and Equation (9) in the paper (1).\n        \"\"\"", "\n", "\n", "batches_indices", "=", "tf", ".", "RaggedTensor", ".", "from_row_lengths", "(", "values", "=", "tf", ".", "range", "(", "tf", ".", "reduce_sum", "(", "lengths", ")", ")", ",", "row_lengths", "=", "lengths", ")", "\n", "values", "=", "tf", ".", "squeeze", "(", "self", ".", "_critic", ".", "value", "(", "obs", ")", ")", "\n", "values_next", "=", "tf", ".", "squeeze", "(", "self", ".", "_critic", ".", "value", "(", "obs_next", ")", ")", "*", "(", "1.0", "-", "tf", ".", "cast", "(", "dones", ",", "tf", ".", "dtypes", ".", "float32", ")", ")", "\n", "policies", ",", "log_policies", "=", "tf", ".", "split", "(", "self", ".", "_actor", ".", "prob", "(", "obs", ",", "actions", ")", ",", "2", ",", "axis", "=", "0", ")", "\n", "policies", ",", "log_policies", "=", "tf", ".", "squeeze", "(", "policies", ")", ",", "tf", ".", "squeeze", "(", "log_policies", ")", "\n", "indices", "=", "tf", ".", "expand_dims", "(", "batches_indices", ",", "axis", "=", "2", ")", "\n", "\n", "# flat tensor", "\n", "policies_ratio", "=", "tf", ".", "math", ".", "divide", "(", "policies", ",", "old_policies", ")", "\n", "# ragged tensor divided into batches", "\n", "policies_ratio_batches", "=", "tf", ".", "squeeze", "(", "tf", ".", "gather", "(", "policies_ratio", ",", "indices", ")", ",", "axis", "=", "2", ")", "\n", "\n", "# cumprod and cumsum do not work on ragged tensors, we transform them into tensors", "\n", "# padded with 0 and then apply boolean mask to retrieve original ragged tensor", "\n", "batch_mask", "=", "tf", ".", "sequence_mask", "(", "policies_ratio_batches", ".", "row_lengths", "(", ")", ")", "\n", "policies_ratio_product", "=", "tf", ".", "math", ".", "cumprod", "(", "policies_ratio_batches", ".", "to_tensor", "(", ")", ",", "axis", "=", "1", ")", "\n", "\n", "truncated_densities", "=", "tf", ".", "ragged", ".", "boolean_mask", "(", "\n", "tf", ".", "minimum", "(", "policies_ratio_product", ",", "self", ".", "_b", ")", ",", "\n", "batch_mask", "\n", ")", "\n", "gamma_coeffs_batches", "=", "tf", ".", "ones_like", "(", "truncated_densities", ")", ".", "to_tensor", "(", ")", "*", "self", ".", "_gamma", "\n", "gamma_coeffs", "=", "tf", ".", "ragged", ".", "boolean_mask", "(", "\n", "tf", ".", "math", ".", "cumprod", "(", "gamma_coeffs_batches", ",", "axis", "=", "1", ",", "exclusive", "=", "True", ")", ",", "\n", "batch_mask", "\n", ")", ".", "flat_values", "\n", "\n", "# flat tensors", "\n", "d_coeffs", "=", "gamma_coeffs", "*", "(", "rewards", "+", "self", ".", "_gamma", "*", "values_next", "-", "values", ")", "*", "truncated_densities", ".", "flat_values", "\n", "# ragged", "\n", "d_coeffs_batches", "=", "tf", ".", "gather_nd", "(", "d_coeffs", ",", "tf", ".", "expand_dims", "(", "indices", ",", "axis", "=", "2", ")", ")", "\n", "# final summation over original batches", "\n", "d", "=", "tf", ".", "stop_gradient", "(", "tf", ".", "reduce_sum", "(", "d_coeffs_batches", ",", "axis", "=", "1", ")", ")", "\n", "\n", "self", ".", "_backward_pass", "(", "first_obs", ",", "first_actions", ",", "d", ")", "\n", "\n", "_", ",", "new_log_policies", "=", "tf", ".", "split", "(", "self", ".", "_actor", ".", "prob", "(", "obs", ",", "actions", ")", ",", "2", ",", "axis", "=", "0", ")", "\n", "new_log_policies", "=", "tf", ".", "squeeze", "(", "new_log_policies", ")", "\n", "approx_kl", "=", "tf", ".", "reduce_mean", "(", "policies", "-", "new_log_policies", ")", "\n", "with", "tf", ".", "name_scope", "(", "'actor'", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "'sample_approx_kl_divergence'", ",", "approx_kl", ",", "self", ".", "_tf_time_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER._backward_pass": [[115, 137], ["tape.gradient", "zip", "acer.ACER._actor_optimizer.apply_gradients", "tape.gradient", "zip", "acer.ACER._critic_optimizer.apply_gradients", "tensorflow.GradientTape", "acer.ACER._actor.loss", "tensorflow.GradientTape", "acer.ACER._critic.loss"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.GaussianActor.loss", "home.repos.pwc.inspect_result.mszulc913_acerac.algos.base.GaussianActor.loss"], ["", "", "def", "_backward_pass", "(", "self", ",", "observations", ":", "tf", ".", "Tensor", ",", "actions", ":", "tf", ".", "Tensor", ",", "d", ":", "tf", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"Performs backward pass for Actor's and Critic's networks.\n\n        Args:\n            observations: Batch [batch_size, observations_dim] of observations.\n            actions: Batch [batch_size, actions_dim] of actions.\n            d: Batch [batch_size, observations_dim] of gradient update coefficient\n                (summation terms in the Equations (8) and (9) from the paper (1)).\n        \"\"\"", "\n", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "            ", "loss", "=", "self", ".", "_actor", ".", "loss", "(", "observations", ",", "actions", ",", "d", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "self", ".", "_actor", ".", "trainable_variables", ")", "\n", "gradients", "=", "zip", "(", "grads", ",", "self", ".", "_actor", ".", "trainable_variables", ")", "\n", "\n", "self", ".", "_actor_optimizer", ".", "apply_gradients", "(", "gradients", ")", "\n", "\n", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "            ", "loss", "=", "self", ".", "_critic", ".", "loss", "(", "observations", ",", "d", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "self", ".", "_critic", ".", "trainable_variables", ")", "\n", "gradients", "=", "zip", "(", "grads", ",", "self", ".", "_critic", ".", "trainable_variables", ")", "\n", "\n", "self", ".", "_critic_optimizer", ".", "apply_gradients", "(", "gradients", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mszulc913_acerac.algos.acer.ACER._fetch_offline_batch": [[138, 143], ["batch.extend", "numpy.random.geometric", "range", "acer.ACER._memory.get", "range"], "methods", ["home.repos.pwc.inspect_result.mszulc913_acerac.acerac.replay_buffer.MultiReplayBuffer.get"], ["", "def", "_fetch_offline_batch", "(", "self", ")", "->", "List", "[", "Dict", "[", "str", ",", "Union", "[", "np", ".", "array", ",", "list", "]", "]", "]", ":", "\n", "        ", "trajectory_lens", "=", "[", "np", ".", "random", ".", "geometric", "(", "1", "-", "self", ".", "_lam", ")", "+", "1", "for", "_", "in", "range", "(", "self", ".", "_num_parallel_envs", ")", "]", "\n", "batch", "=", "[", "]", "\n", "[", "batch", ".", "extend", "(", "self", ".", "_memory", ".", "get", "(", "trajectory_lens", ")", ")", "for", "_", "in", "range", "(", "self", ".", "_batches_per_env", ")", "]", "\n", "return", "batch", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mszulc913_acerac.models.mlp.build_mlp_network": [[8, 30], ["tensorflow.keras.layers.Dense", "initializer"], "function", ["None"], ["def", "build_mlp_network", "(", "\n", "layers_sizes", ":", "Tuple", "[", "int", "]", "=", "(", "256", ",", "256", ")", ",", "activation", ":", "str", "=", "'tanh'", ",", "initializer", ":", "Callable", "=", "normc_initializer", "\n", ")", "->", "List", "[", "tf", ".", "keras", ".", "Model", "]", ":", "\n", "    ", "\"\"\"Builds feedforward neural network.\n\n    Args:\n        layers_sizes: List of sizes of hidden layers.\n        activation: Activation function name.\n        initializer: Callable to weights initializer function.\n\n    Returns:\n        Created network (list of Keras layers)\n    \"\"\"", "\n", "layers", "=", "[", "\n", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "layer_size", ",", "\n", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "initializer", "(", ")", "\n", ")", "for", "layer_size", "in", "layers_sizes", "\n", "]", "\n", "\n", "return", "layers", "\n", "", ""]], "home.repos.pwc.inspect_result.mszulc913_acerac.models.cnn.build_cnn_network": [[8, 43], ["tensorflow.keras.layers.Lambda", "tensorflow.keras.layers.Lambda", "layers.append", "len", "len", "len", "tensorflow.keras.layers.Flatten", "len", "len", "len", "tensorflow.expand_dims", "tensorflow.cast", "tensorflow.keras.layers.Conv2D", "zip", "initializer"], "function", ["None"], ["def", "build_cnn_network", "(", "\n", "filters", ":", "tuple", "=", "(", "32", ",", "64", ",", "64", ")", ",", "kernels", ":", "tuple", "=", "(", "8", ",", "4", ",", "3", ")", ",", "strides", ":", "tuple", "=", "(", "(", "4", ",", "4", ")", ",", "(", "2", ",", "2", ")", ",", "(", "1", ",", "1", ")", ")", ",", "\n", "activation", ":", "str", "=", "'relu'", ",", "initializer", ":", "Callable", "=", "normc_initializer", "\n", ")", "->", "List", "[", "tf", ".", "keras", ".", "Model", "]", ":", "\n", "    ", "\"\"\"Builds convolutional neural network.\n\n    Args:\n        filters: Tuple with filters to be used.\n        kernels: Tuple with kernel sizes to be used.\n        strides: Tuple with strides to be used\n        activation: Activation function to be used.\n        initializer: Callable to weights initializer function.\n\n    Returns:\n        Created network (list of Keras layers).\n    \"\"\"", "\n", "assert", "len", "(", "filters", ")", "==", "len", "(", "kernels", ")", "==", "len", "(", "strides", ")", ",", "f\"Layers' specifications must have the same lengths. \"", "f\"Got: len(filters)=={len(filters)}, len(kernels)=={len(kernels)}, len(strides)=={len(strides)}\"", "\n", "\n", "expand_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "expand_dims", "(", "x", ",", "axis", "=", "1", ")", ")", "\n", "cast_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "cast", "(", "x", ",", "tf", ".", "float32", ")", ")", "\n", "layers", "=", "[", "expand_layer", ",", "cast_layer", "]", "+", "[", "\n", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "cnn_filter", ",", "\n", "kernel", ",", "\n", "strides", "=", "stride", ",", "\n", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "initializer", "(", ")", ",", "\n", "padding", "=", "\"same\"", "\n", ")", "for", "cnn_filter", ",", "kernel", ",", "stride", "in", "zip", "(", "filters", ",", "kernels", ",", "strides", ")", "\n", "]", "\n", "\n", "layers", ".", "append", "(", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", ")", "\n", "return", "layers", "\n", "", ""]]}