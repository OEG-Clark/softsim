{"home.repos.pwc.inspect_result.salesforce_fewshot_absa.None.main.set_seed": [[68, 75], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.None.main.get_model_tokenizer": [[77, 132], ["model_class.to", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "min", "model_class.from_pretrained", "logger.info", "model_class", "tokenizer_class.from_pretrained.add_special_tokens", "tokenizer_class.from_pretrained.add_special_tokens", "config_class.from_pretrained", "config_class", "tokenizer_class.from_pretrained", "ValueError", "bool", "transformers.modeling_utils.SequenceSummary"], "function", ["None"], ["", "def", "get_model_tokenizer", "(", "args", ")", ":", "\n", "    ", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "\n", "if", "args", ".", "config_name", ":", "\n", "        ", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "elif", "args", ".", "model_name_or_path", ":", "\n", "        ", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "config_class", "(", ")", "\n", "\n", "", "if", "args", ".", "tokenizer_name", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "elif", "args", ".", "model_name_or_path", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"You are instantiating a new {} tokenizer. This is not supported, but you can do it from another script, save it,\"", "\n", "\"and load it from here, using --tokenizer_name\"", ".", "format", "(", "tokenizer_class", ".", "__name__", ")", "\n", ")", "\n", "\n", "", "if", "args", ".", "block_size", "<=", "0", ":", "\n", "        ", "args", ".", "block_size", "=", "tokenizer", ".", "model_max_length", "\n", "# Our input block size will be the max possible for the model", "\n", "", "else", ":", "\n", "        ", "args", ".", "block_size", "=", "min", "(", "args", ".", "block_size", ",", "tokenizer", ".", "model_max_length", ")", "\n", "\n", "", "if", "args", ".", "model_name_or_path", ":", "\n", "        ", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", ",", "\n", ")", "\n", "\n", "# modify head head with for 2 classes", "\n", "if", "args", ".", "model_type", "==", "'gpt2_double'", ":", "\n", "            ", "if", "'checkpoint'", "not", "in", "args", ".", "model_name_or_path", ":", "\n", "                ", "config", ".", "num_labels", "=", "2", "\n", "config", ".", "summary_type", "=", "'last'", "\n", "model", ".", "multiple_choice_head", "=", "SequenceSummary", "(", "config", ")", "\n", "", "", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Training new model from scratch\"", ")", "\n", "model", "=", "model_class", "(", "config", "=", "config", ")", "\n", "\n", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "if", "args", ".", "model_name_or_path", "==", "'openai-gpt'", ":", "\n", "        ", "tokenizer", ".", "add_special_tokens", "(", "{", "'bos_token'", ":", "'<|endoftext|>'", "}", ")", "\n", "tokenizer", ".", "add_special_tokens", "(", "{", "'eos_token'", ":", "'<|endoftext|>'", "}", ")", "\n", "", "elif", "args", ".", "model_name_or_path", "==", "'gpt2'", ":", "\n", "        ", "pass", "\n", "\n", "", "return", "model", ",", "tokenizer", ",", "model_class", ",", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.None.main.get_training_info": [[134, 155], ["os.path.exists", "int", "logger.info", "logger.info", "logger.info", "logger.info", "[].split", "logger.info", "len", "len", "args.model_name_or_path.split"], "function", ["None"], ["", "def", "get_training_info", "(", "dataloader", ",", "args", ")", ":", "\n", "    ", "global_step", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "args", ".", "model_name_or_path", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ":", "\n", "        ", "try", ":", "\n", "# set global_step to gobal_step of last saved checkpoint from model path", "\n", "            ", "checkpoint_suffix", "=", "args", ".", "model_name_or_path", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "0", "]", "\n", "global_step", "=", "int", "(", "checkpoint_suffix", ")", "\n", "epochs_trained", "=", "global_step", "//", "(", "len", "(", "dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "steps_trained_in_current_epoch", "=", "global_step", "%", "(", "len", "(", "dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "\n", "logger", ".", "info", "(", "\"  Continuing training from checkpoint, will skip to saved global_step\"", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from epoch %d\"", ",", "epochs_trained", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from global step %d\"", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"  Will skip the first %d steps in the first epoch\"", ",", "steps_trained_in_current_epoch", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "logger", ".", "info", "(", "\"  Starting fine-tuning.\"", ")", "\n", "", "", "return", "global_step", ",", "epochs_trained", ",", "steps_trained_in_current_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.None.main.train_epoch": [[157, 302], ["tqdm.tqdm", "enumerate", "inputs.to.to", "labels.to.to", "model.train", "loss.mean.item", "util.model.compute_label_position_loss.item", "model", "model", "util.model.compute_label_position_loss", "loss.mean.mean", "loss.mean.backward", "loss_lm.mean.item", "loss_mc.mean.item", "optimizer.step", "scheduler.step", "model.zero_grad", "tqdm.tqdm.close", "ImportError", "loss_lm.mean.mean", "loss_mc.mean.mean", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "tb_writer.add_scalar", "tb_writer.add_scalar", "tb_writer.add_scalar", "mc_labels.to.to", "amp.master_params", "model.parameters", "util.model.compute_gpt2_weights_norm", "util.model.compute_gpt2_weights_norm.items", "util.model.extract_gpt2_weights", "util.model.extract_gpt2_weights.keys", "tb_writer.add_scalar", "tb_writer.add_scalar", "ipdb.set_trace", "evaluate.items", "main.evaluate", "evaluate.items", "tb_writer.add_scalar", "numpy.mean", "numpy.mean", "tb_writer.add_scalar", "tb_writer.add_scalar", "scheduler.get_lr", "logger.info", "util.model.save_checkpoint", "logger.info", "util.model.save_checkpoint", "tb_writer.add_scalar", "numpy.abs", "numpy.abs", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.None.main.train", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model.compute_label_position_loss", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model.compute_gpt2_weights_norm", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model.extract_gpt2_weights", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.None.main.evaluate", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model.save_checkpoint", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model.save_checkpoint"], ["", "def", "train_epoch", "(", "model", ",", "tokenizer", ",", "optimizer", ",", "scheduler", ",", "train_dataloader", ",", "tr_loss", ",", "logging_loss", ",", "tr_loss_lm", ",", "logging_loss_lm", ",", "tr_loss_mc", ",", "logging_loss_mc", ",", "global_step", ",", "\n", "steps_trained_in_current_epoch", ",", "tb_writer", ",", "args", ",", "best_checkpoint_acc", ",", "tr_loss_label", ",", "logging_loss_label", ",", "logged_weights", ",", "initial_weights", ")", ":", "\n", "    ", "\"\"\"train one epoch\"\"\"", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "\n", "", "", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "        ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "            ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "if", "'gpt2'", "in", "args", ".", "model_type", ":", "\n", "            ", "if", "args", ".", "model_type", "==", "'gpt2'", ":", "\n", "                ", "inputs", ",", "labels", "=", "(", "batch", ",", "batch", ")", "\n", "", "elif", "args", ".", "model_type", "==", "'gpt2_double'", ":", "\n", "                ", "inputs", ",", "labels", "=", "batch", "[", "0", "]", ",", "batch", "[", "0", "]", "\n", "mc_labels", "=", "batch", "[", "1", "]", "\n", "mc_labels", "=", "mc_labels", ".", "to", "(", "args", ".", "device", ")", "\n", "", "", "else", ":", "\n", "            ", "inputs", ",", "labels", "=", "batch", "[", "0", "]", ",", "batch", "[", "1", "]", "\n", "\n", "", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# ipdb.set_trace()", "\n", "model", ".", "train", "(", ")", "\n", "if", "args", ".", "model_type", "==", "'gpt2_double'", ":", "\n", "            ", "outputs", "=", "model", "(", "inputs", ",", "labels", "=", "labels", ",", "mc_labels", "=", "mc_labels", ")", "\n", "loss_lm", "=", "outputs", "[", "0", "]", "\n", "loss_mc", "=", "outputs", "[", "1", "]", "\n", "loss", "=", "loss_lm", "+", "loss_mc", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "model", "(", "inputs", ",", "labels", "=", "labels", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "logits", "=", "outputs", "[", "1", "]", "\n", "step_loss_label", "=", "compute_label_position_loss", "(", "logits", ",", "inputs", ",", "labels", ",", "tokenizer", ",", "args", ")", "\n", "\n", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "            ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "if", "args", ".", "model_type", "==", "'gpt2_double'", ":", "\n", "                ", "loss_lm", "=", "loss_lm", ".", "mean", "(", ")", "\n", "loss_mc", "=", "loss_mc", ".", "mean", "(", ")", "\n", "", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "            ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "step_loss_label", "=", "step_loss_label", "/", "args", ".", "gradient_accumulation_steps", "\n", "if", "args", ".", "model_type", "==", "'gpt2_double'", ":", "\n", "                ", "loss_lm", "=", "loss_lm", "/", "args", ".", "gradient_accumulation_steps", "\n", "loss_mc", "=", "loss_mc", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "", "if", "args", ".", "fp16", ":", "\n", "            ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "tr_loss_label", "+=", "step_loss_label", ".", "item", "(", ")", "\n", "\n", "if", "args", ".", "model_type", "==", "'gpt2_double'", ":", "\n", "            ", "tr_loss_lm", "+=", "loss_lm", ".", "item", "(", ")", "\n", "tr_loss_mc", "+=", "loss_mc", ".", "item", "(", ")", "\n", "\n", "", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "            ", "if", "args", ".", "fp16", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "results", "=", "{", "}", "\n", "# Log metrics", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                ", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "\n", "                    ", "for", "split", "in", "args", ".", "eval_splits", ":", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "split", "=", "split", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\"metrics/{}/{}\"", ".", "format", "(", "split", ",", "key", ")", ",", "value", ",", "global_step", ")", "\n", "\n", "", "", "model_result", "=", "{", "}", "\n", "model_result", "=", "compute_gpt2_weights_norm", "(", "model", ",", "model_result", ")", "\n", "\n", "for", "key", ",", "value", "in", "model_result", ".", "items", "(", ")", ":", "\n", "                        ", "tb_writer", ".", "add_scalar", "(", "\"model/{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "\n", "", "weights", "=", "extract_gpt2_weights", "(", "model", ")", "\n", "for", "k", "in", "weights", ".", "keys", "(", ")", ":", "\n", "                        ", "aggregate_shift", "=", "np", ".", "mean", "(", "np", ".", "abs", "(", "weights", "[", "k", "]", "-", "logged_weights", "[", "k", "]", ")", ")", "\n", "aggregate_shift_percentage", "=", "np", ".", "mean", "(", "\n", "np", ".", "abs", "(", "weights", "[", "k", "]", "-", "logged_weights", "[", "k", "]", ")", "/", "np", ".", "abs", "(", "initial_weights", "[", "k", "]", ")", ")", "\n", "tb_writer", ".", "add_scalar", "(", "f\"model/aggregate_shift_{k}\"", ",", "aggregate_shift", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "f\"model/aggregate_shift_percentage_{k}\"", ",", "aggregate_shift_percentage", ",", "global_step", ")", "\n", "logged_weights", "[", "k", "]", "=", "weights", "[", "k", "]", "\n", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "if", "args", ".", "model_type", "==", "'gpt2_double'", ":", "\n", "                    ", "tb_writer", ".", "add_scalar", "(", "\"loss_lm\"", ",", "(", "tr_loss_lm", "-", "logging_loss_lm", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss_mc\"", ",", "(", "tr_loss_mc", "-", "logging_loss_mc", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "# else:", "\n", "", "tb_writer", ".", "add_scalar", "(", "\"loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "if", "(", "tr_loss_label", "-", "logging_loss_label", ")", "==", "0", ":", "\n", "                    ", "ipdb", ".", "set_trace", "(", ")", "\n", "", "tb_writer", ".", "add_scalar", "(", "\"loss_label\"", ",", "(", "tr_loss_label", "-", "logging_loss_label", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "logging_loss_lm", "=", "tr_loss_lm", "\n", "logging_loss_mc", "=", "tr_loss_mc", "\n", "logging_loss_label", "=", "tr_loss_label", "\n", "\n", "# # save checkpoint", "\n", "", "step_metric", "=", "'corr'", "if", "args", ".", "subtask", "==", "'cola'", "else", "'acc'", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "evaluate_during_training", ":", "\n", "                    ", "step_performance", "=", "None", "\n", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "                        ", "if", "step_metric", "in", "k", ":", "\n", "                            ", "step_performance", "=", "v", "\n", "", "", "if", "step_performance", "is", "None", ":", "\n", "                        ", "step_performance", "=", "results", "[", "'loss'", "]", "\n", "step_metric", "=", "'loss'", "\n", "\n", "", "if", "step_metric", "is", "not", "'loss'", "and", "step_performance", ">", "best_checkpoint_acc", ":", "\n", "                        ", "logger", ".", "info", "(", "f\"found a better checkpoint @ {global_step}: acc={step_performance}\"", ")", "\n", "best_checkpoint_acc", "=", "step_performance", "\n", "save_checkpoint", "(", "model", ",", "optimizer", ",", "scheduler", ",", "tokenizer", ",", "args", ",", "global_step", ")", "\n", "", "else", ":", "\n", "                        ", "logger", ".", "info", "(", "f\"found a better checkpoint @ {global_step}: loss={step_performance}\"", ")", "\n", "best_checkpoint_acc", "=", "step_performance", "\n", "save_checkpoint", "(", "model", ",", "optimizer", ",", "scheduler", ",", "tokenizer", ",", "args", ",", "global_step", ")", "\n", "\n", "", "", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "return", "model", ",", "optimizer", ",", "scheduler", ",", "global_step", ",", "tr_loss", ",", "logging_loss", ",", "tr_loss_lm", ",", "logging_loss_lm", ",", "tr_loss_mc", ",", "logging_loss_mc", ",", "best_checkpoint_acc", ",", "tr_loss_label", ",", "logging_loss_label", ",", "logged_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.None.main.train": [[304, 398], ["data.dataset.language_model.get_dataloader", "util.language_model.get_optimizer_scheduler", "util.model.compute_gpt2_weights_norm", "util.model.compute_gpt2_weights_norm.items", "util.model.extract_gpt2_weights", "util.model.extract_gpt2_weights", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "main.get_training_info", "model_to_resize.resize_token_embeddings", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "SummaryWriter", "SummaryWriter.add_scalar", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "hasattr", "len", "int", "main.train_epoch", "SummaryWriter.close", "torch.distributed.get_world_size", "len", "tqdm.trange.close", "len", "ImportError", "len", "args.output_dir.split"], "function", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.get_dataloader", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.language_model.get_optimizer_scheduler", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model.compute_gpt2_weights_norm", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model.extract_gpt2_weights", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model.extract_gpt2_weights", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.None.main.get_training_info", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.None.main.train_epoch"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", "'./runs/{}'", ".", "format", "(", "'/'", ".", "join", "(", "args", ".", "output_dir", ".", "split", "(", "'/'", ")", "[", "1", ":", "]", ")", ")", ")", "\n", "\n", "# Prepare dataloader", "\n", "", "train_dataloader", ",", "args", "=", "get_dataloader", "(", "train_dataset", ",", "tokenizer", ",", "args", ")", "\n", "\n", "# total iteration and batch size", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "", "total_batch_size", "=", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "\n", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "optimizer", ",", "scheduler", "=", "get_optimizer_scheduler", "(", "args", ",", "model", ",", "t_total", ")", "\n", "\n", "# compute model params norm before training", "\n", "model_result", "=", "{", "}", "\n", "model_result", "=", "compute_gpt2_weights_norm", "(", "model", ",", "model_result", ")", "\n", "for", "key", ",", "value", "in", "model_result", ".", "items", "(", ")", ":", "\n", "        ", "tb_writer", ".", "add_scalar", "(", "\"model/{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "0", ")", "\n", "\n", "", "logged_weights", "=", "extract_gpt2_weights", "(", "model", ")", "\n", "initial_weights", "=", "extract_gpt2_weights", "(", "model", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = {}\"", ".", "format", "(", "len", "(", "train_dataset", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = {}\"", ".", "format", "(", "args", ".", "num_train_epochs", ")", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = {}\"", ".", "format", "(", "args", ".", "per_gpu_train_batch_size", ")", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = {}\"", ".", "format", "(", "total_batch_size", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = {}\"", ".", "format", "(", "args", ".", "gradient_accumulation_steps", ")", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = {}\"", ".", "format", "(", "t_total", ")", ")", "\n", "\n", "global_step", ",", "epochs_trained", ",", "steps_trained_in_current_epoch", "=", "get_training_info", "(", "train_dataloader", ",", "args", ")", "\n", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "tr_loss_lm", ",", "logging_loss_lm", "=", "0.0", ",", "0.0", "\n", "tr_loss_mc", ",", "logging_loss_mc", "=", "0.0", ",", "0.0", "\n", "tr_loss_label", ",", "logging_loss_label", "=", "0.0", ",", "0.0", "\n", "best_checkpoint_acc", "=", "0.0", "\n", "\n", "model_to_resize", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_resize", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "\n", ")", "\n", "\n", "for", "_", "in", "train_iterator", ":", "\n", "\n", "        ", "model", ",", "optimizer", ",", "scheduler", ",", "global_step", ",", "tr_loss", ",", "logging_loss", ",", "tr_loss_lm", ",", "logging_loss_lm", ",", "tr_loss_mc", ",", "logging_loss_mc", ",", "best_checkpoint_acc", ",", "tr_loss_label", ",", "logging_loss_label", ",", "logged_weights", "=", "train_epoch", "(", "\n", "model", ",", "tokenizer", ",", "optimizer", ",", "\n", "scheduler", ",", "train_dataloader", ",", "\n", "tr_loss", ",", "logging_loss", ",", "\n", "tr_loss_lm", ",", "logging_loss_lm", ",", "\n", "tr_loss_mc", ",", "logging_loss_mc", ",", "\n", "global_step", ",", "\n", "steps_trained_in_current_epoch", ",", "\n", "tb_writer", ",", "args", ",", "best_checkpoint_acc", ",", "tr_loss_label", ",", "logging_loss_label", ",", "logged_weights", ",", "initial_weights", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.None.main.evaluate": [[400, 560], ["data.dataset.language_model.load_and_cache_examples", "data.dataset.language_model.get_dataloader", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "tqdm.tqdm", "torch.exp", "os.path.join", "os.path.join", "os.makedirs", "torch.nn.DataParallel", "inputs.to.to", "labels.to.to", "torch.tensor", "TypeError", "open", "logger.info", "sorted", "open", "len", "torch.no_grad", "total_pred.extend", "total_ground.extend", "util.metrics.compute_term_polarity_metrics", "util.metrics.compute_sst2_metrics.keys", "logger.info", "writer.write", "TypeError", "TypeError", "TypeError", "util.metrics.compute_aspect_term_metrics", "str", "zip", "mc_labels.to.to", "util.metrics.compute_single_term_polarity", "util.metrics.compute_category_polarity_metrics", "TypeError", "[].strip", "[].strip", "[].strip", "[].strip", "util.metrics.sort_output", "util.metrics.sort_output", "writer.write", "zip", "zip", "util.metrics.compute_aspect_term", "util.metrics.compute_aspect_category_metrics", "str", "[].strip", "[].strip", "writer.write", "[].strip", "[].strip", "util.metrics.sort_output", "writer.write", "util.metrics.compute_single_category_polarity", "util.metrics.compute_aspect_term_aspect_category_metrics", "util.metrics.compute_aspect_category", "util.metrics.compute_sentiment_metrics", "[].split", "[].split", "[].split", "[].split", "util.metrics.compute_aspect_term_aspect_category", "util.metrics.compute_sst2_metrics", "[].split", "[].split", "[].split", "[].split", "util.metrics.compute_sentiment", "util.metrics.compute_sst2", "l_t.split", "l_p.split", "l_t.split", "l_p.split", "l_t.split", "l_p.split", "l_t.split", "l_p.split"], "function", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.load_and_cache_examples", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.get_dataloader", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_term_polarity_metrics", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_aspect_term_metrics", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_single_term_polarity", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_category_polarity_metrics", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.sort_output", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.sort_output", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_aspect_term", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_aspect_category_metrics", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.sort_output", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_single_category_polarity", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_aspect_term_aspect_category_metrics", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_aspect_category", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_sentiment_metrics", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_aspect_term_aspect_category", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_sst2_metrics", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_sentiment", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_sst2"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ",", "split", "=", "'val'", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "\n", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "True", ",", "split", "=", "split", ")", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Prepare dataloader", "\n", "", "eval_dataloader", ",", "args", "=", "get_dataloader", "(", "eval_dataset", ",", "tokenizer", ",", "args", ",", "split", "=", "split", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} {} *****\"", ".", "format", "(", "split", ",", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = {}\"", ".", "format", "(", "len", "(", "eval_dataset", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = {}\"", ".", "format", "(", "args", ".", "eval_batch_size", ")", ")", "\n", "logger", ".", "info", "(", "\" Confidence threshold = {}\"", ".", "format", "(", "args", ".", "confidence_threshold", ")", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "total_pred", "=", "[", "]", "\n", "total_ground", "=", "[", "]", "\n", "result", "=", "{", "}", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "\n", "        ", "if", "'gpt2'", "in", "args", ".", "model_type", ":", "\n", "            ", "if", "args", ".", "model_type", "==", "'gpt2'", ":", "\n", "                ", "inputs", ",", "labels", "=", "(", "batch", ",", "batch", ")", "\n", "", "elif", "args", ".", "model_type", "==", "'gpt2_double'", ":", "\n", "                ", "inputs", ",", "labels", "=", "batch", "[", "0", "]", ",", "batch", "[", "0", "]", "\n", "mc_labels", "=", "batch", "[", "1", "]", "\n", "mc_labels", "=", "mc_labels", ".", "to", "(", "args", ".", "device", ")", "\n", "", "", "elif", "'t5'", "in", "args", ".", "model_type", ":", "\n", "            ", "inputs", ",", "labels", "=", "batch", "[", "0", "]", ",", "batch", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'unknown model type'", ")", "\n", "", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "lm_loss", "=", "0", "\n", "if", "'gpt2'", "in", "args", ".", "model_type", ":", "\n", "                ", "if", "args", ".", "subtask", "==", "'single_term_polarity'", ":", "\n", "                    ", "batch_pred", ",", "batch_ground", "=", "compute_single_term_polarity", "(", "model", ",", "inputs", ",", "labels", ",", "tokenizer", ",", "args", ")", "\n", "", "elif", "args", ".", "subtask", "==", "'aspect_term'", ":", "\n", "                    ", "batch_pred", ",", "batch_ground", "=", "compute_aspect_term", "(", "model", ",", "inputs", ",", "labels", ",", "tokenizer", ",", "args", ")", "\n", "", "elif", "args", ".", "subtask", "==", "'single_category_polarity'", ":", "\n", "                    ", "batch_pred", ",", "batch_ground", "=", "compute_single_category_polarity", "(", "model", ",", "inputs", ",", "labels", ",", "tokenizer", ",", "args", ")", "\n", "", "elif", "args", ".", "subtask", "==", "'aspect_category'", ":", "\n", "                    ", "batch_pred", ",", "batch_ground", "=", "compute_aspect_category", "(", "model", ",", "inputs", ",", "labels", ",", "tokenizer", ",", "args", ")", "\n", "", "elif", "args", ".", "subtask", "==", "'aspect_term_aspect_category'", ":", "\n", "                    ", "batch_pred", ",", "batch_ground", "=", "compute_aspect_term_aspect_category", "(", "model", ",", "inputs", ",", "labels", ",", "tokenizer", ",", "args", ")", "\n", "", "elif", "args", ".", "subtask", "==", "'sentiment'", ":", "\n", "                    ", "batch_pred", ",", "batch_ground", "=", "compute_sentiment", "(", "model", ",", "inputs", ",", "labels", ",", "tokenizer", ",", "args", ")", "\n", "", "elif", "args", ".", "subtask", "==", "'sst2'", ":", "\n", "                    ", "batch_pred", ",", "batch_ground", "=", "compute_sst2", "(", "model", ",", "inputs", ",", "labels", ",", "tokenizer", ",", "args", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "\"unknown subtask\"", ")", "\n", "\n", "", "total_pred", ".", "extend", "(", "batch_pred", ")", "\n", "total_ground", ".", "extend", "(", "batch_ground", ")", "\n", "eval_loss", "+=", "lm_loss", "\n", "", "nb_eval_steps", "+=", "1", "\n", "\n", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "exp", "(", "torch", ".", "tensor", "(", "eval_loss", ")", ")", "\n", "result", "[", "'loss'", "]", "=", "eval_loss", "\n", "result", "[", "'perplexity'", "]", "=", "perplexity", "\n", "\n", "if", "'gpt2'", "in", "args", ".", "model_type", ":", "\n", "        ", "if", "args", ".", "subtask", "==", "'single_term_polarity'", ":", "\n", "            ", "result", "=", "compute_term_polarity_metrics", "(", "result", ",", "labels", "=", "total_ground", ",", "\n", "predictions", "=", "total_pred", ")", "\n", "", "elif", "args", ".", "subtask", "==", "'aspect_term'", ":", "\n", "            ", "result", "=", "compute_aspect_term_metrics", "(", "result", ",", "labels", "=", "total_ground", ",", "\n", "predictions", "=", "total_pred", ")", "\n", "", "elif", "args", ".", "subtask", "==", "'single_category_polarity'", ":", "\n", "            ", "result", "=", "compute_category_polarity_metrics", "(", "result", ",", "labels", "=", "total_ground", ",", "\n", "predictions", "=", "total_pred", ")", "\n", "", "elif", "args", ".", "subtask", "==", "'aspect_category'", ":", "\n", "            ", "result", "=", "compute_aspect_category_metrics", "(", "result", ",", "labels", "=", "total_ground", ",", "\n", "predictions", "=", "total_pred", ")", "\n", "", "elif", "args", ".", "subtask", "==", "'aspect_term_aspect_category'", ":", "\n", "            ", "result", "=", "compute_aspect_term_aspect_category_metrics", "(", "result", ",", "labels", "=", "total_ground", ",", "\n", "predictions", "=", "total_pred", ")", "\n", "", "elif", "args", ".", "subtask", "==", "'sentiment'", ":", "\n", "            ", "result", "=", "compute_sentiment_metrics", "(", "result", ",", "labels", "=", "total_ground", ",", "\n", "predictions", "=", "total_pred", ")", "\n", "", "elif", "args", ".", "subtask", "==", "'sst2'", ":", "\n", "            ", "result", "=", "compute_sst2_metrics", "(", "result", ",", "labels", "=", "total_ground", ",", "\n", "predictions", "=", "total_pred", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "'unknown subtask'", ")", "\n", "\n", "", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "\"eval_results_{}.txt\"", ".", "format", "(", "split", ")", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "if", "'term'", "in", "args", ".", "subtask", ":", "\n", "        ", "subtask_st", "=", "'<|term|>'", "\n", "subtask_et", "=", "'<|endofterm|>'", "\n", "", "elif", "'category'", "in", "args", ".", "subtask", ":", "\n", "        ", "subtask_st", "=", "'<|category|>'", "\n", "subtask_et", "=", "'<|endofcategory|>'", "\n", "", "elif", "'sentiment'", "in", "args", ".", "subtask", ":", "\n", "        ", "subtask_st", "=", "'<|sentiment|>'", "\n", "subtask_et", "=", "'<|endofsentiment|>'", "\n", "", "elif", "'sst2'", "in", "args", ".", "subtask", ":", "\n", "        ", "subtask_st", "=", "'<|sentiment|>'", "\n", "subtask_et", "=", "'<|endofsentiment|>'", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "'unknown subtask'", ")", "\n", "\n", "# write generated output", "\n", "", "output_generation_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "\"eval_generations_{}.txt\"", ".", "format", "(", "split", ")", ")", "\n", "with", "open", "(", "output_generation_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "if", "'gpt2'", "in", "args", ".", "model_type", ":", "\n", "            ", "if", "args", ".", "subtask", "==", "'aspect_term_aspect_category'", ":", "\n", "                ", "for", "l_p", ",", "l_t", "in", "zip", "(", "total_pred", ",", "total_ground", ")", ":", "\n", "                    ", "true_term", "=", "l_t", ".", "split", "(", "'<|term|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofterm|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "pred_term", "=", "l_p", ".", "split", "(", "'<|term|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofterm|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "true_category", "=", "l_t", ".", "split", "(", "'<|category|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofcategory|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "pred_category", "=", "l_p", ".", "split", "(", "'<|category|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofcategory|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "true_term_sorted", ",", "pred_term_sorted", "=", "sort_output", "(", "true_term", ",", "pred_term", ")", "\n", "true_category_sorted", ",", "pred_category_sorted", "=", "sort_output", "(", "true_category", ",", "pred_category", ")", "\n", "\n", "true_joint", "=", "f\"<|term|> {true_term_sorted} <|endofterm|> <|category|> {true_category_sorted} <|endofcategory|>\"", "\n", "pred_joint", "=", "f\"<|term|> {pred_term_sorted} <|endofterm|> <|category|> {pred_category_sorted} <|endofcategory|>\"", "\n", "correct", "=", "'True'", "if", "pred_joint", "==", "true_joint", "else", "'False'", "\n", "writer", ".", "write", "(", "f\"{l_p}\\t|\\t{pred_joint}\\t|\\t{true_joint}\\t|\\t{correct}\\n\"", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "'aspect'", "not", "in", "args", ".", "subtask", ":", "\n", "                    ", "for", "l_p", ",", "l_t", "in", "zip", "(", "total_pred", ",", "total_ground", ")", ":", "\n", "                        ", "true_target", "=", "l_t", ".", "split", "(", "subtask_st", ")", "[", "-", "1", "]", ".", "split", "(", "subtask_et", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "pred_target", "=", "l_p", ".", "split", "(", "subtask_st", ")", "[", "-", "1", "]", ".", "split", "(", "subtask_et", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "correct", "=", "'True'", "if", "pred_target", "==", "true_target", "else", "'False'", "\n", "writer", ".", "write", "(", "f\"{l_p}\\t|\\t{pred_target}\\t|\\t{true_target}\\t|\\t{correct}\\n\"", ")", "\n", "", "", "else", ":", "\n", "                    ", "for", "l_p", ",", "l_t", "in", "zip", "(", "total_pred", ",", "total_ground", ")", ":", "\n", "                        ", "true_term", "=", "l_t", ".", "split", "(", "subtask_st", ")", "[", "-", "1", "]", ".", "split", "(", "subtask_et", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "pred_term", "=", "l_p", ".", "split", "(", "subtask_st", ")", "[", "-", "1", "]", ".", "split", "(", "subtask_et", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "true_term_sorted", ",", "pred_term_sorted", "=", "sort_output", "(", "true_term", ",", "pred_term", ")", "\n", "correct", "=", "'True'", "if", "pred_term_sorted", "==", "true_term_sorted", "else", "'False'", "\n", "writer", ".", "write", "(", "f\"{l_p}\\t|\\t{pred_term_sorted}\\t|\\t{true_term_sorted}\\t|\\t{correct}\\n\"", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'unknown model type'", ")", "\n", "\n", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.None.main.main": [[562, 653], ["util.gpt2_args_parser.ArgsParser().parse", "ArgsParser().parse.eval_splits.strip().split", "util.model.set_seed", "logging.basicConfig", "logger.warning", "main.get_model_tokenizer", "logger.info", "ValueError", "util.model._sorted_checkpoints", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "torch.distributed.barrier", "data.dataset.language_model.load_and_cache_examples", "main.train", "logger.info", "util.gpt2_args_parser.ArgsParser", "ArgsParser().parse.eval_splits.strip", "len", "logger.info", "torch.device", "torch.device", "torch.distributed.barrier", "torch.distributed.barrier", "model_class.from_pretrained", "model_class.from_pretrained.to", "main.evaluate", "dict", "results.update", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "dict.items"], "function", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.gpt2_args_parser.ArgsParser.parse", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model.set_seed", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.None.main.get_model_tokenizer", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model._sorted_checkpoints", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.load_and_cache_examples", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.None.main.train", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.None.main.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "ArgsParser", "(", ")", ".", "parse", "(", ")", "\n", "\n", "\n", "args", ".", "eval_splits", "=", "args", ".", "eval_splits", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "if", "args", ".", "eval_data_file", "is", "None", "and", "args", ".", "do_eval", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"--eval_data_file should be specified when do_eval is true\"", "\n", ")", "\n", "", "if", "args", ".", "should_continue", ":", "\n", "        ", "sorted_checkpoints", "=", "_sorted_checkpoints", "(", "args", ")", "\n", "if", "len", "(", "sorted_checkpoints", ")", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"--should_continue is true, but no checkpoint found in --output_dir\"", ")", "\n", "", "else", ":", "\n", "            ", "args", ".", "model_name_or_path", "=", "sorted_checkpoints", "[", "-", "1", "]", "\n", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "if", "args", ".", "no_cuda", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "else", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "index", "=", "args", ".", "device", ")", "\n", "", "args", ".", "n_gpu", "=", "1", "\n", "", "else", ":", "# initialize distributed training", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# set random seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# if not the first process, do not load pretrained model & vocab", "\n", "\n", "", "model", ",", "tokenizer", ",", "model_class", ",", "args", "=", "get_model_tokenizer", "(", "args", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# finish barrier, when first process has loaded pretrained model & vocab", "\n", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters {}\"", ".", "format", "(", "args", ")", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# only first process will preprocess data/caching", "\n", "\n", "", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# end of barrier", "\n", "\n", "", "global_step", ",", "train_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = {}, average loss = {}\"", ".", "format", "(", "global_step", ",", "train_loss", ")", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "eval_checkpoint", "]", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "prefix", "=", "checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "if", "checkpoint", ".", "find", "(", "\"checkpoint\"", ")", "!=", "-", "1", "else", "\"\"", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "for", "split", "in", "args", ".", "eval_splits", ":", "\n", "                ", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "prefix", ",", "split", "=", "split", ")", "\n", "result", "=", "dict", "(", "(", "k", "+", "\"_{}\"", ".", "format", "(", "global_step", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.Attention.__init__": [[121, 144], ["torch.Module.__init__", "modeling_gpt2.Attention.register_buffer", "modeling_gpt2.Attention.register_buffer", "transformers.modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "set", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "transformers.modeling_utils.Conv1D", "transformers.modeling_utils.Conv1D", "transformers.modeling_utils.Conv1D", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.LineByLineTextDataset_gpt2_double.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ",", "is_cross_attention", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "register_buffer", "(", "\n", "\"bias\"", ",", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "(", "n_ctx", ",", "n_ctx", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ")", ".", "view", "(", "1", ",", "1", ",", "n_ctx", ",", "n_ctx", ")", "\n", ")", "\n", "self", ".", "register_buffer", "(", "\"masked_bias\"", ",", "torch", ".", "tensor", "(", "-", "1e4", ")", ")", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "is_cross_attention", "=", "is_cross_attention", "\n", "if", "self", ".", "is_cross_attention", ":", "\n", "            ", "self", ".", "c_attn", "=", "Conv1D", "(", "2", "*", "n_state", ",", "nx", ")", "\n", "self", ".", "q_attn", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "c_attn", "=", "Conv1D", "(", "3", "*", "n_state", ",", "nx", ")", "\n", "", "self", ".", "c_proj", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "attn_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.Attention.prune_heads": [[145, 161], ["transformers.modeling_utils.find_pruneable_heads_and_indices", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformers.modeling_utils.prune_conv1d_layer", "transformers.modeling_utils.prune_conv1d_layer", "modeling_gpt2.Attention.pruned_heads.union", "len", "len", "len"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "heads", ",", "index", "=", "find_pruneable_heads_and_indices", "(", "\n", "heads", ",", "self", ".", "n_head", ",", "self", ".", "split_size", "//", "self", ".", "n_head", ",", "self", ".", "pruned_heads", "\n", ")", "\n", "index_attn", "=", "torch", ".", "cat", "(", "[", "index", ",", "index", "+", "self", ".", "split_size", ",", "index", "+", "(", "2", "*", "self", ".", "split_size", ")", "]", ")", "\n", "\n", "# Prune conv1d layers", "\n", "self", ".", "c_attn", "=", "prune_conv1d_layer", "(", "self", ".", "c_attn", ",", "index_attn", ",", "dim", "=", "1", ")", "\n", "self", ".", "c_proj", "=", "prune_conv1d_layer", "(", "self", ".", "c_proj", ",", "index", ",", "dim", "=", "0", ")", "\n", "\n", "# Update hyper params", "\n", "self", ".", "split_size", "=", "(", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "*", "(", "self", ".", "n_head", "-", "len", "(", "heads", ")", ")", "\n", "self", ".", "n_head", "=", "self", ".", "n_head", "-", "len", "(", "heads", ")", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.Attention._attn": [[162, 188], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "modeling_gpt2.Attention.attn_dropout", "torch.where.size", "torch.where.size", "torch.where.size", "torch.where.size", "torch.where", "torch.where", "torch.where", "torch.where", "torch.Softmax", "torch.Softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "outputs.append", "mask.bool", "modeling_gpt2.Attention.masked_bias.to", "float", "v.size"], "methods", ["None"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ",", "output_attentions", "=", "False", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "(", "float", "(", "v", ".", "size", "(", "-", "1", ")", ")", "**", "0.5", ")", "\n", "", "nd", ",", "ns", "=", "w", ".", "size", "(", "-", "2", ")", ",", "w", ".", "size", "(", "-", "1", ")", "\n", "\n", "if", "not", "self", ".", "is_cross_attention", ":", "\n", "# if only \"normal\" attention layer implements causal mask", "\n", "            ", "mask", "=", "self", ".", "bias", "[", ":", ",", ":", ",", "ns", "-", "nd", ":", "ns", ",", ":", "ns", "]", "\n", "w", "=", "torch", ".", "where", "(", "mask", ".", "bool", "(", ")", ",", "w", ",", "self", ".", "masked_bias", ".", "to", "(", "w", ".", "dtype", ")", ")", "\n", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "            ", "w", "=", "w", "+", "attention_mask", "\n", "\n", "", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "w", "=", "w", "*", "head_mask", "\n", "\n", "", "outputs", "=", "[", "torch", ".", "matmul", "(", "w", ",", "v", ")", "]", "\n", "if", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "w", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.Attention.merge_heads": [[189, 193], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["None"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "x", ".", "size", "(", "-", "2", ")", "*", "x", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct merge_states", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.Attention.split_heads": [[194, 201], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "split_heads", "(", "self", ",", "x", ",", "k", "=", "False", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "n_head", ",", "x", ".", "size", "(", "-", "1", ")", "//", "self", ".", "n_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct split_states", "\n", "if", "k", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "# (batch, head, head_features, seq_length)", "\n", "", "else", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "# (batch, head, seq_length, head_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.Attention.forward": [[202, 245], ["modeling_gpt2.Attention.split_heads", "modeling_gpt2.Attention.split_heads", "modeling_gpt2.Attention.split_heads", "modeling_gpt2.Attention._attn", "modeling_gpt2.Attention.merge_heads", "modeling_gpt2.Attention.c_proj", "modeling_gpt2.Attention.resid_dropout", "hasattr", "modeling_gpt2.Attention.q_attn", "modeling_gpt2.Attention.c_attn().split", "modeling_gpt2.Attention.c_attn().split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer_past[].transpose", "modeling_gpt2.Attention.c_attn", "modeling_gpt2.Attention.c_attn", "torch.cat.transpose", "torch.cat.transpose"], "methods", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.Attention.split_heads", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.Attention.split_heads", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.Attention.split_heads", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.Attention._attn", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.Attention.merge_heads"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "layer_past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "assert", "hasattr", "(", "\n", "self", ",", "\"q_attn\"", "\n", ")", ",", "\"If class is used as cross attention, the weights `q_attn` have to be defined. Please make sure to instantiate class with `Attention(..., is_cross_attention=True)`.\"", "\n", "query", "=", "self", ".", "q_attn", "(", "hidden_states", ")", "\n", "key", ",", "value", "=", "self", ".", "c_attn", "(", "encoder_hidden_states", ")", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "attention_mask", "=", "encoder_attention_mask", "\n", "", "else", ":", "\n", "            ", "query", ",", "key", ",", "value", "=", "self", ".", "c_attn", "(", "hidden_states", ")", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "\n", "", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ",", "k", "=", "True", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "if", "layer_past", "is", "not", "None", ":", "\n", "            ", "past_key", ",", "past_value", "=", "layer_past", "[", "0", "]", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "layer_past", "[", "1", "]", "# transpose back cf below", "\n", "key", "=", "torch", ".", "cat", "(", "(", "past_key", ",", "key", ")", ",", "dim", "=", "-", "1", ")", "\n", "value", "=", "torch", ".", "cat", "(", "(", "past_value", ",", "value", ")", ",", "dim", "=", "-", "2", ")", "\n", "\n", "", "if", "use_cache", "is", "True", ":", "\n", "            ", "present", "=", "torch", ".", "stack", "(", "(", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "value", ")", ")", "# transpose to have same shapes for stacking", "\n", "", "else", ":", "\n", "            ", "present", "=", "(", "None", ",", ")", "\n", "\n", "", "attn_outputs", "=", "self", ".", "_attn", "(", "query", ",", "key", ",", "value", ",", "attention_mask", ",", "head_mask", ",", "output_attentions", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ")", "\n", "\n", "outputs", "=", "[", "a", ",", "present", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "# a, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.MLP.__init__": [[248, 255], ["torch.Module.__init__", "transformers.modeling_utils.Conv1D", "transformers.modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.LineByLineTextDataset_gpt2_double.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ")", ":", "# in MLP: n_state=3072 (4 * n_embd)", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "nx", ",", "n_state", ")", "\n", "self", ".", "act", "=", "ACT2FN", "[", "config", ".", "activation_function", "]", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.MLP.forward": [[256, 260], ["modeling_gpt2.MLP.act", "modeling_gpt2.MLP.c_proj", "modeling_gpt2.MLP.dropout", "modeling_gpt2.MLP.c_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "return", "self", ".", "dropout", "(", "h2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.Block.__init__": [[263, 274], ["torch.Module.__init__", "torch.LayerNorm", "torch.LayerNorm", "modeling_gpt2.Attention", "torch.LayerNorm", "torch.LayerNorm", "modeling_gpt2.MLP", "modeling_gpt2.Attention", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.LineByLineTextDataset_gpt2_double.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "hidden_size", "=", "config", ".", "n_embd", "\n", "inner_dim", "=", "config", ".", "n_inner", "if", "config", ".", "n_inner", "is", "not", "None", "else", "4", "*", "hidden_size", "\n", "self", ".", "ln_1", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "hidden_size", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "self", ".", "ln_2", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "if", "config", ".", "add_cross_attention", ":", "\n", "            ", "self", ".", "crossattention", "=", "Attention", "(", "hidden_size", ",", "n_ctx", ",", "config", ",", "scale", ",", "is_cross_attention", "=", "True", ")", "\n", "self", ".", "ln_cross_attn", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "", "self", ".", "mlp", "=", "MLP", "(", "inner_dim", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.Block.forward": [[275, 323], ["modeling_gpt2.Block.attn", "modeling_gpt2.Block.mlp", "modeling_gpt2.Block.ln_1", "hasattr", "modeling_gpt2.Block.crossattention", "modeling_gpt2.Block.ln_2", "modeling_gpt2.Block.ln_cross_attn"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "layer_past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "        ", "attn_outputs", "=", "self", ".", "attn", "(", "\n", "self", ".", "ln_1", "(", "hidden_states", ")", ",", "\n", "layer_past", "=", "layer_past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "attn_output", "=", "attn_outputs", "[", "0", "]", "# output_attn: a, present, (attentions)", "\n", "outputs", "=", "attn_outputs", "[", "1", ":", "]", "\n", "# residual connection", "\n", "hidden_states", "=", "attn_output", "+", "hidden_states", "\n", "\n", "if", "encoder_hidden_states", "is", "not", "None", ":", "\n", "# add one self-attention block for cross-attention", "\n", "            ", "assert", "hasattr", "(", "\n", "self", ",", "\"crossattention\"", "\n", ")", ",", "f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers by setting `config.add_cross_attention=True`\"", "\n", "cross_attn_outputs", "=", "self", ".", "crossattention", "(", "\n", "self", ".", "ln_cross_attn", "(", "hidden_states", ")", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_attention_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "attn_output", "=", "cross_attn_outputs", "[", "0", "]", "\n", "# residual connection", "\n", "hidden_states", "=", "hidden_states", "+", "attn_output", "\n", "outputs", "=", "outputs", "+", "cross_attn_outputs", "[", "1", ":", "]", "# add cross attentions if we output attention weights", "\n", "\n", "", "feed_forward_hidden_states", "=", "self", ".", "mlp", "(", "self", ".", "ln_2", "(", "hidden_states", ")", ")", "\n", "# residual connection", "\n", "hidden_states", "=", "hidden_states", "+", "feed_forward_hidden_states", "\n", "\n", "outputs", "=", "[", "hidden_states", "]", "+", "outputs", "\n", "return", "outputs", "# hidden_states, present, (cross_attentions, attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2PreTrainedModel.__init__": [[335, 337], ["transformers.modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.LineByLineTextDataset_gpt2_double.__init__"], ["def", "__init__", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2PreTrainedModel._init_weights": [[338, 349], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\"Initialize the weights.\"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ",", "Conv1D", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "Conv1D", ")", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2Model.__init__": [[482, 492], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.LayerNorm", "torch.LayerNorm", "modeling_gpt2.GPT2Model.init_weights", "modeling_gpt2.Block", "range"], "methods", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.LineByLineTextDataset_gpt2_double.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "wte", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "wpe", "=", "nn", ".", "Embedding", "(", "config", ".", "n_positions", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "Block", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "ln_f", "=", "nn", ".", "LayerNorm", "(", "config", ".", "n_embd", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2Model.get_input_embeddings": [[493, 495], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wte", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2Model.set_input_embeddings": [[496, 498], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "wte", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2Model._prune_heads": [[499, 505], ["heads_to_prune.items", "modeling_gpt2.GPT2Model.h[].attn.prune_heads"], "methods", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\"\n        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "h", "[", "layer", "]", ".", "attn", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2Model.forward": [[506, 680], ["transformers.file_utils.add_start_docstrings_to_model_forward", "transformers.file_utils.add_code_sample_docstrings", "modeling_gpt2.GPT2Model.get_head_mask", "modeling_gpt2.GPT2Model.wpe", "modeling_gpt2.GPT2Model.drop", "enumerate", "modeling_gpt2.GPT2Model.ln_f", "hidden_states.view.view.view", "transformers.modeling_outputs.BaseModelOutputWithPast", "warnings.warn", "kwargs.pop", "ValueError", "token_type_ids.view.view.view", "position_ids.unsqueeze().view.unsqueeze().view.view", "[].size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().view.unsqueeze().view.unsqueeze().view", "attention_mask.to.to.view", "attention_mask.to.to.to", "encoder_hidden_states.size", "modeling_gpt2.GPT2Model.invert_attention_mask", "modeling_gpt2.GPT2Model.wte", "modeling_gpt2.GPT2Model.wte", "zip", "getattr", "tuple", "list", "input_ids.view.view.size", "input_ids.view.view.view", "len", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "hidden_states.view.view.size", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "block", "kwargs.keys", "ValueError", "position_ids.unsqueeze().view.unsqueeze().view.unsqueeze", "modeling_gpt2.GPT2Model.forward.create_custom_forward"], "methods", ["None"], ["", "", "@", "add_start_docstrings_to_model_forward", "(", "GPT2_INPUTS_DOCSTRING", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "\"gpt2\"", ",", "\n", "output_type", "=", "BaseModelOutputWithPast", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "if", "\"past\"", "in", "kwargs", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"The `past` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\"", ",", "\n", "FutureWarning", ",", "\n", ")", "\n", "past_key_values", "=", "kwargs", ".", "pop", "(", "\"past\"", ")", "\n", "", "assert", "kwargs", "==", "{", "}", ",", "f\"Unexpected keyword arguments: {list(kwargs.keys())}.\"", "\n", "\n", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "batch_size", "=", "input_ids", ".", "shape", "[", "0", "]", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "batch_size", "=", "inputs_embeds", ".", "shape", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "if", "position_ids", "is", "not", "None", ":", "\n", "            ", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "", "if", "past_key_values", "is", "None", ":", "\n", "            ", "past_length", "=", "0", "\n", "past_key_values", "=", "[", "None", "]", "*", "len", "(", "self", ".", "h", ")", "\n", "", "else", ":", "\n", "            ", "past_length", "=", "past_key_values", "[", "0", "]", "[", "0", "]", ".", "size", "(", "-", "2", ")", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "position_ids", "=", "torch", ".", "arange", "(", "past_length", ",", "input_shape", "[", "-", "1", "]", "+", "past_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "# Attention mask.", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "assert", "batch_size", ">", "0", ",", "\"batch_size has to be defined and > 0\"", "\n", "attention_mask", "=", "attention_mask", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "attention_mask", "=", "attention_mask", ".", "to", "(", "dtype", "=", "self", ".", "dtype", ")", "# fp16 compatibility", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# If a 2D ou 3D attention mask is provided for the cross-attention", "\n", "# we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]", "\n", "", "if", "self", ".", "config", ".", "add_cross_attention", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "encoder_batch_size", ",", "encoder_sequence_length", ",", "_", "=", "encoder_hidden_states", ".", "size", "(", ")", "\n", "encoder_hidden_shape", "=", "(", "encoder_batch_size", ",", "encoder_sequence_length", ")", "\n", "if", "encoder_attention_mask", "is", "None", ":", "\n", "                ", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "encoder_hidden_shape", ",", "device", "=", "device", ")", "\n", "", "encoder_attention_mask", "=", "self", ".", "invert_attention_mask", "(", "encoder_attention_mask", ")", "\n", "", "else", ":", "\n", "            ", "encoder_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# head_mask has shape n_layer x batch x n_heads x N x N", "\n", "", "head_mask", "=", "self", ".", "get_head_mask", "(", "head_mask", ",", "self", ".", "config", ".", "n_layer", ")", "\n", "\n", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "wte", "(", "input_ids", ")", "\n", "", "position_embeds", "=", "self", ".", "wpe", "(", "position_ids", ")", "\n", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "\n", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_embeds", "=", "self", ".", "wte", "(", "token_type_ids", ")", "\n", "hidden_states", "=", "hidden_states", "+", "token_type_embeds", "\n", "\n", "", "hidden_states", "=", "self", ".", "drop", "(", "hidden_states", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "\n", "presents", "=", "(", ")", "if", "use_cache", "else", "None", "\n", "all_attentions", "=", "(", ")", "if", "output_attentions", "else", "None", "\n", "all_hidden_states", "=", "(", ")", "if", "output_hidden_states", "else", "None", "\n", "for", "i", ",", "(", "block", ",", "layer_past", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "h", ",", "past_key_values", ")", ")", ":", "\n", "            ", "if", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "\n", "", "if", "getattr", "(", "self", ".", "config", ",", "\"gradient_checkpointing\"", ",", "False", ")", ":", "\n", "\n", "                ", "def", "create_custom_forward", "(", "module", ")", ":", "\n", "                    ", "def", "custom_forward", "(", "*", "inputs", ")", ":", "\n", "# checkpointing only works with tuple returns, not with lists", "\n", "                        ", "return", "tuple", "(", "output", "for", "output", "in", "module", "(", "*", "inputs", ",", "use_cache", ",", "output_attentions", ")", ")", "\n", "\n", "", "return", "custom_forward", "\n", "\n", "", "outputs", "=", "torch", ".", "utils", ".", "checkpoint", ".", "checkpoint", "(", "\n", "create_custom_forward", "(", "block", ")", ",", "\n", "hidden_states", ",", "\n", "layer_past", ",", "\n", "attention_mask", ",", "\n", "head_mask", "[", "i", "]", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "block", "(", "\n", "hidden_states", ",", "\n", "layer_past", "=", "layer_past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", "[", "i", "]", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_attention_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "\n", "", "hidden_states", ",", "present", "=", "outputs", "[", ":", "2", "]", "\n", "if", "use_cache", "is", "True", ":", "\n", "                ", "presents", "=", "presents", "+", "(", "present", ",", ")", "\n", "\n", "", "if", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "outputs", "[", "2", "]", ",", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "ln_f", "(", "hidden_states", ")", "\n", "\n", "hidden_states", "=", "hidden_states", ".", "view", "(", "*", "output_shape", ")", "\n", "# Add last hidden state", "\n", "if", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "return", "tuple", "(", "v", "for", "v", "in", "[", "hidden_states", ",", "presents", ",", "all_hidden_states", ",", "all_attentions", "]", "if", "v", "is", "not", "None", ")", "\n", "\n", "", "return", "BaseModelOutputWithPast", "(", "\n", "last_hidden_state", "=", "hidden_states", ",", "\n", "past_key_values", "=", "presents", ",", "\n", "hidden_states", "=", "all_hidden_states", ",", "\n", "attentions", "=", "all_attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2LMHeadModel.__init__": [[693, 699], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "modeling_gpt2.GPT2Model", "torch.Linear", "torch.Linear", "modeling_gpt2.GPT2LMHeadModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.LineByLineTextDataset_gpt2_double.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2LMHeadModel.get_output_embeddings": [[700, 702], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2LMHeadModel.prepare_inputs_for_generation": [[703, 725], ["kwargs.get", "kwargs.get", "input_ids[].unsqueeze", "position_ids[].unsqueeze.masked_fill_", "kwargs.get", "kwargs.get.long().cumsum", "position_ids[].unsqueeze", "kwargs.get.long"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "past", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# only last token for inputs_ids if past is defined in kwargs", "\n", "        ", "if", "past", ":", "\n", "            ", "input_ids", "=", "input_ids", "[", ":", ",", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "attention_mask", "=", "kwargs", ".", "get", "(", "\"attention_mask\"", ",", "None", ")", "\n", "position_ids", "=", "kwargs", ".", "get", "(", "\"position_ids\"", ",", "None", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", "and", "position_ids", "is", "None", ":", "\n", "# create position_ids on the fly for batch generation", "\n", "            ", "position_ids", "=", "attention_mask", ".", "long", "(", ")", ".", "cumsum", "(", "-", "1", ")", "-", "1", "\n", "position_ids", ".", "masked_fill_", "(", "attention_mask", "==", "0", ",", "1", ")", "\n", "if", "past", ":", "\n", "                ", "position_ids", "=", "position_ids", "[", ":", ",", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "", "else", ":", "\n", "            ", "position_ids", "=", "None", "\n", "", "return", "{", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"past_key_values\"", ":", "past", ",", "\n", "\"use_cache\"", ":", "kwargs", ".", "get", "(", "\"use_cache\"", ")", ",", "\n", "\"position_ids\"", ":", "position_ids", ",", "\n", "\"attention_mask\"", ":", "attention_mask", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2LMHeadModel.forward": [[727, 806], ["transformers.file_utils.add_start_docstrings_to_model_forward", "transformers.file_utils.add_code_sample_docstrings", "modeling_gpt2.GPT2LMHeadModel.transformer", "modeling_gpt2.GPT2LMHeadModel.lm_head", "transformers.modeling_outputs.CausalLMOutputWithPast", "warnings.warn", "kwargs.pop", "lm_logits[].contiguous", "labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "list", "lm_logits[].contiguous.view", "labels[].contiguous.view", "kwargs.keys", "lm_logits[].contiguous.size"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "GPT2_INPUTS_DOCSTRING", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "\"gpt2\"", ",", "\n", "output_type", "=", "CausalLMOutputWithPast", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n            Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\n            ``labels = input_ids`` Indices are selected in ``[-100, 0, ..., config.vocab_size]`` All labels set to\n            ``-100`` are ignored (masked), the loss is only computed for labels in ``[0, ..., config.vocab_size]``\n        \"\"\"", "\n", "if", "\"past\"", "in", "kwargs", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"The `past` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\"", ",", "\n", "FutureWarning", ",", "\n", ")", "\n", "past_key_values", "=", "kwargs", ".", "pop", "(", "\"past\"", ")", "\n", "", "assert", "kwargs", "==", "{", "}", ",", "f\"Unexpected keyword arguments: {list(kwargs.keys())}.\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_attention_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "# import ipdb", "\n", "# ipdb.set_trace()", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "\n", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Shift so that tokens < n predict n", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "# Flatten the tokens", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "CausalLMOutputWithPast", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "lm_logits", ",", "\n", "past_key_values", "=", "transformer_outputs", ".", "past_key_values", ",", "\n", "hidden_states", "=", "transformer_outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "transformer_outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2DoubleHeadsModel.__init__": [[819, 827], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "modeling_gpt2.GPT2Model", "torch.Linear", "torch.Linear", "transformers.modeling_utils.SequenceSummary", "modeling_gpt2.GPT2DoubleHeadsModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.LineByLineTextDataset_gpt2_double.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "# config.num_labels = 1", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "multiple_choice_head", "=", "SequenceSummary", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2DoubleHeadsModel.get_output_embeddings": [[828, 830], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2DoubleHeadsModel.prepare_inputs_for_generation": [[831, 840], ["input_ids[].unsqueeze", "kwargs.get"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "past", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# only last token for inputs_ids if past is defined in kwargs", "\n", "        ", "if", "past", ":", "\n", "            ", "input_ids", "=", "input_ids", "[", ":", ",", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "return", "{", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"past_key_values\"", ":", "past", ",", "\n", "\"use_cache\"", ":", "kwargs", ".", "get", "(", "\"use_cache\"", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2DoubleHeadsModel.forward": [[842, 975], ["transformers.file_utils.add_start_docstrings_to_model_forward", "transformers.file_utils.replace_return_docstrings", "modeling_gpt2.GPT2DoubleHeadsModel.transformer", "modeling_gpt2.GPT2DoubleHeadsModel.lm_head", "modeling_gpt2.GPT2DoubleHeadsModel.multiple_choice_head().squeeze", "modeling_gpt2.GPT2DoubleHeadsModelOutput", "warnings.warn", "kwargs.pop", "warnings.warn", "kwargs.pop", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "lm_logits_positive[].contiguous", "labels_positive[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "list", "modeling_gpt2.GPT2DoubleHeadsModel.multiple_choice_head", "modeling_gpt2.GPT2DoubleHeadsModel.view", "mc_labels.view", "numpy.where", "lm_logits_positive[].contiguous.view", "labels_positive[].contiguous.view", "kwargs.keys", "modeling_gpt2.GPT2DoubleHeadsModel.size", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "lm_logits_positive[].contiguous.size", "mc_labels.cpu().numpy", "mc_labels.cpu"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "GPT2_INPUTS_DOCSTRING", ")", "\n", "@", "replace_return_docstrings", "(", "output_type", "=", "GPT2DoubleHeadsModelOutput", ",", "config_class", "=", "_CONFIG_FOR_DOC", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "mc_token_ids", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "mc_labels", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        mc_token_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, num_choices)`, `optional`, default to index of the last token of the input):\n            Index of the classification token in each input sequence. Selected in the range ``[0, input_ids.size(-1) -\n            1[``.\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n            Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\n            ``labels = input_ids`` Indices are selected in ``[-1, 0, ..., config.vocab_size]`` All labels set to\n            ``-100`` are ignored (masked), the loss is only computed for labels in ``[0, ..., config.vocab_size]``\n        mc_labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size)`, `optional`):\n            Labels for computing the multiple choice classification loss. Indices should be in ``[0, ...,\n            num_choices]`` where `num_choices` is the size of the second dimension of the input tensors. (see\n            `input_ids` above)\n        kwargs (:obj:`Dict[str, any]`, optional, defaults to `{}`):\n            Used to hide legacy arguments that have been deprecated.\n\n        Return:\n\n        Example::\n\n            >>> import torch\n            >>> from transformers import GPT2Tokenizer, GPT2DoubleHeadsModel\n\n            >>> tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n            >>> model = GPT2DoubleHeadsModel.from_pretrained('gpt2, return_dict=True)\n\n            >>> # Add a [CLS] to the vocabulary (we should train it also!)\n            >>> num_added_tokens = tokenizer.add_special_tokens({'cls_token': '[CLS]'})\n\n            >>> embedding_layer = model.resize_token_embeddings(len(tokenizer))  # Update the model embeddings with the new vocabulary size\n\n            >>> choices = [\"Hello, my dog is cute [CLS]\", \"Hello, my cat is cute [CLS]\"]\n            >>> encoded_choices = [tokenizer.encode(s) for s in choices]\n            >>> cls_token_location = [tokens.index(tokenizer.cls_token_id) for tokens in encoded_choices]\n\n            >>> input_ids = torch.tensor(encoded_choices).unsqueeze(0)  # Batch size: 1, number of choices: 2\n            >>> mc_token_ids = torch.tensor([cls_token_location])  # Batch size: 1\n\n            >>> outputs = model(input_ids, mc_token_ids=mc_token_ids)\n            >>> lm_logits = outputs.lm_logits\n            >>> mc_logits = outputs.mc_logits\n\n        \"\"\"", "\n", "if", "\"lm_labels\"", "in", "kwargs", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"The `lm_labels` argument is deprecated and will be removed in a future version, use `labels` instead.\"", ",", "\n", "FutureWarning", ",", "\n", ")", "\n", "labels", "=", "kwargs", ".", "pop", "(", "\"lm_labels\"", ")", "\n", "", "if", "\"past\"", "in", "kwargs", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"The `past` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\"", ",", "\n", "FutureWarning", ",", "\n", ")", "\n", "past_key_values", "=", "kwargs", ".", "pop", "(", "\"past\"", ")", "\n", "", "assert", "kwargs", "==", "{", "}", ",", "f\"Unexpected keyword arguments: {list(kwargs.keys())}.\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "# import ipdb; ipdb.set_trace()", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "hidden_states", ",", "mc_token_ids", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "mc_loss", "=", "None", "\n", "if", "mc_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "mc_loss", "=", "loss_fct", "(", "mc_logits", ".", "view", "(", "-", "1", ",", "mc_logits", ".", "size", "(", "-", "1", ")", ")", ",", "mc_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "lm_loss", "=", "None", "\n", "# import ipdb; ipdb.set_trace()", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "positive_indices", "=", "np", ".", "where", "(", "mc_labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "==", "0", ")", "[", "0", "]", "\n", "positive_indices", "=", "torch", ".", "tensor", "(", "positive_indices", ")", ".", "to", "(", "lm_logits", ".", "device", ")", "\n", "lm_logits_positive", "=", "torch", ".", "index_select", "(", "lm_logits", ",", "0", ",", "positive_indices", ")", "\n", "labels_positive", "=", "torch", ".", "index_select", "(", "labels", ",", "0", ",", "positive_indices", ")", "\n", "\n", "# shift_logits = lm_logits[..., :-1, :].contiguous()", "\n", "# shift_labels = labels[..., 1:].contiguous()", "\n", "shift_logits", "=", "lm_logits_positive", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "labels_positive", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "lm_loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "# lm_loss = loss_fct(shift_logits_positive.view(-1, shift_logits_positive.size(-1)), shift_labels_positive.view(-1))", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "lm_logits", ",", "mc_logits", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "mc_loss", "is", "not", "None", ":", "\n", "                ", "output", "=", "(", "mc_loss", ",", ")", "+", "output", "\n", "", "return", "(", "(", "lm_loss", ",", ")", "+", "output", ")", "if", "lm_loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "GPT2DoubleHeadsModelOutput", "(", "\n", "loss", "=", "lm_loss", ",", "\n", "mc_loss", "=", "mc_loss", ",", "\n", "logits", "=", "lm_logits", ",", "\n", "mc_logits", "=", "mc_logits", ",", "\n", "past_key_values", "=", "transformer_outputs", ".", "past_key_values", ",", "\n", "hidden_states", "=", "transformer_outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "transformer_outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2ForSequenceClassification.__init__": [[996, 1003], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "modeling_gpt2.GPT2Model", "torch.Linear", "torch.Linear", "modeling_gpt2.GPT2ForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.LineByLineTextDataset_gpt2_double.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "score", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "self", ".", "num_labels", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.GPT2ForSequenceClassification.forward": [[1004, 1092], ["transformers.file_utils.add_start_docstrings_to_model_forward", "transformers.file_utils.add_code_sample_docstrings", "modeling_gpt2.GPT2ForSequenceClassification.transformer", "modeling_gpt2.GPT2ForSequenceClassification.score", "transformers.modeling_outputs.SequenceClassifierOutputWithPast", "logger.warning", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.ne().sum", "torch.ne().sum", "torch.ne().sum", "torch.ne().sum", "range", "pooled_logits.view", "labels.view", "pooled_logits.view", "labels.view", "torch.ne", "torch.ne", "torch.ne", "torch.ne"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "GPT2_INPUTS_DOCSTRING", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "\"microsoft/dialogrpt\"", ",", "\n", "output_type", "=", "SequenceClassifierOutputWithPast", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "logits", "=", "self", ".", "score", "(", "hidden_states", ")", "\n", "\n", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "batch_size", ",", "sequence_length", "=", "input_ids", ".", "shape", "[", ":", "2", "]", "\n", "", "else", ":", "\n", "            ", "batch_size", ",", "sequence_length", "=", "inputs_embeds", ".", "shape", "[", ":", "2", "]", "\n", "\n", "", "assert", "(", "\n", "self", ".", "config", ".", "pad_token_id", "is", "not", "None", "or", "batch_size", "==", "1", "\n", ")", ",", "\"Cannot handle batch sizes > 1 if no padding token is defined.\"", "\n", "if", "self", ".", "config", ".", "pad_token_id", "is", "None", ":", "\n", "            ", "sequence_lengths", "=", "-", "1", "\n", "", "else", ":", "\n", "            ", "if", "input_ids", "is", "not", "None", ":", "\n", "                ", "sequence_lengths", "=", "torch", ".", "ne", "(", "input_ids", ",", "self", ".", "config", ".", "pad_token_id", ")", ".", "sum", "(", "-", "1", ")", "-", "1", "\n", "", "else", ":", "\n", "                ", "sequence_lengths", "=", "-", "1", "\n", "logger", ".", "warning", "(", "\n", "f\"{self.__class__.__name__} will not detect padding tokens in `inputs_embeds`. Results may be \"", "\n", "f\"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"", "\n", ")", "\n", "\n", "", "", "pooled_logits", "=", "logits", "[", "range", "(", "batch_size", ")", ",", "sequence_lengths", "]", "\n", "\n", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "pooled_logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "pooled_logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "pooled_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "SequenceClassifierOutputWithPast", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "pooled_logits", ",", "\n", "past_key_values", "=", "transformer_outputs", ".", "past_key_values", ",", "\n", "hidden_states", "=", "transformer_outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "transformer_outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.model.modeling_gpt2.load_tf_weights_in_gpt2": [[63, 118], ["os.path.abspath", "logger.info", "tf.train.list_variables", "zip", "logger.info", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "logger.info", "torch.from_numpy", "torch.from_numpy", "logger.error", "tf.train.load_variable.squeeze", "re.fullmatch", "re.split", "getattr", "len", "int", "getattr", "getattr", "getattr", "getattr"], "function", ["None"], ["def", "load_tf_weights_in_gpt2", "(", "model", ",", "config", ",", "gpt2_checkpoint_path", ")", ":", "\n", "    ", "\"\"\"Load tf checkpoints in a pytorch model\"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "gpt2_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ".", "squeeze", "(", ")", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", "[", "6", ":", "]", "# skip \"model/\"", "\n", "name", "=", "name", ".", "split", "(", "\"/\"", ")", "\n", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r\"[A-Za-z]+\\d+\"", ",", "m_name", ")", ":", "\n", "                ", "scope_names", "=", "re", ".", "split", "(", "r\"(\\d+)\"", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "scope_names", "=", "[", "m_name", "]", "\n", "", "if", "scope_names", "[", "0", "]", "==", "\"w\"", "or", "scope_names", "[", "0", "]", "==", "\"g\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"b\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"bias\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"wpe\"", "or", "scope_names", "[", "0", "]", "==", "\"wte\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "else", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "", "if", "len", "(", "scope_names", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "scope_names", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "try", ":", "\n", "            ", "assert", "(", "\n", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", ")", ",", "f\"Pointer shape {pointer.shape} and array shape {array.shape} mismatched\"", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_single_term_polarity": [[12, 49], ["tokenizer.encode", "zip", "[].strip", "tokenizer.decode", "tokenizer.encode", "tokenizer.encode().to", "tokenizer.decode", "[].strip", "batch_pred.append", "batch_ground.append", "model", "torch.max", "indexes[].item", "torch.tensor().to", "[].split", "[].strip().split", "tokenizer.encode", "torch.softmax", "len", "tokenizer.decode().split", "torch.tensor", "tokenizer.decode.split", "[].strip", "[].split", "tokenizer.decode", "[].split", "tokenizer.decode.split", "tokenizer.decode().split", "tokenizer.decode"], "function", ["None"], ["def", "compute_single_term_polarity", "(", "model", ",", "input", ",", "label", ",", "tokenizer", ",", "args", ")", ":", "\n", "\n", "    ", "break_tokens", "=", "tokenizer", ".", "encode", "(", "tokenizer", ".", "_eos_token", ".", "content", ")", "\n", "MAX_LEN", "=", "args", ".", "block_size", "\n", "batch_pred", "=", "[", "]", "\n", "batch_ground", "=", "[", "]", "\n", "for", "inp", ",", "ground", "in", "zip", "(", "input", ",", "label", ")", ":", "\n", "        ", "inp_text", "=", "tokenizer", ".", "decode", "(", "inp", ")", ".", "split", "(", "'<|term|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "aspect_term", "=", "' '", ".", "join", "(", "tokenizer", ".", "decode", "(", "inp", ")", ".", "split", "(", "'<|term|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofterm|>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", "-", "1", "]", ")", "\n", "inp_dec", "=", "f\"{inp_text} <|term|> {aspect_term}\"", "\n", "ground_dec", "=", "tokenizer", ".", "decode", "(", "ground", ")", "\n", "\n", "indexed_tokens", "=", "tokenizer", ".", "encode", "(", "inp_dec", ")", "\n", "tokens_tensor", "=", "tokenizer", ".", "encode", "(", "inp_dec", ",", "return_tensors", "=", "'pt'", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "predicted_index", "=", "indexed_tokens", "[", "-", "1", "]", "\n", "while", "predicted_index", "not", "in", "break_tokens", ":", "\n", "            ", "outputs", "=", "model", "(", "tokens_tensor", ")", "\n", "predictions", "=", "outputs", "[", "0", "]", "\n", "probs", ",", "indexes", "=", "torch", ".", "max", "(", "torch", ".", "softmax", "(", "predictions", ",", "-", "1", ")", ",", "-", "1", ")", "\n", "\n", "predicted_index", "=", "indexes", "[", "0", ",", "-", "1", "]", ".", "item", "(", ")", "\n", "indexed_tokens", "+=", "[", "predicted_index", "]", "\n", "\n", "tokens_tensor", "=", "torch", ".", "tensor", "(", "[", "indexed_tokens", "]", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "if", "len", "(", "indexed_tokens", ")", ">", "MAX_LEN", ":", "\n", "                ", "break", "\n", "", "", "gen_text", "=", "tokenizer", ".", "decode", "(", "indexed_tokens", ")", "\n", "\n", "# only consider first generated token", "\n", "gen_term_polarity", "=", "gen_text", ".", "split", "(", "'<|term|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofterm|>'", ")", "[", "0", "]", ".", "split", "(", "','", ")", "[", "0", "]", "\n", "review", "=", "gen_text", ".", "split", "(", "'<|term|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "gen_text", "=", "f\"{review} <|term|> {gen_term_polarity} <|endofterm|> <|endoftext|>\"", "\n", "\n", "batch_pred", ".", "append", "(", "gen_text", ")", "\n", "batch_ground", ".", "append", "(", "ground_dec", ")", "\n", "\n", "", "return", "batch_pred", ",", "batch_ground", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_sentiment": [[51, 88], ["tokenizer.encode", "zip", "[].strip", "tokenizer.decode", "tokenizer.encode", "tokenizer.encode().to", "tokenizer.decode", "[].strip", "[].strip", "batch_pred.append", "batch_ground.append", "model", "torch.max", "indexes[].item", "torch.tensor().to", "tokenizer.encode", "torch.softmax", "len", "tokenizer.decode().split", "torch.tensor", "[].split", "tokenizer.decode.split", "tokenizer.decode", "tokenizer.decode.split"], "function", ["None"], ["", "def", "compute_sentiment", "(", "model", ",", "input", ",", "label", ",", "tokenizer", ",", "args", ")", ":", "\n", "\n", "    ", "break_tokens", "=", "tokenizer", ".", "encode", "(", "tokenizer", ".", "_eos_token", ".", "content", ")", "\n", "MAX_LEN", "=", "args", ".", "block_size", "\n", "batch_pred", "=", "[", "]", "\n", "batch_ground", "=", "[", "]", "\n", "for", "inp", ",", "ground", "in", "zip", "(", "input", ",", "label", ")", ":", "\n", "        ", "inp_text", "=", "tokenizer", ".", "decode", "(", "inp", ")", ".", "split", "(", "'<|sentiment|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "inp_dec", "=", "f\"{inp_text} <|sentiment|>\"", "\n", "ground_dec", "=", "tokenizer", ".", "decode", "(", "ground", ")", "\n", "\n", "indexed_tokens", "=", "tokenizer", ".", "encode", "(", "inp_dec", ")", "\n", "tokens_tensor", "=", "tokenizer", ".", "encode", "(", "inp_dec", ",", "return_tensors", "=", "'pt'", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "predicted_index", "=", "indexed_tokens", "[", "-", "1", "]", "\n", "while", "predicted_index", "not", "in", "break_tokens", ":", "\n", "            ", "outputs", "=", "model", "(", "tokens_tensor", ")", "\n", "predictions", "=", "outputs", "[", "0", "]", "\n", "probs", ",", "indexes", "=", "torch", ".", "max", "(", "torch", ".", "softmax", "(", "predictions", ",", "-", "1", ")", ",", "-", "1", ")", "\n", "\n", "predicted_index", "=", "indexes", "[", "0", ",", "-", "1", "]", ".", "item", "(", ")", "\n", "indexed_tokens", "+=", "[", "predicted_index", "]", "\n", "\n", "tokens_tensor", "=", "torch", ".", "tensor", "(", "[", "indexed_tokens", "]", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "if", "len", "(", "indexed_tokens", ")", ">", "MAX_LEN", ":", "\n", "                ", "break", "\n", "\n", "", "", "gen_text", "=", "tokenizer", ".", "decode", "(", "indexed_tokens", ")", "\n", "\n", "# only consider first generated token", "\n", "gen_sentiment", "=", "gen_text", ".", "split", "(", "'<|sentiment|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofsentiment|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "review", "=", "gen_text", ".", "split", "(", "'<|sentiment|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "gen_text", "=", "f\"{review} <|sentiment|> {gen_sentiment} <|endofsentiment|> <|endoftext|>\"", "\n", "\n", "batch_pred", ".", "append", "(", "gen_text", ")", "\n", "batch_ground", ".", "append", "(", "ground_dec", ")", "\n", "\n", "", "return", "batch_pred", ",", "batch_ground", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_sst2": [[90, 127], ["tokenizer.encode", "zip", "[].strip", "tokenizer.decode", "tokenizer.encode", "tokenizer.encode().to", "tokenizer.decode", "[].strip", "[].strip", "batch_pred.append", "batch_ground.append", "model", "torch.max", "indexes[].item", "torch.tensor().to", "tokenizer.encode", "torch.softmax", "len", "tokenizer.decode().split", "torch.tensor", "[].split", "tokenizer.decode.split", "tokenizer.decode", "tokenizer.decode.split"], "function", ["None"], ["", "def", "compute_sst2", "(", "model", ",", "input", ",", "label", ",", "tokenizer", ",", "args", ")", ":", "\n", "\n", "    ", "break_tokens", "=", "tokenizer", ".", "encode", "(", "tokenizer", ".", "_eos_token", ".", "content", ")", "\n", "MAX_LEN", "=", "args", ".", "block_size", "\n", "batch_pred", "=", "[", "]", "\n", "batch_ground", "=", "[", "]", "\n", "for", "inp", ",", "ground", "in", "zip", "(", "input", ",", "label", ")", ":", "\n", "        ", "inp_text", "=", "tokenizer", ".", "decode", "(", "inp", ")", ".", "split", "(", "'<|sentiment|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "inp_dec", "=", "f\"{inp_text} <|sentiment|>\"", "\n", "ground_dec", "=", "tokenizer", ".", "decode", "(", "ground", ")", "\n", "\n", "indexed_tokens", "=", "tokenizer", ".", "encode", "(", "inp_dec", ")", "\n", "tokens_tensor", "=", "tokenizer", ".", "encode", "(", "inp_dec", ",", "return_tensors", "=", "'pt'", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "predicted_index", "=", "indexed_tokens", "[", "-", "1", "]", "\n", "while", "predicted_index", "not", "in", "break_tokens", ":", "\n", "            ", "outputs", "=", "model", "(", "tokens_tensor", ")", "\n", "predictions", "=", "outputs", "[", "0", "]", "\n", "probs", ",", "indexes", "=", "torch", ".", "max", "(", "torch", ".", "softmax", "(", "predictions", ",", "-", "1", ")", ",", "-", "1", ")", "\n", "\n", "predicted_index", "=", "indexes", "[", "0", ",", "-", "1", "]", ".", "item", "(", ")", "\n", "indexed_tokens", "+=", "[", "predicted_index", "]", "\n", "\n", "tokens_tensor", "=", "torch", ".", "tensor", "(", "[", "indexed_tokens", "]", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "if", "len", "(", "indexed_tokens", ")", ">", "MAX_LEN", ":", "\n", "                ", "break", "\n", "\n", "", "", "gen_text", "=", "tokenizer", ".", "decode", "(", "indexed_tokens", ")", "\n", "\n", "# only consider first generated token", "\n", "gen_sentiment", "=", "gen_text", ".", "split", "(", "'<|sentiment|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofsentiment|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "review", "=", "gen_text", ".", "split", "(", "'<|sentiment|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "gen_text", "=", "f\"{review} <|sentiment|> {gen_sentiment} <|endofsentiment|> <|endoftext|>\"", "\n", "\n", "batch_pred", ".", "append", "(", "gen_text", ")", "\n", "batch_ground", ".", "append", "(", "ground_dec", ")", "\n", "\n", "", "return", "batch_pred", ",", "batch_ground", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_single_category_polarity": [[129, 168], ["tokenizer.encode", "zip", "[].strip", "tokenizer.decode", "tokenizer.encode", "tokenizer.encode().to", "tokenizer.decode", "[].strip", "batch_pred.append", "batch_ground.append", "model", "torch.max", "indexes[].item", "torch.tensor().to", "[].split", "[].strip().split", "tokenizer.encode", "torch.softmax", "len", "tokenizer.decode().split", "torch.tensor", "tokenizer.decode.split", "[].strip", "[].split", "tokenizer.decode", "[].split", "tokenizer.decode.split", "tokenizer.decode().split", "tokenizer.decode"], "function", ["None"], ["", "def", "compute_single_category_polarity", "(", "model", ",", "input", ",", "label", ",", "tokenizer", ",", "args", ")", ":", "\n", "\n", "    ", "break_tokens", "=", "tokenizer", ".", "encode", "(", "tokenizer", ".", "_eos_token", ".", "content", ")", "\n", "MAX_LEN", "=", "args", ".", "block_size", "\n", "batch_pred", "=", "[", "]", "\n", "batch_ground", "=", "[", "]", "\n", "for", "inp", ",", "ground", "in", "zip", "(", "input", ",", "label", ")", ":", "\n", "        ", "inp_text", "=", "tokenizer", ".", "decode", "(", "inp", ")", ".", "split", "(", "'<|category|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "aspect_category", "=", "' '", ".", "join", "(", "tokenizer", ".", "decode", "(", "inp", ")", ".", "split", "(", "'<|category|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofcategory|>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", "-", "1", "]", ")", "\n", "inp_dec", "=", "f\"{inp_text} <|category|> {aspect_category}\"", "\n", "ground_dec", "=", "tokenizer", ".", "decode", "(", "ground", ")", "\n", "\n", "indexed_tokens", "=", "tokenizer", ".", "encode", "(", "inp_dec", ")", "\n", "tokens_tensor", "=", "tokenizer", ".", "encode", "(", "inp_dec", ",", "return_tensors", "=", "'pt'", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "predicted_index", "=", "indexed_tokens", "[", "-", "1", "]", "\n", "while", "predicted_index", "not", "in", "break_tokens", ":", "\n", "            ", "outputs", "=", "model", "(", "tokens_tensor", ")", "\n", "predictions", "=", "outputs", "[", "0", "]", "\n", "probs", ",", "indexes", "=", "torch", ".", "max", "(", "torch", ".", "softmax", "(", "predictions", ",", "-", "1", ")", ",", "-", "1", ")", "\n", "\n", "predicted_index", "=", "indexes", "[", "0", ",", "-", "1", "]", ".", "item", "(", ")", "\n", "\n", "indexed_tokens", "+=", "[", "predicted_index", "]", "\n", "\n", "tokens_tensor", "=", "torch", ".", "tensor", "(", "[", "indexed_tokens", "]", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "if", "len", "(", "indexed_tokens", ")", ">", "MAX_LEN", ":", "\n", "                ", "break", "\n", "", "", "gen_text", "=", "tokenizer", ".", "decode", "(", "indexed_tokens", ")", "\n", "\n", "# only consider first generated token", "\n", "gen_category_polarity", "=", "gen_text", ".", "split", "(", "'<|category|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofcategory|>'", ")", "[", "0", "]", ".", "split", "(", "','", ")", "[", "0", "]", "\n", "review", "=", "gen_text", ".", "split", "(", "'<|category|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "gen_text", "=", "f\"{review} <|category|> {gen_category_polarity} <|endofcategory|> <|endoftext|>\"", "\n", "\n", "\n", "batch_pred", ".", "append", "(", "gen_text", ")", "\n", "batch_ground", ".", "append", "(", "ground_dec", ")", "\n", "\n", "", "return", "batch_pred", ",", "batch_ground", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_aspect_term": [[170, 202], ["tokenizer.encode", "zip", "[].strip", "tokenizer.decode", "tokenizer.encode", "tokenizer.encode().to", "tokenizer.decode", "batch_pred.append", "batch_ground.append", "model", "torch.max", "indexes[].item", "torch.tensor().to", "tokenizer.encode", "torch.softmax", "len", "tokenizer.decode().split", "torch.tensor", "tokenizer.decode"], "function", ["None"], ["", "def", "compute_aspect_term", "(", "model", ",", "input", ",", "label", ",", "tokenizer", ",", "args", ")", ":", "\n", "\n", "    ", "break_tokens", "=", "tokenizer", ".", "encode", "(", "tokenizer", ".", "_eos_token", ".", "content", ")", "\n", "MAX_LEN", "=", "args", ".", "block_size", "\n", "batch_pred", "=", "[", "]", "\n", "batch_ground", "=", "[", "]", "\n", "for", "inp", ",", "ground", "in", "zip", "(", "input", ",", "label", ")", ":", "\n", "        ", "inp_text", "=", "tokenizer", ".", "decode", "(", "inp", ")", ".", "split", "(", "'<|term|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "inp_dec", "=", "f\"{inp_text} <|term|>\"", "\n", "ground_dec", "=", "tokenizer", ".", "decode", "(", "ground", ")", "\n", "\n", "indexed_tokens", "=", "tokenizer", ".", "encode", "(", "inp_dec", ")", "\n", "tokens_tensor", "=", "tokenizer", ".", "encode", "(", "inp_dec", ",", "return_tensors", "=", "'pt'", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "predicted_index", "=", "indexed_tokens", "[", "-", "1", "]", "\n", "while", "predicted_index", "not", "in", "break_tokens", ":", "\n", "            ", "outputs", "=", "model", "(", "tokens_tensor", ")", "\n", "predictions", "=", "outputs", "[", "0", "]", "\n", "probs", ",", "indexes", "=", "torch", ".", "max", "(", "torch", ".", "softmax", "(", "predictions", ",", "-", "1", ")", ",", "-", "1", ")", "\n", "\n", "predicted_index", "=", "indexes", "[", "0", ",", "-", "1", "]", ".", "item", "(", ")", "\n", "\n", "indexed_tokens", "+=", "[", "predicted_index", "]", "\n", "\n", "tokens_tensor", "=", "torch", ".", "tensor", "(", "[", "indexed_tokens", "]", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "if", "len", "(", "indexed_tokens", ")", ">", "MAX_LEN", ":", "\n", "                ", "break", "\n", "", "", "gen_text", "=", "tokenizer", ".", "decode", "(", "indexed_tokens", ")", "\n", "\n", "batch_pred", ".", "append", "(", "gen_text", ")", "\n", "batch_ground", ".", "append", "(", "ground_dec", ")", "\n", "\n", "", "return", "batch_pred", ",", "batch_ground", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_term_polarity": [[204, 236], ["tokenizer.encode", "zip", "[].strip", "tokenizer.decode", "tokenizer.encode", "tokenizer.encode().to", "tokenizer.decode", "batch_pred.append", "batch_ground.append", "model", "torch.max", "indexes[].item", "torch.tensor().to", "[].strip().split", "tokenizer.encode", "torch.softmax", "len", "tokenizer.decode().split", "torch.tensor", "[].strip", "tokenizer.decode", "[].split", "tokenizer.decode().split", "tokenizer.decode"], "function", ["None"], ["", "def", "compute_term_polarity", "(", "model", ",", "input", ",", "label", ",", "tokenizer", ",", "args", ")", ":", "\n", "\n", "    ", "break_tokens", "=", "tokenizer", ".", "encode", "(", "tokenizer", ".", "_eos_token", ".", "content", ")", "\n", "MAX_LEN", "=", "args", ".", "block_size", "\n", "batch_pred", "=", "[", "]", "\n", "batch_ground", "=", "[", "]", "\n", "for", "inp", ",", "ground", "in", "zip", "(", "input", ",", "label", ")", ":", "\n", "        ", "inp_text", "=", "tokenizer", ".", "decode", "(", "inp", ")", ".", "split", "(", "'<|term|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "aspect_term", "=", "' '", ".", "join", "(", "tokenizer", ".", "decode", "(", "inp", ")", ".", "split", "(", "'<|term|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofterm|>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", "-", "1", "]", ")", "\n", "inp_dec", "=", "f\"{inp_text} <|term|> {aspect_term}\"", "\n", "ground_dec", "=", "tokenizer", ".", "decode", "(", "ground", ")", "\n", "\n", "indexed_tokens", "=", "tokenizer", ".", "encode", "(", "inp_dec", ")", "\n", "tokens_tensor", "=", "tokenizer", ".", "encode", "(", "inp_dec", ",", "return_tensors", "=", "'pt'", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "predicted_index", "=", "indexed_tokens", "[", "-", "1", "]", "\n", "while", "predicted_index", "not", "in", "break_tokens", ":", "\n", "            ", "outputs", "=", "model", "(", "tokens_tensor", ")", "\n", "predictions", "=", "outputs", "[", "0", "]", "\n", "probs", ",", "indexes", "=", "torch", ".", "max", "(", "torch", ".", "softmax", "(", "predictions", ",", "-", "1", ")", ",", "-", "1", ")", "\n", "\n", "predicted_index", "=", "indexes", "[", "0", ",", "-", "1", "]", ".", "item", "(", ")", "\n", "indexed_tokens", "+=", "[", "predicted_index", "]", "\n", "\n", "tokens_tensor", "=", "torch", ".", "tensor", "(", "[", "indexed_tokens", "]", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "if", "len", "(", "indexed_tokens", ")", ">", "MAX_LEN", ":", "\n", "                ", "break", "\n", "", "", "gen_text", "=", "tokenizer", ".", "decode", "(", "indexed_tokens", ")", "\n", "\n", "batch_pred", ".", "append", "(", "gen_text", ")", "\n", "batch_ground", ".", "append", "(", "ground_dec", ")", "\n", "\n", "", "return", "batch_pred", ",", "batch_ground", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_category_polarity": [[238, 270], ["tokenizer.encode", "zip", "[].strip", "tokenizer.decode", "tokenizer.encode", "tokenizer.encode().to", "tokenizer.decode", "batch_pred.append", "batch_ground.append", "model", "torch.max", "indexes[].item", "torch.tensor().to", "[].strip().split", "tokenizer.encode", "torch.softmax", "len", "tokenizer.decode().split", "torch.tensor", "[].strip", "tokenizer.decode", "[].split", "tokenizer.decode().split", "tokenizer.decode"], "function", ["None"], ["", "def", "compute_category_polarity", "(", "model", ",", "input", ",", "label", ",", "tokenizer", ",", "args", ")", ":", "\n", "\n", "    ", "break_tokens", "=", "tokenizer", ".", "encode", "(", "tokenizer", ".", "_eos_token", ".", "content", ")", "\n", "MAX_LEN", "=", "args", ".", "block_size", "\n", "batch_pred", "=", "[", "]", "\n", "batch_ground", "=", "[", "]", "\n", "for", "inp", ",", "ground", "in", "zip", "(", "input", ",", "label", ")", ":", "\n", "        ", "inp_text", "=", "tokenizer", ".", "decode", "(", "inp", ")", ".", "split", "(", "'<|category|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "aspect_category", "=", "' '", ".", "join", "(", "tokenizer", ".", "decode", "(", "inp", ")", ".", "split", "(", "'<|category|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofcategory|>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", "-", "1", "]", ")", "\n", "inp_dec", "=", "f\"{inp_text} <|category|> {aspect_category}\"", "\n", "ground_dec", "=", "tokenizer", ".", "decode", "(", "ground", ")", "\n", "\n", "indexed_tokens", "=", "tokenizer", ".", "encode", "(", "inp_dec", ")", "\n", "tokens_tensor", "=", "tokenizer", ".", "encode", "(", "inp_dec", ",", "return_tensors", "=", "'pt'", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "predicted_index", "=", "indexed_tokens", "[", "-", "1", "]", "\n", "while", "predicted_index", "not", "in", "break_tokens", ":", "\n", "            ", "outputs", "=", "model", "(", "tokens_tensor", ")", "\n", "predictions", "=", "outputs", "[", "0", "]", "\n", "probs", ",", "indexes", "=", "torch", ".", "max", "(", "torch", ".", "softmax", "(", "predictions", ",", "-", "1", ")", ",", "-", "1", ")", "\n", "\n", "predicted_index", "=", "indexes", "[", "0", ",", "-", "1", "]", ".", "item", "(", ")", "\n", "indexed_tokens", "+=", "[", "predicted_index", "]", "\n", "\n", "tokens_tensor", "=", "torch", ".", "tensor", "(", "[", "indexed_tokens", "]", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "if", "len", "(", "indexed_tokens", ")", ">", "MAX_LEN", ":", "\n", "                ", "break", "\n", "", "", "gen_text", "=", "tokenizer", ".", "decode", "(", "indexed_tokens", ")", "\n", "\n", "batch_pred", ".", "append", "(", "gen_text", ")", "\n", "batch_ground", ".", "append", "(", "ground_dec", ")", "\n", "\n", "", "return", "batch_pred", ",", "batch_ground", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_aspect_category": [[272, 304], ["tokenizer.encode", "zip", "[].strip", "tokenizer.decode", "tokenizer.encode", "tokenizer.encode().to", "tokenizer.decode", "batch_pred.append", "batch_ground.append", "model", "torch.max", "indexes[].item", "torch.tensor().to", "tokenizer.encode", "torch.softmax", "len", "tokenizer.decode().split", "torch.tensor", "tokenizer.decode"], "function", ["None"], ["", "def", "compute_aspect_category", "(", "model", ",", "input", ",", "label", ",", "tokenizer", ",", "args", ")", ":", "\n", "\n", "    ", "break_tokens", "=", "tokenizer", ".", "encode", "(", "tokenizer", ".", "_eos_token", ".", "content", ")", "\n", "MAX_LEN", "=", "args", ".", "block_size", "\n", "batch_pred", "=", "[", "]", "\n", "batch_ground", "=", "[", "]", "\n", "for", "inp", ",", "ground", "in", "zip", "(", "input", ",", "label", ")", ":", "\n", "        ", "inp_text", "=", "tokenizer", ".", "decode", "(", "inp", ")", ".", "split", "(", "'<|category|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "inp_dec", "=", "f\"{inp_text} <|category|>\"", "\n", "ground_dec", "=", "tokenizer", ".", "decode", "(", "ground", ")", "\n", "\n", "indexed_tokens", "=", "tokenizer", ".", "encode", "(", "inp_dec", ")", "\n", "tokens_tensor", "=", "tokenizer", ".", "encode", "(", "inp_dec", ",", "return_tensors", "=", "'pt'", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "predicted_index", "=", "indexed_tokens", "[", "-", "1", "]", "\n", "while", "predicted_index", "not", "in", "break_tokens", ":", "\n", "            ", "outputs", "=", "model", "(", "tokens_tensor", ")", "\n", "predictions", "=", "outputs", "[", "0", "]", "\n", "probs", ",", "indexes", "=", "torch", ".", "max", "(", "torch", ".", "softmax", "(", "predictions", ",", "-", "1", ")", ",", "-", "1", ")", "\n", "\n", "predicted_index", "=", "indexes", "[", "0", ",", "-", "1", "]", ".", "item", "(", ")", "\n", "\n", "indexed_tokens", "+=", "[", "predicted_index", "]", "\n", "\n", "tokens_tensor", "=", "torch", ".", "tensor", "(", "[", "indexed_tokens", "]", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "if", "len", "(", "indexed_tokens", ")", ">", "MAX_LEN", ":", "\n", "                ", "break", "\n", "", "", "gen_text", "=", "tokenizer", ".", "decode", "(", "indexed_tokens", ")", "\n", "\n", "batch_pred", ".", "append", "(", "gen_text", ")", "\n", "batch_ground", ".", "append", "(", "ground_dec", ")", "\n", "\n", "", "return", "batch_pred", ",", "batch_ground", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_aspect_term_aspect_category": [[306, 338], ["tokenizer.encode", "zip", "[].strip", "tokenizer.decode", "tokenizer.encode", "tokenizer.encode().to", "tokenizer.decode", "batch_pred.append", "batch_ground.append", "model", "torch.max", "indexes[].item", "torch.tensor().to", "tokenizer.encode", "torch.softmax", "len", "tokenizer.decode().split", "torch.tensor", "tokenizer.decode"], "function", ["None"], ["", "def", "compute_aspect_term_aspect_category", "(", "model", ",", "input", ",", "label", ",", "tokenizer", ",", "args", ")", ":", "\n", "\n", "    ", "break_tokens", "=", "tokenizer", ".", "encode", "(", "tokenizer", ".", "_eos_token", ".", "content", ")", "\n", "MAX_LEN", "=", "args", ".", "block_size", "\n", "batch_pred", "=", "[", "]", "\n", "batch_ground", "=", "[", "]", "\n", "for", "inp", ",", "ground", "in", "zip", "(", "input", ",", "label", ")", ":", "\n", "        ", "inp_text", "=", "tokenizer", ".", "decode", "(", "inp", ")", ".", "split", "(", "'<|term|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "inp_dec", "=", "f\"{inp_text} <|term|>\"", "\n", "ground_dec", "=", "tokenizer", ".", "decode", "(", "ground", ")", "\n", "\n", "indexed_tokens", "=", "tokenizer", ".", "encode", "(", "inp_dec", ")", "\n", "tokens_tensor", "=", "tokenizer", ".", "encode", "(", "inp_dec", ",", "return_tensors", "=", "'pt'", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "predicted_index", "=", "indexed_tokens", "[", "-", "1", "]", "\n", "while", "predicted_index", "not", "in", "break_tokens", ":", "\n", "            ", "outputs", "=", "model", "(", "tokens_tensor", ")", "\n", "predictions", "=", "outputs", "[", "0", "]", "\n", "probs", ",", "indexes", "=", "torch", ".", "max", "(", "torch", ".", "softmax", "(", "predictions", ",", "-", "1", ")", ",", "-", "1", ")", "\n", "\n", "predicted_index", "=", "indexes", "[", "0", ",", "-", "1", "]", ".", "item", "(", ")", "\n", "\n", "indexed_tokens", "+=", "[", "predicted_index", "]", "\n", "\n", "tokens_tensor", "=", "torch", ".", "tensor", "(", "[", "indexed_tokens", "]", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "if", "len", "(", "indexed_tokens", ")", ">", "MAX_LEN", ":", "\n", "                ", "break", "\n", "", "", "gen_text", "=", "tokenizer", ".", "decode", "(", "indexed_tokens", ")", "\n", "\n", "batch_pred", ".", "append", "(", "gen_text", ")", "\n", "batch_ground", ".", "append", "(", "ground_dec", ")", "\n", "\n", "", "return", "batch_pred", ",", "batch_ground", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_oos_metrics": [[340, 404], ["zip", "sklearn.metrics.accuracy_score", "sklearn.metrics.recall_score", "result_dict.update", "[].strip", "[].strip", "all_true.append", "all_pred.append", "in_true.append", "in_pred.append", "oos_true.append", "oos_true.append", "oos_pred.append", "oos_pred.append", "[].split", "[].split", "true.split", "pred.split"], "function", ["None"], ["", "def", "compute_oos_metrics", "(", "result_dict", ",", "labels", ",", "predictions", ")", ":", "\n", "\n", "    ", "in_true", "=", "[", "]", "\n", "in_pred", "=", "[", "]", "\n", "in_correct", "=", "0", "\n", "in_total", "=", "0", "\n", "\n", "all_true", "=", "[", "]", "\n", "all_pred", "=", "[", "]", "\n", "all_correct", "=", "0", "\n", "all_total", "=", "0", "\n", "\n", "oos_true", "=", "[", "]", "\n", "oos_pred", "=", "[", "]", "\n", "\n", "for", "true", ",", "pred", "in", "zip", "(", "labels", ",", "predictions", ")", ":", "\n", "        ", "l", "=", "true", ".", "split", "(", "'<|intent|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofintent|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "p", "=", "pred", ".", "split", "(", "'<|intent|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofintent|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "####### for Acc(full) metric #############", "\n", "all_true", ".", "append", "(", "l", ")", "\n", "all_pred", ".", "append", "(", "p", ")", "\n", "\n", "all_total", "+=", "1", "\n", "if", "l", "==", "p", ":", "\n", "            ", "all_correct", "+=", "1", "\n", "\n", "####### for Acc(in) metric #############", "\n", "", "if", "l", "!=", "'out of scope'", ":", "\n", "\n", "            ", "in_true", ".", "append", "(", "l", ")", "\n", "in_pred", ".", "append", "(", "p", ")", "\n", "\n", "in_total", "+=", "1", "\n", "if", "l", "==", "p", ":", "\n", "                ", "in_correct", "+=", "1", "\n", "\n", "####### for Acc(out) metric #############", "\n", "", "", "if", "l", "==", "'out of scope'", ":", "\n", "            ", "oos_true", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "oos_true", ".", "append", "(", "0", ")", "\n", "\n", "", "if", "p", "==", "'out of scope'", ":", "\n", "            ", "oos_pred", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "oos_pred", ".", "append", "(", "0", ")", "\n", "\n", "", "", "oos_acc", "=", "accuracy_score", "(", "oos_true", ",", "oos_pred", ")", "\n", "oos_recall", "=", "recall_score", "(", "oos_true", ",", "oos_pred", ")", "\n", "\n", "in_acc", "=", "in_correct", "/", "in_total", "\n", "all_acc", "=", "all_correct", "/", "all_total", "\n", "\n", "result_dict", ".", "update", "(", "\n", "{", "\n", "'acc_in'", ":", "in_acc", ",", "\n", "'acc_full'", ":", "all_acc", ",", "\n", "'acc_oos'", ":", "oos_acc", ",", "\n", "'recall_oos'", ":", "oos_recall", "\n", "}", "\n", ")", "\n", "\n", "return", "result_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_oos_metrics_hulu": [[406, 501], ["zip", "sklearn.metrics.accuracy_score", "sklearn.metrics.precision_recall_fscore_support", "zip", "result_dict.update", "[].strip", "[].strip", "all_true.append", "all_pred.append", "[].strip", "[].strip", "in_true.append", "in_pred.append", "oos_true.append", "oos_true.append", "oos_pred.append", "oos_pred.append", "in_true_noconfidence.append", "in_pred_noconfidence.append", "[].split", "[].split", "[].split", "[].split", "true.split", "pred.split", "true.split", "pred.split"], "function", ["None"], ["", "def", "compute_oos_metrics_hulu", "(", "result_dict", ",", "labels", ",", "predictions", ",", "probabilites", ",", "label_set", ",", "args", ")", ":", "\n", "\n", "    ", "in_true", "=", "[", "]", "\n", "in_pred", "=", "[", "]", "\n", "in_correct", "=", "0", "\n", "in_total", "=", "0", "\n", "\n", "all_true", "=", "[", "]", "\n", "all_pred", "=", "[", "]", "\n", "all_correct", "=", "0", "\n", "all_total", "=", "0", "\n", "\n", "oos_true", "=", "[", "]", "\n", "oos_pred", "=", "[", "]", "\n", "\n", "threshold", "=", "args", ".", "confidence_threshold", "\n", "\n", "\n", "for", "true", ",", "pred", ",", "prob", "in", "zip", "(", "labels", ",", "predictions", ",", "probabilites", ")", ":", "\n", "        ", "l", "=", "true", ".", "split", "(", "'<|intent|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofintent|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "p", "=", "pred", ".", "split", "(", "'<|intent|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofintent|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "if", "p", "not", "in", "label_set", "or", "prob", "<", "threshold", ":", "\n", "            ", "p", "=", "'out of scope'", "\n", "\n", "\n", "####### for Acc(full) metric #############", "\n", "", "all_true", ".", "append", "(", "l", ")", "\n", "all_pred", ".", "append", "(", "p", ")", "\n", "\n", "all_total", "+=", "1", "\n", "if", "l", "==", "p", ":", "\n", "            ", "all_correct", "+=", "1", "\n", "\n", "####### for Acc(in) metric #############", "\n", "", "if", "l", "!=", "'out of scope'", ":", "\n", "\n", "            ", "in_true", ".", "append", "(", "l", ")", "\n", "in_pred", ".", "append", "(", "p", ")", "\n", "\n", "in_total", "+=", "1", "\n", "if", "l", "==", "p", ":", "\n", "                ", "in_correct", "+=", "1", "\n", "\n", "####### for Acc(out) metric #############", "\n", "", "", "if", "l", "==", "'out of scope'", ":", "\n", "            ", "oos_true", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "oos_true", ".", "append", "(", "0", ")", "\n", "\n", "", "if", "p", "==", "'out of scope'", ":", "\n", "            ", "oos_pred", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "oos_pred", ".", "append", "(", "0", ")", "\n", "\n", "", "", "oos_acc", "=", "accuracy_score", "(", "oos_true", ",", "oos_pred", ")", "\n", "oos_prec", ",", "oos_recall", ",", "oos_fscore", ",", "_", "=", "precision_recall_fscore_support", "(", "oos_true", ",", "oos_pred", ",", "labels", "=", "[", "1", "]", ")", "\n", "in_acc", "=", "in_correct", "/", "in_total", "\n", "all_acc", "=", "all_correct", "/", "all_total", "\n", "\n", "\n", "in_true_noconfidence", "=", "[", "]", "\n", "in_pred_noconfidence", "=", "[", "]", "\n", "in_correct_noconfidence", "=", "0", "\n", "in_total_noconfidence", "=", "0", "\n", "for", "true", ",", "pred", ",", "prob", "in", "zip", "(", "labels", ",", "predictions", ",", "probabilites", ")", ":", "\n", "        ", "l", "=", "true", ".", "split", "(", "'<|intent|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofintent|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "p", "=", "pred", ".", "split", "(", "'<|intent|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofintent|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "\n", "####### for Acc(in) metric #############", "\n", "if", "l", "!=", "'out of scope'", ":", "\n", "\n", "            ", "in_true_noconfidence", ".", "append", "(", "l", ")", "\n", "in_pred_noconfidence", ".", "append", "(", "p", ")", "\n", "\n", "in_total_noconfidence", "+=", "1", "\n", "if", "l", "==", "p", ":", "\n", "                ", "in_correct_noconfidence", "+=", "1", "\n", "\n", "", "", "", "in_acc_noconfidence", "=", "in_correct_noconfidence", "/", "in_total_noconfidence", "\n", "\n", "result_dict", ".", "update", "(", "\n", "{", "\n", "'acc_in'", ":", "in_acc", ",", "\n", "'acc_in_noconfidence'", ":", "in_acc_noconfidence", ",", "\n", "'acc_full'", ":", "all_acc", ",", "\n", "'acc_oos'", ":", "oos_acc", ",", "\n", "'oos_precision'", ":", "oos_prec", "[", "0", "]", ",", "\n", "'oos_recall'", ":", "oos_recall", "[", "0", "]", ",", "\n", "'oos_fscore'", ":", "oos_fscore", "[", "0", "]", ",", "\n", "}", "\n", ")", "\n", "\n", "return", "result_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_metrics": [[503, 531], ["zip", "result_dict.update", "[].strip", "[].strip", "all_true.append", "all_pred.append", "[].split", "[].split", "true.split", "pred.split"], "function", ["None"], ["", "def", "compute_metrics", "(", "result_dict", ",", "labels", ",", "predictions", ",", "task_labels", ",", "args", ")", ":", "\n", "\n", "    ", "all_true", "=", "[", "]", "\n", "all_pred", "=", "[", "]", "\n", "all_correct", "=", "0", "\n", "all_total", "=", "0", "\n", "\n", "for", "true", ",", "pred", "in", "zip", "(", "labels", ",", "predictions", ")", ":", "\n", "        ", "l", "=", "true", ".", "split", "(", "'<|intent|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofintent|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "p", "=", "pred", ".", "split", "(", "'<|intent|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofintent|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "####### for Acc(full) metric #############", "\n", "all_true", ".", "append", "(", "l", ")", "\n", "all_pred", ".", "append", "(", "p", ")", "\n", "\n", "all_total", "+=", "1", "\n", "if", "l", "==", "p", ":", "\n", "            ", "all_correct", "+=", "1", "\n", "\n", "", "", "all_acc", "=", "all_correct", "/", "all_total", "\n", "\n", "result_dict", ".", "update", "(", "\n", "{", "\n", "'acc'", ":", "all_acc", ",", "\n", "}", "\n", ")", "\n", "\n", "return", "result_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_term_polarity_metrics": [[533, 567], ["zip", "sklearn.metrics.accuracy_score", "sklearn.metrics.precision_recall_fscore_support", "result_dict.update", "all_true.append", "all_pred.append", "[].strip().split", "[].strip().split", "[].strip", "[].strip", "[].split", "[].split", "true.split", "pred.split"], "function", ["None"], ["", "def", "compute_term_polarity_metrics", "(", "result_dict", ",", "labels", ",", "predictions", ")", ":", "\n", "\n", "    ", "all_true", "=", "[", "]", "\n", "all_pred", "=", "[", "]", "\n", "all_correct", "=", "0", "\n", "all_total", "=", "0", "\n", "\n", "for", "true", ",", "pred", "in", "zip", "(", "labels", ",", "predictions", ")", ":", "\n", "        ", "l", "=", "true", ".", "split", "(", "'<|term|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofterm|>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", "-", "1", "]", "\n", "p", "=", "pred", ".", "split", "(", "'<|term|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofterm|>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", "-", "1", "]", "\n", "\n", "####### for Acc(full) metric #############", "\n", "all_true", ".", "append", "(", "l", ")", "\n", "all_pred", ".", "append", "(", "p", ")", "\n", "\n", "all_total", "+=", "1", "\n", "if", "l", "==", "p", ":", "\n", "            ", "all_correct", "+=", "1", "\n", "\n", "", "", "all_acc", "=", "all_correct", "/", "all_total", "\n", "acc", "=", "accuracy_score", "(", "all_true", ",", "all_pred", ")", "\n", "assert", "acc", "==", "all_acc", "\n", "prec", ",", "recall", ",", "fscore", ",", "_", "=", "precision_recall_fscore_support", "(", "all_true", ",", "all_pred", ",", "average", "=", "'macro'", ")", "\n", "\n", "result_dict", ".", "update", "(", "\n", "{", "\n", "'term_polarity_acc'", ":", "all_acc", ",", "\n", "'term_polarity_prec'", ":", "prec", ",", "\n", "'term_polarity_recall'", ":", "recall", ",", "\n", "'term_polarity_fscorce'", ":", "fscore", ",", "\n", "}", "\n", ")", "\n", "\n", "return", "result_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_sentiment_metrics": [[569, 603], ["zip", "sklearn.metrics.accuracy_score", "sklearn.metrics.precision_recall_fscore_support", "result_dict.update", "[].strip", "[].strip", "all_true.append", "all_pred.append", "[].split", "[].split", "true.split", "pred.split"], "function", ["None"], ["", "def", "compute_sentiment_metrics", "(", "result_dict", ",", "labels", ",", "predictions", ")", ":", "\n", "\n", "    ", "all_true", "=", "[", "]", "\n", "all_pred", "=", "[", "]", "\n", "all_correct", "=", "0", "\n", "all_total", "=", "0", "\n", "\n", "for", "true", ",", "pred", "in", "zip", "(", "labels", ",", "predictions", ")", ":", "\n", "        ", "l", "=", "true", ".", "split", "(", "'<|sentiment|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofsentiment|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "p", "=", "pred", ".", "split", "(", "'<|sentiment|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofsentiment|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "####### for Acc(full) metric #############", "\n", "all_true", ".", "append", "(", "l", ")", "\n", "all_pred", ".", "append", "(", "p", ")", "\n", "\n", "all_total", "+=", "1", "\n", "if", "l", "==", "p", ":", "\n", "            ", "all_correct", "+=", "1", "\n", "\n", "", "", "all_acc", "=", "all_correct", "/", "all_total", "\n", "acc", "=", "accuracy_score", "(", "all_true", ",", "all_pred", ")", "\n", "assert", "acc", "==", "all_acc", "\n", "prec", ",", "recall", ",", "fscore", ",", "_", "=", "precision_recall_fscore_support", "(", "all_true", ",", "all_pred", ",", "average", "=", "'macro'", ")", "\n", "\n", "result_dict", ".", "update", "(", "\n", "{", "\n", "'sentiment_acc'", ":", "all_acc", ",", "\n", "'sentiment_prec'", ":", "prec", ",", "\n", "'sentiment_recall'", ":", "recall", ",", "\n", "'sentiment_fscorce'", ":", "fscore", ",", "\n", "}", "\n", ")", "\n", "\n", "return", "result_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_sst2_metrics": [[605, 639], ["zip", "sklearn.metrics.accuracy_score", "sklearn.metrics.precision_recall_fscore_support", "result_dict.update", "[].strip", "[].strip", "all_true.append", "all_pred.append", "[].split", "[].split", "true.split", "pred.split"], "function", ["None"], ["", "def", "compute_sst2_metrics", "(", "result_dict", ",", "labels", ",", "predictions", ")", ":", "\n", "\n", "    ", "all_true", "=", "[", "]", "\n", "all_pred", "=", "[", "]", "\n", "all_correct", "=", "0", "\n", "all_total", "=", "0", "\n", "\n", "for", "true", ",", "pred", "in", "zip", "(", "labels", ",", "predictions", ")", ":", "\n", "        ", "l", "=", "true", ".", "split", "(", "'<|sentiment|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofsentiment|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "p", "=", "pred", ".", "split", "(", "'<|sentiment|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofsentiment|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "####### for Acc(full) metric #############", "\n", "all_true", ".", "append", "(", "l", ")", "\n", "all_pred", ".", "append", "(", "p", ")", "\n", "\n", "all_total", "+=", "1", "\n", "if", "l", "==", "p", ":", "\n", "            ", "all_correct", "+=", "1", "\n", "\n", "", "", "all_acc", "=", "all_correct", "/", "all_total", "\n", "acc", "=", "accuracy_score", "(", "all_true", ",", "all_pred", ")", "\n", "assert", "acc", "==", "all_acc", "\n", "prec", ",", "recall", ",", "fscore", ",", "_", "=", "precision_recall_fscore_support", "(", "all_true", ",", "all_pred", ",", "average", "=", "'macro'", ")", "\n", "\n", "result_dict", ".", "update", "(", "\n", "{", "\n", "'sentiment_acc'", ":", "all_acc", ",", "\n", "'sentiment_prec'", ":", "prec", ",", "\n", "'sentiment_recall'", ":", "recall", ",", "\n", "'sentiment_fscorce'", ":", "fscore", ",", "\n", "}", "\n", ")", "\n", "\n", "return", "result_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_category_polarity_metrics": [[641, 675], ["zip", "sklearn.metrics.accuracy_score", "sklearn.metrics.precision_recall_fscore_support", "result_dict.update", "all_true.append", "all_pred.append", "[].strip().split", "[].strip().split", "[].strip", "[].strip", "[].split", "[].split", "true.split", "pred.split"], "function", ["None"], ["", "def", "compute_category_polarity_metrics", "(", "result_dict", ",", "labels", ",", "predictions", ")", ":", "\n", "\n", "    ", "all_true", "=", "[", "]", "\n", "all_pred", "=", "[", "]", "\n", "all_correct", "=", "0", "\n", "all_total", "=", "0", "\n", "\n", "for", "true", ",", "pred", "in", "zip", "(", "labels", ",", "predictions", ")", ":", "\n", "        ", "l", "=", "true", ".", "split", "(", "'<|category|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofcategory|>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", "-", "1", "]", "\n", "p", "=", "pred", ".", "split", "(", "'<|category|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofcategory|>'", ")", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", "-", "1", "]", "\n", "\n", "####### for Acc(full) metric #############", "\n", "all_true", ".", "append", "(", "l", ")", "\n", "all_pred", ".", "append", "(", "p", ")", "\n", "\n", "all_total", "+=", "1", "\n", "if", "l", "==", "p", ":", "\n", "            ", "all_correct", "+=", "1", "\n", "\n", "", "", "all_acc", "=", "all_correct", "/", "all_total", "\n", "acc", "=", "accuracy_score", "(", "all_true", ",", "all_pred", ")", "\n", "assert", "acc", "==", "all_acc", "\n", "prec", ",", "recall", ",", "fscore", ",", "_", "=", "precision_recall_fscore_support", "(", "all_true", ",", "all_pred", ",", "average", "=", "'macro'", ")", "\n", "\n", "result_dict", ".", "update", "(", "\n", "{", "\n", "'category_polarity_acc'", ":", "all_acc", ",", "\n", "'category_polarity_prec'", ":", "prec", ",", "\n", "'category_polarity_recall'", ":", "recall", ",", "\n", "'category_polarity_fscorce'", ":", "fscore", ",", "\n", "}", "\n", ")", "\n", "\n", "return", "result_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.sort_output": [[677, 710], ["ground.strip().split", "pred.strip().split", "sorted", "sorted", "[].strip", "[].strip", "ground_list.append", "pred_list.append", "ground.strip", "sorted.append", "pred.strip", "sorted.append", "t.split", "t.split", "t.split", "t.split"], "function", ["None"], ["", "def", "sort_output", "(", "ground", ",", "pred", ")", ":", "\n", "    ", "ground_dic", "=", "[", "]", "\n", "for", "t", "in", "ground", ".", "strip", "(", ")", ".", "split", "(", "','", ")", ":", "\n", "        ", "if", "t", "in", "[", "''", ",", "' '", "]", ":", "\n", "            ", "continue", "\n", "", "term", "=", "' '", ".", "join", "(", "t", ".", "split", "(", "' '", ")", "[", ":", "-", "1", "]", ")", ".", "strip", "(", ")", "\n", "label", "=", "t", ".", "split", "(", "' '", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "\n", "if", "(", "term", ",", "label", ")", "not", "in", "ground_dic", ":", "\n", "            ", "ground_dic", ".", "append", "(", "(", "term", ",", "label", ")", ")", "\n", "\n", "", "", "pred_dic", "=", "[", "]", "\n", "for", "t", "in", "pred", ".", "strip", "(", ")", ".", "split", "(", "','", ")", ":", "\n", "        ", "if", "t", "in", "[", "''", ",", "' '", "]", ":", "\n", "            ", "continue", "\n", "", "term", "=", "' '", ".", "join", "(", "t", ".", "split", "(", "' '", ")", "[", ":", "-", "1", "]", ")", ".", "strip", "(", ")", "\n", "label", "=", "t", ".", "split", "(", "' '", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "\n", "if", "(", "term", ",", "label", ")", "not", "in", "pred_dic", ":", "\n", "            ", "pred_dic", ".", "append", "(", "(", "term", ",", "label", ")", ")", "\n", "\n", "", "", "ground_dic", "=", "sorted", "(", "ground_dic", ",", "key", "=", "lambda", "a", ":", "a", "[", "0", "]", ")", "\n", "pred_dic", "=", "sorted", "(", "pred_dic", ",", "key", "=", "lambda", "a", ":", "a", "[", "0", "]", ")", "\n", "\n", "ground_list", "=", "[", "]", "\n", "for", "term", ",", "label", "in", "ground_dic", ":", "\n", "        ", "ground_list", ".", "append", "(", "f\"{term} {label}\"", ")", "\n", "", "ground_text", "=", "', '", ".", "join", "(", "ground_list", ")", "\n", "\n", "pred_list", "=", "[", "]", "\n", "for", "term", ",", "label", "in", "pred_dic", ":", "\n", "        ", "pred_list", ".", "append", "(", "f\"{term} {label}\"", ")", "\n", "", "pred_text", "=", "', '", ".", "join", "(", "pred_list", ")", "\n", "\n", "return", "ground_text", ",", "pred_text", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.aspect_extraction": [[713, 725], ["range", "len", "len", "len", "len", "t.split", "correct[].split", "t.split", "predicted[].split"], "function", ["None"], ["", "def", "aspect_extraction", "(", "correct", ",", "predicted", ",", "b", "=", "1", ")", ":", "\n", "    ", "common", ",", "relevant", ",", "retrieved", "=", "0.", ",", "0.", ",", "0.", "\n", "for", "i", "in", "range", "(", "len", "(", "correct", ")", ")", ":", "\n", "        ", "cor", "=", "[", "t", ".", "split", "(", "' '", ")", "[", ":", "-", "1", "]", "for", "t", "in", "correct", "[", "i", "]", ".", "split", "(", "','", ")", "]", "\n", "pre", "=", "[", "t", ".", "split", "(", "' '", ")", "[", ":", "-", "1", "]", "for", "t", "in", "predicted", "[", "i", "]", ".", "split", "(", "','", ")", "]", "\n", "common", "+=", "len", "(", "[", "a", "for", "a", "in", "pre", "if", "a", "in", "cor", "]", ")", "\n", "retrieved", "+=", "len", "(", "pre", ")", "\n", "relevant", "+=", "len", "(", "cor", ")", "\n", "", "p", "=", "common", "/", "retrieved", "if", "retrieved", ">", "0", "else", "0.", "\n", "r", "=", "common", "/", "relevant", "\n", "f1", "=", "(", "1", "+", "(", "b", "**", "2", ")", ")", "*", "p", "*", "r", "/", "(", "(", "p", "*", "b", "**", "2", ")", "+", "r", ")", "if", "p", ">", "0", "and", "r", ">", "0", "else", "0.", "\n", "return", "p", ",", "r", ",", "f1", ",", "common", ",", "retrieved", ",", "relevant", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.category_detection": [[728, 740], ["range", "len", "len", "len", "len", "t.split", "correct[].split", "t.split", "predicted[].split"], "function", ["None"], ["", "def", "category_detection", "(", "correct", ",", "predicted", ",", "b", "=", "1", ")", ":", "\n", "    ", "common", ",", "relevant", ",", "retrieved", "=", "0.", ",", "0.", ",", "0.", "\n", "for", "i", "in", "range", "(", "len", "(", "correct", ")", ")", ":", "\n", "        ", "cor", "=", "[", "t", ".", "split", "(", "' '", ")", "[", ":", "-", "1", "]", "for", "t", "in", "correct", "[", "i", "]", ".", "split", "(", "','", ")", "]", "\n", "pre", "=", "[", "t", ".", "split", "(", "' '", ")", "[", ":", "-", "1", "]", "for", "t", "in", "predicted", "[", "i", "]", ".", "split", "(", "','", ")", "]", "\n", "common", "+=", "len", "(", "[", "c", "for", "c", "in", "pre", "if", "c", "in", "cor", "]", ")", "\n", "retrieved", "+=", "len", "(", "pre", ")", "\n", "relevant", "+=", "len", "(", "cor", ")", "\n", "", "p", "=", "common", "/", "retrieved", "if", "retrieved", ">", "0", "else", "0.", "\n", "r", "=", "common", "/", "relevant", "\n", "f1", "=", "(", "1", "+", "b", "**", "2", ")", "*", "p", "*", "r", "/", "(", "(", "p", "*", "b", "**", "2", ")", "+", "r", ")", "if", "p", ">", "0", "and", "r", ">", "0", "else", "0.", "\n", "return", "p", ",", "r", ",", "f1", ",", "common", ",", "retrieved", ",", "relevant", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.aspect_polarity_estimation": [[742, 761], ["range", "len", "correct[].split", "predicted[].split", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "aspect_polarity_estimation", "(", "correct", ",", "predicted", ",", "b", "=", "1", ")", ":", "\n", "    ", "common", ",", "relevant", ",", "retrieved", "=", "0.", ",", "0.", ",", "0.", "\n", "true_relevant", "=", "0.", "\n", "false_positive", "=", "0.", "\n", "false_negative", "=", "0.", "\n", "for", "i", "in", "range", "(", "len", "(", "correct", ")", ")", ":", "\n", "        ", "cor", "=", "correct", "[", "i", "]", ".", "split", "(", "','", ")", "\n", "pre", "=", "predicted", "[", "i", "]", ".", "split", "(", "','", ")", "\n", "common", "+=", "len", "(", "[", "a", "for", "a", "in", "pre", "if", "a", "in", "cor", "]", ")", "\n", "false_positive", "+=", "len", "(", "[", "a", "for", "a", "in", "pre", "if", "a", "not", "in", "cor", "]", ")", "\n", "false_negative", "+=", "len", "(", "[", "a", "for", "a", "in", "cor", "if", "a", "not", "in", "pre", "]", ")", "\n", "\n", "retrieved", "+=", "len", "(", "pre", ")", "\n", "true_relevant", "+=", "len", "(", "cor", ")", "\n", "\n", "", "acc", "=", "common", "/", "retrieved", "\n", "acc_true", "=", "common", "/", "true_relevant", "\n", "acc_correct", "=", "common", "/", "(", "false_positive", "+", "false_negative", "+", "common", ")", "\n", "return", "acc", ",", "acc_true", ",", "acc_correct", ",", "common", ",", "retrieved", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.aspect_category_polarity_estimation": [[763, 780], ["range", "len", "correct[].split", "predicted[].split", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "aspect_category_polarity_estimation", "(", "correct", ",", "predicted", ",", "b", "=", "1", ")", ":", "\n", "    ", "common", ",", "relevant", ",", "retrieved", "=", "0.", ",", "0.", ",", "0.", "\n", "true_relevant", "=", "0.", "\n", "false_positive", "=", "0.", "\n", "false_negative", "=", "0.", "\n", "for", "i", "in", "range", "(", "len", "(", "correct", ")", ")", ":", "\n", "        ", "cor", "=", "correct", "[", "i", "]", ".", "split", "(", "','", ")", "\n", "pre", "=", "predicted", "[", "i", "]", ".", "split", "(", "','", ")", "\n", "common", "+=", "len", "(", "[", "a", "for", "a", "in", "pre", "if", "a", "in", "cor", "]", ")", "\n", "false_positive", "+=", "len", "(", "[", "a", "for", "a", "in", "pre", "if", "a", "not", "in", "cor", "]", ")", "\n", "false_negative", "+=", "len", "(", "[", "a", "for", "a", "in", "cor", "if", "a", "not", "in", "pre", "]", ")", "\n", "retrieved", "+=", "len", "(", "pre", ")", "\n", "true_relevant", "+=", "len", "(", "cor", ")", "\n", "", "acc", "=", "common", "/", "retrieved", "\n", "acc_true", "=", "common", "/", "true_relevant", "\n", "acc_correct", "=", "common", "/", "(", "false_positive", "+", "false_negative", "+", "common", ")", "\n", "return", "acc", ",", "acc_true", ",", "acc_correct", ",", "common", ",", "retrieved", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_aspect_term_metrics": [[782, 832], ["zip", "sklearn.metrics.accuracy_score", "sklearn.metrics.precision_recall_fscore_support", "metrics.aspect_extraction", "metrics.aspect_polarity_estimation", "result_dict.update", "[].strip", "[].strip", "metrics.sort_output", "all_true.append", "all_pred.append", "[].split", "[].split", "true.split", "pred.split"], "function", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.aspect_extraction", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.aspect_polarity_estimation", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.sort_output"], ["", "def", "compute_aspect_term_metrics", "(", "result_dict", ",", "labels", ",", "predictions", ")", ":", "\n", "\n", "    ", "all_true", "=", "[", "]", "\n", "all_pred", "=", "[", "]", "\n", "all_correct", "=", "0", "\n", "all_total", "=", "0", "\n", "\n", "for", "true", ",", "pred", "in", "zip", "(", "labels", ",", "predictions", ")", ":", "\n", "        ", "l", "=", "true", ".", "split", "(", "'<|term|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofterm|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "p", "=", "pred", ".", "split", "(", "'<|term|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofterm|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "l_new", ",", "p_new", "=", "sort_output", "(", "l", ",", "p", ")", "\n", "\n", "####### for Acc(full) metric #############", "\n", "all_true", ".", "append", "(", "l_new", ")", "\n", "all_pred", ".", "append", "(", "p_new", ")", "\n", "\n", "all_total", "+=", "1", "\n", "if", "l_new", "==", "p_new", ":", "\n", "            ", "all_correct", "+=", "1", "\n", "\n", "", "", "all_acc", "=", "all_correct", "/", "all_total", "\n", "acc", "=", "accuracy_score", "(", "all_true", ",", "all_pred", ")", "\n", "assert", "acc", "==", "all_acc", "\n", "prec", ",", "recall", ",", "fscore", ",", "_", "=", "precision_recall_fscore_support", "(", "all_true", ",", "all_pred", ",", "average", "=", "'macro'", ")", "\n", "\n", "# compute aspect term extraction", "\n", "prec_extract", ",", "recall_extract", ",", "f1_extract", ",", "_", ",", "_", ",", "_", "=", "aspect_extraction", "(", "all_true", ",", "all_pred", ")", "\n", "\n", "# compute aspect term polarity", "\n", "acc_polarity", ",", "acc_polarity_true", ",", "acc_polarity_correct", ",", "_", ",", "_", "=", "aspect_polarity_estimation", "(", "all_true", ",", "all_pred", ")", "\n", "\n", "result_dict", ".", "update", "(", "\n", "{", "\n", "'term_acc'", ":", "all_acc", ",", "\n", "'term_prec'", ":", "prec", ",", "\n", "'term_recall'", ":", "recall", ",", "\n", "'term_fscorce'", ":", "fscore", ",", "\n", "\n", "'term_extract_prec'", ":", "prec_extract", ",", "\n", "'term_extract_recall'", ":", "recall_extract", ",", "\n", "'term_extract_fscorce'", ":", "f1_extract", ",", "\n", "\n", "'term_polarity_acc'", ":", "acc_polarity", ",", "\n", "'term_polarity_acc_true'", ":", "acc_polarity_true", ",", "\n", "'term_polarity_acc_correct'", ":", "acc_polarity_correct", "\n", "}", "\n", ")", "\n", "\n", "return", "result_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_aspect_category_metrics": [[834, 884], ["zip", "sklearn.metrics.accuracy_score", "sklearn.metrics.precision_recall_fscore_support", "metrics.category_detection", "metrics.aspect_category_polarity_estimation", "result_dict.update", "[].strip", "[].strip", "metrics.sort_output", "all_true.append", "all_pred.append", "[].split", "[].split", "true.split", "pred.split"], "function", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.category_detection", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.aspect_category_polarity_estimation", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.sort_output"], ["", "def", "compute_aspect_category_metrics", "(", "result_dict", ",", "labels", ",", "predictions", ")", ":", "\n", "\n", "    ", "all_true", "=", "[", "]", "\n", "all_pred", "=", "[", "]", "\n", "all_correct", "=", "0", "\n", "all_total", "=", "0", "\n", "\n", "for", "true", ",", "pred", "in", "zip", "(", "labels", ",", "predictions", ")", ":", "\n", "        ", "l", "=", "true", ".", "split", "(", "'<|category|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofcategory|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "p", "=", "pred", ".", "split", "(", "'<|category|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofcategory|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "l_new", ",", "p_new", "=", "sort_output", "(", "l", ",", "p", ")", "\n", "\n", "####### for Acc(full) metric #############", "\n", "all_true", ".", "append", "(", "l_new", ")", "\n", "all_pred", ".", "append", "(", "p_new", ")", "\n", "\n", "all_total", "+=", "1", "\n", "if", "l_new", "==", "p_new", ":", "\n", "            ", "all_correct", "+=", "1", "\n", "\n", "", "", "all_acc", "=", "all_correct", "/", "all_total", "\n", "acc", "=", "accuracy_score", "(", "all_true", ",", "all_pred", ")", "\n", "assert", "acc", "==", "all_acc", "\n", "prec", ",", "recall", ",", "fscore", ",", "_", "=", "precision_recall_fscore_support", "(", "all_true", ",", "all_pred", ",", "average", "=", "'macro'", ")", "\n", "\n", "# compute aspect category detection", "\n", "prec_detect", ",", "recall_detect", ",", "f1_detect", ",", "_", ",", "_", ",", "_", "=", "category_detection", "(", "all_true", ",", "all_pred", ")", "\n", "\n", "# compute aspect category polarity", "\n", "acc_polarity", ",", "acc_polarity_true", ",", "acc_polarity_correct", ",", "_", ",", "_", "=", "aspect_category_polarity_estimation", "(", "all_true", ",", "all_pred", ")", "\n", "\n", "result_dict", ".", "update", "(", "\n", "{", "\n", "'category_acc'", ":", "all_acc", ",", "\n", "'category_prec'", ":", "prec", ",", "\n", "'category_recall'", ":", "recall", ",", "\n", "'category_fscorce'", ":", "fscore", ",", "\n", "\n", "'category_detection_prec'", ":", "prec_detect", ",", "\n", "'category_detection_recall'", ":", "recall_detect", ",", "\n", "'category_detection_fscorce'", ":", "f1_detect", ",", "\n", "\n", "'category_polarity_acc'", ":", "acc_polarity", ",", "\n", "'category_polarity_acc_true'", ":", "acc_polarity_true", ",", "\n", "'category_polarity_acc_correct'", ":", "acc_polarity_correct", "\n", "}", "\n", ")", "\n", "\n", "return", "result_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.compute_aspect_term_aspect_category_metrics": [[886, 1005], ["zip", "sklearn.metrics.accuracy_score", "sklearn.metrics.precision_recall_fscore_support", "sklearn.metrics.accuracy_score", "sklearn.metrics.precision_recall_fscore_support", "sklearn.metrics.accuracy_score", "sklearn.metrics.precision_recall_fscore_support", "metrics.aspect_extraction", "metrics.aspect_polarity_estimation", "metrics.category_detection", "metrics.aspect_category_polarity_estimation", "result_dict.update", "[].strip", "[].strip", "[].strip", "[].strip", "metrics.sort_output", "metrics.sort_output", "all_term_true.append", "all_term_pred.append", "all_category_true.append", "all_category_pred.append", "all_true.append", "all_pred.append", "[].split", "[].split", "[].split", "[].split", "true.split", "pred.split", "true.split", "pred.split"], "function", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.aspect_extraction", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.aspect_polarity_estimation", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.category_detection", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.aspect_category_polarity_estimation", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.sort_output", "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.metrics.sort_output"], ["", "def", "compute_aspect_term_aspect_category_metrics", "(", "result_dict", ",", "labels", ",", "predictions", ")", ":", "\n", "\n", "    ", "all_term_true", "=", "[", "]", "\n", "all_term_pred", "=", "[", "]", "\n", "all_term_correct", "=", "0", "\n", "all_term_total", "=", "0", "\n", "\n", "all_category_true", "=", "[", "]", "\n", "all_category_pred", "=", "[", "]", "\n", "all_category_correct", "=", "0", "\n", "all_category_total", "=", "0", "\n", "\n", "all_true", "=", "[", "]", "\n", "all_pred", "=", "[", "]", "\n", "all_correct", "=", "0", "\n", "all_total", "=", "0", "\n", "\n", "for", "true", ",", "pred", "in", "zip", "(", "labels", ",", "predictions", ")", ":", "\n", "        ", "l_term", "=", "true", ".", "split", "(", "'<|term|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofterm|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "p_term", "=", "pred", ".", "split", "(", "'<|term|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofterm|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "l_category", "=", "true", ".", "split", "(", "'<|category|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofcategory|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "p_category", "=", "pred", ".", "split", "(", "'<|category|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofcategory|>'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "\n", "l_term_sorted", ",", "p_term_sorted", "=", "sort_output", "(", "l_term", ",", "p_term", ")", "\n", "l_category_sorted", ",", "p_category_sorted", "=", "sort_output", "(", "l_category", ",", "p_category", ")", "\n", "\n", "l_joint", "=", "f\"<|term|> {l_term_sorted} <|endofterm|> <|category|> {l_category_sorted} <|endofcategory|>\"", "\n", "p_joint", "=", "f\"<|term|> {p_term_sorted} <|endofterm|> <|category|> {p_category_sorted} <|endofcategory|>\"", "\n", "\n", "####### Term Acc(full) metric #############", "\n", "all_term_true", ".", "append", "(", "l_term_sorted", ")", "\n", "all_term_pred", ".", "append", "(", "p_term_sorted", ")", "\n", "\n", "all_term_total", "+=", "1", "\n", "if", "l_term_sorted", "==", "p_term_sorted", ":", "\n", "            ", "all_term_correct", "+=", "1", "\n", "\n", "####### Category Acc(full) metric #############", "\n", "", "all_category_true", ".", "append", "(", "l_category_sorted", ")", "\n", "all_category_pred", ".", "append", "(", "p_category_sorted", ")", "\n", "\n", "all_category_total", "+=", "1", "\n", "if", "l_category_sorted", "==", "p_category_sorted", ":", "\n", "            ", "all_category_correct", "+=", "1", "\n", "\n", "####### Joint Term + Category Acc(full) metric #############", "\n", "", "all_true", ".", "append", "(", "l_joint", ")", "\n", "all_pred", ".", "append", "(", "p_joint", ")", "\n", "\n", "all_total", "+=", "1", "\n", "if", "l_joint", "==", "p_joint", ":", "\n", "            ", "all_correct", "+=", "1", "\n", "\n", "# term metric #", "\n", "", "", "acc_term", "=", "accuracy_score", "(", "all_term_true", ",", "all_term_pred", ")", "\n", "prec_term", ",", "recall_term", ",", "fscore_term", ",", "_", "=", "precision_recall_fscore_support", "(", "all_term_true", ",", "all_term_pred", ",", "average", "=", "'macro'", ")", "\n", "\n", "# category metric #", "\n", "acc_category", "=", "accuracy_score", "(", "all_category_true", ",", "all_category_pred", ")", "\n", "prec_category", ",", "recall_category", ",", "fscore_category", ",", "_", "=", "precision_recall_fscore_support", "(", "all_category_true", ",", "all_category_pred", ",", "average", "=", "'macro'", ")", "\n", "\n", "# joint metrics #", "\n", "all_acc", "=", "all_correct", "/", "all_total", "\n", "acc", "=", "accuracy_score", "(", "all_true", ",", "all_pred", ")", "\n", "assert", "acc", "==", "all_acc", "\n", "prec", ",", "recall", ",", "fscore", ",", "_", "=", "precision_recall_fscore_support", "(", "all_true", ",", "all_pred", ",", "average", "=", "'macro'", ")", "\n", "\n", "# compute aspect term extraction", "\n", "prec_term_extract", ",", "recall_term_extract", ",", "f1_term_extract", ",", "_", ",", "_", ",", "_", "=", "aspect_extraction", "(", "all_term_true", ",", "all_term_pred", ")", "\n", "\n", "# compute aspect term polarity", "\n", "acc_term_polarity", ",", "acc_term_polarity_true", ",", "acc_term_polarity_correct", ",", "_", ",", "_", "=", "aspect_polarity_estimation", "(", "all_term_true", ",", "all_term_pred", ")", "\n", "\n", "# compute aspect category detection", "\n", "prec_category_detect", ",", "recall_category_detect", ",", "f1_category_detect", ",", "_", ",", "_", ",", "_", "=", "category_detection", "(", "all_category_true", ",", "all_category_pred", ")", "\n", "\n", "# compute aspect category polarity", "\n", "acc_category_polarity", ",", "acc_category_polarity_true", ",", "acc_category_polarity_correct", ",", "_", ",", "_", "=", "aspect_category_polarity_estimation", "(", "all_category_true", ",", "\n", "all_category_pred", ")", "\n", "\n", "result_dict", ".", "update", "(", "\n", "{", "\n", "'joint_acc'", ":", "all_acc", ",", "\n", "'joint_prec'", ":", "prec", ",", "\n", "'joint_recall'", ":", "recall", ",", "\n", "'joint_fscorce'", ":", "fscore", ",", "\n", "\n", "'term_acc'", ":", "acc_term", ",", "\n", "'term_prec'", ":", "prec_term", ",", "\n", "'term_recall'", ":", "recall_term", ",", "\n", "'term_fscorce'", ":", "fscore_term", ",", "\n", "\n", "'term_extract_prec'", ":", "prec_term_extract", ",", "\n", "'term_extract_recall'", ":", "recall_term_extract", ",", "\n", "'term_extract_fscorce'", ":", "f1_term_extract", ",", "\n", "\n", "'term_polarity_acc'", ":", "acc_term_polarity", ",", "\n", "'term_polarity_acc_true'", ":", "acc_term_polarity_true", ",", "\n", "'term_polarity_acc_correct'", ":", "acc_term_polarity_correct", ",", "\n", "\n", "\n", "'category_acc'", ":", "acc_category", ",", "\n", "'category_prec'", ":", "prec_category", ",", "\n", "'category_recall'", ":", "recall_category", ",", "\n", "'category_fscorce'", ":", "fscore_category", ",", "\n", "\n", "'category_detection_prec'", ":", "prec_category_detect", ",", "\n", "'category_detection_recall'", ":", "recall_category_detect", ",", "\n", "'category_detection_fscorce'", ":", "f1_category_detect", ",", "\n", "\n", "'category_polarity_acc'", ":", "acc_category_polarity", ",", "\n", "'category_polarity_acc_true'", ":", "acc_category_polarity_true", ",", "\n", "'category_polarity_acc_correct'", ":", "acc_category_polarity_correct", "\n", "}", "\n", ")", "\n", "\n", "return", "result_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model.compute_label_position_loss": [[15, 62], ["tokenizer.encode", "tokenizer.encode", "tokenizer.encode", "tokenizer.encode", "inputs.cpu().numpy", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "CrossEntropyLoss", "CrossEntropyLoss.", "CrossEntropyLoss.", "CrossEntropyLoss.", "CrossEntropyLoss.", "torch.tensor().to", "loss_fct.isnan", "loss_fct.isnan", "loss_fct.isnan", "loss_fct.isnan", "inputs.cpu", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "torch.tensor", "labels.cpu().numpy", "labels.cpu().numpy", "labels.cpu().numpy", "labels.cpu().numpy", "labels.cpu", "labels.cpu", "labels.cpu", "labels.cpu"], "function", ["None"], ["def", "compute_label_position_loss", "(", "logits", ",", "inputs", ",", "labels", ",", "tokenizer", ",", "args", ")", ":", "\n", "    ", "loss_label", "=", "None", "\n", "negative_token", "=", "tokenizer", ".", "encode", "(", "' negative'", ")", "\n", "positive_token", "=", "tokenizer", ".", "encode", "(", "' positive'", ")", "\n", "neutral_token", "=", "tokenizer", ".", "encode", "(", "' neutral'", ")", "\n", "conflict_token", "=", "tokenizer", ".", "encode", "(", "' conflict'", ")", "\n", "inparr", "=", "inputs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "negative_row", ",", "negative_column", "=", "np", ".", "where", "(", "inparr", "==", "negative_token", ")", "\n", "negative_column", "=", "negative_column", "-", "1", "# shift position", "\n", "negative_logits", "=", "logits", "[", "negative_row", ",", "negative_column", "]", "\n", "positive_row", ",", "positive_column", "=", "np", ".", "where", "(", "inparr", "==", "positive_token", ")", "\n", "positive_column", "=", "positive_column", "-", "1", "# shift position", "\n", "positive_logits", "=", "logits", "[", "positive_row", ",", "positive_column", "]", "\n", "neutral_row", ",", "neutral_column", "=", "np", ".", "where", "(", "inparr", "==", "neutral_token", ")", "\n", "neutral_column", "=", "neutral_column", "-", "1", "# shift position", "\n", "neutral_logits", "=", "logits", "[", "neutral_row", ",", "neutral_column", "]", "\n", "conflict_row", ",", "conflict_column", "=", "np", ".", "where", "(", "inparr", "==", "conflict_token", ")", "\n", "conflict_column", "=", "conflict_column", "-", "1", "# shift position", "\n", "conflict_logits", "=", "logits", "[", "conflict_row", ",", "conflict_column", "]", "\n", "# Flatten the tokens", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "positive_labels", "=", "labels", "[", "np", ".", "where", "(", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "==", "positive_token", ")", "]", "\n", "loss_positive", "=", "loss_fct", "(", "positive_logits", ",", "positive_labels", ")", "\n", "negative_labels", "=", "labels", "[", "np", ".", "where", "(", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "==", "negative_token", ")", "]", "\n", "loss_negative", "=", "loss_fct", "(", "negative_logits", ",", "negative_labels", ")", "\n", "neutral_labels", "=", "labels", "[", "np", ".", "where", "(", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "==", "neutral_token", ")", "]", "\n", "loss_neutral", "=", "loss_fct", "(", "neutral_logits", ",", "neutral_labels", ")", "\n", "conflict_labels", "=", "labels", "[", "np", ".", "where", "(", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "==", "conflict_token", ")", "]", "\n", "loss_conflict", "=", "loss_fct", "(", "conflict_logits", ",", "conflict_labels", ")", "\n", "num_losses", "=", "0", "\n", "step_loss_label", "=", "torch", ".", "tensor", "(", "0", ",", "dtype", "=", "torch", ".", "float64", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "if", "not", "loss_positive", ".", "isnan", "(", ")", ":", "\n", "        ", "step_loss_label", "+=", "loss_positive", "\n", "num_losses", "+=", "1", "\n", "", "if", "not", "loss_negative", ".", "isnan", "(", ")", ":", "\n", "        ", "step_loss_label", "+=", "loss_negative", "\n", "num_losses", "+=", "1", "\n", "", "if", "not", "loss_neutral", ".", "isnan", "(", ")", ":", "\n", "        ", "step_loss_label", "+=", "loss_neutral", "\n", "num_losses", "+=", "1", "\n", "", "if", "not", "loss_conflict", ".", "isnan", "(", ")", ":", "\n", "        ", "step_loss_label", "+=", "loss_conflict", "\n", "num_losses", "+=", "1", "\n", "", "if", "num_losses", "!=", "0", ":", "\n", "        ", "step_loss_label", "/=", "num_losses", "\n", "\n", "", "return", "step_loss_label", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model.compute_loss_at_initialization": [[64, 139], ["tb_writer.add_scalar", "tb_writer.add_scalar", "torch.no_grad", "enumerate", "evaluate", "evaluate.items", "inputs.to.to", "labels.to.to", "model.eval", "model", "tokenizer.encode", "tokenizer.encode", "tokenizer.encode", "inputs.to.cpu().numpy", "numpy.where", "numpy.where", "numpy.where", "CrossEntropyLoss", "CrossEntropyLoss.", "CrossEntropyLoss.", "CrossEntropyLoss.", "loss.mean.item", "tb_writer.add_scalar", "loss_fct.isnan", "loss_fct.isnan", "loss_fct.isnan", "loss.mean.mean", "inputs.to.cpu", "numpy.where", "numpy.where", "numpy.where", "loss_lm.mean.mean", "loss_mc.mean.mean", "labels.to.cpu().numpy", "labels.to.cpu().numpy", "labels.to.cpu().numpy", "labels.to.cpu", "labels.to.cpu", "labels.to.cpu"], "function", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.None.main.evaluate"], ["", "def", "compute_loss_at_initialization", "(", "model", ",", "data_iterator", ",", "tokenizer", ",", "args", ",", "tb_writer", ")", ":", "\n", "    ", "total_loss", "=", "0", "\n", "total_loss_label", "=", "0", "\n", "steps", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "data_iterator", ")", ":", "\n", "            ", "steps", "+=", "1", "\n", "inputs", ",", "labels", "=", "(", "batch", ",", "batch", ")", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "outputs", "=", "model", "(", "inputs", ",", "labels", "=", "labels", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "\n", "logits", "=", "outputs", "[", "1", "]", "\n", "negative_token", "=", "tokenizer", ".", "encode", "(", "' negative'", ")", "\n", "positive_token", "=", "tokenizer", ".", "encode", "(", "' positive'", ")", "\n", "neutral_token", "=", "tokenizer", ".", "encode", "(", "' neutral'", ")", "\n", "inparr", "=", "inputs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "negative_row", ",", "negative_column", "=", "np", ".", "where", "(", "inparr", "==", "negative_token", ")", "\n", "negative_column", "=", "negative_column", "-", "1", "# shift position", "\n", "negative_logits", "=", "logits", "[", "negative_row", ",", "negative_column", "]", "\n", "positive_row", ",", "positive_column", "=", "np", ".", "where", "(", "inparr", "==", "positive_token", ")", "\n", "positive_column", "=", "positive_column", "-", "1", "# shift position", "\n", "positive_logits", "=", "logits", "[", "positive_row", ",", "positive_column", "]", "\n", "neutral_row", ",", "neutral_column", "=", "np", ".", "where", "(", "inparr", "==", "neutral_token", ")", "\n", "neutral_column", "=", "neutral_column", "-", "1", "# shift position", "\n", "neutral_logits", "=", "logits", "[", "neutral_row", ",", "neutral_column", "]", "\n", "# Flatten the tokens", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "positive_labels", "=", "labels", "[", "np", ".", "where", "(", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "==", "positive_token", ")", "]", "\n", "loss_positive", "=", "loss_fct", "(", "positive_logits", ",", "positive_labels", ")", "\n", "negative_labels", "=", "labels", "[", "np", ".", "where", "(", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "==", "negative_token", ")", "]", "\n", "loss_negative", "=", "loss_fct", "(", "negative_logits", ",", "negative_labels", ")", "\n", "neutral_labels", "=", "labels", "[", "np", ".", "where", "(", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "==", "neutral_token", ")", "]", "\n", "loss_neutral", "=", "loss_fct", "(", "neutral_logits", ",", "neutral_labels", ")", "\n", "num_losses", "=", "0", "\n", "step_loss_label", "=", "0", "\n", "if", "not", "loss_positive", ".", "isnan", "(", ")", ":", "\n", "                ", "step_loss_label", "+=", "loss_positive", "\n", "num_losses", "+=", "1", "\n", "", "if", "not", "loss_negative", ".", "isnan", "(", ")", ":", "\n", "                ", "step_loss_label", "+=", "loss_negative", "\n", "num_losses", "+=", "1", "\n", "", "if", "not", "loss_neutral", ".", "isnan", "(", ")", ":", "\n", "                ", "step_loss_label", "+=", "loss_neutral", "\n", "num_losses", "+=", "1", "\n", "", "step_loss_label", "/=", "num_losses", "\n", "total_loss_label", "+=", "step_loss_label", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "if", "args", ".", "model_type", "==", "'gpt2_double'", ":", "\n", "                    ", "loss_lm", "=", "loss_lm", ".", "mean", "(", ")", "\n", "loss_mc", "=", "loss_mc", ".", "mean", "(", ")", "\n", "", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "if", "args", ".", "model_type", "==", "'gpt2_double'", ":", "\n", "                    ", "loss_lm", "=", "loss_lm", "/", "args", ".", "gradient_accumulation_steps", "\n", "loss_mc", "=", "loss_mc", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "", "", "train_loss", "=", "total_loss", "/", "steps", "\n", "train_loss_label", "=", "total_loss_label", "/", "steps", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss\"", ",", "train_loss", ",", "0", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss_label\"", ",", "train_loss_label", ",", "0", ")", "\n", "\n", "for", "split", "in", "args", ".", "eval_splits", ":", "\n", "        ", "eval_results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "split", "=", "split", ")", "\n", "\n", "for", "key", ",", "value", "in", "eval_results", ".", "items", "(", ")", ":", "\n", "            ", "tb_writer", ".", "add_scalar", "(", "\"metrics/{}/{}\"", ".", "format", "(", "split", ",", "key", ")", ",", "value", ",", "0", ")", "\n", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model.compute_gpt2_weights_norm": [[141, 167], ["model.named_parameters", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "all_params.append", "p.data.cpu().numpy", "name.split", "attention_params.append", "numpy.linalg.norm().mean", "numpy.linalg.norm().mean", "numpy.linalg.norm().sum", "w.sum", "numpy.linalg.norm().mean", "numpy.linalg.norm().mean", "numpy.linalg.norm().sum", "w.sum", "p.data.cpu().numpy", "p.data.cpu", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.linalg.norm", "p.data.cpu"], "function", ["None"], ["", "def", "compute_gpt2_weights_norm", "(", "model", ",", "results", ")", ":", "\n", "    ", "attention_params", "=", "[", "]", "\n", "all_params", "=", "[", "]", "\n", "for", "name", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "all_params", ".", "append", "(", "p", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "if", "'bias'", "not", "in", "name", "and", "(", "'c_proj'", "in", "name", "or", "'c_attn'", "in", "name", ")", ":", "\n", "            ", "_", ",", "_", ",", "block", ",", "_", ",", "l", ",", "_", "=", "name", ".", "split", "(", "'.'", ")", "\n", "attention_params", ".", "append", "(", "p", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "", "attention_l2_norms", "=", "np", ".", "mean", "(", "[", "np", ".", "linalg", ".", "norm", "(", "w", ",", "ord", "=", "2", ",", "axis", "=", "0", ")", ".", "mean", "(", ")", "for", "w", "in", "attention_params", "]", ")", "\n", "attention_l1_norms", "=", "np", ".", "mean", "(", "[", "np", ".", "linalg", ".", "norm", "(", "w", ",", "ord", "=", "1", ",", "axis", "=", "0", ")", ".", "mean", "(", ")", "for", "w", "in", "attention_params", "]", ")", "\n", "attention_sum_abs", "=", "np", ".", "mean", "(", "[", "np", ".", "linalg", ".", "norm", "(", "w", ",", "ord", "=", "1", ",", "axis", "=", "0", ")", ".", "sum", "(", ")", "for", "w", "in", "attention_params", "]", ")", "\n", "attention_sum", "=", "np", ".", "mean", "(", "[", "w", ".", "sum", "(", ")", "for", "w", "in", "attention_params", "]", ")", "\n", "all_l2_norms", "=", "np", ".", "mean", "(", "[", "np", ".", "linalg", ".", "norm", "(", "w", ",", "ord", "=", "2", ",", "axis", "=", "0", ")", ".", "mean", "(", ")", "for", "w", "in", "all_params", "]", ")", "\n", "all_l1_norms", "=", "np", ".", "mean", "(", "[", "np", ".", "linalg", ".", "norm", "(", "w", ",", "ord", "=", "1", ",", "axis", "=", "0", ")", ".", "mean", "(", ")", "for", "w", "in", "all_params", "]", ")", "\n", "all_sum_abs", "=", "np", ".", "mean", "(", "[", "np", ".", "linalg", ".", "norm", "(", "w", ",", "ord", "=", "1", ",", "axis", "=", "0", ")", ".", "sum", "(", ")", "for", "w", "in", "all_params", "]", ")", "\n", "all_sum", "=", "np", ".", "mean", "(", "[", "w", ".", "sum", "(", ")", "for", "w", "in", "all_params", "]", ")", "\n", "# ipdb.set_trace()", "\n", "results", "[", "'attention_l2norm'", "]", "=", "attention_l2_norms", "\n", "results", "[", "'attention_l1norm'", "]", "=", "attention_l1_norms", "\n", "results", "[", "'attention_sum_abs'", "]", "=", "attention_sum_abs", "\n", "results", "[", "'attention_sum'", "]", "=", "attention_sum", "\n", "results", "[", "'all_l2norm'", "]", "=", "all_l2_norms", "\n", "results", "[", "'all_l1norm'", "]", "=", "all_l1_norms", "\n", "results", "[", "'all_sum_abs'", "]", "=", "all_sum_abs", "\n", "results", "[", "'all_sum'", "]", "=", "all_sum", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model.extract_model_weights": [[169, 188], ["model.named_parameters", "numpy.concatenate", "numpy.concatenate", "all_params.append", "unfolded_params.append", "unfolded_params.append", "p.data.cpu().numpy", "name.split", "attention_params.append", "p.reshape", "p.reshape", "p.data.cpu().numpy", "p.data.cpu", "p.data.cpu"], "function", ["None"], ["", "def", "extract_model_weights", "(", "model", ")", ":", "\n", "    ", "attention_params", "=", "[", "]", "\n", "all_params", "=", "[", "]", "\n", "for", "name", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "all_params", ".", "append", "(", "p", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "if", "'bias'", "not", "in", "name", "and", "(", "'c_proj'", "in", "name", "or", "'c_attn'", "in", "name", ")", ":", "\n", "            ", "_", ",", "_", ",", "block", ",", "_", ",", "l", ",", "_", "=", "name", ".", "split", "(", "'.'", ")", "\n", "attention_params", ".", "append", "(", "p", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "unfolded_params", "=", "[", "]", "\n", "for", "p", "in", "all_params", ":", "\n", "        ", "unfolded_params", ".", "append", "(", "p", ".", "reshape", "(", "-", "1", ")", ")", "\n", "", "all_params_unfolded", "=", "np", ".", "concatenate", "(", "unfolded_params", ",", "0", ")", "\n", "\n", "unfolded_params", "=", "[", "]", "\n", "for", "p", "in", "attention_params", ":", "\n", "        ", "unfolded_params", ".", "append", "(", "p", ".", "reshape", "(", "-", "1", ")", ")", "\n", "", "attention_params_unfolded", "=", "np", ".", "concatenate", "(", "unfolded_params", ",", "0", ")", "\n", "return", "all_params_unfolded", ",", "attention_params_unfolded", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model.extract_gpt2_weights": [[190, 217], ["dict", "model.named_parameters", "dict", "dict.keys", "dict.setdefault().append", "numpy.concatenate", "p.data.cpu().numpy", "dict.setdefault().append", "tmp.append", "dict.setdefault", "p.data.cpu().numpy", "dict.setdefault().append", "p.reshape", "p.data.cpu", "dict.setdefault", "p.data.cpu().numpy", "dict.setdefault().append", "p.data.cpu", "dict.setdefault", "p.data.cpu().numpy", "dict.setdefault().append", "p.data.cpu", "dict.setdefault", "p.data.cpu().numpy", "dict.setdefault().append", "print", "ipdb.set_trace", "p.data.cpu", "dict.setdefault", "p.data.cpu().numpy", "p.data.cpu", "dict.setdefault", "p.data.cpu"], "function", ["None"], ["", "def", "extract_gpt2_weights", "(", "model", ")", ":", "\n", "    ", "params", "=", "dict", "(", ")", "\n", "for", "name", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "params", ".", "setdefault", "(", "'all'", ",", "[", "]", ")", ".", "append", "(", "p", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "if", "'attn'", "in", "name", ":", "\n", "            ", "params", ".", "setdefault", "(", "'attention'", ",", "[", "]", ")", ".", "append", "(", "p", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "elif", "'mlp'", "in", "name", ":", "\n", "            ", "params", ".", "setdefault", "(", "'feedforward'", ",", "[", "]", ")", ".", "append", "(", "p", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "elif", "'ln_'", "in", "name", ":", "\n", "            ", "params", ".", "setdefault", "(", "'layernorm'", ",", "[", "]", ")", ".", "append", "(", "p", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "# elif 'pooler' in name:", "\n", "#     params.setdefault('pooler', []).append(p.data.cpu().numpy())", "\n", "", "elif", "'score'", "in", "name", ":", "\n", "            ", "params", ".", "setdefault", "(", "'classifier'", ",", "[", "]", ")", ".", "append", "(", "p", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "elif", "'wte'", "in", "name", "or", "'wpe'", "in", "name", ":", "\n", "            ", "params", ".", "setdefault", "(", "'embeddings'", ",", "[", "]", ")", ".", "append", "(", "p", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f\"unknown name {name}\"", ")", "\n", "ipdb", ".", "set_trace", "(", ")", "\n", "", "", "unfolded_params", "=", "dict", "(", ")", "\n", "for", "k", "in", "params", ".", "keys", "(", ")", ":", "\n", "        ", "tmp", "=", "[", "]", "\n", "for", "p", "in", "params", "[", "k", "]", ":", "\n", "            ", "tmp", ".", "append", "(", "p", ".", "reshape", "(", "-", "1", ")", ")", "\n", "", "unfolded_params", "[", "k", "]", "=", "np", ".", "concatenate", "(", "tmp", ",", "0", ")", "\n", "\n", "", "return", "unfolded_params", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model.set_seed": [[219, 225], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model._sorted_checkpoints": [[227, 243], ["glob.glob", "sorted", "os.path.join", "ordering_and_checkpoint_path.append", "regex.match", "re.match.groups", "ordering_and_checkpoint_path.append", "os.path.getmtime", "int", "re.match.groups"], "function", ["None"], ["", "", "def", "_sorted_checkpoints", "(", "args", ",", "checkpoint_prefix", "=", "\"checkpoint\"", ",", "use_mtime", "=", "False", ")", ":", "\n", "    ", "ordering_and_checkpoint_path", "=", "[", "]", "\n", "\n", "glob_checkpoints", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-*\"", ".", "format", "(", "checkpoint_prefix", ")", ")", ")", "\n", "\n", "for", "path", "in", "glob_checkpoints", ":", "\n", "        ", "if", "use_mtime", ":", "\n", "            ", "ordering_and_checkpoint_path", ".", "append", "(", "(", "os", ".", "path", ".", "getmtime", "(", "path", ")", ",", "path", ")", ")", "\n", "", "else", ":", "\n", "            ", "regex_match", "=", "re", ".", "match", "(", "\".*{}-([0-9]+)\"", ".", "format", "(", "checkpoint_prefix", ")", ",", "path", ")", "\n", "if", "regex_match", "and", "regex_match", ".", "groups", "(", ")", ":", "\n", "                ", "ordering_and_checkpoint_path", ".", "append", "(", "(", "int", "(", "regex_match", ".", "groups", "(", ")", "[", "0", "]", ")", ",", "path", ")", ")", "\n", "\n", "", "", "", "checkpoints_sorted", "=", "sorted", "(", "ordering_and_checkpoint_path", ")", "\n", "checkpoints_sorted", "=", "[", "checkpoint", "[", "1", "]", "for", "checkpoint", "in", "checkpoints_sorted", "]", "\n", "return", "checkpoints_sorted", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model._rotate_checkpoints": [[245, 261], ["model._sorted_checkpoints", "max", "len", "logger.info", "shutil.rmtree", "len"], "function", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model._sorted_checkpoints"], ["", "def", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", "=", "\"checkpoint\"", ",", "use_mtime", "=", "False", ")", ":", "\n", "    ", "if", "not", "args", ".", "save_total_limit", ":", "\n", "        ", "return", "\n", "", "if", "args", ".", "save_total_limit", "<=", "0", ":", "\n", "        ", "return", "\n", "\n", "# Check if we should delete older checkpoint(s)", "\n", "", "checkpoints_sorted", "=", "_sorted_checkpoints", "(", "args", ",", "checkpoint_prefix", ",", "use_mtime", ")", "\n", "if", "len", "(", "checkpoints_sorted", ")", "<=", "args", ".", "save_total_limit", ":", "\n", "        ", "return", "\n", "\n", "", "number_of_checkpoints_to_delete", "=", "max", "(", "0", ",", "len", "(", "checkpoints_sorted", ")", "-", "args", ".", "save_total_limit", ")", "\n", "checkpoints_to_be_deleted", "=", "checkpoints_sorted", "[", ":", "number_of_checkpoints_to_delete", "]", "\n", "for", "checkpoint", "in", "checkpoints_to_be_deleted", ":", "\n", "        ", "logger", ".", "info", "(", "\"Deleting older checkpoint [{}] due to args.save_total_limit\"", ".", "format", "(", "checkpoint", ")", ")", "\n", "shutil", ".", "rmtree", "(", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model.save_checkpoint": [[263, 280], ["os.path.join", "os.makedirs", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "model._rotate_checkpoints", "torch.save", "torch.save", "logger.info", "hasattr", "os.path.join", "optimizer.state_dict", "os.path.join", "scheduler.state_dict", "os.path.join"], "function", ["home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.model._rotate_checkpoints"], ["", "", "def", "save_checkpoint", "(", "model", ",", "optimizer", ",", "scheduler", ",", "tokenizer", ",", "args", ",", "global_step", ")", ":", "\n", "    ", "checkpoint_prefix", "=", "\"checkpoint\"", "\n", "# Save model checkpoint", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-{}\"", ".", "format", "(", "checkpoint_prefix", ",", "global_step", ")", ")", "\n", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "model_to_save", "=", "(", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", ")", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.gpt2_args_parser.ArgsParser.__init__": [[8, 182], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--subtask\"", ",", "default", "=", "'single_term_polarity'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The aspect-base subtask.\"", ",", "\n", "choices", "=", "[", "'single_term_polarity'", ",", "'aspect_term'", ",", "\n", "'single_category_polarity'", ",", "'aspect_category'", ",", "\n", "'aspect_term_aspect_category'", ",", "\n", "'aspect_term_aspect_category_split'", ",", "\n", "'sentiment'", ",", "'sst2'", "]", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dataset\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The dataset (task).\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input training data file (a text file).\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"The model architecture to be trained or fine-tuned.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_data_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--test_data_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_splits\"", ",", "\n", "default", "=", "'val,test'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"split set to be evaluated.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_per_domain\"", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"domain to be evaluated.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_oos\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"evaluate out of scope\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--should_continue\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to continue from latest checkpoint in output_dir\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization. Leave None if you want to train a model from scratch.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_checkpoint\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"evaluated checkpoint.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path. If both are None, initialize a new config.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path. If both are None, initialize a new tokenizer.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional directory to store the pre-trained models downloaded from s3 (instead of the default one)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_size\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Optional input sequence length after tokenization.\"", "\n", "\"The training dataset will be truncated in block of this size for training.\"", "\n", "\"Default to the model max input length for single sentence inputs (take into account special tokens).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--confidence_threshold\"", ",", "default", "=", "0.99", ",", "type", "=", "float", ",", "help", "=", "\"confidence.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "200.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_total_limit\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Limit the total amount of checkpoints, delete the older checkpoints in the output_dir, does not delete by default\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "# parser.add_argument(", "\n", "#     \"--overwrite_output_dir\", action=\"store_true\", help=\"Overwrite the content of the output directory\"", "\n", "# )", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--device\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"gpu number\"", ")", "\n", "self", ".", "parser", "=", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.gpt2_args_parser.ArgsParser.parse": [[183, 186], ["gpt2_args_parser.ArgsParser.parser.parse_args"], "methods", ["None"], ["", "def", "parse", "(", "self", ")", ":", "\n", "        ", "args", "=", "self", ".", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "", "", "", ""]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.language_model.get_optimizer_scheduler": [[12, 37], ["transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "os.path.isfile", "os.path.isfile", "transformers.AdamW.load_state_dict", "transformers.get_linear_schedule_with_warmup.load_state_dict", "os.path.join", "os.path.join", "torch.load", "torch.load", "os.path.join", "os.path.join", "model.named_parameters", "model.named_parameters", "any", "any"], "function", ["None"], ["def", "get_optimizer_scheduler", "(", "args", ",", "model", ",", "t_total", ")", ":", "\n", "    ", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "(", "\n", "args", ".", "model_name_or_path", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", "\n", ")", ":", "\n", "# Load in optimizer and scheduler states", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "return", "optimizer", ",", "scheduler", "\n", "", ""]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.util.clean.clean_text": [[5, 13], ["regex.sub", "re.sub.lower().strip", "re.sub.lower"], "function", ["None"], ["def", "clean_text", "(", "text", ")", ":", "\n", "    ", "'''\n    remove special characters, lower\n    :param text:\n    :return: cleaned text\n    '''", "\n", "text", "=", "re", ".", "sub", "(", "\"[^A-Za-z0-9?!(),.'$%:-]+\"", ",", "\" \"", ",", "text", ")", "\n", "return", "text", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.LineByLineTextDataset.__init__": [[13, 24], ["os.path.isfile", "logger.info", "open", "tokenizer.batch_encode_plus", "f.read().splitlines", "f.read", "len", "line.isspace"], "methods", ["None"], ["    ", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.LineByLineTextDataset.__len__": [[25, 27], ["len"], "methods", ["None"], ["\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "(", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.LineByLineTextDataset.__getitem__": [[28, 30], ["torch.tensor"], "methods", ["None"], ["args", ".", "model_name_or_path", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", "\n"]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.LineByLineTextDataset_gpt2_double.__init__": [[33, 47], ["os.path.isfile", "logger.info", "open", "f.read().splitlines", "tokenizer.batch_encode_plus", "f.read", "line.split", "int", "len", "line.isspace", "line.split", "len", "line.isspace"], "methods", ["None"], ["        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "return", "optimizer", ",", "scheduler", "\n", "", ""]], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.LineByLineTextDataset_gpt2_double.__len__": [[48, 50], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.LineByLineTextDataset_gpt2_double.__getitem__": [[51, 53], ["torch.tensor", "torch.tensor"], "methods", ["None"], []], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.load_and_cache_examples": [[55, 77], ["language_model.LineByLineTextDataset_gpt2_double", "language_model.LineByLineTextDataset", "language_model.LineByLineTextDataset_gpt2_double", "language_model.LineByLineTextDataset", "TypeError"], "function", ["None"], []], "home.repos.pwc.inspect_result.salesforce_fewshot_absa.dataset.language_model.get_dataloader": [[79, 110], ["torch.utils.data.DataLoader", "torch.utils.data.SequentialSampler", "torch.stack", "torch.nn.utils.rnn.pad_sequence", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "max", "torch.stack", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence"], "function", ["None"], []]}