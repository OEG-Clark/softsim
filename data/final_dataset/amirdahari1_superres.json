{"home.repos.pwc.inspect_result.amirdahari1_superres.code.LearnTools.DownSample.__init__": [[188, 223], ["torch.nn.Module.__init__", "torch.cat", "LearnTools.DownSample.low_res_idx.numel", "torch.nn.MSELoss", "LearnTools.DownSample.calc_gaussian_kernel_3d", "LearnTools.DownSample.gaussian_k.view", "LearnTools.DownSample.gaussian_k.repeat().to", "torch.zeros().to", "LearnTools.DownSample.gaussian_k.size", "LearnTools.DownSample.gaussian_k.repeat", "torch.zeros", "LearnTools.DownSample.gaussian_k.dim"], "methods", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator2D.__init__", "home.repos.pwc.inspect_result.amirdahari1_superres.code.LearnTools.DownSample.calc_gaussian_kernel_3d"], ["def", "__init__", "(", "self", ",", "squash", ",", "n_dims", ",", "low_res_idx", ",", "scale_factor", ",", "\n", "device", ",", "super_sampling", "=", "False", ",", "separator", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param n_dims: 2d to 2d or 3d to 3d.\n        :param low_res_idx: the indices of phases to down-sample.\n        :param scale_factor: scale factor between high-res and low-res.\n        :param squash: if to squash all material phases together for\n        :param separator: different voxel-wise loss for the separator material.\n        :param device: The device the object is on.\n        down-sampling. (when it is hard to distinguish between material phases\n        in low resolution e.g. SOFC cathode.)\n        \"\"\"", "\n", "super", "(", "DownSample", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "squash", "=", "squash", "\n", "self", ".", "n_dims", "=", "n_dims", "\n", "# Here we want to compare the pore as well:", "\n", "self", ".", "low_res_idx", "=", "torch", ".", "cat", "(", "(", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "low_res_idx", ")", ",", "\n", "low_res_idx", ")", ")", "\n", "\n", "self", ".", "low_res_len", "=", "self", ".", "low_res_idx", ".", "numel", "(", ")", "# how many phases", "\n", "self", ".", "scale_factor", "=", "scale_factor", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "separator", "=", "separator", "\n", "self", ".", "voxel_wise_loss", "=", "nn", ".", "MSELoss", "(", ")", "# the voxel-wise loss", "\n", "# Calculate the gaussian kernel and make the 3d convolution:", "\n", "self", ".", "gaussian_k", "=", "self", ".", "calc_gaussian_kernel_3d", "(", "self", ".", "scale_factor", ")", "\n", "# Reshape to convolutional weight", "\n", "self", ".", "gaussian_k", "=", "self", ".", "gaussian_k", ".", "view", "(", "1", ",", "1", ",", "*", "self", ".", "gaussian_k", ".", "size", "(", ")", ")", "\n", "self", ".", "gaussian_k", "=", "self", ".", "gaussian_k", ".", "repeat", "(", "self", ".", "low_res_len", ",", "*", "[", "1", "]", "*", "(", "\n", "self", ".", "gaussian_k", ".", "dim", "(", ")", "-", "1", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "groups", "=", "self", ".", "low_res_len", "# ensures that each phase will be", "\n", "# blurred independently.", "\n", "self", ".", "gaussian_conv", "=", "functional", ".", "conv3d", "\n", "self", ".", "softmax", "=", "functional", ".", "softmax", "\n", "self", ".", "super_sampling", "=", "super_sampling", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.LearnTools.DownSample.voxel_wise_distance": [[224, 242], ["LearnTools.DownSample.", "torch.nn.MSELoss", "torch.nn.MSELoss"], "methods", ["None"], ["", "def", "voxel_wise_distance", "(", "self", ",", "generated_im", ",", "low_res", ")", ":", "\n", "        ", "\"\"\"\n        calculates and returns the pixel wise distance between the low-res\n        image and the down sampling of the high-res generated image.\n        :return: the normalized distance (divided by the number of pixels of\n        the low resolution image.)\n        \"\"\"", "\n", "down_sampled_im", "=", "self", "(", "generated_im", ")", "\n", "if", "self", ".", "separator", ":", "# no punishment for making more material where pore", "\n", "# is in low_res. All low res phases which are not pore are to be", "\n", "# matched:", "\n", "            ", "low_res", "=", "low_res", "[", ":", ",", "1", ":", "]", "\n", "down_sampled_im", "=", "down_sampled_im", "[", ":", ",", "1", ":", "]", "\n", "down_sampled_im", "=", "down_sampled_im", "*", "low_res", "\n", "return", "torch", ".", "nn", ".", "MSELoss", "(", ")", "(", "low_res", ",", "down_sampled_im", ")", "\n", "# There is a double error for a mismatch:", "\n", "", "mse_loss", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", "(", "low_res", ",", "down_sampled_im", ")", "\n", "return", "mse_loss", "*", "self", ".", "low_res_len", "/", "2", "# to standardize the loss.", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.LearnTools.DownSample.forward": [[243, 270], ["torch.index_select", "LearnTools.DownSample.gaussian_conv", "torch.nn.functional.interpolate", "LearnTools.DownSample.softmax", "torch.sum().unsqueeze", "torch.nn.functional.interpolate", "LearnTools.DownSample.get_low_res_input", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.LearnTools.DownSample.get_low_res_input"], ["", "def", "forward", "(", "self", ",", "generated_im", ",", "low_res_input", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Apply gaussian filter to the generated image.\n        \"\"\"", "\n", "# First choose the material phase in the image:", "\n", "low_res_phases", "=", "torch", ".", "index_select", "(", "generated_im", ",", "1", ",", "self", ".", "low_res_idx", ")", "\n", "if", "self", ".", "squash", ":", "# all phases of material are same in low-res", "\n", "# sum all the material phases:", "\n", "            ", "low_res_phases", "=", "torch", ".", "sum", "(", "low_res_phases", ",", "dim", "=", "1", ")", ".", "unsqueeze", "(", "\n", "dim", "=", "1", ")", "\n", "# if it is super-sampling, return nearest-neighbour interpolation:", "\n", "", "if", "self", ".", "super_sampling", ":", "\n", "            ", "return", "interpolate", "(", "low_res_phases", ",", "scale_factor", "=", "1", "/", "\n", "self", ".", "scale_factor", ",", "mode", "=", "'nearest'", ")", "\n", "# Then gaussian blur the low res phases generated image:", "\n", "", "blurred_im", "=", "self", ".", "gaussian_conv", "(", "input", "=", "low_res_phases", ",", "\n", "weight", "=", "self", ".", "gaussian_k", ",", "\n", "padding", "=", "'same'", ",", "groups", "=", "self", ".", "groups", ")", "\n", "# Then downsample using trilinear interpolation:", "\n", "blurred_low_res", "=", "interpolate", "(", "blurred_im", ",", "\n", "scale_factor", "=", "1", "/", "self", ".", "scale_factor", ",", "\n", "mode", "=", "modes", "[", "self", ".", "n_dims", "-", "2", "]", ")", "\n", "if", "low_res_input", ":", "# calculate a low-res input.", "\n", "            ", "return", "self", ".", "get_low_res_input", "(", "blurred_low_res", ")", "\n", "# Multiplying the softmax probabilities by a large number to get a", "\n", "# differentiable argmax function to avoid blocky super-res volumes:", "\n", "", "return", "self", ".", "softmax", "(", "blurred_low_res", "*", "100", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.LearnTools.DownSample.get_low_res_input": [[271, 286], ["torch.argmax", "torch.nn.functional.one_hot", "torch.nn.functional.one_hot.permute", "torch.argmax.size", "torch.rand", "torch.arange", "torch.argmax.size"], "methods", ["None"], ["", "def", "get_low_res_input", "(", "self", ",", "blurred_image", ")", ":", "\n", "        ", "\"\"\"\n        If only the low-res input is to be calculated for evaluation study.\n        :param blurred_image: after the image has been blurred and\n        down-sampled.\n        :return: a batch_size X low_res_phases X *low_res_vol_dimensions of a\n        for a one-hot volume.\n        \"\"\"", "\n", "# Adding little noise for the (0.5, 0.5) scenarios.", "\n", "blurred_image", "+=", "(", "torch", ".", "rand", "(", "blurred_image", ".", "size", "(", ")", ",", "\n", "device", "=", "blurred_image", ".", "device", ")", "-", "0.5", ")", "/", "1000", "\n", "num_phases", "=", "blurred_image", ".", "size", "(", ")", "[", "1", "]", "\n", "blurred_image", "=", "torch", ".", "argmax", "(", "blurred_image", ",", "dim", "=", "1", ")", "# find max phase", "\n", "one_hot_vol", "=", "one_hot", "(", "blurred_image", ",", "num_classes", "=", "num_phases", ")", "\n", "return", "one_hot_vol", ".", "permute", "(", "0", ",", "-", "1", ",", "*", "torch", ".", "arange", "(", "1", ",", "self", ".", "n_dims", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.LearnTools.DownSample.calc_gaussian_kernel_3d": [[287, 305], ["math.ceil", "torch.linspace", "torch.exp", "torch.einsum", "torch.exp.sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "calc_gaussian_kernel_3d", "(", "scale_factor", ")", ":", "\n", "        ", "\"\"\"\n        :param scale_factor: The scale factor used between the low- and\n        high-res volumes.\n        :return: A gaussian blur 3d kernel for blurring before interpolating\n        \"\"\"", "\n", "ks", "=", "math", ".", "ceil", "(", "scale_factor", ")", "# the kernel size", "\n", "if", "ks", "%", "2", "==", "0", ":", "\n", "            ", "ks", "-=", "1", "# if even, the closest odd number from below.", "\n", "# The same default sigma as in transforms.functional.gaussian_blur:", "\n", "", "sigma", "=", "0.3", "*", "(", "(", "ks", "-", "1", ")", "*", "0.5", "-", "1", ")", "+", "0.8", "\n", "ts", "=", "torch", ".", "linspace", "(", "-", "(", "ks", "//", "2", ")", ",", "ks", "//", "2", ",", "ks", ")", "\n", "gauss", "=", "torch", ".", "exp", "(", "(", "-", "(", "ts", "/", "sigma", ")", "**", "2", "/", "2", ")", ")", "\n", "kernel_1d", "=", "gauss", "/", "gauss", ".", "sum", "(", ")", "# Normalization", "\n", "# 3d gaussian kernel can be computed in the following way:", "\n", "kernel_3d", "=", "torch", ".", "einsum", "(", "'i,j,k->ijk'", ",", "kernel_1d", ",", "kernel_1d", ",", "kernel_1d", ")", "\n", "return", "kernel_3d", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.LearnTools.return_args": [[17, 79], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.parse_known_args"], "function", ["None"], ["def", "return_args", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "'-d'", ",", "'--directory'", ",", "type", "=", "str", ",", "default", "=", "'default'", ",", "\n", "help", "=", "'Stores the progress output in the \\\n                        directory name given'", ")", "\n", "parser", ".", "add_argument", "(", "'-sf'", ",", "'--scale_factor'", ",", "type", "=", "float", ",", "default", "=", "4", ",", "\n", "help", "=", "'scale factor between high res and low res.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--down_sample\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Down samples the input for G for testing \"", "\n", "\"purposes.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--super_sampling\"", ",", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "help", "=", "\"When comparing super-res \"", "\n", "\"and low-res, instead of blurring, it picks one voxel \"", "\n", "\"with nearest-neighbour interpolation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--squash_phases\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"All material phases in low res are the same.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--anisotropic\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"The material is anisotropic (requires dif Ds).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--with_rotation\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"create rotations and mirrors for the BM.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--separator\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Different voxel-wise loss for separator \"", "\n", "\"material.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-rotations_bool'", ",", "nargs", "=", "'+'", ",", "type", "=", "int", ",", "\n", "default", "=", "[", "0", ",", "0", ",", "1", "]", ",", "help", "=", "\"If the material is \"", "\n", "\"anisotropic, specify which images can be augmented \"", "\n", "\"(rotations and mirrors)\"", ")", "\n", "parser", ".", "add_argument", "(", "'-g_image_path'", ",", "type", "=", "str", ",", "help", "=", "\"Path to the LR \"", "\n", "\"3D volume\"", ")", "\n", "parser", ".", "add_argument", "(", "'-d_image_path'", ",", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "help", "=", "\"Path to \"", "\n", "\"the HR 2D slice, if Isotropic, 3 paths are needed, \"", "\n", "\"in correct order\"", ")", "\n", "parser", ".", "add_argument", "(", "'-phases_idx'", ",", "'--phases_low_res_idx'", ",", "nargs", "=", "'+'", ",", "\n", "type", "=", "int", ",", "default", "=", "[", "1", ",", "2", "]", ")", "\n", "parser", ".", "add_argument", "(", "'-d_dimensions'", ",", "'--d_dimensions_to_check'", ",", "nargs", "=", "'+'", ",", "\n", "type", "=", "int", ",", "default", "=", "[", "0", ",", "1", ",", "2", "]", ")", "\n", "parser", ".", "add_argument", "(", "'-volume_size_to_evaluate'", ",", "nargs", "=", "'+'", ",", "type", "=", "int", ",", "\n", "default", "=", "[", "128", ",", "128", ",", "128", "]", ")", "\n", "parser", ".", "add_argument", "(", "'-wd'", ",", "'--widthD'", ",", "type", "=", "int", ",", "default", "=", "9", ",", "\n", "help", "=", "'Hyper-parameter for \\\n                        the width of the Discriminator network'", ")", "\n", "parser", ".", "add_argument", "(", "'-wg'", ",", "'--widthG'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'Hyper-parameter for the \\\n                        width of the Generator network'", ")", "\n", "parser", ".", "add_argument", "(", "'-n_res'", ",", "'--n_res_blocks'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of residual blocks in the network.'", ")", "\n", "parser", ".", "add_argument", "(", "'-n_dims'", ",", "'--n_dims'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "'The generated image dimension (and input '", "\n", "'dimension), can be either 2 or 3.'", ")", "\n", "parser", ".", "add_argument", "(", "'-gu'", ",", "'--g_update'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'Number of iterations the generator waits before '", "\n", "'being updated'", ")", "\n", "parser", ".", "add_argument", "(", "'-e'", ",", "'--num_epochs'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Number of epochs.'", ")", "\n", "parser", ".", "add_argument", "(", "'-pix_d'", ",", "'--pixel_coefficient_distance'", ",", "type", "=", "int", ",", "\n", "default", "=", "10", ",", "\n", "help", "=", "'The coefficient of the pixel distance loss '", "\n", "'added to the cost of G.'", ")", "\n", "parser", ".", "add_argument", "(", "'-g_epoch_id'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'Since '", "\n", "'more than 1 G is saved during a run, specific G can '", "\n", "'be chosen for evaluation'", ")", "\n", "args", ",", "unknown", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.LearnTools.forty_five_deg_masks": [[81, 112], ["int", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "math.sqrt", "torch.zeros.size", "torch.zeros.size", "torch.zeros.size", "range", "masks.extend", "range", "masks.extend"], "function", ["None"], ["", "def", "forty_five_deg_masks", "(", "batch_size", ",", "phases", ",", "high_l", ")", ":", "\n", "    ", "\"\"\"\n    :param batch_size: batch size for the images for the making of the mask.\n    :param phases: number of phases.\n    :param high_l: the length of the high resolution\n    :return: list of two masks of the 45 degree angle slices along the\n    z-axis of the 3d (returns masks for both slices of 45 degrees).\n    \"\"\"", "\n", "over_sqrt_2", "=", "int", "(", "high_l", "/", "math", ".", "sqrt", "(", "2", ")", ")", "# high_l in the diagonal", "\n", "\n", "# create the masks:", "\n", "masks", "=", "[", "]", "\n", "for", "m", "in", "range", "(", "high_l", "-", "over_sqrt_2", ")", ":", "\n", "        ", "mask1", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "phases", ",", "*", "[", "high_l", "]", "*", "3", ")", ",", "\n", "dtype", "=", "torch", ".", "bool", ")", "\n", "mask2", "=", "torch", ".", "zeros", "(", "mask1", ".", "size", "(", ")", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "mask3", "=", "torch", ".", "zeros", "(", "mask1", ".", "size", "(", ")", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "mask4", "=", "torch", ".", "zeros", "(", "mask1", ".", "size", "(", ")", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "if", "m", "==", "0", ":", "\n", "            ", "for", "i", "in", "range", "(", "over_sqrt_2", ")", ":", "\n", "                ", "mask1", "[", "...", ",", "m", "+", "i", ",", "i", ",", ":", "]", "=", "True", "\n", "mask3", "[", "...", ",", "i", "+", "m", ",", "-", "1", "-", "i", ",", ":", "]", "=", "True", "\n", "", "masks", ".", "extend", "(", "[", "mask1", ",", "mask3", "]", ")", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "over_sqrt_2", ")", ":", "\n", "                ", "mask1", "[", "...", ",", "m", "+", "i", ",", "i", ",", ":", "]", "=", "True", "\n", "mask2", "[", "...", ",", "i", ",", "m", "+", "i", ",", ":", "]", "=", "True", "\n", "mask3", "[", "...", ",", "i", "+", "m", ",", "-", "1", "-", "i", ",", ":", "]", "=", "True", "\n", "mask4", "[", "...", ",", "i", ",", "-", "1", "-", "(", "i", "+", "m", ")", ",", ":", "]", "=", "True", "\n", "", "masks", ".", "extend", "(", "[", "mask1", ",", "mask2", ",", "mask3", ",", "mask4", "]", ")", "\n", "", "", "return", "masks", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.LearnTools.to_slice": [[114, 127], ["None"], "function", ["None"], ["", "def", "to_slice", "(", "k", ",", "forty_five_deg", ",", "D_dimensions_to_check", ")", ":", "\n", "    ", "\"\"\"\n    :param k: axis idx.\n    :param forty_five_deg: bool determining if to slice in 45 deg.\n    :param D_dimensions_to_check: The dimensions to check by the user.\n    :return: When to slice the volume (in which axis/45 deg angles).\n    \"\"\"", "\n", "if", "k", "not", "in", "D_dimensions_to_check", ":", "\n", "        ", "if", "k", "!=", "2", ":", "\n", "            ", "return", "False", "\n", "", "if", "not", "forty_five_deg", ":", "\n", "            ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.LearnTools.forty_five_deg_slices": [[129, 143], ["torch.cat", "volume_input.size", "volume_input[].view", "tensors.append", "torch.nn.functional.interpolate"], "function", ["None"], ["", "def", "forty_five_deg_slices", "(", "masks", ",", "volume_input", ")", ":", "\n", "    ", "\"\"\"\n    :param masks: the masks of the 45 degree angle slices\n    :param volume_input: the volume to slice\n    :return: the two slices (as a tensor of batch size x 2)\n    \"\"\"", "\n", "tensors", "=", "[", "]", "\n", "batch_size", ",", "phases", ",", "high_l", "=", "volume_input", ".", "size", "(", ")", "[", ":", "3", "]", "\n", "for", "mask", "in", "masks", ":", "\n", "# the result of the mask on the input:", "\n", "        ", "slice_mask", "=", "volume_input", "[", "mask", "]", ".", "view", "(", "batch_size", ",", "phases", ",", "-", "1", ",", "high_l", ")", "\n", "# add the slice after up_sample to wanted size:", "\n", "tensors", ".", "append", "(", "interpolate", "(", "slice_mask", ",", "size", "=", "(", "high_l", ",", "high_l", ")", ",", "mode", "=", "modes", "[", "0", "]", ")", ")", "\n", "", "return", "torch", ".", "cat", "(", "tensors", ",", "dim", "=", "0", ")", "# concat tensors along batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.LearnTools.calc_gradient_penalty": [[145, 180], ["torch.rand", "alpha.view.expand().contiguous", "alpha.view.view", "interpolates.requires_grad_", "netD", "gradients.view.view", "real_data.size", "torch.autograd.grad", "gradients.view.size", "alpha.view.expand", "real_data.detach", "fake_data.detach", "int", "torch.ones", "netD.size", "real_data.numel", "gradients.view.norm"], "function", ["None"], ["", "def", "calc_gradient_penalty", "(", "netD", ",", "real_data", ",", "fake_data", ",", "batch_size", ",", "l", ",", "device", ",", "\n", "gp_lambda", ",", "nc", ")", ":", "\n", "    ", "\"\"\"\n    calculate gradient penalty for a batch of real and fake data\n    :param netD: Discriminator network\n    :param real_data:\n    :param fake_data:\n    :param batch_size:\n    :param l: image size\n    :param device:\n    :param gp_lambda: learning parameter for GP\n    :param nc: channels\n    :return: gradient penalty\n    \"\"\"", "\n", "# sample and reshape random numbers", "\n", "alpha", "=", "torch", ".", "rand", "(", "batch_size", ",", "1", ",", "device", "=", "device", ")", "\n", "num_images", "=", "real_data", ".", "size", "(", ")", "[", "0", "]", "\n", "alpha", "=", "alpha", ".", "expand", "(", "batch_size", ",", "int", "(", "real_data", ".", "numel", "(", ")", "/", "\n", "batch_size", ")", ")", ".", "contiguous", "(", ")", "\n", "alpha", "=", "alpha", ".", "view", "(", "num_images", ",", "nc", ",", "l", ",", "l", ")", "\n", "\n", "# create interpolate dataset", "\n", "interpolates", "=", "alpha", "*", "real_data", ".", "detach", "(", ")", "+", "(", "(", "1", "-", "alpha", ")", "*", "fake_data", ".", "detach", "(", ")", ")", "\n", "interpolates", ".", "requires_grad_", "(", "True", ")", "\n", "\n", "# pass interpolates through netD", "\n", "disc_interpolates", "=", "netD", "(", "interpolates", ")", "\n", "gradients", "=", "autograd", ".", "grad", "(", "outputs", "=", "disc_interpolates", ",", "inputs", "=", "interpolates", ",", "\n", "grad_outputs", "=", "torch", ".", "ones", "(", "disc_interpolates", ".", "size", "(", ")", ",", "\n", "device", "=", "device", ")", ",", "\n", "create_graph", "=", "True", ",", "only_inputs", "=", "True", ")", "[", "0", "]", "\n", "# extract the grads and calculate gp", "\n", "gradients", "=", "gradients", ".", "view", "(", "gradients", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "gradient_penalty", "=", "(", "(", "gradients", ".", "norm", "(", "2", ",", "dim", "=", "1", ")", "-", "1", ")", "**", "2", ")", ".", "mean", "(", ")", "*", "gp_lambda", "\n", "return", "gradient_penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.__init__": [[30, 83], ["tifffile.imread", "len", "numpy.unique", "ImageTools.one_hot_encoding", "ImageTools.vf_sa_metrics", "BatchMaker.BatchMaker.rotate_and_mirror", "int", "LearnTools.DownSample().to", "numpy.array", "int", "BatchMaker.BatchMaker.down_sample_im().detach().cpu", "list", "LearnTools.DownSample", "BatchMaker.BatchMaker.down_sample_im().detach", "numpy.array", "numpy.array", "BatchMaker.BatchMaker.down_sample_im", "BatchMaker.BatchMaker.to_low_idx.detach().cpu", "BatchMaker.BatchMaker.to_low_idx.detach"], "methods", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.one_hot_encoding", "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.vf_sa_metrics", "home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.rotate_and_mirror", "home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.down_sample_im"], ["def", "__init__", "(", "self", ",", "device", ",", "to_low_idx", "=", "None", ",", "path", "=", "NMC_PATH", ",", "sf", "=", "4", ",", "dims", "=", "3", ",", "\n", "stack", "=", "True", ",", "down_sample", "=", "False", ",", "separator", "=", "False", ",", "\n", "low_res", "=", "False", ",", "rot_and_mir", "=", "True", ",", "squash", "=", "False", ",", "\n", "super_sample", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param device: the device that the image is on.\n        :param to_low_idx: the indices of the phases to be down-sampled.\n        :param path: the path of the tif file\n        TODO make it more general than just tif..\n        :param sf: the scale factor between low and high res.\n        :param dims: number of dimensions for the batches (2 or 3)\n        :param stack: if the data is a stack of 2D images\n        :param down_sample: whether to down-sample the data or not.\n        :param separator: whether the material is a separator.\n        :param rot_and_mir: if True, the stack of 2D images will rotate and\n        mirror for another 8 configurations\n        :param squash: whether to squash all phases (other than pore) to one phase.\n        :param super_sample: whether when down sampling to make it with\n        super-sampling and not with blurring.\n        \"\"\"", "\n", "# TODO currently training images are on cpu, maybe better to move", "\n", "#  them to gpu.", "\n", "# down-sample parameters:", "\n", "self", ".", "down_sample", ",", "self", ".", "to_low_idx", ",", "self", ".", "squash", "=", "down_sample", ",", "to_low_idx", ",", "squash", "\n", "self", ".", "scale_factor", "=", "sf", "\n", "self", ".", "path", "=", "path", "# the path of the tif file", "\n", "self", ".", "dims", "=", "dims", "# if G is 3D to 3D or 2D to 2D", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "stack", "=", "stack", "# if the data is a stack of 2D images", "\n", "self", ".", "im", "=", "imread", "(", "path", ")", "\n", "self", ".", "high_l", "=", "HIGH_L_3D", "\n", "if", "stack", "and", "not", "low_res", ":", "# it is the high-res training data", "\n", "            ", "self", ".", "hr_metrics", "=", "ImageTools", ".", "vf_sa_metrics", "(", "self", ".", "im", ")", "\n", "self", ".", "high_l", "-=", "crop_size", "*", "2", "\n", "", "if", "rot_and_mir", ":", "\n", "            ", "self", ".", "rotate_and_mirror", "(", ")", "\n", "", "self", ".", "dim_im", "=", "len", "(", "self", ".", "im", ".", "shape", ")", "# the dimension of the image", "\n", "self", ".", "phases", "=", "np", ".", "unique", "(", "self", ".", "im", ")", "# the unique values in image", "\n", "self", ".", "im", "=", "ImageTools", ".", "one_hot_encoding", "(", "self", ".", "im", ",", "self", ".", "phases", ")", "\n", "if", "low_res", ":", "\n", "            ", "self", ".", "high_l", "=", "int", "(", "HIGH_L_3D", "/", "self", ".", "scale_factor", ")", "\n", "", "if", "self", ".", "dims", "==", "2", ":", "\n", "            ", "self", ".", "high_l", "=", "self", ".", "high_l", "*", "2", "\n", "", "if", "self", ".", "down_sample", ":", "\n", "            ", "self", ".", "down_sample_object", "=", "LearnTools", ".", "DownSample", "(", "self", ".", "squash", ",", "self", ".", "dims", ",", "self", ".", "to_low_idx", ",", "\n", "self", ".", "scale_factor", ",", "device", ",", "super_sample", ",", "\n", "separator", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "im", "=", "np", ".", "array", "(", "self", ".", "down_sample_im", "(", "self", ".", "im", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", "\n", "self", ".", "phases", "=", "[", "self", ".", "phases", "[", "0", "]", "]", "+", "list", "(", "np", ".", "array", "(", "self", ".", "phases", ")", "[", "\n", "np", ".", "array", "(", "self", ".", "to_low_idx", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", "]", ")", "\n", "self", ".", "high_l", "=", "int", "(", "HIGH_L_3D", "/", "self", ".", "scale_factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.down_sample_im": [[84, 91], ["torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "BatchMaker.BatchMaker.down_sample_object().squeeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "BatchMaker.BatchMaker.down_sample_object", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["None"], ["", "", "def", "down_sample_im", "(", "self", ",", "image", ")", ":", "\n", "        ", "\"\"\"\n        :return: a down-sample image of the high resolution image for the input\n        of G.\n        \"\"\"", "\n", "torch_im", "=", "torch", ".", "FloatTensor", "(", "image", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "return", "self", ".", "down_sample_object", "(", "torch_im", ",", "low_res_input", "=", "True", ")", ".", "squeeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.rotate_and_mirror": [[92, 109], ["numpy.flip", "numpy.zeros", "numpy.arange", "numpy.rot90", "numpy.rot90"], "methods", ["None"], ["", "def", "rotate_and_mirror", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Given a stack of 2D images, in the form of num_images X width X heigth\n        return a num_images*8 X width X height stack, with all 8 different\n        90deg rotations and mirrors of the images.\n        \"\"\"", "\n", "num_ims", "=", "self", ".", "im", ".", "shape", "[", "0", "]", "\n", "flip_im", "=", "np", ".", "flip", "(", "self", ".", "im", ",", "-", "1", ")", "\n", "res", "=", "np", ".", "zeros", "(", "(", "num_ims", "*", "8", ",", "*", "self", ".", "im", ".", "shape", "[", "1", ":", "]", ")", ",", "dtype", "=", "self", ".", "im", ".", "dtype", ")", "\n", "for", "k", "in", "np", ".", "arange", "(", "4", ")", ":", "# for each 90 deg rotation", "\n", "            ", "first_i", ",", "second_i", "=", "2", "*", "k", "*", "num_ims", ",", "(", "2", "*", "k", "+", "1", ")", "*", "num_ims", "\n", "# rotation images of original image:", "\n", "res", "[", "first_i", ":", "second_i", ",", "...", "]", "=", "np", ".", "rot90", "(", "self", ".", "im", ",", "k", ",", "[", "-", "2", ",", "-", "1", "]", ")", "\n", "# rotation images of flipped image:", "\n", "res", "[", "second_i", ":", "second_i", "+", "num_ims", ",", "...", "]", "=", "np", ".", "rot90", "(", "flip_im", ",", "k", ",", "\n", "[", "-", "2", ",", "-", "1", "]", ")", "\n", "", "self", ".", "im", "=", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.random_batch_for_real": [[110, 112], ["BatchMaker.BatchMaker.random_batch2d"], "methods", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.random_batch2d"], ["", "def", "random_batch_for_real", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "return", "self", ".", "random_batch2d", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.random_batch_for_fake": [[113, 118], ["BatchMaker.BatchMaker.random_batch3d", "BatchMaker.BatchMaker.random_batch2d"], "methods", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.random_batch3d", "home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.random_batch2d"], ["", "def", "random_batch_for_fake", "(", "self", ",", "batch_size", ",", "dim_chosen", ")", ":", "\n", "        ", "if", "self", ".", "dims", "==", "3", ":", "\n", "            ", "return", "self", ".", "random_batch3d", "(", "batch_size", ",", "dim_chosen", ")", "\n", "", "else", ":", "# dims = 2", "\n", "            ", "return", "self", ".", "random_batch2d", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.random_batch3d": [[119, 131], ["numpy.zeros", "range", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "BatchMaker.BatchMaker.generate_a_random_image3d", "len", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.generate_a_random_image3d"], ["", "", "def", "random_batch3d", "(", "self", ",", "batch_size", ",", "dim_chosen", ")", ":", "\n", "        ", "\"\"\"\n        :return: A batch of high resolution images,\n        along the dimension chosen (0->x,1->y,2->z) in the 3d tif image.\n        \"\"\"", "\n", "res", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "len", "(", "self", ".", "phases", ")", ",", "\n", "*", "self", ".", "high_l", "*", "np", ".", "ones", "(", "self", ".", "dims", ",", "dtype", "=", "int", ")", ")", ",", "\n", "dtype", "=", "self", ".", "im", ".", "dtype", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "res", "[", "i", ",", "...", "]", "=", "self", ".", "generate_a_random_image3d", "(", "dim_chosen", ")", "\n", "# return a torch tensor:", "\n", "", "return", "torch", ".", "FloatTensor", "(", "res", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.generate_a_random_image3d": [[132, 146], ["numpy.random.randint", "res_image.transpose", "numpy.array"], "methods", ["None"], ["", "def", "generate_a_random_image3d", "(", "self", ",", "dim_chosen", ")", ":", "\n", "        ", "\"\"\"\n        :param dim_chosen: the dimension chosen for the slice\n        :return: A random image of size res from the dimension chosen of the\n        image.\n        \"\"\"", "\n", "h_r", "=", "self", ".", "high_l", "\n", "# starting voxels", "\n", "s_ind", "=", "np", ".", "random", ".", "randint", "(", "np", ".", "array", "(", "self", ".", "im", ".", "shape", "[", "1", ":", "]", ")", "-", "h_r", ")", "\n", "e_ind", "=", "s_ind", "+", "h_r", "# the end indices", "\n", "res_image", "=", "self", ".", "im", "[", ":", ",", "s_ind", "[", "0", "]", ":", "e_ind", "[", "0", "]", ",", "s_ind", "[", "1", "]", ":", "e_ind", "[", "1", "]", ",", "\n", "s_ind", "[", "2", "]", ":", "e_ind", "[", "2", "]", "]", "\n", "# for different view, change the cube around..", "\n", "return", "res_image", ".", "transpose", "(", "0", ",", "*", "perms", "[", "dim_chosen", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.random_batch2d": [[147, 158], ["numpy.zeros", "range", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "BatchMaker.BatchMaker.generate_a_random_image2d", "len", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.generate_a_random_image2d"], ["", "def", "random_batch2d", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        :return: A batch of high resolution images,\n        along the dimension chosen (0->x,1->y,2->z) in the 3d tif image.\n        \"\"\"", "\n", "res", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "len", "(", "self", ".", "phases", ")", ",", "self", ".", "high_l", ",", "\n", "self", ".", "high_l", ")", ",", "dtype", "=", "self", ".", "im", ".", "dtype", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "res", "[", "i", ",", ":", ",", ":", ",", ":", "]", "=", "self", ".", "generate_a_random_image2d", "(", ")", "\n", "# return a torch tensor:", "\n", "", "return", "torch", ".", "FloatTensor", "(", "res", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.generate_a_random_image2d": [[159, 175], ["numpy.random.randint", "numpy.random.randint", "ValueError", "numpy.array"], "methods", ["None"], ["", "def", "generate_a_random_image2d", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :return: A random image of size res from the dimension chosen of the\n        image.\n        \"\"\"", "\n", "# the starting pixels of the other dimensions:", "\n", "if", "self", ".", "stack", ":", "# has to be, since this function is only called for", "\n", "# by the discriminator batch maker.", "\n", "            ", "s_ind", "=", "np", ".", "random", ".", "randint", "(", "np", ".", "array", "(", "self", ".", "im", ".", "shape", "[", "2", ":", "]", ")", "-", "\n", "self", ".", "high_l", ")", "\n", "e_ind", "=", "s_ind", "+", "self", ".", "high_l", "\n", "slice_chosen", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "im", ".", "shape", "[", "1", "]", ")", "\n", "return", "self", ".", "im", "[", ":", ",", "slice_chosen", ",", "s_ind", "[", "0", "]", ":", "e_ind", "[", "0", "]", ",", "\n", "s_ind", "[", "1", "]", ":", "e_ind", "[", "1", "]", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"2D images should be stacked as \"", "\n", "\"n_stack X height X width\"", ")", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.BatchMaker.BatchMaker.all_image_batch": [[177, 183], ["torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["None"], ["", "", "def", "all_image_batch", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :return: the 3d image ready to be fed into the G with dimensions\n        1xCxDxHxW or 1xCxHxW\n        \"\"\"", "\n", "return", "torch", ".", "FloatTensor", "(", "self", ".", "im", ")", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Architecture.save_differences_and_metrics": [[109, 127], ["output_of_g.cpu", "ImageTools.log_metrics", "ImageTools.plot_fake_difference", "input_to_g.clone().detach().cpu", "str", "torch.save", "torch.save", "torch.save", "wandb.save", "LearnTools.forty_five_deg_slices", "images.append", "np.round", "generator.state_dict", "input_to_g.detach().cpu", "LearnTools.forty_five_deg_slices.detach().cpu", "input_to_g.clone().detach", "input_to_g.detach", "LearnTools.forty_five_deg_slices.detach", "input_to_g.clone"], "function", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.log_metrics", "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.plot_fake_difference", "home.repos.pwc.inspect_result.amirdahari1_superres.code.LearnTools.forty_five_deg_slices"], ["def", "save_differences_and_metrics", "(", "input_to_g", ",", "output_of_g", ",", "save_dir", ",", "filename", ",", "\n", "masks", ",", "hr_metrics", ",", "generator", ",", "with_deg", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Saves the image of the differences between the high-res real and the\n    generated images that are supposed to be similar.\n    \"\"\"", "\n", "images", "=", "[", "input_to_g", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "]", "\n", "g_output", "=", "output_of_g", ".", "cpu", "(", ")", "\n", "metrics_loss", "=", "ImageTools", ".", "log_metrics", "(", "g_output", ",", "hr_metrics", ")", "\n", "if", "metrics_loss", "<", "0.015", ":", "# mean difference is smaller than 1.5%", "\n", "        ", "difference_str", "=", "str", "(", "np", ".", "round", "(", "metrics_loss", ",", "4", ")", ")", "\n", "torch", ".", "save", "(", "generator", ".", "state_dict", "(", ")", ",", "PATH_G", "+", "difference_str", ")", "\n", "wandb", ".", "save", "(", "PATH_G", "+", "difference_str", ")", "\n", "", "images", "=", "images", "+", "[", "input_to_g", ".", "detach", "(", ")", ".", "cpu", "(", ")", ",", "g_output", "]", "\n", "if", "with_deg", ":", "\n", "        ", "slices_45", "=", "LearnTools", ".", "forty_five_deg_slices", "(", "masks", ",", "g_output", ")", "\n", "images", ".", "append", "(", "slices_45", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", "\n", "", "ImageTools", ".", "plot_fake_difference", "(", "images", ",", "save_dir", ",", "filename", ",", "with_deg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.show_grey_image": [[14, 20], ["matplotlib.pyplot.imshow", "wandb.log", "wandb.Image"], "function", ["None"], ["def", "show_grey_image", "(", "image", ",", "title", ")", ":", "\n", "    ", "\"\"\"\n    Plots the image in grey scale, assuming the image is 1 channel of 0-255\n    \"\"\"", "\n", "plt", ".", "imshow", "(", "image", ",", "cmap", "=", "'gray'", ",", "vmin", "=", "0", ",", "vmax", "=", "255", ")", "\n", "wandb", ".", "log", "(", "{", "title", ":", "[", "wandb", ".", "Image", "(", "plt", ")", "]", "}", ")", "\n", "# plt.show()", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.log_metrics": [[23, 46], ["ImageTools.one_hot_decoding", "ImageTools.vf_sa_metrics", "numpy.mean", "wandb.log", "ImageTools.fractions_to_ohe", "wandb.log", "wandb.log", "numpy.abs", "wandb.log", "wandb.log", "numpy.abs", "range", "range", "range", "range", "range", "range", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.one_hot_decoding", "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.vf_sa_metrics", "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.fractions_to_ohe"], ["", "def", "log_metrics", "(", "g_output", ",", "hr_metrics", ")", ":", "\n", "    ", "\"\"\"\n    Logs the volume fraction and surface area metrics of the\n    generated super-res volumes in wandb.\n    :param g_output: the current output from g (batch_size*64^3 tensors)\n    :param hr_metrics: the same metrics of the high-res 2D slice for\n    comparison.\n    \"\"\"", "\n", "g_output", "=", "one_hot_decoding", "(", "fractions_to_ohe", "(", "g_output", ")", ")", "\n", "# The super-res volume fraction and surface area values:", "\n", "sr_vf", ",", "sr_sa", "=", "vf_sa_metrics", "(", "g_output", ")", "\n", "hr_vf", ",", "hr_sa", "=", "hr_metrics", "\n", "vf_labels", ",", "sa_labels", "=", "[", "\"VF pore \"", ",", "\"VF AM \"", ",", "\"VF binder \"", "]", ",", "[", "\"SA pore/AM \"", ",", "\"SA pore/binder \"", ",", "\"SA AM/binder \"", "]", "\n", "[", "wandb", ".", "log", "(", "{", "vf_labels", "[", "i", "]", "+", "'SR'", ":", "sr_vf", "[", "i", "]", "}", ")", "for", "i", "in", "range", "(", "len", "(", "sr_vf", ")", ")", "]", "\n", "[", "wandb", ".", "log", "(", "{", "vf_labels", "[", "i", "]", "+", "'HR'", ":", "hr_vf", "[", "i", "]", "}", ")", "for", "i", "in", "range", "(", "len", "(", "hr_vf", ")", ")", "]", "\n", "m_loss", "=", "[", "np", ".", "abs", "(", "1", "-", "sr_vf", "[", "i", "]", "/", "hr_vf", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "hr_vf", ")", ")", "]", "\n", "[", "wandb", ".", "log", "(", "{", "sa_labels", "[", "i", "]", "+", "'SR'", ":", "sr_sa", "[", "i", "]", "}", ")", "for", "i", "in", "range", "(", "len", "(", "sr_sa", ")", ")", "]", "\n", "[", "wandb", ".", "log", "(", "{", "sa_labels", "[", "i", "]", "+", "'HR'", ":", "hr_sa", "[", "i", "]", "}", ")", "for", "i", "in", "range", "(", "len", "(", "hr_sa", ")", ")", "]", "\n", "m_loss", "+=", "[", "np", ".", "abs", "(", "1", "-", "sr_sa", "[", "i", "]", "/", "hr_sa", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "hr_sa", ")", ")", "]", "\n", "m_loss", "=", "np", ".", "mean", "(", "m_loss", ")", "\n", "wandb", ".", "log", "(", "{", "'Metrics percentage difference'", ":", "m_loss", "}", ")", "\n", "return", "m_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.vf_sa_metrics": [[48, 63], ["numpy.unique", "numpy.mean", "numpy.mean", "list", "list", "range", "taufactor.metrics.surface_area().item", "range", "itertools.combinations", "taufactor.metrics.surface_area"], "function", ["None"], ["", "def", "vf_sa_metrics", "(", "batch_images", ")", ":", "\n", "    ", "\"\"\"\n    :param batch_images: a 4-dim or 3-dim array of images (batch_size x H x\n    W or batch_size x D x H x W)\n    :return: a list of the mean volume fractions of the different phases and\n    the interfacial surface area between every pair of phases.\n    \"\"\"", "\n", "batch_size", "=", "batch_images", ".", "shape", "[", "0", "]", "\n", "phases", "=", "np", ".", "unique", "(", "batch_images", ")", "\n", "vf", "=", "np", ".", "mean", "(", "[", "[", "(", "batch_images", "[", "j", "]", "==", "p", ")", ".", "mean", "(", ")", "for", "p", "in", "phases", "]", "for", "j", "\n", "in", "range", "(", "batch_size", ")", "]", ",", "axis", "=", "0", ")", "\n", "sa", "=", "np", ".", "mean", "(", "[", "[", "metrics", ".", "surface_area", "(", "batch_images", "[", "j", "]", ",", "[", "ph1", ",", "ph2", "]", ")", ".", "item", "(", ")", "for", "\n", "ph1", ",", "ph2", "in", "combinations", "(", "phases", ",", "2", ")", "]", "for", "j", "in", "range", "(", "\n", "batch_size", ")", "]", ",", "axis", "=", "0", ")", "\n", "return", "list", "(", "vf", ")", ",", "list", "(", "sa", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.plot_fake_difference": [[65, 75], ["ImageTools.fractions_to_ohe", "ImageTools.save_three_by_two_grey", "numpy.array", "ImageTools.fractions_to_ohe", "ImageTools.one_hot_decoding"], "function", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.fractions_to_ohe", "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.save_three_by_two_grey", "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.fractions_to_ohe", "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.one_hot_decoding"], ["", "def", "plot_fake_difference", "(", "images", ",", "save_dir", ",", "filename", ",", "with_deg", "=", "False", ")", ":", "\n", "# first move everything to numpy", "\n", "# rand_sim = np.array(input_to_g[:, 2, :, :])", "\n", "    ", "images", "=", "[", "np", ".", "array", "(", "image", ")", "for", "image", "in", "images", "]", "\n", "images", "[", "2", "]", "=", "fractions_to_ohe", "(", "images", "[", "2", "]", ")", "# the output from g needs to ohe", "\n", "if", "with_deg", ":", "\n", "        ", "images", "[", "3", "]", "=", "fractions_to_ohe", "(", "images", "[", "3", "]", ")", "# also the slices", "\n", "", "images", "=", "[", "one_hot_decoding", "(", "image", ")", "for", "image", "in", "images", "]", "\n", "save_three_by_two_grey", "(", "images", ",", "save_dir", "+", "' '", "+", "filename", ",", "save_dir", ",", "\n", "filename", ",", "with_deg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.save_three_by_two_grey": [[77, 101], ["range", "range", "matplotlib.pyplot.suptitle", "wandb.log", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "matplotlib.pyplot.subplots", "matplotlib.pyplot.subplots", "range", "axarr[].imshow", "range", "int", "axarr[].imshow", "axarr[].set_xticks", "axarr[].set_yticks", "axarr[].imshow"], "function", ["None"], ["", "def", "save_three_by_two_grey", "(", "images", ",", "title", ",", "save_dir", ",", "filename", ",", "with_deg", "=", "False", ")", ":", "\n", "    ", "if", "with_deg", ":", "\n", "        ", "f", ",", "axarr", "=", "plt", ".", "subplots", "(", "5", ",", "3", ")", "\n", "", "else", ":", "\n", "        ", "f", ",", "axarr", "=", "plt", ".", "subplots", "(", "4", ",", "3", ")", "\n", "", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "3", ")", ":", "\n", "            ", "length_im", "=", "images", "[", "i", "]", ".", "shape", "[", "1", "]", "\n", "middle", "=", "int", "(", "length_im", "/", "2", ")", "\n", "axarr", "[", "i", ",", "j", "]", ".", "imshow", "(", "images", "[", "i", "]", "[", "j", ",", "middle", ",", ":", ",", ":", "]", ",", "cmap", "=", "'gray'", ",", "vmin", "=", "0", ",", "\n", "vmax", "=", "2", ")", "\n", "axarr", "[", "i", ",", "j", "]", ".", "set_xticks", "(", "[", "0", ",", "length_im", "-", "1", "]", ")", "\n", "axarr", "[", "i", ",", "j", "]", ".", "set_yticks", "(", "[", "0", ",", "length_im", "-", "1", "]", ")", "\n", "", "", "for", "j", "in", "range", "(", "3", ")", ":", "# showing xy slices from 'above'", "\n", "        ", "axarr", "[", "3", ",", "j", "]", ".", "imshow", "(", "images", "[", "2", "]", "[", "j", ",", ":", ",", ":", ",", "4", "]", ",", "cmap", "=", "'gray'", ",", "vmin", "=", "0", ",", "\n", "vmax", "=", "2", ")", "\n", "", "if", "with_deg", ":", "\n", "        ", "for", "j", "in", "range", "(", "3", ")", ":", "# showing 45 deg slices", "\n", "            ", "axarr", "[", "4", ",", "j", "]", ".", "imshow", "(", "images", "[", "3", "]", "[", "j", ",", ":", ",", ":", "]", ",", "cmap", "=", "'gray'", ",", "vmin", "=", "0", ",", "\n", "vmax", "=", "2", ")", "\n", "", "", "plt", ".", "suptitle", "(", "title", ")", "\n", "wandb", ".", "log", "(", "{", "\"running slices\"", ":", "plt", "}", ")", "\n", "plt", ".", "savefig", "(", "progress_dir", "+", "save_dir", "+", "'/'", "+", "filename", "+", "'.png'", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.cbd_to_pore": [[103, 110], ["numpy.copy"], "function", ["None"], ["", "def", "cbd_to_pore", "(", "im_with_cbd", ")", ":", "\n", "    ", "\"\"\"\n    :return: the image without cbd. cbd -> pore.\n    \"\"\"", "\n", "res", "=", "np", ".", "copy", "(", "im_with_cbd", ")", "\n", "res", "[", "res", "==", "255", "]", "=", "0", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.one_hot_encoding": [[112, 127], ["numpy.zeros", "enumerate", "numpy.zeros", "len"], "function", ["None"], ["", "def", "one_hot_encoding", "(", "image", ",", "phases", ")", ":", "\n", "    ", "\"\"\"\n    :param image: a [depth, height, width] 3d image\n    :param phases: the unique phases in the image\n    :return: a one-hot encoding of image.\n    \"\"\"", "\n", "im_shape", "=", "image", ".", "shape", "\n", "res", "=", "np", ".", "zeros", "(", "(", "len", "(", "phases", ")", ",", ")", "+", "im_shape", ",", "dtype", "=", "image", ".", "dtype", ")", "\n", "# create one channel per phase for one hot encoding", "\n", "for", "count", ",", "phase", "in", "enumerate", "(", "phases", ")", ":", "\n", "        ", "image_copy", "=", "np", ".", "zeros", "(", "im_shape", ",", "dtype", "=", "image", ".", "dtype", ")", "# just an encoding", "\n", "# for one channel", "\n", "image_copy", "[", "image", "==", "phase", "]", "=", "1", "\n", "res", "[", "count", ",", "...", "]", "=", "image_copy", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.one_hot_decoding": [[129, 149], ["numpy.array", "numpy.zeros", "range", "list"], "function", ["None"], ["", "def", "one_hot_decoding", "(", "image", ")", ":", "\n", "    ", "\"\"\"\n    decodes the image back from one hot encoding to grayscale for\n    visualization.\n    :param image: a [batch_size, phases, height, width] tensor/numpy array\n    :return: a [batch_size, height, width] numpy array\n    \"\"\"", "\n", "np_image", "=", "np", ".", "array", "(", "image", ")", "\n", "im_shape", "=", "np_image", ".", "shape", "\n", "phases", "=", "im_shape", "[", "1", "]", "\n", "res", "=", "np", ".", "zeros", "(", "[", "im_shape", "[", "0", "]", "]", "+", "list", "(", "im_shape", "[", "2", ":", "]", ")", ")", "\n", "\n", "# the assumption is that each pixel has exactly one 1 in its phases", "\n", "# and 0 in all other phases:", "\n", "for", "i", "in", "range", "(", "phases", ")", ":", "\n", "        ", "if", "i", "==", "0", ":", "\n", "            ", "continue", "# the res is already 0 in all places..", "\n", "", "phase_image", "=", "np_image", "[", ":", ",", "i", ",", "...", "]", "\n", "res", "[", "phase_image", "==", "1", "]", "=", "i", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.fractions_to_ohe": [[151, 166], ["numpy.array", "numpy.zeros", "numpy.expand_dims", "numpy.put_along_axis", "numpy.argmax", "numpy.random.rand"], "function", ["None"], ["", "def", "fractions_to_ohe", "(", "image", ")", ":", "\n", "    ", "\"\"\"\n    :param image: a [n,c,w,h] image (generated) with fractions in the phases.\n    :return: a one-hot-encoding of the image with the maximum rule, i.e. the\n    phase which has the highest number will be 1 and all else 0.\n    \"\"\"", "\n", "np_image", "=", "np", ".", "array", "(", "image", ")", "\n", "res", "=", "np", ".", "zeros", "(", "np_image", ".", "shape", ")", "\n", "# Add a little noise for (0.5, 0.5) situations.", "\n", "np_image", "+=", "(", "np", ".", "random", ".", "rand", "(", "*", "np_image", ".", "shape", ")", "-", "0.5", ")", "/", "100", "\n", "# finding the indices of the maximum phases:", "\n", "arg_phase_max", "=", "np", ".", "expand_dims", "(", "np", ".", "argmax", "(", "np_image", ",", "axis", "=", "1", ")", ",", "axis", "=", "1", ")", "\n", "# make them 1:", "\n", "np", ".", "put_along_axis", "(", "res", ",", "arg_phase_max", ",", "1", ",", "axis", "=", "1", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.graph_plot": [[168, 183], ["zip", "matplotlib.pyplot.legend", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "matplotlib.pyplot.plot"], "function", ["None"], ["", "def", "graph_plot", "(", "data", ",", "labels", ",", "pth", ",", "filename", ")", ":", "\n", "    ", "\"\"\"\n    simple plotter for all the different graphs\n    :param data: a list of data arrays\n    :param labels: a list of plot labels\n    :param pth: where to save plots\n    :param filename: the directory name to save the plot.\n    :return:\n    \"\"\"", "\n", "\n", "for", "datum", ",", "lbl", "in", "zip", "(", "data", ",", "labels", ")", ":", "\n", "        ", "plt", ".", "plot", "(", "datum", ",", "label", "=", "lbl", ")", "\n", "", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "savefig", "(", "progress_dir", "+", "pth", "+", "'/'", "+", "filename", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.ImageTools.calc_and_save_eta": [[185, 207], ["int", "int", "print"], "function", ["None"], ["", "def", "calc_and_save_eta", "(", "steps", ",", "time", ",", "start", ",", "i", ",", "epoch", ",", "num_epochs", ",", "filename", ")", ":", "\n", "    ", "\"\"\"\n    Estimates the time remaining based on the elapsed time and epochs\n    :param steps: number of steps in an epoch\n    :param time: current time\n    :param start: start time\n    :param i: iteration through this epoch\n    :param epoch: epoch number\n    :param num_epochs: total no. of epochs\n    :param filename: the filename to save\n    \"\"\"", "\n", "elap", "=", "time", "-", "start", "\n", "progress", "=", "epoch", "*", "steps", "+", "i", "+", "1", "\n", "rem", "=", "num_epochs", "*", "steps", "-", "progress", "\n", "ETA", "=", "rem", "/", "progress", "*", "elap", "\n", "hrs", "=", "int", "(", "ETA", "/", "3600", ")", "\n", "minutes", "=", "int", "(", "(", "ETA", "/", "3600", "%", "1", ")", "*", "60", ")", "\n", "# save_res = np.array([epoch, num_epochs, i, steps, hrs, minutes])", "\n", "# np.save(progress_dir + filename, save_res)", "\n", "print", "(", "'[%d/%d][%d/%d]\\tETA: %d hrs %d mins'", "\n", "%", "(", "epoch", ",", "num_epochs", ",", "i", ",", "steps", ",", "\n", "hrs", ",", "minutes", ")", ")", "", "", ""]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Evaluation.crop_to_down_sample": [[81, 95], ["numpy.array", "range", "len", "range", "crop_dims.append", "numpy.round"], "function", ["None"], ["def", "crop_to_down_sample", "(", "high_res", ")", ":", "\n", "    ", "\"\"\"\n    If down sample, crops the high resolution image to fit the scale factor.\n    \"\"\"", "\n", "dims", "=", "np", ".", "array", "(", "high_res", ".", "shape", ")", "\n", "crop_dims", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "dims", ")", ")", ":", "\n", "        ", "dim", "=", "dims", "[", "idx", "]", "\n", "for", "subtract", "in", "range", "(", "dim", ")", ":", "\n", "# doing % twice because the number can be 0 from below (%1.6=1.599)", "\n", "            ", "if", "np", ".", "round", "(", "(", "dim", "-", "subtract", ")", "%", "scale_f", ",", "5", ")", "%", "scale_f", "==", "0", ":", "\n", "                ", "crop_dims", ".", "append", "(", "dim", "-", "subtract", ")", "\n", "break", "\n", "", "", "", "return", "high_res", "[", ":", "crop_dims", "[", "0", "]", ",", ":", "crop_dims", "[", "1", "]", ",", ":", "crop_dims", "[", "2", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator3D.__init__": [[75, 116], ["torch.Module.__init__", "int", "print", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "math.log", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ConvTranspose3d", "torch.ConvTranspose3d", "torch.ConvTranspose3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "range", "range"], "methods", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator2D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ngpu", ",", "wg", ",", "nc_g", ",", "nc_d", ",", "n_res_blocks", ",", "scale_factor", ")", ":", "\n", "        ", "super", "(", "Generator3D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "scale_factor", "=", "scale_factor", "\n", "self", ".", "n_res_blocks", "=", "n_res_blocks", "\n", "self", ".", "ngpu", "=", "ngpu", "\n", "# how to change the channels depends on the number of layers", "\n", "sf_c", "=", "int", "(", "math", ".", "log", "(", "self", ".", "scale_factor", "-", "EPS", ",", "2", ")", ")", "\n", "wg_sf", "=", "wg", "+", "sf_c", "\n", "print", "(", "wg_sf", ")", "\n", "# first convolution, making many channels", "\n", "self", ".", "conv_minus_1", "=", "nn", ".", "Conv3d", "(", "nc_g", ",", "2", "**", "(", "wg_sf", "-", "1", ")", ",", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "padding_mode", "=", "'replicate'", ")", "\n", "self", ".", "bn_minus_1", "=", "nn", ".", "BatchNorm3d", "(", "2", "**", "(", "wg_sf", "-", "1", ")", ")", "\n", "\n", "self", ".", "conv_res", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv3d", "(", "2", "**", "(", "wg_sf", "-", "1", ")", ",", "2", "**", "(", "wg_sf", "-", "1", ")", ",", "3", ",", "\n", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "padding_mode", "=", "'replicate'", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "n_res_blocks", "*", "2", ")", "]", ")", "\n", "self", ".", "bn_res", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "BatchNorm3d", "(", "2", "**", "(", "wg_sf", "-", "1", ")", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "n_res_blocks", "*", "2", ")", "]", ")", "\n", "\n", "# convolution resize before t-conv (if scale-ratio > 4):", "\n", "if", "self", ".", "scale_factor", ">", "4", ":", "\n", "            ", "self", ".", "conv_resize_0", "=", "nn", ".", "Conv3d", "(", "2", "**", "(", "wg_sf", "-", "1", ")", ",", "2", "**", "(", "wg_sf", "-", "2", ")", ",", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "padding_mode", "=", "'replicate'", ")", "\n", "self", ".", "bn_resize_0", "=", "nn", ".", "BatchNorm3d", "(", "2", "**", "(", "wg_sf", "-", "2", ")", ")", "\n", "wg_sf", "-=", "1", "\n", "# transpose convolution:", "\n", "", "if", "self", ".", "scale_factor", ">", "2", ":", "\n", "            ", "self", ".", "conv_trans", "=", "nn", ".", "ConvTranspose3d", "(", "2", "**", "(", "wg_sf", "-", "1", ")", ",", "\n", "2", "**", "(", "wg_sf", "-", "2", ")", ",", "4", ",", "2", ",", "1", ")", "\n", "self", ".", "bn_trans", "=", "nn", ".", "BatchNorm3d", "(", "2", "**", "(", "wg_sf", "-", "2", ")", ")", "\n", "wg_sf", "-=", "1", "\n", "# convolution resize:", "\n", "", "self", ".", "conv_resize", "=", "nn", ".", "Conv3d", "(", "2", "**", "(", "wg_sf", "-", "1", ")", ",", "2", "**", "(", "wg_sf", "-", "2", ")", ",", "\n", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "padding_mode", "=", "'replicate'", ")", "\n", "self", ".", "bn_resize", "=", "nn", ".", "BatchNorm3d", "(", "2", "**", "(", "wg_sf", "-", "2", ")", ")", "\n", "self", ".", "conv_bf_end", "=", "nn", ".", "Conv3d", "(", "2", "**", "(", "wg_sf", "-", "2", ")", ",", "nc_d", ",", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "padding_mode", "=", "'replicate'", ")", "\n", "# self.conv_concat = nn.Conv3d(nc_d+nc_g, nc_d, 1, 1, 0)", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator3D.res_block": [[118, 130], ["bn_out", "conv_out", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "bn_in", "conv_in"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "res_block", "(", "x", ",", "bn_out", ",", "conv_out", ",", "bn_in", ",", "conv_in", ")", ":", "\n", "        ", "\"\"\"\n        A forward pass of a residual block (from the original paper)\n        :return: the result after the residual block. the convolution\n        function should return the same number of channels, and the same\n        width and height of the image. For example, kernel size 3, padding 1\n        stride 1.\n        \"\"\"", "\n", "# the residual side", "\n", "x_side", "=", "bn_out", "(", "conv_out", "(", "nn", ".", "ReLU", "(", ")", "(", "bn_in", "(", "conv_in", "(", "x", ")", ")", ")", ")", ")", "\n", "return", "nn", ".", "ReLU", "(", ")", "(", "x", "+", "x_side", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator3D.forward": [[131, 172], ["copy.copy", "Networks.Generator3D.res_block", "range", "torch.Upsample", "torch.Upsample", "torch.Upsample", "Networks.Generator3D.conv_bf_end", "torch.ReLU", "torch.ReLU", "torch.ReLU", "Networks.Generator3D.bn_minus_1", "Networks.Generator3D.res_block", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.ReLU", "torch.ReLU", "torch.ReLU", "Networks.Generator3D.bn_resize", "torch.Softmax", "torch.Softmax", "torch.Softmax", "Networks.Generator3D.conv_minus_1", "torch.ReLU", "torch.ReLU", "torch.ReLU", "Networks.Generator3D.bn_resize_0", "torch.ReLU", "torch.ReLU", "torch.ReLU", "Networks.Generator3D.bn_trans", "Networks.Generator3D.conv_resize", "Networks.Generator3D.conv_resize_0", "Networks.Generator3D.conv_trans", "torch.Upsample.", "torch.Upsample."], "methods", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator2D.res_block", "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator2D.res_block"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        forward pass of x\n        :param x: input\n        :param mask: for plotting purposes, returns the mask (result of all\n        convolutions) and the up-sampled original image.\n        :return: the output of the forward pass.\n        \"\"\"", "\n", "cur_scale", "=", "copy", ".", "copy", "(", "self", ".", "scale_factor", ")", "# current scale factor of", "\n", "# the image on the forward run.", "\n", "# x after the first run for many channels:", "\n", "x_first", "=", "nn", ".", "ReLU", "(", ")", "(", "self", ".", "bn_minus_1", "(", "self", ".", "conv_minus_1", "(", "x", ")", ")", ")", "\n", "# first residual block:", "\n", "after_block", "=", "self", ".", "res_block", "(", "x_first", ",", "self", ".", "bn_res", "[", "0", "]", ",", "self", ".", "conv_res", "[", "0", "]", ",", "\n", "self", ".", "bn_res", "[", "1", "]", ",", "self", ".", "conv_res", "[", "1", "]", ")", "\n", "# more residual blocks:", "\n", "for", "i", "in", "range", "(", "2", ",", "self", ".", "n_res_blocks", ",", "2", ")", ":", "\n", "            ", "after_block", "=", "self", ".", "res_block", "(", "after_block", ",", "self", ".", "bn_res", "[", "i", "]", ",", "\n", "self", ".", "conv_res", "[", "i", "]", ",", "self", ".", "bn_res", "[", "i", "+", "1", "]", ",", "\n", "self", ".", "conv_res", "[", "i", "+", "1", "]", ")", "\n", "# skip connection to the end after all the blocks:", "\n", "", "res", "=", "x_first", "+", "after_block", "\n", "# up sampling using conv resize", "\n", "if", "4", "<", "cur_scale", "<=", "8", ":", "\n", "            ", "up_sample", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "modes", "[", "1", "]", ")", "\n", "res", "=", "nn", ".", "ReLU", "(", ")", "(", "self", ".", "bn_resize_0", "(", "self", ".", "conv_resize_0", "(", "up_sample", "(", "\n", "res", ")", ")", ")", ")", "\n", "cur_scale", "/=", "2", "\n", "# up sampling using transpose convolution", "\n", "", "if", "2", "<", "cur_scale", "<=", "4", ":", "\n", "            ", "res", "=", "nn", ".", "ReLU", "(", ")", "(", "self", ".", "bn_trans", "(", "self", ".", "conv_trans", "(", "res", ")", ")", ")", "\n", "cur_scale", "/=", "2", "\n", "# last up sample using conv resize:", "\n", "", "up_sample", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "cur_scale", ",", "mode", "=", "modes", "[", "1", "]", ")", "\n", "super_res", "=", "nn", ".", "ReLU", "(", ")", "(", "self", ".", "bn_resize", "(", "self", ".", "conv_resize", "(", "up_sample", "(", "res", ")", ")", ")", ")", "\n", "# another convolution before the end:", "\n", "bf_end", "=", "self", ".", "conv_bf_end", "(", "super_res", ")", "\n", "# softmax of the phase dimension:", "\n", "result", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "bf_end", ")", "\n", "# returns the result and the cropped result to feed into D", "\n", "return", "result", ",", "result", "[", "...", ",", "crop", ":", "-", "crop", ",", "crop", ":", "-", "crop", ",", "crop", ":", "-", "crop", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Discriminator3d.__init__": [[183, 198], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator2D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ngpu", ",", "wd", ",", "nc_d", ")", ":", "\n", "        ", "super", "(", "Discriminator3d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ngpu", "=", "ngpu", "\n", "# first convolution, input is 3x56^3", "\n", "self", ".", "conv0", "=", "nn", ".", "Conv2d", "(", "nc_d", ",", "2", "**", "(", "wd", "-", "3", ")", ",", "4", ",", "2", ",", "1", ")", "\n", "# second convolution, input is 64x28^3", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "2", "**", "(", "wd", "-", "3", ")", ",", "2", "**", "(", "wd", "-", "2", ")", ",", "4", ",", "2", ",", "1", ")", "\n", "# third convolution, input is 128x14^3", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "2", "**", "(", "wd", "-", "2", ")", ",", "2", "**", "(", "wd", "-", "1", ")", ",", "4", ",", "2", ",", "1", ")", "\n", "# fourth convolution, input is 256x7^3, conv kernel 3", "\n", "self", ".", "conv4", "=", "nn", ".", "Conv2d", "(", "2", "**", "(", "wd", "-", "1", ")", ",", "2", "**", "wd", ",", "3", ",", "2", ",", "1", ")", "\n", "# fifth convolution, input is 512x4^3", "\n", "self", ".", "conv5", "=", "nn", ".", "Conv2d", "(", "2", "**", "wd", ",", "1", ",", "4", ",", "2", ",", "0", ")", "\n", "# for smaller cube", "\n", "self", ".", "conv_early", "=", "nn", ".", "Conv2d", "(", "2", "**", "(", "wd", "-", "1", ")", ",", "1", ",", "4", ",", "2", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Discriminator3d.forward": [[199, 208], ["Networks.Discriminator3d.conv5", "torch.ReLU", "torch.ReLU", "torch.ReLU", "Networks.Discriminator3d.conv0", "torch.ReLU", "torch.ReLU", "torch.ReLU", "Networks.Discriminator3d.conv2", "torch.ReLU", "torch.ReLU", "torch.ReLU", "Networks.Discriminator3d.conv3", "Networks.Discriminator3d.conv_early", "torch.ReLU", "torch.ReLU", "torch.ReLU", "Networks.Discriminator3d.conv4"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "nn", ".", "ReLU", "(", ")", "(", "self", ".", "conv0", "(", "x", ")", ")", "\n", "# x = nn.ReLU()(self.conv1(x))", "\n", "x", "=", "nn", ".", "ReLU", "(", ")", "(", "self", ".", "conv2", "(", "x", ")", ")", "\n", "x", "=", "nn", ".", "ReLU", "(", ")", "(", "self", ".", "conv3", "(", "x", ")", ")", "\n", "if", "smaller_cube", ":", "\n", "            ", "return", "self", ".", "conv_early", "(", "x", ")", "\n", "", "x", "=", "nn", ".", "ReLU", "(", ")", "(", "self", ".", "conv4", "(", "x", ")", ")", "\n", "return", "self", ".", "conv5", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Discriminator2d.__init__": [[212, 227], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator2D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ngpu", ",", "wd", ",", "nc_d", ")", ":", "\n", "        ", "super", "(", "Discriminator2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ngpu", "=", "ngpu", "\n", "# first convolution, input is 3x128x128", "\n", "self", ".", "conv0", "=", "nn", ".", "Conv2d", "(", "nc_d", ",", "2", "**", "(", "wd", "-", "4", ")", ",", "4", ",", "2", ",", "1", ")", "\n", "# first convolution, input is 4x64x64", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "2", "**", "(", "wd", "-", "4", ")", ",", "2", "**", "(", "wd", "-", "3", ")", ",", "4", ",", "2", ",", "1", ")", "\n", "# second convolution, input is 8x32x32", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "2", "**", "(", "wd", "-", "3", ")", ",", "2", "**", "(", "wd", "-", "2", ")", ",", "4", ",", "2", ",", "1", ")", "\n", "# third convolution, input is 32x16x16", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "2", "**", "(", "wd", "-", "2", ")", ",", "2", "**", "(", "wd", "-", "1", ")", ",", "4", ",", "2", ",", "1", ")", "\n", "# fourth convolution, input is 64x8x8", "\n", "self", ".", "conv4", "=", "nn", ".", "Conv2d", "(", "2", "**", "(", "wd", "-", "1", ")", ",", "2", "**", "wd", ",", "4", ",", "2", ",", "1", ")", "\n", "# fifth convolution, input is 128x4x4", "\n", "self", ".", "conv5", "=", "nn", ".", "Conv2d", "(", "2", "**", "wd", ",", "1", ",", "4", ",", "2", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Discriminator2d.forward": [[228, 235], ["Networks.Discriminator2d.conv5", "torch.ReLU", "torch.ReLU", "torch.ReLU", "Networks.Discriminator2d.conv0", "torch.ReLU", "torch.ReLU", "torch.ReLU", "Networks.Discriminator2d.conv1", "torch.ReLU", "torch.ReLU", "torch.ReLU", "Networks.Discriminator2d.conv2", "torch.ReLU", "torch.ReLU", "torch.ReLU", "Networks.Discriminator2d.conv3", "torch.ReLU", "torch.ReLU", "torch.ReLU", "Networks.Discriminator2d.conv4"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "nn", ".", "ReLU", "(", ")", "(", "self", ".", "conv0", "(", "x", ")", ")", "\n", "x", "=", "nn", ".", "ReLU", "(", ")", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "x", "=", "nn", ".", "ReLU", "(", ")", "(", "self", ".", "conv2", "(", "x", ")", ")", "\n", "x", "=", "nn", ".", "ReLU", "(", ")", "(", "self", ".", "conv3", "(", "x", ")", ")", "\n", "x", "=", "nn", ".", "ReLU", "(", ")", "(", "self", ".", "conv4", "(", "x", ")", ")", "\n", "return", "self", ".", "conv5", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator2D.__init__": [[239, 257], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.nn.PixelShuffle", "torch.nn.PixelShuffle", "torch.nn.PixelShuffle", "torch.nn.PixelShuffle", "torch.nn.PixelShuffle", "torch.nn.PixelShuffle", "torch.nn.PixelShuffle", "torch.nn.PixelShuffle", "torch.nn.PixelShuffle", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "range", "range"], "methods", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator2D.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ngpu", ",", "wg", ",", "nc_g", ",", "nc_d", ",", "n_res_blocks", ")", ":", "\n", "        ", "super", "(", "Generator2D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_res_blocks", "=", "n_res_blocks", "\n", "self", ".", "ngpu", "=", "ngpu", "\n", "self", ".", "conv_minus_1", "=", "nn", ".", "Conv2d", "(", "nc_g", ",", "2", "**", "wg", ",", "3", ",", "1", ",", "1", ")", "\n", "self", ".", "bn_minus_1", "=", "nn", ".", "BatchNorm2d", "(", "2", "**", "wg", ")", "\n", "# first convolution, making many channels", "\n", "self", ".", "conv_res", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv2d", "(", "2", "**", "wg", ",", "2", "**", "wg", ",", "3", ",", "1", ",", "1", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "n_res_blocks", ")", "]", ")", "\n", "self", ".", "bn_res", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "BatchNorm2d", "(", "2", "**", "wg", ")", "for", "_", "in", "\n", "range", "(", "self", ".", "n_res_blocks", ")", "]", ")", "\n", "# the number of channels is because of pixel shuffling", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "2", "**", "(", "wg", "-", "2", ")", ",", "2", "**", "(", "wg", "-", "2", ")", ",", "3", ",", "1", ",", "1", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "2", "**", "(", "wg", "-", "2", ")", ")", "\n", "# last convolution, squashing all of the channels to 3 phases:", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "2", "**", "(", "wg", "-", "4", ")", ",", "nc_d", ",", "3", ",", "1", ",", "1", ")", "\n", "# use twice pixel shuffling:", "\n", "self", ".", "pixel", "=", "torch", ".", "nn", ".", "PixelShuffle", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator2D.res_block": [[258, 272], ["bn", "conv", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "bn", "conv"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "res_block", "(", "x", ",", "conv", ",", "bn", ")", ":", "\n", "        ", "\"\"\"\n        A forward pass of a residual block (from the original paper)\n        :param x: the input\n        :param conv: the convolution function, should return the same number\n        of channels, and the same width and height of the image. For example,\n        kernel size 3, padding 1 stride 1.\n        :param bn: batch norm function\n        :return: the result after the residual block.\n        \"\"\"", "\n", "# the residual side", "\n", "x_side", "=", "bn", "(", "conv", "(", "nn", ".", "ReLU", "(", ")", "(", "bn", "(", "conv", "(", "x", ")", ")", ")", ")", ")", "\n", "return", "nn", ".", "ReLU", "(", ")", "(", "x", "+", "x_side", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator2D.up_sample": [[273, 279], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "pix_shuffling", "bn", "conv"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "up_sample", "(", "x", ",", "pix_shuffling", ",", "conv", ",", "bn", ")", ":", "\n", "        ", "\"\"\"\n        Up sampling with pixel shuffling block.\n        \"\"\"", "\n", "return", "nn", ".", "ReLU", "(", ")", "(", "pix_shuffling", "(", "bn", "(", "conv", "(", "x", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator2D.forward": [[280, 303], ["Networks.Generator2D.res_block", "range", "Networks.Generator2D.up_sample", "Networks.Generator2D.up_sample", "Networks.Generator2D.conv2", "torch.ReLU", "torch.ReLU", "torch.ReLU", "Networks.Generator2D.bn_minus_1", "Networks.Generator2D.res_block", "torch.Softmax", "torch.Softmax", "torch.Softmax", "Networks.Generator2D.conv_minus_1"], "methods", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator2D.res_block", "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator2D.up_sample", "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator2D.up_sample", "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator2D.res_block"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        forward pass of x\n        :param x: input\n        :return: the output of the forward pass.\n        \"\"\"", "\n", "# x after the first run for many channels:", "\n", "x_first", "=", "nn", ".", "ReLU", "(", ")", "(", "self", ".", "bn_minus_1", "(", "self", ".", "conv_minus_1", "(", "x", ")", ")", ")", "\n", "# first residual block:", "\n", "after_block", "=", "self", ".", "res_block", "(", "x_first", ",", "self", ".", "conv_res", "[", "0", "]", ",", "self", ".", "bn_res", "[", "0", "]", ")", "\n", "# more residual blocks:", "\n", "for", "i", "in", "range", "(", "1", ",", "self", ".", "n_res_blocks", ")", ":", "\n", "            ", "after_block", "=", "self", ".", "res_block", "(", "after_block", ",", "self", ".", "conv_res", "[", "i", "]", ",", "\n", "self", ".", "bn_res", "[", "i", "]", ")", "\n", "# skip connection to the end after all the blocks:", "\n", "", "after_res", "=", "x_first", "+", "after_block", "\n", "# up sampling with pixel shuffling (0):", "\n", "up_0", "=", "self", ".", "up_sample", "(", "after_res", ",", "self", ".", "pixel", ",", "self", ".", "bn0", ",", "self", ".", "conv0", ")", "\n", "# up sampling with pixel shuffling (1):", "\n", "up_1", "=", "self", ".", "up_sample", "(", "up_0", ",", "self", ".", "pixel", ",", "self", ".", "bn1", ",", "self", ".", "conv1", ")", "\n", "\n", "y", "=", "self", ".", "conv2", "(", "up_1", ")", "\n", "return", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.Generator2D.return_scale_factor": [[304, 306], ["None"], "methods", ["None"], ["", "def", "return_scale_factor", "(", "self", ",", "high_res_length", ")", ":", "\n", "        ", "return", "(", "high_res_length", "/", "4", ")", "/", "high_res_length", "", "", "", ""]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.return_D_nets": [[15, 61], ["numpy.arange", "BatchMaker.BatchMaker", "len", "discriminator().to", "torch.Adam", "BatchMaker.BatchMaker", "len", "discriminator().to", "torch.Adam", "D_BMs.append", "D_nets.append", "D_optimisers.append", "torch.DataParallel", "nn.DataParallel.parameters", "torch.DataParallel", "nn.DataParallel.parameters", "Networks.discriminator", "list", "Networks.discriminator", "list", "range", "range"], "function", ["home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.discriminator", "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.discriminator"], ["def", "return_D_nets", "(", "ngpu", ",", "wd", ",", "n_dims", ",", "device", ",", "lr", ",", "beta1", ",", "anisotropic", ",", "\n", "D_images", ",", "scale_f", ",", "rotation", ",", "rotation_bool", ")", ":", "\n", "    ", "\"\"\"\n    :return: Returns the batch makers, discriminators, and optimizers for the\n    discriminators. If the material is isotropic, there is 1 discriminator,\n    and if the material is anisotropic, there are 3 discriminators.\n    \"\"\"", "\n", "D_nets", "=", "[", "]", "\n", "D_optimisers", "=", "[", "]", "\n", "D_BMs", "=", "[", "]", "\n", "if", "anisotropic", ":", "\n", "        ", "for", "i", "in", "np", ".", "arange", "(", "n_dims", ")", ":", "\n", "            ", "BM_D", "=", "BatchMaker", "(", "device", ",", "path", "=", "D_images", "[", "i", "]", ",", "sf", "=", "scale_f", ",", "\n", "dims", "=", "n_dims", ",", "stack", "=", "True", ",", "low_res", "=", "False", ",", "\n", "rot_and_mir", "=", "rotation_bool", "[", "i", "]", ")", "\n", "nc_d", "=", "len", "(", "BM_D", ".", "phases", ")", "\n", "# Create the Discriminator", "\n", "netD", "=", "discriminator", "(", "ngpu", ",", "wd", ",", "nc_d", ",", "n_dims", ")", ".", "to", "(", "device", ")", "\n", "# Handle multi-gpu if desired", "\n", "if", "(", "device", ".", "type", "==", "'cuda'", ")", "and", "(", "ngpu", ">", "1", ")", ":", "\n", "                ", "netD", "=", "nn", ".", "DataParallel", "(", "netD", ",", "list", "(", "range", "(", "ngpu", ")", ")", ")", "\n", "", "optimiserD", "=", "optim", ".", "Adam", "(", "netD", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "\n", "betas", "=", "(", "beta1", ",", "0.999", ")", ")", "\n", "# append the BMs, nets and optimisers:", "\n", "D_BMs", ".", "append", "(", "BM_D", ")", "\n", "D_nets", ".", "append", "(", "netD", ")", "\n", "D_optimisers", ".", "append", "(", "optimiserD", ")", "\n", "\n", "", "", "else", ":", "# material is isotropic", "\n", "# Create the batch maker", "\n", "        ", "BM_D", "=", "BatchMaker", "(", "device", ",", "path", "=", "D_images", "[", "0", "]", ",", "sf", "=", "scale_f", ",", "\n", "dims", "=", "n_dims", ",", "stack", "=", "True", ",", "low_res", "=", "False", ",", "\n", "rot_and_mir", "=", "rotation", ")", "\n", "# Create the Discriminator", "\n", "nc_d", "=", "len", "(", "BM_D", ".", "phases", ")", "\n", "netD", "=", "discriminator", "(", "ngpu", ",", "wd", ",", "nc_d", ",", "n_dims", ")", ".", "to", "(", "device", ")", "\n", "# Handle multi-gpu if desired", "\n", "if", "(", "device", ".", "type", "==", "'cuda'", ")", "and", "(", "ngpu", ">", "1", ")", ":", "\n", "            ", "netD", "=", "nn", ".", "DataParallel", "(", "netD", ",", "list", "(", "range", "(", "ngpu", ")", ")", ")", "\n", "", "optimiserD", "=", "optim", ".", "Adam", "(", "netD", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "\n", "betas", "=", "(", "beta1", ",", "0.999", ")", ")", "\n", "D_BMs", "=", "[", "BM_D", "]", "*", "n_dims", "# same batch maker, different pointers", "\n", "D_nets", "=", "[", "netD", "]", "*", "n_dims", "# same network, different pointers", "\n", "D_optimisers", "=", "[", "optimiserD", "]", "*", "n_dims", "# same optimiser, different", "\n", "# pointers", "\n", "", "return", "D_BMs", ",", "D_nets", ",", "D_optimisers", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.generator": [[63, 71], ["Networks.Generator3D", "Networks.Generator2D"], "function", ["None"], ["", "def", "generator", "(", "ngpu", ",", "wg", ",", "nc_g", ",", "nc_d", ",", "n_res_block", ",", "dims", ",", "scale_factor", ")", ":", "\n", "    ", "\"\"\"\n    :return: The generator depending on the number of dimensions.\n    \"\"\"", "\n", "if", "dims", "==", "3", ":", "\n", "        ", "return", "Generator3D", "(", "ngpu", ",", "wg", ",", "nc_g", ",", "nc_d", ",", "n_res_block", ",", "scale_factor", ")", "\n", "", "else", ":", "# dims == 2", "\n", "        ", "return", "Generator2D", "(", "ngpu", ",", "wg", ",", "nc_g", ",", "nc_d", ",", "n_res_block", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amirdahari1_superres.code.Networks.discriminator": [[174, 179], ["Networks.Discriminator3d", "Networks.Discriminator2d"], "function", ["None"], ["", "", "def", "discriminator", "(", "ngpu", ",", "wd", ",", "nc_d", ",", "dims", ")", ":", "\n", "    ", "if", "dims", "==", "3", ":", "# practically always", "\n", "        ", "return", "Discriminator3d", "(", "ngpu", ",", "wd", ",", "nc_d", ")", "\n", "", "else", ":", "# dims == 2", "\n", "        ", "return", "Discriminator2d", "(", "ngpu", ",", "wd", ",", "nc_d", ")", "\n", "\n"]]}