{"home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.config.build_file_name": [[41, 46], ["None"], "function", ["None"], ["def", "build_file_name", "(", ")", ":", "\n", "    ", "all_EEG_file", "=", "config", "[", "'task'", "]", "+", "'_with_'", "+", "config", "[", "'dataset'", "]", "\n", "all_EEG_file", "=", "all_EEG_file", "+", "'_'", "+", "'synchronised_'", "+", "config", "[", "'preprocessing'", "]", "\n", "all_EEG_file", "=", "all_EEG_file", "+", "(", "'_hilbert.npz'", "if", "config", "[", "'feature_extraction'", "]", "else", "'.npz'", ")", "\n", "return", "all_EEG_file", "\n", "", "config", "[", "'all_EEG_file'", "]", "=", "build_file_name", "(", ")", "# or use your own specified file name", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.config.create_folder": [[70, 91], ["str", "os.path.abspath", "str", "int", "os.path.join", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "int", "time.time", "time.time"], "function", ["None"], ["def", "create_folder", "(", ")", ":", "\n", "    ", "if", "config", "[", "'retrain'", "]", ":", "\n", "        ", "model_folder_name", "=", "str", "(", "int", "(", "time", ".", "time", "(", ")", ")", ")", "\n", "model_folder_name", "+=", "'_'", "+", "config", "[", "'task'", "]", "+", "'_'", "+", "config", "[", "'dataset'", "]", "+", "'_'", "+", "config", "[", "'preprocessing'", "]", "\n", "config", "[", "'model_dir'", "]", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "config", "[", "'log_dir'", "]", ",", "model_folder_name", ")", ")", "\n", "config", "[", "'checkpoint_dir'", "]", "=", "config", "[", "'model_dir'", "]", "+", "'/checkpoint/'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "config", "[", "'model_dir'", "]", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "config", "[", "'model_dir'", "]", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "config", "[", "'checkpoint_dir'", "]", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "config", "[", "'checkpoint_dir'", "]", ")", "\n", "\n", "", "config", "[", "'info_log'", "]", "=", "config", "[", "'model_dir'", "]", "+", "'/'", "+", "'info.log'", "\n", "config", "[", "'batches_log'", "]", "=", "config", "[", "'model_dir'", "]", "+", "'/'", "+", "'batches.log'", "\n", "\n", "", "else", ":", "\n", "        ", "config", "[", "'model_dir'", "]", "=", "config", "[", "'log_dir'", "]", "+", "config", "[", "'load_experiment_dir'", "]", "\n", "config", "[", "'checkpoint_dir'", "]", "=", "config", "[", "'model_dir'", "]", "+", "'checkpoint/'", "\n", "stamp", "=", "str", "(", "int", "(", "time", ".", "time", "(", ")", ")", ")", "\n", "config", "[", "'info_log'", "]", "=", "config", "[", "'model_dir'", "]", "+", "'/'", "+", "'inference_info_'", "+", "stamp", "+", "'.log'", "\n", "config", "[", "'batches_log'", "]", "=", "config", "[", "'model_dir'", "]", "+", "'/'", "+", "'inference_batches_'", "+", "stamp", "+", "'.log'", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.main.Tee.__init__": [[10, 12], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "*", "files", ")", ":", "\n", "        ", "self", ".", "files", "=", "files", "\n", "", "def", "write", "(", "self", ",", "obj", ")", ":", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.main.Tee.write": [[12, 16], ["f.write", "f.flush"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.main.Tee.write", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.main.Tee.flush"], ["", "def", "write", "(", "self", ",", "obj", ")", ":", "\n", "        ", "for", "f", "in", "self", ".", "files", ":", "\n", "            ", "f", ".", "write", "(", "obj", ")", "\n", "f", ".", "flush", "(", ")", "# If you want the output to be visible immediately", "\n", "", "", "def", "flush", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.main.Tee.flush": [[16, 19], ["f.flush"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.main.Tee.flush"], ["", "", "def", "flush", "(", "self", ")", ":", "\n", "        ", "for", "f", "in", "self", ".", "files", ":", "\n", "            ", "f", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.main.main": [[26, 49], ["config.create_folder", "logging.basicConfig", "logging.info", "logging.info", "time.time", "open", "main.Tee", "utils.IOHelper.get_npz_data", "benchmark.benchmark", "logging.info", "logging.info", "time.time"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.config.create_folder", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.IOHelper.get_npz_data", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.benchmark.benchmark"], ["def", "main", "(", ")", ":", "\n", "# Setting up logging", "\n", "    ", "create_folder", "(", ")", "\n", "logging", ".", "basicConfig", "(", "filename", "=", "config", "[", "'info_log'", "]", ",", "level", "=", "logging", ".", "INFO", ")", "\n", "logging", ".", "info", "(", "'Started the Logging'", ")", "\n", "logging", ".", "info", "(", "f\"Using {config['framework']}\"", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# For being able to see progress that some methods use verbose (for debugging purposes)", "\n", "f", "=", "open", "(", "config", "[", "'model_dir'", "]", "+", "'/console.out'", ",", "'w'", ")", "\n", "original", "=", "sys", ".", "stdout", "\n", "sys", ".", "stdout", "=", "Tee", "(", "sys", ".", "stdout", ",", "f", ")", "\n", "\n", "#Load the data", "\n", "trainX", ",", "trainY", "=", "IOHelper", ".", "get_npz_data", "(", "config", "[", "'data_dir'", "]", ",", "verbose", "=", "True", ")", "\n", "\n", "#Start benchmark", "\n", "benchmark", "(", "trainX", ",", "trainY", ")", "\n", "#directory = 'results/standardML'", "\n", "#print_table(directory, preprocessing='max')", "\n", "\n", "logging", ".", "info", "(", "\"--- Runtime: %s seconds ---\"", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "logging", ".", "info", "(", "'Finished Logging'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.hyperparameters.merge_models": [[415, 430], ["dict", "base_dict.keys", "new_dict.keys", "hyperparameters.merge_models", "type", "type"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.hyperparameters.merge_models"], ["def", "merge_models", "(", "base_dict", ",", "new_dict", ")", ":", "\n", "    ", "result", "=", "dict", "(", ")", "\n", "keys", "=", "base_dict", ".", "keys", "(", ")", "|", "new_dict", ".", "keys", "(", ")", "\n", "for", "k", "in", "keys", ":", "\n", "        ", "if", "k", "in", "base_dict", "and", "k", "in", "new_dict", ":", "\n", "            ", "if", "type", "(", "base_dict", "[", "k", "]", ")", "==", "dict", "and", "type", "(", "new_dict", "[", "k", "]", ")", "==", "dict", ":", "\n", "                ", "result", "[", "k", "]", "=", "merge_models", "(", "base_dict", "[", "k", "]", ",", "new_dict", "[", "k", "]", ")", "\n", "", "else", ":", "\n", "# overriding", "\n", "                ", "result", "[", "k", "]", "=", "new_dict", "[", "k", "]", "\n", "", "", "elif", "k", "in", "base_dict", ":", "\n", "            ", "result", "[", "k", "]", "=", "base_dict", "[", "k", "]", "\n", "", "else", ":", "\n", "            ", "result", "[", "k", "]", "=", "new_dict", "[", "k", "]", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.benchmark.split": [[15, 30], ["numpy.unique", "len", "math.ceil", "math.ceil", "numpy.isin", "numpy.isin", "numpy.isin"], "function", ["None"], ["def", "split", "(", "ids", ",", "train", ",", "val", ",", "test", ")", ":", "\n", "    ", "assert", "(", "train", "+", "val", "+", "test", "==", "1", ")", "\n", "IDs", "=", "np", ".", "unique", "(", "ids", ")", "\n", "num_ids", "=", "len", "(", "IDs", ")", "\n", "\n", "# priority given to the test/val sets", "\n", "test_split", "=", "math", ".", "ceil", "(", "test", "*", "num_ids", ")", "\n", "val_split", "=", "math", ".", "ceil", "(", "val", "*", "num_ids", ")", "\n", "train_split", "=", "num_ids", "-", "val_split", "-", "test_split", "\n", "\n", "train", "=", "np", ".", "isin", "(", "ids", ",", "IDs", "[", ":", "train_split", "]", ")", "\n", "val", "=", "np", ".", "isin", "(", "ids", ",", "IDs", "[", "train_split", ":", "train_split", "+", "val_split", "]", ")", "\n", "test", "=", "np", ".", "isin", "(", "ids", ",", "IDs", "[", "train_split", "+", "val_split", ":", "]", ")", "\n", "\n", "return", "train", ",", "val", ",", "test", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.benchmark.try_models": [[32, 94], ["logging.info", "benchmark.split", "models.items", "numpy.savetxt", "numpy.savetxt", "logging.info", "sklearn.preprocessing.StandardScaler", "sklearn.preprocessing.StandardScaler.fit", "sklearn.preprocessing.StandardScaler.transform", "sklearn.preprocessing.StandardScaler.transform", "sklearn.preprocessing.StandardScaler.transform", "logging.info", "range", "numpy.array", "statistics.append", "logging.info", "time.time", "scoring", "all_runs.append", "np.array.append", "logging.info", "logging.info", "os.path.exists", "os.makedirs", "trainer.fit", "trainer.load", "trainer.save", "trainer.predict", "time.time", "model_scores.mean", "model_scores.std", "model_runtimes.mean", "model_runtimes.std", "str"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.ml_utils.split", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.load", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.save", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.predict"], ["", "def", "try_models", "(", "trainX", ",", "trainY", ",", "ids", ",", "models", ",", "N", "=", "5", ",", "scoring", "=", "None", ",", "scale", "=", "False", ",", "save_trail", "=", "''", ",", "save", "=", "False", ")", ":", "\n", "\n", "    ", "logging", ".", "info", "(", "\"Training the models\"", ")", "\n", "train", ",", "val", ",", "test", "=", "split", "(", "ids", ",", "0.7", ",", "0.15", ",", "0.15", ")", "\n", "X_train", ",", "y_train", "=", "trainX", "[", "train", "]", ",", "trainY", "[", "train", "]", "\n", "X_val", ",", "y_val", "=", "trainX", "[", "val", "]", ",", "trainY", "[", "val", "]", "\n", "X_test", ",", "y_test", "=", "trainX", "[", "test", "]", ",", "trainY", "[", "test", "]", "\n", "\n", "if", "scale", ":", "\n", "        ", "logging", ".", "info", "(", "'Standard Scaling'", ")", "\n", "scaler", "=", "StandardScaler", "(", ")", "\n", "scaler", ".", "fit", "(", "X_train", ")", "\n", "X_train", "=", "scaler", ".", "transform", "(", "X_train", ")", "\n", "X_val", "=", "scaler", ".", "transform", "(", "X_val", ")", "\n", "X_test", "=", "scaler", ".", "transform", "(", "X_test", ")", "\n", "\n", "", "all_runs", "=", "[", "]", "\n", "statistics", "=", "[", "]", "\n", "\n", "for", "name", ",", "model", "in", "models", ".", "items", "(", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"Training of \"", "+", "name", ")", "\n", "\n", "model_runs", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "# create the model with the corresponding parameters", "\n", "            ", "trainer", "=", "model", "[", "0", "]", "(", "**", "model", "[", "1", "]", ")", "\n", "logging", ".", "info", "(", "trainer", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Taking care of saving and loading", "\n", "path", "=", "config", "[", "'checkpoint_dir'", "]", "+", "'run'", "+", "str", "(", "i", "+", "1", ")", "+", "'/'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "path", ")", "\n", "\n", "", "if", "config", "[", "'retrain'", "]", ":", "\n", "                ", "trainer", ".", "fit", "(", "X_train", ",", "y_train", ",", "X_val", ",", "y_val", ")", "\n", "", "else", ":", "\n", "                ", "trainer", ".", "load", "(", "path", ")", "\n", "\n", "", "if", "config", "[", "'save_models'", "]", ":", "\n", "                ", "trainer", ".", "save", "(", "path", ")", "\n", "\n", "#pred = trainer.predict(X_test)", "\n", "#print(y_test.shape)", "\n", "#print(pred.shape)", "\n", "", "score", "=", "scoring", "(", "y_test", ",", "trainer", ".", "predict", "(", "X_test", ")", ")", "\n", "#print(score)", "\n", "\n", "runtime", "=", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", "\n", "all_runs", ".", "append", "(", "[", "name", ",", "score", ",", "runtime", "]", ")", "\n", "model_runs", ".", "append", "(", "[", "score", ",", "runtime", "]", ")", "\n", "\n", "logging", ".", "info", "(", "\"--- Score: %s \"", "%", "score", ")", "\n", "logging", ".", "info", "(", "\"--- Runtime: %s for seconds ---\"", "%", "runtime", ")", "\n", "\n", "", "model_runs", "=", "np", ".", "array", "(", "model_runs", ")", "\n", "model_scores", ",", "model_runtimes", "=", "model_runs", "[", ":", ",", "0", "]", ",", "model_runs", "[", ":", ",", "1", "]", "\n", "statistics", ".", "append", "(", "[", "name", ",", "model_scores", ".", "mean", "(", ")", ",", "model_scores", ".", "std", "(", ")", ",", "model_runtimes", ".", "mean", "(", ")", ",", "model_runtimes", ".", "std", "(", ")", "]", ")", "\n", "\n", "", "np", ".", "savetxt", "(", "config", "[", "'model_dir'", "]", "+", "'/runs'", "+", "save_trail", "+", "'.csv'", ",", "all_runs", ",", "fmt", "=", "'%s'", ",", "delimiter", "=", "','", ",", "header", "=", "'Model,Score,Runtime'", ",", "comments", "=", "''", ")", "\n", "np", ".", "savetxt", "(", "config", "[", "'model_dir'", "]", "+", "'/statistics'", "+", "save_trail", "+", "'.csv'", ",", "statistics", ",", "fmt", "=", "'%s'", ",", "delimiter", "=", "','", ",", "header", "=", "'Model,Mean_score,Std_score,Mean_runtime,Std_runtime'", ",", "comments", "=", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.benchmark.benchmark": [[95, 130], ["numpy.savetxt", "benchmark.try_models", "ValueError", "sklearn.metrics.accuracy_score", "benchmark.try_models", "benchmark.try_models", "ValueError", "NotImplementedError", "y_pred.ravel", "numpy.sqrt", "numpy.sqrt", "benchmark.try_models", "ValueError", "sklearn.metrics.mean_squared_error", "numpy.mean", "numpy.sqrt", "numpy.linalg.norm().mean", "y_pred.ravel", "numpy.square", "sklearn.metrics.mean_squared_error", "numpy.arctan2", "numpy.linalg.norm", "numpy.sin", "numpy.cos", "y_pred.ravel", "y_pred.ravel"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.benchmark.try_models", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.benchmark.try_models", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.benchmark.try_models", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.None.benchmark.try_models", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.EEGModels.square"], ["", "def", "benchmark", "(", "trainX", ",", "trainY", ")", ":", "\n", "    ", "np", ".", "savetxt", "(", "config", "[", "'model_dir'", "]", "+", "'/config.csv'", ",", "[", "config", "[", "'task'", "]", ",", "config", "[", "'dataset'", "]", ",", "config", "[", "'preprocessing'", "]", "]", ",", "fmt", "=", "'%s'", ")", "\n", "models", "=", "all_models", "[", "config", "[", "'task'", "]", "]", "[", "config", "[", "'dataset'", "]", "]", "[", "config", "[", "'preprocessing'", "]", "]", "\n", "\n", "ids", "=", "trainY", "[", ":", ",", "0", "]", "\n", "\n", "if", "config", "[", "'task'", "]", "==", "'LR_task'", ":", "\n", "        ", "if", "config", "[", "'dataset'", "]", "==", "'antisaccade'", ":", "\n", "            ", "scoring", "=", "(", "lambda", "y", ",", "y_pred", ":", "accuracy_score", "(", "y", ",", "y_pred", ".", "ravel", "(", ")", ")", ")", "# Subject to change to mean euclidean distance.", "\n", "y", "=", "trainY", "[", ":", ",", "1", "]", "# The first column are the Id-s, we take the second which are labels", "\n", "try_models", "(", "trainX", "=", "trainX", ",", "trainY", "=", "y", ",", "ids", "=", "ids", ",", "models", "=", "models", ",", "scoring", "=", "scoring", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"This task cannot be predicted (is not implemented yet) with the given dataset.\"", ")", "\n", "\n", "", "", "elif", "config", "[", "'task'", "]", "==", "'Direction_task'", ":", "\n", "        ", "if", "config", "[", "'dataset'", "]", "==", "'dots'", ":", "\n", "            ", "scoring", "=", "(", "lambda", "y", ",", "y_pred", ":", "np", ".", "sqrt", "(", "mean_squared_error", "(", "y", ",", "y_pred", ".", "ravel", "(", ")", ")", ")", ")", "\n", "y1", "=", "trainY", "[", ":", ",", "1", "]", "# The first column are the Id-s, we take the second which are amplitude labels", "\n", "try_models", "(", "trainX", "=", "trainX", ",", "trainY", "=", "y1", ",", "ids", "=", "ids", ",", "models", "=", "models", "[", "'amplitude'", "]", ",", "scoring", "=", "scoring", ",", "save_trail", "=", "'_amplitude'", ")", "\n", "scoring2", "=", "(", "lambda", "y", ",", "y_pred", ":", "np", ".", "sqrt", "(", "np", ".", "mean", "(", "np", ".", "square", "(", "np", ".", "arctan2", "(", "np", ".", "sin", "(", "y", "-", "y_pred", ".", "ravel", "(", ")", ")", ",", "np", ".", "cos", "(", "y", "-", "y_pred", ".", "ravel", "(", ")", ")", ")", ")", ")", ")", ")", "\n", "y2", "=", "trainY", "[", ":", ",", "2", "]", "# The first column are the Id-s, second are the amplitude labels, we take the third which are the angle labels", "\n", "try_models", "(", "trainX", "=", "trainX", ",", "trainY", "=", "y2", ",", "ids", "=", "ids", ",", "models", "=", "models", "[", "'angle'", "]", ",", "scoring", "=", "scoring2", ",", "save_trail", "=", "'_angle'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"This task cannot be predicted (is not implemented yet) with the given dataset.\"", ")", "\n", "\n", "", "", "elif", "config", "[", "'task'", "]", "==", "'Position_task'", ":", "\n", "        ", "if", "config", "[", "'dataset'", "]", "==", "'dots'", ":", "\n", "            ", "scoring", "=", "(", "lambda", "y", ",", "y_pred", ":", "np", ".", "sqrt", "(", "mean_squared_error", "(", "y", ",", "y_pred", ")", ")", ")", "# Subject to change to mean euclidean distance.", "\n", "scoring2", "=", "(", "lambda", "y", ",", "y_pred", ":", "np", ".", "linalg", ".", "norm", "(", "y", "-", "y_pred", ",", "axis", "=", "1", ")", ".", "mean", "(", ")", ")", "# Euclidean distance", "\n", "y", "=", "trainY", "[", ":", ",", "1", ":", "]", "# The first column are the Id-s, the second and third are position x and y which we use", "\n", "try_models", "(", "trainX", "=", "trainX", ",", "trainY", "=", "y", ",", "ids", "=", "ids", ",", "models", "=", "models", ",", "scoring", "=", "scoring2", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"This task cannot be predicted (is not implemented yet) with the given dataset.\"", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"Task {config['task']} is not implemented yet.\"", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.IOHelper.get_npz_data": [[8, 21], ["logging.info", "numpy.load", "logging.info", "logging.info", "logging.info", "logging.info"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.load"], ["def", "get_npz_data", "(", "data_dir", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "if", "verbose", ":", "\n", "        ", "logging", ".", "info", "(", "'Loading '", "+", "config", "[", "'all_EEG_file'", "]", ")", "\n", "", "with", "np", ".", "load", "(", "data_dir", "+", "config", "[", "'all_EEG_file'", "]", ")", "as", "f", ":", "\n", "        ", "X", "=", "f", "[", "config", "[", "'trainX_variable'", "]", "]", "\n", "if", "verbose", ":", "\n", "            ", "logging", ".", "info", "(", "\"X training loaded.\"", ")", "\n", "logging", ".", "info", "(", "X", ".", "shape", ")", "\n", "", "y", "=", "f", "[", "config", "[", "'trainY_variable'", "]", "]", "\n", "if", "verbose", ":", "\n", "            ", "logging", ".", "info", "(", "\"y training loaded.\"", ")", "\n", "logging", ".", "info", "(", "y", ".", "shape", ")", "\n", "", "", "return", "X", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.IOHelper.store": [[22, 33], ["open", "pickle.dump", "open.close", "open", "pickle.dump", "open.close"], "function", ["None"], ["", "def", "store", "(", "x", ",", "y", ",", "clip", "=", "True", ")", ":", "\n", "    ", "if", "clip", ":", "\n", "        ", "x", "=", "x", "[", ":", "10000", "]", "\n", "y", "=", "y", "[", ":", "10000", "]", "\n", "", "output_x", "=", "open", "(", "'x_clip.pkl'", ",", "'wb'", ")", "\n", "pickle", ".", "dump", "(", "x", ",", "output_x", ")", "\n", "output_x", ".", "close", "(", ")", "\n", "\n", "output_y", "=", "open", "(", "'y_clip.pkl'", ",", "'wb'", ")", "\n", "pickle", ".", "dump", "(", "y", ",", "output_y", ")", "\n", "output_y", ".", "close", "(", ")", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.tables_utils.f": [[20, 29], ["abs", "int"], "function", ["None"], ["def", "f", "(", "x", ",", "n", ",", "shift", "=", "None", ",", "tol", "=", "8", ")", ":", "\n", "    ", "if", "shift", ":", "\n", "        ", "x", "=", "x", "*", "10", "**", "shift", "\n", "", "if", "abs", "(", "x", ")", "<", "10", "**", "-", "tol", ":", "\n", "        ", "return", "'0'", "\n", "", "if", "int", "(", "x", "*", "10", "**", "n", ")", "==", "0", ":", "\n", "        ", "return", "f'\\\\num{{{x:.0e}}}'", "\n", "", "else", ":", "\n", "        ", "return", "f'{x:.{n}f}'", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.tables_utils.print_table": [[30, 65], ["sorted", "os.listdir", "os.listdir", "numpy.loadtxt", "sorted", "pandas.read_csv", "stats.replace.replace", "stat_files.append", "print", "os.path.splitext", "tables_utils.f", "tables_utils.f", "tables_utils.f", "tables_utils.f"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.tables_utils.f", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.tables_utils.f", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.tables_utils.f", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.tables_utils.f"], ["", "", "def", "print_table", "(", "directory", ",", "preprocessing", "=", "None", ")", ":", "\n", "    ", "for", "f1", "in", "sorted", "(", "os", ".", "listdir", "(", "directory", ")", ")", ":", "\n", "        ", "cur_dir", "=", "directory", "+", "'/'", "+", "f1", "\n", "\n", "config_file", "=", "None", "\n", "stat_files", "=", "[", "]", "\n", "\n", "for", "f2", "in", "os", ".", "listdir", "(", "cur_dir", ")", ":", "\n", "            ", "if", "'config'", "in", "f2", ":", "\n", "                ", "config_file", "=", "f2", "\n", "", "elif", "'statistics'", "in", "f2", ":", "\n", "                ", "stat_files", ".", "append", "(", "f2", ")", "\n", "\n", "", "", "if", "config_file", "!=", "None", ":", "\n", "            ", "config", "=", "np", ".", "loadtxt", "(", "cur_dir", "+", "'/'", "+", "config_file", ",", "dtype", "=", "str", ")", "\n", "\n", "if", "preprocessing", "and", "config", "[", "2", "]", "!=", "preprocessing", ":", "\n", "                ", "continue", "\n", "\n", "", "for", "stats", "in", "sorted", "(", "stat_files", ")", ":", "\n", "\n", "                ", "metrics", "=", "pd", ".", "read_csv", "(", "cur_dir", "+", "'/'", "+", "stats", ")", "\n", "\n", "stats", "=", "stats", ".", "replace", "(", "'statistics_'", ",", "''", ")", "\n", "label", "=", "os", ".", "path", ".", "splitext", "(", "stats", ")", "[", "0", "]", "if", "'statistics'", "not", "in", "stats", "else", "'-'", "\n", "\n", "#txt1 = f'{{{config[0]}}} & {{{config[1]}}} & {{{config[2]}}} & {{{label}}} & '", "\n", "txt1", "=", "f'{{{Task[config[0]][label]}}} & '", "\n", "shift", "=", "2", "if", "config", "[", "0", "]", "==", "'LR_task'", "else", "None", "\n", "\n", "for", "i", "in", "metrics", ".", "index", ":", "\n", "                    ", "row", "=", "metrics", ".", "loc", "[", "i", "]", "\n", "x0", ",", "x1", ",", "x2", ",", "x3", ",", "x4", "=", "row", "[", "'Model'", "]", ",", "row", "[", "'Mean_score'", "]", ",", "row", "[", "'Std_score'", "]", ",", "row", "[", "'Mean_runtime'", "]", ",", "row", "[", "'Std_runtime'", "]", "\n", "txt2", "=", "f'{{{x0}}} & {f(x1, 4, shift=shift)} & {f(x2, 4, shift=shift)} & {f(x3, 3)} & {f(x4, 3)} \\\\\\\\'", "\n", "print", "(", "txt1", "+", "txt2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.plot.plot_batches_log_loss": [[11, 31], ["pandas.read_csv", "pd.read_csv.to_numpy", "matplotlib.plot", "matplotlib.plot", "matplotlib.ylabel", "matplotlib.title", "matplotlib.legend", "matplotlib.savefig"], "function", ["None"], ["x", "=", "np", ".", "loadtxt", "(", "file_path", ",", "delimiter", "=", "','", ")", "\n", "epochs", "=", "np", ".", "arange", "(", "len", "(", "x", ")", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "if", "config", "[", "'pretrained'", "]", ":", "\n", "        ", "plt", ".", "title", "(", "\"Pretrained \"", "+", "config", "[", "'model'", "]", "+", "' loss'", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "title", "(", "config", "[", "'model'", "]", "+", "' loss'", ")", "\n", "", "plt", ".", "plot", "(", "epochs", ",", "x", ",", "'b-'", ",", "label", "=", "'validation'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "xlabel", "(", "'epochs'", ")", "\n", "\n", "if", "config", "[", "'task'", "]", "==", "'gaze-reg'", ":", "\n", "        ", "plt", ".", "ylabel", "(", "\"MSE\"", ")", "\n", "", "elif", "config", "[", "'task'", "]", "==", "'angle-reg'", ":", "\n", "        ", "plt", ".", "ylabel", "(", "\"Mean Absolute Angle Error\"", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "ylabel", "(", "'Binary Cross Entropy Loss'", ")", "\n", "", "if", "savefig", ":", "\n", "        ", "plt", ".", "savefig", "(", "output_dir", "+", "'/plots/'", "+", "config", "[", "'model'", "]", "+", "'_val_'", "+", "metric", "+", "'.png'", ")", "\n", "\n", "", "", "def", "plot_array", "(", "x", ",", "output_dir", ",", "metric", ",", "savefig", "=", "True", ")", ":", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.plot.plot_model": [[32, 38], ["tensorflow.keras.utils.plot_model"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.plot.plot_model"], ["    ", "\"\"\"\n    Plot the metric saved in the file_path file \n    \"\"\"", "\n", "logging", ".", "info", "(", "\"Plotting metrics...\"", ")", "\n", "epochs", "=", "np", ".", "arange", "(", "len", "(", "x", ")", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "if", "config", "[", "'pretrained'", "]", ":", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.plot.compute_loss": [[47, 55], ["feature_extractor", "tensorflow.reduce_mean"], "function", ["None"], ["        ", "plt", ".", "ylabel", "(", "\"MSE\"", ")", "\n", "", "elif", "metric", "==", "'accuracy'", ":", "\n", "        ", "plt", ".", "ylabel", "(", "\"Accuracy\"", ")", "\n", "", "elif", "config", "[", "'task'", "]", "==", "'angle-reg'", ":", "\n", "        ", "plt", ".", "ylabel", "(", "\"Mean Absolute Angle Error\"", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "ylabel", "(", "'Binary Cross Entropy Loss'", ")", "\n", "", "if", "savefig", ":", "\n", "        ", "plt", ".", "savefig", "(", "output_dir", "+", "'/plots/'", "+", "config", "[", "'model'", "]", "+", "'_val_'", "+", "metric", "+", "'.png'", ")", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.plot.gradient_ascent_step": [[56, 67], ["tape.gradient", "tensorflow.math.l2_normalize", "tensorflow.GradientTape", "tape.watch", "plot.compute_loss"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.utils.compute_loss"], ["\n", "", "", "def", "plot_metrics", "(", "train", ",", "val", ",", "output_dir", ",", "metric", ",", "model_number", "=", "0", ",", "savefig", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Plot the training and validation metric together in one image \n    \"\"\"", "\n", "logging", ".", "info", "(", "\"Plotting training and validation metrics ...\"", ")", "\n", "epochs", "=", "np", ".", "arange", "(", "len", "(", "train", ")", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "if", "config", "[", "'pretrained'", "]", ":", "\n", "        ", "plt", ".", "title", "(", "\"Pretrained \"", "+", "config", "[", "'model'", "]", "+", "\" \"", "+", "metric", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "title", "(", "config", "[", "'model'", "]", "+", "\" \"", "+", "str", "(", "model_number", ")", "+", "\" \"", "+", "metric", ")", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.plot.initialize_image": [[68, 74], ["tensorflow.random.uniform"], "function", ["None"], ["", "plt", ".", "plot", "(", "epochs", ",", "np", ".", "array", "(", "train", ")", ",", "'b-'", ",", "label", "=", "'train'", ")", "\n", "plt", ".", "plot", "(", "epochs", ",", "np", ".", "array", "(", "val", ")", ",", "'g-'", ",", "label", "=", "'validation'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "xlabel", "(", "'epochs'", ")", "\n", "plt", ".", "ylabel", "(", "metric", ")", "\n", "\n", "if", "savefig", ":", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.plot.visualize_filter": [[75, 86], ["plot.initialize_image", "range", "plot.deprocess_image", "plot.gradient_ascent_step", "img[].numpy"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.plot.initialize_image", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.plot.deprocess_image", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.plot.gradient_ascent_step"], ["        ", "plt", ".", "savefig", "(", "output_dir", "+", "'/plots/'", "+", "config", "[", "'model'", "]", "+", "'_'", "+", "str", "(", "model_number", ")", "+", "\"_\"", "+", "metric", "+", "'.png'", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.plot.deprocess_image": [[87, 104], ["np.clip().astype.mean", "numpy.clip", "numpy.clip().astype", "np.clip().astype.std", "numpy.clip"], "function", ["None"], []], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.utils.losses.angle_loss": [[7, 15], ["tensorflow.reduce_mean", "tensorflow.math.square", "tensorflow.abs", "tensorflow.atan2", "tensorflow.sin", "tensorflow.cos"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.EEGModels.square"], ["def", "angle_loss", "(", "a", ",", "b", ")", ":", "\n", "    ", "\"\"\"\n    Custom loss function for models that predict the angle on the fix-sacc-fix dataset\n    Angles -pi and pi should lead to 0 loss, since this is actually the same angle on the unit circle\n    Angles pi/2 and -pi/2 should lead to a large loss, since this is a difference by pi on the unit circle\n    Therefore we compute the absolute error of the \"shorter\" direction on the unit circle\n    \"\"\"", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "math", ".", "square", "(", "tf", ".", "abs", "(", "tf", ".", "atan2", "(", "tf", ".", "sin", "(", "a", "-", "b", ")", ",", "tf", ".", "cos", "(", "a", "-", "b", ")", ")", ")", ")", ")", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningDL.kerasTuner.build_model": [[14, 74], ["logging.info", "DeepEyeRNN.deepeyeRNN.Classifier_DEEPEYE_RNN.get_model", "DeepEye.deepeye.Classifier_DEEPEYE", "CNN.CNN.Classifier_CNN", "hp.Choice", "hp.Choice", "hp.Int", "hp.Choice", "hp.Choice", "hp.Choice", "EEGNet.eegNet.Classifier_EEGNet", "hp.Choice", "hp.Choice", "hp.Choice", "hp.Int", "InceptionTime.Inception.Classifier_INCEPTION", "hp.Choice", "hp.Choice", "hp.Choice", "hp.Choice", "Xception.Xception.Classifier_XCEPTION", "hp.Choice", "hp.Choice", "hp.Choice", "hp.Int", "hp.Choice", "DeepEyeRNN.deepeyeRNN.Classifier_DEEPEYE_RNN", "logging.info", "hp.Choice", "hp.Choice", "hp.Choice", "hp.Int"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.BaseNet.BaseNet.get_model"], ["def", "build_model", "(", "hp", ")", ":", "\n", "    ", "classifier", "=", "None", "\n", "logging", ".", "info", "(", "'Starting tuning '", "+", "config", "[", "'model'", "]", ")", "\n", "if", "config", "[", "'model'", "]", "==", "'deepeye'", ":", "\n", "        ", "classifier", "=", "Classifier_DEEPEYE", "(", "input_shape", "=", "config", "[", "'deepeye'", "]", "[", "'input_shape'", "]", ",", "\n", "epochs", "=", "15", ",", "verbose", "=", "True", ",", "batch_size", "=", "64", ",", "use_residual", "=", "True", ",", "\n", "kernel_size", "=", "hp", ".", "Choice", "(", "'kernel_size'", ",", "values", "=", "[", "32", ",", "40", ",", "64", "]", ")", ",", "\n", "nb_filters", "=", "hp", ".", "Choice", "(", "'nb_filters'", ",", "values", "=", "[", "32", ",", "64", "]", ")", ",", "\n", "depth", "=", "hp", ".", "Int", "(", "'depth'", ",", "min_value", "=", "6", ",", "max_value", "=", "14", ",", "step", "=", "4", ")", ",", "\n", "bottleneck_size", "=", "hp", ".", "Choice", "(", "'bottleneck_size'", ",", "values", "=", "[", "32", ",", "64", "]", ")", ",", "\n", "use_simple_convolution", "=", "hp", ".", "Choice", "(", "'use_simple_convolution'", ",", "values", "=", "[", "True", ",", "False", "]", ")", ",", "\n", "use_separable_convolution", "=", "hp", ".", "Choice", "(", "'use_separable_convolution'", ",", "values", "=", "[", "True", ",", "False", "]", ")", ",", "\n", "preprocessing", "=", "False", ")", "\n", "\n", "# use_separable_convolution=hp.Choice('use_separable_convolution', values=[True, False]),", "\n", "# preprocessing_F1 = hp.Choice('preprocessing_F1', values=[8, 16, 32, 64]),", "\n", "# preprocessing_D = hp.Choice('preprocessing_F1', values=[2, 4, 6, 8]),", "\n", "# preprocessing_kernLength = hp.Choice('preprocessing_kernlength', values=[64, 125, 250]),", "\n", "\n", "", "elif", "config", "[", "'model'", "]", "==", "'cnn'", ":", "\n", "        ", "classifier", "=", "Classifier_CNN", "(", "input_shape", "=", "config", "[", "'cnn'", "]", "[", "'input_shape'", "]", ",", "\n", "epochs", "=", "2", ",", "verbose", "=", "True", ",", "batch_size", "=", "64", ",", "\n", "use_residual", "=", "hp", ".", "Choice", "(", "'use_residual'", ",", "values", "=", "[", "True", ",", "False", "]", ")", ",", "\n", "kernel_size", "=", "hp", ".", "Choice", "(", "'kernel_size'", ",", "values", "=", "[", "40", ",", "32", ",", "64", "]", ")", ",", "\n", "nb_filters", "=", "hp", ".", "Choice", "(", "'nb_filters'", ",", "values", "=", "[", "16", ",", "32", ",", "64", "]", ")", ",", "\n", "depth", "=", "hp", ".", "Int", "(", "'depth'", ",", "min_value", "=", "6", ",", "max_value", "=", "20", ",", "step", "=", "3", ")", ",", "\n", "preprocessing", "=", "False", "\n", ")", "\n", "", "elif", "config", "[", "'model'", "]", "==", "'eegnet'", ":", "\n", "        ", "classifier", "=", "Classifier_EEGNet", "(", "dropoutRate", "=", "0.5", ",", "\n", "kernLength", "=", "hp", ".", "Choice", "(", "'kernelLength'", ",", "values", "=", "[", "64", ",", "125", ",", "250", "]", ")", ",", "\n", "F1", "=", "hp", ".", "Choice", "(", "'F1'", ",", "values", "=", "[", "16", ",", "32", ",", "64", "]", ")", ",", "\n", "D", "=", "hp", ".", "Choice", "(", "'D'", ",", "values", "=", "[", "2", ",", "4", ",", "8", "]", ")", ",", "\n", "F2", "=", "hp", ".", "Choice", "(", "'F2'", ",", "values", "=", "[", "32", ",", "64", ",", "128", ",", "256", ",", "512", "]", ")", ",", "\n", "norm_rate", "=", "0.5", ",", "dropoutType", "=", "'Dropout'", ",", "epochs", "=", "50", ")", "\n", "\n", "", "elif", "config", "[", "'model'", "]", "==", "'inception'", ":", "\n", "        ", "classifier", "=", "Classifier_INCEPTION", "(", "input_shape", "=", "config", "[", "'inception'", "]", "[", "'input_shape'", "]", ",", "\n", "epochs", "=", "15", ",", "verbose", "=", "True", ",", "batch_size", "=", "64", ",", "\n", "use_residual", "=", "hp", ".", "Choice", "(", "'use_residual'", ",", "values", "=", "[", "True", ",", "False", "]", ")", ",", "\n", "kernel_size", "=", "hp", ".", "Choice", "(", "'kernel_size'", ",", "values", "=", "[", "40", ",", "32", ",", "64", "]", ")", ",", "\n", "nb_filters", "=", "hp", ".", "Choice", "(", "'nb_filters'", ",", "values", "=", "[", "16", ",", "32", ",", "64", "]", ")", ",", "\n", "depth", "=", "hp", ".", "Int", "(", "'depth'", ",", "min_value", "=", "6", ",", "max_value", "=", "20", ",", "step", "=", "3", ")", ",", "\n", "bottleneck_size", "=", "hp", ".", "Choice", "(", "'bottleneck_size'", ",", "values", "=", "[", "16", ",", "32", ",", "64", "]", ")", "\n", ")", "\n", "\n", "", "elif", "config", "[", "'model'", "]", "==", "'xception'", ":", "\n", "        ", "classifier", "=", "Classifier_XCEPTION", "(", "input_shape", "=", "config", "[", "'inception'", "]", "[", "'input_shape'", "]", ",", "\n", "epochs", "=", "2", ",", "verbose", "=", "True", ",", "batch_size", "=", "64", ",", "\n", "use_residual", "=", "hp", ".", "Choice", "(", "'use_residual'", ",", "values", "=", "[", "True", ",", "False", "]", ")", ",", "\n", "kernel_size", "=", "hp", ".", "Choice", "(", "'kernel_size'", ",", "values", "=", "[", "40", ",", "32", ",", "64", "]", ")", ",", "\n", "nb_filters", "=", "hp", ".", "Choice", "(", "'nb_filters'", ",", "values", "=", "[", "16", ",", "32", ",", "64", "]", ")", ",", "\n", "depth", "=", "hp", ".", "Int", "(", "'depth'", ",", "min_value", "=", "6", ",", "max_value", "=", "20", ",", "step", "=", "3", ")", "\n", ")", "\n", "", "elif", "config", "[", "'model'", "]", "==", "'deepeye-rnn'", ":", "\n", "        ", "classifier", "=", "Classifier_DEEPEYE_RNN", "(", "input_shape", "=", "config", "[", "'deepeye-rnn'", "]", "[", "'input_shape'", "]", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "'Cannot start the program. Please choose one model in the config.py file'", ")", "\n", "\n", "", "return", "classifier", ".", "get_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningDL.kerasTuner.tune": [[76, 90], ["kerastuner.tuners.RandomSearch", "print", "kerastuner.tuners.RandomSearch.search_space_summary", "sklearn.model_selection.train_test_split", "kerastuner.tuners.RandomSearch.search", "kerastuner.tuners.RandomSearch.results_summary"], "function", ["None"], ["", "def", "tune", "(", "trainX", ",", "trainY", ")", ":", "\n", "    ", "tuner", "=", "RandomSearch", "(", "\n", "build_model", ",", "\n", "objective", "=", "'val_accuracy'", ",", "\n", "max_trials", "=", "32", ",", "\n", "executions_per_trial", "=", "1", ",", "\n", "directory", "=", "'kerasTunerResults'", ",", "\n", "project_name", "=", "'KerasTuner'", ")", "\n", "\n", "print", "(", "trainX", ".", "shape", ")", "\n", "tuner", ".", "search_space_summary", "(", ")", "\n", "X_train", ",", "X_val", ",", "y_train", ",", "y_val", "=", "train_test_split", "(", "trainX", ",", "trainY", ",", "test_size", "=", "0.2", ",", "random_state", "=", "42", ")", "\n", "tuner", ".", "search", "(", "X_train", ",", "y_train", ",", "epochs", "=", "15", ",", "validation_data", "=", "(", "X_val", ",", "y_val", ")", ",", "verbose", "=", "2", ")", "\n", "tuner", ".", "results_summary", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearndummy.try_sklearn_dummy": [[33, 73], ["logging.info", "sklearndummy.export_dict", "logging.info", "sklearn.preprocessing.StandardScaler", "sklearn.preprocessing.StandardScaler.fit", "sklearn.preprocessing.StandardScaler.transform", "logging.info", "models.append", "time.time", "classifier.fit", "scores.append", "runtimes.append", "logging.info", "logging.info", "y_train.ravel", "classifier.score", "time.time", "y_test.ravel", "sklearn.metrics.mean_squared_error", "y_test.ravel", "classifier.predict"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.export_dict", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.predict"], ["def", "try_sklearn_dummy", "(", "X", ",", "y", ",", "train", ",", "ml_type", ",", "scale", "=", "False", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"Training the simple classifiers\"", ")", "\n", "\n", "if", "scale", ":", "\n", "        ", "logging", ".", "info", "(", "'Standard Scaling'", ")", "\n", "scaler", "=", "StandardScaler", "(", ")", "\n", "scaler", ".", "fit", "(", "X", "[", "train", "]", ")", "\n", "X", "=", "scaler", ".", "transform", "(", "X", ")", "\n", "\n", "", "X_train", ",", "y_train", "=", "X", "[", "train", "]", ",", "y", "[", "train", "]", "\n", "X_test", ",", "y_test", "=", "X", "[", "~", "train", "]", ",", "y", "[", "~", "train", "]", "\n", "\n", "tm", "=", "train_models", "[", "ml_type", "]", "\n", "\n", "models", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "runtimes", "=", "[", "]", "\n", "\n", "for", "model", "in", "tm", ":", "\n", "        ", "logging", ".", "info", "(", "\"Trainning of \"", "+", "model", ")", "\n", "\n", "models", ".", "append", "(", "model", ")", "\n", "classifier", "=", "tm", "[", "model", "]", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "classifier", ".", "fit", "(", "X_train", ",", "y_train", ".", "ravel", "(", ")", ")", "\n", "if", "ml_type", "==", "'c'", ":", "\n", "            ", "score", "=", "classifier", ".", "score", "(", "X_test", ",", "y_test", ".", "ravel", "(", ")", ")", "\n", "", "elif", "ml_type", "==", "'r'", ":", "\n", "            ", "score", "=", "mean_squared_error", "(", "y_test", ".", "ravel", "(", ")", ",", "classifier", ".", "predict", "(", "X_test", ")", ")", "\n", "#score = classifier.score(X_test, y_test.ravel())", "\n", "", "runtime", "=", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", "\n", "\n", "scores", ".", "append", "(", "score", ")", "\n", "runtimes", ".", "append", "(", "runtime", ")", "\n", "\n", "logging", ".", "info", "(", "\"--- Score: %s \"", "%", "score", ")", "\n", "logging", ".", "info", "(", "\"--- Runtime: %s for seconds ---\"", "%", "runtime", ")", "\n", "\n", "", "export_dict", "(", "models", ",", "scores", ",", "runtimes", ",", "first_row", "=", "(", "'Model'", ",", "'Score'", ",", "'Runtime'", ")", ",", "file_name", "=", "'results.csv'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearndummy.export_dict": [[74, 82], ["zip", "open", "csv.writer", "csv.writer.writerow", "csv.writer.writerow"], "function", ["None"], ["", "def", "export_dict", "(", "*", "columns", ",", "first_row", ",", "file_name", ")", ":", "\n", "    ", "rows", "=", "zip", "(", "*", "columns", ")", "\n", "file", "=", "config", "[", "'model_dir'", "]", "+", "'/'", "+", "file_name", "\n", "with", "open", "(", "file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "first_row", ")", "\n", "for", "row", "in", "rows", ":", "\n", "            ", "writer", ".", "writerow", "(", "row", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnclassifier.cross_validate": [[48, 69], ["logging.info", "numpy.zeros", "sklearn.model_selection.PredefinedSplit", "sklearn.model_selection.GridSearchCV", "sklearn.model_selection.GridSearchCV.fit", "sklearnclassifier.export_dict", "sklearnclassifier.export_dict", "y.ravel"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.export_dict", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.export_dict"], ["def", "cross_validate", "(", "model_name", ",", "X", ",", "y", ",", "train", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"Cross-validation \"", "+", "model_name", "+", "\"...\"", ")", "\n", "classifier", "=", "val_models", "[", "model_name", "]", "\n", "parameters", "=", "params", "[", "model_name", "]", "\n", "\n", "# -1 for the training set, 0 for the validation set", "\n", "fold_arr", "=", "np", ".", "zeros", "(", "train", ".", "shape", ")", "\n", "fold_arr", "[", "train", "]", "=", "-", "1", "\n", "ps", "=", "PredefinedSplit", "(", "test_fold", "=", "fold_arr", ")", "\n", "\n", "clf", "=", "GridSearchCV", "(", "classifier", ",", "parameters", ",", "scoring", "=", "'accuracy'", ",", "verbose", "=", "3", ",", "cv", "=", "ps", ")", "\n", "clf", ".", "fit", "(", "X", ",", "y", ".", "ravel", "(", ")", ")", "\n", "\n", "export_dict", "(", "clf", ".", "cv_results_", "[", "'mean_fit_time'", "]", ",", "clf", ".", "cv_results_", "[", "'std_fit_time'", "]", ",", "clf", ".", "cv_results_", "[", "'mean_score_time'", "]", ",", "\n", "clf", ".", "cv_results_", "[", "'std_score_time'", "]", ",", "clf", ".", "cv_results_", "[", "'mean_test_score'", "]", ",", "clf", ".", "cv_results_", "[", "'std_test_score'", "]", ",", "clf", ".", "cv_results_", "[", "'params'", "]", ",", "file_name", "=", "model_name", "+", "'_CrossValidation_results.csv'", ",", "\n", "first_row", "=", "(", "'mean_fit_time'", ",", "'std_fit_time'", ",", "'mean_score_time'", ",", "'std_score_time'", ",", "\n", "'mean_test_score'", ",", "'std_test_score'", ",", "'params'", ")", ")", "\n", "\n", "best_columns", "=", "(", "'BEST ESTIMATOR'", ",", "'BEST SCORE'", ",", "'BEST PARAMS'", ")", "\n", "export_dict", "(", "[", "clf", ".", "best_estimator_", "]", ",", "[", "clf", ".", "best_score_", "]", ",", "[", "clf", ".", "best_params_", "]", ",", "file_name", "=", "model_name", "+", "'_best_results.csv'", ",", "first_row", "=", "best_columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnclassifier.validate_classifiers": [[70, 85], ["sklearnclassifier.cross_validate", "sklearnclassifier.cross_validate", "sklearnclassifier.cross_validate", "sklearnclassifier.cross_validate", "sklearnclassifier.cross_validate", "sklearnclassifier.cross_validate", "sklearnclassifier.cross_validate", "sklearnclassifier.cross_validate", "sklearnclassifier.cross_validate", "logging.info", "sklearn.preprocessing.StandardScaler", "sklearn.preprocessing.StandardScaler.fit", "sklearn.preprocessing.StandardScaler.transform"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit"], ["", "def", "validate_classifiers", "(", "X", ",", "y", ",", "train", ",", "scale", "=", "False", ")", ":", "\n", "    ", "if", "(", "scale", ")", ":", "\n", "        ", "logging", ".", "info", "(", "'Standard Scaling'", ")", "\n", "scaler", "=", "StandardScaler", "(", ")", "\n", "scaler", ".", "fit", "(", "X", "[", "train", "]", ")", "\n", "X", "=", "scaler", ".", "transform", "(", "X", ")", "\n", "", "cross_validate", "(", "'KNN'", ",", "X", ",", "y", ",", "train", ")", "\n", "cross_validate", "(", "'GaussianNB'", ",", "X", ",", "y", ",", "train", ")", "\n", "cross_validate", "(", "'LinearSVC'", ",", "X", ",", "y", ",", "train", ")", "\n", "cross_validate", "(", "'RBF_SVC'", ",", "X", ",", "y", ",", "train", ")", "\n", "cross_validate", "(", "'DTC'", ",", "X", ",", "y", ",", "train", ")", "\n", "cross_validate", "(", "'RFC'", ",", "X", ",", "y", ",", "train", ")", "\n", "cross_validate", "(", "'GBC'", ",", "X", ",", "y", ",", "train", ")", "\n", "cross_validate", "(", "'ABC'", ",", "X", ",", "y", ",", "train", ")", "\n", "cross_validate", "(", "'XGB'", ",", "X", ",", "y", ",", "train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnclassifier.export_dict": [[86, 94], ["zip", "open", "csv.writer", "csv.writer.writerow", "csv.writer.writerow"], "function", ["None"], ["", "def", "export_dict", "(", "*", "columns", ",", "first_row", ",", "file_name", ")", ":", "\n", "    ", "rows", "=", "zip", "(", "*", "columns", ")", "\n", "file", "=", "config", "[", "'model_dir'", "]", "+", "'/'", "+", "file_name", "\n", "with", "open", "(", "file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "first_row", ")", "\n", "for", "row", "in", "rows", ":", "\n", "            ", "writer", ".", "writerow", "(", "row", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate": [[52, 73], ["logging.info", "numpy.zeros", "sklearn.model_selection.PredefinedSplit", "sklearn.model_selection.GridSearchCV", "sklearn.model_selection.GridSearchCV.fit", "sklearnregressor.export_dict", "sklearnregressor.export_dict", "y.ravel"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.export_dict", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.export_dict"], ["def", "cross_validate", "(", "model_name", ",", "X", ",", "y", ",", "train", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"Cross-validation \"", "+", "model_name", "+", "\"...\"", ")", "\n", "classifier", "=", "val_models", "[", "model_name", "]", "\n", "parameters", "=", "params", "[", "model_name", "]", "\n", "\n", "# -1 for the train set, 0 for the validation set", "\n", "fold_arr", "=", "np", ".", "zeros", "(", "train", ".", "shape", ")", "\n", "fold_arr", "[", "train", "]", "=", "-", "1", "\n", "ps", "=", "PredefinedSplit", "(", "test_fold", "=", "fold_arr", ")", "\n", "\n", "clf", "=", "GridSearchCV", "(", "classifier", ",", "parameters", ",", "verbose", "=", "3", ",", "cv", "=", "ps", ")", "\n", "clf", ".", "fit", "(", "X", ",", "y", ".", "ravel", "(", ")", ")", "\n", "\n", "export_dict", "(", "clf", ".", "cv_results_", "[", "'mean_fit_time'", "]", ",", "clf", ".", "cv_results_", "[", "'std_fit_time'", "]", ",", "clf", ".", "cv_results_", "[", "'mean_score_time'", "]", ",", "\n", "clf", ".", "cv_results_", "[", "'std_score_time'", "]", ",", "clf", ".", "cv_results_", "[", "'mean_test_score'", "]", ",", "clf", ".", "cv_results_", "[", "'std_test_score'", "]", ",", "clf", ".", "cv_results_", "[", "'params'", "]", ",", "file_name", "=", "model_name", "+", "'_CrossValidation_results.csv'", ",", "\n", "first_row", "=", "(", "'mean_fit_time'", ",", "'std_fit_time'", ",", "'mean_score_time'", ",", "'std_score_time'", ",", "\n", "'mean_test_score'", ",", "'std_test_score'", ",", "'params'", ")", ")", "\n", "\n", "best_columns", "=", "(", "'BEST ESTIMATOR'", ",", "'BEST SCORE'", ",", "'BEST PARAMS'", ")", "\n", "export_dict", "(", "[", "clf", ".", "best_estimator_", "]", ",", "[", "clf", ".", "best_score_", "]", ",", "[", "clf", ".", "best_params_", "]", ",", "file_name", "=", "model_name", "+", "'_best_results.csv'", ",", "first_row", "=", "best_columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.validate_regressors": [[74, 91], ["sklearnregressor.cross_validate", "sklearnregressor.cross_validate", "sklearnregressor.cross_validate", "sklearnregressor.cross_validate", "sklearnregressor.cross_validate", "sklearnregressor.cross_validate", "sklearnregressor.cross_validate", "sklearnregressor.cross_validate", "sklearnregressor.cross_validate", "sklearnregressor.cross_validate", "logging.info", "sklearn.preprocessing.StandardScaler", "sklearn.preprocessing.StandardScaler.fit", "sklearn.preprocessing.StandardScaler.transform"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.cross_validate", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit"], ["", "def", "validate_regressors", "(", "X", ",", "y", ",", "train", ",", "scale", "=", "False", ")", ":", "\n", "    ", "if", "(", "scale", ")", ":", "\n", "        ", "logging", ".", "info", "(", "'Standard Scaling'", ")", "\n", "scaler", "=", "StandardScaler", "(", ")", "\n", "scaler", ".", "fit", "(", "X", "[", "train", "]", ")", "\n", "X", "=", "scaler", ".", "transform", "(", "X", ")", "\n", "", "cross_validate", "(", "\"KNN\"", ",", "X", ",", "y", ",", "train", ")", "\n", "cross_validate", "(", "\"LinearReg\"", ",", "X", ",", "y", ",", "train", ")", "\n", "cross_validate", "(", "\"Ridge\"", ",", "X", ",", "y", ",", "train", ")", "\n", "cross_validate", "(", "\"Lasso\"", ",", "X", ",", "y", ",", "train", ")", "\n", "cross_validate", "(", "\"ElasticNet\"", ",", "X", ",", "y", ",", "train", ")", "\n", "cross_validate", "(", "\"RBF_SVR\"", ",", "X", ",", "y", ",", "train", ")", "\n", "#cross_validate(\"DTR\", X, y, train)", "\n", "cross_validate", "(", "\"RFR\"", ",", "X", ",", "y", ",", "train", ")", "\n", "cross_validate", "(", "\"GBR\"", ",", "X", ",", "y", ",", "train", ")", "\n", "cross_validate", "(", "\"ABR\"", ",", "X", ",", "y", ",", "train", ")", "\n", "cross_validate", "(", "\"XGB\"", ",", "X", ",", "y", ",", "train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.export_dict": [[92, 100], ["zip", "open", "csv.writer", "csv.writer.writerow", "csv.writer.writerow"], "function", ["None"], ["", "def", "export_dict", "(", "*", "columns", ",", "first_row", ",", "file_name", ")", ":", "\n", "    ", "rows", "=", "zip", "(", "*", "columns", ")", "\n", "file", "=", "config", "[", "'model_dir'", "]", "+", "'/'", "+", "file_name", "\n", "with", "open", "(", "file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "first_row", ")", "\n", "for", "row", "in", "rows", ":", "\n", "            ", "writer", ".", "writerow", "(", "row", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.ml_utils.split": [[12, 27], ["numpy.unique", "len", "math.ceil", "math.ceil", "numpy.isin", "numpy.isin", "numpy.isin"], "function", ["None"], ["def", "split", "(", "trainY", ",", "train", ",", "val", ",", "test", ")", ":", "\n", "    ", "assert", "(", "train", "+", "val", "+", "test", "==", "1", ")", "\n", "IDs", "=", "np", ".", "unique", "(", "trainY", "[", ":", ",", "0", "]", ")", "\n", "num_ids", "=", "len", "(", "IDs", ")", "\n", "\n", "# priority given to the test/val sets", "\n", "test_split", "=", "math", ".", "ceil", "(", "test", "*", "num_ids", ")", "\n", "val_split", "=", "math", ".", "ceil", "(", "val", "*", "num_ids", ")", "\n", "train_split", "=", "num_ids", "-", "val_split", "-", "test_split", "\n", "\n", "train", "=", "np", ".", "isin", "(", "trainY", "[", ":", ",", "0", "]", ",", "IDs", "[", ":", "train_split", "]", ")", "\n", "val", "=", "np", ".", "isin", "(", "trainY", "[", ":", ",", "0", "]", ",", "IDs", "[", "train_split", ":", "train_split", "+", "val_split", "]", ")", "\n", "test", "=", "np", ".", "isin", "(", "trainY", "[", ":", ",", "0", "]", ",", "IDs", "[", "train_split", "+", "val_split", ":", "]", ")", "\n", "\n", "return", "train", ",", "val", ",", "test", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.ml_utils.crossvalidate_models": [[28, 41], ["logging.info", "ml_utils.split", "trainX.reshape.reshape", "Victor_files.sklearnclassifier.validate_classifiers", "Victor_files.sklearnregressor.validate_regressors"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.ml_utils.split", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnclassifier.validate_classifiers", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.sklearnregressor.validate_regressors"], ["", "def", "crossvalidate_models", "(", "trainX", ",", "trainY", ",", "train", ",", "val", ",", "test", ",", "scale", "=", "False", ")", ":", "\n", "    ", "logging", ".", "info", "(", "'ML - '", "+", "config", "[", "'ml'", "]", ")", "\n", "train", ",", "val", ",", "test", "=", "split", "(", "trainY", ",", "train", ",", "val", ",", "test", ")", "\n", "trainX", "=", "trainX", ".", "reshape", "(", "(", "-", "1", ",", "258", ")", ")", "\n", "X", "=", "trainX", "[", "train", "|", "val", "]", "\n", "lab", "=", "config", "[", "'label'", "]", "\n", "y", "=", "trainY", "[", ":", ",", "lab", "]", "[", "train", "|", "val", "]", "\n", "t", "=", "train", "[", "train", "|", "val", "]", "# reduce the length of train array", "\n", "\n", "if", "config", "[", "'ml'", "]", "==", "'c'", ":", "\n", "        ", "validate_classifiers", "(", "X", ",", "y", ",", "t", ",", "scale", "=", "scale", ")", "\n", "", "elif", "config", "[", "'ml'", "]", "==", "'r'", ":", "\n", "        ", "validate_regressors", "(", "X", ",", "y", ",", "t", ",", "scale", "=", "scale", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.StandardML_Models.StandardClassifier_1D.StandardClassifier_1D.__init__": [[4, 38], ["KNeighborsClassifier", "GaussianNB", "LinearSVC", "SVC", "DecisionTreeClassifier", "RandomForestClassifier", "GradientBoostingClassifier", "AdaBoostClassifier", "XGBClassifier", "DummyClassifier"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model_name", ",", "**", "model_params", ")", ":", "\n", "        ", "self", ".", "model_name", "=", "model_name", "\n", "self", ".", "model", "=", "None", "\n", "if", "self", ".", "model_name", "==", "'KNN'", ":", "\n", "            ", "from", "sklearn", ".", "neighbors", "import", "KNeighborsClassifier", "\n", "self", ".", "model", "=", "KNeighborsClassifier", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'GaussianNB'", ":", "\n", "            ", "from", "sklearn", ".", "naive_bayes", "import", "GaussianNB", "\n", "self", ".", "model", "=", "GaussianNB", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'LinearSVC'", ":", "\n", "            ", "from", "sklearn", ".", "svm", "import", "LinearSVC", "\n", "self", ".", "model", "=", "LinearSVC", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'RBF SVC'", ":", "\n", "            ", "from", "sklearn", ".", "svm", "import", "SVC", "\n", "self", ".", "model", "=", "SVC", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'DecisionTree'", ":", "\n", "            ", "from", "sklearn", ".", "tree", "import", "DecisionTreeClassifier", "\n", "self", ".", "model", "=", "DecisionTreeClassifier", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'RandomForest'", ":", "\n", "            ", "from", "sklearn", ".", "ensemble", "import", "RandomForestClassifier", "\n", "self", ".", "model", "=", "RandomForestClassifier", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'GradientBoost'", ":", "\n", "            ", "from", "sklearn", ".", "ensemble", "import", "GradientBoostingClassifier", "\n", "self", ".", "model", "=", "GradientBoostingClassifier", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'AdaBoost'", ":", "\n", "            ", "from", "sklearn", ".", "ensemble", "import", "AdaBoostClassifier", "\n", "self", ".", "model", "=", "AdaBoostClassifier", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'XGBoost'", ":", "\n", "            ", "from", "xgboost", "import", "XGBClassifier", "\n", "self", ".", "model", "=", "XGBClassifier", "(", "**", "model_params", ")", "\n", "", "elif", "(", "self", ".", "model_name", "==", "'Stratified'", "or", "self", ".", "model_name", "==", "'MostFrequent'", "or", "\n", "self", ".", "model_name", "==", "'Prior'", "or", "self", ".", "model_name", "==", "'Uniform'", ")", ":", "\n", "            ", "from", "sklearn", ".", "dummy", "import", "DummyClassifier", "\n", "self", ".", "model", "=", "DummyClassifier", "(", "**", "model_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.StandardML_Models.StandardClassifier_1D.StandardClassifier_1D.fit": [[39, 43], ["trainX.reshape.reshape.reshape", "print", "StandardClassifier_1D.StandardClassifier_1D.model.fit", "trainY.ravel"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit"], ["", "", "def", "fit", "(", "self", ",", "trainX", ",", "trainY", ",", "validX", ",", "validY", ")", ":", "\n", "        ", "trainX", "=", "trainX", ".", "reshape", "(", "(", "-", "1", ",", "258", ")", ")", "# TODO: A hack for now", "\n", "print", "(", "self", ".", "model", ")", "\n", "self", ".", "model", ".", "fit", "(", "trainX", ",", "trainY", ".", "ravel", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.StandardML_Models.StandardClassifier_1D.StandardClassifier_1D.predict": [[44, 47], ["testX.reshape.reshape.reshape", "StandardClassifier_1D.StandardClassifier_1D.model.predict"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.predict"], ["", "def", "predict", "(", "self", ",", "testX", ")", ":", "\n", "        ", "testX", "=", "testX", ".", "reshape", "(", "(", "-", "1", ",", "258", ")", ")", "# TODO: A hack for now", "\n", "return", "self", ".", "model", ".", "predict", "(", "testX", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.StandardML_Models.StandardClassifier_1D.StandardClassifier_1D.save": [[48, 53], ["pickle.dump", "open"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "path", ")", ":", "\n", "# save the model to disk", "\n", "        ", "import", "pickle", "\n", "filename", "=", "path", "+", "self", ".", "model_name", "+", "'.sav'", "\n", "pickle", ".", "dump", "(", "self", ".", "model", ",", "open", "(", "filename", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.StandardML_Models.StandardClassifier_1D.StandardClassifier_1D.load": [[54, 60], ["pickle.load", "open"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.load"], ["", "def", "load", "(", "self", ",", "path", ")", ":", "\n", "# Test", "\n", "# load the model from disk", "\n", "        ", "import", "pickle", "\n", "filename", "=", "path", "+", "self", ".", "model_name", "+", "'.sav'", "\n", "self", ".", "model", "=", "pickle", ".", "load", "(", "open", "(", "filename", ",", "'rb'", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.StandardML_Models.StandardRegressor_1D.StandardRegressor_1D.__init__": [[4, 43], ["KNeighborsRegressor", "LinearRegression", "Ridge", "Lasso", "ElasticNet", "SVR", "DecisionTreeRegressor", "RandomForestRegressor", "GradientBoostingRegressor", "AdaBoostRegressor", "XGBRegressor", "DummyRegressor"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model_name", ",", "**", "model_params", ")", ":", "\n", "        ", "self", ".", "model_name", "=", "model_name", "\n", "self", ".", "model", "=", "None", "\n", "if", "self", ".", "model_name", "==", "'KNN'", ":", "\n", "            ", "from", "sklearn", ".", "neighbors", "import", "KNeighborsRegressor", "\n", "self", ".", "model", "=", "KNeighborsRegressor", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'LinearReg'", ":", "\n", "            ", "from", "sklearn", ".", "linear_model", "import", "LinearRegression", "\n", "self", ".", "model", "=", "LinearRegression", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'Ridge'", ":", "\n", "            ", "from", "sklearn", ".", "linear_model", "import", "Ridge", "\n", "self", ".", "model", "=", "Ridge", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'Lasso'", ":", "\n", "            ", "from", "sklearn", ".", "linear_model", "import", "Lasso", "\n", "self", ".", "model", "=", "Lasso", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'ElasticNet'", ":", "\n", "            ", "from", "sklearn", ".", "linear_model", "import", "ElasticNet", "\n", "self", ".", "model", "=", "ElasticNet", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'RBF SVR'", ":", "\n", "            ", "from", "sklearn", ".", "svm", "import", "SVR", "\n", "self", ".", "model", "=", "SVR", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'DecisionTree'", ":", "\n", "            ", "from", "sklearn", ".", "tree", "import", "DecisionTreeRegressor", "\n", "self", ".", "model", "=", "DecisionTreeRegressor", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'RandomForest'", ":", "\n", "            ", "from", "sklearn", ".", "ensemble", "import", "RandomForestRegressor", "\n", "self", ".", "model", "=", "RandomForestRegressor", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'GradientBoost'", ":", "\n", "            ", "from", "sklearn", ".", "ensemble", "import", "GradientBoostingRegressor", "\n", "self", ".", "model", "=", "GradientBoostingRegressor", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'AdaBoost'", ":", "\n", "            ", "from", "sklearn", ".", "ensemble", "import", "AdaBoostRegressor", "\n", "self", ".", "model", "=", "AdaBoostRegressor", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'XGBoost'", ":", "\n", "            ", "from", "xgboost", "import", "XGBRegressor", "\n", "self", ".", "model", "=", "XGBRegressor", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'Mean'", "or", "self", ".", "model_name", "==", "'Median'", ":", "\n", "            ", "from", "sklearn", ".", "dummy", "import", "DummyRegressor", "\n", "self", ".", "model", "=", "DummyRegressor", "(", "**", "model_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.StandardML_Models.StandardRegressor_1D.StandardRegressor_1D.fit": [[44, 47], ["trainX.reshape.reshape.reshape", "StandardRegressor_1D.StandardRegressor_1D.model.fit", "trainY.ravel"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit"], ["", "", "def", "fit", "(", "self", ",", "trainX", ",", "trainY", ",", "validX", ",", "validY", ")", ":", "\n", "        ", "trainX", "=", "trainX", ".", "reshape", "(", "(", "-", "1", ",", "258", ")", ")", "# TODO: A hack for now", "\n", "self", ".", "model", ".", "fit", "(", "trainX", ",", "trainY", ".", "ravel", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.StandardML_Models.StandardRegressor_1D.StandardRegressor_1D.predict": [[48, 51], ["testX.reshape.reshape.reshape", "StandardRegressor_1D.StandardRegressor_1D.model.predict"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.predict"], ["", "def", "predict", "(", "self", ",", "testX", ")", ":", "\n", "        ", "testX", "=", "testX", ".", "reshape", "(", "(", "-", "1", ",", "258", ")", ")", "# TODO: A hack for now", "\n", "return", "self", ".", "model", ".", "predict", "(", "testX", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.StandardML_Models.StandardRegressor_1D.StandardRegressor_1D.save": [[52, 57], ["pickle.dump", "open"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "path", ")", ":", "\n", "# save the model to disk", "\n", "        ", "import", "pickle", "\n", "filename", "=", "path", "+", "self", ".", "model_name", "+", "'.sav'", "\n", "pickle", ".", "dump", "(", "self", ".", "model", ",", "open", "(", "filename", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.StandardML_Models.StandardRegressor_1D.StandardRegressor_1D.load": [[58, 64], ["pickle.load", "open"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.load"], ["", "def", "load", "(", "self", ",", "path", ")", ":", "\n", "# Test", "\n", "# load the model from disk", "\n", "        ", "import", "pickle", "\n", "filename", "=", "path", "+", "self", ".", "model_name", "+", "'.sav'", "\n", "self", ".", "model", "=", "pickle", ".", "load", "(", "open", "(", "filename", ",", "'rb'", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.StandardML_Models.StandardRegressor_2D.StandardRegressor_2D.__init__": [[4, 59], ["KNeighborsRegressor", "KNeighborsRegressor", "LinearRegression", "LinearRegression", "Ridge", "Ridge", "Lasso", "Lasso", "ElasticNet", "ElasticNet", "SVR", "SVR", "DecisionTreeRegressor", "DecisionTreeRegressor", "RandomForestRegressor", "RandomForestRegressor", "GradientBoostingRegressor", "GradientBoostingRegressor", "AdaBoostRegressor", "AdaBoostRegressor", "XGBRegressor", "XGBRegressor", "DummyRegressor", "DummyRegressor", "DummyRegressor", "DummyRegressor"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model_name", ",", "**", "model_params", ")", ":", "\n", "        ", "self", ".", "model_name", "=", "model_name", "\n", "self", ".", "model", "=", "None", "\n", "if", "self", ".", "model_name", "==", "'KNN'", ":", "\n", "            ", "from", "sklearn", ".", "neighbors", "import", "KNeighborsRegressor", "\n", "self", ".", "model1", "=", "KNeighborsRegressor", "(", "**", "model_params", ")", "\n", "self", ".", "model2", "=", "KNeighborsRegressor", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'LinearReg'", ":", "\n", "            ", "from", "sklearn", ".", "linear_model", "import", "LinearRegression", "\n", "self", ".", "model1", "=", "LinearRegression", "(", "**", "model_params", ")", "\n", "self", ".", "model2", "=", "LinearRegression", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'Ridge'", ":", "\n", "            ", "from", "sklearn", ".", "linear_model", "import", "Ridge", "\n", "self", ".", "model1", "=", "Ridge", "(", "**", "model_params", ")", "\n", "self", ".", "model2", "=", "Ridge", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'Lasso'", ":", "\n", "            ", "from", "sklearn", ".", "linear_model", "import", "Lasso", "\n", "self", ".", "model1", "=", "Lasso", "(", "**", "model_params", ")", "\n", "self", ".", "model2", "=", "Lasso", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'ElasticNet'", ":", "\n", "            ", "from", "sklearn", ".", "linear_model", "import", "ElasticNet", "\n", "self", ".", "model1", "=", "ElasticNet", "(", "**", "model_params", ")", "\n", "self", ".", "model2", "=", "ElasticNet", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'RBF SVR'", ":", "\n", "            ", "from", "sklearn", ".", "svm", "import", "SVR", "\n", "self", ".", "model1", "=", "SVR", "(", "**", "model_params", ")", "\n", "self", ".", "model2", "=", "SVR", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'DecisionTree'", ":", "\n", "            ", "from", "sklearn", ".", "tree", "import", "DecisionTreeRegressor", "\n", "self", ".", "model1", "=", "DecisionTreeRegressor", "(", "**", "model_params", ")", "\n", "self", ".", "model2", "=", "DecisionTreeRegressor", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'RandomForest'", ":", "\n", "            ", "from", "sklearn", ".", "ensemble", "import", "RandomForestRegressor", "\n", "self", ".", "model1", "=", "RandomForestRegressor", "(", "**", "model_params", ")", "\n", "self", ".", "model2", "=", "RandomForestRegressor", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'GradientBoost'", ":", "\n", "            ", "from", "sklearn", ".", "ensemble", "import", "GradientBoostingRegressor", "\n", "self", ".", "model1", "=", "GradientBoostingRegressor", "(", "**", "model_params", ")", "\n", "self", ".", "model2", "=", "GradientBoostingRegressor", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'AdaBoost'", ":", "\n", "            ", "from", "sklearn", ".", "ensemble", "import", "AdaBoostRegressor", "\n", "self", ".", "model1", "=", "AdaBoostRegressor", "(", "**", "model_params", ")", "\n", "self", ".", "model2", "=", "AdaBoostRegressor", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'XGBoost'", ":", "\n", "            ", "from", "xgboost", "import", "XGBRegressor", "\n", "self", ".", "model1", "=", "XGBRegressor", "(", "**", "model_params", ")", "\n", "self", ".", "model2", "=", "XGBRegressor", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'Mean'", "or", "self", ".", "model_name", "==", "'Median'", ":", "\n", "            ", "from", "sklearn", ".", "dummy", "import", "DummyRegressor", "\n", "self", ".", "model1", "=", "DummyRegressor", "(", "**", "model_params", ")", "\n", "self", ".", "model2", "=", "DummyRegressor", "(", "**", "model_params", ")", "\n", "", "elif", "self", ".", "model_name", "==", "'Constant'", ":", "\n", "            ", "from", "sklearn", ".", "dummy", "import", "DummyRegressor", "\n", "self", ".", "model1", "=", "DummyRegressor", "(", "**", "model_params", ",", "constant", "=", "400", ")", "\n", "self", ".", "model2", "=", "DummyRegressor", "(", "**", "model_params", ",", "constant", "=", "300", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.StandardML_Models.StandardRegressor_2D.StandardRegressor_2D.fit": [[60, 64], ["trainX.reshape.reshape.reshape", "StandardRegressor_2D.StandardRegressor_2D.model1.fit", "StandardRegressor_2D.StandardRegressor_2D.model2.fit", "trainY[].ravel", "trainY[].ravel"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit"], ["", "", "def", "fit", "(", "self", ",", "trainX", ",", "trainY", ",", "validX", ",", "validY", ")", ":", "\n", "        ", "trainX", "=", "trainX", ".", "reshape", "(", "(", "-", "1", ",", "258", ")", ")", "# TODO: A hack for now", "\n", "self", ".", "model1", ".", "fit", "(", "trainX", ",", "trainY", "[", ":", ",", "0", "]", ".", "ravel", "(", ")", ")", "\n", "self", ".", "model2", ".", "fit", "(", "trainX", ",", "trainY", "[", ":", ",", "1", "]", ".", "ravel", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.StandardML_Models.StandardRegressor_2D.StandardRegressor_2D.predict": [[65, 71], ["testX.reshape.reshape.reshape", "StandardRegressor_2D.StandardRegressor_2D.model1.predict", "StandardRegressor_2D.StandardRegressor_2D.model2.predict", "np.column_stack"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.predict", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.predict"], ["", "def", "predict", "(", "self", ",", "testX", ")", ":", "\n", "        ", "testX", "=", "testX", ".", "reshape", "(", "(", "-", "1", ",", "258", ")", ")", "# TODO: A hack for now", "\n", "predict1", "=", "self", ".", "model1", ".", "predict", "(", "testX", ")", "\n", "predict2", "=", "self", ".", "model2", ".", "predict", "(", "testX", ")", "\n", "import", "numpy", "as", "np", "\n", "return", "np", ".", "column_stack", "(", "(", "predict1", ",", "predict2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.StandardML_Models.StandardRegressor_2D.StandardRegressor_2D.save": [[72, 79], ["pickle.dump", "pickle.dump", "open", "open"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "path", ")", ":", "\n", "# save the model to disk", "\n", "        ", "import", "pickle", "\n", "filename1", "=", "path", "+", "self", ".", "model_name", "+", "'_X.sav'", "\n", "pickle", ".", "dump", "(", "self", ".", "model1", ",", "open", "(", "filename1", ",", "'wb'", ")", ")", "\n", "filename2", "=", "path", "+", "self", ".", "model_name", "+", "'_Y.sav'", "\n", "pickle", ".", "dump", "(", "self", ".", "model2", ",", "open", "(", "filename2", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.StandardML_Models.StandardRegressor_2D.StandardRegressor_2D.load": [[80, 88], ["pickle.load", "pickle.load", "open", "open"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.load", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.load"], ["", "def", "load", "(", "self", ",", "path", ")", ":", "\n", "# Test", "\n", "# load the model from disk", "\n", "        ", "import", "pickle", "\n", "filename1", "=", "path", "+", "self", ".", "model_name", "+", "'_X.sav'", "\n", "self", ".", "model1", "=", "pickle", ".", "load", "(", "open", "(", "filename1", ",", "'rb'", ")", ")", "\n", "filename2", "=", "path", "+", "self", ".", "model_name", "+", "'_Y.sav'", "\n", "self", ".", "model2", "=", "pickle", ".", "load", "(", "open", "(", "filename2", ",", "'rb'", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.DL_Models.Ensemble.Ensemble.__init__": [[8, 23], ["Ensemble_tf", "Ensemble_torch", "ValueError"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model_name", ",", "nb_models", ",", "loss", ",", "batch_size", "=", "64", ",", "**", "model_params", ")", ":", "\n", "        ", "\"\"\"\n\n        :type model_params: dic\n        \"\"\"", "\n", "self", ".", "type", "=", "'classifier'", "if", "loss", "==", "'bce'", "else", "'regressor'", "\n", "# create the ensemble ", "\n", "if", "config", "[", "'framework'", "]", "==", "'tensorflow'", ":", "\n", "            ", "from", "DL_Models", ".", "tf_models", ".", "Ensemble_tf", "import", "Ensemble_tf", "\n", "self", ".", "ensemble", "=", "Ensemble_tf", "(", "model_name", "=", "model_name", ",", "nb_models", "=", "nb_models", ",", "loss", "=", "loss", ",", "batch_size", "=", "batch_size", ",", "**", "model_params", ")", "\n", "", "elif", "config", "[", "'framework'", "]", "==", "'pytorch'", ":", "\n", "            ", "from", "DL_Models", ".", "torch_models", ".", "Ensemble_torch", "import", "Ensemble_torch", "\n", "self", ".", "ensemble", "=", "Ensemble_torch", "(", "model_name", "=", "model_name", ",", "nb_models", "=", "nb_models", ",", "loss", "=", "loss", ",", "batch_size", "=", "batch_size", ",", "**", "model_params", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Choose a valid deep learning framework\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.DL_Models.Ensemble.Ensemble.fit": [[24, 26], ["Ensemble.Ensemble.ensemble.fit"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit"], ["", "", "def", "fit", "(", "self", ",", "trainX", ",", "trainY", ",", "validX", ",", "validY", ")", ":", "\n", "        ", "self", ".", "ensemble", ".", "fit", "(", "trainX", ",", "trainY", ",", "validX", ",", "validY", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.DL_Models.Ensemble.Ensemble.predict": [[27, 32], ["numpy.round", "Ensemble.Ensemble.ensemble.predict", "Ensemble.Ensemble.ensemble.predict"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.predict", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.predict"], ["", "def", "predict", "(", "self", ",", "testX", ")", ":", "\n", "        ", "if", "self", ".", "type", "==", "'classifier'", ":", "\n", "            ", "return", "np", ".", "round", "(", "self", ".", "ensemble", ".", "predict", "(", "testX", ")", ")", "#TODO: Hack", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "ensemble", ".", "predict", "(", "testX", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.DL_Models.Ensemble.Ensemble.save": [[33, 35], ["Ensemble.Ensemble.ensemble.save"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.save"], ["", "", "def", "save", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "ensemble", ".", "save", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.DL_Models.Ensemble.Ensemble.load": [[36, 38], ["Ensemble.Ensemble.ensemble.load"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.load"], ["", "def", "load", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "ensemble", ".", "load", "(", "path", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Modules.Pad_Pool.__init__": [[9, 14], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__"], ["def", "__init__", "(", "self", ",", "left", "=", "0", ",", "right", "=", "1", ",", "value", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "left", "=", "left", "\n", "self", ".", "right", "=", "right", "\n", "self", ".", "value", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Modules.Pad_Pool.forward": [[15, 17], ["torch.ConstantPad1d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "nn", ".", "ConstantPad1d", "(", "padding", "=", "(", "self", ".", "left", ",", "self", ".", "right", ")", ",", "value", "=", "self", ".", "value", ")", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Modules.Pad_Pool2d.__init__": [[23, 30], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__"], ["def", "__init__", "(", "self", ",", "left", "=", "0", ",", "right", "=", "1", ",", "top", "=", "0", ",", "bottom", "=", "1", ",", "value", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "left", "=", "left", "\n", "self", ".", "right", "=", "right", "\n", "self", ".", "top", "=", "top", "\n", "self", ".", "bottom", "=", "bottom", "\n", "self", ".", "value", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Modules.Pad_Pool2d.forward": [[31, 33], ["torch.ConstantPad2d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "nn", ".", "ConstantPad2d", "(", "padding", "=", "(", "self", ".", "left", ",", "self", ".", "right", ",", "self", ".", "top", ",", "self", ".", "bottom", ")", ",", "value", "=", "self", ".", "value", ")", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Modules.Pad_Conv.__init__": [[39, 44], ["torch.Module.__init__", "max", "max", "math.floor", "math.floor"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__"], ["def", "__init__", "(", "self", ",", "kernel_size", ",", "value", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "value", "=", "value", "\n", "self", ".", "left", "=", "max", "(", "math", ".", "floor", "(", "kernel_size", "/", "2", ")", "-", "1", ",", "0", ")", "\n", "self", ".", "right", "=", "max", "(", "math", ".", "floor", "(", "kernel_size", "/", "2", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Modules.Pad_Conv.forward": [[45, 47], ["torch.ConstantPad1d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "nn", ".", "ConstantPad1d", "(", "padding", "=", "(", "self", ".", "left", ",", "self", ".", "right", ")", ",", "value", "=", "self", ".", "value", ")", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Modules.Pad_Conv2d.__init__": [[57, 65], ["torch.Module.__init__", "max", "max", "max", "max", "math.floor", "math.floor", "math.floor", "math.floor"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__"], ["def", "__init__", "(", "self", ",", "kernel", ",", "value", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "kernel_x", ",", "kernel_y", "=", "kernel", "\n", "self", ".", "value", "=", "value", "\n", "self", ".", "left", "=", "max", "(", "math", ".", "floor", "(", "kernel_y", "/", "2", ")", "-", "1", ",", "0", ")", "\n", "self", ".", "right", "=", "max", "(", "math", ".", "floor", "(", "kernel_y", "/", "2", ")", ",", "0", ")", "\n", "self", ".", "top", "=", "max", "(", "math", ".", "floor", "(", "kernel_x", "/", "2", ")", "-", "1", ",", "0", ")", "\n", "self", ".", "bottom", "=", "max", "(", "math", ".", "floor", "(", "kernel_x", "/", "2", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Modules.Pad_Conv2d.forward": [[66, 68], ["torch.ConstantPad2d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "nn", ".", "ConstantPad2d", "(", "(", "self", ".", "left", ",", "self", ".", "right", ",", "self", ".", "top", ",", "self", ".", "bottom", ")", ",", "self", ".", "value", ")", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Modules.TCSConv1d.__init__": [[74, 87], ["torch.Module.__init__", "Modules.Pad_Conv", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__"], ["def", "__init__", "(", "self", ",", "mother", ",", "depth", ",", "bias", "=", "False", ")", ":", "\n", "        ", "super", "(", "TCSConv1d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pad_depthwise", "=", "Pad_Conv", "(", "mother", ".", "kernel_size", ")", "\n", "# groups=in_channels makes it separable", "\n", "self", ".", "depthwise", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "mother", ".", "nb_channels", "if", "depth", "==", "0", "else", "mother", ".", "nb_features", ",", "\n", "out_channels", "=", "mother", ".", "nb_channels", "if", "depth", "==", "0", "else", "mother", ".", "nb_features", ",", "\n", "groups", "=", "mother", ".", "nb_channels", "if", "depth", "==", "0", "else", "mother", ".", "nb_features", ",", "\n", "kernel_size", "=", "mother", ".", "kernel_size", ",", "\n", "bias", "=", "bias", ")", "\n", "self", ".", "pointwise", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "mother", ".", "nb_channels", "if", "depth", "==", "0", "else", "mother", ".", "nb_features", ",", "\n", "out_channels", "=", "mother", ".", "nb_features", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Modules.TCSConv1d.forward": [[88, 93], ["Modules.TCSConv1d.pad_depthwise", "Modules.TCSConv1d.depthwise", "Modules.TCSConv1d.pointwise"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "pad_depthwise", "(", "x", ")", "\n", "x", "=", "self", ".", "depthwise", "(", "x", ")", "\n", "x", "=", "self", ".", "pointwise", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Modules.SeparableConv2d.__init__": [[99, 111], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ":", "\n", "        ", "super", "(", "SeparableConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "depthwise", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "\n", "in_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "groups", "=", "in_channels", ",", "\n", "bias", "=", "bias", ",", "\n", "padding", "=", "padding", ")", "\n", "self", ".", "pointwise", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Modules.SeparableConv2d.forward": [[112, 116], ["Modules.SeparableConv2d.depthwise", "Modules.SeparableConv2d.pointwise"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "depthwise", "(", "x", ")", "\n", "out", "=", "self", ".", "pointwise", "(", "out", ")", "\n", "return", "out", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.BaseNetTorch.Prediction_history.__init__": [[16, 23], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataloader", ",", "model", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        predhis: a list of lists (one for each epoch) of tensors (one for each batch of length batch_size)\n        \"\"\"", "\n", "self", ".", "dataloader", "=", "dataloader", "\n", "self", ".", "predhis", "=", "[", "]", "\n", "self", ".", "model", "=", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.BaseNetTorch.Prediction_history.on_epoch_end": [[24, 39], ["torch.no_grad", "enumerate", "BaseNetTorch.Prediction_history.predhis.append", "torch.cuda.is_available", "BaseNetTorch.Prediction_history.model", "y_pred.append", "torch.cuda.empty_cache", "x.cuda.cuda.cuda", "y.cuda.cuda.cuda"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "y_pred", "=", "[", "]", "\n", "for", "batch", ",", "(", "x", ",", "y", ")", "in", "enumerate", "(", "self", ".", "dataloader", ")", ":", "\n", "# Move batch to GPU", "\n", "                ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "x", "=", "x", ".", "cuda", "(", ")", "\n", "y", "=", "y", ".", "cuda", "(", ")", "\n", "", "pred", "=", "self", ".", "model", "(", "x", ")", "\n", "y_pred", ".", "append", "(", "pred", ")", "\n", "# Remove batch from GPU ", "\n", "del", "x", "\n", "del", "y", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "self", ".", "predhis", ".", "append", "(", "y_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.BaseNetTorch.BaseNet.__init__": [[44, 82], ["torch.nn.Module.__init__", "torch.nn.BCELoss", "torch.nn.Sequential", "logging.info", "torch.nn.Linear", "torch.nn.Sigmoid", "torch.nn.MSELoss", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Sequential", "ValueError", "BaseNetTorch.BaseNet.get_nb_features_output_layer", "torch.nn.Linear", "BaseNetTorch.BaseNet.get_nb_features_output_layer", "BaseNetTorch.BaseNet.get_nb_features_output_layer"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.eegNet.EEGNet.get_nb_features_output_layer", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.eegNet.EEGNet.get_nb_features_output_layer", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.eegNet.EEGNet.get_nb_features_output_layer"], ["def", "__init__", "(", "self", ",", "loss", ",", "input_shape", ",", "output_shape", ",", "epochs", "=", "50", ",", "verbose", "=", "True", ",", "model_number", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Initialize common variables of models based on BaseNet, e.g. ConvNet or EEGNET \n        Create the common output layer dependent on the task to run \n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_shape", "=", "input_shape", "\n", "self", ".", "epochs", "=", "epochs", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "model_number", "=", "model_number", "\n", "self", ".", "timesamples", "=", "self", ".", "input_shape", "[", "0", "]", "\n", "self", ".", "nb_channels", "=", "self", ".", "input_shape", "[", "1", "]", "\n", "self", ".", "early_stopped", "=", "False", "\n", "self", ".", "loss", "=", "loss", "\n", "\n", "# Create output layer depending on task", "\n", "if", "loss", "==", "'bce'", ":", "\n", "            ", "self", ".", "loss_fn", "=", "nn", ".", "BCELoss", "(", ")", "\n", "self", ".", "output_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_features", "=", "self", ".", "get_nb_features_output_layer", "(", ")", ",", "out_features", "=", "output_shape", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n", "", "elif", "loss", "==", "'mse'", ":", "\n", "            ", "self", ".", "loss_fn", "=", "nn", ".", "MSELoss", "(", ")", "\n", "self", ".", "output_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_features", "=", "self", ".", "get_nb_features_output_layer", "(", ")", ",", "out_features", "=", "output_shape", ")", "\n", ")", "\n", "", "elif", "loss", "==", "'angle-loss'", ":", "\n", "            ", "from", "DL_Models", ".", "torch_models", ".", "torch_utils", ".", "custom_losses", "import", "angle_loss", "\n", "self", ".", "loss_fn", "=", "angle_loss", "\n", "self", ".", "output_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_features", "=", "self", ".", "get_nb_features_output_layer", "(", ")", ",", "out_features", "=", "output_shape", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Choose a valid task\"", ")", "\n", "\n", "", "if", "verbose", "and", "self", ".", "model_number", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "f\"Using loss fct: {self.loss_fn}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.BaseNetTorch.BaseNet.forward": [[84, 90], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Implements a forward pass of the network \n        This method has to be implemented by models based on BaseNet \n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.BaseNetTorch.BaseNet.get_nb_features_output_layer": [[92, 98], ["None"], "methods", ["None"], ["", "def", "get_nb_features_output_layer", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return the number of features that the output layer should take as input\n        This method has to be implemented by models based on BaseNet to compute the number of hidden neurons that the output layer takes as input. \n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.BaseNetTorch.BaseNet._split_model": [[100, 102], ["None"], "methods", ["None"], ["", "def", "_split_model", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.BaseNetTorch.BaseNet.fit": [[105, 155], ["torch.cuda.is_available", "torch.optim.Adam", "range", "BaseNetTorch.BaseNet.cuda", "logging.info", "list", "logging.info", "logging.info", "BaseNetTorch.BaseNet.parameters", "DL_Models.torch_models.torch_utils.training.train_loop", "DL_Models.torch_models.torch_utils.training.validation_loop", "BaseNetTorch.BaseNet.float", "BaseNetTorch.BaseNet.float", "logging.info", "logging.info", "logging.info"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.training.train_loop", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.training.validation_loop"], ["", "def", "fit", "(", "self", ",", "train_dataloader", ",", "validation_dataloader", ")", ":", "\n", "        ", "\"\"\"\n        Fit the model on the dataset defined by data x and labels y \n\n        Inputs:\n        training, validation and test dataloader containing the respective datasets\n\n        Output:\n        prediction_ensemble containing the predictions on the test data, prediction on test data when model stops is used to compute the ensemble metrics \n        \"\"\"", "\n", "# Move the model to GPU", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "cuda", "(", ")", "\n", "logging", ".", "info", "(", "f\"Model moved to cuda\"", ")", "\n", "# Create the optimizer", "\n", "", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "list", "(", "self", ".", "parameters", "(", ")", ")", ",", "lr", "=", "config", "[", "'learning_rate'", "]", ")", "\n", "# Create a history to track ensemble performance, similar to tensorflow.keras callbacks", "\n", "#prediction_ensemble = Prediction_history(dataloader=test_dataloader, model=self)", "\n", "# Create datastructures to collect metrics and implement early stopping", "\n", "epochs", "=", "self", ".", "epochs", "\n", "#metrics = {'train_loss':[], 'val_loss':[], 'train_acc':[], 'val_acc':[]} if config['task'] == 'prosaccade-clf' else {'train_loss':[], 'val_loss':[]}", "\n", "best_val_loss", "=", "sys", ".", "maxsize", "# For early stopping ", "\n", "patience", "=", "0", "\n", "# Train the model ", "\n", "for", "t", "in", "range", "(", "epochs", ")", ":", "\n", "            ", "logging", ".", "info", "(", "\"-------------------------------\"", ")", "\n", "logging", ".", "info", "(", "f\"Epoch {t+1}\"", ")", "\n", "# Run through training and validation set  ", "\n", "if", "not", "self", ".", "early_stopped", ":", "\n", "                ", "train_loss_epoch", ",", "train_acc_epoch", "=", "train_loop", "(", "train_dataloader", ",", "self", ".", "float", "(", ")", ",", "self", ".", "loss", ",", "self", ".", "loss_fn", ",", "optimizer", ")", "\n", "val_loss_epoch", ",", "val_acc_epoch", "=", "validation_loop", "(", "validation_dataloader", ",", "self", ".", "float", "(", ")", ",", "self", ".", "loss", ",", "self", ".", "loss_fn", ")", "\n", "#metrics['train_loss'].append(train_loss_epoch)", "\n", "#metrics['val_loss'].append(val_loss_epoch)", "\n", "#if config['task'] == 'prosaccade-clf':", "\n", "#metrics['train_acc'].append(train_acc_epoch)", "\n", "#metrics['val_acc'].append(val_acc_epoch) ", "\n", "# Add the predictions on the validation set, even if model was early stopped, later we will compute ensemble metrics on them ", "\n", "#prediction_ensemble.on_epoch_end()", "\n", "# Impementation of early stopping ", "\n", "", "if", "config", "[", "'early_stopping'", "]", "and", "not", "self", ".", "early_stopped", ":", "\n", "                ", "if", "patience", ">", "config", "[", "'patience'", "]", ":", "\n", "                    ", "logging", ".", "info", "(", "f\"Early stopping the model after {t} epochs\"", ")", "\n", "self", ".", "early_stopped", "=", "True", "\n", "", "if", "val_loss_epoch", ">=", "best_val_loss", ":", "\n", "                    ", "logging", ".", "info", "(", "f\"Validation loss did not improve, best was {best_val_loss}\"", ")", "\n", "patience", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "best_val_loss", "=", "val_loss_epoch", "\n", "logging", ".", "info", "(", "f\"Improved validation loss to: {best_val_loss}\"", ")", "\n", "patience", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.BaseNetTorch.BaseNet.predict": [[156, 161], ["torch.tensor().float", "torch.cuda.is_available", "BaseNetTorch.BaseNet.detach().numpy", "torch.tensor().float.cuda", "torch.tensor", "BaseNetTorch.BaseNet.detach", "BaseNetTorch.BaseNet."], "methods", ["None"], ["", "", "", "", "def", "predict", "(", "self", ",", "X", ")", ":", "\n", "        ", "tensor_X", "=", "torch", ".", "tensor", "(", "X", ")", ".", "float", "(", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "tensor_X", ".", "cuda", "(", ")", "\n", "", "return", "self", "(", "tensor_X", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.ConvNetTorch.ConvNet.__init__": [[18, 49], ["abc.ABC.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.AvgPool1d", "torch.AvgPool1d", "torch.AvgPool1d", "DL_Models.torch_models.Modules.Pad_Pool", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "ConvNetTorch.ConvNet._module", "range", "ConvNetTorch.ConvNet._shortcut", "str", "str", "str", "str", "str", "str", "range", "sum", "sum", "int", "p.numel", "p.numel", "ConvNetTorch.ConvNet.parameters", "ConvNetTorch.ConvNet.parameters"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.ConvNet.ConvNet._module", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.ConvNetTorch.ConvNet._shortcut"], ["def", "__init__", "(", "self", ",", "loss", ",", "model_number", ",", "batch_size", ",", "input_shape", ",", "output_shape", ",", "kernel_size", "=", "32", ",", "epochs", "=", "2", ",", "nb_filters", "=", "32", ",", "verbose", "=", "True", ",", "\n", "use_residual", "=", "False", ",", "depth", "=", "6", ",", "preprocessing", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        We define the layers of the network in the __init__ function\n        \"\"\"", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "super", "(", ")", ".", "__init__", "(", "loss", "=", "loss", ",", "input_shape", "=", "input_shape", ",", "output_shape", "=", "output_shape", ",", "epochs", "=", "epochs", ",", "verbose", "=", "verbose", ",", "\n", "model_number", "=", "model_number", ")", "\n", "\n", "self", ".", "use_residual", "=", "use_residual", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "nb_filters", "=", "nb_filters", "\n", "self", ".", "preprocessing", "=", "preprocessing", "\n", "\n", "# Define all the convolutional and shortcut modules that we will need in the model ", "\n", "self", ".", "conv_blocks", "=", "nn", ".", "ModuleList", "(", "[", "self", ".", "_module", "(", "d", ")", "for", "d", "in", "range", "(", "self", ".", "depth", ")", "]", ")", "\n", "if", "self", ".", "use_residual", ":", "\n", "            ", "self", ".", "shortcuts", "=", "nn", ".", "ModuleList", "(", "[", "self", ".", "_shortcut", "(", "d", ")", "for", "d", "in", "range", "(", "int", "(", "self", ".", "depth", "/", "3", ")", ")", "]", ")", "\n", "", "self", ".", "gap_layer", "=", "nn", ".", "AvgPool1d", "(", "kernel_size", "=", "2", ",", "stride", "=", "1", ")", "\n", "self", ".", "gap_layer_pad", "=", "Pad_Pool", "(", "left", "=", "0", ",", "right", "=", "1", ",", "value", "=", "0", ")", "\n", "\n", "if", "self", ".", "verbose", "and", "model_number", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "f\"Number of model parameters: {sum(p.numel() for p in self.parameters())}\"", ")", "\n", "logging", ".", "info", "(", "f\"Number of trainable parameters: {sum(p.numel() for p in self.parameters() if p.requires_grad)}\"", ")", "\n", "logging", ".", "info", "(", "'--------------- use residual : '", "+", "str", "(", "self", ".", "use_residual", ")", ")", "\n", "logging", ".", "info", "(", "'--------------- depth        : '", "+", "str", "(", "self", ".", "depth", ")", ")", "\n", "logging", ".", "info", "(", "'--------------- batch_size        : '", "+", "str", "(", "self", ".", "batch_size", ")", ")", "\n", "logging", ".", "info", "(", "'--------------- kernel size  : '", "+", "str", "(", "self", ".", "kernel_size", ")", ")", "\n", "logging", ".", "info", "(", "'--------------- nb filters   : '", "+", "str", "(", "self", ".", "nb_filters", ")", ")", "\n", "logging", ".", "info", "(", "'--------------- preprocessing: '", "+", "str", "(", "self", ".", "preprocessing", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.ConvNetTorch.ConvNet.forward": [[51, 74], ["range", "ConvNetTorch.ConvNet.gap_layer_pad", "ConvNetTorch.ConvNet.gap_layer", "torch.functional.relu.view", "ConvNetTorch.ConvNet.output_layer", "ConvNetTorch.ConvNet._preprocessing", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.functional.relu", "torch.functional.relu", "torch.functional.relu"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.ConvNet.ConvNet._preprocessing"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Implements the forward pass of the network\n        Modules defined in a class implementing ConvNet are stacked and shortcut connections are used if specified. \n        \"\"\"", "\n", "if", "self", ".", "preprocessing", ":", "\n", "            ", "x", "=", "self", ".", "_preprocessing", "(", "x", ")", "\n", "", "input_res", "=", "x", "# set for the residual shortcut connection   ", "\n", "# Stack the modules and residual connection ", "\n", "shortcut_cnt", "=", "0", "\n", "for", "d", "in", "range", "(", "self", ".", "depth", ")", ":", "\n", "            ", "x", "=", "self", ".", "conv_blocks", "[", "d", "]", "(", "x", ")", "\n", "if", "self", ".", "use_residual", "and", "d", "%", "3", "==", "2", ":", "\n", "                ", "res", "=", "self", ".", "shortcuts", "[", "shortcut_cnt", "]", "(", "input_res", ")", "\n", "shortcut_cnt", "+=", "1", "\n", "x", "=", "torch", ".", "add", "(", "x", ",", "res", ")", "\n", "x", "=", "nn", ".", "functional", ".", "relu", "(", "x", ")", "\n", "input_res", "=", "x", "\n", "", "", "x", "=", "self", ".", "gap_layer_pad", "(", "x", ")", "\n", "x", "=", "self", ".", "gap_layer", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "self", ".", "batch_size", ",", "-", "1", ")", "\n", "output", "=", "self", ".", "output_layer", "(", "x", ")", "# Defined in BaseNet ", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.ConvNetTorch.ConvNet._shortcut": [[75, 86], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "DL_Models.torch_models.Modules.Pad_Conv", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d"], "methods", ["None"], ["", "def", "_shortcut", "(", "self", ",", "depth", ")", ":", "\n", "        ", "\"\"\"\n        Implements a shortcut with a convolution and batch norm \n        This is the same for all models implementing ConvNet, therefore defined here \n        Padding before convolution for constant tensor shape, similar to tensorflow.keras padding=same\n        \"\"\"", "\n", "return", "nn", ".", "Sequential", "(", "\n", "Pad_Conv", "(", "kernel_size", "=", "self", ".", "kernel_size", ",", "value", "=", "0", ")", ",", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "self", ".", "nb_channels", "if", "depth", "==", "0", "else", "self", ".", "nb_features", ",", "\n", "out_channels", "=", "self", ".", "nb_features", ",", "kernel_size", "=", "self", ".", "kernel_size", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "self", ".", "nb_features", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.ConvNetTorch.ConvNet.get_nb_features_output_layer": [[88, 94], ["None"], "methods", ["None"], ["", "def", "get_nb_features_output_layer", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return number of features passed into the output layer of the network \n        nb.features has to be defined in a model implementing ConvNet\n        \"\"\"", "\n", "return", "self", ".", "nb_features", "*", "self", ".", "timesamples", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.ConvNetTorch.ConvNet._preprocessing": [[96, 98], ["None"], "methods", ["None"], ["", "def", "_preprocessing", "(", "self", ",", "input_tensor", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.ConvNetTorch.ConvNet._module": [[100, 102], ["None"], "methods", ["None"], ["", "def", "_module", "(", "self", ",", "input_tensor", ",", "current_depth", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.ConvNetTorch.ConvNet._split_model": [[103, 105], ["None"], "methods", ["None"], ["", "def", "_split_model", "(", "self", ")", ":", "\n", "        ", "pass", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Ensemble_torch.Ensemble_torch.__init__": [[17, 48], ["re.compile"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_name", "=", "'CNN'", ",", "nb_models", "=", "5", ",", "loss", "=", "'bce'", ",", "batch_size", "=", "64", ",", "**", "model_params", ")", ":", "\n", "        ", "\"\"\"\n        model_name: the model that the ensemble uses\n        nb_models: Number of models to run in the ensemble\n        model_list: optional, give a list of models that should be contained in the Ensemble\n        ...\n        \"\"\"", "\n", "self", ".", "model_name", "=", "model_name", "\n", "self", ".", "nb_models", "=", "nb_models", "\n", "self", ".", "model_params", "=", "model_params", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "loss", "=", "loss", "\n", "self", ".", "model_instance", "=", "None", "\n", "self", ".", "load_file_pattern", "=", "re", ".", "compile", "(", "self", ".", "model_name", "[", ":", "3", "]", "+", "'.*_nb_._best_model.pth'", ",", "re", ".", "IGNORECASE", ")", "\n", "self", ".", "models", "=", "[", "]", "\n", "\n", "if", "self", ".", "model_name", "==", "'CNN'", ":", "\n", "            ", "from", "DL_Models", ".", "torch_models", ".", "CNN", ".", "CNN", "import", "CNN", "\n", "self", ".", "model", "=", "CNN", "\n", "", "elif", "self", ".", "model_name", "==", "'EEGNet'", ":", "\n", "            ", "from", "DL_Models", ".", "torch_models", ".", "EEGNet", ".", "eegNet", "import", "EEGNet", "\n", "self", ".", "model", "=", "EEGNet", "\n", "", "elif", "self", ".", "model_name", "==", "'InceptionTime'", ":", "\n", "            ", "from", "DL_Models", ".", "torch_models", ".", "InceptionTime", ".", "InceptionTime", "import", "Inception", "\n", "self", ".", "model", "=", "Inception", "\n", "", "elif", "self", ".", "model_name", "==", "'PyramidalCNN'", ":", "\n", "            ", "from", "DL_Models", ".", "torch_models", ".", "PyramidalCNN", ".", "PyramidalCNN", "import", "PyramidalCNN", "\n", "self", ".", "model", "=", "PyramidalCNN", "\n", "", "elif", "self", ".", "model_name", "==", "'Xception'", ":", "\n", "            ", "from", "DL_Models", ".", "torch_models", ".", "Xception", ".", "Xception", "import", "XCEPTION", "\n", "self", ".", "model", "=", "XCEPTION", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Ensemble_torch.Ensemble_torch.fit": [[50, 67], ["numpy.transpose", "numpy.transpose", "DL_Models.torch_models.torch_utils.dataloader.create_dataloader", "DL_Models.torch_models.torch_utils.dataloader.create_dataloader", "range", "logging.info", "logging.info", "Ensemble_torch.Ensemble_torch.model", "Ensemble_torch.Ensemble_torch.fit", "Ensemble_torch.Ensemble_torch.models.append", "logging.info"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.dataloader.create_dataloader", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.dataloader.create_dataloader", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit"], ["", "", "def", "fit", "(", "self", ",", "trainX", ",", "trainY", ",", "validX", ",", "validY", ")", ":", "\n", "        ", "\"\"\"\n        Fit an ensemble of models. They will be saved by BaseNet into the model dir\n        \"\"\"", "\n", "# Create dataloaders", "\n", "trainX", "=", "np", ".", "transpose", "(", "trainX", ",", "(", "0", ",", "2", ",", "1", ")", ")", "# (batch_size, samples, channels) to (bs, ch, samples) as torch conv layers want it", "\n", "validX", "=", "np", ".", "transpose", "(", "validX", ",", "(", "0", ",", "2", ",", "1", ")", ")", "# (batch_size, samples, channels) to (bs, ch, samples) as torch conv layers want it", "\n", "train_dataloader", "=", "create_dataloader", "(", "trainX", ",", "trainY", ",", "self", ".", "batch_size", ",", "self", ".", "model_name", ")", "\n", "validation_dataloader", "=", "create_dataloader", "(", "validX", ",", "validY", ",", "self", ".", "batch_size", ",", "self", ".", "model_name", ")", "\n", "# Fit the models ", "\n", "for", "i", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "            ", "logging", ".", "info", "(", "\"------------------------------------------------------------------------------------\"", ")", "\n", "logging", ".", "info", "(", "'Start fitting model number {}/{} ...'", ".", "format", "(", "i", "+", "1", ",", "self", ".", "nb_models", ")", ")", "\n", "model", "=", "self", ".", "model", "(", "loss", "=", "self", ".", "loss", ",", "model_number", "=", "i", ",", "batch_size", "=", "self", ".", "batch_size", ",", "**", "self", ".", "model_params", ")", "\n", "model", ".", "fit", "(", "train_dataloader", ",", "validation_dataloader", ")", "\n", "self", ".", "models", ".", "append", "(", "model", ")", "\n", "logging", ".", "info", "(", "'Finished fitting model number {}/{} ...'", ".", "format", "(", "i", "+", "1", ",", "self", ".", "nb_models", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Ensemble_torch.Ensemble_torch.predict": [[69, 88], ["numpy.transpose", "numpy.zeros", "numpy.concatenate", "DL_Models.torch_models.torch_utils.dataloader.create_dataloader", "torch.cuda.is_available", "len", "model.cuda", "DL_Models.torch_models.torch_utils.training.test_loop", "DL_Models.torch_models.torch_utils.training.test_loop"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.dataloader.create_dataloader", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.training.test_loop", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.training.test_loop"], ["", "", "def", "predict", "(", "self", ",", "testX", ")", ":", "\n", "        ", "testX", "=", "np", ".", "transpose", "(", "testX", ",", "(", "0", ",", "2", ",", "1", ")", ")", "# (batch_size, samples, channels) to (bs, ch, samples) as torch conv layers want it", "\n", "a", ",", "b", ",", "c", "=", "testX", ".", "shape", "\n", "a", "=", "self", ".", "batch_size", "-", "a", "%", "self", ".", "batch_size", "\n", "dummy", "=", "np", ".", "zeros", "(", "(", "a", ",", "b", ",", "c", ")", ")", "\n", "#print(dummy.shape)", "\n", "testX", "=", "np", ".", "concatenate", "(", "(", "testX", ",", "dummy", ")", ")", "# TO ADD batch_size - testX.shape[0]%batch_size", "\n", "test_dataloader", "=", "create_dataloader", "(", "testX", ",", "testX", ",", "self", ".", "batch_size", ",", "self", ".", "model_name", ",", "drop_last", "=", "False", ")", "\n", "pred", "=", "None", "\n", "#print(f\"self models len {len(self.models)}\")", "\n", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "model", ".", "cuda", "(", ")", "\n", "", "if", "pred", "is", "not", "None", ":", "\n", "                ", "pred", "+=", "test_loop", "(", "dataloader", "=", "test_dataloader", ",", "model", "=", "model", ")", "\n", "", "else", ":", "\n", "                ", "pred", "=", "test_loop", "(", "dataloader", "=", "test_dataloader", ",", "model", "=", "model", ")", "\n", "", "", "pred", "=", "pred", "[", ":", "-", "a", "]", "\n", "return", "pred", "/", "len", "(", "self", ".", "models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Ensemble_torch.Ensemble_torch.save": [[89, 93], ["enumerate", "torch.save", "model.state_dict"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.save"], ["", "def", "save", "(", "self", ",", "path", ")", ":", "\n", "        ", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "ckpt_dir", "=", "path", "+", "self", ".", "model_name", "+", "'_nb_{}_'", ".", "format", "(", "i", ")", "+", "'.pth'", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_models.Ensemble_torch.Ensemble_torch.load": [[94, 108], ["os.listdir", "logging.info", "Ensemble_torch.Ensemble_torch.model", "Ensemble_torch.Ensemble_torch.load_state_dict", "Ensemble_torch.Ensemble_torch.eval", "Ensemble_torch.Ensemble_torch.models.append", "Ensemble_torch.Ensemble_torch.load_file_pattern.match", "torch.load"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.load"], ["", "", "def", "load", "(", "self", ",", "path", ")", ":", "\n", "#print(f\"cuda avail {torch.cuda.is_available()}\")", "\n", "        ", "self", ".", "models", "=", "[", "]", "\n", "for", "file", "in", "os", ".", "listdir", "(", "path", ")", ":", "\n", "            ", "if", "not", "self", ".", "load_file_pattern", ".", "match", "(", "file", ")", ":", "\n", "                ", "continue", "\n", "# These 3 lines are needed for torch to load", "\n", "", "logging", ".", "info", "(", "f\"Loading model nb from file {file} and predict with it\"", ")", "\n", "model", "=", "self", ".", "model", "(", "loss", "=", "self", ".", "loss", ",", "model_number", "=", "0", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "**", "self", ".", "model_params", ")", "# model = TheModelClass(*args, **kwargs)", "\n", "#print(path + file)", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "path", "+", "file", ")", ")", "# model.load_state_dict(torch.load(PATH))", "\n", "model", ".", "eval", "(", ")", "# needed before prediction", "\n", "self", ".", "models", ".", "append", "(", "model", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.PyramidalCNN.PyramidalCNN.PyramidalCNN.__init__": [[14, 19], ["DL_Models.tf_models.ConvNet.ConvNet.__init__"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__"], ["\n", "self", ".", "nb_features", "=", "depth", "*", "nb_filters", "# For pyramidal we increase the nbfilters each depth layer", "\n", "super", "(", ")", ".", "__init__", "(", "loss", "=", "loss", ",", "model_number", "=", "model_number", ",", "batch_size", "=", "batch_size", ",", "input_shape", "=", "input_shape", ",", "output_shape", "=", "output_shape", ",", "kernel_size", "=", "kernel_size", ",", "epochs", "=", "epochs", ",", "nb_filters", "=", "nb_filters", ",", "\n", "verbose", "=", "verbose", ",", "use_residual", "=", "use_residual", ",", "depth", "=", "depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.PyramidalCNN.PyramidalCNN.PyramidalCNN._module": [[23, 32], ["tensorflow.keras.layers.Conv1D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.MaxPool1D"], "methods", ["None"], ["\n", "return", "nn", ".", "Sequential", "(", "\n", "Pad_Conv", "(", "kernel_size", "=", "self", ".", "kernel_size", ")", ",", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "self", ".", "nb_channels", "if", "depth", "==", "0", "else", "depth", "*", "self", ".", "nb_filters", ",", "\n", "out_channels", "=", "(", "depth", "+", "1", ")", "*", "self", ".", "nb_filters", ",", "\n", "kernel_size", "=", "self", ".", "kernel_size", ",", "\n", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "(", "depth", "+", "1", ")", "*", "self", ".", "nb_filters", ")", ",", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.PyramidalCNN.PyramidalCNN.PyramidalCNN.__str__": [[20, 22], ["None"], "methods", ["None"], ["", "def", "_module", "(", "self", ",", "depth", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.InceptionTime.InceptionTime.Inception.__init__": [[18, 29], ["logging.info", "DL_Models.torch_models.ConvNetTorch.ConvNet.__init__", "str"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__"], ["def", "__init__", "(", "self", ",", "loss", ",", "model_number", ",", "batch_size", ",", "input_shape", ",", "output_shape", ",", "kernel_size", "=", "64", ",", "epochs", "=", "50", ",", "nb_filters", "=", "16", ",", "verbose", "=", "True", ",", "\n", "use_residual", "=", "True", ",", "depth", "=", "12", ",", "bottleneck_size", "=", "16", ")", ":", "\n", "        ", "\"\"\"\n        nb_features: specifies number of channels before the output layer \n        \"\"\"", "\n", "self", ".", "bottleneck_size", "=", "bottleneck_size", "\n", "self", ".", "nb_features", "=", "4", "*", "nb_filters", "# these are the 4 concatenated parallel convolutions, width of the inner tensort passed through network ", "\n", "logging", ".", "info", "(", "'--------------- bottleneck_size : '", "+", "str", "(", "self", ".", "bottleneck_size", ")", ")", "\n", "super", "(", ")", ".", "__init__", "(", "loss", "=", "loss", ",", "model_number", "=", "model_number", ",", "batch_size", "=", "batch_size", ",", "input_shape", "=", "input_shape", ",", "output_shape", "=", "output_shape", ",", "kernel_size", "=", "kernel_size", ",", "epochs", "=", "epochs", ",", "\n", "nb_filters", "=", "nb_filters", ",", "verbose", "=", "verbose", ",", "\n", "use_residual", "=", "use_residual", ",", "depth", "=", "depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.InceptionTime.InceptionTime.Inception._module": [[30, 42], ["InceptionTime.Inception_module"], "methods", ["None"], ["", "def", "_module", "(", "self", ",", "depth", ")", ":", "\n", "        ", "\"\"\"\n        The module of InceptionTime (Taken from the implementation of InceptionTime paper).\n        It is made of a bottleneck convolution that reduces the number of channels from 128 -> 32.\n        Then it uses 3 filters with different kernel sizes (Default values are 40, 20, and 10)\n        In parallel it uses a simple convolution with kernel size 1 with max pooling for stability during training.\n        The outputs of each convolution are concatenated, followed by batch normalization and a ReLu activation.\n\n        Padding=same \n        \"\"\"", "\n", "return", "Inception_module", "(", "self", ".", "kernel_size", ",", "self", ".", "nb_features", ",", "self", ".", "nb_channels", ",", "\n", "self", ".", "nb_filters", ",", "self", ".", "bottleneck_size", ",", "depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.InceptionTime.InceptionTime.Inception_module.__init__": [[47, 82], ["torch.Module.__init__", "DL_Models.torch_models.Modules.Pad_Conv", "torch.Conv1d", "torch.Conv1d", "DL_Models.torch_models.Modules.Pad_Pool", "torch.MaxPool1d", "torch.MaxPool1d", "torch.Conv1d", "torch.Conv1d", "DL_Models.torch_models.Modules.Pad_Conv", "torch.Conv1d", "torch.Conv1d", "DL_Models.torch_models.Modules.Pad_Conv", "torch.Conv1d", "torch.Conv1d", "DL_Models.torch_models.Modules.Pad_Conv", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "range"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__"], ["def", "__init__", "(", "self", ",", "kernel_size", ",", "nb_features", ",", "nb_channels", ",", "nb_filters", ",", "bottleneck_size", ",", "depth", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "kernel_size_s", "=", "[", "kernel_size", "//", "(", "2", "**", "i", ")", "for", "i", "in", "range", "(", "3", ")", "]", "\n", "# Define all the layers and modules we need in the forward pass: first the initial convolution and the parallel maxpooling ", "\n", "self", ".", "pad_conv_in", "=", "Pad_Conv", "(", "kernel_size", "=", "kernel_size", ")", "\n", "# This is the bottleneck convolution ", "\n", "self", ".", "conv_in", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "nb_channels", "if", "depth", "==", "0", "else", "nb_features", ",", "\n", "out_channels", "=", "bottleneck_size", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "pad_pool_in", "=", "Pad_Pool", "(", "left", "=", "1", ",", "right", "=", "1", ")", "\n", "self", ".", "maxpool_in", "=", "nn", ".", "MaxPool1d", "(", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "# 3 parallel convolutions taking the bottleneck as input", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "bottleneck_size", ",", "\n", "out_channels", "=", "nb_filters", ",", "\n", "kernel_size", "=", "kernel_size_s", "[", "0", "]", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "pad1", "=", "Pad_Conv", "(", "kernel_size", "=", "kernel_size_s", "[", "0", "]", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "bottleneck_size", ",", "\n", "out_channels", "=", "nb_filters", ",", "\n", "kernel_size", "=", "kernel_size_s", "[", "1", "]", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "pad2", "=", "Pad_Conv", "(", "kernel_size", "=", "kernel_size_s", "[", "1", "]", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "bottleneck_size", ",", "\n", "out_channels", "=", "nb_filters", ",", "\n", "kernel_size", "=", "kernel_size_s", "[", "2", "]", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "pad3", "=", "Pad_Conv", "(", "kernel_size", "=", "kernel_size_s", "[", "2", "]", ")", "\n", "# and the 4th parallel convolution following the maxpooling, no padding needed since 1x1 convolution ", "\n", "self", ".", "conv4", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "nb_channels", "if", "depth", "==", "0", "else", "nb_features", ",", "\n", "out_channels", "=", "nb_filters", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "batchnorm", "=", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "nb_features", ")", "\n", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.InceptionTime.InceptionTime.Inception_module.forward": [[83, 105], ["InceptionTime.Inception_module.pad_conv_in", "InceptionTime.Inception_module.conv_in", "InceptionTime.Inception_module.pad1", "InceptionTime.Inception_module.conv1", "InceptionTime.Inception_module.pad2", "InceptionTime.Inception_module.conv2", "InceptionTime.Inception_module.pad1", "InceptionTime.Inception_module.conv1", "InceptionTime.Inception_module.pad_pool_in", "InceptionTime.Inception_module.maxpool_in", "InceptionTime.Inception_module.conv4", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "InceptionTime.Inception_module.batchnorm", "InceptionTime.Inception_module.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Implements a forward pass through one inception module\n        \"\"\"", "\n", "# Implement the left convolution ", "\n", "x_left", "=", "self", ".", "pad_conv_in", "(", "x", ")", "\n", "x_left", "=", "self", ".", "conv_in", "(", "x_left", ")", "\n", "# Implement the 3 parallel convolutions afterwards", "\n", "x_left1", "=", "self", ".", "pad1", "(", "x_left", ")", "\n", "x_left1", "=", "self", ".", "conv1", "(", "x_left1", ")", "\n", "x_left2", "=", "self", ".", "pad2", "(", "x_left", ")", "\n", "x_left2", "=", "self", ".", "conv2", "(", "x_left2", ")", "\n", "x_left3", "=", "self", ".", "pad1", "(", "x_left", ")", "\n", "x_left3", "=", "self", ".", "conv1", "(", "x_left3", ")", "\n", "# Implement the right maxpooling followed by a conv", "\n", "x_right", "=", "self", ".", "pad_pool_in", "(", "x", ")", "\n", "x_right", "=", "self", ".", "maxpool_in", "(", "x_right", ")", "\n", "x_right", "=", "self", ".", "conv4", "(", "x_right", ")", "\n", "# Concatenate the 4 outputs        ", "\n", "x", "=", "torch", ".", "cat", "(", "tensors", "=", "(", "x_left1", ",", "x_left2", ",", "x_left3", ",", "x_right", ")", ",", "dim", "=", "1", ")", "# concatenate along the feature dimension ", "\n", "x", "=", "self", ".", "batchnorm", "(", "x", ")", "\n", "return", "self", ".", "activation", "(", "x", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.InceptionTime.Inception.INCEPTION.__init__": [[17, 24], ["DL_Models.tf_models.ConvNet.ConvNet.__init__", "logging.info", "str"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__"], ["def", "__init__", "(", "self", ",", "loss", ",", "model_number", ",", "batch_size", ",", "input_shape", ",", "output_shape", ",", "kernel_size", "=", "64", ",", "epochs", "=", "50", ",", "nb_filters", "=", "16", ",", "verbose", "=", "True", ",", "\n", "use_residual", "=", "True", ",", "depth", "=", "12", ",", "bottleneck_size", "=", "16", ")", ":", "\n", "        ", "self", ".", "bottleneck_size", "=", "bottleneck_size", "\n", "super", "(", "INCEPTION", ",", "self", ")", ".", "__init__", "(", "input_shape", "=", "input_shape", ",", "output_shape", "=", "output_shape", ",", "loss", "=", "loss", ",", "kernel_size", "=", "kernel_size", ",", "epochs", "=", "epochs", ",", "\n", "nb_filters", "=", "nb_filters", ",", "verbose", "=", "verbose", ",", "batch_size", "=", "batch_size", ",", "\n", "use_residual", "=", "use_residual", ",", "depth", "=", "depth", ",", "model_number", "=", "model_number", ")", "\n", "logging", ".", "info", "(", "'--------------- bottleneck_size : '", "+", "str", "(", "self", ".", "bottleneck_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.InceptionTime.Inception.INCEPTION._module": [[25, 54], ["range", "conv_list.append", "int", "len", "conv_list.append", "tensorflow.keras.layers.MaxPool1D", "tensorflow.keras.layers.Conv1D", "tensorflow.keras.layers.Concatenate", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv1D", "range", "tensorflow.keras.layers.Conv1D"], "methods", ["None"], ["", "def", "_module", "(", "self", ",", "input_tensor", ",", "current_depth", ")", ":", "\n", "        ", "\"\"\"\n        The module of InceptionTime (Taken from the implementation of InceptionTime paper).\n        It is made of a bottleneck convolution that reduces the number of channels from 128 -> 32.\n        Then it uses 3 filters with different kernel sizes (Default values are 40, 20, and 10)\n        In parallel it uses a simple convolution with kernel size 1 with max pooling for stability during training.\n        The outputs of each convolution are concatenated, followed by batch normalization and a ReLu activation.\n        \"\"\"", "\n", "if", "int", "(", "input_tensor", ".", "shape", "[", "-", "1", "]", ")", ">", "1", ":", "\n", "            ", "input_inception", "=", "tf", ".", "keras", ".", "layers", ".", "Conv1D", "(", "filters", "=", "self", ".", "bottleneck_size", ",", "kernel_size", "=", "1", ",", "padding", "=", "'same'", ",", "use_bias", "=", "False", ")", "(", "input_tensor", ")", "\n", "", "else", ":", "\n", "            ", "input_inception", "=", "input_tensor", "\n", "\n", "# kernel_size_s = [3, 5, 8, 11, 17]", "\n", "", "kernel_size_s", "=", "[", "self", ".", "kernel_size", "//", "(", "2", "**", "i", ")", "for", "i", "in", "range", "(", "3", ")", "]", "\n", "conv_list", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "kernel_size_s", ")", ")", ":", "\n", "            ", "conv_list", ".", "append", "(", "\n", "tf", ".", "keras", ".", "layers", ".", "Conv1D", "(", "filters", "=", "self", ".", "nb_filters", ",", "kernel_size", "=", "kernel_size_s", "[", "i", "]", ",", "padding", "=", "'same'", ",", "use_bias", "=", "False", ")", "(", "input_inception", ")", ")", "\n", "\n", "", "max_pool_1", "=", "tf", ".", "keras", ".", "layers", ".", "MaxPool1D", "(", "pool_size", "=", "3", ",", "strides", "=", "1", ",", "padding", "=", "'same'", ")", "(", "input_tensor", ")", "\n", "conv_6", "=", "tf", ".", "keras", ".", "layers", ".", "Conv1D", "(", "filters", "=", "self", ".", "nb_filters", ",", "kernel_size", "=", "1", ",", "padding", "=", "'same'", ",", "use_bias", "=", "False", ")", "(", "max_pool_1", ")", "\n", "\n", "conv_list", ".", "append", "(", "conv_6", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Concatenate", "(", "axis", "=", "2", ")", "(", "conv_list", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "x", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "activation", "=", "'relu'", ")", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.CNN.CNN.CNN.__init__": [[15, 24], ["DL_Models.tf_models.ConvNet.ConvNet.__init__"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__"], ["super", "(", ")", ".", "__init__", "(", "loss", "=", "loss", ",", "model_number", "=", "model_number", ",", "batch_size", "=", "batch_size", ",", "input_shape", "=", "input_shape", ",", "output_shape", "=", "output_shape", ",", "kernel_size", "=", "kernel_size", ",", "epochs", "=", "epochs", ",", "\n", "nb_filters", "=", "nb_filters", ",", "verbose", "=", "verbose", ",", "\n", "use_residual", "=", "use_residual", ",", "depth", "=", "depth", ")", "\n", "\n", "", "def", "_module", "(", "self", ",", "depth", ")", ":", "\n", "        ", "\"\"\"\n        The module of CNN is made of a simple convolution with batch normalization and ReLu activation. Finally, MaxPooling is used.\n        We use two custom padding modules such that keras-like padding='same' is achieved, i.e. tensor shape stays constant when passed through the module.\n        \"\"\"", "\n", "return", "nn", ".", "Sequential", "(", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.CNN.CNN.CNN._module": [[28, 37], ["tensorflow.keras.layers.Conv1D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.MaxPool1D"], "methods", ["None"], ["nn", ".", "BatchNorm1d", "(", "num_features", "=", "self", ".", "nb_features", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "Pad_Pool", "(", "left", "=", "0", ",", "right", "=", "1", ",", "value", "=", "0", ")", ",", "\n", "nn", ".", "MaxPool1d", "(", "kernel_size", "=", "2", ",", "stride", "=", "1", ")", "\n", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.CNN.CNN.CNN.__str__": [[25, 27], ["None"], "methods", ["None"], ["Pad_Conv", "(", "kernel_size", "=", "self", ".", "kernel_size", ",", "value", "=", "0", ")", ",", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "self", ".", "nb_channels", "if", "depth", "==", "0", "else", "self", ".", "nb_features", ",", "\n", "out_channels", "=", "self", ".", "nb_features", ",", "kernel_size", "=", "self", ".", "kernel_size", ",", "bias", "=", "False", ")", ",", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.Xception.Xception.XCEPTION.__init__": [[14, 19], ["DL_Models.tf_models.ConvNet.ConvNet.__init__"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__"], ["def", "__init__", "(", "self", ",", "loss", ",", "model_number", ",", "batch_size", ",", "input_shape", ",", "output_shape", ",", "kernel_size", "=", "40", ",", "nb_filters", "=", "64", ",", "verbose", "=", "True", ",", "epochs", "=", "1", ",", "\n", "use_residual", "=", "True", ",", "depth", "=", "6", ")", ":", "\n", "        ", "\"\"\"\n        nb_features: specifies number of channels before the output layer \n        \"\"\"", "\n", "self", ".", "nb_features", "=", "nb_filters", "# Exception passes a tensor of shape (timesamples, nb_filters) through the network", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.Xception.Xception.XCEPTION._module": [[20, 28], ["tensorflow.keras.layers.SeparableConv1D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation"], "methods", ["None"], ["super", "(", "XCEPTION", ",", "self", ")", ".", "__init__", "(", "loss", "=", "loss", ",", "model_number", "=", "model_number", ",", "batch_size", "=", "batch_size", ",", "input_shape", "=", "input_shape", ",", "output_shape", "=", "output_shape", ",", "kernel_size", "=", "kernel_size", ",", "\n", "nb_filters", "=", "nb_filters", ",", "verbose", "=", "verbose", ",", "epochs", "=", "epochs", ",", "use_residual", "=", "use_residual", ",", "depth", "=", "depth", ",", "preprocessing", "=", "False", ")", "\n", "\n", "", "def", "_module", "(", "self", ",", "depth", ")", ":", "\n", "        ", "\"\"\"\n        The module of Xception. Consists of a separable convolution followed by batch normalization and a ReLu activation function.\n        Padding=same \n        \"\"\"", "\n", "return", "nn", ".", "Sequential", "(", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.eegNet.EEGNet.__init__": [[26, 53], ["DL_Models.tf_models.BaseNet.BaseNet.__init__", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__"], ["self", ".", "channels", "=", "input_shape", "[", "1", "]", "\n", "self", ".", "F1", "=", "F1", "\n", "self", ".", "D", "=", "D", "\n", "self", ".", "F2", "=", "F2", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "dropout_rate", "=", "dropout_rate", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "loss", ",", "input_shape", "=", "input_shape", ",", "output_shape", "=", "output_shape", ",", "epochs", "=", "epochs", ",", "model_number", "=", "model_number", ",", "verbose", "=", "verbose", ")", "\n", "\n", "# Block 1: 2dconv and depthwise conv", "\n", "self", ".", "padconv1", "=", "Pad_Conv2d", "(", "kernel", "=", "(", "1", ",", "self", ".", "kernel_size", ")", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "1", ",", "\n", "out_channels", "=", "self", ".", "F1", ",", "\n", "kernel_size", "=", "(", "1", ",", "self", ".", "kernel_size", ")", ",", "\n", "bias", "=", "False", "\n", ")", "\n", "self", ".", "batchnorm1", "=", "nn", ".", "BatchNorm2d", "(", "self", ".", "F1", ",", "False", ")", "\n", "self", ".", "depthwise_conv1", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "self", ".", "F1", ",", "\n", "out_channels", "=", "self", ".", "F1", "*", "self", ".", "D", ",", "\n", "groups", "=", "self", ".", "F1", ",", "\n", "kernel_size", "=", "(", "self", ".", "channels", ",", "1", ")", ",", "\n", "bias", "=", "False", "\n", ")", "\n", "self", ".", "batchnorm1_2", "=", "nn", ".", "BatchNorm2d", "(", "self", ".", "F1", "*", "self", ".", "D", ")", "\n", "self", ".", "activation1", "=", "nn", ".", "ELU", "(", ")", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.eegNet.EEGNet.forward": [[86, 117], ["eegNet.EEGNet.padconv1", "eegNet.EEGNet.conv1", "eegNet.EEGNet.batchnorm1", "eegNet.EEGNet.depthwise_conv1", "eegNet.EEGNet.batchnorm1_2", "eegNet.EEGNet.activation1", "eegNet.EEGNet.padpool1", "eegNet.EEGNet.avgpool1", "eegNet.EEGNet.dropout1", "eegNet.EEGNet.pad_depthwise2", "eegNet.EEGNet.depthwise_conv2", "eegNet.EEGNet.pointwise_conv2", "eegNet.EEGNet.batchnorm2", "eegNet.EEGNet.activation2", "eegNet.EEGNet.padpool2", "eegNet.EEGNet.avgpool2", "eegNet.EEGNet.dropout2", "eegNet.EEGNet.view", "eegNet.EEGNet.output_layer"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Implements a forward pass of the eegnet.\n        \"\"\"", "\n", "# Block 1", "\n", "x", "=", "self", ".", "padconv1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "batchnorm1", "(", "x", ")", "\n", "x", "=", "self", ".", "depthwise_conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "batchnorm1_2", "(", "x", ")", "\n", "x", "=", "self", ".", "activation1", "(", "x", ")", "\n", "x", "=", "self", ".", "padpool1", "(", "x", ")", "\n", "x", "=", "self", ".", "avgpool1", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout1", "(", "x", ")", "\n", "\n", "# Block2", "\n", "x", "=", "self", ".", "pad_depthwise2", "(", "x", ")", "\n", "x", "=", "self", ".", "depthwise_conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "pointwise_conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "batchnorm2", "(", "x", ")", "\n", "x", "=", "self", ".", "activation2", "(", "x", ")", "\n", "x", "=", "self", ".", "padpool2", "(", "x", ")", "\n", "x", "=", "self", ".", "avgpool2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout2", "(", "x", ")", "\n", "\n", "# Reshape", "\n", "x", "=", "x", ".", "view", "(", "self", ".", "batch_size", ",", "-", "1", ")", "\n", "# Output", "\n", "x", "=", "self", ".", "output_layer", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.eegNet.EEGNet.get_nb_features_output_layer": [[118, 124], ["None"], "methods", ["None"], ["", "def", "get_nb_features_output_layer", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return number of features passed into the output layer of the network \n        \"\"\"", "\n", "# 4 channels before the output layer ", "\n", "return", "4", "*", "self", ".", "timesamples", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.eegNet.EEGNet._split_model": [[54, 77], ["tensorflow.layers.Input", "tensorflow.layers.Input", "config[].keys", "tensorflow.keras.models.Model", "tensorflow.keras.models.Model", "output.append", "tensorflow.keras.layers.Concatenate", "tensorflow.keras.layers.Concatenate", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "eegNet.EEGNet._build_model", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.transpose", "tensorflow.transpose"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.BaseNet.BaseNet._build_model"], ["self", ".", "padpool1", "=", "Pad_Conv2d", "(", "kernel", "=", "(", "1", ",", "16", ")", ")", "\n", "self", ".", "avgpool1", "=", "nn", ".", "AvgPool2d", "(", "kernel_size", "=", "(", "1", ",", "16", ")", ",", "stride", "=", "1", ")", "\n", "self", ".", "dropout1", "=", "nn", ".", "Dropout", "(", "self", ".", "dropout_rate", ")", "\n", "\n", "# Block 2: separable conv = depthwise + pointwise ", "\n", "self", ".", "pad_depthwise2", "=", "Pad_Conv2d", "(", "kernel", "=", "(", "1", ",", "64", ")", ")", "\n", "self", ".", "depthwise_conv2", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "self", ".", "F1", "*", "self", ".", "D", ",", "\n", "out_channels", "=", "self", ".", "F2", ",", "\n", "groups", "=", "self", ".", "F1", "*", "self", ".", "D", ",", "\n", "kernel_size", "=", "(", "1", ",", "64", ")", ",", "\n", "bias", "=", "False", "\n", ")", "\n", "self", ".", "pointwise_conv2", "=", "nn", ".", "Conv2d", "(", "# no need for padding or pointwise ", "\n", "in_channels", "=", "self", ".", "F2", ",", "\n", "out_channels", "=", "4", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "False", "\n", ")", "\n", "self", ".", "batchnorm2", "=", "nn", ".", "BatchNorm2d", "(", "4", ",", "False", ")", "\n", "self", ".", "activation2", "=", "nn", ".", "ELU", "(", ")", "\n", "self", ".", "padpool2", "=", "Pad_Conv2d", "(", "kernel", "=", "(", "1", ",", "8", ")", ")", "\n", "self", ".", "avgpool2", "=", "nn", ".", "AvgPool2d", "(", "kernel_size", "=", "(", "1", ",", "8", ")", ",", "stride", "=", "1", ")", "\n", "self", ".", "dropout2", "=", "nn", ".", "Dropout", "(", "self", ".", "dropout_rate", ")", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.eegNet.EEGNet._build_model": [[79, 123], ["tensorflow.keras.layers.Input", "tensorflow.keras.layers.Input", "tensorflow.keras.models.Model", "tensorflow.keras.models.Model", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.DepthwiseConv2D", "tensorflow.keras.layers.DepthwiseConv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.AveragePooling2D", "tensorflow.keras.layers.AveragePooling2D", "dropoutType", "tensorflow.keras.layers.SeparableConv2D", "tensorflow.keras.layers.SeparableConv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.AveragePooling2D", "tensorflow.keras.layers.AveragePooling2D", "dropoutType", "tensorflow.keras.layers.Flatten", "tensorflow.keras.layers.Flatten", "ValueError", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "ValueError", "tensorflow.keras.constraints.max_norm", "tensorflow.keras.constraints.max_norm", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense"], "methods", ["None"], ["logging", ".", "info", "(", "f\"Number of model parameters: {sum(p.numel() for p in self.parameters())}\"", ")", "\n", "logging", ".", "info", "(", "f\"Number of trainable parameters: {sum(p.numel() for p in self.parameters() if p.requires_grad)}\"", ")", "\n", "\n", "if", "verbose", "and", "self", ".", "model_number", "==", "0", ":", "\n", "#print(self)", "\n", "            ", "pass", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Implements a forward pass of the eegnet.\n        \"\"\"", "\n", "# Block 1", "\n", "x", "=", "self", ".", "padconv1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "batchnorm1", "(", "x", ")", "\n", "x", "=", "self", ".", "depthwise_conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "batchnorm1_2", "(", "x", ")", "\n", "x", "=", "self", ".", "activation1", "(", "x", ")", "\n", "x", "=", "self", ".", "padpool1", "(", "x", ")", "\n", "x", "=", "self", ".", "avgpool1", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout1", "(", "x", ")", "\n", "\n", "# Block2", "\n", "x", "=", "self", ".", "pad_depthwise2", "(", "x", ")", "\n", "x", "=", "self", ".", "depthwise_conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "pointwise_conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "batchnorm2", "(", "x", ")", "\n", "x", "=", "self", ".", "activation2", "(", "x", ")", "\n", "x", "=", "self", ".", "padpool2", "(", "x", ")", "\n", "x", "=", "self", ".", "avgpool2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout2", "(", "x", ")", "\n", "\n", "# Reshape", "\n", "x", "=", "x", ".", "view", "(", "self", ".", "batch_size", ",", "-", "1", ")", "\n", "# Output", "\n", "x", "=", "self", ".", "output_layer", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n", "", "def", "get_nb_features_output_layer", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return number of features passed into the output layer of the network \n        \"\"\"", "\n", "# 4 channels before the output layer ", "\n", "return", "4", "*", "self", ".", "timesamples", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.EEGModels.EEGNet": [[55, 156], ["tensorflow.keras.layers.Input", "tensorflow.keras.models.Model", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.DepthwiseConv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.AveragePooling2D", "dropoutType", "tensorflow.keras.layers.SeparableConv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.AveragePooling2D", "dropoutType", "tensorflow.keras.layers.Flatten", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Activation", "ValueError", "tensorflow.keras.constraints.max_norm", "tensorflow.keras.constraints.max_norm"], "function", ["None"], ["def", "EEGNet", "(", "nb_classes", ",", "Chans", "=", "64", ",", "Samples", "=", "128", ",", "\n", "dropoutRate", "=", "0.5", ",", "kernLength", "=", "64", ",", "F1", "=", "8", ",", "\n", "D", "=", "2", ",", "F2", "=", "16", ",", "norm_rate", "=", "0.25", ",", "dropoutType", "=", "'Dropout'", ")", ":", "\n", "    ", "\"\"\" Keras Implementation of EEGNet\n    http://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta\n\n    Note that this implements the newest version of EEGNet and NOT the earlier\n    version (version v1 and v2 on arxiv). We strongly recommend using this\n    architecture as it performs much better and has nicer properties than\n    our earlier version. For example:\n        \n        1. Depthwise Convolutions to learn spatial filters within a \n        temporal convolution. The use of the depth_multiplier option maps \n        exactly to the number of spatial filters learned within a temporal\n        filter. This matches the setup of algorithms like FBCSP which learn \n        spatial filters within each filter in a filter-bank. This also limits \n        the number of free parameters to fit when compared to a fully-connected\n        convolution. \n        \n        2. Separable Convolutions to learn how to optimally combine spatial\n        filters across temporal bands. Separable Convolutions are Depthwise\n        Convolutions followed by (1x1) Pointwise Convolutions. \n        \n    \n    While the original paper used Dropout, we found that SpatialDropout2D \n    sometimes produced slightly better results for classification of ERP \n    signals. However, SpatialDropout2D significantly reduced performance \n    on the Oscillatory dataset (SMR, BCI-IV Dataset 2A). We recommend using\n    the default Dropout in most cases.\n        \n    Assumes the input signal is sampled at 128Hz. If you want to use this model\n    for any other sampling rate you will need to modify the lengths of temporal\n    kernels and average pooling size in blocks 1 and 2 as needed (double the \n    kernel lengths for double the sampling rate, etc). Note that we haven't \n    tested the model performance with this rule so this may not work well. \n    \n    The model with default parameters gives the EEGNet-8,2 model as discussed\n    in the paper. This model should do pretty well in general, although it is\n\tadvised to do some model searching to get optimal performance on your\n\tparticular dataset.\n\n    We set F2 = F1 * D (number of input filters = number of output filters) for\n    the SeparableConv2D layer. We haven't extensively tested other values of this\n    parameter (say, F2 < F1 * D for compressed learning, and F2 > F1 * D for\n    overcomplete). We believe the main parameters to focus on are F1 and D. \n\n    Inputs:\n        \n      nb_classes      : int, number of classes to classify\n      Chans, Samples  : number of channels and time points in the EEG data\n      dropoutRate     : dropout fraction\n      kernLength      : length of temporal convolution in first layer. We found\n                        that setting this to be half the sampling rate worked\n                        well in practice. For the SMR dataset in particular\n                        since the data was high-passed at 4Hz we used a kernel\n                        length of 32.     \n      F1, F2          : number of temporal filters (F1) and number of pointwise\n                        filters (F2) to learn. Default: F1 = 8, F2 = F1 * D. \n      D               : number of spatial filters to learn within each temporal\n                        convolution. Default: D = 2\n      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n\n    \"\"\"", "\n", "\n", "if", "dropoutType", "==", "'SpatialDropout2D'", ":", "\n", "        ", "dropoutType", "=", "SpatialDropout2D", "\n", "", "elif", "dropoutType", "==", "'Dropout'", ":", "\n", "        ", "dropoutType", "=", "Dropout", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'dropoutType must be one of SpatialDropout2D '", "\n", "'or Dropout, passed as a string.'", ")", "\n", "\n", "", "input1", "=", "Input", "(", "shape", "=", "(", "Chans", ",", "Samples", ",", "1", ")", ")", "\n", "\n", "##################################################################", "\n", "block1", "=", "Conv2D", "(", "F1", ",", "(", "1", ",", "kernLength", ")", ",", "padding", "=", "'same'", ",", "\n", "input_shape", "=", "(", "Chans", ",", "Samples", ",", "1", ")", ",", "\n", "use_bias", "=", "False", ")", "(", "input1", ")", "\n", "block1", "=", "BatchNormalization", "(", ")", "(", "block1", ")", "\n", "block1", "=", "DepthwiseConv2D", "(", "(", "Chans", ",", "1", ")", ",", "use_bias", "=", "False", ",", "\n", "depth_multiplier", "=", "D", ",", "\n", "depthwise_constraint", "=", "max_norm", "(", "1.", ")", ")", "(", "block1", ")", "\n", "block1", "=", "BatchNormalization", "(", ")", "(", "block1", ")", "\n", "block1", "=", "Activation", "(", "'elu'", ")", "(", "block1", ")", "\n", "block1", "=", "AveragePooling2D", "(", "(", "1", ",", "4", ")", ")", "(", "block1", ")", "\n", "block1", "=", "dropoutType", "(", "dropoutRate", ")", "(", "block1", ")", "\n", "\n", "block2", "=", "SeparableConv2D", "(", "F2", ",", "(", "1", ",", "16", ")", ",", "\n", "use_bias", "=", "False", ",", "padding", "=", "'same'", ")", "(", "block1", ")", "\n", "block2", "=", "BatchNormalization", "(", ")", "(", "block2", ")", "\n", "block2", "=", "Activation", "(", "'elu'", ")", "(", "block2", ")", "\n", "block2", "=", "AveragePooling2D", "(", "(", "1", ",", "8", ")", ")", "(", "block2", ")", "\n", "block2", "=", "dropoutType", "(", "dropoutRate", ")", "(", "block2", ")", "\n", "\n", "flatten", "=", "Flatten", "(", "name", "=", "'flatten'", ")", "(", "block2", ")", "\n", "\n", "dense", "=", "Dense", "(", "nb_classes", ",", "name", "=", "'dense'", ",", "\n", "kernel_constraint", "=", "max_norm", "(", "norm_rate", ")", ")", "(", "flatten", ")", "\n", "softmax", "=", "Activation", "(", "'softmax'", ",", "name", "=", "'softmax'", ")", "(", "dense", ")", "\n", "\n", "return", "Model", "(", "inputs", "=", "input1", ",", "outputs", "=", "softmax", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.EEGModels.EEGNet_SSVEP": [[160, 221], ["tensorflow.keras.layers.Input", "tensorflow.keras.models.Model", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.DepthwiseConv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.AveragePooling2D", "dropoutType", "tensorflow.keras.layers.SeparableConv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.AveragePooling2D", "dropoutType", "tensorflow.keras.layers.Flatten", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Activation", "ValueError", "tensorflow.keras.constraints.max_norm"], "function", ["None"], ["", "def", "EEGNet_SSVEP", "(", "nb_classes", "=", "12", ",", "Chans", "=", "8", ",", "Samples", "=", "256", ",", "\n", "dropoutRate", "=", "0.5", ",", "kernLength", "=", "256", ",", "F1", "=", "96", ",", "\n", "D", "=", "1", ",", "F2", "=", "96", ",", "dropoutType", "=", "'Dropout'", ")", ":", "\n", "    ", "\"\"\" SSVEP Variant of EEGNet, as used in [1]. \n\n    Inputs:\n        \n      nb_classes      : int, number of classes to classify\n      Chans, Samples  : number of channels and time points in the EEG data\n      dropoutRate     : dropout fraction\n      kernLength      : length of temporal convolution in first layer\n      F1, F2          : number of temporal filters (F1) and number of pointwise\n                        filters (F2) to learn. \n      D               : number of spatial filters to learn within each temporal\n                        convolution.\n      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n      \n      \n    [1]. Waytowich, N. et. al. (2018). Compact Convolutional Neural Networks\n    for Classification of Asynchronous Steady-State Visual Evoked Potentials.\n    Journal of Neural Engineering vol. 15(6). \n    http://iopscience.iop.org/article/10.1088/1741-2552/aae5d8\n\n    \"\"\"", "\n", "\n", "if", "dropoutType", "==", "'SpatialDropout2D'", ":", "\n", "        ", "dropoutType", "=", "SpatialDropout2D", "\n", "", "elif", "dropoutType", "==", "'Dropout'", ":", "\n", "        ", "dropoutType", "=", "Dropout", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'dropoutType must be one of SpatialDropout2D '", "\n", "'or Dropout, passed as a string.'", ")", "\n", "\n", "", "input1", "=", "Input", "(", "shape", "=", "(", "Chans", ",", "Samples", ",", "1", ")", ")", "\n", "\n", "##################################################################", "\n", "block1", "=", "Conv2D", "(", "F1", ",", "(", "1", ",", "kernLength", ")", ",", "padding", "=", "'same'", ",", "\n", "input_shape", "=", "(", "Chans", ",", "Samples", ",", "1", ")", ",", "\n", "use_bias", "=", "False", ")", "(", "input1", ")", "\n", "block1", "=", "BatchNormalization", "(", ")", "(", "block1", ")", "\n", "block1", "=", "DepthwiseConv2D", "(", "(", "Chans", ",", "1", ")", ",", "use_bias", "=", "False", ",", "\n", "depth_multiplier", "=", "D", ",", "\n", "depthwise_constraint", "=", "max_norm", "(", "1.", ")", ")", "(", "block1", ")", "\n", "block1", "=", "BatchNormalization", "(", ")", "(", "block1", ")", "\n", "block1", "=", "Activation", "(", "'elu'", ")", "(", "block1", ")", "\n", "block1", "=", "AveragePooling2D", "(", "(", "1", ",", "4", ")", ")", "(", "block1", ")", "\n", "block1", "=", "dropoutType", "(", "dropoutRate", ")", "(", "block1", ")", "\n", "\n", "block2", "=", "SeparableConv2D", "(", "F2", ",", "(", "1", ",", "16", ")", ",", "\n", "use_bias", "=", "False", ",", "padding", "=", "'same'", ")", "(", "block1", ")", "\n", "block2", "=", "BatchNormalization", "(", ")", "(", "block2", ")", "\n", "block2", "=", "Activation", "(", "'elu'", ")", "(", "block2", ")", "\n", "block2", "=", "AveragePooling2D", "(", "(", "1", ",", "8", ")", ")", "(", "block2", ")", "\n", "block2", "=", "dropoutType", "(", "dropoutRate", ")", "(", "block2", ")", "\n", "\n", "flatten", "=", "Flatten", "(", "name", "=", "'flatten'", ")", "(", "block2", ")", "\n", "\n", "dense", "=", "Dense", "(", "nb_classes", ",", "name", "=", "'dense'", ")", "(", "flatten", ")", "\n", "softmax", "=", "Activation", "(", "'softmax'", ",", "name", "=", "'softmax'", ")", "(", "dense", ")", "\n", "\n", "return", "Model", "(", "inputs", "=", "input1", ",", "outputs", "=", "softmax", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.EEGModels.EEGNet_old": [[224, 282], ["tensorflow.keras.layers.Input", "tensorflow.keras.models.Model", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Permute", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Flatten", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Activation", "tensorflow.keras.regularizers.l1_l2", "tensorflow.keras.regularizers.l1_l2", "tensorflow.keras.regularizers.l1_l2"], "function", ["None"], ["", "def", "EEGNet_old", "(", "nb_classes", ",", "Chans", "=", "64", ",", "Samples", "=", "128", ",", "regRate", "=", "0.0001", ",", "\n", "dropoutRate", "=", "0.25", ",", "kernels", "=", "[", "(", "2", ",", "32", ")", ",", "(", "8", ",", "4", ")", "]", ",", "strides", "=", "(", "2", ",", "4", ")", ")", ":", "\n", "    ", "\"\"\" Keras Implementation of EEGNet_v1 (https://arxiv.org/abs/1611.08024v2)\n\n    This model is the original EEGNet model proposed on arxiv\n            https://arxiv.org/abs/1611.08024v2\n    \n    with a few modifications: we use striding instead of max-pooling as this \n    helped slightly in classification performance while also providing a \n    computational speed-up. \n    \n    Note that we no longer recommend the use of this architecture, as the new\n    version of EEGNet performs much better overall and has nicer properties.\n    \n    Inputs:\n        \n        nb_classes     : total number of final categories\n        Chans, Samples : number of EEG channels and samples, respectively\n        regRate        : regularization rate for L1 and L2 regularizations\n        dropoutRate    : dropout fraction\n        kernels        : the 2nd and 3rd layer kernel dimensions (default is \n                         the [2, 32] x [8, 4] configuration)\n        strides        : the stride size (note that this replaces the max-pool\n                         used in the original paper)\n    \n    \"\"\"", "\n", "\n", "# start the model", "\n", "input_main", "=", "Input", "(", "(", "Chans", ",", "Samples", ")", ")", "\n", "layer1", "=", "Conv2D", "(", "16", ",", "(", "Chans", ",", "1", ")", ",", "input_shape", "=", "(", "Chans", ",", "Samples", ",", "1", ")", ",", "\n", "kernel_regularizer", "=", "l1_l2", "(", "l1", "=", "regRate", ",", "l2", "=", "regRate", ")", ")", "(", "input_main", ")", "\n", "layer1", "=", "BatchNormalization", "(", ")", "(", "layer1", ")", "\n", "layer1", "=", "Activation", "(", "'elu'", ")", "(", "layer1", ")", "\n", "layer1", "=", "Dropout", "(", "dropoutRate", ")", "(", "layer1", ")", "\n", "\n", "permute_dims", "=", "2", ",", "1", ",", "3", "\n", "permute1", "=", "Permute", "(", "permute_dims", ")", "(", "layer1", ")", "\n", "\n", "layer2", "=", "Conv2D", "(", "4", ",", "kernels", "[", "0", "]", ",", "padding", "=", "'same'", ",", "\n", "kernel_regularizer", "=", "l1_l2", "(", "l1", "=", "0.0", ",", "l2", "=", "regRate", ")", ",", "\n", "strides", "=", "strides", ")", "(", "permute1", ")", "\n", "layer2", "=", "BatchNormalization", "(", ")", "(", "layer2", ")", "\n", "layer2", "=", "Activation", "(", "'elu'", ")", "(", "layer2", ")", "\n", "layer2", "=", "Dropout", "(", "dropoutRate", ")", "(", "layer2", ")", "\n", "\n", "layer3", "=", "Conv2D", "(", "4", ",", "kernels", "[", "1", "]", ",", "padding", "=", "'same'", ",", "\n", "kernel_regularizer", "=", "l1_l2", "(", "l1", "=", "0.0", ",", "l2", "=", "regRate", ")", ",", "\n", "strides", "=", "strides", ")", "(", "layer2", ")", "\n", "layer3", "=", "BatchNormalization", "(", ")", "(", "layer3", ")", "\n", "layer3", "=", "Activation", "(", "'elu'", ")", "(", "layer3", ")", "\n", "layer3", "=", "Dropout", "(", "dropoutRate", ")", "(", "layer3", ")", "\n", "\n", "flatten", "=", "Flatten", "(", "name", "=", "'flatten'", ")", "(", "layer3", ")", "\n", "\n", "dense", "=", "Dense", "(", "nb_classes", ",", "name", "=", "'dense'", ")", "(", "flatten", ")", "\n", "softmax", "=", "Activation", "(", "'softmax'", ",", "name", "=", "'softmax'", ")", "(", "dense", ")", "\n", "\n", "return", "Model", "(", "inputs", "=", "input_main", ",", "outputs", "=", "softmax", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.EEGModels.DeepConvNet": [[285, 349], ["tensorflow.keras.layers.Input", "tensorflow.keras.models.Model", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.MaxPooling2D", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.MaxPooling2D", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.MaxPooling2D", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.MaxPooling2D", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Flatten", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Activation", "tensorflow.keras.constraints.max_norm", "tensorflow.keras.constraints.max_norm", "tensorflow.keras.constraints.max_norm", "tensorflow.keras.constraints.max_norm", "tensorflow.keras.constraints.max_norm", "tensorflow.keras.constraints.max_norm"], "function", ["None"], ["", "def", "DeepConvNet", "(", "nb_classes", ",", "Chans", "=", "64", ",", "Samples", "=", "256", ",", "\n", "dropoutRate", "=", "0.5", ")", ":", "\n", "    ", "\"\"\" Keras implementation of the Deep Convolutional Network as described in\n    Schirrmeister et. al. (2017), Human Brain Mapping.\n    \n    This implementation assumes the input is a 2-second EEG signal sampled at \n    128Hz, as opposed to signals sampled at 250Hz as described in the original\n    paper. We also perform temporal convolutions of length (1, 5) as opposed\n    to (1, 10) due to this sampling rate difference. \n    \n    Note that we use the max_norm constraint on all convolutional layers, as \n    well as the classification layer. We also change the defaults for the\n    BatchNormalization layer. We used this based on a personal communication \n    with the original authors.\n    \n                      ours        original paper\n    pool_size        1, 2        1, 3\n    strides          1, 2        1, 3\n    conv filters     1, 5        1, 10\n    \n    Note that this implementation has not been verified by the original \n    authors. \n    \n    \"\"\"", "\n", "\n", "# start the model", "\n", "input_main", "=", "Input", "(", "(", "Chans", ",", "Samples", ",", "1", ")", ")", "\n", "block1", "=", "Conv2D", "(", "25", ",", "(", "1", ",", "5", ")", ",", "\n", "input_shape", "=", "(", "Chans", ",", "Samples", ",", "1", ")", ",", "\n", "kernel_constraint", "=", "max_norm", "(", "2.", ",", "axis", "=", "(", "0", ",", "1", ",", "2", ")", ")", ")", "(", "input_main", ")", "\n", "block1", "=", "Conv2D", "(", "25", ",", "(", "Chans", ",", "1", ")", ",", "\n", "kernel_constraint", "=", "max_norm", "(", "2.", ",", "axis", "=", "(", "0", ",", "1", ",", "2", ")", ")", ")", "(", "block1", ")", "\n", "block1", "=", "BatchNormalization", "(", "epsilon", "=", "1e-05", ",", "momentum", "=", "0.1", ")", "(", "block1", ")", "\n", "block1", "=", "Activation", "(", "'elu'", ")", "(", "block1", ")", "\n", "block1", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "1", ",", "2", ")", ",", "strides", "=", "(", "1", ",", "2", ")", ")", "(", "block1", ")", "\n", "block1", "=", "Dropout", "(", "dropoutRate", ")", "(", "block1", ")", "\n", "\n", "block2", "=", "Conv2D", "(", "50", ",", "(", "1", ",", "5", ")", ",", "\n", "kernel_constraint", "=", "max_norm", "(", "2.", ",", "axis", "=", "(", "0", ",", "1", ",", "2", ")", ")", ")", "(", "block1", ")", "\n", "block2", "=", "BatchNormalization", "(", "epsilon", "=", "1e-05", ",", "momentum", "=", "0.1", ")", "(", "block2", ")", "\n", "block2", "=", "Activation", "(", "'elu'", ")", "(", "block2", ")", "\n", "block2", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "1", ",", "2", ")", ",", "strides", "=", "(", "1", ",", "2", ")", ")", "(", "block2", ")", "\n", "block2", "=", "Dropout", "(", "dropoutRate", ")", "(", "block2", ")", "\n", "\n", "block3", "=", "Conv2D", "(", "100", ",", "(", "1", ",", "5", ")", ",", "\n", "kernel_constraint", "=", "max_norm", "(", "2.", ",", "axis", "=", "(", "0", ",", "1", ",", "2", ")", ")", ")", "(", "block2", ")", "\n", "block3", "=", "BatchNormalization", "(", "epsilon", "=", "1e-05", ",", "momentum", "=", "0.1", ")", "(", "block3", ")", "\n", "block3", "=", "Activation", "(", "'elu'", ")", "(", "block3", ")", "\n", "block3", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "1", ",", "2", ")", ",", "strides", "=", "(", "1", ",", "2", ")", ")", "(", "block3", ")", "\n", "block3", "=", "Dropout", "(", "dropoutRate", ")", "(", "block3", ")", "\n", "\n", "block4", "=", "Conv2D", "(", "200", ",", "(", "1", ",", "5", ")", ",", "\n", "kernel_constraint", "=", "max_norm", "(", "2.", ",", "axis", "=", "(", "0", ",", "1", ",", "2", ")", ")", ")", "(", "block3", ")", "\n", "block4", "=", "BatchNormalization", "(", "epsilon", "=", "1e-05", ",", "momentum", "=", "0.1", ")", "(", "block4", ")", "\n", "block4", "=", "Activation", "(", "'elu'", ")", "(", "block4", ")", "\n", "block4", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "1", ",", "2", ")", ",", "strides", "=", "(", "1", ",", "2", ")", ")", "(", "block4", ")", "\n", "block4", "=", "Dropout", "(", "dropoutRate", ")", "(", "block4", ")", "\n", "\n", "flatten", "=", "Flatten", "(", ")", "(", "block4", ")", "\n", "\n", "dense", "=", "Dense", "(", "nb_classes", ",", "kernel_constraint", "=", "max_norm", "(", "0.5", ")", ")", "(", "flatten", ")", "\n", "softmax", "=", "Activation", "(", "'softmax'", ")", "(", "dense", ")", "\n", "\n", "return", "Model", "(", "inputs", "=", "input_main", ",", "outputs", "=", "softmax", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.EEGModels.square": [[352, 354], ["tensorflow.keras.backend.square"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.EEGModels.square"], ["", "def", "square", "(", "x", ")", ":", "\n", "    ", "return", "K", ".", "square", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.EEGModels.log": [[355, 357], ["tensorflow.keras.backend.log", "tensorflow.keras.backend.clip"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.EEGModels.log"], ["", "def", "log", "(", "x", ")", ":", "\n", "    ", "return", "K", ".", "log", "(", "K", ".", "clip", "(", "x", ",", "min_value", "=", "1e-7", ",", "max_value", "=", "10000", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.EEGModels.ShallowConvNet": [[359, 401], ["tensorflow.keras.layers.Input", "tensorflow.keras.models.Model", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.AveragePooling2D", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Flatten", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Activation", "tensorflow.keras.constraints.max_norm", "tensorflow.keras.constraints.max_norm", "tensorflow.keras.constraints.max_norm"], "function", ["None"], ["", "def", "ShallowConvNet", "(", "nb_classes", ",", "Chans", "=", "64", ",", "Samples", "=", "128", ",", "dropoutRate", "=", "0.5", ")", ":", "\n", "    ", "\"\"\" Keras implementation of the Shallow Convolutional Network as described\n    in Schirrmeister et. al. (2017), Human Brain Mapping.\n    \n    Assumes the input is a 2-second EEG signal sampled at 128Hz. Note that in \n    the original paper, they do temporal convolutions of length 25 for EEG\n    data sampled at 250Hz. We instead use length 13 since the sampling rate is \n    roughly half of the 250Hz which the paper used. The pool_size and stride\n    in later layers is also approximately half of what is used in the paper.\n    \n    Note that we use the max_norm constraint on all convolutional layers, as \n    well as the classification layer. We also change the defaults for the\n    BatchNormalization layer. We used this based on a personal communication \n    with the original authors.\n    \n                     ours        original paper\n    pool_size        1, 35       1, 75\n    strides          1, 7        1, 15\n    conv filters     1, 13       1, 25    \n    \n    Note that this implementation has not been verified by the original \n    authors. We do note that this implementation reproduces the results in the\n    original paper with minor deviations. \n    \"\"\"", "\n", "\n", "# start the model", "\n", "input_main", "=", "Input", "(", "(", "Chans", ",", "Samples", ",", "1", ")", ")", "\n", "block1", "=", "Conv2D", "(", "40", ",", "(", "1", ",", "13", ")", ",", "\n", "input_shape", "=", "(", "Chans", ",", "Samples", ",", "1", ")", ",", "\n", "kernel_constraint", "=", "max_norm", "(", "2.", ",", "axis", "=", "(", "0", ",", "1", ",", "2", ")", ")", ")", "(", "input_main", ")", "\n", "block1", "=", "Conv2D", "(", "40", ",", "(", "Chans", ",", "1", ")", ",", "use_bias", "=", "False", ",", "\n", "kernel_constraint", "=", "max_norm", "(", "2.", ",", "axis", "=", "(", "0", ",", "1", ",", "2", ")", ")", ")", "(", "block1", ")", "\n", "block1", "=", "BatchNormalization", "(", "epsilon", "=", "1e-05", ",", "momentum", "=", "0.1", ")", "(", "block1", ")", "\n", "block1", "=", "Activation", "(", "square", ")", "(", "block1", ")", "\n", "block1", "=", "AveragePooling2D", "(", "pool_size", "=", "(", "1", ",", "35", ")", ",", "strides", "=", "(", "1", ",", "7", ")", ")", "(", "block1", ")", "\n", "block1", "=", "Activation", "(", "log", ")", "(", "block1", ")", "\n", "block1", "=", "Dropout", "(", "dropoutRate", ")", "(", "block1", ")", "\n", "flatten", "=", "Flatten", "(", ")", "(", "block1", ")", "\n", "dense", "=", "Dense", "(", "nb_classes", ",", "kernel_constraint", "=", "max_norm", "(", "0.5", ")", ")", "(", "flatten", ")", "\n", "softmax", "=", "Activation", "(", "'softmax'", ")", "(", "dense", ")", "\n", "\n", "return", "Model", "(", "inputs", "=", "input_main", ",", "outputs", "=", "softmax", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.custom_losses.angle_loss": [[6, 20], ["torch.mean", "torch.square", "torch.abs", "torch.atan2", "torch.sin", "torch.cos"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.EEGNet.EEGModels.square"], ["def", "angle_loss", "(", "a", ",", "b", ")", ":", "\n", "    ", "\"\"\"\n    Custom loss function for models that predict the angle on the fix-sacc-fix dataset\n    Angles -pi and pi should lead to 0 loss, since this is actually the same angle on the unit circle\n    Angles pi/2 and -pi/2 should lead to a large loss, since this is a difference by pi on the unit circle\n    Therefore we compute the absolute error of the \"shorter\" direction on the unit circle\n\n    Inputs:\n    a: predicted angle in rad\n    b: target angle in rad \n\n    Output: reduced angle diff MSE of the batch \n    \"\"\"", "\n", "return", "torch", ".", "mean", "(", "torch", ".", "square", "(", "torch", ".", "abs", "(", "torch", ".", "atan2", "(", "torch", ".", "sin", "(", "a", "-", "b", ")", ",", "torch", ".", "cos", "(", "a", "-", "b", ")", ")", ")", ")", ")", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.plot.plot_from_csv": [[6, 30], ["logging.info", "numpy.loadtxt", "numpy.arange", "matplotlib.figure", "matplotlib.plot", "matplotlib.legend", "matplotlib.xlabel", "len", "matplotlib.title", "matplotlib.title", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.ylabel", "matplotlib.ylabel"], "function", ["None"], ["def", "plot_from_csv", "(", "file_path", ",", "output_dir", ",", "metric", ",", "savefig", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Plot the metric saved in the file_path file \n    \"\"\"", "\n", "logging", ".", "info", "(", "\"Plotting metrics...\"", ")", "\n", "x", "=", "np", ".", "loadtxt", "(", "file_path", ",", "delimiter", "=", "','", ")", "\n", "epochs", "=", "np", ".", "arange", "(", "len", "(", "x", ")", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "if", "config", "[", "'pretrained'", "]", ":", "\n", "        ", "plt", ".", "title", "(", "\"Pretrained \"", "+", "config", "[", "'model'", "]", "+", "' loss'", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "title", "(", "config", "[", "'model'", "]", "+", "' loss'", ")", "\n", "", "plt", ".", "plot", "(", "epochs", ",", "x", ",", "'b-'", ",", "label", "=", "'validation'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "xlabel", "(", "'epochs'", ")", "\n", "\n", "if", "config", "[", "'task'", "]", "==", "'gaze-reg'", ":", "\n", "        ", "plt", ".", "ylabel", "(", "\"MSE\"", ")", "\n", "", "elif", "config", "[", "'task'", "]", "==", "'angle-reg'", ":", "\n", "        ", "plt", ".", "ylabel", "(", "\"Mean Absolute Angle Error\"", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "ylabel", "(", "'Binary Cross Entropy Loss'", ")", "\n", "", "if", "savefig", ":", "\n", "        ", "plt", ".", "savefig", "(", "output_dir", "+", "'/plots/'", "+", "config", "[", "'model'", "]", "+", "'_val_'", "+", "metric", "+", "'.png'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.plot.plot_array": [[31, 56], ["logging.info", "numpy.arange", "matplotlib.figure", "matplotlib.plot", "matplotlib.legend", "matplotlib.xlabel", "len", "matplotlib.title", "matplotlib.title", "numpy.array", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.ylabel", "matplotlib.ylabel", "matplotlib.ylabel"], "function", ["None"], ["", "", "def", "plot_array", "(", "x", ",", "output_dir", ",", "metric", ",", "savefig", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Plot the metric saved in the file_path file \n    \"\"\"", "\n", "logging", ".", "info", "(", "\"Plotting metrics...\"", ")", "\n", "epochs", "=", "np", ".", "arange", "(", "len", "(", "x", ")", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "if", "config", "[", "'pretrained'", "]", ":", "\n", "        ", "plt", ".", "title", "(", "\"Pretrained \"", "+", "config", "[", "'model'", "]", "+", "\" \"", "+", "metric", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "title", "(", "config", "[", "'model'", "]", "+", "\" \"", "+", "metric", ")", "\n", "", "plt", ".", "plot", "(", "epochs", ",", "np", ".", "array", "(", "x", ")", ",", "'b-'", ",", "label", "=", "'validation'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "xlabel", "(", "'epochs'", ")", "\n", "\n", "if", "config", "[", "'task'", "]", "==", "'gaze-reg'", ":", "\n", "        ", "plt", ".", "ylabel", "(", "\"MSE\"", ")", "\n", "", "elif", "metric", "==", "'accuracy'", ":", "\n", "        ", "plt", ".", "ylabel", "(", "\"Accuracy\"", ")", "\n", "", "elif", "config", "[", "'task'", "]", "==", "'angle-reg'", ":", "\n", "        ", "plt", ".", "ylabel", "(", "\"Mean Absolute Angle Error\"", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "ylabel", "(", "'Binary Cross Entropy Loss'", ")", "\n", "", "if", "savefig", ":", "\n", "        ", "plt", ".", "savefig", "(", "output_dir", "+", "'/plots/'", "+", "config", "[", "'model'", "]", "+", "'_val_'", "+", "metric", "+", "'.png'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.plot.plot_metrics": [[57, 76], ["logging.info", "numpy.arange", "matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.legend", "matplotlib.xlabel", "matplotlib.ylabel", "len", "matplotlib.title", "matplotlib.title", "numpy.array", "numpy.array", "matplotlib.savefig", "str", "str"], "function", ["None"], ["", "", "def", "plot_metrics", "(", "train", ",", "val", ",", "output_dir", ",", "metric", ",", "model_number", "=", "0", ",", "savefig", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Plot the training and validation metric together in one image \n    \"\"\"", "\n", "logging", ".", "info", "(", "\"Plotting training and validation metrics ...\"", ")", "\n", "epochs", "=", "np", ".", "arange", "(", "len", "(", "train", ")", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "if", "config", "[", "'pretrained'", "]", ":", "\n", "        ", "plt", ".", "title", "(", "\"Pretrained \"", "+", "config", "[", "'model'", "]", "+", "\" \"", "+", "metric", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "title", "(", "config", "[", "'model'", "]", "+", "\" \"", "+", "str", "(", "model_number", ")", "+", "\" \"", "+", "metric", ")", "\n", "", "plt", ".", "plot", "(", "epochs", ",", "np", ".", "array", "(", "train", ")", ",", "'b-'", ",", "label", "=", "'train'", ")", "\n", "plt", ".", "plot", "(", "epochs", ",", "np", ".", "array", "(", "val", ")", ",", "'g-'", ",", "label", "=", "'validation'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "xlabel", "(", "'epochs'", ")", "\n", "plt", ".", "ylabel", "(", "metric", ")", "\n", "\n", "if", "savefig", ":", "\n", "        ", "plt", ".", "savefig", "(", "output_dir", "+", "'/plots/'", "+", "config", "[", "'model'", "]", "+", "'_'", "+", "str", "(", "model_number", ")", "+", "\"_\"", "+", "metric", "+", "'.png'", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.training.train_loop": [[6, 48], ["len", "len", "enumerate", "logging.info", "torch.cuda.is_available", "model", "loss_fn", "optimizer.zero_grad", "loss_fn.backward", "optimizer.step", "loss_fn.item", "torch.cuda.empty_cache", "logging.info", "float", "X.cuda.cuda", "y.view.cuda", "len", "y.view.view", "float", "float", "y.view.size"], "function", ["None"], ["def", "train_loop", "(", "dataloader", ",", "model", ",", "loss_name", ",", "loss_fn", ",", "optimizer", ")", ":", "\n", "    ", "\"\"\"\n    Performs one epoch of training the model through the dataset stored in dataloader, predicting one batch at a time \n    Using the given loss_fn and optimizer\n    Returns training metrics (loss for regressions, loss and accuracy for classification) of the epoch \n    This function is called by BaseNet each epoch \n    \"\"\"", "\n", "size", "=", "len", "(", "dataloader", ")", "\n", "num_datapoints", "=", "len", "(", "dataloader", ".", "dataset", ")", "\n", "training_loss", ",", "correct", "=", "0", ",", "0", "\n", "for", "batch", ",", "(", "X", ",", "y", ")", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "# Move tensors to GPU", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "X", "=", "X", ".", "cuda", "(", ")", "\n", "y", "=", "y", ".", "cuda", "(", ")", "\n", "# Compute prediction and loss", "\n", "", "pred", "=", "model", "(", "X", ")", "\n", "\n", "if", "len", "(", "y", ".", "size", "(", ")", ")", "==", "1", ":", "\n", "            ", "y", "=", "y", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "", "loss", "=", "loss_fn", "(", "pred", ",", "y", ")", "\n", "# Backpropagation and optimization ", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "# Add up metrics", "\n", "training_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "loss_name", "==", "'bce'", ":", "\n", "            ", "pred", "=", "(", "pred", ">", "0.5", ")", ".", "float", "(", ")", "\n", "correct", "+=", "(", "pred", "==", "y", ")", ".", "float", "(", ")", ".", "sum", "(", ")", "\n", "# Remove batch from gpu", "\n", "", "del", "X", "\n", "del", "y", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "loss", "=", "training_loss", "/", "size", "\n", "logging", ".", "info", "(", "f\"Avg training loss: {loss:>7f}\"", ")", "\n", "if", "config", "[", "'task'", "]", "==", "'LR_task'", ":", "\n", "        ", "accuracy", "=", "correct", "/", "num_datapoints", "\n", "logging", ".", "info", "(", "f\"Avg training accuracy {accuracy:>8f}\"", ")", "\n", "return", "float", "(", "loss", ")", ",", "float", "(", "accuracy", ")", "\n", "", "return", "float", "(", "loss", ")", ",", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.training.validation_loop": [[49, 88], ["len", "len", "logging.info", "torch.no_grad", "enumerate", "logging.info", "float", "torch.cuda.is_available", "model", "loss_fn().item", "torch.cuda.empty_cache", "float", "float", "X.cuda.cuda", "y.view.cuda", "len", "y.view.view", "y.view.size", "loss_fn"], "function", ["None"], ["", "def", "validation_loop", "(", "dataloader", ",", "model", ",", "loss_name", ",", "loss_fn", ")", ":", "\n", "    ", "\"\"\"\n    Performs one prediction through the validation set set stored in the given dataloader\n    Returns training metrics (loss for regressions, loss and accuracy for classification) of the epoch \n    This function is called by BaseNet each epoch, an early stopping is implemented on the returned validation loss \n    \"\"\"", "\n", "num_batches", "=", "len", "(", "dataloader", ")", "\n", "size", "=", "len", "(", "dataloader", ".", "dataset", ")", "\n", "\n", "val_loss", ",", "correct", "=", "0", ",", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", ",", "(", "X", ",", "y", ")", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "# Move tensors to GPU", "\n", "            ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "X", "=", "X", ".", "cuda", "(", ")", "\n", "y", "=", "y", ".", "cuda", "(", ")", "\n", "# Predict ", "\n", "", "pred", "=", "model", "(", "X", ")", "\n", "\n", "if", "len", "(", "y", ".", "size", "(", ")", ")", "==", "1", ":", "\n", "                ", "y", "=", "y", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n", "# Compute metrics", "\n", "", "val_loss", "+=", "loss_fn", "(", "pred", ",", "y", ")", ".", "item", "(", ")", "\n", "if", "loss_name", "==", "'bce'", ":", "\n", "                ", "pred", "=", "(", "pred", ">", "0.5", ")", ".", "float", "(", ")", "\n", "correct", "+=", "(", "pred", "==", "y", ")", ".", "float", "(", ")", ".", "sum", "(", ")", "\n", "# Remove batch from gpu", "\n", "", "del", "X", "\n", "del", "y", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "", "loss", "=", "val_loss", "/", "num_batches", "\n", "logging", ".", "info", "(", "f\"Avg validation loss: {loss:>8f}\"", ")", "\n", "if", "config", "[", "'task'", "]", "==", "'LR_task'", ":", "\n", "        ", "accuracy", "=", "correct", "/", "size", "\n", "logging", ".", "info", "(", "f\"Avg validation accuracy {accuracy:>8f}\"", ")", "\n", "return", "float", "(", "loss", ")", ",", "float", "(", "accuracy", ")", "\n", "", "return", "float", "(", "loss", ")", ",", "-", "1", "# Can be used for early stopping", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.training.test_loop": [[90, 116], ["len", "len", "torch.cat.data.numpy", "torch.no_grad", "enumerate", "torch.cuda.is_available", "model", "torch.cuda.empty_cache", "X.cuda.cuda", "model.cpu", "torch.cat", "model.cpu"], "function", ["None"], ["", "def", "test_loop", "(", "dataloader", ",", "model", ")", ":", "\n", "    ", "\"\"\"\n    Performs one prediction through the validation set set stored in the given dataloader\n    Returns training metrics (loss for regressions, loss and accuracy for classification) of the epoch\n    This function is called by BaseNet each epoch, an early stopping is implemented on the returned validation loss\n    \"\"\"", "\n", "num_batches", "=", "len", "(", "dataloader", ")", "\n", "size", "=", "len", "(", "dataloader", ".", "dataset", ")", "\n", "\n", "val_loss", ",", "correct", "=", "0", ",", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", ",", "(", "X", ",", "_", ")", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "# Move tensors to GPU", "\n", "            ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "X", "=", "X", ".", "cuda", "(", ")", "\n", "# Predict", "\n", "", "pred", "=", "model", "(", "X", ")", "\n", "#print(pred.shape)", "\n", "#print(pred.detach().numpy().ravel().shape)", "\n", "if", "batch", "==", "0", ":", "\n", "                ", "all_pred", "=", "pred", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "                ", "all_pred", "=", "torch", ".", "cat", "(", "(", "all_pred", ",", "pred", ".", "cpu", "(", ")", ")", ")", "\n", "", "del", "X", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "", "return", "all_pred", ".", "data", ".", "numpy", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.dataloader.create_dataloader": [[7, 27], ["torch.as_tensor().float", "torch.as_tensor().float", "torch.utils.data.TensorDataset", "torch.utils.data.DataLoader", "logging.info", "tensor_x.unsqueeze.unsqueeze", "torch.as_tensor", "torch.as_tensor"], "function", ["None"], ["def", "create_dataloader", "(", "X", ",", "y", ",", "batch_size", ",", "model_name", ",", "drop_last", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Input: X, y of type np.array\n    Return: pytorch dataloader containing the dataset of X and y that returns batches of size batch_size \n    \"\"\"", "\n", "# Transform np.array to torch flaot tensor", "\n", "tensor_x", "=", "torch", ".", "as_tensor", "(", "X", ")", ".", "float", "(", ")", "\n", "tensor_y", "=", "torch", ".", "as_tensor", "(", "y", ")", ".", "float", "(", ")", "\n", "# Unsqueeze channel direction for eegNet model", "\n", "if", "model_name", "==", "'EEGNet'", ":", "\n", "        ", "logging", ".", "info", "(", "f\"Unsqueeze data for eegnet\"", ")", "\n", "tensor_x", "=", "tensor_x", ".", "unsqueeze", "(", "1", ")", "\n", "# Log the shapes", "\n", "#logging.info(f\"Tensor x {mode} size: {tensor_x.size()}\")", "\n", "#logging.info(f\"Tensor y {mode} size: {tensor_y.size()}\")", "\n", "# Set device ", "\n", "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") ", "\n", "# Create dataset and dataloader ", "\n", "", "dataset", "=", "TensorDataset", "(", "tensor_x", ",", "tensor_y", ")", "\n", "return", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "drop_last", "=", "drop_last", ",", "num_workers", "=", "1", ")", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.utils.get_gpu_memory": [[9, 19], ["print", "_output_to_list", "int", "x.decode().split", "subprocess.check_output", "enumerate", "COMMAND.split", "x.split", "x.decode"], "function", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.ml_utils.split", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.ml_utils.split", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tuningML.ml_utils.split"], ["#import torch", "\n", "#import pandas as pd", "\n", "#import math", "\n", "#from sklearn.utils import shuffle", "\n", "#from sklearn.model_selection import train_test_split", "\n", "#import os", "\n", "#from subprocess import call", "\n", "import", "operator", "\n", "#import shutil", "\n", "#import main cyclic import!", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.utils.timing_decorator": [[20, 33], ["time.time", "func", "time.time", "print"], "function", ["None"], ["#sns.set_style('darkgrid')", "\n", "#import logging", "\n", "\n", "#def plot_acc(hist, output_directory, model, val=False):", "\n", "#    '''", "\n", "#    plot the accuracy against the epochs during training", "\n", "#    '''", "\n", "#    epochs = len(hist.history['accuracy'])", "\n", "#    epochs = np.arange(epochs)", "\n", "#    plt.figure()", "\n", "#   plt.title(model + ' accuracy')", "\n", "#    plt.plot(epochs, hist.history['accuracy'],'b-',label='training')", "\n", "#    if val:", "\n", "#        plt.plot(epochs, hist.history['val_accuracy'],'g-',label='validation')", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.utils.compute_loss": [[35, 61], ["len", "enumerate", "print", "torch.cuda.is_available", "torch.div().float", "loss_fn", "y.cuda.cuda", "torch.div"], "function", ["None"], ["#    plt.legend()", "\n", "#    plt.xlabel('epochs')", "\n", "#    plt.ylabel('Accuracy')", "\n", "#    plt.savefig(output_directory + '/' + model + '_accuracy.png')", "\n", "#    # plt.show()", "\n", "#    logging.info(10*'*'+'\\n')", "\n", "\n", "\n", "#def plot_loss(hist, output_directory, model, val=False, savefig=True):", "\n", "#    \"\"\"", "\n", "#    Plot loss function of the trained model over the epochs", "\n", "#    Works for both classification and regression, set config.py accordingly", "\n", "#    \"\"\"", "\n", "#", "\n", "#    \"\"\"", "\n", "#    if config['task'] != 'prosaccade-clf':", "\n", "#        metric = \"loss\"", "\n", "#    else:", "\n", "#        metric = 'accuracy'", "\n", "#    \"\"\"", "\n", "\n", "#    epochs = len(hist.history['loss'])", "\n", "#    epochs = np.arange(epochs)", "\n", "\n", "#    plt.figure()", "\n", "#    if config['pretrained']:", "\n", "#        plt.title(\"Pretrained \" + model + ' loss')", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.utils.compute_accuracy": [[63, 87], ["len", "enumerate", "torch.cuda.is_available", "torch.div().float", "torch.round", "y.cuda.cuda", "torch.div"], "function", ["None"], ["#        plt.title(model + ' loss')", "\n", "#    # plot the training curve", "\n", "#    plt.plot(epochs, np.array(hist.history['loss']), 'b-', label='training')", "\n", "#    # plot the validation curve", "\n", "#    if val:", "\n", "#        plt.plot(epochs, np.array(hist.history['val_loss']),'g-',label='validation')", "\n", "#    plt.legend()", "\n", "#    plt.xlabel('epochs')", "\n", "\n", "#    if config['task'] == 'gaze-reg':", "\n", "#        plt.ylabel(\"MSE\")", "\n", "#     elif config['task'] == 'angle-reg':", "\n", "#         plt.ylabel(\"Mean Absolute Angle Error\")", "\n", "#     else:", "\n", "#         plt.ylabel('Binary Cross Entropy Loss')", "\n", "#", "\n", "#", "\n", "#     if savefig:", "\n", "#         plt.savefig(output_directory + '/' + model + '_loss.png')", "\n", "#     #plt.show()", "\n", "\n", "# def plot_loss_torch(loss, output_directory, model):", "\n", "#     epochs=np.arange(len(loss))", "\n", "#     plt.figure()", "\n", "#     plt.title(model + ' loss')", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.torch_utils.utils.sum_predictions": [[88, 108], ["torch.no_grad", "enumerate", "torch.cuda.is_available", "model", "torch.cuda.empty_cache", "X.cuda", "y.cuda", "prediction_list.append"], "function", ["None"], ["#     plt.plot(epochs, loss, 'b-', label='training')", "\n", "#     plt.legend()", "\n", "#     plt.xlabel('epochs')", "\n", "#     plt.ylabel('Binary Cross Entropy')", "\n", "#     plt.savefig(output_directory + '/' + model + 'loss.png')", "\n", "#     # plt.show()", "\n", "#", "\n", "#", "\n", "# def cp_dir(source, target):", "\n", "#     call(['cp', '-a', source, target])", "\n", "#", "\n", "# def comparison_plot_accuracy():", "\n", "#", "\n", "#     run_dir = './results/OHBM/'", "\n", "#     print(run_dir)", "\n", "#     plt.figure()", "\n", "#     plt.title('Comparison of the validation accuracy' )", "\n", "#     plt.grid(True)", "\n", "#     plt.xlabel('epochs')", "\n", "#     plt.ylabel('accuracy (%)')", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.ConvNet.ConvNet.__init__": [[9, 27], ["abc.ABC.__init__", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "str", "str", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_shape", ",", "output_shape", ",", "loss", ",", "kernel_size", "=", "32", ",", "nb_filters", "=", "32", ",", "verbose", "=", "True", ",", "batch_size", "=", "64", ",", "\n", "use_residual", "=", "False", ",", "depth", "=", "6", ",", "epochs", "=", "2", ",", "preprocessing", "=", "False", ",", "model_number", "=", "0", ")", ":", "\n", "        ", "self", ".", "use_residual", "=", "use_residual", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "callbacks", "=", "None", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "nb_filters", "=", "nb_filters", "\n", "self", ".", "preprocessing", "=", "preprocessing", "\n", "self", ".", "input_shape", "=", "input_shape", "\n", "super", "(", "ConvNet", ",", "self", ")", ".", "__init__", "(", "input_shape", "=", "input_shape", ",", "output_shape", "=", "output_shape", ",", "loss", "=", "loss", ",", "epochs", "=", "epochs", ",", "verbose", "=", "verbose", ",", "model_number", "=", "model_number", ")", "\n", "logging", ".", "info", "(", "'Parameters of {}, model number {}: '", ".", "format", "(", "self", ",", "model_number", ")", ")", "\n", "logging", ".", "info", "(", "'--------------- use residual : '", "+", "str", "(", "self", ".", "use_residual", ")", ")", "\n", "logging", ".", "info", "(", "'--------------- depth        : '", "+", "str", "(", "self", ".", "depth", ")", ")", "\n", "logging", ".", "info", "(", "'--------------- batch size   : '", "+", "str", "(", "self", ".", "batch_size", ")", ")", "\n", "logging", ".", "info", "(", "'--------------- kernel size  : '", "+", "str", "(", "self", ".", "kernel_size", ")", ")", "\n", "logging", ".", "info", "(", "'--------------- nb filters   : '", "+", "str", "(", "self", ".", "nb_filters", ")", ")", "\n", "logging", ".", "info", "(", "'--------------- preprocessing: '", "+", "str", "(", "self", ".", "preprocessing", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.ConvNet.ConvNet._preprocessing": [[29, 31], ["None"], "methods", ["None"], ["", "def", "_preprocessing", "(", "self", ",", "input_tensor", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.ConvNet.ConvNet._module": [[33, 35], ["None"], "methods", ["None"], ["", "def", "_module", "(", "self", ",", "input_tensor", ",", "current_depth", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.ConvNet.ConvNet._shortcut_layer": [[36, 42], ["tensorflow.keras.layers.Conv1D", "tensorflow.keras.layers.Conv1D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.layers.Add", "tensorflow.layers.Add", "tensorflow.layers.Activation", "tensorflow.layers.Activation", "int"], "methods", ["None"], ["", "def", "_shortcut_layer", "(", "self", ",", "input_tensor", ",", "out_tensor", ")", ":", "\n", "        ", "shortcut_y", "=", "tf", ".", "keras", ".", "layers", ".", "Conv1D", "(", "filters", "=", "int", "(", "out_tensor", ".", "shape", "[", "-", "1", "]", ")", ",", "kernel_size", "=", "1", ",", "padding", "=", "'same'", ",", "use_bias", "=", "False", ")", "(", "input_tensor", ")", "\n", "shortcut_y", "=", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "shortcut_y", ")", "\n", "x", "=", "keras", ".", "layers", ".", "Add", "(", ")", "(", "[", "shortcut_y", ",", "out_tensor", "]", ")", "\n", "x", "=", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.ConvNet.ConvNet._build_model": [[43, 73], ["tensorflow.keras.layers.Input", "tensorflow.keras.layers.Input", "range", "tensorflow.keras.models.Model", "tensorflow.keras.models.Model", "ConvNet.ConvNet._preprocessing", "ConvNet.ConvNet._module", "tensorflow.keras.layers.GlobalAveragePooling1D", "tensorflow.keras.layers.GlobalAveragePooling1D", "ConvNet.ConvNet._shortcut_layer", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "ValueError", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.ConvNet.ConvNet._preprocessing", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.ConvNet.ConvNet._module", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.ConvNet.ConvNet._shortcut_layer"], ["", "def", "_build_model", "(", "self", ",", "X", "=", "[", "]", ")", ":", "\n", "        ", "input_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Input", "(", "self", ".", "input_shape", ")", "\n", "\n", "if", "self", ".", "preprocessing", ":", "\n", "            ", "preprocessed", "=", "self", ".", "_preprocessing", "(", "input_layer", ")", "\n", "x", "=", "preprocessed", "\n", "input_res", "=", "preprocessed", "\n", "", "else", ":", "\n", "            ", "x", "=", "input_layer", "\n", "input_res", "=", "input_layer", "\n", "\n", "", "for", "d", "in", "range", "(", "self", ".", "depth", ")", ":", "\n", "            ", "x", "=", "self", ".", "_module", "(", "x", ",", "d", ")", "\n", "if", "self", ".", "use_residual", "and", "d", "%", "3", "==", "2", ":", "\n", "                ", "x", "=", "self", ".", "_shortcut_layer", "(", "input_res", ",", "x", ")", "\n", "input_res", "=", "x", "\n", "\n", "", "", "gap_layer", "=", "tf", ".", "keras", ".", "layers", ".", "GlobalAveragePooling1D", "(", ")", "(", "x", ")", "\n", "\n", "if", "self", ".", "loss", "==", "'bce'", ":", "\n", "            ", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "output_shape", ",", "activation", "=", "'sigmoid'", ")", "(", "gap_layer", ")", "\n", "", "elif", "self", ".", "loss", "==", "'mse'", ":", "\n", "            ", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "output_shape", ",", "activation", "=", "'linear'", ")", "(", "gap_layer", ")", "\n", "", "elif", "self", ".", "loss", "==", "'angle-loss'", ":", "\n", "            ", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "output_shape", ",", "activation", "=", "'linear'", ")", "(", "gap_layer", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Choose valid loss function\"", ")", "\n", "\n", "", "model", "=", "tf", ".", "keras", ".", "models", ".", "Model", "(", "inputs", "=", "input_layer", ",", "outputs", "=", "output_layer", ")", "\n", "return", "model", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.BaseNet.prediction_history.__init__": [[12, 16], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "validation_data", ")", ":", "\n", "        ", "self", ".", "validation_data", "=", "validation_data", "\n", "self", ".", "predhis", "=", "[", "]", "\n", "self", ".", "targets", "=", "validation_data", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.BaseNet.prediction_history.on_epoch_end": [[17, 20], ["BaseNet.prediction_history.model.predict", "BaseNet.prediction_history.predhis.append"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.predict"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "y_pred", "=", "self", ".", "model", ".", "predict", "(", "self", ".", "validation_data", "[", "0", "]", ")", "\n", "self", ".", "predhis", ".", "append", "(", "y_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.BaseNet.BaseNet.__init__": [[23, 50], ["BaseNet.BaseNet._build_model", "logging.info", "logging.info", "BaseNet.BaseNet.model.compile", "BaseNet.BaseNet.model.compile", "tensorflow.optimizers.Adam", "tensorflow.optimizers.Adam", "BaseNet.BaseNet.model.compile", "ValueError", "numpy.sum", "numpy.sum", "tensorflow.optimizers.Adam", "tensorflow.optimizers.Adam", "tensorflow.optimizers.Adam", "tensorflow.optimizers.Adam", "numpy.prod", "numpy.prod", "v.get_shape", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.BaseNet.BaseNet._build_model"], ["    ", "def", "__init__", "(", "self", ",", "loss", ",", "input_shape", ",", "output_shape", ",", "epochs", "=", "50", ",", "verbose", "=", "True", ",", "model_number", "=", "0", ")", ":", "\n", "        ", "self", ".", "epochs", "=", "epochs", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "model_number", "=", "model_number", "\n", "self", ".", "input_shape", "=", "input_shape", "\n", "self", ".", "output_shape", "=", "output_shape", "\n", "self", ".", "loss", "=", "loss", "\n", "self", ".", "nb_channels", "=", "input_shape", "[", "1", "]", "\n", "self", ".", "timesamples", "=", "input_shape", "[", "0", "]", "\n", "self", ".", "model", "=", "self", ".", "_build_model", "(", ")", "\n", "\n", "# Compile the model depending on the task ", "\n", "if", "self", ".", "loss", "==", "'bce'", ":", "\n", "            ", "self", ".", "model", ".", "compile", "(", "loss", "=", "'binary_crossentropy'", ",", "optimizer", "=", "keras", ".", "optimizers", ".", "Adam", "(", "learning_rate", "=", "config", "[", "'learning_rate'", "]", ")", ",", "metrics", "=", "[", "'accuracy'", "]", ")", "\n", "", "elif", "self", ".", "loss", "==", "'mse'", ":", "\n", "            ", "self", ".", "model", ".", "compile", "(", "loss", "=", "'mean_squared_error'", ",", "optimizer", "=", "keras", ".", "optimizers", ".", "Adam", "(", "learning_rate", "=", "config", "[", "'learning_rate'", "]", ")", ",", "metrics", "=", "[", "'mean_squared_error'", "]", ")", "\n", "", "elif", "self", ".", "loss", "==", "'angle-loss'", ":", "\n", "            ", "from", "DL_Models", ".", "tf_models", ".", "utils", ".", "losses", "import", "angle_loss", "\n", "self", ".", "model", ".", "compile", "(", "loss", "=", "angle_loss", ",", "optimizer", "=", "keras", ".", "optimizers", ".", "Adam", "(", "learning_rate", "=", "config", "[", "'learning_rate'", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Choose valid loss for your task\"", ")", "\n", "\n", "# if self.verbose:", "\n", "# self.model.summary()", "\n", "\n", "", "logging", ".", "info", "(", "f\"Number of trainable parameters: {np.sum([np.prod(v.get_shape()) for v in self.model.trainable_weights])}\"", ")", "\n", "logging", ".", "info", "(", "f\"Number of non-trainable parameters: {np.sum([np.prod(v.get_shape()) for v in self.model.non_trainable_weights])}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.BaseNet.BaseNet._split_model": [[52, 54], ["None"], "methods", ["None"], ["", "def", "_split_model", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.BaseNet.BaseNet._build_model": [[56, 58], ["None"], "methods", ["None"], ["", "def", "_build_model", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.BaseNet.BaseNet.get_model": [[59, 61], ["None"], "methods", ["None"], ["", "def", "get_model", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.BaseNet.BaseNet.save": [[62, 64], ["BaseNet.BaseNet.model.save"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.save"], ["", "def", "save", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "model", ".", "save", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.BaseNet.BaseNet.fit": [[65, 72], ["tensorflow.keras.callbacks.EarlyStopping", "tensorflow.keras.callbacks.EarlyStopping", "BaseNet.BaseNet.model.fit"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit"], ["", "def", "fit", "(", "self", ",", "X_train", ",", "y_train", ",", "X_val", ",", "y_val", ")", ":", "\n", "#csv_logger = CSVLogger(config['batches_log'], append=True, separator=';')", "\n", "#ckpt_dir = config['model_dir'] + '/best_models/' + config['model'] + '_nb_{}_'.format(self.model_number) + 'best_model.h5'", "\n", "#ckpt = tf.keras.callbacks.ModelCheckpoint(ckpt_dir, verbose=1, monitor='val_loss', save_best_only=True, mode='auto')", "\n", "        ", "early_stop", "=", "tf", ".", "keras", ".", "callbacks", ".", "EarlyStopping", "(", "monitor", "=", "'val_loss'", ",", "patience", "=", "20", ")", "\n", "hist", "=", "self", ".", "model", ".", "fit", "(", "X_train", ",", "y_train", ",", "verbose", "=", "2", ",", "batch_size", "=", "self", ".", "batch_size", ",", "validation_data", "=", "(", "X_val", ",", "y_val", ")", ",", "\n", "epochs", "=", "self", ".", "epochs", ",", "callbacks", "=", "[", "early_stop", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.BaseNet.BaseNet.predict": [[73, 75], ["BaseNet.BaseNet.model.predict"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.predict"], ["", "def", "predict", "(", "self", ",", "testX", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "predict", "(", "testX", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.__init__": [[16, 49], ["re.compile", "logging.info"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_name", "=", "'CNN'", ",", "nb_models", "=", "'5'", ",", "loss", "=", "'mse'", ",", "batch_size", "=", "64", ",", "**", "model_params", ")", ":", "\n", "        ", "\"\"\"\n        model_name: the model that the ensemble uses\n        nb_models: Number of models to run in the ensemble\n        model_list: optional, give a list of models that should be contained in the Ensemble\n        ...\n        \"\"\"", "\n", "self", ".", "model_name", "=", "model_name", "\n", "self", ".", "nb_models", "=", "nb_models", "\n", "self", ".", "model_params", "=", "model_params", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "loss", "=", "loss", "\n", "self", ".", "model_instance", "=", "None", "\n", "self", ".", "load_file_pattern", "=", "re", ".", "compile", "(", "self", ".", "model_name", "[", ":", "3", "]", "+", "'.*_nb_._best_model.pth'", ",", "re", ".", "IGNORECASE", ")", "\n", "self", ".", "models", "=", "[", "]", "\n", "\n", "logging", ".", "info", "(", "f\"Instantiated Ensemble of {self.model_name} models\"", ")", "\n", "\n", "if", "self", ".", "model_name", "==", "'CNN'", ":", "\n", "            ", "from", "DL_Models", ".", "tf_models", ".", "CNN", ".", "CNN", "import", "CNN", "\n", "self", ".", "model", "=", "CNN", "\n", "", "elif", "self", ".", "model_name", "==", "'EEGNet'", ":", "\n", "            ", "from", "DL_Models", ".", "tf_models", ".", "EEGNet", ".", "eegNet", "import", "EEGNet", "\n", "self", ".", "model", "=", "EEGNet", "\n", "", "elif", "self", ".", "model_name", "==", "'InceptionTime'", ":", "\n", "            ", "from", "DL_Models", ".", "tf_models", ".", "InceptionTime", ".", "Inception", "import", "INCEPTION", "\n", "self", ".", "model", "=", "INCEPTION", "\n", "", "elif", "self", ".", "model_name", "==", "'PyramidalCNN'", ":", "\n", "            ", "from", "DL_Models", ".", "tf_models", ".", "PyramidalCNN", ".", "PyramidalCNN", "import", "PyramidalCNN", "\n", "self", ".", "model", "=", "PyramidalCNN", "\n", "", "elif", "self", ".", "model_name", "==", "'Xception'", ":", "\n", "            ", "from", "DL_Models", ".", "tf_models", ".", "Xception", ".", "Xception", "import", "XCEPTION", "\n", "self", ".", "model", "=", "XCEPTION", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit": [[51, 70], ["print", "print", "range", "numpy.transpose", "numpy.transpose", "logging.info", "logging.info", "Ensemble_tf.Ensemble_tf.model", "Ensemble_tf.Ensemble_tf.models.append", "Ensemble_tf.Ensemble_tf.fit", "logging.info"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.fit"], ["", "", "def", "fit", "(", "self", ",", "trainX", ",", "trainY", ",", "validX", ",", "validY", ")", ":", "\n", "        ", "\"\"\"\n        Fit all the models in the ensemble and save them to the run directory \n        \"\"\"", "\n", "print", "(", "f\"trainX shape before transpose: {trainX.shape}\"", ")", "\n", "if", "self", ".", "model_name", "==", "'EEGNet'", ":", "\n", "            ", "trainX", "=", "np", ".", "transpose", "(", "trainX", ",", "(", "0", ",", "2", ",", "1", ")", ")", "# (batch_size, samples, channels) to (bs, ch, samples) as torch conv layers want it", "\n", "validX", "=", "np", ".", "transpose", "(", "validX", ",", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "", "print", "(", "f\"trainX shape after transpose: {trainX.shape}\"", ")", "\n", "\n", "self", ".", "models", "=", "[", "]", "\n", "# Fit the models ", "\n", "for", "i", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "            ", "logging", ".", "info", "(", "\"------------------------------------------------------------------------------------\"", ")", "\n", "logging", ".", "info", "(", "'Start fitting model number {}/{} ...'", ".", "format", "(", "i", "+", "1", ",", "self", ".", "nb_models", ")", ")", "\n", "model", "=", "self", ".", "model", "(", "loss", "=", "self", ".", "loss", ",", "model_number", "=", "i", ",", "batch_size", "=", "self", ".", "batch_size", ",", "**", "self", ".", "model_params", ")", "\n", "self", ".", "models", ".", "append", "(", "model", ")", "\n", "model", ".", "fit", "(", "trainX", ",", "trainY", ",", "validX", ",", "validY", ")", "\n", "logging", ".", "info", "(", "'Finished fitting model number {}/{} ...'", ".", "format", "(", "i", "+", "1", ",", "self", ".", "nb_models", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.predict": [[71, 81], ["numpy.transpose", "len", "model.predict", "model.predict"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.predict", "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.predict"], ["", "", "def", "predict", "(", "self", ",", "testX", ")", ":", "\n", "        ", "if", "self", ".", "model_name", "==", "'EEGNet'", ":", "\n", "            ", "testX", "=", "np", ".", "transpose", "(", "testX", ",", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "", "pred", "=", "None", "\n", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "if", "pred", "is", "not", "None", ":", "\n", "                ", "pred", "+=", "model", ".", "predict", "(", "testX", ")", "\n", "", "else", ":", "\n", "                ", "pred", "=", "model", ".", "predict", "(", "testX", ")", "\n", "", "", "return", "pred", "/", "len", "(", "self", ".", "models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.save": [[82, 86], ["enumerate", "model.save"], "methods", ["home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.save"], ["", "def", "save", "(", "self", ",", "path", ")", ":", "\n", "        ", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "ckpt_dir", "=", "path", "+", "self", ".", "model_name", "+", "'_nb_{}_'", ".", "format", "(", "i", ")", "\n", "model", ".", "save", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ardkastrati_eegeyenet.tf_models.Ensemble_tf.Ensemble_tf.load": [[87, 94], ["os.listdir", "logging.info", "Ensemble_tf.Ensemble_tf.models.append", "Ensemble_tf.Ensemble_tf.load_file_pattern.match", "keras.models.load_model"], "methods", ["None"], ["", "", "def", "load", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "models", "=", "[", "]", "\n", "for", "file", "in", "os", ".", "listdir", "(", "path", ")", ":", "\n", "            ", "if", "not", "self", ".", "load_file_pattern", ".", "match", "(", "file", ")", ":", "\n", "                ", "continue", "\n", "", "logging", ".", "info", "(", "f\"Loading model nb from file {file} and predict with it\"", ")", "\n", "self", ".", "models", ".", "append", "(", "keras", ".", "models", ".", "load_model", "(", "path", "+", "file", ")", ")", "", "", "", "", ""]]}