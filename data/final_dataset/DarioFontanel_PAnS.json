{"home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.argparser.modify_command_options": [[4, 26], ["None"], "function", ["None"], ["def", "modify_command_options", "(", "opts", ")", ":", "\n", "    ", "if", "opts", ".", "default", ":", "\n", "        ", "opts", ".", "multi_scala", "=", "True", "\n", "opts", ".", "num_classes", "=", "13", "\n", "opts", ".", "fix_bn", "=", "False", "\n", "opts", ".", "lr", "=", "0.007", "\n", "opts", ".", "momentum", "=", "0.9", "\n", "opts", ".", "weight_decay", "=", "1e-4", "\n", "opts", ".", "deepsup", "=", "0.4", "\n", "opts", ".", "backbone", "=", "'resnet50'", "\n", "opts", ".", "head", "=", "'PPM'", "\n", "opts", ".", "crop_size", "=", "450", "\n", "opts", ".", "num_workers", "=", "16", "\n", "opts", ".", "batch_size", "=", "2", "\n", "opts", ".", "epochs", "=", "40", "\n", "opts", ".", "classifier", "=", "\"cosine\"", "\n", "opts", ".", "cosine_scores", "=", "True", "\n", "\n", "", "if", "not", "opts", ".", "visualize", ":", "\n", "        ", "opts", ".", "sample_num", "=", "0", "\n", "\n", "", "return", "opts", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.argparser.get_argparser": [[28, 136], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["", "def", "get_argparser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Performance Options", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--random_seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed (default: 42)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "type", "=", "int", ",", "default", "=", "16", ",", "\n", "help", "=", "'number of workers (default: 16)'", ")", "\n", "\n", "# Datset Options", "\n", "parser", ".", "add_argument", "(", "\"--data_root\"", ",", "type", "=", "str", ",", "default", "=", "'data'", ",", "\n", "help", "=", "\"path to Dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "type", "=", "str", ",", "default", "=", "'streethazards'", ",", "\n", "choices", "=", "[", "'streethazards'", "]", ",", "help", "=", "'Which training dataset to use'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--num_classes\"", ",", "type", "=", "int", ",", "default", "=", "13", ",", "\n", "help", "=", "\"num classes (default: 13)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--unk_class\"", ",", "type", "=", "int", ",", "default", "=", "13", ",", "\n", "help", "=", "\"unknown class to segment\"", ")", "\n", "\n", "# Train Options", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "type", "=", "int", ",", "default", "=", "40", ",", "\n", "help", "=", "\"epoch number (default: 40)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--fix_bn\"", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'fix batch normalization during training (default: False)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'batch size (default: 2)'", ")", "\n", "parser", ".", "add_argument", "(", "\"--crop_size\"", ",", "type", "=", "int", ",", "default", "=", "512", ",", "\n", "help", "=", "\"crop size (default: 512)\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "0.007", ",", "\n", "help", "=", "\"learning rate (default: 0.007)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--momentum\"", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "\n", "help", "=", "'momentum for SGD (default: 0.9)'", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "type", "=", "float", ",", "default", "=", "1e-4", ",", "\n", "help", "=", "'weight decay (default: 1e-4)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--lr_policy\"", ",", "type", "=", "str", ",", "default", "=", "'poly'", ",", "\n", "choices", "=", "[", "'poly'", ",", "'step'", "]", ",", "help", "=", "\"lr schedule policy (default: poly)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr_decay_step\"", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "\n", "help", "=", "\"decay step for stepLR (default: 5000)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr_decay_factor\"", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "\"decay factor for stepLR (default: 0.1)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr_power\"", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "\n", "help", "=", "\"power for polyLR (default: 0.9)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--deepsup\"", ",", "type", "=", "float", ",", "default", "=", "0.4", ",", "\n", "help", "=", "\"Scaling factor for Deepsup loss (default: 0.4)\"", ")", "\n", "\n", "# Validation Options", "\n", "parser", ".", "add_argument", "(", "\"--val_on_trainset\"", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"enable validation on train set (default: False)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--multi_scala\"", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'whether to use or not multiple resizes for testing (default: True)'", ")", "\n", "\n", "# Logging Options", "\n", "parser", ".", "add_argument", "(", "\"--logdir\"", ",", "type", "=", "str", ",", "default", "=", "'./logs'", ",", "\n", "help", "=", "\"path to Log directory (default: ./logs)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--name\"", ",", "type", "=", "str", ",", "default", "=", "'Experiment'", ",", "\n", "help", "=", "\"name of the experiment - to append to log directory (default: Experiment)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--sample_num\"", ",", "type", "=", "int", ",", "default", "=", "6", ",", "\n", "help", "=", "'number of samples for visualization (default: 8)'", ")", "\n", "parser", ".", "add_argument", "(", "\"--visualize\"", ",", "action", "=", "'store_false'", ",", "default", "=", "True", ",", "\n", "help", "=", "\"visualization on tensorboard (def: Yes)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--print_interval\"", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "\"print interval of loss (default: 10)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--val_interval\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"epoch interval for eval (default: 1)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--ckpt_interval\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"epoch interval for saving model (default: 1)\"", ")", "\n", "\n", "# Model Options", "\n", "parser", ".", "add_argument", "(", "\"--backbone\"", ",", "type", "=", "str", ",", "default", "=", "'resnet50'", ",", "\n", "choices", "=", "[", "'resnet50'", ",", "'resnet101'", "]", ",", "help", "=", "'backbone for the body (def: resnet50)'", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_stride\"", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "choices", "=", "[", "8", ",", "16", "]", ",", "help", "=", "'stride for the backbone (def: 8)'", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_pretrained\"", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Wheather to use pretrained or not (def: True)'", ")", "\n", "parser", ".", "add_argument", "(", "\"--norm_act\"", ",", "type", "=", "str", ",", "default", "=", "\"iabn_sync\"", ",", "\n", "choices", "=", "[", "'iabn_sync'", ",", "'iabn'", ",", "'abn'", ",", "'std'", "]", ",", "help", "=", "'Which BN to use (def: iabn_sync'", ")", "\n", "parser", ".", "add_argument", "(", "\"--pooling\"", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "'pooling in ASPP for the validation phase (def: 32)'", ")", "\n", "parser", ".", "add_argument", "(", "\"--head\"", ",", "type", "=", "str", ",", "default", "=", "'PPM'", ",", "\n", "choices", "=", "[", "'PPM'", "]", ",", "help", "=", "'head to use (def: PPM)'", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifier\"", ",", "type", "=", "str", ",", "default", "=", "'standard'", ",", "\n", "choices", "=", "[", "'standard'", ",", "'cosine'", "]", ",", "help", "=", "'classifier to use (def: standard)'", ")", "\n", "parser", ".", "add_argument", "(", "\"--cosine_scores\"", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Wheather to use the direct cosine scores instead of softmax (def: False)'", ")", "\n", "parser", ".", "add_argument", "(", "\"--msp\"", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Wheather to use the MSP or not (def: False)'", ")", "\n", "\n", "\n", "# Test and Checkpoint options", "\n", "parser", ".", "add_argument", "(", "\"--test\"", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"Whether to train or test only (def: train and test)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--ckpt_test\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Name of a specific trained model (starts from checkpoints/{dataset}). Different from the \"", "\n", "\"name of the exp. loaded when --test is True. If none, it uses the ckpt named as the experiment\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--ckpt\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Name of trained model (it starts from checkpoints/{dataset}). None if retrain the model\"", ")", "\n", "parser", ".", "add_argument", "(", "'--opt_level'", ",", "type", "=", "str", ",", "choices", "=", "[", "'O0'", ",", "'O1'", ",", "'O2'", ",", "'O3'", "]", ",", "default", "=", "'O0'", ")", "\n", "\n", "# Standard protocols", "\n", "parser", ".", "add_argument", "(", "'--default'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"Whether to use default protocol or not\"", ")", "\n", "\n", "return", "parser", "\n", "", ""]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.__init__": [[10, 22], ["torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "device", ",", "opts", ")", ":", "\n", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "255", ",", "reduction", "=", "'mean'", ")", "\n", "\n", "self", ".", "deepsup_factor", "=", "opts", ".", "deepsup", "\n", "\n", "self", ".", "unk_class", "=", "opts", ".", "unk_class", "\n", "self", ".", "multi_scala", "=", "opts", ".", "multi_scala", "\n", "self", ".", "msp", "=", "opts", ".", "msp", "\n", "self", ".", "cosine_scores", "=", "opts", ".", "cosine_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.train": [[23, 90], ["logger.info", "train_loader.sampler.set_epoch", "model.train", "enumerate", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "logger.info", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "images.to.to.to", "labels.to.to.to", "labels.to.to.clone", "optim.zero_grad", "model", "criterion", "criterion.backward", "optim.step", "criterion.item", "criterion.item", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "scheduler.step", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "criterion", "logger.add_scalar", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "len", "len"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.train", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_scalar"], ["", "def", "train", "(", "self", ",", "cur_epoch", ",", "optim", ",", "train_loader", ",", "scheduler", "=", "None", ",", "print_int", "=", "10", ",", "logger", "=", "None", ")", ":", "\n", "        ", "\"\"\"Train and return epoch loss\"\"\"", "\n", "logger", ".", "info", "(", "\"Epoch %d, lr = %f\"", "%", "(", "cur_epoch", ",", "optim", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", ")", "\n", "\n", "device", "=", "self", ".", "device", "\n", "model", "=", "self", ".", "model", "\n", "criterion", "=", "self", ".", "criterion", "\n", "\n", "epoch_loss", "=", "0.0", "\n", "interval_loss", "=", "0.0", "\n", "\n", "train_loader", ".", "sampler", ".", "set_epoch", "(", "cur_epoch", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "for", "cur_step", ",", "(", "images", ",", "labels", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "loss_deepsup", "=", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# normal training images", "\n", "images", "=", "images", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "labels", "=", "labels", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "targets", "=", "labels", ".", "clone", "(", ")", "\n", "optim", ".", "zero_grad", "(", ")", "\n", "\n", "outputs", ",", "outputs_deepsup", ",", "feat_head", "=", "model", "(", "images", ")", "\n", "\n", "# xxx Criterion Loss", "\n", "loss", "=", "criterion", "(", "outputs", ",", "targets", ")", "# B x H x W", "\n", "\n", "# xxx DeepSup Loss", "\n", "if", "outputs_deepsup", "is", "not", "None", ":", "\n", "                ", "loss_deepsup", "=", "criterion", "(", "outputs_deepsup", ",", "targets", ")", "*", "self", ".", "deepsup_factor", "\n", "\n", "", "loss", "=", "loss", "+", "loss_deepsup", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "optim", ".", "step", "(", ")", "\n", "\n", "if", "scheduler", "is", "not", "None", ":", "\n", "                ", "scheduler", ".", "step", "(", ")", "\n", "\n", "", "epoch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "interval_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "if", "(", "cur_step", "+", "1", ")", "%", "print_int", "==", "0", ":", "\n", "                ", "interval_loss", "=", "interval_loss", "/", "print_int", "\n", "\n", "logger", ".", "info", "(", "f\"Epoch {cur_epoch}, Batch {cur_step + 1}/{len(train_loader)},\"", "f\" Loss={interval_loss}\"", ")", "\n", "\n", "# visualization", "\n", "if", "logger", "is", "not", "None", ":", "\n", "                    ", "x", "=", "cur_epoch", "*", "len", "(", "train_loader", ")", "+", "cur_step", "+", "1", "\n", "logger", ".", "add_scalar", "(", "'Loss/Loss'", ",", "interval_loss", ",", "x", ")", "\n", "", "interval_loss", "=", "0.0", "\n", "\n", "# collect statistics from multiple processes", "\n", "", "", "epoch_loss", "=", "torch", ".", "tensor", "(", "epoch_loss", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "torch", ".", "distributed", ".", "reduce", "(", "epoch_loss", ",", "dst", "=", "0", ")", "\n", "\n", "if", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "epoch_loss", "=", "epoch_loss", "/", "distributed", ".", "get_world_size", "(", ")", "/", "len", "(", "train_loader", ")", "\n", "\n", "", "logger", ".", "info", "(", "f\"Epoch {cur_epoch}, Class Loss={epoch_loss}\"", ")", "\n", "return", "epoch_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.validate": [[91, 162], ["metrics.reset", "model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "metrics.synch", "metrics.get_results", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "tqdm.tqdm.tqdm", "images[].detach().cpu().numpy.to", "labels.to.to.to", "model", "torch.interpolate", "torch.interpolate", "torch.interpolate", "criterion", "criterion.item", "torch.functional.softmax", "torch.functional.softmax", "torch.functional.softmax", "torch.functional.softmax.max", "metrics.update", "tqdm.tqdm.tqdm.close", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "logger.info", "labels.to.to.squeeze().cpu().numpy", "prediction[].detach().cpu().numpy.squeeze().cpu().numpy", "probabilities.squeeze().cpu().numpy", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate().squeeze().to", "torch.interpolate().squeeze().to", "torch.interpolate().squeeze().to", "images[].detach().cpu().numpy", "prediction[].detach().cpu().numpy", "ret_samples.append", "tqdm.tqdm.tqdm.update", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "labels.to.to.squeeze().cpu", "prediction[].detach().cpu().numpy.squeeze().cpu", "probabilities.squeeze().cpu", "torch.interpolate().squeeze", "torch.interpolate().squeeze", "torch.interpolate().squeeze", "images[].detach().cpu", "prediction[].detach().cpu", "labels.to.to.squeeze", "prediction[].detach().cpu().numpy.squeeze", "probabilities.squeeze", "torch.interpolate", "torch.interpolate", "torch.interpolate", "images[].detach", "prediction[].detach", "prediction[].detach().cpu().numpy.unsqueeze().to", "prediction[].detach().cpu().numpy.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.reset", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.synch", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.get_results", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.update", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.close", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.update"], ["", "def", "validate", "(", "self", ",", "loader", ",", "metrics", ",", "ret_samples_ids", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "\"\"\"Do validation and return specified samples\"\"\"", "\n", "metrics", ".", "reset", "(", ")", "\n", "model", "=", "self", ".", "model", "\n", "device", "=", "self", ".", "device", "\n", "criterion", "=", "self", ".", "criterion", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "class_loss", "=", "0.0", "\n", "\n", "ret_samples", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "if", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "loader", ")", ")", "\n", "", "else", ":", "\n", "                ", "pbar", "=", "None", "\n", "\n", "", "for", "i", ",", "(", "images", ",", "labels", ")", "in", "enumerate", "(", "loader", ")", ":", "\n", "\n", "                ", "images", "=", "images", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "labels", "=", "labels", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "interpolation_size", "=", "(", "labels", ".", "shape", "[", "1", "]", ",", "labels", ".", "shape", "[", "2", "]", ")", "\n", "\n", "outputs", ",", "_", ",", "_", ",", "_", "=", "model", "(", "images", ",", "body_and_head", "=", "True", ",", "interpolate", "=", "False", ")", "\n", "outputs", "=", "functional", ".", "interpolate", "(", "outputs", ",", "size", "=", "interpolation_size", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", "\n", "loss", "=", "criterion", "(", "outputs", ",", "labels", ")", "\n", "class_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "outputs", "=", "nn", ".", "functional", ".", "softmax", "(", "outputs", ",", "dim", "=", "1", ")", "\n", "probabilities", ",", "prediction", "=", "outputs", ".", "max", "(", "dim", "=", "1", ")", "\n", "\n", "metrics", ".", "update", "(", "labels", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "prediction", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "probabilities", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "if", "ret_samples_ids", "is", "not", "None", "and", "i", "in", "ret_samples_ids", ":", "# get samples", "\n", "# resizing for logger", "\n", "                    ", "visualization_size", "=", "(", "interpolation_size", "[", "0", "]", "//", "2", ",", "interpolation_size", "[", "1", "]", "//", "2", ")", "\n", "\n", "images", "=", "functional", ".", "interpolate", "(", "images", ",", "size", "=", "visualization_size", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", "prediction", "=", "functional", ".", "interpolate", "(", "prediction", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "torch", ".", "float", ")", ",", "size", "=", "visualization_size", ",", "\n", "mode", "=", "\"nearest\"", ")", ".", "squeeze", "(", "0", ")", ".", "to", "(", "torch", ".", "long", ")", "\n", "\n", "images", "=", "images", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "prediction", "=", "prediction", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "ret_samples", ".", "append", "(", "(", "images", ",", "prediction", ")", ")", "\n", "\n", "", "if", "pbar", "is", "not", "None", ":", "\n", "                    ", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "", "if", "pbar", "is", "not", "None", ":", "\n", "                ", "pbar", ".", "close", "(", ")", "\n", "\n", "# collect statistics from multiple processes", "\n", "", "metrics", ".", "synch", "(", "device", ")", "\n", "score", "=", "metrics", ".", "get_results", "(", ")", "\n", "\n", "class_loss", "=", "torch", ".", "tensor", "(", "class_loss", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "torch", ".", "distributed", ".", "reduce", "(", "class_loss", ",", "dst", "=", "0", ")", "\n", "\n", "if", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "class_loss", "=", "class_loss", "/", "distributed", ".", "get_world_size", "(", ")", "/", "len", "(", "loader", ")", "\n", "\n", "", "if", "logger", "is", "not", "None", ":", "\n", "                ", "logger", ".", "info", "(", "f\"Validation, Class Loss={class_loss}\"", ")", "\n", "\n", "", "", "return", "class_loss", ",", "score", ",", "ret_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.test": [[163, 218], ["metrics.reset", "model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm.tqdm", "enumerate", "metrics.synch", "metrics.get_results", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "labels.to.to.to", "enumerate", "torch.zeros.max", "torch.zeros.max", "torch.zeros.max", "torch.zeros.max", "torch.zeros.max", "torch.zeros.max", "metrics.update", "tqdm.tqdm.tqdm.update", "len", "images_resized_list[].to", "model", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.functional.softmax", "torch.functional.softmax", "torch.functional.softmax", "labels.to.to.squeeze().cpu().numpy", "prediction.squeeze().cpu().numpy", "anomaly_probabilities.squeeze().cpu().numpy", "torch.interpolate.max", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate.cpu", "len", "labels.to.to.squeeze().cpu", "prediction.squeeze().cpu", "anomaly_probabilities.squeeze().cpu", "torch.interpolate.cpu", "len", "labels.to.to.squeeze", "prediction.squeeze", "anomaly_probabilities.squeeze"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.reset", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.synch", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.get_results", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.update", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.update"], ["", "def", "test", "(", "self", ",", "loader", ",", "metrics", ")", ":", "\n", "        ", "\"\"\"Do validation and return specified samples\"\"\"", "\n", "metrics", ".", "reset", "(", ")", "\n", "model", "=", "self", ".", "model", "\n", "device", "=", "self", ".", "device", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "loader", ")", ")", "\n", "for", "i", ",", "(", "images_resized_list", ",", "labels", ")", "in", "enumerate", "(", "loader", ")", ":", "\n", "\n", "                ", "interpolation_size", "=", "(", "labels", ".", "shape", "[", "1", "]", ",", "labels", ".", "shape", "[", "2", "]", ")", "\n", "anomaly_scores", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "labels", ".", "shape", "[", "1", "]", ",", "labels", ".", "shape", "[", "2", "]", ")", "\n", "scores", "=", "torch", ".", "zeros", "(", "1", ",", "model", ".", "module", ".", "cls", ".", "classes", ",", "labels", ".", "shape", "[", "1", "]", ",", "labels", ".", "shape", "[", "2", "]", ")", "\n", "\n", "if", "not", "self", ".", "multi_scala", ":", "\n", "                    ", "images_resized_list", "=", "[", "images_resized_list", "]", "\n", "\n", "", "labels", "=", "labels", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "idx", ",", "_", "in", "enumerate", "(", "images_resized_list", ")", ":", "\n", "# original images", "\n", "                    ", "img", "=", "images_resized_list", "[", "idx", "]", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "# forward pass", "\n", "logits", ",", "_", ",", "feat_head", ",", "feat_body", "=", "model", "(", "img", ",", "body_and_head", "=", "True", ",", "interpolate", "=", "False", ")", "\n", "\n", "if", "self", ".", "cosine_scores", ":", "\n", "                        ", "logits_max", ",", "_", "=", "logits", ".", "max", "(", "dim", "=", "1", ")", "\n", "logits_max", "=", "(", "(", "logits_max", "+", "10.", ")", "/", "20.", ")", ".", "unsqueeze", "(", "0", ")", "\n", "outputs", "=", "functional", ".", "interpolate", "(", "logits_max", ",", "size", "=", "interpolation_size", ",", "mode", "=", "\"bilinear\"", ",", "\n", "align_corners", "=", "False", ")", "\n", "anomaly_scores", "=", "anomaly_scores", "+", "outputs", ".", "cpu", "(", ")", "/", "len", "(", "images_resized_list", ")", "\n", "\n", "", "logits", "=", "functional", ".", "interpolate", "(", "logits", ",", "size", "=", "interpolation_size", ",", "mode", "=", "\"bilinear\"", ",", "\n", "align_corners", "=", "False", ")", "\n", "outputs", "=", "nn", ".", "functional", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "scores", "=", "scores", "+", "outputs", ".", "cpu", "(", ")", "/", "len", "(", "images_resized_list", ")", "\n", "\n", "", "if", "self", ".", "msp", ":", "\n", "                    ", "anomaly_scores", "=", "scores", "\n", "\n", "", "_", ",", "prediction", "=", "scores", ".", "max", "(", "dim", "=", "1", ")", "\n", "anomaly_probabilities", ",", "_", "=", "anomaly_scores", ".", "max", "(", "dim", "=", "1", ")", "\n", "\n", "metrics", ".", "update", "(", "labels", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "prediction", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "anomaly_probabilities", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "# collect statistics from multiple processes", "\n", "", "metrics", ".", "synch", "(", "device", ")", "\n", "score", "=", "metrics", ".", "get_results", "(", ")", "\n", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.state_dict": [[219, 221], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.load_state_dict": [[222, 224], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.segmentation_module.SegmentationModule.__init__": [[55, 63], ["torch.Module.__init__", "segmentation_module.SegmentationModule.fix_bn"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.__init__", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.utils.fix_bn"], ["    ", "def", "__init__", "(", "self", ",", "body", ",", "head", ",", "cls", ",", "fix_bn", "=", "False", ")", ":", "\n", "        ", "super", "(", "SegmentationModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "body", "=", "body", "\n", "self", ".", "head", "=", "head", "\n", "self", ".", "cls", "=", "cls", "\n", "\n", "if", "fix_bn", ":", "\n", "            ", "self", ".", "fix_bn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.segmentation_module.SegmentationModule._network": [[64, 72], ["segmentation_module.SegmentationModule.body", "segmentation_module.SegmentationModule.head", "segmentation_module.SegmentationModule.update"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.update"], ["", "", "def", "_network", "(", "self", ",", "x", ",", "body_and_head", "=", "False", ")", ":", "\n", "\n", "        ", "x_b_all", ",", "x_b_last", "=", "self", ".", "body", "(", "x", ")", "\n", "x_h", "=", "self", ".", "head", "(", "(", "x_b_all", ",", "x_b_last", ")", ")", "\n", "if", "body_and_head", ":", "\n", "            ", "x_h", ".", "update", "(", "{", "'body'", ":", "x_b_last", "}", ")", "\n", "return", "x_h", "\n", "", "return", "x_h", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.segmentation_module.SegmentationModule.freeze_network": [[73, 80], ["segmentation_module.SegmentationModule.body.parameters", "segmentation_module.SegmentationModule.head.parameters", "segmentation_module.SegmentationModule.cls.parameters"], "methods", ["None"], ["", "def", "freeze_network", "(", "self", ")", ":", "\n", "        ", "for", "par", "in", "self", ".", "body", ".", "parameters", "(", ")", ":", "\n", "            ", "par", ".", "requires_grad", "=", "False", "\n", "", "for", "par", "in", "self", ".", "head", ".", "parameters", "(", ")", ":", "\n", "            ", "par", ".", "requires_grad", "=", "False", "\n", "", "for", "par", "in", "self", ".", "cls", ".", "parameters", "(", ")", ":", "\n", "            ", "par", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.segmentation_module.SegmentationModule.forward": [[81, 104], ["segmentation_module.SegmentationModule._network", "segmentation_module.SegmentationModule.cls", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.segmentation_module.SegmentationModule._network"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "body_and_head", "=", "False", ",", "custom_outsize", "=", "None", ",", "interpolate", "=", "True", ")", ":", "\n", "        ", "out", "=", "self", ".", "_network", "(", "x", ",", "body_and_head", ")", "\n", "out_size", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "\n", "features", ",", "features_deepsup", "=", "out", "[", "'outputs'", "]", ",", "out", "[", "'outputs_deepsup'", "]", "\n", "if", "body_and_head", ":", "\n", "            ", "feat_body", "=", "out", "[", "'body'", "]", "\n", "# body_output, _ = self.intermediate_cls(feat_body, None)", "\n", "\n", "# SEGMENTATION TASK", "\n", "", "sem_output", ",", "sem_output_deepsup", "=", "self", ".", "cls", "(", "features", ",", "features_deepsup", ")", "\n", "\n", "# === PREDICTIONS", "\n", "if", "interpolate", ":", "\n", "            ", "sem_output", "=", "functional", ".", "interpolate", "(", "sem_output", ",", "size", "=", "torch", ".", "Size", "(", "custom_outsize", ")", "if", "custom_outsize", "\n", "is", "not", "None", "else", "out_size", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", "\n", "if", "sem_output_deepsup", "is", "not", "None", ":", "\n", "                ", "sem_output_deepsup", "=", "functional", ".", "interpolate", "(", "sem_output_deepsup", ",", "size", "=", "out_size", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", "\n", "", "", "if", "body_and_head", ":", "\n", "            ", "return", "sem_output", ",", "sem_output_deepsup", ",", "features", ",", "feat_body", "\n", "\n", "", "return", "sem_output", ",", "sem_output_deepsup", ",", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.segmentation_module.SegmentationModule.fix_bn": [[105, 110], ["segmentation_module.SegmentationModule.modules", "isinstance", "isinstance"], "methods", ["None"], ["", "def", "fix_bn", "(", "self", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", "or", "isinstance", "(", "m", ",", "inplace_abn", ".", "ABN", ")", ":", "\n", "                ", "m", ".", "weight", ".", "requires_grad", "=", "False", "\n", "m", ".", "bias", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.segmentation_module.SegmentationModule.freeze": [[111, 118], ["segmentation_module.SegmentationModule.body.parameters", "segmentation_module.SegmentationModule.head.parameters", "segmentation_module.SegmentationModule.cls.parameters"], "methods", ["None"], ["", "", "", "def", "freeze", "(", "self", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "body", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "", "for", "p", "in", "self", ".", "head", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "", "for", "p", "in", "self", ".", "cls", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.segmentation_module.make_model": [[15, 52], ["modules.get_classifier", "modules.get_classifier.", "segmentation_module.SegmentationModule", "functools.partial", "torch.load", "torch.load", "torch.load", "body.load_state_dict", "modules.PyramidPoolingModule", "NotImplementedError", "functools.partial", "functools.partial"], "function", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.modules.classifier.get_classifier", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.load_state_dict"], ["def", "make_model", "(", "opts", ")", ":", "\n", "    ", "if", "opts", ".", "norm_act", "==", "'iabn_sync'", ":", "\n", "        ", "norm", "=", "partial", "(", "InPlaceABNSync", ",", "activation", "=", "\"leaky_relu\"", ",", "activation_param", "=", ".01", ")", "\n", "", "elif", "opts", ".", "norm_act", "==", "'iabn'", ":", "\n", "        ", "norm", "=", "partial", "(", "InPlaceABN", ",", "activation", "=", "\"leaky_relu\"", ",", "activation_param", "=", ".01", ")", "\n", "", "elif", "opts", ".", "norm_act", "==", "'abn'", ":", "\n", "        ", "norm", "=", "partial", "(", "ABN", ",", "activation", "=", "\"leaky_relu\"", ",", "activation_param", "=", ".01", ")", "\n", "", "else", ":", "\n", "        ", "norm", "=", "nn", ".", "BatchNorm2d", "# not synchronized, can be enabled with apex", "\n", "\n", "# === BODY", "\n", "", "body", "=", "models", ".", "__dict__", "[", "f'net_{opts.backbone}'", "]", "(", "norm_act", "=", "norm", ",", "output_stride", "=", "opts", ".", "output_stride", ")", "\n", "if", "not", "opts", ".", "no_pretrained", ":", "\n", "        ", "pretrained_path", "=", "f'pretrained/{opts.backbone}_{opts.norm_act}.pth.tar'", "\n", "pre_dict", "=", "torch", ".", "load", "(", "pretrained_path", ",", "map_location", "=", "'cpu'", ")", "\n", "del", "pre_dict", "[", "'state_dict'", "]", "[", "'classifier.fc.weight'", "]", "\n", "del", "pre_dict", "[", "'state_dict'", "]", "[", "'classifier.fc.bias'", "]", "\n", "\n", "body", ".", "load_state_dict", "(", "pre_dict", "[", "'state_dict'", "]", ")", "\n", "del", "pre_dict", "# free memory", "\n", "\n", "# === HEAD", "\n", "", "if", "opts", ".", "head", "==", "'PPM'", ":", "\n", "        ", "deepsup", "=", "True", "\n", "head_channels", "=", "512", "\n", "head", "=", "PyramidPoolingModule", "(", "body", ".", "out_channels", ",", "head_channels", ",", "norm_act", "=", "norm", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"Head _{opts.head}_ not implemented.\"", ")", "\n", "\n", "# === CLASSIFIER", "\n", "", "classifier", "=", "get_classifier", "(", "opts", ".", "classifier", ")", "\n", "cls", "=", "classifier", "(", "head", ".", "out_channels", ",", "opts", ".", "num_classes", ",", "deepsup", ")", "\n", "\n", "model", "=", "SegmentationModule", "(", "body", ",", "head", ",", "cls", ",", "opts", ".", "fix_bn", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.run.save_ckpt": [[23, 36], ["torch.save", "model.state_dict", "optimizer.state_dict", "scheduler.state_dict", "trainer.state_dict"], "function", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.state_dict", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.state_dict", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.state_dict", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.state_dict"], ["def", "save_ckpt", "(", "path", ",", "model", ",", "trainer", ",", "optimizer", ",", "scheduler", ",", "epoch", ",", "best_score", ")", ":", "\n", "    ", "\"\"\" save current model\n    \"\"\"", "\n", "state", "=", "{", "\n", "\"epoch\"", ":", "epoch", ",", "\n", "\"model_state\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer_state\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"scheduler_state\"", ":", "scheduler", ".", "state_dict", "(", ")", ",", "\n", "\"best_score\"", ":", "best_score", ",", "\n", "\"trainer_state\"", ":", "trainer", ".", "state_dict", "(", ")", "\n", "}", "\n", "\n", "torch", ".", "save", "(", "state", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.run.get_dataset": [[37, 107], ["dataset.transform.Compose", "dataset.utils.round2nearest_multiple", "dataset.utils.round2nearest_multiple", "train_dataset", "train_dataset", "test_dataset", "dataset.transform.Compose", "NotImplementedError", "int", "int", "NotImplementedError", "dataset.transform.ToTensor", "dataset.transform.Normalize", "zip", "NotImplementedError", "dataset.transform.Compose", "NotImplementedError", "dataset.transform.RandomScale", "dataset.transform.RandomCrop", "dataset.transform.RandomHorizontalFlip", "transform.Compose.append", "dataset.transform.Compose", "dataset.transform.Resize", "dataset.transform.Resize"], "function", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.utils.round2nearest_multiple", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.utils.round2nearest_multiple"], ["", "def", "get_dataset", "(", "opts", ")", ":", "\n", "    ", "\"\"\" Dataset And Augmentation\n    \"\"\"", "\n", "resize_scales", "=", "[", "300", "/", "720", ",", "375", "/", "720", ",", "450", "/", "720", ",", "525", "/", "720", ",", "1000", "/", "1280", "]", "\n", "\n", "# TRAIN", "\n", "basic_transform", "=", "transform", ".", "Compose", "(", "[", "\n", "transform", ".", "ToTensor", "(", ")", ",", "\n", "transform", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ",", "\n", "]", ")", "\n", "\n", "if", "opts", ".", "dataset", "==", "'streethazards'", ":", "\n", "        ", "train_transform", "=", "transform", ".", "Compose", "(", "[", "\n", "transform", ".", "RandomScale", "(", "[", "resize_scales", "[", "0", "]", ",", "resize_scales", "[", "-", "1", "]", "]", ")", ",", "\n", "transform", ".", "RandomCrop", "(", "opts", ".", "crop_size", ",", "pad_if_needed", "=", "True", ")", ",", "# 450", "\n", "transform", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "basic_transform", "\n", "]", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"Transformations for /{opts.dataset}/ dataset not available\"", ")", "\n", "\n", "# VALIDATION", "\n", "", "val_transform", "=", "basic_transform", "\n", "\n", "# TEST", "\n", "heights", "=", "[", "int", "(", "720", "*", "s", ")", "for", "s", "in", "resize_scales", "]", "\n", "widhts", "=", "[", "int", "(", "1280", "*", "s", ")", "for", "s", "in", "resize_scales", "]", "\n", "\n", "widhts", "=", "round2nearest_multiple", "(", "widhts", ",", "8", ")", "\n", "heights", "=", "round2nearest_multiple", "(", "heights", ",", "8", ")", "\n", "\n", "if", "opts", ".", "multi_scala", ":", "\n", "        ", "if", "opts", ".", "dataset", "==", "'streethazards'", ":", "\n", "            ", "test_transform", "=", "[", "]", "\n", "for", "height", ",", "widht", "in", "zip", "(", "heights", ",", "widhts", ")", ":", "\n", "                ", "test_transform", ".", "append", "(", "transform", ".", "Compose", "(", "[", "\n", "transform", ".", "Resize", "(", "(", "height", ",", "widht", ")", ")", ",", "\n", "basic_transform", "\n", "]", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"Multi scale transformations for /{opts.dataset}/ dataset not available\"", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "if", "opts", ".", "dataset", "==", "'streethazards'", ":", "\n", "            ", "test_transform", "=", "transform", ".", "Compose", "(", "[", "\n", "transform", ".", "Resize", "(", "(", "heights", "[", "-", "1", "]", ",", "widhts", "[", "-", "1", "]", ")", ")", ",", "\n", "basic_transform", "\n", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"Transformations for /{opts.dataset}/ dataset not available\"", ")", "\n", "\n", "# DATATSET", "\n", "", "", "if", "opts", ".", "dataset", "==", "'streethazards'", ":", "\n", "        ", "train_dataset", "=", "StreetHazardsSegmentation", "\n", "test_dataset", "=", "StreetHazardsSegmentation", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"/{opts.dataset}/ dataset not available\"", ")", "\n", "\n", "", "train_dst", "=", "train_dataset", "(", "root", "=", "opts", ".", "data_root", ",", "split", "=", "'train'", ",", "transform", "=", "train_transform", ",", "\n", "basic_transform", "=", "basic_transform", ")", "\n", "\n", "\n", "val_dst", "=", "train_dataset", "(", "root", "=", "opts", ".", "data_root", ",", "split", "=", "'validation'", ",", "transform", "=", "val_transform", ",", "\n", "basic_transform", "=", "basic_transform", ")", "\n", "\n", "test_dst", "=", "test_dataset", "(", "root", "=", "opts", ".", "data_root", ",", "split", "=", "'test'", ",", "transform", "=", "test_transform", ",", "basic_transform", "=", "basic_transform", ",", "\n", "multiple_resizes_test", "=", "opts", ".", "multi_scala", ")", "\n", "\n", "return", "train_dst", ",", "val_dst", ",", "test_dst", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.run.main": [[109, 325], ["torch.distributed.init_process_group", "torch.cuda.set_device", "utils.logger.Logger.print", "os.makedirs", "torch.manual_seed", "torch.cuda.manual_seed", "numpy.random.seed", "random.seed", "run.get_dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "utils.logger.Logger.info", "utils.logger.Logger.info", "utils.logger.Logger.info", "segmentation_module.make_model", "utils.logger.Logger.info", "params.append", "params.append", "params.append", "torch.optim.SGD", "torch.nn.parallel.DistributedDataParallel.to", "torch.nn.parallel.DistributedDataParallel", "train.Trainer", "utils.logger.Logger.add_table", "utils.Label2Color", "utils.Denormalize", "metrics.StreamSegMetrics", "utils.logger.Logger.print", "torch.distributed.barrier", "utils.logger.Logger.info", "torch.utils.data.DataLoader", "segmentation_module.make_model", "torch.nn.parallel.DistributedDataParallel", "torch.load", "torch.nn.parallel.DistributedDataParallel.load_state_dict", "utils.logger.Logger.info", "train.Trainer", "torch.nn.parallel.DistributedDataParallel.eval", "train.Trainer.test", "utils.logger.Logger.print", "utils.logger.Logger.info", "utils.logger.Logger.info", "utils.logger.Logger.add_table", "utils.logger.Logger.add_table", "utils.logger.Logger.add_figure", "utils.logger.Logger.add_results", "utils.logger.Logger.add_scalar", "utils.logger.Logger.add_scalar", "utils.logger.Logger.add_scalar", "utils.logger.Logger.add_scalar", "utils.logger.Logger.add_scalar", "utils.logger.Logger.add_scalar", "utils.logger.Logger.close", "torch.device", "torch.distributed.get_rank", "torch.distributed.get_world_size", "utils.logger.Logger", "utils.logger.Logger", "utils.PolyLR", "os.path.isfile", "torch.load", "torch.nn.parallel.DistributedDataParallel.load_state_dict", "torch.optim.SGD.load_state_dict", "torch.optim.lr_scheduler.StepLR.load_state_dict", "utils.logger.Logger.info", "utils.logger.Logger.info", "vars", "numpy.random.choice", "utils.logger.Logger.info", "torch.randint", "torch.nn.parallel.DistributedDataParallel.train", "train.Trainer.train", "utils.logger.Logger.info", "utils.logger.Logger.add_scalar", "run.save_ckpt", "utils.logger.Logger.info", "torch.nn.parallel.DistributedDataParallel.cuda", "metrics.StreamSegMetrics.to_str", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "filter", "filter", "filter", "torch.optim.lr_scheduler.StepLR", "train.Trainer.load_state_dict", "len", "utils.color_map", "utils.logger.Logger.info", "torch.nn.parallel.DistributedDataParallel.eval", "train.Trainer.validate", "utils.logger.Logger.print", "utils.logger.Logger.info", "utils.logger.Logger.info", "utils.logger.Logger.add_scalar", "utils.logger.Logger.add_scalar", "utils.logger.Logger.add_scalar", "utils.logger.Logger.add_table", "utils.logger.Logger.add_table", "utils.logger.Logger.add_figure", "enumerate", "run.save_ckpt", "utils.logger.Logger.info", "torch.utils.data.distributed.DistributedSampler", "len", "len", "len", "torch.nn.parallel.DistributedDataParallel.body.parameters", "torch.nn.parallel.DistributedDataParallel.head.parameters", "torch.nn.parallel.DistributedDataParallel.cls.parameters", "metrics.StreamSegMetrics.to_str", "utils.Label2Color.transpose().astype", "numpy.concatenate", "utils.logger.Logger.add_image", "len", "utils.Label2Color.transpose", "utils.Denormalize.", "utils.Label2Color."], "function", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.print", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.run.get_dataset", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.segmentation_module.make_model", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_table", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.print", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.segmentation_module.make_model", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.load_state_dict", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.test", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.print", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_table", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_table", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_figure", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_results", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.close", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.load_state_dict", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.load_state_dict", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.load_state_dict", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.train", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.train", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.run.save_ckpt", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.to_str", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.load_state_dict", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.utils.color_map", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.train.Trainer.validate", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.print", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_table", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_table", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_figure", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.None.run.save_ckpt", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.to_str", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_image"], ["", "def", "main", "(", "opts", ")", ":", "\n", "    ", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ",", "init_method", "=", "'env://'", ")", "\n", "device_id", ",", "device", "=", "opts", ".", "local_rank", ",", "torch", ".", "device", "(", "opts", ".", "local_rank", ")", "\n", "rank", ",", "world_size", "=", "distributed", ".", "get_rank", "(", ")", ",", "distributed", ".", "get_world_size", "(", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "device_id", ")", "\n", "# Initialize logging", "\n", "logdir_full", "=", "f\"{opts.logdir}/{opts.dataset}/{opts.name}/\"", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "logger", "=", "Logger", "(", "logdir_full", ",", "rank", "=", "rank", ",", "summary", "=", "opts", ".", "visualize", ")", "\n", "", "else", ":", "\n", "        ", "logger", "=", "Logger", "(", "logdir_full", ",", "rank", "=", "rank", ",", "summary", "=", "False", ")", "\n", "\n", "", "logger", ".", "print", "(", "f\"Device: {device}\"", ")", "\n", "\n", "checkpoint_path", "=", "f\"checkpoints/{opts.dataset}/{opts.name}.pth\"", "\n", "os", ".", "makedirs", "(", "f\"checkpoints/{opts.dataset}\"", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Set up random seed", "\n", "torch", ".", "manual_seed", "(", "opts", ".", "random_seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "opts", ".", "random_seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "opts", ".", "random_seed", ")", "\n", "random", ".", "seed", "(", "opts", ".", "random_seed", ")", "\n", "\n", "train_dst", ",", "val_dst", ",", "test_dst", "=", "get_dataset", "(", "opts", ")", "\n", "\n", "train_loader", "=", "data", ".", "DataLoader", "(", "train_dst", ",", "batch_size", "=", "opts", ".", "batch_size", ",", "\n", "sampler", "=", "DistributedSampler", "(", "train_dst", ",", "num_replicas", "=", "world_size", ",", "rank", "=", "rank", ")", ",", "\n", "num_workers", "=", "opts", ".", "num_workers", ",", "drop_last", "=", "True", ")", "\n", "val_loader", "=", "data", ".", "DataLoader", "(", "val_dst", ",", "batch_size", "=", "1", ",", "\n", "sampler", "=", "DistributedSampler", "(", "val_dst", ",", "num_replicas", "=", "world_size", ",", "rank", "=", "rank", ")", ",", "\n", "num_workers", "=", "opts", ".", "num_workers", ",", "drop_last", "=", "True", ")", "\n", "logger", ".", "info", "(", "f\"Dataset: {opts.dataset}, Train set: {len(train_dst)}, Val set (w/o anomalies): {len(val_dst)},\"", "\n", "f\" Test set (w/ anomalies): {len(test_dst)}, #training classes: {opts.num_classes}\"", ")", "\n", "logger", ".", "info", "(", "f\"Total batch size is {opts.batch_size * world_size}\"", ")", "\n", "opts", ".", "n_gpus", "=", "world_size", "\n", "\n", "# xxx Set up model", "\n", "logger", ".", "info", "(", "f\"Backbone: {opts.backbone}\"", ")", "\n", "\n", "model", "=", "make_model", "(", "opts", ")", "\n", "\n", "logger", ".", "info", "(", "f\"[!] Model made with{'out' if opts.no_pretrained else ''} pre-trained\"", ")", "\n", "\n", "# xxx Set up optimizer", "\n", "params", "=", "[", "]", "\n", "params", ".", "append", "(", "{", "\"params\"", ":", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "body", ".", "parameters", "(", ")", ")", ",", "\n", "'weight_decay'", ":", "opts", ".", "weight_decay", "}", ")", "\n", "params", ".", "append", "(", "{", "\"params\"", ":", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "head", ".", "parameters", "(", ")", ")", ",", "\n", "'weight_decay'", ":", "opts", ".", "weight_decay", "}", ")", "\n", "params", ".", "append", "(", "{", "\"params\"", ":", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "cls", ".", "parameters", "(", ")", ")", ",", "\n", "'weight_decay'", ":", "opts", ".", "weight_decay", "}", ")", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "params", ",", "lr", "=", "opts", ".", "lr", ",", "momentum", "=", "0.9", ",", "nesterov", "=", "True", ")", "\n", "\n", "if", "opts", ".", "lr_policy", "==", "'poly'", ":", "\n", "        ", "scheduler", "=", "utils", ".", "PolyLR", "(", "optimizer", ",", "max_iters", "=", "opts", ".", "epochs", "*", "len", "(", "train_loader", ")", ",", "power", "=", "opts", ".", "lr_power", ")", "\n", "", "elif", "opts", ".", "lr_policy", "==", "'step'", ":", "\n", "        ", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "step_size", "=", "opts", ".", "lr_decay_step", ",", "gamma", "=", "opts", ".", "lr_decay_factor", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "\n", "# Put the model on GPU", "\n", "model", "=", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "opts", ".", "local_rank", "]", ",", "output_device", "=", "opts", ".", "local_rank", ")", "\n", "\n", "trainer", "=", "Trainer", "(", "model", ",", "device", "=", "device", ",", "opts", "=", "opts", ")", "\n", "\n", "# xxx Handle checkpoint for current model (model old will always be as previous step or None)", "\n", "best_score", "=", "0.0", "\n", "cur_epoch", "=", "0", "\n", "if", "opts", ".", "ckpt", "is", "not", "None", ":", "\n", "        ", "ckpt_path", "=", "f\"checkpoints/{opts.dataset}/{opts.ckpt}\"", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "ckpt_path", ")", ",", "\"Error, ckpt not found. Check the correct directory\"", "\n", "checkpoint", "=", "torch", ".", "load", "(", "ckpt_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"model_state\"", "]", ",", "strict", "=", "False", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "\"optimizer_state\"", "]", ")", "\n", "scheduler", ".", "load_state_dict", "(", "checkpoint", "[", "\"scheduler_state\"", "]", ")", "\n", "cur_epoch", "=", "checkpoint", "[", "\"epoch\"", "]", "+", "1", "\n", "best_score", "=", "checkpoint", "[", "'best_score'", "]", "\n", "logger", ".", "info", "(", "\"[!] Model restored from %s\"", "%", "ckpt_path", ")", "\n", "# if we want to resume training, resume trainer from checkpoint", "\n", "if", "'trainer_state'", "in", "checkpoint", ":", "\n", "            ", "trainer", ".", "load_state_dict", "(", "checkpoint", "[", "'trainer_state'", "]", ")", "\n", "", "del", "checkpoint", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"[!] Train from scratch\"", ")", "\n", "\n", "# xxx Train procedure", "\n", "# print opts before starting training to log all parameters", "\n", "", "logger", ".", "add_table", "(", "\"Opts\"", ",", "vars", "(", "opts", ")", ")", "\n", "\n", "# For visualization -> select random batches to display on tensorboard", "\n", "if", "rank", "==", "0", "and", "opts", ".", "sample_num", ">", "0", ":", "\n", "        ", "sample_ids", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "val_loader", ")", ",", "opts", ".", "sample_num", ",", "replace", "=", "False", ")", "# sample idxs for visualization", "\n", "logger", ".", "info", "(", "f\"The samples id are {sample_ids}\"", ")", "\n", "", "else", ":", "\n", "        ", "sample_ids", "=", "None", "\n", "\n", "", "label2color", "=", "utils", ".", "Label2Color", "(", "cmap", "=", "utils", ".", "color_map", "(", "opts", ".", "dataset", ")", ")", "# convert labels t   o images", "\n", "denorm", "=", "utils", ".", "Denormalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "# de-normalization for original images", "\n", "\n", "val_metrics", "=", "StreamSegMetrics", "(", "opts", ".", "num_classes", ",", "opts", ".", "unk_class", ")", "\n", "val_score", "=", "None", "\n", "results", "=", "{", "}", "\n", "\n", "# check if random is equal here.", "\n", "logger", ".", "print", "(", "torch", ".", "randint", "(", "0", ",", "100", ",", "(", "1", ",", "1", ")", ")", ")", "\n", "# train/val here", "\n", "while", "cur_epoch", "<", "opts", ".", "epochs", "and", "not", "opts", ".", "test", ":", "\n", "# =====  Train  =====", "\n", "        ", "model", ".", "train", "(", ")", "\n", "\n", "epoch_loss", "=", "trainer", ".", "train", "(", "cur_epoch", "=", "cur_epoch", ",", "optim", "=", "optimizer", ",", "train_loader", "=", "train_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "logger", "=", "logger", ")", "\n", "\n", "logger", ".", "info", "(", "f\"End of Epoch {cur_epoch}/{opts.epochs -1}, Class Loss={epoch_loss},\"", ")", "\n", "\n", "# =====  Log metrics on Tensorboard =====", "\n", "logger", ".", "add_scalar", "(", "\"E-Loss/E-Loss\"", ",", "epoch_loss", ",", "cur_epoch", ")", "\n", "\n", "# =====  Validation  =====", "\n", "\n", "if", "(", "cur_epoch", "+", "1", ")", "%", "opts", ".", "val_interval", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"validate on val set...\"", ")", "\n", "model", ".", "eval", "(", ")", "\n", "val_loss", ",", "val_score", ",", "ret_samples", "=", "trainer", ".", "validate", "(", "loader", "=", "val_loader", ",", "metrics", "=", "val_metrics", ",", "\n", "logger", "=", "logger", ",", "ret_samples_ids", "=", "sample_ids", ")", "\n", "\n", "logger", ".", "print", "(", "\"Done validation\"", ")", "\n", "logger", ".", "info", "(", "f\"End of Validation {cur_epoch}/{opts.epochs}, Validation Loss={val_loss}\"", ")", "\n", "\n", "logger", ".", "info", "(", "val_metrics", ".", "to_str", "(", "val_score", ")", ")", "\n", "\n", "# =====  Log metrics on Tensorboard =====", "\n", "# visualize validation score and samples", "\n", "logger", ".", "add_scalar", "(", "\"V-Loss\"", ",", "val_loss", ",", "cur_epoch", ")", "\n", "logger", ".", "add_scalar", "(", "\"Val_Overall_Acc\"", ",", "val_score", "[", "'Overall Acc'", "]", ",", "cur_epoch", ")", "\n", "logger", ".", "add_scalar", "(", "\"Val_MeanIoU\"", ",", "val_score", "[", "'Mean IoU'", "]", ",", "cur_epoch", ")", "\n", "logger", ".", "add_table", "(", "\"Val_Class_IoU\"", ",", "val_score", "[", "'Class IoU'", "]", ",", "cur_epoch", ")", "\n", "logger", ".", "add_table", "(", "\"Val_Acc_IoU\"", ",", "val_score", "[", "'Class Acc'", "]", ",", "cur_epoch", ")", "\n", "logger", ".", "add_figure", "(", "\"Val_Confusion_Matrix\"", ",", "val_score", "[", "'Confusion Matrix'", "]", ",", "cur_epoch", ")", "\n", "\n", "for", "k", ",", "(", "img", ",", "target", ")", "in", "enumerate", "(", "ret_samples", ")", ":", "\n", "                ", "img", "=", "(", "denorm", "(", "img", ")", "*", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "target", "=", "label2color", "(", "target", ")", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "concat_img", "=", "np", ".", "concatenate", "(", "(", "img", ",", "target", ")", ",", "axis", "=", "2", ")", "# concat along width", "\n", "logger", ".", "add_image", "(", "f'Validation_sample_{k}'", ",", "concat_img", ",", "cur_epoch", ")", "\n", "\n", "# keep the metric to print them at the end of training", "\n", "", "results", "[", "\"V-IoU\"", "]", "=", "val_score", "[", "'Class IoU'", "]", "\n", "results", "[", "\"V-Acc\"", "]", "=", "val_score", "[", "'Class Acc'", "]", "\n", "\n", "# =====  Save Model  =====", "\n", "", "if", "rank", "==", "0", ":", "# save best model at the last iteration", "\n", "            ", "score", "=", "val_score", "[", "'Mean IoU'", "]", "if", "val_score", "is", "not", "None", "else", "0.", "# use last score we have", "\n", "# best model to build incremental steps", "\n", "save_ckpt", "(", "checkpoint_path", ",", "model", ",", "trainer", ",", "optimizer", ",", "scheduler", ",", "cur_epoch", ",", "score", ")", "\n", "logger", ".", "info", "(", "\"[!] Checkpoint saved.\"", ")", "\n", "\n", "", "cur_epoch", "+=", "1", "\n", "\n", "# =====  Save Best Model at the end of training =====", "\n", "", "if", "rank", "==", "0", "and", "not", "opts", ".", "test", ":", "# save best model at the last iteration", "\n", "# best model to build incremental steps", "\n", "        ", "save_ckpt", "(", "checkpoint_path", ",", "model", ",", "trainer", ",", "optimizer", ",", "scheduler", ",", "cur_epoch", ",", "best_score", ")", "\n", "logger", ".", "info", "(", "\"[!] Best model Checkpoint saved.\"", ")", "\n", "\n", "", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "# xxx From here starts the test code", "\n", "logger", ".", "info", "(", "\"*** Test the model on all seen classes...\"", ")", "\n", "# make data loader", "\n", "test_loader", "=", "data", ".", "DataLoader", "(", "test_dst", ",", "batch_size", "=", "1", ",", "\n", "sampler", "=", "DistributedSampler", "(", "test_dst", ",", "num_replicas", "=", "world_size", ",", "rank", "=", "rank", ")", ",", "\n", "num_workers", "=", "opts", ".", "num_workers", ",", "drop_last", "=", "True", ")", "\n", "\n", "model", "=", "make_model", "(", "opts", ")", "\n", "# Put the model on GPU", "\n", "model", "=", "DistributedDataParallel", "(", "model", ".", "cuda", "(", "device", ")", ",", "device_ids", "=", "[", "opts", ".", "local_rank", "]", ",", "output_device", "=", "opts", ".", "local_rank", ")", "\n", "\n", "if", "opts", ".", "ckpt_test", "is", "not", "None", ":", "\n", "        ", "checkpoint_path", "=", "f\"checkpoints/{opts.dataset}/{opts.ckpt_test}\"", "\n", "", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"model_state\"", "]", ")", "\n", "logger", ".", "info", "(", "f\"*** Model restored from {checkpoint_path}\"", ")", "\n", "del", "checkpoint", "\n", "\n", "trainer", "=", "Trainer", "(", "model", ",", "device", "=", "device", ",", "opts", "=", "opts", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "val_score", "=", "trainer", ".", "test", "(", "loader", "=", "test_loader", ",", "metrics", "=", "val_metrics", ")", "\n", "\n", "# =====  Log test results on Tensorboard =====", "\n", "# visualize test score and samples", "\n", "logger", ".", "print", "(", "\"Done test\"", ")", "\n", "logger", ".", "info", "(", "f\"*** End of Test\"", ")", "\n", "logger", ".", "info", "(", "val_metrics", ".", "to_str", "(", "val_score", ")", ")", "\n", "logger", ".", "add_table", "(", "\"Test_Class_IoU\"", ",", "val_score", "[", "'Class IoU'", "]", ")", "\n", "logger", ".", "add_table", "(", "\"Test_Class_Acc\"", ",", "val_score", "[", "'Class Acc'", "]", ")", "\n", "logger", ".", "add_figure", "(", "\"Test_Confusion_Matrix\"", ",", "val_score", "[", "'Confusion Matrix'", "]", ")", "\n", "# logger.add_figure(\"ROC Curve\", val_score['ROC_Curve'])", "\n", "results", "[", "\"T-IoU\"", "]", "=", "val_score", "[", "'Class IoU'", "]", "\n", "results", "[", "\"T-Acc\"", "]", "=", "val_score", "[", "'Class Acc'", "]", "\n", "logger", ".", "add_results", "(", "results", ")", "\n", "\n", "logger", ".", "add_scalar", "(", "\"T_Overall_Acc\"", ",", "val_score", "[", "'Overall Acc'", "]", ")", "\n", "logger", ".", "add_scalar", "(", "\"T_MeanIoU\"", ",", "val_score", "[", "'Mean IoU'", "]", ")", "\n", "logger", ".", "add_scalar", "(", "\"T_MeanAcc\"", ",", "val_score", "[", "'Mean Acc'", "]", ")", "\n", "logger", ".", "add_scalar", "(", "\"AUROC\"", ",", "val_score", "[", "'AUROC'", "]", ")", "\n", "logger", ".", "add_scalar", "(", "\"AUPR\"", ",", "val_score", "[", "'AUPR'", "]", ")", "\n", "logger", ".", "add_scalar", "(", "\"FPR95\"", ",", "val_score", "[", "'FPR95'", "]", ")", "\n", "\n", "logger", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.__init__": [[7, 32], ["os.path.join", "logging.basicConfig", "os.makedirs", "logging.info", "tensorboardX.SummaryWriter", "SummaryWriter"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info"], ["    ", "def", "__init__", "(", "self", ",", "logdir", ",", "rank", ",", "type", "=", "'torch'", ",", "filename", "=", "None", ",", "summary", "=", "True", ",", "step", "=", "None", ")", ":", "\n", "        ", "self", ".", "logger", "=", "None", "\n", "self", ".", "type", "=", "type", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "step", "=", "step", "\n", "self", ".", "logdir_results", "=", "os", ".", "path", ".", "join", "(", "\"logs\"", ",", "\"results\"", ")", "\n", "self", ".", "summary", "=", "summary", "\n", "if", "summary", ":", "\n", "            ", "if", "type", "==", "'tensorboardX'", ":", "\n", "                ", "import", "tensorboardX", "\n", "self", ".", "logger", "=", "tensorboardX", ".", "SummaryWriter", "(", "logdir", ")", "\n", "", "elif", "type", "==", "\"torch\"", ":", "\n", "                ", "from", "torch", ".", "utils", ".", "tensorboard", "import", "SummaryWriter", "\n", "self", ".", "logger", "=", "SummaryWriter", "(", "logdir", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "type", "=", "'None'", "\n", "\n", "\n", "", "logging", ".", "basicConfig", "(", "filename", "=", "filename", ",", "level", "=", "logging", ".", "INFO", ",", "format", "=", "f'%(levelname)s:rank{rank}: %(message)s'", ")", "\n", "\n", "if", "rank", "==", "0", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "logdir_results", ",", "exist_ok", "=", "True", ")", "\n", "logging", ".", "info", "(", "f\"[!] starting logging at directory {logdir}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.close": [[34, 38], ["logger.Logger.info", "logger.Logger.logger.close"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.close"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "logger", "is", "not", "None", ":", "\n", "            ", "self", ".", "logger", ".", "close", "(", ")", "\n", "", "self", ".", "info", "(", "\"Closing the Logger.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_scalar": [[39, 43], ["logger.Logger.is_not_none", "logger.Logger._transform_tag", "logger.Logger.logger.add_scalar"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.is_not_none", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger._transform_tag", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_scalar"], ["", "def", "add_scalar", "(", "self", ",", "tag", ",", "scalar_value", ",", "step", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "is_not_none", "(", ")", ":", "\n", "            ", "tag", "=", "self", ".", "_transform_tag", "(", "tag", ")", "\n", "self", ".", "logger", ".", "add_scalar", "(", "tag", ",", "scalar_value", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_image": [[44, 48], ["logger.Logger.is_not_none", "logger.Logger._transform_tag", "logger.Logger.logger.add_image"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.is_not_none", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger._transform_tag", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_image"], ["", "", "def", "add_image", "(", "self", ",", "tag", ",", "image", ",", "step", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "is_not_none", "(", ")", ":", "\n", "            ", "tag", "=", "self", ".", "_transform_tag", "(", "tag", ")", "\n", "self", ".", "logger", ".", "add_image", "(", "tag", ",", "image", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_figure": [[49, 53], ["logger.Logger.is_not_none", "logger.Logger._transform_tag", "logger.Logger.logger.add_figure"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.is_not_none", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger._transform_tag", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_figure"], ["", "", "def", "add_figure", "(", "self", ",", "tag", ",", "image", ",", "step", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "is_not_none", "(", ")", ":", "\n", "            ", "tag", "=", "self", ".", "_transform_tag", "(", "tag", ")", "\n", "self", ".", "logger", ".", "add_figure", "(", "tag", ",", "image", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_table": [[54, 70], ["logger.Logger.is_not_none", "logger.Logger._transform_tag", "tbl.items", "logger.Logger.logger.add_text"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.is_not_none", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger._transform_tag"], ["", "", "def", "add_table", "(", "self", ",", "tag", ",", "tbl", ",", "step", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "is_not_none", "(", ")", ":", "\n", "            ", "tag", "=", "self", ".", "_transform_tag", "(", "tag", ")", "\n", "tbl_str", "=", "\"<table width=\\\"100%\\\"> \"", "\n", "tbl_str", "+=", "\"<tr> \\\n                     <th>Term</th> \\\n                     <th>Value</th> \\\n                     </tr>\"", "\n", "for", "k", ",", "v", "in", "tbl", ".", "items", "(", ")", ":", "\n", "                ", "tbl_str", "+=", "\"<tr> \\\n                           <td>%s</td> \\\n                           <td>%s</td> \\\n                           </tr>\"", "%", "(", "k", ",", "v", ")", "\n", "\n", "", "tbl_str", "+=", "\"</table>\"", "\n", "self", ".", "logger", ".", "add_text", "(", "tag", ",", "tbl_str", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.add_results": [[71, 79], ["logger.Logger.is_not_none", "logger.Logger._transform_tag", "results.items", "logger.Logger.logger.add_text", "str", "res.values"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.is_not_none", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger._transform_tag"], ["", "", "def", "add_results", "(", "self", ",", "results", ",", "tag", "=", "\"Results\"", ")", ":", "\n", "        ", "if", "self", ".", "is_not_none", "(", ")", ":", "\n", "            ", "tag", "=", "self", ".", "_transform_tag", "(", "tag", ")", "\n", "text", "=", "\"<table width=\\\"100%\\\">\"", "\n", "for", "k", ",", "res", "in", "results", ".", "items", "(", ")", ":", "\n", "                ", "text", "+=", "f\"<tr><td>{k}</td>\"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "f'<td>{x}</td>'", ")", "for", "x", "in", "res", ".", "values", "(", ")", "]", ")", "+", "\"</tr>\"", "\n", "", "text", "+=", "\"</table>\"", "\n", "self", ".", "logger", ".", "add_text", "(", "tag", ",", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.print": [[80, 82], ["logging.info"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info"], ["", "", "def", "print", "(", "self", ",", "msg", ")", ":", "\n", "        ", "logging", ".", "info", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info": [[83, 86], ["logging.info"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.info"], ["", "def", "info", "(", "self", ",", "msg", ")", ":", "\n", "        ", "if", "self", ".", "rank", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.error": [[87, 89], ["logging.error"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.error"], ["", "", "def", "error", "(", "self", ",", "msg", ")", ":", "\n", "        ", "logging", ".", "error", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.log_results": [[90, 100], ["text.append", "open", "file.write", "str"], "methods", ["None"], ["", "def", "log_results", "(", "self", ",", "task", ",", "name", ",", "results", ",", "novel", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "rank", "==", "0", ":", "\n", "            ", "file_name", "=", "f\"{task}.csv\"", "if", "not", "novel", "else", "f\"{task}_novel.csv\"", "\n", "path", "=", "f\"{self.logdir_results}/{file_name}\"", "\n", "text", "=", "[", "name", "]", "\n", "for", "val", "in", "results", ":", "\n", "                ", "text", ".", "append", "(", "str", "(", "val", ")", ")", "\n", "", "row", "=", "\",\"", ".", "join", "(", "text", ")", "+", "\"\\n\"", "\n", "with", "open", "(", "path", ",", "\"a\"", ")", "as", "file", ":", "\n", "                ", "file", ".", "write", "(", "row", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger._transform_tag": [[101, 104], ["None"], "methods", ["None"], ["", "", "", "def", "_transform_tag", "(", "self", ",", "tag", ")", ":", "\n", "        ", "tag", "=", "tag", "+", "f\"/{self.step}\"", "if", "self", ".", "step", "is", "not", "None", "else", "tag", "\n", "return", "tag", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.is_not_none": [[105, 107], ["None"], "methods", ["None"], ["", "def", "is_not_none", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "type", "!=", "\"None\"", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.scheduler.PolyLR.__init__": [[4, 8], ["torch.optim.lr_scheduler._LRScheduler.__init__"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "optimizer", ",", "max_iters", ",", "power", "=", "0.9", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "power", "=", "power", "\n", "self", ".", "max_iters", "=", "max_iters", "\n", "super", "(", "PolyLR", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.scheduler.PolyLR.get_lr": [[9, 12], ["None"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "return", "[", "base_lr", "*", "(", "1", "-", "self", ".", "last_epoch", "/", "self", ".", "max_iters", ")", "**", "self", ".", "power", "\n", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.utils.Denormalize.__init__": [[17, 22], ["numpy.array", "numpy.array"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "mean", "=", "np", ".", "array", "(", "mean", ")", "\n", "std", "=", "np", ".", "array", "(", "std", ")", "\n", "self", ".", "_mean", "=", "-", "mean", "/", "std", "\n", "self", ".", "_std", "=", "1", "/", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.utils.Denormalize.__call__": [[23, 27], ["isinstance", "torchvision.transforms.functional.normalize", "utils.Denormalize._std.reshape", "utils.Denormalize._mean.reshape"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "if", "isinstance", "(", "tensor", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "return", "(", "tensor", "-", "self", ".", "_mean", ".", "reshape", "(", "-", "1", ",", "1", ",", "1", ")", ")", "/", "self", ".", "_std", ".", "reshape", "(", "-", "1", ",", "1", ",", "1", ")", "\n", "", "return", "normalize", "(", "tensor", ",", "self", ".", "_mean", ",", "self", ".", "_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.utils.Label2Color.__init__": [[68, 70], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "cmap", ")", ":", "\n", "        ", "self", ".", "cmap", "=", "cmap", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.utils.Label2Color.__call__": [[71, 73], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "lbls", ")", ":", "\n", "        ", "return", "self", ".", "cmap", "[", "lbls", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.utils.denormalize": [[7, 14], ["numpy.array", "numpy.array", "torchvision.transforms.functional.normalize"], "function", ["None"], ["def", "denormalize", "(", "tensor", ",", "mean", ",", "std", ")", ":", "\n", "    ", "mean", "=", "np", ".", "array", "(", "mean", ")", "\n", "std", "=", "np", ".", "array", "(", "std", ")", "\n", "\n", "_mean", "=", "-", "mean", "/", "std", "\n", "_std", "=", "1", "/", "std", "\n", "return", "normalize", "(", "tensor", ",", "_mean", ",", "_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.utils.fix_bn": [[29, 35], ["model.modules", "isinstance", "m.eval"], "function", ["None"], ["", "", "def", "fix_bn", "(", "model", ")", ":", "\n", "    ", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "            ", "m", ".", "eval", "(", ")", "\n", "m", ".", "weight", ".", "requires_grad", "=", "False", "\n", "m", ".", "bias", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.utils.color_map": [[37, 40], ["utils.streethazards_cmap"], "function", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.utils.streethazards_cmap"], ["", "", "", "def", "color_map", "(", "dataset", ")", ":", "\n", "    ", "if", "dataset", "==", "'streethazards'", ":", "\n", "        ", "return", "streethazards_cmap", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.utils.streethazards_cmap": [[41, 66], ["numpy.zeros"], "function", ["None"], ["", "", "def", "streethazards_cmap", "(", ")", ":", "\n", "# Left: modified labels after -1. Right: original label", "\n", "# total classes on which the model is trained: 13 (12 common classes + sky/unlabeled)", "\n", "# total classes with anomaly: 14", "\n", "    ", "cmap", "=", "np", ".", "zeros", "(", "(", "256", ",", "3", ")", ")", "\n", "\n", "cmap", "[", "255", "]", "=", "[", "0", ",", "0", ",", "0", "]", "# // padding       =   -1 (n.d.) # padding, to ignore", "\n", "\n", "cmap", "[", "0", "]", "=", "[", "0", ",", "0", ",", "0", "]", "# // unlabeled     =   0 (1)     # sky and unlabeled (used in training)", "\n", "cmap", "[", "1", "]", "=", "[", "70", ",", "70", ",", "70", "]", "# // building      =   1 (2),", "\n", "cmap", "[", "2", "]", "=", "[", "190", ",", "153", ",", "153", "]", "# // fence         =   2 (3),", "\n", "cmap", "[", "3", "]", "=", "[", "250", ",", "170", ",", "160", "]", "# // other         =   3 (4),    # background", "\n", "cmap", "[", "4", "]", "=", "[", "220", ",", "20", ",", "60", "]", "# // pedestrian    =   4 (5),", "\n", "cmap", "[", "5", "]", "=", "[", "153", ",", "153", ",", "153", "]", "# // pole          =   5 (6),", "\n", "cmap", "[", "6", "]", "=", "[", "157", ",", "234", ",", "50", "]", "# // road line     =   6 (7),", "\n", "cmap", "[", "7", "]", "=", "[", "128", ",", "64", ",", "128", "]", "# // road          =   7 (8),", "\n", "cmap", "[", "8", "]", "=", "[", "244", ",", "35", ",", "232", "]", "# // sidewalk      =   8 (9),", "\n", "cmap", "[", "9", "]", "=", "[", "107", ",", "142", ",", "35", "]", "# // vegetation    =   9 (10),", "\n", "cmap", "[", "10", "]", "=", "[", "0", ",", "0", ",", "142", "]", "# // car           =  10 (11),", "\n", "cmap", "[", "11", "]", "=", "[", "102", ",", "102", ",", "156", "]", "# // wall          =  11 (12),", "\n", "cmap", "[", "12", "]", "=", "[", "220", ",", "220", ",", "0", "]", "# // traffic sign  =  12 (13),", "\n", "\n", "cmap", "[", "13", "]", "=", "[", "60", ",", "250", ",", "240", "]", "# // anomaly       =  13 (14)", "\n", "\n", "return", "cmap", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.streethazards.StreetHazardsSegmentation.__init__": [[10, 29], ["os.path.expanduser", "os.path.join", "os.path.join", "open", "os.path.join", "json.loads", "handler.rstrip", "os.path.join", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "split", "=", "'train'", ",", "transform", "=", "None", ",", "basic_transform", "=", "None", ",", "multiple_resizes_test", "=", "False", ")", ":", "\n", "\n", "        ", "root", "=", "os", ".", "path", ".", "expanduser", "(", "root", ")", "\n", "self", ".", "base_dir", "=", "\"StreetHazards\"", "\n", "root", "=", "os", ".", "path", ".", "join", "(", "root", ",", "self", ".", "base_dir", ")", "\n", "main_folder", "=", "os", ".", "path", ".", "join", "(", "root", ",", "split", ")", "\n", "\n", "self", ".", "images", "=", "[", "]", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "split", ",", "split", "+", "\".odgt\"", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "handler", "in", "f", ":", "\n", "                ", "fnames", "=", "json", ".", "loads", "(", "handler", ".", "rstrip", "(", ")", ")", "\n", "\n", "self", ".", "images", "=", "[", "(", "os", ".", "path", ".", "join", "(", "main_folder", ",", "x", "[", "'fpath_img'", "]", ")", ",", "os", ".", "path", ".", "join", "(", "main_folder", ",", "x", "[", "'fpath_segm'", "]", ")", ")", "\n", "for", "x", "in", "fnames", "]", "\n", "\n", "", "", "self", ".", "transform", "=", "transform", "\n", "self", ".", "basic_transform", "=", "basic_transform", "\n", "self", ".", "multiple_resizes_test", "=", "multiple_resizes_test", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.streethazards.StreetHazardsSegmentation.__getitem__": [[30, 54], ["PIL.Image.open().convert", "PIL.Image.open", "PIL.Image.open", "streethazards.StreetHazardsSegmentation.basic_transform", "streethazards.StreetHazardsSegmentation.transform", "imgs.append", "t"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is the image segmentation.\n        \"\"\"", "\n", "img", "=", "Image", ".", "open", "(", "self", ".", "images", "[", "index", "]", "[", "0", "]", ")", ".", "convert", "(", "'RGB'", ")", "\n", "target", "=", "Image", ".", "open", "(", "self", ".", "images", "[", "index", "]", "[", "1", "]", ")", "\n", "assert", "(", "target", ".", "mode", "==", "\"L\"", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "multiple_resizes_test", ":", "\n", "                ", "imgs", "=", "[", "]", "\n", "for", "t", "in", "self", ".", "transform", ":", "\n", "                    ", "imgs", ".", "append", "(", "t", "(", "img", ",", "None", ")", ")", "\n", "", "_", ",", "target", "=", "self", ".", "basic_transform", "(", "img", ",", "target", ")", "\n", "img", "=", "imgs", "\n", "", "else", ":", "\n", "                ", "img", ",", "target", "=", "self", ".", "transform", "(", "img", ",", "target", ")", "\n", "\n", "", "target", "=", "target", "-", "1", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.streethazards.StreetHazardsSegmentation.__len__": [[55, 57], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "images", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.Compose.__init__": [[29, 31], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.Compose.__call__": [[32, 41], ["t", "t"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ",", "lbl", "=", "None", ")", ":", "\n", "        ", "if", "lbl", "is", "not", "None", ":", "\n", "            ", "for", "t", "in", "self", ".", "transforms", ":", "\n", "                ", "img", ",", "lbl", "=", "t", "(", "img", ",", "lbl", ")", "\n", "", "return", "img", ",", "lbl", "\n", "", "else", ":", "\n", "            ", "for", "t", "in", "self", ".", "transforms", ":", "\n", "                ", "img", "=", "t", "(", "img", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.Compose.__repr__": [[42, 49], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'('", "\n", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "format_string", "+=", "'\\n'", "\n", "format_string", "+=", "'    {0}'", ".", "format", "(", "t", ")", "\n", "", "format_string", "+=", "'\\n)'", "\n", "return", "format_string", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.Resize.__init__": [[64, 68], ["isinstance", "isinstance", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "interpolation", "=", "Image", ".", "BILINEAR", ")", ":", "\n", "        ", "assert", "isinstance", "(", "size", ",", "int", ")", "or", "(", "isinstance", "(", "size", ",", "collections", ".", "Iterable", ")", "and", "len", "(", "size", ")", "==", "2", ")", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.Resize.__call__": [[69, 81], ["torchvision.resize", "torchvision.resize", "torchvision.resize"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ",", "lbl", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be scaled.\n\n        Returns:\n            PIL Image: Rescaled image.\n        \"\"\"", "\n", "if", "lbl", "is", "not", "None", ":", "\n", "            ", "return", "F", ".", "resize", "(", "img", ",", "self", ".", "size", ",", "self", ".", "interpolation", ")", ",", "F", ".", "resize", "(", "lbl", ",", "self", ".", "size", ",", "Image", ".", "NEAREST", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "resize", "(", "img", ",", "self", ".", "size", ",", "self", ".", "interpolation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.Resize.__repr__": [[82, 85], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "interpolate_str", "=", "_pil_interpolation_to_str", "[", "self", ".", "interpolation", "]", "\n", "return", "self", ".", "__class__", ".", "__name__", "+", "'(size={0}, interpolation={1})'", ".", "format", "(", "self", ".", "size", ",", "interpolate_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.CenterCrop.__init__": [[96, 101], ["isinstance", "int", "int"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "self", ".", "size", "=", "(", "int", "(", "size", ")", ",", "int", "(", "size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.CenterCrop.__call__": [[102, 114], ["torchvision.center_crop", "torchvision.center_crop", "torchvision.center_crop"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "img", ",", "lbl", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be cropped.\n\n        Returns:\n            PIL Image: Cropped image.\n        \"\"\"", "\n", "if", "lbl", "is", "not", "None", ":", "\n", "            ", "return", "F", ".", "center_crop", "(", "img", ",", "self", ".", "size", ")", ",", "F", ".", "center_crop", "(", "lbl", ",", "self", ".", "size", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "center_crop", "(", "img", ",", "self", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.CenterCrop.__repr__": [[115, 117], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f'(size={self.size})'", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.Pad.__init__": [[141, 152], ["isinstance", "isinstance", "isinstance", "ValueError", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "padding", ",", "fill", "=", "0", ",", "padding_mode", "=", "'constant'", ")", ":", "\n", "        ", "assert", "isinstance", "(", "padding", ",", "(", "numbers", ".", "Number", ",", "tuple", ")", ")", "\n", "assert", "isinstance", "(", "fill", ",", "(", "numbers", ".", "Number", ",", "str", ")", ")", "\n", "assert", "padding_mode", "in", "[", "'constant'", ",", "'edge'", ",", "'reflect'", ",", "'symmetric'", "]", "\n", "if", "isinstance", "(", "padding", ",", "collections", ".", "Sequence", ")", "and", "len", "(", "padding", ")", "not", "in", "[", "2", ",", "4", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\"Padding must be an int or a 2, or 4 element tuple, not a \"", "+", "\n", "\"{} element tuple\"", ".", "format", "(", "len", "(", "padding", ")", ")", ")", "\n", "\n", "", "self", ".", "padding", "=", "padding", "\n", "self", ".", "fill", "=", "fill", "\n", "self", ".", "padding_mode", "=", "padding_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.Pad.__call__": [[153, 164], ["torchvision.pad", "torchvision.pad", "torchvision.pad"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ",", "lbl", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be padded.\n        Returns:\n            PIL Image: Padded image.\n        \"\"\"", "\n", "if", "lbl", "is", "not", "None", ":", "\n", "            ", "return", "F", ".", "pad", "(", "img", ",", "self", ".", "padding", ",", "self", ".", "fill", ",", "self", ".", "padding_mode", ")", ",", "F", ".", "pad", "(", "lbl", ",", "self", ".", "padding", ",", "self", ".", "fill", ",", "self", ".", "padding_mode", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "pad", "(", "img", ",", "self", ".", "padding", ",", "self", ".", "fill", ",", "self", ".", "padding_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.Pad.__repr__": [[165, 168], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(padding={0}, fill={1}, padding_mode={2})'", ".", "format", "(", "self", ".", "padding", ",", "self", ".", "fill", ",", "self", ".", "padding_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.Lambda.__init__": [[176, 179], ["callable", "repr", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "lambd", ")", ":", "\n", "        ", "assert", "callable", "(", "lambd", ")", ",", "repr", "(", "type", "(", "lambd", ")", ".", "__name__", ")", "+", "\" object is not callable\"", "\n", "self", ".", "lambd", "=", "lambd", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.Lambda.__call__": [[180, 185], ["transform.Lambda.lambd", "transform.Lambda.lambd", "transform.Lambda.lambd"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ",", "lbl", "=", "None", ")", ":", "\n", "        ", "if", "lbl", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "lambd", "(", "img", ")", ",", "self", ".", "lambd", "(", "lbl", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "lambd", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.Lambda.__repr__": [[186, 188], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'()'", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomRotation.__init__": [[210, 223], ["isinstance", "ValueError", "len", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "degrees", ",", "resample", "=", "False", ",", "expand", "=", "False", ",", "center", "=", "None", ")", ":", "\n", "        ", "if", "isinstance", "(", "degrees", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "if", "degrees", "<", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\"If degrees is a single number, it must be positive.\"", ")", "\n", "", "self", ".", "degrees", "=", "(", "-", "degrees", ",", "degrees", ")", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "degrees", ")", "!=", "2", ":", "\n", "                ", "raise", "ValueError", "(", "\"If degrees is a sequence, it must be of len 2.\"", ")", "\n", "", "self", ".", "degrees", "=", "degrees", "\n", "\n", "", "self", ".", "resample", "=", "resample", "\n", "self", ".", "expand", "=", "expand", "\n", "self", ".", "center", "=", "center", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomRotation.get_params": [[224, 234], ["random.uniform"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_params", "(", "degrees", ")", ":", "\n", "        ", "\"\"\"Get parameters for ``rotate`` for a random rotation.\n\n        Returns:\n            sequence: params to be passed to ``rotate`` for random rotation.\n        \"\"\"", "\n", "angle", "=", "random", ".", "uniform", "(", "degrees", "[", "0", "]", ",", "degrees", "[", "1", "]", ")", "\n", "\n", "return", "angle", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomRotation.__call__": [[235, 251], ["transform.RandomRotation.get_params", "torchvision.rotate", "torchvision.rotate", "torchvision.rotate"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.ColorJitter.get_params"], ["", "def", "__call__", "(", "self", ",", "img", ",", "lbl", ")", ":", "\n", "        ", "\"\"\"\n            img (PIL Image): Image to be rotated.\n            lbl (PIL Image): Label to be rotated.\n\n        Returns:\n            PIL Image: Rotated image.\n            PIL Image: Rotated label.\n        \"\"\"", "\n", "\n", "angle", "=", "self", ".", "get_params", "(", "self", ".", "degrees", ")", "\n", "if", "lbl", "is", "not", "None", ":", "\n", "            ", "return", "F", ".", "rotate", "(", "img", ",", "angle", ",", "self", ".", "resample", ",", "self", ".", "expand", ",", "self", ".", "center", ")", ",", "F", ".", "rotate", "(", "lbl", ",", "angle", ",", "self", ".", "resample", ",", "self", ".", "expand", ",", "self", ".", "center", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "rotate", "(", "img", ",", "angle", ",", "self", ".", "resample", ",", "self", ".", "expand", ",", "self", ".", "center", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomRotation.__repr__": [[252, 260], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'(degrees={0}'", ".", "format", "(", "self", ".", "degrees", ")", "\n", "format_string", "+=", "', resample={0}'", ".", "format", "(", "self", ".", "resample", ")", "\n", "format_string", "+=", "', expand={0}'", ".", "format", "(", "self", ".", "expand", ")", "\n", "if", "self", ".", "center", "is", "not", "None", ":", "\n", "            ", "format_string", "+=", "', center={0}'", ".", "format", "(", "self", ".", "center", ")", "\n", "", "format_string", "+=", "')'", "\n", "return", "format_string", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomHorizontalFlip.__init__": [[269, 271], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "p", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "p", "=", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomHorizontalFlip.__call__": [[272, 289], ["random.random", "torchvision.hflip", "torchvision.hflip", "torchvision.hflip"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ",", "lbl", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be flipped.\n\n        Returns:\n            PIL Image: Randomly flipped image.\n        \"\"\"", "\n", "if", "random", ".", "random", "(", ")", "<", "self", ".", "p", ":", "\n", "            ", "if", "lbl", "is", "not", "None", ":", "\n", "                ", "return", "F", ".", "hflip", "(", "img", ")", ",", "F", ".", "hflip", "(", "lbl", ")", "\n", "", "else", ":", "\n", "                ", "return", "F", ".", "hflip", "(", "img", ")", "\n", "", "", "if", "lbl", "is", "not", "None", ":", "\n", "            ", "return", "img", ",", "lbl", "\n", "", "else", ":", "\n", "            ", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomHorizontalFlip.__repr__": [[290, 292], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(p={})'", ".", "format", "(", "self", ".", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomVerticalFlip.__init__": [[301, 303], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "p", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "p", "=", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomVerticalFlip.__call__": [[304, 323], ["random.random", "torchvision.vflip", "torchvision.vflip", "torchvision.vflip"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ",", "lbl", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be flipped.\n            lbl (PIL Image): Label to be flipped.\n\n        Returns:\n            PIL Image: Randomly flipped image.\n            PIL Image: Randomly flipped label.\n        \"\"\"", "\n", "if", "random", ".", "random", "(", ")", "<", "self", ".", "p", ":", "\n", "            ", "if", "lbl", "is", "not", "None", ":", "\n", "                ", "return", "F", ".", "vflip", "(", "img", ")", ",", "F", ".", "vflip", "(", "lbl", ")", "\n", "", "else", ":", "\n", "                ", "return", "F", ".", "vflip", "(", "img", ")", "\n", "", "", "if", "lbl", "is", "not", "None", ":", "\n", "            ", "return", "img", ",", "lbl", "\n", "", "else", ":", "\n", "            ", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomVerticalFlip.__repr__": [[324, 326], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(p={})'", ".", "format", "(", "self", ".", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomScale.__init__": [[335, 338], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "scale_range", ",", "interpolation", "=", "Image", ".", "BILINEAR", ")", ":", "\n", "        ", "self", ".", "scale_range", "=", "scale_range", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomScale.__call__": [[339, 357], ["random.uniform", "int", "int", "torchvision.resize", "torchvision.resize", "torchvision.resize"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ",", "lbl", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be scaled.\n            lbl (PIL Image): Label to be scaled.\n        Returns:\n            PIL Image: Rescaled image.\n            PIL Image: Rescaled label.\n        \"\"\"", "\n", "if", "lbl", "is", "not", "None", ":", "\n", "            ", "assert", "img", ".", "size", "==", "lbl", ".", "size", "\n", "", "scale", "=", "random", ".", "uniform", "(", "self", ".", "scale_range", "[", "0", "]", ",", "self", ".", "scale_range", "[", "1", "]", ")", "\n", "target_size", "=", "(", "int", "(", "img", ".", "size", "[", "1", "]", "*", "scale", ")", ",", "int", "(", "img", ".", "size", "[", "0", "]", "*", "scale", ")", ")", "\n", "\n", "if", "lbl", "is", "not", "None", ":", "\n", "            ", "return", "F", ".", "resize", "(", "img", ",", "target_size", ",", "self", ".", "interpolation", ")", ",", "F", ".", "resize", "(", "lbl", ",", "target_size", ",", "Image", ".", "NEAREST", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "resize", "(", "img", ",", "target_size", ",", "self", ".", "interpolation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomScale.__repr__": [[358, 361], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "interpolate_str", "=", "_pil_interpolation_to_str", "[", "self", ".", "interpolation", "]", "\n", "return", "self", ".", "__class__", ".", "__name__", "+", "'(scale_range={0}, interpolation={1})'", ".", "format", "(", "self", ".", "scale_range", ",", "interpolate_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.ToTensor.__call__": [[374, 388], ["torchvision.to_tensor", "torchvision.to_tensor", "torch.from_numpy", "numpy.array"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "pic", ",", "lbl", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Note that labels will not be normalized to [0, 1].\n\n        Args:\n            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n            lbl (PIL Image or numpy.ndarray): Label to be converted to tensor.\n        Returns:\n            Tensor: Converted image and label\n        \"\"\"", "\n", "if", "lbl", "is", "not", "None", ":", "\n", "            ", "return", "F", ".", "to_tensor", "(", "pic", ")", ",", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "lbl", ",", "dtype", "=", "np", ".", "uint8", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "to_tensor", "(", "pic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.ToTensor.__repr__": [[389, 391], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'()'", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.Normalize.__init__": [[404, 407], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.Normalize.__call__": [[408, 421], ["torchvision.normalize", "torchvision.normalize"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "tensor", ",", "lbl", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n            tensor (Tensor): Tensor of label. A dummy input for ExtCompose\n        Returns:\n            Tensor: Normalized Tensor image.\n            Tensor: Unchanged Tensor label\n        \"\"\"", "\n", "if", "lbl", "is", "not", "None", ":", "\n", "            ", "return", "F", ".", "normalize", "(", "tensor", ",", "self", ".", "mean", ",", "self", ".", "std", ")", ",", "lbl", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "normalize", "(", "tensor", ",", "self", ".", "mean", ",", "self", ".", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.Normalize.__repr__": [[422, 424], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(mean={0}, std={1})'", ".", "format", "(", "self", ".", "mean", ",", "self", ".", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomCrop.__init__": [[441, 448], ["isinstance", "int", "int"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "padding", "=", "0", ",", "pad_if_needed", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "self", ".", "size", "=", "(", "int", "(", "size", ")", ",", "int", "(", "size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "size", "=", "size", "\n", "", "self", ".", "padding", "=", "padding", "\n", "self", ".", "pad_if_needed", "=", "pad_if_needed", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomCrop.get_params": [[449, 468], ["random.randint", "random.randint"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_params", "(", "img", ",", "output_size", ")", ":", "\n", "        ", "\"\"\"Get parameters for ``crop`` for a random crop.\n\n        Args:\n            img (PIL Image): Image to be cropped.\n            output_size (tuple): Expected output size of the crop.\n\n        Returns:\n            tuple: params (i, j, h, w) to be passed to ``crop`` for random crop.\n        \"\"\"", "\n", "w", ",", "h", "=", "img", ".", "size", "\n", "th", ",", "tw", "=", "output_size", "\n", "if", "w", "==", "tw", "and", "h", "==", "th", ":", "\n", "            ", "return", "0", ",", "0", ",", "h", ",", "w", "\n", "\n", "", "i", "=", "random", ".", "randint", "(", "0", ",", "h", "-", "th", ")", "\n", "j", "=", "random", ".", "randint", "(", "0", ",", "w", "-", "tw", ")", "\n", "return", "i", ",", "j", ",", "th", ",", "tw", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomCrop.__call__": [[469, 511], ["transform.RandomCrop.get_params", "torchvision.crop", "transform.RandomCrop.get_params", "torchvision.pad", "torchvision.pad", "torchvision.pad", "torchvision.pad", "torchvision.pad", "torchvision.pad", "torchvision.pad", "torchvision.pad", "torchvision.pad", "torchvision.crop", "torchvision.crop", "int", "int", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.ColorJitter.get_params", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.ColorJitter.get_params"], ["", "def", "__call__", "(", "self", ",", "img", ",", "lbl", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be cropped.\n            lbl (PIL Image): Label to be cropped.\n        Returns:\n            PIL Image: Cropped image.\n            PIL Image: Cropped label.\n        \"\"\"", "\n", "if", "lbl", "is", "None", ":", "\n", "            ", "if", "self", ".", "padding", ">", "0", ":", "\n", "                ", "img", "=", "F", ".", "pad", "(", "img", ",", "self", ".", "padding", ")", "\n", "# pad the width if needed", "\n", "", "if", "self", ".", "pad_if_needed", "and", "img", ".", "size", "[", "0", "]", "<", "self", ".", "size", "[", "1", "]", ":", "\n", "                ", "img", "=", "F", ".", "pad", "(", "img", ",", "padding", "=", "int", "(", "(", "1", "+", "self", ".", "size", "[", "1", "]", "-", "img", ".", "size", "[", "0", "]", ")", "/", "2", ")", ")", "\n", "# pad the height if needed", "\n", "", "if", "self", ".", "pad_if_needed", "and", "img", ".", "size", "[", "1", "]", "<", "self", ".", "size", "[", "0", "]", ":", "\n", "                ", "img", "=", "F", ".", "pad", "(", "img", ",", "padding", "=", "int", "(", "(", "1", "+", "self", ".", "size", "[", "0", "]", "-", "img", ".", "size", "[", "1", "]", ")", "/", "2", ")", ")", "\n", "\n", "", "i", ",", "j", ",", "h", ",", "w", "=", "self", ".", "get_params", "(", "img", ",", "self", ".", "size", ")", "\n", "\n", "return", "F", ".", "crop", "(", "img", ",", "i", ",", "j", ",", "h", ",", "w", ")", "\n", "\n", "", "else", ":", "\n", "            ", "assert", "img", ".", "size", "==", "lbl", ".", "size", ",", "'size of img and lbl should be the same. %s, %s'", "%", "(", "img", ".", "size", ",", "lbl", ".", "size", ")", "\n", "if", "self", ".", "padding", ">", "0", ":", "\n", "                ", "img", "=", "F", ".", "pad", "(", "img", ",", "self", ".", "padding", ")", "\n", "lbl", "=", "F", ".", "pad", "(", "lbl", ",", "self", ".", "padding", ")", "\n", "\n", "# pad the width if needed", "\n", "", "if", "self", ".", "pad_if_needed", "and", "img", ".", "size", "[", "0", "]", "<", "self", ".", "size", "[", "1", "]", ":", "\n", "                ", "img", "=", "F", ".", "pad", "(", "img", ",", "padding", "=", "int", "(", "(", "1", "+", "self", ".", "size", "[", "1", "]", "-", "img", ".", "size", "[", "0", "]", ")", "/", "2", ")", ")", "\n", "lbl", "=", "F", ".", "pad", "(", "lbl", ",", "padding", "=", "int", "(", "(", "1", "+", "self", ".", "size", "[", "1", "]", "-", "lbl", ".", "size", "[", "0", "]", ")", "/", "2", ")", ",", "fill", "=", "0", ")", "\n", "\n", "# pad the height if needed", "\n", "", "if", "self", ".", "pad_if_needed", "and", "img", ".", "size", "[", "1", "]", "<", "self", ".", "size", "[", "0", "]", ":", "\n", "                ", "img", "=", "F", ".", "pad", "(", "img", ",", "padding", "=", "int", "(", "(", "1", "+", "self", ".", "size", "[", "0", "]", "-", "img", ".", "size", "[", "1", "]", ")", "/", "2", ")", ")", "\n", "lbl", "=", "F", ".", "pad", "(", "lbl", ",", "padding", "=", "int", "(", "(", "1", "+", "self", ".", "size", "[", "0", "]", "-", "lbl", ".", "size", "[", "1", "]", ")", "/", "2", ")", ",", "fill", "=", "0", ")", "\n", "\n", "", "i", ",", "j", ",", "h", ",", "w", "=", "self", ".", "get_params", "(", "img", ",", "self", ".", "size", ")", "\n", "\n", "return", "F", ".", "crop", "(", "img", ",", "i", ",", "j", ",", "h", ",", "w", ")", ",", "F", ".", "crop", "(", "lbl", ",", "i", ",", "j", ",", "h", ",", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomCrop.__repr__": [[512, 514], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(size={0}, padding={1})'", ".", "format", "(", "self", ".", "size", ",", "self", ".", "padding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomResizedCrop.__init__": [[529, 540], ["isinstance", "warnings.warn"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "scale", "=", "(", "0.08", ",", "1.0", ")", ",", "ratio", "=", "(", "3.", "/", "4.", ",", "4.", "/", "3.", ")", ",", "interpolation", "=", "Image", ".", "BILINEAR", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "tuple", ")", ":", "\n", "            ", "self", ".", "size", "=", "size", "\n", "", "else", ":", "\n", "            ", "self", ".", "size", "=", "(", "size", ",", "size", ")", "\n", "", "if", "(", "scale", "[", "0", "]", ">", "scale", "[", "1", "]", ")", "or", "(", "ratio", "[", "0", "]", ">", "ratio", "[", "1", "]", ")", ":", "\n", "            ", "warnings", ".", "warn", "(", "\"range should be of kind (min, max)\"", ")", "\n", "\n", "", "self", ".", "interpolation", "=", "interpolation", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "ratio", "=", "ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomResizedCrop.get_params": [[541, 581], ["range", "math.exp", "int", "int", "min", "int", "random.uniform", "math.log", "math.log", "random.uniform", "round", "round", "random.randint", "random.randint", "round", "max", "int", "math.sqrt", "math.sqrt", "round", "min", "max"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_params", "(", "img", ",", "scale", ",", "ratio", ")", ":", "\n", "        ", "\"\"\"Get parameters for ``crop`` for a random sized crop.\n        Args:\n            img (PIL Image): Image to be cropped.\n            scale (tuple): range of size of the origin size cropped\n            ratio (tuple): range of aspect ratio of the origin aspect ratio cropped\n        Returns:\n            tuple: params (i, j, h, w) to be passed to ``crop`` for a random\n                sized crop.\n        \"\"\"", "\n", "area", "=", "img", ".", "size", "[", "0", "]", "*", "img", ".", "size", "[", "1", "]", "\n", "\n", "for", "attempt", "in", "range", "(", "10", ")", ":", "\n", "            ", "target_area", "=", "random", ".", "uniform", "(", "*", "scale", ")", "*", "area", "\n", "log_ratio", "=", "(", "math", ".", "log", "(", "ratio", "[", "0", "]", ")", ",", "math", ".", "log", "(", "ratio", "[", "1", "]", ")", ")", "\n", "aspect_ratio", "=", "math", ".", "exp", "(", "random", ".", "uniform", "(", "*", "log_ratio", ")", ")", "\n", "\n", "w", "=", "int", "(", "round", "(", "math", ".", "sqrt", "(", "target_area", "*", "aspect_ratio", ")", ")", ")", "\n", "h", "=", "int", "(", "round", "(", "math", ".", "sqrt", "(", "target_area", "/", "aspect_ratio", ")", ")", ")", "\n", "\n", "if", "w", "<=", "img", ".", "size", "[", "0", "]", "and", "h", "<=", "img", ".", "size", "[", "1", "]", ":", "\n", "                ", "i", "=", "random", ".", "randint", "(", "0", ",", "img", ".", "size", "[", "1", "]", "-", "h", ")", "\n", "j", "=", "random", ".", "randint", "(", "0", ",", "img", ".", "size", "[", "0", "]", "-", "w", ")", "\n", "return", "i", ",", "j", ",", "h", ",", "w", "\n", "\n", "# Fallback to central crop", "\n", "", "", "in_ratio", "=", "img", ".", "size", "[", "0", "]", "/", "img", ".", "size", "[", "1", "]", "\n", "if", "(", "in_ratio", "<", "min", "(", "ratio", ")", ")", ":", "\n", "            ", "w", "=", "img", ".", "size", "[", "0", "]", "\n", "h", "=", "int", "(", "round", "(", "w", "/", "min", "(", "ratio", ")", ")", ")", "\n", "", "elif", "(", "in_ratio", ">", "max", "(", "ratio", ")", ")", ":", "\n", "            ", "h", "=", "img", ".", "size", "[", "1", "]", "\n", "w", "=", "int", "(", "round", "(", "h", "*", "max", "(", "ratio", ")", ")", ")", "\n", "", "else", ":", "# whole image", "\n", "            ", "w", "=", "img", ".", "size", "[", "0", "]", "\n", "h", "=", "img", ".", "size", "[", "1", "]", "\n", "", "i", "=", "(", "img", ".", "size", "[", "1", "]", "-", "h", ")", "//", "2", "\n", "j", "=", "(", "img", ".", "size", "[", "0", "]", "-", "w", ")", "//", "2", "\n", "return", "i", ",", "j", ",", "h", ",", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomResizedCrop.__call__": [[582, 595], ["transform.RandomResizedCrop.get_params", "torchvision.resized_crop", "torchvision.resized_crop", "torchvision.resized_crop"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.ColorJitter.get_params"], ["", "def", "__call__", "(", "self", ",", "img", ",", "lbl", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be cropped and resized.\n        Returns:\n            PIL Image: Randomly cropped and resized image.\n        \"\"\"", "\n", "i", ",", "j", ",", "h", ",", "w", "=", "self", ".", "get_params", "(", "img", ",", "self", ".", "scale", ",", "self", ".", "ratio", ")", "\n", "if", "lbl", "is", "not", "None", ":", "\n", "            ", "return", "F", ".", "resized_crop", "(", "img", ",", "i", ",", "j", ",", "h", ",", "w", ",", "self", ".", "size", ",", "self", ".", "interpolation", ")", ",", "F", ".", "resized_crop", "(", "lbl", ",", "i", ",", "j", ",", "h", ",", "w", ",", "self", ".", "size", ",", "Image", ".", "NEAREST", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "resized_crop", "(", "img", ",", "i", ",", "j", ",", "h", ",", "w", ",", "self", ".", "size", ",", "self", ".", "interpolation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.RandomResizedCrop.__repr__": [[596, 603], ["tuple", "tuple", "round", "round"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "interpolate_str", "=", "_pil_interpolation_to_str", "[", "self", ".", "interpolation", "]", "\n", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'(size={0}'", ".", "format", "(", "self", ".", "size", ")", "\n", "format_string", "+=", "', scale={0}'", ".", "format", "(", "tuple", "(", "round", "(", "s", ",", "4", ")", "for", "s", "in", "self", ".", "scale", ")", ")", "\n", "format_string", "+=", "', ratio={0}'", ".", "format", "(", "tuple", "(", "round", "(", "r", ",", "4", ")", "for", "r", "in", "self", ".", "ratio", ")", ")", "\n", "format_string", "+=", "', interpolation={0})'", ".", "format", "(", "interpolate_str", ")", "\n", "return", "format_string", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.ColorJitter.__init__": [[621, 627], ["transform.ColorJitter._check_input", "transform.ColorJitter._check_input", "transform.ColorJitter._check_input", "transform.ColorJitter._check_input"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.ColorJitter._check_input", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.ColorJitter._check_input", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.ColorJitter._check_input", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.ColorJitter._check_input"], ["def", "__init__", "(", "self", ",", "brightness", "=", "0", ",", "contrast", "=", "0", ",", "saturation", "=", "0", ",", "hue", "=", "0", ")", ":", "\n", "        ", "self", ".", "brightness", "=", "self", ".", "_check_input", "(", "brightness", ",", "'brightness'", ")", "\n", "self", ".", "contrast", "=", "self", ".", "_check_input", "(", "contrast", ",", "'contrast'", ")", "\n", "self", ".", "saturation", "=", "self", ".", "_check_input", "(", "saturation", ",", "'saturation'", ")", "\n", "self", ".", "hue", "=", "self", ".", "_check_input", "(", "hue", ",", "'hue'", ",", "center", "=", "0", ",", "bound", "=", "(", "-", "0.5", ",", "0.5", ")", ",", "\n", "clip_first_on_zero", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.ColorJitter._check_input": [[628, 646], ["isinstance", "float", "ValueError", "max", "isinstance", "TypeError", "len", "ValueError"], "methods", ["None"], ["", "def", "_check_input", "(", "self", ",", "value", ",", "name", ",", "center", "=", "1", ",", "bound", "=", "(", "0", ",", "float", "(", "'inf'", ")", ")", ",", "clip_first_on_zero", "=", "True", ")", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "if", "value", "<", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\"If {} is a single number, it must be non negative.\"", ".", "format", "(", "name", ")", ")", "\n", "", "value", "=", "[", "center", "-", "value", ",", "center", "+", "value", "]", "\n", "if", "clip_first_on_zero", ":", "\n", "                ", "value", "[", "0", "]", "=", "max", "(", "value", "[", "0", "]", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "value", ",", "(", "tuple", ",", "list", ")", ")", "and", "len", "(", "value", ")", "==", "2", ":", "\n", "            ", "if", "not", "bound", "[", "0", "]", "<=", "value", "[", "0", "]", "<=", "value", "[", "1", "]", "<=", "bound", "[", "1", "]", ":", "\n", "                ", "raise", "ValueError", "(", "\"{} values should be between {}\"", ".", "format", "(", "name", ",", "bound", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "\"{} should be a single number or a list/tuple with lenght 2.\"", ".", "format", "(", "name", ")", ")", "\n", "\n", "# if value is 0 or (1., 1.) for brightness/contrast/saturation", "\n", "# or (0., 0.) for hue, do nothing", "\n", "", "if", "value", "[", "0", "]", "==", "value", "[", "1", "]", "==", "center", ":", "\n", "            ", "value", "=", "None", "\n", "", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.ColorJitter.get_params": [[647, 677], ["random.shuffle", "Compose.Compose", "random.uniform", "transforms.append", "random.uniform", "transforms.append", "random.uniform", "transforms.append", "random.uniform", "transforms.append", "Compose.Lambda", "Compose.Lambda", "Compose.Lambda", "Compose.Lambda", "torchvision.adjust_brightness", "torchvision.adjust_contrast", "torchvision.adjust_saturation", "torchvision.adjust_hue"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_params", "(", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", ":", "\n", "        ", "\"\"\"Get a randomized transform to be applied on image.\n        Arguments are same as that of __init__.\n        Returns:\n            Transform which randomly adjusts brightness, contrast and\n            saturation in a random order.\n        \"\"\"", "\n", "transforms", "=", "[", "]", "\n", "\n", "if", "brightness", "is", "not", "None", ":", "\n", "            ", "brightness_factor", "=", "random", ".", "uniform", "(", "brightness", "[", "0", "]", ",", "brightness", "[", "1", "]", ")", "\n", "transforms", ".", "append", "(", "Lambda", "(", "lambda", "img", ":", "F", ".", "adjust_brightness", "(", "img", ",", "brightness_factor", ")", ")", ")", "\n", "\n", "", "if", "contrast", "is", "not", "None", ":", "\n", "            ", "contrast_factor", "=", "random", ".", "uniform", "(", "contrast", "[", "0", "]", ",", "contrast", "[", "1", "]", ")", "\n", "transforms", ".", "append", "(", "Lambda", "(", "lambda", "img", ":", "F", ".", "adjust_contrast", "(", "img", ",", "contrast_factor", ")", ")", ")", "\n", "\n", "", "if", "saturation", "is", "not", "None", ":", "\n", "            ", "saturation_factor", "=", "random", ".", "uniform", "(", "saturation", "[", "0", "]", ",", "saturation", "[", "1", "]", ")", "\n", "transforms", ".", "append", "(", "Lambda", "(", "lambda", "img", ":", "F", ".", "adjust_saturation", "(", "img", ",", "saturation_factor", ")", ")", ")", "\n", "\n", "", "if", "hue", "is", "not", "None", ":", "\n", "            ", "hue_factor", "=", "random", ".", "uniform", "(", "hue", "[", "0", "]", ",", "hue", "[", "1", "]", ")", "\n", "transforms", ".", "append", "(", "Lambda", "(", "lambda", "img", ":", "F", ".", "adjust_hue", "(", "img", ",", "hue_factor", ")", ")", ")", "\n", "\n", "", "random", ".", "shuffle", "(", "transforms", ")", "\n", "transform", "=", "Compose", "(", "transforms", ")", "\n", "\n", "return", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.ColorJitter.__call__": [[678, 691], ["transform.ColorJitter.ColorJitter.get_params", "transform.ColorJitter.ColorJitter.", "transform.ColorJitter.ColorJitter."], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.ColorJitter.get_params"], ["", "def", "__call__", "(", "self", ",", "img", ",", "lbl", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Input image.\n        Returns:\n            PIL Image: Color jittered image.\n        \"\"\"", "\n", "transform", "=", "self", ".", "get_params", "(", "self", ".", "brightness", ",", "self", ".", "contrast", ",", "\n", "self", ".", "saturation", ",", "self", ".", "hue", ")", "\n", "if", "lbl", "is", "not", "None", ":", "\n", "            ", "return", "transform", "(", "img", ")", ",", "lbl", "\n", "", "else", ":", "\n", "            ", "return", "transform", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.transform.ColorJitter.__repr__": [[692, 699], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'('", "\n", "format_string", "+=", "'brightness={0}'", ".", "format", "(", "self", ".", "brightness", ")", "\n", "format_string", "+=", "', contrast={0}'", ".", "format", "(", "self", ".", "contrast", ")", "\n", "format_string", "+=", "', saturation={0}'", ".", "format", "(", "self", ".", "saturation", ")", "\n", "format_string", "+=", "', hue={0})'", ".", "format", "(", "self", ".", "hue", ")", "\n", "return", "format_string", "", "", "", ""]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.utils.Subset.__init__": [[80, 85], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.utils.Subset.__getitem__": [[86, 96], ["utils.Subset.transform", "utils.Subset.target_transform"], "methods", ["None"], []], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.utils.Subset.__len__": [[97, 99], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.utils.ConcatDataset.cumsum": [[110, 118], ["len", "r.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.utils.ConcatDataset.__init__": [[119, 124], ["super().__init__", "list", "utils.ConcatDataset.cumsum", "len"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.__init__", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.utils.ConcatDataset.cumsum"], []], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.utils.ConcatDataset.__len__": [[125, 127], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.utils.ConcatDataset.__getitem__": [[128, 139], ["bisect.bisect_right", "len", "ValueError", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.utils.has_file_allowed_extension": [[8, 18], ["filename.lower", "any", "filename.lower.endswith"], "function", ["None"], ["    ", "mean", "=", "np", ".", "array", "(", "mean", ")", "\n", "std", "=", "np", ".", "array", "(", "std", ")", "\n", "\n", "_mean", "=", "-", "mean", "/", "std", "\n", "_std", "=", "1", "/", "std", "\n", "return", "normalize", "(", "tensor", ",", "_mean", ",", "_std", ")", "\n", "\n", "\n", "", "class", "Denormalize", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "mean", "=", "np", ".", "array", "(", "mean", ")", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.utils.get_batch": [[20, 28], ["next", "iter", "next"], "function", ["None"], ["self", ".", "_mean", "=", "-", "mean", "/", "std", "\n", "self", ".", "_std", "=", "1", "/", "std", "\n", "\n", "", "def", "__call__", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "if", "isinstance", "(", "tensor", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "return", "(", "tensor", "-", "self", ".", "_mean", ".", "reshape", "(", "-", "1", ",", "1", ",", "1", ")", ")", "/", "self", ".", "_std", ".", "reshape", "(", "-", "1", ",", "1", ",", "1", ")", "\n", "", "return", "normalize", "(", "tensor", ",", "self", ".", "_mean", ",", "self", ".", "_std", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.utils.group_images": [[30, 42], ["range", "len", "numpy.unique", "all", "numpy.array", "idxs[].append"], "function", ["None"], ["    ", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "            ", "m", ".", "eval", "(", ")", "\n", "m", ".", "weight", ".", "requires_grad", "=", "False", "\n", "m", ".", "bias", ".", "requires_grad", "=", "False", "\n", "\n", "\n", "", "", "", "def", "color_map", "(", "dataset", ")", ":", "\n", "    ", "if", "dataset", "==", "'streethazards'", ":", "\n", "        ", "return", "streethazards_cmap", "(", ")", "\n", "\n", "", "", "def", "streethazards_cmap", "(", ")", ":", "\n", "# Left: modified labels after -1. Right: original label", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.utils.filter_images": [[44, 68], ["print", "range", "labels.remove", "len", "numpy.unique", "fil", "any", "numpy.array", "idxs.append", "print", "any", "all", "len"], "function", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.print", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.print"], ["# total classes with anomaly: 14", "\n", "    ", "cmap", "=", "np", ".", "zeros", "(", "(", "256", ",", "3", ")", ")", "\n", "\n", "cmap", "[", "255", "]", "=", "[", "0", ",", "0", ",", "0", "]", "# // padding       =   -1 (n.d.) # padding, to ignore", "\n", "\n", "cmap", "[", "0", "]", "=", "[", "0", ",", "0", ",", "0", "]", "# // unlabeled     =   0 (1)     # sky and unlabeled (used in training)", "\n", "cmap", "[", "1", "]", "=", "[", "70", ",", "70", ",", "70", "]", "# // building      =   1 (2),", "\n", "cmap", "[", "2", "]", "=", "[", "190", ",", "153", ",", "153", "]", "# // fence         =   2 (3),", "\n", "cmap", "[", "3", "]", "=", "[", "250", ",", "170", ",", "160", "]", "# // other         =   3 (4),    # background", "\n", "cmap", "[", "4", "]", "=", "[", "220", ",", "20", ",", "60", "]", "# // pedestrian    =   4 (5),", "\n", "cmap", "[", "5", "]", "=", "[", "153", ",", "153", ",", "153", "]", "# // pole          =   5 (6),", "\n", "cmap", "[", "6", "]", "=", "[", "157", ",", "234", ",", "50", "]", "# // road line     =   6 (7),", "\n", "cmap", "[", "7", "]", "=", "[", "128", ",", "64", ",", "128", "]", "# // road          =   7 (8),", "\n", "cmap", "[", "8", "]", "=", "[", "244", ",", "35", ",", "232", "]", "# // sidewalk      =   8 (9),", "\n", "cmap", "[", "9", "]", "=", "[", "107", ",", "142", ",", "35", "]", "# // vegetation    =   9 (10),", "\n", "cmap", "[", "10", "]", "=", "[", "0", ",", "0", ",", "142", "]", "# // car           =  10 (11),", "\n", "cmap", "[", "11", "]", "=", "[", "102", ",", "102", ",", "156", "]", "# // wall          =  11 (12),", "\n", "cmap", "[", "12", "]", "=", "[", "220", ",", "220", ",", "0", "]", "# // traffic sign  =  12 (13),", "\n", "\n", "cmap", "[", "13", "]", "=", "[", "60", ",", "250", ",", "240", "]", "# // anomaly       =  13 (14)", "\n", "\n", "return", "cmap", "\n", "\n", "", "class", "Label2Color", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "cmap", ")", ":", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.utils.round2nearest_multiple": [[142, 147], ["l.append"], "function", ["None"], []], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.modules.residual.ResidualBlock.__init__": [[31, 83], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "ValueError", "ValueError", "len", "norm_act", "norm_act", "collections.OrderedDict", "torch.Conv2d", "torch.Conv2d", "norm_act", "len", "len", "len", "torch.Conv2d", "torch.Conv2d", "norm_act", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_act", "torch.Conv2d", "torch.Conv2d", "norm_act", "torch.Conv2d", "torch.Conv2d", "dropout", "dropout"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.__init__"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "channels", ",", "\n", "stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "norm_act", "=", "nn", ".", "BatchNorm2d", ",", "\n", "dropout", "=", "None", ")", ":", "\n", "        ", "super", "(", "ResidualBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Check parameters for inconsistencies", "\n", "if", "len", "(", "channels", ")", "!=", "2", "and", "len", "(", "channels", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"channels must contain either two or three values\"", ")", "\n", "", "if", "len", "(", "channels", ")", "==", "2", "and", "groups", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"groups > 1 are only valid if len(channels) == 3\"", ")", "\n", "\n", "", "is_bottleneck", "=", "len", "(", "channels", ")", "==", "3", "\n", "need_proj_conv", "=", "stride", "!=", "1", "or", "in_channels", "!=", "channels", "[", "-", "1", "]", "\n", "\n", "if", "not", "is_bottleneck", ":", "\n", "            ", "bn2", "=", "norm_act", "(", "channels", "[", "1", "]", ")", "\n", "bn2", ".", "activation", "=", "\"identity\"", "\n", "layers", "=", "[", "\n", "(", "\"conv1\"", ",", "nn", ".", "Conv2d", "(", "in_channels", ",", "channels", "[", "0", "]", ",", "3", ",", "stride", "=", "stride", ",", "padding", "=", "dilation", ",", "bias", "=", "False", ",", "\n", "dilation", "=", "dilation", ")", ")", ",", "\n", "(", "\"bn1\"", ",", "norm_act", "(", "channels", "[", "0", "]", ")", ")", ",", "\n", "(", "\"conv2\"", ",", "nn", ".", "Conv2d", "(", "channels", "[", "0", "]", ",", "channels", "[", "1", "]", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "dilation", ",", "bias", "=", "False", ",", "\n", "dilation", "=", "dilation", ")", ")", ",", "\n", "(", "\"bn2\"", ",", "bn2", ")", "\n", "]", "\n", "if", "dropout", "is", "not", "None", ":", "\n", "                ", "layers", "=", "layers", "[", "0", ":", "2", "]", "+", "[", "(", "\"dropout\"", ",", "dropout", "(", ")", ")", "]", "+", "layers", "[", "2", ":", "]", "\n", "", "", "else", ":", "\n", "            ", "bn3", "=", "norm_act", "(", "channels", "[", "2", "]", ")", "\n", "bn3", ".", "activation", "=", "\"identity\"", "\n", "layers", "=", "[", "\n", "(", "\"conv1\"", ",", "nn", ".", "Conv2d", "(", "in_channels", ",", "channels", "[", "0", "]", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ")", ",", "\n", "(", "\"bn1\"", ",", "norm_act", "(", "channels", "[", "0", "]", ")", ")", ",", "\n", "(", "\"conv2\"", ",", "nn", ".", "Conv2d", "(", "channels", "[", "0", "]", ",", "channels", "[", "1", "]", ",", "3", ",", "stride", "=", "stride", ",", "padding", "=", "dilation", ",", "bias", "=", "False", ",", "\n", "groups", "=", "groups", ",", "dilation", "=", "dilation", ")", ")", ",", "\n", "(", "\"bn2\"", ",", "norm_act", "(", "channels", "[", "1", "]", ")", ")", ",", "\n", "(", "\"conv3\"", ",", "nn", ".", "Conv2d", "(", "channels", "[", "1", "]", ",", "channels", "[", "2", "]", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ")", ",", "\n", "(", "\"bn3\"", ",", "bn3", ")", "\n", "]", "\n", "if", "dropout", "is", "not", "None", ":", "\n", "                ", "layers", "=", "layers", "[", "0", ":", "4", "]", "+", "[", "(", "\"dropout\"", ",", "dropout", "(", ")", ")", "]", "+", "layers", "[", "4", ":", "]", "\n", "", "", "self", ".", "convs", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "layers", ")", ")", "\n", "\n", "if", "need_proj_conv", ":", "\n", "            ", "self", ".", "proj_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "channels", "[", "-", "1", "]", ",", "1", ",", "stride", "=", "stride", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "proj_bn", "=", "norm_act", "(", "channels", "[", "-", "1", "]", ")", "\n", "self", ".", "proj_bn", ".", "activation", "=", "\"identity\"", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.modules.residual.ResidualBlock.forward": [[84, 98], ["hasattr", "residual.ResidualBlock.ResidualBlock.proj_conv", "residual.ResidualBlock.ResidualBlock.proj_bn", "residual.ResidualBlock.ResidualBlock.convs", "torch.leaky_relu", "torch.leaky_relu", "torch.elu", "torch.elu"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "\"proj_conv\"", ")", ":", "\n", "            ", "residual", "=", "self", ".", "proj_conv", "(", "x", ")", "\n", "residual", "=", "self", ".", "proj_bn", "(", "residual", ")", "\n", "", "else", ":", "\n", "            ", "residual", "=", "x", "\n", "", "x", "=", "self", ".", "convs", "(", "x", ")", "+", "residual", "\n", "\n", "if", "self", ".", "convs", ".", "bn1", ".", "activation", "==", "\"leaky_relu\"", ":", "\n", "            ", "return", "functional", ".", "leaky_relu", "(", "x", ",", "negative_slope", "=", "self", ".", "convs", ".", "bn1", ".", "activation_param", ",", "inplace", "=", "True", ")", "\n", "", "elif", "self", ".", "convs", ".", "bn1", ".", "activation", "==", "\"elu\"", ":", "\n", "            ", "return", "functional", ".", "elu", "(", "x", ",", "alpha", "=", "self", ".", "convs", ".", "bn1", ".", "activation_param", ",", "inplace", "=", "True", ")", "\n", "", "elif", "self", ".", "convs", ".", "bn1", ".", "activation", "==", "\"identity\"", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.modules.residual.IdentityResidualBlock.__init__": [[101, 168], ["torch.Module.__init__", "norm_act", "torch.Sequential", "torch.Sequential", "ValueError", "ValueError", "len", "collections.OrderedDict", "torch.Conv2d", "torch.Conv2d", "len", "len", "len", "torch.Conv2d", "torch.Conv2d", "norm_act", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_act", "torch.Conv2d", "torch.Conv2d", "norm_act", "torch.Conv2d", "torch.Conv2d", "dropout", "dropout"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "channels", ",", "\n", "stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "norm_act", "=", "nn", ".", "BatchNorm2d", ",", "\n", "dropout", "=", "None", ")", ":", "\n", "        ", "\"\"\"Configurable identity-mapping residual block\n\n        Parameters\n        ----------\n        in_channels : int\n            Number of input channels.\n        channels : list of int\n            Number of channels in the internal feature maps. Can either have two or three elements: if three construct\n            a residual block with two `3 x 3` convolutions, otherwise construct a bottleneck block with `1 x 1`, then\n            `3 x 3` then `1 x 1` convolutions.\n        stride : int\n            Stride of the first `3 x 3` convolution\n        dilation : int\n            Dilation to apply to the `3 x 3` convolutions.\n        groups : int\n            Number of convolution groups. This is used to create ResNeXt-style blocks and is only compatible with\n            bottleneck blocks.\n        norm_act : callable\n            Function to create normalization / activation Module.\n        dropout: callable\n            Function to create Dropout Module.\n        \"\"\"", "\n", "super", "(", "IdentityResidualBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Check parameters for inconsistencies", "\n", "if", "len", "(", "channels", ")", "!=", "2", "and", "len", "(", "channels", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"channels must contain either two or three values\"", ")", "\n", "", "if", "len", "(", "channels", ")", "==", "2", "and", "groups", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"groups > 1 are only valid if len(channels) == 3\"", ")", "\n", "\n", "", "is_bottleneck", "=", "len", "(", "channels", ")", "==", "3", "\n", "need_proj_conv", "=", "stride", "!=", "1", "or", "in_channels", "!=", "channels", "[", "-", "1", "]", "\n", "\n", "self", ".", "bn1", "=", "norm_act", "(", "in_channels", ")", "\n", "if", "not", "is_bottleneck", ":", "\n", "            ", "layers", "=", "[", "\n", "(", "\"conv1\"", ",", "nn", ".", "Conv2d", "(", "in_channels", ",", "channels", "[", "0", "]", ",", "3", ",", "stride", "=", "stride", ",", "padding", "=", "dilation", ",", "bias", "=", "False", ",", "\n", "dilation", "=", "dilation", ")", ")", ",", "\n", "(", "\"bn2\"", ",", "norm_act", "(", "channels", "[", "0", "]", ")", ")", ",", "\n", "(", "\"conv2\"", ",", "nn", ".", "Conv2d", "(", "channels", "[", "0", "]", ",", "channels", "[", "1", "]", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "dilation", ",", "bias", "=", "False", ",", "\n", "dilation", "=", "dilation", ")", ")", "\n", "]", "\n", "if", "dropout", "is", "not", "None", ":", "\n", "                ", "layers", "=", "layers", "[", "0", ":", "2", "]", "+", "[", "(", "\"dropout\"", ",", "dropout", "(", ")", ")", "]", "+", "layers", "[", "2", ":", "]", "\n", "", "", "else", ":", "\n", "            ", "layers", "=", "[", "\n", "(", "\"conv1\"", ",", "nn", ".", "Conv2d", "(", "in_channels", ",", "channels", "[", "0", "]", ",", "1", ",", "stride", "=", "stride", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ")", ",", "\n", "(", "\"bn2\"", ",", "norm_act", "(", "channels", "[", "0", "]", ")", ")", ",", "\n", "(", "\"conv2\"", ",", "nn", ".", "Conv2d", "(", "channels", "[", "0", "]", ",", "channels", "[", "1", "]", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "dilation", ",", "bias", "=", "False", ",", "\n", "groups", "=", "groups", ",", "dilation", "=", "dilation", ")", ")", ",", "\n", "(", "\"bn3\"", ",", "norm_act", "(", "channels", "[", "1", "]", ")", ")", ",", "\n", "(", "\"conv3\"", ",", "nn", ".", "Conv2d", "(", "channels", "[", "1", "]", ",", "channels", "[", "2", "]", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ")", "\n", "]", "\n", "if", "dropout", "is", "not", "None", ":", "\n", "                ", "layers", "=", "layers", "[", "0", ":", "4", "]", "+", "[", "(", "\"dropout\"", ",", "dropout", "(", ")", ")", "]", "+", "layers", "[", "4", ":", "]", "\n", "", "", "self", ".", "convs", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "layers", ")", ")", "\n", "\n", "if", "need_proj_conv", ":", "\n", "            ", "self", ".", "proj_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "channels", "[", "-", "1", "]", ",", "1", ",", "stride", "=", "stride", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.modules.residual.IdentityResidualBlock.forward": [[169, 181], ["hasattr", "residual.IdentityResidualBlock.convs", "residual.IdentityResidualBlock.add_", "residual.IdentityResidualBlock.bn1", "residual.IdentityResidualBlock.proj_conv", "x.clone", "residual.IdentityResidualBlock.bn1"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "\"proj_conv\"", ")", ":", "\n", "            ", "bn1", "=", "self", ".", "bn1", "(", "x", ")", "\n", "shortcut", "=", "self", ".", "proj_conv", "(", "bn1", ")", "\n", "", "else", ":", "\n", "            ", "shortcut", "=", "x", ".", "clone", "(", ")", "\n", "bn1", "=", "self", ".", "bn1", "(", "x", ")", "\n", "\n", "", "out", "=", "self", ".", "convs", "(", "bn1", ")", "\n", "out", ".", "add_", "(", "shortcut", ")", "\n", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.modules.ppm.PyramidPoolingModule.__init__": [[7, 37], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Dropout2d", "torch.Dropout2d", "ppm.PyramidPoolingModule.ppm.append", "torch.Conv2d", "torch.Conv2d", "norm_act", "torch.Dropout2d", "torch.Dropout2d", "torch.Conv2d", "torch.Conv2d", "norm_act", "torch.Sequential", "torch.Sequential", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Conv2d", "torch.Conv2d", "norm_act", "len"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "in_channels", "=", "2048", ",", "\n", "out_channels", "=", "512", ",", "\n", "norm_act", "=", "nn", ".", "BatchNorm2d", ",", "\n", "pool_scales", "=", "(", "1", ",", "2", ",", "3", ",", "6", ")", ")", ":", "\n", "\n", "        ", "super", "(", "PyramidPoolingModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "ppm", "=", "[", "]", "\n", "\n", "for", "scale", "in", "pool_scales", ":", "\n", "            ", "self", ".", "ppm", ".", "append", "(", "nn", ".", "Sequential", "(", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "scale", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "512", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "norm_act", "(", "512", ")", ",", "\n", ")", ")", "\n", "", "self", ".", "ppm", "=", "nn", ".", "ModuleList", "(", "self", ".", "ppm", ")", "\n", "self", ".", "conv_last", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", "+", "len", "(", "pool_scales", ")", "*", "512", ",", "512", ",", "\n", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "norm_act", "(", "self", ".", "out_channels", ")", ",", "\n", "nn", ".", "Dropout2d", "(", "0.1", ")", ",", "\n", "\n", ")", "\n", "self", ".", "cbr_deepsup", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", "//", "2", ",", "in_channels", "//", "4", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "norm_act", "(", "in_channels", "//", "4", ")", "\n", ")", "\n", "self", ".", "dropout_deepsup", "=", "nn", ".", "Dropout2d", "(", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.modules.ppm.PyramidPoolingModule.forward": [[38, 60], ["conv5.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ppm.PyramidPoolingModule.conv_last", "ppm.PyramidPoolingModule.cbr_deepsup", "ppm.PyramidPoolingModule.dropout_deepsup", "torch.cat.append", "torch.cat.append", "torch.functional.interpolate", "torch.functional.interpolate", "pool_scale"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "conv_out", ")", ":", "\n", "        ", "all_conv_out", ",", "_", "=", "conv_out", "\n", "conv5", "=", "all_conv_out", "[", "-", "1", "]", "\n", "\n", "input_size", "=", "conv5", ".", "size", "(", ")", "\n", "ppm_out", "=", "[", "conv5", "]", "\n", "for", "pool_scale", "in", "self", ".", "ppm", ":", "\n", "            ", "ppm_out", ".", "append", "(", "nn", ".", "functional", ".", "interpolate", "(", "\n", "pool_scale", "(", "conv5", ")", ",", "\n", "(", "input_size", "[", "2", "]", ",", "input_size", "[", "3", "]", ")", ",", "\n", "mode", "=", "'bilinear'", ",", "align_corners", "=", "False", ")", ")", "\n", "", "ppm_out", "=", "torch", ".", "cat", "(", "ppm_out", ",", "1", ")", "\n", "\n", "outputs", "=", "self", ".", "conv_last", "(", "ppm_out", ")", "\n", "\n", "# deep sup", "\n", "conv4", "=", "all_conv_out", "[", "-", "2", "]", "\n", "outputs_deepsup", "=", "self", ".", "cbr_deepsup", "(", "conv4", ")", "\n", "outputs_deepsup", "=", "self", ".", "dropout_deepsup", "(", "outputs_deepsup", ")", "\n", "\n", "return", "{", "'outputs'", ":", "outputs", ",", "\n", "'outputs_deepsup'", ":", "outputs_deepsup", "}", "", "", "", ""]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.modules.classifier.Classifier.__init__": [[14, 23], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channels", ",", "classes", ",", "deepsup", "=", "False", ")", ":", "\n", "        ", "super", "(", "Classifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "channels", "=", "channels", "\n", "self", ".", "classes", "=", "classes", "\n", "self", ".", "cls", "=", "nn", ".", "Conv2d", "(", "channels", ",", "classes", ",", "1", ")", "\n", "\n", "self", ".", "deepsup", "=", "deepsup", "\n", "if", "deepsup", ":", "\n", "            ", "self", ".", "cls_deepsup", "=", "nn", ".", "Conv2d", "(", "channels", ",", "classes", ",", "1", ",", "1", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.modules.classifier.Classifier.forward": [[24, 29], ["classifier.Classifier.cls", "classifier.Classifier.cls_deepsup"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "x_deepsup", ")", ":", "\n", "        ", "logits_deepsup", "=", "self", ".", "cls_deepsup", "(", "x_deepsup", ")", "if", "self", ".", "deepsup", "else", "None", "\n", "logits", "=", "self", ".", "cls", "(", "x", ")", "\n", "\n", "return", "logits", ",", "logits_deepsup", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.modules.classifier.CosineClassifier.__init__": [[32, 45], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channels", ",", "classes", ",", "deepsup", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "channels", "=", "channels", "\n", "self", ".", "scaler", "=", "10.", "\n", "self", ".", "classes", "=", "classes", "\n", "self", ".", "tot_classes", "=", "0", "\n", "\n", "self", ".", "cls", "=", "nn", ".", "Conv2d", "(", "channels", ",", "classes", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "deepsup", "=", "deepsup", "\n", "\n", "if", "deepsup", ":", "\n", "            ", "self", ".", "cls_deepsup", "=", "nn", ".", "Conv2d", "(", "channels", ",", "classes", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.modules.classifier.CosineClassifier.forward": [[46, 57], ["torch.normalize", "torch.normalize", "torch.conv2d", "torch.conv2d", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.conv2d", "torch.conv2d", "torch.normalize", "torch.normalize"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "x_deepsup", ")", ":", "\n", "        ", "out", "=", "F", ".", "normalize", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "logits", "=", "self", ".", "scaler", "*", "F", ".", "conv2d", "(", "out", ",", "F", ".", "normalize", "(", "self", ".", "cls", ".", "weight", ",", "dim", "=", "1", ",", "p", "=", "2", ")", ")", "\n", "\n", "if", "self", ".", "deepsup", ":", "\n", "            ", "out", "=", "F", ".", "normalize", "(", "x_deepsup", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "logits_deepsup", "=", "self", ".", "scaler", "*", "F", ".", "conv2d", "(", "out", ",", "F", ".", "normalize", "(", "self", ".", "cls_deepsup", ".", "weight", ",", "dim", "=", "1", ",", "p", "=", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "logits_deepsup", "=", "None", "\n", "\n", "", "return", "logits", ",", "logits_deepsup", "", "", "", ""]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.modules.classifier.get_classifier": [[5, 10], ["None"], "function", ["None"], ["def", "get_classifier", "(", "classifier_type", ")", ":", "\n", "    ", "if", "classifier_type", "==", "'standard'", ":", "\n", "        ", "return", "Classifier", "\n", "", "elif", "classifier_type", "==", "'cosine'", ":", "\n", "        ", "return", "CosineClassifier", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.models.resnet.GlobalAvgPool2d.__init__": [[12, 15], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Global average pooling over the input's spatial dimensions\"\"\"", "\n", "super", "(", "GlobalAvgPool2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.models.resnet.GlobalAvgPool2d.forward": [[16, 19], ["inputs.size", "inputs.view().mean", "inputs.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "in_size", "=", "inputs", ".", "size", "(", ")", "\n", "return", "inputs", ".", "view", "(", "(", "in_size", "[", "0", "]", ",", "in_size", "[", "1", "]", ",", "-", "1", ")", ")", ".", "mean", "(", "dim", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.models.resnet.ResNet.__init__": [[41, 107], ["torch.Module.__init__", "torch.Sequential", "enumerate", "len", "ValueError", "ValueError", "util.try_index", "layers.append", "collections.OrderedDict", "range", "resnet.ResNet.add_module", "torch.Sequential", "torch.Conv2d", "norm_act", "resnet.ResNet._stride_dilation", "blocks.append", "torch.Sequential", "collections.OrderedDict", "torch.MaxPool2d", "collections.OrderedDict", "modules.ResidualBlock", "resnet.GlobalAvgPool2d", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.__init__", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.models.util.try_index", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.models.resnet.ResNet._stride_dilation"], ["def", "__init__", "(", "self", ",", "\n", "structure", ",", "\n", "bottleneck", ",", "\n", "norm_act", "=", "nn", ".", "BatchNorm2d", ",", "\n", "classes", "=", "0", ",", "\n", "output_stride", "=", "16", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "structure", "=", "structure", "\n", "self", ".", "bottleneck", "=", "bottleneck", "\n", "\n", "if", "len", "(", "structure", ")", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "\"Expected a structure with four values\"", ")", "\n", "", "if", "output_stride", "!=", "8", "and", "output_stride", "!=", "16", ":", "\n", "            ", "raise", "ValueError", "(", "\"Output stride must be 8 or 16\"", ")", "\n", "\n", "", "if", "output_stride", "==", "16", ":", "\n", "            ", "dilation", "=", "[", "1", ",", "1", ",", "1", ",", "2", "]", "# dilated conv for last 3 blocks (9 layers)", "\n", "", "elif", "output_stride", "==", "8", ":", "\n", "            ", "dilation", "=", "[", "1", ",", "1", ",", "2", ",", "4", "]", "# 23+3 blocks (78 layers)", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "dilation", "=", "dilation", "\n", "\n", "# Initial layers", "\n", "layers", "=", "[", "\n", "# nn.Conv2d(#in_channel, #out_channel, #kernel_size, stride, padding)", "\n", "(", "\"conv1\"", ",", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "bias", "=", "False", ")", ")", ",", "\n", "(", "\"bn1\"", ",", "norm_act", "(", "64", ")", ")", "\n", "]", "\n", "if", "try_index", "(", "dilation", ",", "0", ")", "==", "1", ":", "\n", "            ", "layers", ".", "append", "(", "(", "\"pool1\"", ",", "nn", ".", "MaxPool2d", "(", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ")", ")", "\n", "", "self", ".", "mod1", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "layers", ")", ")", "\n", "\n", "# Groups of residual blocks", "\n", "in_channels", "=", "64", "\n", "if", "self", ".", "bottleneck", ":", "\n", "            ", "channels", "=", "(", "64", ",", "64", ",", "256", ")", "\n", "", "else", ":", "\n", "            ", "channels", "=", "(", "64", ",", "64", ")", "\n", "", "for", "mod_id", ",", "num", "in", "enumerate", "(", "structure", ")", ":", "\n", "# Create blocks for module", "\n", "            ", "blocks", "=", "[", "]", "\n", "for", "block_id", "in", "range", "(", "num", ")", ":", "\n", "                ", "stride", ",", "dil", "=", "self", ".", "_stride_dilation", "(", "dilation", ",", "mod_id", ",", "block_id", ")", "\n", "blocks", ".", "append", "(", "(", "\n", "\"block%d\"", "%", "(", "block_id", "+", "1", ")", ",", "\n", "ResidualBlock", "(", "in_channels", ",", "channels", ",", "norm_act", "=", "norm_act", ",", "stride", "=", "stride", ",", "dilation", "=", "dil", ")", "\n", ")", ")", "\n", "\n", "# Update channels and p_keep", "\n", "in_channels", "=", "channels", "[", "-", "1", "]", "\n", "\n", "# Create module", "\n", "", "self", ".", "add_module", "(", "\"mod%d\"", "%", "(", "mod_id", "+", "2", ")", ",", "nn", ".", "Sequential", "(", "OrderedDict", "(", "blocks", ")", ")", ")", "\n", "\n", "# Double the number of channels for the next module", "\n", "channels", "=", "[", "c", "*", "2", "for", "c", "in", "channels", "]", "\n", "\n", "", "self", ".", "out_channels", "=", "in_channels", "\n", "\n", "# Pooling and predictor", "\n", "if", "classes", "!=", "0", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "\"avg_pool\"", ",", "GlobalAvgPool2d", "(", ")", ")", ",", "\n", "(", "\"fc\"", ",", "nn", ".", "Linear", "(", "in_channels", ",", "classes", ")", ")", "\n", "]", ")", ")", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.models.resnet.ResNet._stride_dilation": [[109, 114], ["util.try_index"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.models.util.try_index"], ["", "", "@", "staticmethod", "\n", "def", "_stride_dilation", "(", "dilation", ",", "mod_id", ",", "block_id", ")", ":", "\n", "        ", "d", "=", "try_index", "(", "dilation", ",", "mod_id", ")", "\n", "s", "=", "2", "if", "d", "==", "1", "and", "block_id", "==", "0", "and", "mod_id", ">", "0", "else", "1", "\n", "return", "s", ",", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.models.resnet.ResNet.forward": [[115, 128], ["list", "list.append", "list.append", "list.append", "list.append", "list.append", "hasattr", "resnet.ResNet.mod1", "resnet.ResNet.mod2", "resnet.ResNet.mod3", "resnet.ResNet.mod4", "resnet.ResNet.mod5", "list.append", "resnet.ResNet.classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "outs", "=", "list", "(", ")", "\n", "\n", "outs", ".", "append", "(", "self", ".", "mod1", "(", "x", ")", ")", "\n", "outs", ".", "append", "(", "self", ".", "mod2", "(", "outs", "[", "-", "1", "]", ")", ")", "\n", "outs", ".", "append", "(", "self", ".", "mod3", "(", "outs", "[", "-", "1", "]", ")", ")", "\n", "outs", ".", "append", "(", "self", ".", "mod4", "(", "outs", "[", "-", "1", "]", ")", ")", "\n", "outs", ".", "append", "(", "self", ".", "mod5", "(", "outs", "[", "-", "1", "]", ")", ")", "\n", "\n", "if", "hasattr", "(", "self", ",", "\"classifier\"", ")", ":", "\n", "            ", "outs", ".", "append", "(", "self", ".", "classifier", "(", "outs", "[", "-", "1", "]", ")", ")", "\n", "\n", "", "return", "outs", ",", "outs", "[", "-", "1", "]", "# return all the output list and the last one", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.models.util.try_index": [[1, 6], ["None"], "function", ["None"], ["def", "try_index", "(", "scalar_or_list", ",", "i", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "return", "scalar_or_list", "[", "i", "]", "\n", "", "except", "TypeError", ":", "\n", "        ", "return", "scalar_or_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics._StreamMetrics.__init__": [[13, 16], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Overridden by subclasses \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics._StreamMetrics.update": [[17, 20], ["NotImplementedError"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "gt", ",", "pred", ")", ":", "\n", "        ", "\"\"\" Overridden by subclasses \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics._StreamMetrics.get_results": [[21, 24], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_results", "(", "self", ")", ":", "\n", "        ", "\"\"\" Overridden by subclasses \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics._StreamMetrics.to_str": [[25, 28], ["NotImplementedError"], "methods", ["None"], ["", "def", "to_str", "(", "self", ",", "metrics", ")", ":", "\n", "        ", "\"\"\" Overridden by subclasses \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics._StreamMetrics.reset": [[29, 32], ["NotImplementedError"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\" Overridden by subclasses \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics._StreamMetrics.synch": [[33, 36], ["NotImplementedError"], "methods", ["None"], ["", "def", "synch", "(", "self", ",", "device", ")", ":", "\n", "        ", "\"\"\" Overridden by subclasses \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.__init__": [[43, 53], ["stream_metrics._StreamMetrics.__init__", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.__init__"], ["def", "__init__", "(", "self", ",", "n_classes", ",", "unk_class", "=", "13", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "self", ".", "unk_class", "=", "unk_class", "\n", "self", ".", "confusion_matrix", "=", "np", ".", "zeros", "(", "(", "n_classes", ",", "n_classes", ")", ")", "\n", "self", ".", "total_samples", "=", "0", "\n", "self", ".", "auroc", "=", "0", "\n", "self", ".", "aupr", "=", "0", "\n", "self", ".", "fpr", "=", "0", "\n", "self", ".", "total_test_images", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.update": [[54, 72], ["zip", "len", "stream_metrics.StreamSegMetrics.compute_as_metrics", "print", "stream_metrics.StreamSegMetrics._fast_hist", "len", "len", "lt.flatten", "lp.flatten", "numpy.logical_not"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.compute_as_metrics", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.utils.logger.Logger.print", "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics._fast_hist"], ["", "def", "update", "(", "self", ",", "label_trues", ",", "label_preds", "=", "None", ",", "prob_preds", "=", "None", ")", ":", "\n", "        ", "if", "label_preds", "is", "not", "None", ":", "\n", "            ", "for", "lt", ",", "lp", "in", "zip", "(", "label_trues", ",", "label_preds", ")", ":", "\n", "                ", "self", ".", "confusion_matrix", "+=", "self", ".", "_fast_hist", "(", "lt", ".", "flatten", "(", ")", ",", "lp", ".", "flatten", "(", ")", ")", "\n", "", "self", ".", "total_samples", "+=", "len", "(", "label_trues", ")", "\n", "\n", "", "out_label", "=", "label_trues", ">=", "self", ".", "unk_class", "\n", "in_scores", "=", "1", "-", "prob_preds", "[", "np", ".", "logical_not", "(", "out_label", ")", "]", "\n", "out_scores", "=", "1", "-", "prob_preds", "[", "out_label", "]", "\n", "\n", "if", "(", "len", "(", "out_scores", ")", "!=", "0", ")", "and", "(", "len", "(", "in_scores", ")", "!=", "0", ")", ":", "\n", "            ", "auroc", ",", "aupr", ",", "fpr", "=", "self", ".", "compute_as_metrics", "(", "out_scores", ",", "in_scores", ")", "\n", "self", ".", "auroc", "+=", "auroc", "\n", "self", ".", "aupr", "+=", "aupr", "\n", "self", ".", "fpr", "+=", "fpr", "\n", "self", ".", "total_test_images", "+=", "1", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"This image does not contain any OOD pixels or is only OOD.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.compute_as_metrics": [[73, 85], ["numpy.array().reshape", "numpy.array().reshape", "numpy.squeeze", "numpy.zeros", "sklearn.roc_auc_score", "sklearn.average_precision_score", "stream_metrics.StreamSegMetrics.fpr_and_fdr_at_recall", "numpy.vstack", "len", "numpy.array", "numpy.array", "len"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.fpr_and_fdr_at_recall"], ["", "", "def", "compute_as_metrics", "(", "self", ",", "_pos", ",", "_neg", ",", "recall_level", "=", "recall_level_default", ")", ":", "\n", "        ", "pos", "=", "np", ".", "array", "(", "_pos", "[", ":", "]", ")", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "neg", "=", "np", ".", "array", "(", "_neg", "[", ":", "]", ")", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "examples", "=", "np", ".", "squeeze", "(", "np", ".", "vstack", "(", "(", "pos", ",", "neg", ")", ")", ")", "\n", "labels", "=", "np", ".", "zeros", "(", "len", "(", "examples", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "labels", "[", ":", "len", "(", "pos", ")", "]", "+=", "1", "\n", "\n", "auroc", "=", "sk", ".", "roc_auc_score", "(", "labels", ",", "examples", ")", "\n", "aupr", "=", "sk", ".", "average_precision_score", "(", "labels", ",", "examples", ")", "\n", "fpr", "=", "self", ".", "fpr_and_fdr_at_recall", "(", "labels", ",", "examples", ",", "recall_level", ")", "\n", "\n", "return", "auroc", ",", "aupr", ",", "fpr", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.fpr_and_fdr_at_recall": [[86, 137], ["numpy.unique", "tps.searchsorted", "slice", "numpy.argmin", "ValueError", "numpy.argsort", "numpy.where", "stream_metrics.StreamSegMetrics.stable_cumsum", "numpy.abs", "numpy.sum", "numpy.diff", "numpy.logical_not", "numpy.array_equal", "numpy.array_equal", "numpy.array_equal", "numpy.array_equal", "numpy.array_equal"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.stable_cumsum"], ["", "def", "fpr_and_fdr_at_recall", "(", "self", ",", "y_true", ",", "y_score", ",", "recall_level", "=", "recall_level_default", ",", "pos_label", "=", "None", ")", ":", "\n", "        ", "classes", "=", "np", ".", "unique", "(", "y_true", ")", "\n", "if", "(", "pos_label", "is", "None", "and", "\n", "not", "(", "np", ".", "array_equal", "(", "classes", ",", "[", "0", ",", "1", "]", ")", "or", "\n", "np", ".", "array_equal", "(", "classes", ",", "[", "-", "1", ",", "1", "]", ")", "or", "\n", "np", ".", "array_equal", "(", "classes", ",", "[", "0", "]", ")", "or", "\n", "np", ".", "array_equal", "(", "classes", ",", "[", "-", "1", "]", ")", "or", "\n", "np", ".", "array_equal", "(", "classes", ",", "[", "1", "]", ")", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Data is not binary and pos_label is not specified\"", ")", "\n", "", "elif", "pos_label", "is", "None", ":", "\n", "            ", "pos_label", "=", "1.", "\n", "\n", "# True per ogni pixel appartenente a unknown, false per ogni pixel appartenente a known (una sorta", "\n", "# di nuovo vettore label per gli sore (mantiene il match alle posizioni)", "\n", "", "y_true", "=", "(", "y_true", "==", "pos_label", ")", "\n", "\n", "# sort scores and corresponding truth values", "\n", "# ritorna gli indici per sortare y_score in modo decrescente (dato da [::-1]", "\n", "desc_score_indices", "=", "np", ".", "argsort", "(", "y_score", ",", "kind", "=", "\"mergesort\"", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "# sorto effettivamente il vettore di probabilities (e di label True False)", "\n", "y_score", "=", "y_score", "[", "desc_score_indices", "]", "\n", "y_true", "=", "y_true", "[", "desc_score_indices", "]", "\n", "\n", "# y_score typically has many tied values. Here we extract the indices associated with the distinct values.", "\n", "# We also concatenate a value for the end of the curve.", "\n", "\n", "# con np.diff() facciamo emergere i valori di probabilit\u00e0 molto diversi dagli altri (generalmente simili)", "\n", "# con np.where() selezioniamo gli indici solo nei valori diversi a True (tutti i diversi da 0)", "\n", "distinct_value_indices", "=", "np", ".", "where", "(", "np", ".", "diff", "(", "y_score", ")", ")", "[", "0", "]", "\n", "# np.r_ attacca alla fine del vettore distinct_value_indices il valore di y_true.size - 1", "\n", "threshold_idxs", "=", "np", ".", "r_", "[", "distinct_value_indices", ",", "y_true", ".", "size", "-", "1", "]", "\n", "\n", "# accumulate the true positives with decreasing threshold", "\n", "# per ogni step conta quanti true positivi ci sono. Sar\u00e0 nella forma: 0,0,0,0,1,2,3,4", "\n", "# a questo accede mediante gli indici dei valori diversi tra loro", "\n", "tps", "=", "self", ".", "stable_cumsum", "(", "y_true", ")", "[", "threshold_idxs", "]", "\n", "# add one because of zero-based indexing", "\n", "fps", "=", "1", "+", "threshold_idxs", "-", "tps", "\n", "\n", "thresholds", "=", "y_score", "[", "threshold_idxs", "]", "\n", "\n", "recall", "=", "tps", "/", "tps", "[", "-", "1", "]", "\n", "\n", "last_ind", "=", "tps", ".", "searchsorted", "(", "tps", "[", "-", "1", "]", ")", "\n", "sl", "=", "slice", "(", "last_ind", ",", "None", ",", "-", "1", ")", "# [last_ind::-1]", "\n", "recall", ",", "fps", ",", "tps", ",", "thresholds", "=", "np", ".", "r_", "[", "recall", "[", "sl", "]", ",", "1", "]", ",", "np", ".", "r_", "[", "fps", "[", "sl", "]", ",", "0", "]", ",", "np", ".", "r_", "[", "tps", "[", "sl", "]", ",", "0", "]", ",", "thresholds", "[", "sl", "]", "\n", "\n", "cutoff", "=", "np", ".", "argmin", "(", "np", ".", "abs", "(", "recall", "-", "recall_level", ")", ")", "\n", "\n", "return", "fps", "[", "cutoff", "]", "/", "(", "np", ".", "sum", "(", "np", ".", "logical_not", "(", "y_true", ")", ")", ")", "# , fps[cutoff]/(fps[cutoff] + tps[cutoff])", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.stable_cumsum": [[138, 155], ["numpy.cumsum", "numpy.sum", "numpy.allclose", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.dataset.utils.ConcatDataset.cumsum"], ["", "def", "stable_cumsum", "(", "self", ",", "arr", ",", "rtol", "=", "1e-05", ",", "atol", "=", "1e-08", ")", ":", "\n", "        ", "\"\"\"Use high precision for cumsum and check that final value matches sum\n        Parameters\n        ----------\n        arr : array-like\n            To be cumulatively summed as flat\n        rtol : float\n            Relative tolerance, see ``np.allclose``\n        atol : float\n            Absolute tolerance, see ``np.allclose``\n        \"\"\"", "\n", "out", "=", "np", ".", "cumsum", "(", "arr", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "expected", "=", "np", ".", "sum", "(", "arr", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "if", "not", "np", ".", "allclose", "(", "out", "[", "-", "1", "]", ",", "expected", ",", "rtol", "=", "rtol", ",", "atol", "=", "atol", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'cumsum was found to be unstable: '", "\n", "'its last element does not correspond to sum'", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.to_str": [[156, 171], ["results.items", "results[].items", "results[].items", "str", "str"], "methods", ["None"], ["", "def", "to_str", "(", "self", ",", "results", ")", ":", "\n", "        ", "string", "=", "\"\\n\"", "\n", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "!=", "\"Class IoU\"", "and", "k", "!=", "\"Class Acc\"", "and", "k", "!=", "\"Confusion Matrix\"", ":", "\n", "                ", "string", "+=", "\"%s: %f\\n\"", "%", "(", "k", ",", "v", ")", "\n", "\n", "", "", "string", "+=", "'Class IoU:\\n'", "\n", "for", "k", ",", "v", "in", "results", "[", "'Class IoU'", "]", ".", "items", "(", ")", ":", "\n", "            ", "string", "+=", "\"\\tclass %d: %s\\n\"", "%", "(", "k", ",", "str", "(", "v", ")", ")", "\n", "\n", "", "string", "+=", "'Class Acc:\\n'", "\n", "for", "k", ",", "v", "in", "results", "[", "'Class Acc'", "]", ".", "items", "(", ")", ":", "\n", "            ", "string", "+=", "\"\\tclass %d: %s\\n\"", "%", "(", "k", ",", "str", "(", "v", ")", ")", "\n", "\n", "", "return", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics._fast_hist": [[172, 179], ["numpy.bincount().reshape", "numpy.bincount", "label_true[].astype"], "methods", ["None"], ["", "def", "_fast_hist", "(", "self", ",", "label_true", ",", "label_pred", ")", ":", "\n", "        ", "mask", "=", "(", "label_true", ">=", "0", ")", "&", "(", "label_true", "<", "self", ".", "n_classes", ")", "\n", "hist", "=", "np", ".", "bincount", "(", "\n", "self", ".", "n_classes", "*", "label_true", "[", "mask", "]", ".", "astype", "(", "int", ")", "+", "label_pred", "[", "mask", "]", ",", "\n", "minlength", "=", "self", ".", "n_classes", "**", "2", ",", "\n", ")", ".", "reshape", "(", "self", ".", "n_classes", ",", "self", ".", "n_classes", ")", "\n", "return", "hist", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.get_results": [[180, 228], ["hist.sum", "numpy.diag", "numpy.mean", "numpy.mean", "dict", "dict", "numpy.diag.sum", "hist.sum", "hist.sum", "hist.sum", "zip", "zip", "stream_metrics.StreamSegMetrics.confusion_matrix_to_fig", "range", "range", "hist.sum", "enumerate", "enumerate"], "methods", ["home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.confusion_matrix_to_fig"], ["", "def", "get_results", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns accuracy score evaluation result.\n            - overall accuracy\n            - mean accuracy\n            - mean IU\n            - fwavacc\n            - auroc\n            - aupr\n            - fpr95\n        \"\"\"", "\n", "auroc", "=", "0", "\n", "aupr", "=", "0", "\n", "fpr", "=", "0", "\n", "\n", "EPS", "=", "1e-6", "\n", "hist", "=", "self", ".", "confusion_matrix", "\n", "\n", "gt_sum", "=", "hist", ".", "sum", "(", "axis", "=", "1", ")", "\n", "mask", "=", "(", "gt_sum", "!=", "0", ")", "\n", "diag", "=", "np", ".", "diag", "(", "hist", ")", "\n", "\n", "acc", "=", "diag", ".", "sum", "(", ")", "/", "hist", ".", "sum", "(", ")", "\n", "acc_cls_c", "=", "diag", "/", "(", "gt_sum", "+", "EPS", ")", "\n", "acc_cls", "=", "np", ".", "mean", "(", "acc_cls_c", "[", "mask", "]", ")", "\n", "iu", "=", "diag", "/", "(", "gt_sum", "+", "hist", ".", "sum", "(", "axis", "=", "0", ")", "-", "diag", "+", "EPS", ")", "\n", "mean_iu", "=", "np", ".", "mean", "(", "iu", "[", "mask", "]", ")", "\n", "freq", "=", "hist", ".", "sum", "(", "axis", "=", "1", ")", "/", "hist", ".", "sum", "(", ")", "\n", "fwavacc", "=", "(", "freq", "[", "freq", ">", "0", "]", "*", "iu", "[", "freq", ">", "0", "]", ")", ".", "sum", "(", ")", "\n", "cls_iu", "=", "dict", "(", "zip", "(", "range", "(", "self", ".", "n_classes", ")", ",", "[", "iu", "[", "i", "]", "if", "m", "else", "\"X\"", "for", "i", ",", "m", "in", "enumerate", "(", "mask", ")", "]", ")", ")", "\n", "cls_acc", "=", "dict", "(", "zip", "(", "range", "(", "self", ".", "n_classes", ")", ",", "[", "acc_cls_c", "[", "i", "]", "if", "m", "else", "\"X\"", "for", "i", ",", "m", "in", "enumerate", "(", "mask", ")", "]", ")", ")", "\n", "\n", "if", "self", ".", "total_test_images", ":", "\n", "            ", "auroc", "=", "self", ".", "auroc", "/", "self", ".", "total_test_images", "*", "100.", "\n", "aupr", "=", "self", ".", "aupr", "/", "self", ".", "total_test_images", "*", "100.", "\n", "fpr", "=", "self", ".", "fpr", "/", "self", ".", "total_test_images", "*", "100.", "\n", "\n", "", "return", "{", "\n", "\"Total samples\"", ":", "self", ".", "total_samples", ",", "\n", "\"Overall Acc\"", ":", "acc", ",", "\n", "\"Mean Acc\"", ":", "acc_cls", ",", "\n", "\"FreqW Acc\"", ":", "fwavacc", ",", "\n", "\"Mean IoU\"", ":", "mean_iu", ",", "\n", "\"Class IoU\"", ":", "cls_iu", ",", "\n", "\"Class Acc\"", ":", "cls_acc", ",", "\n", "\"Confusion Matrix\"", ":", "self", ".", "confusion_matrix_to_fig", "(", ")", ",", "\n", "\"AUROC\"", ":", "auroc", ",", "\n", "\"AUPR\"", ":", "aupr", ",", "\n", "\"FPR95\"", ":", "fpr", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.reset": [[230, 237], ["numpy.zeros"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "confusion_matrix", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_classes", ",", "self", ".", "n_classes", ")", ")", "\n", "self", ".", "total_samples", "=", "0", "\n", "self", ".", "auroc", "=", "0", "\n", "self", ".", "aupr", "=", "0", "\n", "self", ".", "fpr", "=", "0", "\n", "self", ".", "total_test_images", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.synch": [[238, 263], ["torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.reduce", "torch.distributed.barrier", "torch.distributed.get_rank", "torch.tensor().to.cpu().numpy", "torch.tensor().to.cpu().numpy", "torch.tensor().to.cpu().numpy", "torch.tensor().to.cpu().numpy", "torch.tensor().to.cpu().numpy", "torch.tensor().to.cpu().numpy", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor().to.cpu", "torch.tensor().to.cpu", "torch.tensor().to.cpu", "torch.tensor().to.cpu", "torch.tensor().to.cpu", "torch.tensor().to.cpu"], "methods", ["None"], ["", "def", "synch", "(", "self", ",", "device", ")", ":", "\n", "# collect from multi-processes", "\n", "        ", "confusion_matrix", "=", "torch", ".", "tensor", "(", "self", ".", "confusion_matrix", ")", ".", "to", "(", "device", ")", "\n", "samples", "=", "torch", ".", "tensor", "(", "self", ".", "total_samples", ")", ".", "to", "(", "device", ")", "\n", "auroc", "=", "torch", ".", "tensor", "(", "self", ".", "auroc", ")", ".", "to", "(", "device", ")", "\n", "aupr", "=", "torch", ".", "tensor", "(", "self", ".", "aupr", ")", ".", "to", "(", "device", ")", "\n", "fpr", "=", "torch", ".", "tensor", "(", "self", ".", "fpr", ")", ".", "to", "(", "device", ")", "\n", "test_images", "=", "torch", ".", "tensor", "(", "self", ".", "total_test_images", ")", ".", "to", "(", "device", ")", "\n", "\n", "torch", ".", "distributed", ".", "reduce", "(", "confusion_matrix", ",", "dst", "=", "0", ")", "\n", "torch", ".", "distributed", ".", "reduce", "(", "samples", ",", "dst", "=", "0", ")", "\n", "torch", ".", "distributed", ".", "reduce", "(", "auroc", ",", "dst", "=", "0", ")", "\n", "torch", ".", "distributed", ".", "reduce", "(", "aupr", ",", "dst", "=", "0", ")", "\n", "torch", ".", "distributed", ".", "reduce", "(", "fpr", ",", "dst", "=", "0", ")", "\n", "torch", ".", "distributed", ".", "reduce", "(", "test_images", ",", "dst", "=", "0", ")", "\n", "\n", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "self", ".", "confusion_matrix", "=", "confusion_matrix", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "total_samples", "=", "samples", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "auroc", "=", "auroc", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "aupr", "=", "aupr", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "fpr", "=", "fpr", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "total_test_images", "=", "test_images", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.StreamSegMetrics.confusion_matrix_to_fig": [[264, 276], ["matplotlib.subplots", "matplotlib.subplots", "ax.imshow", "ax.figure.colorbar", "ax.set", "fig.tight_layout", "stream_metrics.StreamSegMetrics.confusion_matrix.astype", "stream_metrics.StreamSegMetrics.confusion_matrix.sum"], "methods", ["None"], ["", "", "def", "confusion_matrix_to_fig", "(", "self", ")", ":", "\n", "        ", "cm", "=", "self", ".", "confusion_matrix", ".", "astype", "(", "'float'", ")", "/", "(", "self", ".", "confusion_matrix", ".", "sum", "(", "axis", "=", "1", ")", "+", "0.000001", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "im", "=", "ax", ".", "imshow", "(", "cm", ",", "interpolation", "=", "'nearest'", ",", "cmap", "=", "plt", ".", "cm", ".", "Blues", ")", "\n", "ax", ".", "figure", ".", "colorbar", "(", "im", ",", "ax", "=", "ax", ")", "\n", "\n", "ax", ".", "set", "(", "title", "=", "f'Confusion Matrix'", ",", "\n", "ylabel", "=", "'True label'", ",", "\n", "xlabel", "=", "'Predicted label'", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.__init__": [[280, 282], ["dict"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "book", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.reset_all": [[283, 285], ["stream_metrics.AverageMeter.book.clear"], "methods", ["None"], ["", "def", "reset_all", "(", "self", ")", ":", "\n", "        ", "self", ".", "book", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.reset": [[286, 291], ["stream_metrics.AverageMeter.book.get"], "methods", ["None"], ["", "def", "reset", "(", "self", ",", "id", ")", ":", "\n", "        ", "item", "=", "self", ".", "book", ".", "get", "(", "id", ",", "None", ")", "\n", "if", "item", "is", "not", "None", ":", "\n", "            ", "item", "[", "0", "]", "=", "0", "\n", "item", "[", "1", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.update": [[292, 299], ["stream_metrics.AverageMeter.book.get"], "methods", ["None"], ["", "", "def", "update", "(", "self", ",", "id", ",", "val", ")", ":", "\n", "        ", "record", "=", "self", ".", "book", ".", "get", "(", "id", ",", "None", ")", "\n", "if", "record", "is", "None", ":", "\n", "            ", "self", ".", "book", "[", "id", "]", "=", "[", "val", ",", "1", "]", "\n", "", "else", ":", "\n", "            ", "record", "[", "0", "]", "+=", "val", "\n", "record", "[", "1", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.DarioFontanel_PAnS.metrics.stream_metrics.AverageMeter.get_results": [[300, 304], ["stream_metrics.AverageMeter.book.get"], "methods", ["None"], ["", "", "def", "get_results", "(", "self", ",", "id", ")", ":", "\n", "        ", "record", "=", "self", ".", "book", ".", "get", "(", "id", ",", "None", ")", "\n", "assert", "record", "is", "not", "None", "\n", "return", "record", "[", "0", "]", "/", "record", "[", "1", "]", "\n", "", "", ""]]}