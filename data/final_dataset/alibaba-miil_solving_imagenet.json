{"home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.validate.validate": [[116, 284], ["models.create_model", "torch.nn.DataParallel.cpu().eval", "InplacABN_to_ABN", "fuse_bn2d_bn1d_abn", "sum", "_logger.info", "timm.data.resolve_data_config", "torch.nn.DataParallel.cuda", "torch.CrossEntropyLoss().cuda", "timm.data.create_dataset", "timm.data.create_loader", "timm.utils.AverageMeter", "timm.utils.AverageMeter", "timm.utils.AverageMeter", "timm.utils.AverageMeter", "torch.nn.DataParallel.eval", "collections.OrderedDict", "_logger.info", "_logger.info", "hasattr", "models.load_checkpoint", "vars", "models.apply_test_time_pool", "torch.jit.optimized_execution", "torch.jit.optimized_execution", "torch.jit.optimized_execution", "torch.jit.script", "torch.jit.script", "torch.jit.script", "amp.initialize", "torch.nn.DataParallel.to", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "timm.data.RealLabelsImagenet", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "time.time", "enumerate", "_logger.info", "_logger.info", "torch.nn.DataParallel.cpu", "m.numel", "torch.CrossEntropyLoss", "open", "timm.data.create_dataset.filenames", "input.contiguous.contiguous", "amp_autocast", "torch.nn.DataParallel.", "nn.CrossEntropyLoss().cuda.", "timm.utils.accuracy", "timm.utils.AverageMeter.update", "timm.utils.AverageMeter.update", "timm.utils.AverageMeter.update", "timm.utils.AverageMeter.update", "time.time", "timm.data.RealLabelsImagenet.get_accuracy", "timm.data.RealLabelsImagenet.get_accuracy", "round", "round", "round", "round", "round", "_logger.warning", "torch.nn.DataParallel.parameters", "list", "int", "torch.randn", "torch.randn", "torch.randn", "target.cuda.cuda", "input.contiguous.cuda", "input.contiguous.contiguous", "amp_autocast", "torch.nn.DataParallel.", "timm.data.RealLabelsImagenet.add_result", "model.detach", "criterion.item", "input.contiguous.size", "acc1.item", "input.contiguous.size", "acc5.item", "input.contiguous.size", "_logger.info", "range", "line.rstrip", "range", "time.time", "tuple", "len", "input.contiguous.size"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.factory.create_model", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.InplacABN_to_ABN", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.fuse_bn2d_bn1d_abn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.load_checkpoint", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.test_time_pool.apply_test_time_pool"], ["def", "validate", "(", "args", ")", ":", "\n", "# might as well try to validate something", "\n", "    ", "args", ".", "pretrained", "=", "args", ".", "pretrained", "or", "not", "args", ".", "checkpoint", "\n", "args", ".", "prefetcher", "=", "not", "args", ".", "no_prefetcher", "\n", "amp_autocast", "=", "suppress", "# do nothing", "\n", "if", "args", ".", "amp", ":", "\n", "        ", "if", "has_native_amp", ":", "\n", "            ", "args", ".", "native_amp", "=", "True", "\n", "", "elif", "has_apex", ":", "\n", "            ", "args", ".", "apex_amp", "=", "True", "\n", "", "else", ":", "\n", "            ", "_logger", ".", "warning", "(", "\"Neither APEX or Native Torch AMP is available.\"", ")", "\n", "", "", "assert", "not", "args", ".", "apex_amp", "or", "not", "args", ".", "native_amp", ",", "\"Only one AMP mode should be set.\"", "\n", "if", "args", ".", "native_amp", ":", "\n", "        ", "amp_autocast", "=", "torch", ".", "cuda", ".", "amp", ".", "autocast", "\n", "_logger", ".", "info", "(", "'Validating in mixed precision with native PyTorch AMP.'", ")", "\n", "", "elif", "args", ".", "apex_amp", ":", "\n", "        ", "_logger", ".", "info", "(", "'Validating in mixed precision with NVIDIA APEX AMP.'", ")", "\n", "", "else", ":", "\n", "        ", "_logger", ".", "info", "(", "'Validating in float32. AMP not enabled.'", ")", "\n", "\n", "# create model", "\n", "", "model", "=", "create_model", "(", "\n", "args", ".", "model", ",", "\n", "pretrained", "=", "args", ".", "pretrained", ",", "\n", "num_classes", "=", "args", ".", "num_classes", ",", "\n", "in_chans", "=", "3", ",", "\n", "global_pool", "=", "args", ".", "gp", ",", "\n", "scriptable", "=", "args", ".", "torchscript", ")", "\n", "model", ".", "cpu", "(", ")", ".", "eval", "(", ")", "\n", "from", "kd", ".", "helpers", "import", "InplacABN_to_ABN", ",", "fuse_bn2d_bn1d_abn", "\n", "model", "=", "InplacABN_to_ABN", "(", "model", ")", "\n", "model", "=", "fuse_bn2d_bn1d_abn", "(", "model", ")", "\n", "\n", "\n", "if", "args", ".", "num_classes", "is", "None", ":", "\n", "        ", "assert", "hasattr", "(", "model", ",", "'num_classes'", ")", ",", "'Model must have `num_classes` attr if not set on cmd line/config.'", "\n", "args", ".", "num_classes", "=", "model", ".", "num_classes", "\n", "\n", "", "if", "args", ".", "checkpoint", ":", "\n", "        ", "load_checkpoint", "(", "model", ",", "args", ".", "checkpoint", ",", "args", ".", "use_ema", ")", "\n", "\n", "", "param_count", "=", "sum", "(", "[", "m", ".", "numel", "(", ")", "for", "m", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "_logger", ".", "info", "(", "'Model %s created, param count: %d'", "%", "(", "args", ".", "model", ",", "param_count", ")", ")", "\n", "\n", "data_config", "=", "resolve_data_config", "(", "vars", "(", "args", ")", ",", "model", "=", "model", ",", "use_test_size", "=", "True", ",", "verbose", "=", "True", ")", "\n", "test_time_pool", "=", "False", "\n", "if", "args", ".", "test_pool", ":", "\n", "        ", "model", ",", "test_time_pool", "=", "apply_test_time_pool", "(", "model", ",", "data_config", ",", "use_test_size", "=", "True", ")", "\n", "\n", "", "if", "args", ".", "torchscript", ":", "\n", "        ", "torch", ".", "jit", ".", "optimized_execution", "(", "True", ")", "\n", "model", "=", "torch", ".", "jit", ".", "script", "(", "model", ")", "\n", "\n", "", "model", "=", "model", ".", "cuda", "(", ")", "\n", "if", "args", ".", "apex_amp", ":", "\n", "        ", "model", "=", "amp", ".", "initialize", "(", "model", ",", "opt_level", "=", "'O1'", ")", "\n", "\n", "", "if", "args", ".", "channels_last", ":", "\n", "        ", "model", "=", "model", ".", "to", "(", "memory_format", "=", "torch", ".", "channels_last", ")", "\n", "\n", "", "if", "args", ".", "num_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "list", "(", "range", "(", "args", ".", "num_gpu", ")", ")", ")", "\n", "\n", "", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "dataset", "=", "create_dataset", "(", "\n", "root", "=", "args", ".", "data", ",", "name", "=", "args", ".", "dataset", ",", "split", "=", "args", ".", "split", ",", "\n", "download", "=", "args", ".", "dataset_download", ",", "load_bytes", "=", "args", ".", "tf_preprocessing", ",", "class_map", "=", "args", ".", "class_map", ")", "\n", "\n", "if", "args", ".", "valid_labels", ":", "\n", "        ", "with", "open", "(", "args", ".", "valid_labels", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "valid_labels", "=", "{", "int", "(", "line", ".", "rstrip", "(", ")", ")", "for", "line", "in", "f", "}", "\n", "valid_labels", "=", "[", "i", "in", "valid_labels", "for", "i", "in", "range", "(", "args", ".", "num_classes", ")", "]", "\n", "", "", "else", ":", "\n", "        ", "valid_labels", "=", "None", "\n", "\n", "", "if", "args", ".", "real_labels", ":", "\n", "        ", "real_labels", "=", "RealLabelsImagenet", "(", "dataset", ".", "filenames", "(", "basename", "=", "True", ")", ",", "real_json", "=", "args", ".", "real_labels", ")", "\n", "", "else", ":", "\n", "        ", "real_labels", "=", "None", "\n", "\n", "", "crop_pct", "=", "1.0", "if", "test_time_pool", "else", "data_config", "[", "'crop_pct'", "]", "\n", "loader", "=", "create_loader", "(", "\n", "dataset", ",", "\n", "input_size", "=", "data_config", "[", "'input_size'", "]", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "use_prefetcher", "=", "args", ".", "prefetcher", ",", "\n", "interpolation", "=", "data_config", "[", "'interpolation'", "]", ",", "\n", "mean", "=", "data_config", "[", "'mean'", "]", ",", "\n", "std", "=", "data_config", "[", "'std'", "]", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "crop_pct", "=", "crop_pct", ",", "\n", "pin_memory", "=", "args", ".", "pin_mem", ",", "\n", "tf_preprocessing", "=", "args", ".", "tf_preprocessing", ")", "\n", "\n", "batch_time", "=", "AverageMeter", "(", ")", "\n", "losses", "=", "AverageMeter", "(", ")", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# warmup, reduce variability of first batch time, especially for comparing torchscript vs non", "\n", "        ", "input", "=", "torch", ".", "randn", "(", "(", "args", ".", "batch_size", ",", ")", "+", "tuple", "(", "data_config", "[", "'input_size'", "]", ")", ")", ".", "cuda", "(", ")", "\n", "if", "args", ".", "channels_last", ":", "\n", "            ", "input", "=", "input", ".", "contiguous", "(", "memory_format", "=", "torch", ".", "channels_last", ")", "\n", "", "with", "amp_autocast", "(", ")", ":", "\n", "            ", "model", "(", "input", ")", "\n", "\n", "", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "batch_idx", ",", "(", "input", ",", "target", ")", "in", "enumerate", "(", "loader", ")", ":", "\n", "            ", "if", "args", ".", "no_prefetcher", ":", "\n", "                ", "target", "=", "target", ".", "cuda", "(", ")", "\n", "input", "=", "input", ".", "cuda", "(", ")", "\n", "", "if", "args", ".", "channels_last", ":", "\n", "                ", "input", "=", "input", ".", "contiguous", "(", "memory_format", "=", "torch", ".", "channels_last", ")", "\n", "\n", "# compute output", "\n", "", "with", "amp_autocast", "(", ")", ":", "\n", "                ", "output", "=", "model", "(", "input", ")", "\n", "\n", "", "if", "valid_labels", "is", "not", "None", ":", "\n", "                ", "output", "=", "output", "[", ":", ",", "valid_labels", "]", "\n", "", "loss", "=", "criterion", "(", "output", ",", "target", ")", "\n", "\n", "if", "real_labels", "is", "not", "None", ":", "\n", "                ", "real_labels", ".", "add_result", "(", "output", ")", "\n", "\n", "# measure accuracy and record loss", "\n", "", "acc1", ",", "acc5", "=", "accuracy", "(", "output", ".", "detach", "(", ")", ",", "target", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "top1", ".", "update", "(", "acc1", ".", "item", "(", ")", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "acc5", ".", "item", "(", ")", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "batch_idx", "%", "args", ".", "log_freq", "==", "0", ":", "\n", "                ", "_logger", ".", "info", "(", "\n", "'Test: [{0:>4d}/{1}]  '", "\n", "'Time: {batch_time.val:.3f}s ({batch_time.avg:.3f}s, {rate_avg:>7.2f}/s)  '", "\n", "'Loss: {loss.val:>7.4f} ({loss.avg:>6.4f})  '", "\n", "'Acc@1: {top1.val:>7.3f} ({top1.avg:>7.3f})  '", "\n", "'Acc@5: {top5.val:>7.3f} ({top5.avg:>7.3f})'", ".", "format", "(", "\n", "batch_idx", ",", "len", "(", "loader", ")", ",", "batch_time", "=", "batch_time", ",", "\n", "rate_avg", "=", "input", ".", "size", "(", "0", ")", "/", "batch_time", ".", "avg", ",", "\n", "loss", "=", "losses", ",", "top1", "=", "top1", ",", "top5", "=", "top5", ")", ")", "\n", "\n", "", "", "", "if", "real_labels", "is", "not", "None", ":", "\n", "# real labels mode replaces topk values at the end", "\n", "        ", "top1a", ",", "top5a", "=", "real_labels", ".", "get_accuracy", "(", "k", "=", "1", ")", ",", "real_labels", ".", "get_accuracy", "(", "k", "=", "5", ")", "\n", "", "else", ":", "\n", "        ", "top1a", ",", "top5a", "=", "top1", ".", "avg", ",", "top5", ".", "avg", "\n", "", "results", "=", "OrderedDict", "(", "\n", "model", "=", "args", ".", "model", ",", "\n", "top1", "=", "round", "(", "top1a", ",", "4", ")", ",", "top1_err", "=", "round", "(", "100", "-", "top1a", ",", "4", ")", ",", "\n", "top5", "=", "round", "(", "top5a", ",", "4", ")", ",", "top5_err", "=", "round", "(", "100", "-", "top5a", ",", "4", ")", ",", "\n", "param_count", "=", "round", "(", "param_count", "/", "1e6", ",", "2", ")", ",", "\n", "img_size", "=", "data_config", "[", "'input_size'", "]", "[", "-", "1", "]", ",", "\n", "cropt_pct", "=", "crop_pct", ",", "\n", "interpolation", "=", "data_config", "[", "'interpolation'", "]", ")", "\n", "\n", "_logger", ".", "info", "(", "' * Acc@1 {:.3f} ({:.3f}) Acc@5 {:.3f} ({:.3f})'", ".", "format", "(", "\n", "results", "[", "'top1'", "]", ",", "results", "[", "'top1_err'", "]", ",", "results", "[", "'top5'", "]", ",", "results", "[", "'top5_err'", "]", ")", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.validate._try_run": [[286, 305], ["collections.OrderedDict", "_logger.error", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "validate.validate", "str", "_logger.warning"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.train.validate"], ["", "def", "_try_run", "(", "args", ",", "initial_batch_size", ")", ":", "\n", "    ", "batch_size", "=", "initial_batch_size", "\n", "results", "=", "OrderedDict", "(", ")", "\n", "error_str", "=", "'Unknown'", "\n", "while", "batch_size", ">=", "1", ":", "\n", "        ", "args", ".", "batch_size", "=", "batch_size", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "try", ":", "\n", "            ", "results", "=", "validate", "(", "args", ")", "\n", "return", "results", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "            ", "error_str", "=", "str", "(", "e", ")", "\n", "if", "'channels_last'", "in", "error_str", ":", "\n", "                ", "break", "\n", "", "_logger", ".", "warning", "(", "f'\"{error_str}\" while running validation. Reducing batch size to {batch_size} for retry.'", ")", "\n", "", "batch_size", "=", "batch_size", "//", "2", "\n", "", "results", "[", "'error'", "]", "=", "error_str", "\n", "_logger", ".", "error", "(", "f'{args.model} failed to validate ({error_str}).'", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.validate.main": [[307, 358], ["timm.utils.setup_default_logging", "parser.parse_args", "os.path.isdir", "len", "print", "glob.glob", "glob.glob", "models.list_models", "_logger.info", "sorted", "len", "validate.validate", "models.list_models", "os.path.isfile", "validate.write_results", "sorted", "models.is_model", "models.list_models", "open", "validate._try_run", "validate.append", "json.dumps", "line.rstrip"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.list_models", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.train.validate", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.list_models", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.validate.write_results", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.is_model", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.list_models", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.validate._try_run"], ["", "def", "main", "(", ")", ":", "\n", "    ", "setup_default_logging", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "model_cfgs", "=", "[", "]", "\n", "model_names", "=", "[", "]", "\n", "if", "os", ".", "path", ".", "isdir", "(", "args", ".", "checkpoint", ")", ":", "\n", "# validate all checkpoints in a path with same model", "\n", "        ", "checkpoints", "=", "glob", ".", "glob", "(", "args", ".", "checkpoint", "+", "'/*.pth.tar'", ")", "\n", "checkpoints", "+=", "glob", ".", "glob", "(", "args", ".", "checkpoint", "+", "'/*.pth'", ")", "\n", "model_names", "=", "list_models", "(", "args", ".", "model", ")", "\n", "model_cfgs", "=", "[", "(", "args", ".", "model", ",", "c", ")", "for", "c", "in", "sorted", "(", "checkpoints", ",", "key", "=", "natural_key", ")", "]", "\n", "", "else", ":", "\n", "        ", "if", "args", ".", "model", "==", "'all'", ":", "\n", "# validate all models in a list of names with pretrained checkpoints", "\n", "            ", "args", ".", "pretrained", "=", "True", "\n", "model_names", "=", "list_models", "(", "pretrained", "=", "True", ",", "exclude_filters", "=", "[", "'*_in21k'", ",", "'*_in22k'", ",", "'*_dino'", "]", ")", "\n", "model_cfgs", "=", "[", "(", "n", ",", "''", ")", "for", "n", "in", "model_names", "]", "\n", "", "elif", "not", "is_model", "(", "args", ".", "model", ")", ":", "\n", "# model name doesn't exist, try as wildcard filter", "\n", "            ", "model_names", "=", "list_models", "(", "args", ".", "model", ")", "\n", "model_cfgs", "=", "[", "(", "n", ",", "''", ")", "for", "n", "in", "model_names", "]", "\n", "\n", "", "if", "not", "model_cfgs", "and", "os", ".", "path", ".", "isfile", "(", "args", ".", "model", ")", ":", "\n", "            ", "with", "open", "(", "args", ".", "model", ")", "as", "f", ":", "\n", "                ", "model_names", "=", "[", "line", ".", "rstrip", "(", ")", "for", "line", "in", "f", "]", "\n", "", "model_cfgs", "=", "[", "(", "n", ",", "None", ")", "for", "n", "in", "model_names", "if", "n", "]", "\n", "\n", "", "", "if", "len", "(", "model_cfgs", ")", ":", "\n", "        ", "results_file", "=", "args", ".", "results_file", "or", "'./results-all.csv'", "\n", "_logger", ".", "info", "(", "'Running bulk validation on these pretrained models: {}'", ".", "format", "(", "', '", ".", "join", "(", "model_names", ")", ")", ")", "\n", "results", "=", "[", "]", "\n", "try", ":", "\n", "            ", "initial_batch_size", "=", "args", ".", "batch_size", "\n", "for", "m", ",", "c", "in", "model_cfgs", ":", "\n", "                ", "args", ".", "model", "=", "m", "\n", "args", ".", "checkpoint", "=", "c", "\n", "r", "=", "_try_run", "(", "args", ",", "initial_batch_size", ")", "\n", "if", "'error'", "in", "r", ":", "\n", "                    ", "continue", "\n", "", "if", "args", ".", "checkpoint", ":", "\n", "                    ", "r", "[", "'checkpoint'", "]", "=", "args", ".", "checkpoint", "\n", "", "results", ".", "append", "(", "r", ")", "\n", "", "", "except", "KeyboardInterrupt", "as", "e", ":", "\n", "            ", "pass", "\n", "", "results", "=", "sorted", "(", "results", ",", "key", "=", "lambda", "x", ":", "x", "[", "'top1'", "]", ",", "reverse", "=", "True", ")", "\n", "if", "len", "(", "results", ")", ":", "\n", "            ", "write_results", "(", "results_file", ",", "results", ")", "\n", "", "", "else", ":", "\n", "        ", "results", "=", "validate", "(", "args", ")", "\n", "# output results in JSON to stdout w/ delimiter for runner script", "\n", "", "print", "(", "f'--result\\n{json.dumps(results, indent=4)}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.validate.write_results": [[360, 367], ["open", "csv.DictWriter", "csv.DictWriter.writeheader", "cf.flush", "csv.DictWriter.writerow", "results[].keys"], "function", ["None"], ["", "def", "write_results", "(", "results_file", ",", "results", ")", ":", "\n", "    ", "with", "open", "(", "results_file", ",", "mode", "=", "'w'", ")", "as", "cf", ":", "\n", "        ", "dw", "=", "csv", ".", "DictWriter", "(", "cf", ",", "fieldnames", "=", "results", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "dw", ".", "writeheader", "(", ")", "\n", "for", "r", "in", "results", ":", "\n", "            ", "dw", ".", "writerow", "(", "r", ")", "\n", "", "cf", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.inference.main": [[60, 124], ["timm.utils.setup_default_logging", "parser.parse_args", "models.create_model", "_logger.info", "timm.data.resolve_data_config", "timm.data.create_loader", "model.cuda.eval", "min", "timm.utils.AverageMeter", "time.time", "numpy.concatenate", "vars", "models.apply_test_time_pool", "torch.nn.DataParallel().cuda", "model.cuda.cuda", "timm.data.ImageDataset", "torch.no_grad", "enumerate", "open", "timm.data.create_loader.dataset.filenames", "zip", "input.cuda.cuda", "model.cuda.", "np.concatenate.append", "timm.utils.AverageMeter.update", "time.time", "os.path.join", "out_file.write", "sum", "torch.nn.DataParallel", "model.topk", "topk.cpu().numpy", "_logger.info", "time.time", "m.numel", "list", "topk.cpu", "len", "model.cuda.parameters", "range", "str"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.factory.create_model", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.test_time_pool.apply_test_time_pool"], ["def", "main", "(", ")", ":", "\n", "    ", "setup_default_logging", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "# might as well try to do something useful...", "\n", "args", ".", "pretrained", "=", "args", ".", "pretrained", "or", "not", "args", ".", "checkpoint", "\n", "\n", "# create model", "\n", "model", "=", "create_model", "(", "\n", "args", ".", "model", ",", "\n", "num_classes", "=", "args", ".", "num_classes", ",", "\n", "in_chans", "=", "3", ",", "\n", "pretrained", "=", "args", ".", "pretrained", ",", "\n", "checkpoint_path", "=", "args", ".", "checkpoint", ")", "\n", "\n", "_logger", ".", "info", "(", "'Model %s created, param count: %d'", "%", "\n", "(", "args", ".", "model", ",", "sum", "(", "[", "m", ".", "numel", "(", ")", "for", "m", "in", "model", ".", "parameters", "(", ")", "]", ")", ")", ")", "\n", "\n", "config", "=", "resolve_data_config", "(", "vars", "(", "args", ")", ",", "model", "=", "model", ")", "\n", "model", ",", "test_time_pool", "=", "(", "model", ",", "False", ")", "if", "args", ".", "no_test_pool", "else", "apply_test_time_pool", "(", "model", ",", "config", ")", "\n", "\n", "if", "args", ".", "num_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "list", "(", "range", "(", "args", ".", "num_gpu", ")", ")", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "", "loader", "=", "create_loader", "(", "\n", "ImageDataset", "(", "args", ".", "data", ")", ",", "\n", "input_size", "=", "config", "[", "'input_size'", "]", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "use_prefetcher", "=", "True", ",", "\n", "interpolation", "=", "config", "[", "'interpolation'", "]", ",", "\n", "mean", "=", "config", "[", "'mean'", "]", ",", "\n", "std", "=", "config", "[", "'std'", "]", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "crop_pct", "=", "1.0", "if", "test_time_pool", "else", "config", "[", "'crop_pct'", "]", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "k", "=", "min", "(", "args", ".", "topk", ",", "args", ".", "num_classes", ")", "\n", "batch_time", "=", "AverageMeter", "(", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "topk_ids", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch_idx", ",", "(", "input", ",", "_", ")", "in", "enumerate", "(", "loader", ")", ":", "\n", "            ", "input", "=", "input", ".", "cuda", "(", ")", "\n", "labels", "=", "model", "(", "input", ")", "\n", "topk", "=", "labels", ".", "topk", "(", "k", ")", "[", "1", "]", "\n", "topk_ids", ".", "append", "(", "topk", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "batch_idx", "%", "args", ".", "log_freq", "==", "0", ":", "\n", "                ", "_logger", ".", "info", "(", "'Predict: [{0}/{1}] Time {batch_time.val:.3f} ({batch_time.avg:.3f})'", ".", "format", "(", "\n", "batch_idx", ",", "len", "(", "loader", ")", ",", "batch_time", "=", "batch_time", ")", ")", "\n", "\n", "", "", "", "topk_ids", "=", "np", ".", "concatenate", "(", "topk_ids", ",", "axis", "=", "0", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'./topk_ids.csv'", ")", ",", "'w'", ")", "as", "out_file", ":", "\n", "        ", "filenames", "=", "loader", ".", "dataset", ".", "filenames", "(", "basename", "=", "True", ")", "\n", "for", "filename", ",", "label", "in", "zip", "(", "filenames", ",", "topk_ids", ")", ":", "\n", "            ", "out_file", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "\n", "filename", ",", "','", ".", "join", "(", "[", "str", "(", "v", ")", "for", "v", "in", "label", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.train._parse_args": [[312, 327], ["config_parser.parse_known_args", "parser.parse_args", "yaml.safe_dump", "open", "yaml.safe_load", "parser.set_defaults"], "function", ["None"], ["def", "_parse_args", "(", ")", ":", "\n", "# Do we have a config file to parse?", "\n", "    ", "args_config", ",", "remaining", "=", "config_parser", ".", "parse_known_args", "(", ")", "\n", "if", "args_config", ".", "config", ":", "\n", "        ", "with", "open", "(", "args_config", ".", "config", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "cfg", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "parser", ".", "set_defaults", "(", "**", "cfg", ")", "\n", "\n", "# The main arg parser parses the rest of the args, the usual", "\n", "# defaults will have been overridden if config file specified.", "\n", "", "", "args", "=", "parser", ".", "parse_args", "(", "remaining", ")", "\n", "\n", "# Cache the args as a text string to save them in the output dir later", "\n", "args_text", "=", "yaml", ".", "safe_dump", "(", "args", ".", "__dict__", ",", "default_flow_style", "=", "False", ")", "\n", "return", "args", ",", "args_text", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.train.main": [[329, 677], ["setup_default_logging", "train._parse_args", "random_seed", "models.create_model", "timm.data.resolve_data_config", "torch.nn.parallel.DistributedDataParallel.cuda", "timm.optim.create_optimizer_v2", "timm.scheduler.create_scheduler", "timm.data.create_dataset", "timm.data.create_dataset", "timm.data.create_loader", "timm.data.create_loader", "LabelSmoothingCrossEntropy.cuda", "torch.CrossEntropyLoss().cuda", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "_logger.info", "_logger.info", "kd.kd_utils.build_kd_model", "hasattr", "_logger.info", "vars", "models.convert_splitbn_model", "torch.nn.parallel.DistributedDataParallel.to", "torch.jit.script", "torch.jit.script", "torch.jit.script", "amp.initialize", "timm.utils.ApexScaler", "models.resume_checkpoint", "ModelEmaV2", "lr_scheduler.step", "_logger.info", "dict", "timm.data.AugMixDataset", "JsdCrossEntropy", "get_outdir", "utils.checkpoint_saver.CheckpointSaverUSI", "range", "_logger.info", "wandb.init", "_logger.warning", "int", "max", "convert_syncbn_model", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "_logger.info", "timm.optim.optimizer_kwargs", "_logger.info", "timm.utils.NativeScaler", "models.load_checkpoint", "ApexDDP", "torch.nn.parallel.DistributedDataParallel", "timm.data.FastCollateMixup", "timm.data.Mixup", "torch.CrossEntropyLoss", "open", "f.write", "train.train_one_epoch", "train.validate", "_logger.warning", "_logger.info", "_logger.info", "_logger.info", "_logger.info", "BinaryCrossEntropy", "SoftTargetCrossEntropy", "torch.CrossEntropyLoss", "os.path.join", "hasattr", "timm.data.create_loader.sampler.set_epoch", "distribute_bn", "train.validate", "lr_scheduler.step", "update_summary", "utils.checkpoint_saver.CheckpointSaverUSI.save_checkpoint", "models.safe_model_name", "sum", "BinaryCrossEntropy", "LabelSmoothingCrossEntropy", "datetime.datetime.now().strftime", "models.safe_model_name", "str", "_logger.info", "distribute_bn", "os.path.join", "m.numel", "datetime.datetime.now", "torch.nn.parallel.DistributedDataParallel.parameters"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.train._parse_args", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.factory.create_model", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.split_batchnorm.convert_splitbn_model", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.resume_checkpoint", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.load_checkpoint", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.train.train_one_epoch", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.train.validate", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.train.validate", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.utils.checkpoint_saver.CheckpointSaverUSI.save_checkpoint", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.factory.safe_model_name", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.factory.safe_model_name"], ["", "def", "main", "(", ")", ":", "\n", "    ", "setup_default_logging", "(", ")", "\n", "args", ",", "args_text", "=", "_parse_args", "(", ")", "\n", "\n", "if", "args", ".", "log_wandb", ":", "\n", "        ", "if", "has_wandb", ":", "\n", "            ", "wandb", ".", "init", "(", "project", "=", "args", ".", "experiment", ",", "config", "=", "args", ")", "\n", "", "else", ":", "\n", "            ", "_logger", ".", "warning", "(", "\"You've requested to log metrics to wandb but package not found. \"", "\n", "\"Metrics not being logged to wandb, try `pip install wandb`\"", ")", "\n", "\n", "", "", "args", ".", "prefetcher", "=", "not", "args", ".", "no_prefetcher", "\n", "args", ".", "distributed", "=", "False", "\n", "if", "'WORLD_SIZE'", "in", "os", ".", "environ", ":", "\n", "        ", "args", ".", "distributed", "=", "int", "(", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", ")", ">", "1", "\n", "", "args", ".", "device", "=", "'cuda:0'", "\n", "args", ".", "world_size", "=", "1", "\n", "args", ".", "rank", "=", "0", "# global rank", "\n", "if", "args", ".", "distributed", ":", "\n", "        ", "args", ".", "device", "=", "'cuda:%d'", "%", "args", ".", "local_rank", "\n", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ",", "init_method", "=", "'env://'", ")", "\n", "args", ".", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "args", ".", "rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "_logger", ".", "info", "(", "'Training in distributed mode with multiple processes, 1 GPU per process. Process %d, total %d.'", "\n", "%", "(", "args", ".", "rank", ",", "args", ".", "world_size", ")", ")", "\n", "", "else", ":", "\n", "        ", "_logger", ".", "info", "(", "'Training with a single process on 1 GPUs.'", ")", "\n", "", "assert", "args", ".", "rank", ">=", "0", "\n", "\n", "# resolve AMP arguments based on PyTorch / Apex availability", "\n", "use_amp", "=", "None", "\n", "if", "args", ".", "amp", ":", "\n", "# `--amp` chooses native amp before apex (APEX ver not actively maintained)", "\n", "        ", "if", "has_native_amp", ":", "\n", "            ", "args", ".", "native_amp", "=", "True", "\n", "", "elif", "has_apex", ":", "\n", "            ", "args", ".", "apex_amp", "=", "True", "\n", "", "", "if", "args", ".", "apex_amp", "and", "has_apex", ":", "\n", "        ", "use_amp", "=", "'apex'", "\n", "", "elif", "args", ".", "native_amp", "and", "has_native_amp", ":", "\n", "        ", "use_amp", "=", "'native'", "\n", "", "elif", "args", ".", "apex_amp", "or", "args", ".", "native_amp", ":", "\n", "        ", "_logger", ".", "warning", "(", "\"Neither APEX or native Torch AMP is available, using float32. \"", "\n", "\"Install NVIDA apex or upgrade to PyTorch 1.6\"", ")", "\n", "\n", "", "random_seed", "(", "args", ".", "seed", ",", "args", ".", "rank", ")", "\n", "\n", "model_KD", "=", "None", "\n", "if", "args", ".", "kd_model_name", "is", "not", "None", ":", "\n", "        ", "model_KD", "=", "build_kd_model", "(", "args", ")", "\n", "\n", "", "model", "=", "create_model", "(", "\n", "args", ".", "model", ",", "\n", "pretrained", "=", "args", ".", "pretrained", ",", "\n", "num_classes", "=", "args", ".", "num_classes", ",", "\n", "drop_rate", "=", "args", ".", "drop", ",", "\n", "drop_connect_rate", "=", "args", ".", "drop_connect", ",", "# DEPRECATED, use drop_path", "\n", "drop_path_rate", "=", "args", ".", "drop_path", ",", "\n", "drop_block_rate", "=", "args", ".", "drop_block", ",", "\n", "global_pool", "=", "args", ".", "gp", ",", "\n", "bn_momentum", "=", "args", ".", "bn_momentum", ",", "\n", "bn_eps", "=", "args", ".", "bn_eps", ",", "\n", "scriptable", "=", "args", ".", "torchscript", ",", "\n", "checkpoint_path", "=", "args", ".", "initial_checkpoint", ")", "\n", "if", "args", ".", "num_classes", "is", "None", ":", "\n", "        ", "assert", "hasattr", "(", "model", ",", "'num_classes'", ")", ",", "'Model must have `num_classes` attr if not set on cmd line/config.'", "\n", "args", ".", "num_classes", "=", "model", ".", "num_classes", "# FIXME handle model default vs config num_classes more elegantly", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "_logger", ".", "info", "(", "\n", "f'Model {safe_model_name(args.model)} created, param count:{sum([m.numel() for m in model.parameters()])}'", ")", "\n", "\n", "", "data_config", "=", "resolve_data_config", "(", "vars", "(", "args", ")", ",", "model", "=", "model", ",", "verbose", "=", "args", ".", "local_rank", "==", "0", ")", "\n", "\n", "# setup augmentation batch splits for contrastive loss or split bn", "\n", "num_aug_splits", "=", "0", "\n", "if", "args", ".", "aug_splits", ">", "0", ":", "\n", "        ", "assert", "args", ".", "aug_splits", ">", "1", ",", "'A split of 1 makes no sense'", "\n", "num_aug_splits", "=", "args", ".", "aug_splits", "\n", "\n", "# enable split bn (separate bn stats per batch-portion)", "\n", "", "if", "args", ".", "split_bn", ":", "\n", "        ", "assert", "num_aug_splits", ">", "1", "or", "args", ".", "resplit", "\n", "model", "=", "convert_splitbn_model", "(", "model", ",", "max", "(", "num_aug_splits", ",", "2", ")", ")", "\n", "\n", "# move model to GPU, enable channels last layout if set", "\n", "", "model", ".", "cuda", "(", ")", "\n", "if", "args", ".", "channels_last", ":", "\n", "        ", "model", "=", "model", ".", "to", "(", "memory_format", "=", "torch", ".", "channels_last", ")", "\n", "\n", "# setup synchronized BatchNorm for distributed training", "\n", "", "if", "args", ".", "distributed", "and", "args", ".", "sync_bn", ":", "\n", "        ", "assert", "not", "args", ".", "split_bn", "\n", "if", "has_apex", "and", "use_amp", "==", "'apex'", ":", "\n", "# Apex SyncBN preferred unless native amp is activated", "\n", "            ", "model", "=", "convert_syncbn_model", "(", "model", ")", "\n", "", "else", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "SyncBatchNorm", ".", "convert_sync_batchnorm", "(", "model", ")", "\n", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "_logger", ".", "info", "(", "\n", "'Converted model to use Synchronized BatchNorm. WARNING: You may have issues if using '", "\n", "'zero initialized BN layers (enabled by default for ResNets) while sync-bn enabled.'", ")", "\n", "\n", "", "", "if", "args", ".", "torchscript", ":", "\n", "        ", "assert", "not", "use_amp", "==", "'apex'", ",", "'Cannot use APEX AMP with torchscripted model'", "\n", "assert", "not", "args", ".", "sync_bn", ",", "'Cannot use SyncBatchNorm with torchscripted model'", "\n", "model", "=", "torch", ".", "jit", ".", "script", "(", "model", ")", "\n", "\n", "", "optimizer", "=", "create_optimizer_v2", "(", "model", ",", "**", "optimizer_kwargs", "(", "cfg", "=", "args", ")", ")", "\n", "\n", "# setup automatic mixed-precision (AMP) loss scaling and op casting", "\n", "amp_autocast", "=", "suppress", "# do nothing", "\n", "loss_scaler", "=", "None", "\n", "if", "use_amp", "==", "'apex'", ":", "\n", "        ", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "'O1'", ")", "\n", "loss_scaler", "=", "ApexScaler", "(", ")", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "_logger", ".", "info", "(", "'Using NVIDIA APEX AMP. Training in mixed precision.'", ")", "\n", "", "", "elif", "use_amp", "==", "'native'", ":", "\n", "        ", "amp_autocast", "=", "torch", ".", "cuda", ".", "amp", ".", "autocast", "\n", "loss_scaler", "=", "NativeScaler", "(", ")", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "_logger", ".", "info", "(", "'Using native Torch AMP. Training in mixed precision.'", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "_logger", ".", "info", "(", "'AMP not enabled. Training in float32.'", ")", "\n", "\n", "# optionally resume from a checkpoint", "\n", "", "", "resume_epoch", "=", "None", "\n", "if", "args", ".", "resume", ":", "\n", "        ", "resume_epoch", "=", "resume_checkpoint", "(", "\n", "model", ",", "args", ".", "resume", ",", "\n", "optimizer", "=", "None", "if", "args", ".", "no_resume_opt", "else", "optimizer", ",", "\n", "loss_scaler", "=", "None", "if", "args", ".", "no_resume_opt", "else", "loss_scaler", ",", "\n", "log_info", "=", "args", ".", "local_rank", "==", "0", ")", "\n", "\n", "# setup exponential moving average of model weights, SWA could be used here too", "\n", "", "model_ema", "=", "None", "\n", "if", "args", ".", "model_ema", ":", "\n", "# Important to create EMA model after cuda(), DP wrapper, and AMP but before SyncBN and DDP wrapper", "\n", "        ", "model_ema", "=", "ModelEmaV2", "(", "\n", "model", ",", "decay", "=", "args", ".", "model_ema_decay", ",", "device", "=", "'cpu'", "if", "args", ".", "model_ema_force_cpu", "else", "None", ")", "\n", "if", "args", ".", "resume", ":", "\n", "            ", "load_checkpoint", "(", "model_ema", ".", "module", ",", "args", ".", "resume", ",", "use_ema", "=", "True", ")", "\n", "\n", "# setup distributed training", "\n", "", "", "if", "args", ".", "distributed", ":", "\n", "        ", "if", "has_apex", "and", "use_amp", "==", "'apex'", ":", "\n", "# Apex DDP preferred unless native amp is activated", "\n", "            ", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "                ", "_logger", ".", "info", "(", "\"Using NVIDIA APEX DistributedDataParallel.\"", ")", "\n", "", "model", "=", "ApexDDP", "(", "model", ",", "delay_allreduce", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "                ", "_logger", ".", "info", "(", "\"Using native Torch DistributedDataParallel.\"", ")", "\n", "", "model", "=", "NativeDDP", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "broadcast_buffers", "=", "not", "args", ".", "no_ddp_bb", ")", "\n", "# NOTE: EMA model does not need to be wrapped by DDP", "\n", "\n", "# setup learning rate schedule and starting epoch", "\n", "", "", "lr_scheduler", ",", "num_epochs", "=", "create_scheduler", "(", "args", ",", "optimizer", ")", "\n", "start_epoch", "=", "0", "\n", "if", "args", ".", "start_epoch", "is", "not", "None", ":", "\n", "# a specified start_epoch will always override the resume epoch", "\n", "        ", "start_epoch", "=", "args", ".", "start_epoch", "\n", "", "elif", "resume_epoch", "is", "not", "None", ":", "\n", "        ", "start_epoch", "=", "resume_epoch", "\n", "", "if", "lr_scheduler", "is", "not", "None", "and", "start_epoch", ">", "0", ":", "\n", "        ", "lr_scheduler", ".", "step", "(", "start_epoch", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "_logger", ".", "info", "(", "'Scheduled epochs: {}'", ".", "format", "(", "num_epochs", ")", ")", "\n", "\n", "# create the train and eval datasets", "\n", "", "dataset_train", "=", "create_dataset", "(", "\n", "args", ".", "dataset", ",", "root", "=", "args", ".", "data_dir", ",", "split", "=", "args", ".", "train_split", ",", "is_training", "=", "True", ",", "\n", "class_map", "=", "args", ".", "class_map", ",", "\n", "download", "=", "args", ".", "dataset_download", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "repeats", "=", "args", ".", "epoch_repeats", ")", "\n", "dataset_eval", "=", "create_dataset", "(", "\n", "args", ".", "dataset", ",", "root", "=", "args", ".", "data_dir", ",", "split", "=", "args", ".", "val_split", ",", "is_training", "=", "False", ",", "\n", "class_map", "=", "args", ".", "class_map", ",", "\n", "download", "=", "args", ".", "dataset_download", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ")", "\n", "\n", "# setup mixup / cutmix", "\n", "collate_fn", "=", "None", "\n", "mixup_fn", "=", "None", "\n", "mixup_active", "=", "args", ".", "mixup", ">", "0", "or", "args", ".", "cutmix", ">", "0.", "or", "args", ".", "cutmix_minmax", "is", "not", "None", "\n", "if", "mixup_active", ":", "\n", "        ", "mixup_args", "=", "dict", "(", "\n", "mixup_alpha", "=", "args", ".", "mixup", ",", "cutmix_alpha", "=", "args", ".", "cutmix", ",", "cutmix_minmax", "=", "args", ".", "cutmix_minmax", ",", "\n", "prob", "=", "args", ".", "mixup_prob", ",", "switch_prob", "=", "args", ".", "mixup_switch_prob", ",", "mode", "=", "args", ".", "mixup_mode", ",", "\n", "label_smoothing", "=", "args", ".", "smoothing", ",", "num_classes", "=", "args", ".", "num_classes", ")", "\n", "if", "args", ".", "prefetcher", ":", "\n", "            ", "assert", "not", "num_aug_splits", "# collate conflict (need to support deinterleaving in collate mixup)", "\n", "collate_fn", "=", "FastCollateMixup", "(", "**", "mixup_args", ")", "\n", "", "else", ":", "\n", "            ", "mixup_fn", "=", "Mixup", "(", "**", "mixup_args", ")", "\n", "\n", "# wrap dataset in AugMix helper", "\n", "", "", "if", "num_aug_splits", ">", "1", ":", "\n", "        ", "dataset_train", "=", "AugMixDataset", "(", "dataset_train", ",", "num_splits", "=", "num_aug_splits", ")", "\n", "\n", "# create data loaders w/ augmentation pipeiine", "\n", "", "train_interpolation", "=", "args", ".", "train_interpolation", "\n", "if", "args", ".", "no_aug", "or", "not", "train_interpolation", ":", "\n", "        ", "train_interpolation", "=", "data_config", "[", "'interpolation'", "]", "\n", "", "loader_train", "=", "create_loader", "(", "\n", "dataset_train", ",", "\n", "input_size", "=", "data_config", "[", "'input_size'", "]", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "is_training", "=", "True", ",", "\n", "use_prefetcher", "=", "args", ".", "prefetcher", ",", "\n", "no_aug", "=", "args", ".", "no_aug", ",", "\n", "re_prob", "=", "args", ".", "reprob", ",", "\n", "re_mode", "=", "args", ".", "remode", ",", "\n", "re_count", "=", "args", ".", "recount", ",", "\n", "re_split", "=", "args", ".", "resplit", ",", "\n", "scale", "=", "args", ".", "scale", ",", "\n", "ratio", "=", "args", ".", "ratio", ",", "\n", "hflip", "=", "args", ".", "hflip", ",", "\n", "vflip", "=", "args", ".", "vflip", ",", "\n", "color_jitter", "=", "args", ".", "color_jitter", ",", "\n", "auto_augment", "=", "args", ".", "aa", ",", "\n", "num_aug_repeats", "=", "args", ".", "aug_repeats", ",", "\n", "num_aug_splits", "=", "num_aug_splits", ",", "\n", "interpolation", "=", "train_interpolation", ",", "\n", "mean", "=", "data_config", "[", "'mean'", "]", ",", "\n", "std", "=", "data_config", "[", "'std'", "]", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "pin_memory", "=", "args", ".", "pin_mem", ",", "\n", "use_multi_epochs_loader", "=", "args", ".", "use_multi_epochs_loader", ",", "\n", "worker_seeding", "=", "args", ".", "worker_seeding", ",", "\n", ")", "\n", "\n", "loader_eval", "=", "create_loader", "(", "\n", "dataset_eval", ",", "\n", "input_size", "=", "data_config", "[", "'input_size'", "]", ",", "\n", "batch_size", "=", "args", ".", "validation_batch_size", "or", "args", ".", "batch_size", ",", "\n", "is_training", "=", "False", ",", "\n", "use_prefetcher", "=", "args", ".", "prefetcher", ",", "\n", "interpolation", "=", "data_config", "[", "'interpolation'", "]", ",", "\n", "mean", "=", "data_config", "[", "'mean'", "]", ",", "\n", "std", "=", "data_config", "[", "'std'", "]", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "distributed", "=", "args", ".", "distributed", ",", "\n", "crop_pct", "=", "data_config", "[", "'crop_pct'", "]", ",", "\n", "pin_memory", "=", "args", ".", "pin_mem", ",", "\n", ")", "\n", "\n", "# setup loss function", "\n", "if", "args", ".", "jsd_loss", ":", "\n", "        ", "assert", "num_aug_splits", ">", "1", "# JSD only valid with aug splits set", "\n", "train_loss_fn", "=", "JsdCrossEntropy", "(", "num_splits", "=", "num_aug_splits", ",", "smoothing", "=", "args", ".", "smoothing", ")", "\n", "", "elif", "mixup_active", ":", "\n", "# smoothing is handled with mixup target transform which outputs sparse, soft targets", "\n", "        ", "if", "args", ".", "bce_loss", ":", "\n", "            ", "train_loss_fn", "=", "BinaryCrossEntropy", "(", "target_threshold", "=", "args", ".", "bce_target_thresh", ")", "\n", "", "else", ":", "\n", "            ", "train_loss_fn", "=", "SoftTargetCrossEntropy", "(", ")", "\n", "", "", "elif", "args", ".", "smoothing", ":", "\n", "        ", "if", "args", ".", "bce_loss", ":", "\n", "            ", "train_loss_fn", "=", "BinaryCrossEntropy", "(", "smoothing", "=", "args", ".", "smoothing", ",", "target_threshold", "=", "args", ".", "bce_target_thresh", ")", "\n", "", "else", ":", "\n", "            ", "train_loss_fn", "=", "LabelSmoothingCrossEntropy", "(", "smoothing", "=", "args", ".", "smoothing", ")", "\n", "", "", "else", ":", "\n", "        ", "train_loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "", "train_loss_fn", "=", "train_loss_fn", ".", "cuda", "(", ")", "\n", "validate_loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "# setup checkpoint saver and eval metric tracking", "\n", "eval_metric", "=", "args", ".", "eval_metric", "\n", "best_metric", "=", "None", "\n", "best_epoch", "=", "None", "\n", "saver", "=", "None", "\n", "output_dir", "=", "None", "\n", "if", "args", ".", "rank", "==", "0", ":", "\n", "        ", "if", "args", ".", "experiment", ":", "\n", "            ", "exp_name", "=", "args", ".", "experiment", "\n", "", "else", ":", "\n", "            ", "exp_name", "=", "'-'", ".", "join", "(", "[", "\n", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y%m%d-%H%M%S\"", ")", ",", "\n", "safe_model_name", "(", "args", ".", "model", ")", ",", "\n", "str", "(", "data_config", "[", "'input_size'", "]", "[", "-", "1", "]", ")", "\n", "]", ")", "\n", "", "output_dir", "=", "get_outdir", "(", "args", ".", "output", "if", "args", ".", "output", "else", "'./output/train'", ",", "exp_name", ")", "\n", "decreasing", "=", "True", "if", "eval_metric", "==", "'loss'", "else", "False", "\n", "saver", "=", "CheckpointSaverUSI", "(", "\n", "model", "=", "model", ",", "optimizer", "=", "optimizer", ",", "args", "=", "args", ",", "model_ema", "=", "model_ema", ",", "amp_scaler", "=", "loss_scaler", ",", "\n", "checkpoint_dir", "=", "output_dir", ",", "recovery_dir", "=", "output_dir", ",", "decreasing", "=", "decreasing", ",", "max_history", "=", "args", ".", "checkpoint_hist", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'args.yaml'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "args_text", ")", "\n", "\n", "", "", "try", ":", "\n", "        ", "for", "epoch", "in", "range", "(", "start_epoch", ",", "num_epochs", ")", ":", "\n", "            ", "if", "args", ".", "distributed", "and", "hasattr", "(", "loader_train", ".", "sampler", ",", "'set_epoch'", ")", ":", "\n", "                ", "loader_train", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "\n", "", "train_metrics", "=", "train_one_epoch", "(", "\n", "epoch", ",", "model", ",", "loader_train", ",", "optimizer", ",", "train_loss_fn", ",", "args", ",", "\n", "lr_scheduler", "=", "lr_scheduler", ",", "saver", "=", "saver", ",", "output_dir", "=", "output_dir", ",", "\n", "amp_autocast", "=", "amp_autocast", ",", "loss_scaler", "=", "loss_scaler", ",", "model_ema", "=", "model_ema", ",", "mixup_fn", "=", "mixup_fn", ",", "\n", "model_KD", "=", "model_KD", ")", "\n", "\n", "if", "args", ".", "distributed", "and", "args", ".", "dist_bn", "in", "(", "'broadcast'", ",", "'reduce'", ")", ":", "\n", "                ", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "                    ", "_logger", ".", "info", "(", "\"Distributing BatchNorm running means and vars\"", ")", "\n", "", "distribute_bn", "(", "model", ",", "args", ".", "world_size", ",", "args", ".", "dist_bn", "==", "'reduce'", ")", "\n", "\n", "", "eval_metrics", "=", "validate", "(", "model", ",", "loader_eval", ",", "validate_loss_fn", ",", "args", ",", "amp_autocast", "=", "amp_autocast", ")", "\n", "eval_metrics_unite", "=", "eval_metrics", "\n", "\n", "ema_eval_metrics", "=", "None", "\n", "if", "model_ema", "is", "not", "None", "and", "not", "args", ".", "model_ema_force_cpu", ":", "\n", "                ", "if", "args", ".", "distributed", "and", "args", ".", "dist_bn", "in", "(", "'broadcast'", ",", "'reduce'", ")", ":", "\n", "                    ", "distribute_bn", "(", "model_ema", ",", "args", ".", "world_size", ",", "args", ".", "dist_bn", "==", "'reduce'", ")", "\n", "", "ema_eval_metrics", "=", "validate", "(", "\n", "model_ema", ".", "module", ",", "loader_eval", ",", "validate_loss_fn", ",", "args", ",", "amp_autocast", "=", "amp_autocast", ",", "\n", "log_suffix", "=", "' (EMA)'", ")", "\n", "if", "ema_eval_metrics", "[", "eval_metric", "]", ">", "eval_metrics", "[", "eval_metric", "]", ":", "# choose the best model", "\n", "                    ", "eval_metrics_unite", "=", "ema_eval_metrics", "\n", "\n", "", "", "if", "lr_scheduler", "is", "not", "None", ":", "\n", "# step LR for next epoch", "\n", "                ", "lr_scheduler", ".", "step", "(", "epoch", "+", "1", ",", "eval_metrics_unite", "[", "eval_metric", "]", ")", "\n", "\n", "", "if", "output_dir", "is", "not", "None", ":", "\n", "                ", "update_summary", "(", "\n", "epoch", ",", "train_metrics", ",", "eval_metrics_unite", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'summary.csv'", ")", ",", "\n", "write_header", "=", "best_metric", "is", "None", ",", "log_wandb", "=", "args", ".", "log_wandb", "and", "has_wandb", ")", "\n", "\n", "", "if", "saver", "is", "not", "None", ":", "\n", "# save proper checkpoint with eval metric", "\n", "                ", "save_metric", "=", "eval_metrics", "[", "eval_metric", "]", "\n", "if", "ema_eval_metrics", ":", "\n", "                    ", "save_metric_ema", "=", "ema_eval_metrics", "[", "eval_metric", "]", "\n", "", "else", ":", "\n", "                    ", "save_metric_ema", "=", "-", "1", "\n", "", "best_metric", ",", "best_epoch", "=", "saver", ".", "save_checkpoint", "(", "epoch", ",", "metric", "=", "save_metric", ",", "metric_ema", "=", "save_metric_ema", ")", "\n", "\n", "", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "\n", "", "if", "best_metric", "is", "not", "None", ":", "\n", "        ", "_logger", ".", "info", "(", "'*** Best metric: {0} (epoch {1})'", ".", "format", "(", "best_metric", ",", "best_epoch", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.train.train_one_epoch": [[679, 801], ["AverageMeter", "AverageMeter", "AverageMeter", "model.train", "time.time", "enumerate", "hasattr", "collections.OrderedDict", "hasattr", "len", "len", "AverageMeter.update", "optimizer.zero_grad", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "AverageMeter.update", "time.time", "optimizer.sync_lookahead", "input.contiguous.contiguous", "amp_autocast", "model", "loss_fn", "AverageMeter.update", "loss_scaler", "loss_fn.backward", "optimizer.step", "model_ema.update", "saver.save_recovery", "lr_scheduler.step_update", "time.time", "input.contiguous.cuda", "target.cuda", "mixup_fn", "torch.log_softmax", "loss_fn.item", "input.contiguous.size", "dispatch_clip_grad", "time.time", "sum", "len", "reduce_tensor", "AverageMeter.update", "_logger.info", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model_KD.normalize_input", "model_KD.model", "torch.softmax", "models.model_parameters", "models.model_parameters", "reduce_tensor.item", "input.contiguous.size", "torchvision.utils.save_image", "model_KD.normalize_input.detach", "torch.kl_div", "torch.kl_div", "len", "os.path.join", "input.contiguous.size", "input.contiguous.size"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.AttentionSubsample.train", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.HardMishJitAutoFn.backward", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.utils.checkpoint_saver.CheckpointSaverUSI.save_recovery", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.kd_utils.build_kd_model.normalize_input", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.model_parameters", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.model_parameters"], ["", "", "def", "train_one_epoch", "(", "\n", "epoch", ",", "model", ",", "loader", ",", "optimizer", ",", "loss_fn", ",", "args", ",", "\n", "lr_scheduler", "=", "None", ",", "saver", "=", "None", ",", "output_dir", "=", "None", ",", "amp_autocast", "=", "suppress", ",", "\n", "loss_scaler", "=", "None", ",", "model_ema", "=", "None", ",", "mixup_fn", "=", "None", ",", "model_KD", "=", "None", ")", ":", "\n", "    ", "if", "args", ".", "mixup_off_epoch", "and", "epoch", ">=", "args", ".", "mixup_off_epoch", ":", "\n", "        ", "if", "args", ".", "prefetcher", "and", "loader", ".", "mixup_enabled", ":", "\n", "            ", "loader", ".", "mixup_enabled", "=", "False", "\n", "", "elif", "mixup_fn", "is", "not", "None", ":", "\n", "            ", "mixup_fn", ".", "mixup_enabled", "=", "False", "\n", "\n", "", "", "second_order", "=", "hasattr", "(", "optimizer", ",", "'is_second_order'", ")", "and", "optimizer", ".", "is_second_order", "\n", "batch_time_m", "=", "AverageMeter", "(", ")", "\n", "data_time_m", "=", "AverageMeter", "(", ")", "\n", "losses_m", "=", "AverageMeter", "(", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "last_idx", "=", "len", "(", "loader", ")", "-", "1", "\n", "num_updates", "=", "epoch", "*", "len", "(", "loader", ")", "\n", "for", "batch_idx", ",", "(", "input", ",", "target", ")", "in", "enumerate", "(", "loader", ")", ":", "\n", "        ", "last_batch", "=", "batch_idx", "==", "last_idx", "\n", "data_time_m", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "if", "not", "args", ".", "prefetcher", ":", "\n", "            ", "input", ",", "target", "=", "input", ".", "cuda", "(", ")", ",", "target", ".", "cuda", "(", ")", "\n", "if", "mixup_fn", "is", "not", "None", ":", "\n", "                ", "input", ",", "target", "=", "mixup_fn", "(", "input", ",", "target", ")", "\n", "", "", "if", "args", ".", "channels_last", ":", "\n", "            ", "input", "=", "input", ".", "contiguous", "(", "memory_format", "=", "torch", ".", "channels_last", ")", "\n", "\n", "", "with", "amp_autocast", "(", ")", ":", "\n", "            ", "output", "=", "model", "(", "input", ")", "\n", "loss", "=", "loss_fn", "(", "output", ",", "target", ")", "\n", "\n", "# KD logic", "\n", "if", "model_KD", "is", "not", "None", ":", "\n", "# student probability calculation", "\n", "                ", "prob_s", "=", "F", ".", "log_softmax", "(", "output", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# teacher probability calculation", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "input_kd", "=", "model_KD", ".", "normalize_input", "(", "input", ",", "model", ")", "\n", "out_t", "=", "model_KD", ".", "model", "(", "input_kd", ".", "detach", "(", ")", ")", "\n", "prob_t", "=", "F", ".", "softmax", "(", "out_t", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# adding KL loss", "\n", "", "if", "not", "args", ".", "use_kd_only_loss", ":", "\n", "                    ", "loss", "+=", "args", ".", "alpha_kd", "*", "F", ".", "kl_div", "(", "prob_s", ",", "prob_t", ",", "reduction", "=", "'batchmean'", ")", "\n", "", "else", ":", "# only kid", "\n", "                    ", "loss", "=", "args", ".", "alpha_kd", "*", "F", ".", "kl_div", "(", "prob_s", ",", "prob_t", ",", "reduction", "=", "'batchmean'", ")", "\n", "\n", "", "", "", "if", "not", "args", ".", "distributed", ":", "\n", "            ", "losses_m", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "loss_scaler", "is", "not", "None", ":", "\n", "            ", "loss_scaler", "(", "\n", "loss", ",", "optimizer", ",", "\n", "clip_grad", "=", "args", ".", "clip_grad", ",", "clip_mode", "=", "args", ".", "clip_mode", ",", "\n", "parameters", "=", "model_parameters", "(", "model", ",", "exclude_head", "=", "'agc'", "in", "args", ".", "clip_mode", ")", ",", "\n", "create_graph", "=", "second_order", ")", "\n", "", "else", ":", "\n", "            ", "loss", ".", "backward", "(", "create_graph", "=", "second_order", ")", "\n", "if", "args", ".", "clip_grad", "is", "not", "None", ":", "\n", "                ", "dispatch_clip_grad", "(", "\n", "model_parameters", "(", "model", ",", "exclude_head", "=", "'agc'", "in", "args", ".", "clip_mode", ")", ",", "\n", "value", "=", "args", ".", "clip_grad", ",", "mode", "=", "args", ".", "clip_mode", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "if", "model_ema", "is", "not", "None", ":", "\n", "            ", "model_ema", ".", "update", "(", "model", ")", "\n", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "num_updates", "+=", "1", "\n", "batch_time_m", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "if", "last_batch", "or", "batch_idx", "%", "args", ".", "log_interval", "==", "0", ":", "\n", "            ", "lrl", "=", "[", "param_group", "[", "'lr'", "]", "for", "param_group", "in", "optimizer", ".", "param_groups", "]", "\n", "lr", "=", "sum", "(", "lrl", ")", "/", "len", "(", "lrl", ")", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "                ", "reduced_loss", "=", "reduce_tensor", "(", "loss", ".", "data", ",", "args", ".", "world_size", ")", "\n", "losses_m", ".", "update", "(", "reduced_loss", ".", "item", "(", ")", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "                ", "_logger", ".", "info", "(", "\n", "'Train: {} [{:>4d}/{} ({:>3.0f}%)]  '", "\n", "'Loss: {loss.val:#.4g} ({loss.avg:#.3g})  '", "\n", "'Time: {batch_time.val:.3f}s, {rate:>7.2f}/s  '", "\n", "'({batch_time.avg:.3f}s, {rate_avg:>7.2f}/s)  '", "\n", "'LR: {lr:.3e}  '", "\n", "'Data: {data_time.val:.3f} ({data_time.avg:.3f})'", ".", "format", "(", "\n", "epoch", ",", "\n", "batch_idx", ",", "len", "(", "loader", ")", ",", "\n", "100.", "*", "batch_idx", "/", "last_idx", ",", "\n", "loss", "=", "losses_m", ",", "\n", "batch_time", "=", "batch_time_m", ",", "\n", "rate", "=", "input", ".", "size", "(", "0", ")", "*", "args", ".", "world_size", "/", "batch_time_m", ".", "val", ",", "\n", "rate_avg", "=", "input", ".", "size", "(", "0", ")", "*", "args", ".", "world_size", "/", "batch_time_m", ".", "avg", ",", "\n", "lr", "=", "lr", ",", "\n", "data_time", "=", "data_time_m", ")", ")", "\n", "\n", "if", "args", ".", "save_images", "and", "output_dir", ":", "\n", "                    ", "torchvision", ".", "utils", ".", "save_image", "(", "\n", "input", ",", "\n", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'train-batch-%d.jpg'", "%", "batch_idx", ")", ",", "\n", "padding", "=", "0", ",", "\n", "normalize", "=", "True", ")", "\n", "\n", "", "", "", "if", "saver", "is", "not", "None", "and", "args", ".", "recovery_interval", "and", "(", "\n", "last_batch", "or", "(", "batch_idx", "+", "1", ")", "%", "args", ".", "recovery_interval", "==", "0", ")", ":", "\n", "            ", "saver", ".", "save_recovery", "(", "epoch", ",", "batch_idx", "=", "batch_idx", ")", "\n", "\n", "", "if", "lr_scheduler", "is", "not", "None", ":", "\n", "            ", "lr_scheduler", ".", "step_update", "(", "num_updates", "=", "num_updates", ",", "metric", "=", "losses_m", ".", "avg", ")", "\n", "\n", "", "end", "=", "time", ".", "time", "(", ")", "\n", "# end for", "\n", "\n", "", "if", "hasattr", "(", "optimizer", ",", "'sync_lookahead'", ")", ":", "\n", "        ", "optimizer", ".", "sync_lookahead", "(", ")", "\n", "\n", "", "return", "OrderedDict", "(", "[", "(", "'loss'", ",", "losses_m", ".", "avg", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.None.train.validate": [[803, 865], ["AverageMeter", "AverageMeter", "AverageMeter", "AverageMeter", "model.eval", "time.time", "collections.OrderedDict", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "isinstance", "loss_fn", "accuracy", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "AverageMeter.update", "AverageMeter.update", "AverageMeter.update", "AverageMeter.update", "time.time", "input.contiguous.cuda", "target.cuda.cuda", "input.contiguous.contiguous", "amp_autocast", "model", "output.unfold().mean.unfold().mean", "reduce_tensor", "reduce_tensor", "reduce_tensor", "reduce_tensor.item", "input.contiguous.size", "reduce_tensor.item", "output.unfold().mean.size", "reduce_tensor.item", "output.unfold().mean.size", "_logger.info", "time.time", "output.unfold().mean.unfold", "target.cuda.size"], "function", ["None"], ["", "def", "validate", "(", "model", ",", "loader", ",", "loss_fn", ",", "args", ",", "amp_autocast", "=", "suppress", ",", "log_suffix", "=", "''", ")", ":", "\n", "    ", "batch_time_m", "=", "AverageMeter", "(", ")", "\n", "losses_m", "=", "AverageMeter", "(", ")", "\n", "top1_m", "=", "AverageMeter", "(", ")", "\n", "top5_m", "=", "AverageMeter", "(", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "last_idx", "=", "len", "(", "loader", ")", "-", "1", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch_idx", ",", "(", "input", ",", "target", ")", "in", "enumerate", "(", "loader", ")", ":", "\n", "            ", "last_batch", "=", "batch_idx", "==", "last_idx", "\n", "if", "not", "args", ".", "prefetcher", ":", "\n", "                ", "input", "=", "input", ".", "cuda", "(", ")", "\n", "target", "=", "target", ".", "cuda", "(", ")", "\n", "", "if", "args", ".", "channels_last", ":", "\n", "                ", "input", "=", "input", ".", "contiguous", "(", "memory_format", "=", "torch", ".", "channels_last", ")", "\n", "\n", "", "with", "amp_autocast", "(", ")", ":", "\n", "                ", "output", "=", "model", "(", "input", ")", "\n", "", "if", "isinstance", "(", "output", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "                ", "output", "=", "output", "[", "0", "]", "\n", "\n", "# augmentation reduction", "\n", "", "reduce_factor", "=", "args", ".", "tta", "\n", "if", "reduce_factor", ">", "1", ":", "\n", "                ", "output", "=", "output", ".", "unfold", "(", "0", ",", "reduce_factor", ",", "reduce_factor", ")", ".", "mean", "(", "dim", "=", "2", ")", "\n", "target", "=", "target", "[", "0", ":", "target", ".", "size", "(", "0", ")", ":", "reduce_factor", "]", "\n", "\n", "", "loss", "=", "loss_fn", "(", "output", ",", "target", ")", "\n", "acc1", ",", "acc5", "=", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "                ", "reduced_loss", "=", "reduce_tensor", "(", "loss", ".", "data", ",", "args", ".", "world_size", ")", "\n", "acc1", "=", "reduce_tensor", "(", "acc1", ",", "args", ".", "world_size", ")", "\n", "acc5", "=", "reduce_tensor", "(", "acc5", ",", "args", ".", "world_size", ")", "\n", "", "else", ":", "\n", "                ", "reduced_loss", "=", "loss", ".", "data", "\n", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "\n", "losses_m", ".", "update", "(", "reduced_loss", ".", "item", "(", ")", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "top1_m", ".", "update", "(", "acc1", ".", "item", "(", ")", ",", "output", ".", "size", "(", "0", ")", ")", "\n", "top5_m", ".", "update", "(", "acc5", ".", "item", "(", ")", ",", "output", ".", "size", "(", "0", ")", ")", "\n", "\n", "batch_time_m", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "if", "args", ".", "local_rank", "==", "0", "and", "(", "last_batch", "or", "batch_idx", "%", "args", ".", "log_interval", "==", "0", ")", ":", "\n", "                ", "log_name", "=", "'Test'", "+", "log_suffix", "\n", "_logger", ".", "info", "(", "\n", "'{0}: [{1:>4d}/{2}]  '", "\n", "'Time: {batch_time.val:.3f} ({batch_time.avg:.3f})  '", "\n", "'Loss: {loss.val:>7.4f} ({loss.avg:>6.4f})  '", "\n", "'Acc@1: {top1.val:>7.4f} ({top1.avg:>7.4f})  '", "\n", "'Acc@5: {top5.val:>7.4f} ({top5.avg:>7.4f})'", ".", "format", "(", "\n", "log_name", ",", "batch_idx", ",", "last_idx", ",", "batch_time", "=", "batch_time_m", ",", "\n", "loss", "=", "losses_m", ",", "top1", "=", "top1_m", ",", "top5", "=", "top5_m", ")", ")", "\n", "\n", "", "", "", "metrics", "=", "OrderedDict", "(", "[", "(", "'loss'", ",", "losses_m", ".", "avg", ")", ",", "(", "'top1'", ",", "top1_m", ".", "avg", ")", ",", "(", "'top5'", ",", "top5_m", ".", "avg", ")", "]", ")", "\n", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.extract_layer": [[16, 32], ["layer.split.split", "hasattr", "hasattr", "hasattr", "l.isdigit", "getattr", "int"], "function", ["None"], ["def", "extract_layer", "(", "model", ",", "layer", ")", ":", "\n", "    ", "layer", "=", "layer", ".", "split", "(", "'.'", ")", "\n", "module", "=", "model", "\n", "if", "hasattr", "(", "model", ",", "'module'", ")", "and", "layer", "[", "0", "]", "!=", "'module'", ":", "\n", "        ", "module", "=", "model", ".", "module", "\n", "", "if", "not", "hasattr", "(", "model", ",", "'module'", ")", "and", "layer", "[", "0", "]", "==", "'module'", ":", "\n", "        ", "layer", "=", "layer", "[", "1", ":", "]", "\n", "", "for", "l", "in", "layer", ":", "\n", "        ", "if", "hasattr", "(", "module", ",", "l", ")", ":", "\n", "            ", "if", "not", "l", ".", "isdigit", "(", ")", ":", "\n", "                ", "module", "=", "getattr", "(", "module", ",", "l", ")", "\n", "", "else", ":", "\n", "                ", "module", "=", "module", "[", "int", "(", "l", ")", "]", "\n", "", "", "else", ":", "\n", "            ", "return", "module", "\n", "", "", "return", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.set_layer": [[34, 56], ["layer.split.split", "setattr", "hasattr", "hasattr", "l.isdigit", "getattr", "l.isdigit", "getattr", "int", "int"], "function", ["None"], ["", "def", "set_layer", "(", "model", ",", "layer", ",", "val", ")", ":", "\n", "    ", "layer", "=", "layer", ".", "split", "(", "'.'", ")", "\n", "module", "=", "model", "\n", "if", "hasattr", "(", "model", ",", "'module'", ")", "and", "layer", "[", "0", "]", "!=", "'module'", ":", "\n", "        ", "module", "=", "model", ".", "module", "\n", "", "lst_index", "=", "0", "\n", "module2", "=", "module", "\n", "for", "l", "in", "layer", ":", "\n", "        ", "if", "hasattr", "(", "module2", ",", "l", ")", ":", "\n", "            ", "if", "not", "l", ".", "isdigit", "(", ")", ":", "\n", "                ", "module2", "=", "getattr", "(", "module2", ",", "l", ")", "\n", "", "else", ":", "\n", "                ", "module2", "=", "module2", "[", "int", "(", "l", ")", "]", "\n", "", "lst_index", "+=", "1", "\n", "", "", "lst_index", "-=", "1", "\n", "for", "l", "in", "layer", "[", ":", "lst_index", "]", ":", "\n", "        ", "if", "not", "l", ".", "isdigit", "(", ")", ":", "\n", "            ", "module", "=", "getattr", "(", "module", ",", "l", ")", "\n", "", "else", ":", "\n", "            ", "module", "=", "module", "[", "int", "(", "l", ")", "]", "\n", "", "", "l", "=", "layer", "[", "lst_index", "]", "\n", "setattr", "(", "module", ",", "l", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.fuse_bn_to_conv": [[59, 95], ["bn_layer.state_dict", "conv_layer.state_dict", "torch.sqrt", "torch.sqrt", "gamma.div", "A.expand_as().transpose.expand_as().transpose", "W.mul_", "torch.zeros().float().to.add_", "conv_layer.weight.data.copy_", "torch.zeros().float().to", "torch.zeros().float().to", "torch.zeros().float().to", "torch.zeros().float().to", "gamma.mul().div", "torch.nn.Parameter", "torch.nn.Parameter", "conv_layer.bias.data.copy_", "A.expand_as().transpose.expand_as", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "gamma.mul", "W.transpose", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "gamma.size", "W.size"], "function", ["None"], ["", "def", "fuse_bn_to_conv", "(", "bn_layer", ",", "conv_layer", ")", ":", "\n", "    ", "bn_st_dict", "=", "bn_layer", ".", "state_dict", "(", ")", "\n", "conv_st_dict", "=", "conv_layer", ".", "state_dict", "(", ")", "\n", "\n", "# BatchNorm params", "\n", "eps", "=", "bn_layer", ".", "eps", "\n", "mu", "=", "bn_st_dict", "[", "'running_mean'", "]", "\n", "var", "=", "bn_st_dict", "[", "'running_var'", "]", "\n", "gamma", "=", "bn_st_dict", "[", "'weight'", "]", "\n", "\n", "if", "'bias'", "in", "bn_st_dict", ":", "\n", "        ", "beta", "=", "bn_st_dict", "[", "'bias'", "]", "\n", "", "else", ":", "\n", "        ", "beta", "=", "torch", ".", "zeros", "(", "gamma", ".", "size", "(", "0", ")", ")", ".", "float", "(", ")", ".", "to", "(", "gamma", ".", "device", ")", "\n", "\n", "# Conv params", "\n", "", "W", "=", "conv_st_dict", "[", "'weight'", "]", "\n", "if", "'bias'", "in", "conv_st_dict", ":", "\n", "        ", "bias", "=", "conv_st_dict", "[", "'bias'", "]", "\n", "", "else", ":", "\n", "        ", "bias", "=", "torch", ".", "zeros", "(", "W", ".", "size", "(", "0", ")", ")", ".", "float", "(", ")", ".", "to", "(", "gamma", ".", "device", ")", "\n", "\n", "", "denom", "=", "torch", ".", "sqrt", "(", "var", "+", "eps", ")", "\n", "b", "=", "beta", "-", "gamma", ".", "mul", "(", "mu", ")", ".", "div", "(", "denom", ")", "\n", "A", "=", "gamma", ".", "div", "(", "denom", ")", "\n", "bias", "*=", "A", "\n", "A", "=", "A", ".", "expand_as", "(", "W", ".", "transpose", "(", "0", ",", "-", "1", ")", ")", ".", "transpose", "(", "0", ",", "-", "1", ")", "\n", "\n", "W", ".", "mul_", "(", "A", ")", "\n", "bias", ".", "add_", "(", "b", ")", "\n", "\n", "conv_layer", ".", "weight", ".", "data", ".", "copy_", "(", "W", ")", "\n", "if", "conv_layer", ".", "bias", "is", "None", ":", "\n", "        ", "conv_layer", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "bias", ")", "\n", "", "else", ":", "\n", "        ", "conv_layer", ".", "bias", ".", "data", ".", "copy_", "(", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.fuse_bn_to_linear": [[97, 134], ["bn_layer.state_dict", "linear_layer.state_dict", "torch.sqrt", "torch.sqrt", "gamma.div", "A.expand_as().transpose.expand_as().transpose", "W.mul_", "torch.zeros().float().to.add_", "linear_layer.weight.data.copy_", "torch.zeros().float().to", "torch.zeros().float().to", "torch.zeros().float().to", "torch.zeros().float().to", "gamma.mul().div", "torch.nn.Parameter", "torch.nn.Parameter", "linear_layer.bias.data.copy_", "A.expand_as().transpose.expand_as", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "gamma.mul", "W.transpose", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "gamma.size", "W.size"], "function", ["None"], ["", "", "def", "fuse_bn_to_linear", "(", "bn_layer", ",", "linear_layer", ")", ":", "\n", "# print('bn fuse')", "\n", "    ", "bn_st_dict", "=", "bn_layer", ".", "state_dict", "(", ")", "\n", "conv_st_dict", "=", "linear_layer", ".", "state_dict", "(", ")", "\n", "\n", "# BatchNorm params", "\n", "eps", "=", "bn_layer", ".", "eps", "\n", "mu", "=", "bn_st_dict", "[", "'running_mean'", "]", "\n", "var", "=", "bn_st_dict", "[", "'running_var'", "]", "\n", "gamma", "=", "bn_st_dict", "[", "'weight'", "]", "\n", "\n", "if", "'bias'", "in", "bn_st_dict", ":", "\n", "        ", "beta", "=", "bn_st_dict", "[", "'bias'", "]", "\n", "", "else", ":", "\n", "        ", "beta", "=", "torch", ".", "zeros", "(", "gamma", ".", "size", "(", "0", ")", ")", ".", "float", "(", ")", ".", "to", "(", "gamma", ".", "device", ")", "\n", "\n", "# Conv params", "\n", "", "W", "=", "conv_st_dict", "[", "'weight'", "]", "\n", "if", "'bias'", "in", "conv_st_dict", ":", "\n", "        ", "bias", "=", "conv_st_dict", "[", "'bias'", "]", "\n", "", "else", ":", "\n", "        ", "bias", "=", "torch", ".", "zeros", "(", "W", ".", "size", "(", "0", ")", ")", ".", "float", "(", ")", ".", "to", "(", "gamma", ".", "device", ")", "\n", "\n", "", "denom", "=", "torch", ".", "sqrt", "(", "var", "+", "eps", ")", "\n", "b", "=", "beta", "-", "gamma", ".", "mul", "(", "mu", ")", ".", "div", "(", "denom", ")", "\n", "A", "=", "gamma", ".", "div", "(", "denom", ")", "\n", "bias", "*=", "A", "\n", "A", "=", "A", ".", "expand_as", "(", "W", ".", "transpose", "(", "0", ",", "-", "1", ")", ")", ".", "transpose", "(", "0", ",", "-", "1", ")", "\n", "\n", "W", ".", "mul_", "(", "A", ")", "\n", "bias", ".", "add_", "(", "b", ")", "\n", "\n", "linear_layer", ".", "weight", ".", "data", ".", "copy_", "(", "W", ")", "\n", "if", "linear_layer", ".", "bias", "is", "None", ":", "\n", "        ", "linear_layer", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "bias", ")", "\n", "", "else", ":", "\n", "        ", "linear_layer", ".", "bias", ".", "data", ".", "copy_", "(", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.extract_layers": [[136, 141], ["model.named_modules", "list_layers.append"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules"], ["", "", "def", "extract_layers", "(", "model", ")", ":", "\n", "    ", "list_layers", "=", "[", "]", "\n", "for", "n", ",", "p", "in", "model", ".", "named_modules", "(", ")", ":", "\n", "        ", "list_layers", ".", "append", "(", "n", ")", "\n", "", "return", "list_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.compute_next_bn": [[143, 152], ["helpers.extract_layers", "extract_layers.index", "helpers.extract_layer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.extract_layers", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.extract_layer"], ["", "def", "compute_next_bn", "(", "layer_name", ",", "resnet", ")", ":", "\n", "    ", "list_layer", "=", "extract_layers", "(", "resnet", ")", "\n", "assert", "layer_name", "in", "list_layer", "\n", "if", "layer_name", "==", "list_layer", "[", "-", "1", "]", ":", "\n", "        ", "return", "None", "\n", "", "next_bn", "=", "list_layer", "[", "list_layer", ".", "index", "(", "layer_name", ")", "+", "1", "]", "\n", "if", "extract_layer", "(", "resnet", ",", "next_bn", ")", ".", "__class__", ".", "__name__", "==", "'BatchNorm2d'", ":", "\n", "        ", "return", "next_bn", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.compute_next_abn": [[154, 163], ["helpers.extract_layers", "extract_layers.index", "helpers.extract_layer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.extract_layers", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.extract_layer"], ["", "def", "compute_next_abn", "(", "layer_name", ",", "resnet", ")", ":", "\n", "    ", "list_layer", "=", "extract_layers", "(", "resnet", ")", "\n", "assert", "layer_name", "in", "list_layer", "\n", "if", "layer_name", "==", "list_layer", "[", "-", "1", "]", ":", "\n", "        ", "return", "None", "\n", "", "next_bn", "=", "list_layer", "[", "list_layer", ".", "index", "(", "layer_name", ")", "+", "1", "]", "\n", "if", "extract_layer", "(", "resnet", ",", "next_bn", ")", ".", "__class__", ".", "__name__", "==", "'ABN'", ":", "\n", "        ", "return", "next_bn", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.compute_next_bn_1d": [[165, 174], ["helpers.extract_layers", "extract_layers.index", "helpers.extract_layer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.extract_layers", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.extract_layer"], ["", "def", "compute_next_bn_1d", "(", "layer_name", ",", "resnet", ")", ":", "\n", "    ", "list_layer", "=", "extract_layers", "(", "resnet", ")", "\n", "assert", "layer_name", "in", "list_layer", "\n", "if", "layer_name", "==", "list_layer", "[", "-", "1", "]", ":", "\n", "        ", "return", "None", "\n", "", "next_bn", "=", "list_layer", "[", "list_layer", ".", "index", "(", "layer_name", ")", "+", "1", "]", "\n", "if", "extract_layer", "(", "resnet", ",", "next_bn", ")", ".", "__class__", ".", "__name__", "==", "'BatchNorm1d'", ":", "\n", "        ", "return", "next_bn", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.fuse_bn2d_bn1d_abn": [[176, 199], ["model.named_modules", "isinstance", "isinstance", "helpers.compute_next_bn", "helpers.compute_next_abn", "helpers.compute_next_bn_1d", "helpers.extract_layer", "helpers.fuse_bn_to_conv", "helpers.set_layer", "helpers.extract_layer", "helpers.calc_abn_activation", "helpers.fuse_bn_to_conv", "helpers.set_layer", "helpers.extract_layer", "helpers.fuse_bn_to_linear", "helpers.set_layer", "torch.Identity", "torch.Identity"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.compute_next_bn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.compute_next_abn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.compute_next_bn_1d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.extract_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.fuse_bn_to_conv", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.set_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.extract_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.calc_abn_activation", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.fuse_bn_to_conv", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.set_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.extract_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.fuse_bn_to_linear", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.set_layer"], ["", "def", "fuse_bn2d_bn1d_abn", "(", "model", ")", ":", "\n", "    ", "for", "n", ",", "m", "in", "model", ".", "named_modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "next_bn", "=", "compute_next_bn", "(", "n", ",", "model", ")", "\n", "if", "next_bn", "is", "not", "None", ":", "\n", "                ", "next_bn_", "=", "extract_layer", "(", "model", ",", "next_bn", ")", "\n", "fuse_bn_to_conv", "(", "next_bn_", ",", "m", ")", "\n", "set_layer", "(", "model", ",", "next_bn", ",", "nn", ".", "Identity", "(", ")", ")", "\n", "\n", "", "next_abn", "=", "compute_next_abn", "(", "n", ",", "model", ")", "\n", "if", "next_abn", "is", "not", "None", ":", "\n", "                ", "next_bn_", "=", "extract_layer", "(", "model", ",", "next_abn", ")", "\n", "activation", "=", "calc_abn_activation", "(", "next_bn_", ")", "\n", "fuse_bn_to_conv", "(", "next_bn_", ",", "m", ")", "\n", "set_layer", "(", "model", ",", "next_abn", ",", "activation", ")", "\n", "", "", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "Linear", ")", ":", "\n", "            ", "next_bn1d", "=", "compute_next_bn_1d", "(", "n", ",", "model", ")", "\n", "if", "next_bn1d", "is", "not", "None", ":", "\n", "                ", "next_bn1d_", "=", "extract_layer", "(", "model", ",", "next_bn1d", ")", "\n", "fuse_bn_to_linear", "(", "next_bn1d_", ",", "m", ")", "\n", "set_layer", "(", "model", ",", "next_bn1d", ",", "nn", ".", "Identity", "(", ")", ")", "\n", "\n", "", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.calc_abn_activation": [[200, 211], ["torch.Identity", "isinstance", "torch.ReLU", "torch.LeakyReLU", "torch.ELU"], "function", ["None"], ["", "def", "calc_abn_activation", "(", "ABN_layer", ")", ":", "\n", "    ", "from", "inplace_abn", "import", "ABN", "\n", "activation", "=", "nn", ".", "Identity", "(", ")", "\n", "if", "isinstance", "(", "ABN_layer", ",", "ABN", ")", ":", "\n", "        ", "if", "ABN_layer", ".", "activation", "==", "\"relu\"", ":", "\n", "            ", "activation", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "", "elif", "ABN_layer", ".", "activation", "==", "\"leaky_relu\"", ":", "\n", "            ", "activation", "=", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "ABN_layer", ".", "activation_param", ",", "inplace", "=", "True", ")", "\n", "", "elif", "ABN_layer", ".", "activation", "==", "\"elu\"", ":", "\n", "            ", "activation", "=", "nn", ".", "ELU", "(", "alpha", "=", "ABN_layer", ".", "activation_param", ",", "inplace", "=", "True", ")", "\n", "", "", "return", "activation", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.InplacABN_to_ABN": [[212, 229], ["isinstance", "reversed", "ABN", "module.state_dict", "module._modules.items", "helpers.InplacABN_to_ABN", "[].copy_", "ABN.weight.abs", "module.state_dict", "ABN.state_dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.InplacABN_to_ABN"], ["", "def", "InplacABN_to_ABN", "(", "module", ":", "nn", ".", "Module", ")", "->", "nn", ".", "Module", ":", "\n", "    ", "from", "models", ".", "layers", "import", "InplaceAbn", "\n", "from", "inplace_abn", "import", "ABN", "\n", "# convert all InplaceABN layer to bit-accurate ABN layers.", "\n", "if", "isinstance", "(", "module", ",", "InplaceAbn", ")", ":", "\n", "        ", "module_new", "=", "ABN", "(", "module", ".", "num_features", ",", "activation", "=", "module", ".", "act_name", ",", "\n", "activation_param", "=", "module", ".", "act_param", ")", "\n", "for", "key", "in", "module", ".", "state_dict", "(", ")", ":", "\n", "            ", "module_new", ".", "state_dict", "(", ")", "[", "key", "]", ".", "copy_", "(", "module", ".", "state_dict", "(", ")", "[", "key", "]", ")", "\n", "", "module_new", ".", "training", "=", "module", ".", "training", "\n", "module_new", ".", "weight", ".", "data", "=", "module_new", ".", "weight", ".", "abs", "(", ")", "+", "module_new", ".", "eps", "\n", "return", "module_new", "\n", "", "for", "name", ",", "child", "in", "reversed", "(", "module", ".", "_modules", ".", "items", "(", ")", ")", ":", "\n", "        ", "new_child", "=", "InplacABN_to_ABN", "(", "child", ")", "\n", "if", "new_child", "!=", "child", ":", "\n", "            ", "module", ".", "_modules", "[", "name", "]", "=", "new_child", "\n", "", "", "return", "module", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.kd_utils.build_kd_model.__init__": [[8, 25], ["torch.Module.__init__", "models.factory.create_model", "kd.helpers.fuse_bn2d_bn1d_abn.cpu().eval", "kd.helpers.InplacABN_to_ABN", "kd.helpers.fuse_bn2d_bn1d_abn", "kd.helpers.fuse_bn2d_bn1d_abn.cuda().eval", "kd.helpers.fuse_bn2d_bn1d_abn.cpu", "kd.helpers.fuse_bn2d_bn1d_abn.cuda"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.factory.create_model", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.InplacABN_to_ABN", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.helpers.fuse_bn2d_bn1d_abn"], ["    ", "def", "__init__", "(", "self", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", "build_kd_model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "model_kd", "=", "create_model", "(", "\n", "model_name", "=", "args", ".", "kd_model_name", ",", "\n", "checkpoint_path", "=", "args", ".", "kd_model_path", ",", "\n", "# pretrained=False,", "\n", "pretrained", "=", "args", ".", "kd_model_path", "is", "None", ",", "\n", "num_classes", "=", "args", ".", "num_classes", ",", "\n", "in_chans", "=", "3", ")", "\n", "\n", "model_kd", ".", "cpu", "(", ")", ".", "eval", "(", ")", "\n", "model_kd", "=", "InplacABN_to_ABN", "(", "model_kd", ")", "\n", "model_kd", "=", "fuse_bn2d_bn1d_abn", "(", "model_kd", ")", "\n", "self", ".", "model", "=", "model_kd", ".", "cuda", "(", ")", ".", "eval", "(", ")", "\n", "self", ".", "mean_model_kd", "=", "model_kd", ".", "default_cfg", "[", "'mean'", "]", "\n", "self", ".", "std_model_kd", "=", "model_kd", ".", "default_cfg", "[", "'std'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.kd.kd_utils.build_kd_model.normalize_input": [[27, 49], ["hasattr", "torchvision.Normalize", "torchvision.Normalize", "torchvision.Normalize.", "torchvision.Normalize."], "methods", ["None"], ["", "def", "normalize_input", "(", "self", ",", "input", ",", "student_model", ")", ":", "\n", "        ", "if", "hasattr", "(", "student_model", ",", "'module'", ")", ":", "\n", "            ", "model_s", "=", "student_model", ".", "module", "\n", "", "else", ":", "\n", "            ", "model_s", "=", "student_model", "\n", "\n", "", "mean_student", "=", "model_s", ".", "default_cfg", "[", "'mean'", "]", "\n", "std_student", "=", "model_s", ".", "default_cfg", "[", "'std'", "]", "\n", "\n", "input_kd", "=", "input", "\n", "if", "mean_student", "!=", "self", ".", "mean_model_kd", "or", "std_student", "!=", "self", ".", "std_model_kd", ":", "\n", "            ", "std", "=", "(", "self", ".", "std_model_kd", "[", "0", "]", "/", "std_student", "[", "0", "]", ",", "self", ".", "std_model_kd", "[", "1", "]", "/", "std_student", "[", "1", "]", ",", "\n", "self", ".", "std_model_kd", "[", "2", "]", "/", "std_student", "[", "2", "]", ")", "\n", "transform_std", "=", "T", ".", "Normalize", "(", "mean", "=", "(", "0", ",", "0", ",", "0", ")", ",", "std", "=", "std", ")", "\n", "\n", "mean", "=", "(", "self", ".", "mean_model_kd", "[", "0", "]", "-", "mean_student", "[", "0", "]", ",", "self", ".", "mean_model_kd", "[", "1", "]", "-", "mean_student", "[", "1", "]", ",", "\n", "self", ".", "mean_model_kd", "[", "2", "]", "-", "mean_student", "[", "2", "]", ")", "\n", "transform_mean", "=", "T", ".", "Normalize", "(", "mean", "=", "mean", ",", "std", "=", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "\n", "input_kd", "=", "transform_mean", "(", "transform_std", "(", "input", ")", ")", "\n", "\n", "", "return", "input_kd", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.utils.checkpoint_saver.CheckpointSaverUSI.__init__": [[21, 61], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "optimizer", ",", "\n", "args", "=", "None", ",", "\n", "model_ema", "=", "None", ",", "\n", "amp_scaler", "=", "None", ",", "\n", "checkpoint_prefix", "=", "'checkpoint'", ",", "\n", "recovery_prefix", "=", "'recovery'", ",", "\n", "checkpoint_dir", "=", "''", ",", "\n", "recovery_dir", "=", "''", ",", "\n", "decreasing", "=", "False", ",", "\n", "max_history", "=", "10", ",", "\n", "unwrap_fn", "=", "unwrap_model", ")", ":", "\n", "\n", "# objects to save state_dicts of", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "model_ema", "=", "model_ema", "\n", "self", ".", "amp_scaler", "=", "amp_scaler", "\n", "\n", "# state", "\n", "self", ".", "checkpoint_files", "=", "[", "]", "# (filename, metric) tuples in order of decreasing betterness", "\n", "self", ".", "best_epoch", "=", "None", "\n", "self", ".", "best_metric", "=", "None", "\n", "self", ".", "curr_recovery_file", "=", "''", "\n", "self", ".", "last_recovery_file", "=", "''", "\n", "\n", "# config", "\n", "self", ".", "checkpoint_dir", "=", "checkpoint_dir", "\n", "self", ".", "recovery_dir", "=", "recovery_dir", "\n", "self", ".", "save_prefix", "=", "checkpoint_prefix", "\n", "self", ".", "recovery_prefix", "=", "recovery_prefix", "\n", "self", ".", "extension", "=", "'.pth.tar'", "\n", "self", ".", "decreasing", "=", "decreasing", "# a lower metric is better if True", "\n", "self", ".", "cmp", "=", "operator", ".", "lt", "if", "decreasing", "else", "operator", ".", "gt", "# True if lhs better than rhs", "\n", "self", ".", "max_history", "=", "max_history", "\n", "self", ".", "unwrap_fn", "=", "unwrap_fn", "\n", "assert", "self", ".", "max_history", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.utils.checkpoint_saver.CheckpointSaverUSI.save_checkpoint": [[62, 97], ["os.path.join", "os.path.join", "checkpoint_saver.CheckpointSaverUSI._save", "os.path.exists", "os.rename", "os.unlink", "checkpoint_saver.CheckpointSaverUSI.cmp", "os.path.join", "os.link", "checkpoint_saver.CheckpointSaverUSI.checkpoint_files.append", "sorted", "_logger.info", "len", "len", "checkpoint_saver.CheckpointSaverUSI._cleanup_checkpoints", "os.path.join", "os.path.exists", "os.link", "checkpoint_saver.CheckpointSaverUSI.cmp", "os.unlink", "str"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.utils.checkpoint_saver.CheckpointSaverUSI._save", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.utils.checkpoint_saver.CheckpointSaverUSI._cleanup_checkpoints"], ["", "def", "save_checkpoint", "(", "self", ",", "epoch", ",", "metric", "=", "None", ",", "metric_ema", "=", "None", ")", ":", "\n", "        ", "assert", "epoch", ">=", "0", "\n", "tmp_save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoint_dir", ",", "'tmp'", "+", "self", ".", "extension", ")", "\n", "last_save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoint_dir", ",", "'last'", "+", "self", ".", "extension", ")", "\n", "self", ".", "_save", "(", "tmp_save_path", ",", "epoch", ",", "metric", ",", "metric_ema", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "last_save_path", ")", ":", "\n", "            ", "os", ".", "unlink", "(", "last_save_path", ")", "# required for Windows support.", "\n", "", "os", ".", "rename", "(", "tmp_save_path", ",", "last_save_path", ")", "\n", "worst_file", "=", "self", ".", "checkpoint_files", "[", "-", "1", "]", "if", "self", ".", "checkpoint_files", "else", "None", "\n", "if", "(", "len", "(", "self", ".", "checkpoint_files", ")", "<", "self", ".", "max_history", "\n", "or", "metric", "is", "None", "or", "self", ".", "cmp", "(", "metric", ",", "worst_file", "[", "1", "]", ")", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "checkpoint_files", ")", ">=", "self", ".", "max_history", ":", "\n", "                ", "self", ".", "_cleanup_checkpoints", "(", "1", ")", "\n", "", "filename", "=", "'-'", ".", "join", "(", "[", "self", ".", "save_prefix", ",", "str", "(", "epoch", ")", "]", ")", "+", "self", ".", "extension", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoint_dir", ",", "filename", ")", "\n", "os", ".", "link", "(", "last_save_path", ",", "save_path", ")", "\n", "self", ".", "checkpoint_files", ".", "append", "(", "(", "save_path", ",", "metric", ")", ")", "\n", "self", ".", "checkpoint_files", "=", "sorted", "(", "\n", "self", ".", "checkpoint_files", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "\n", "reverse", "=", "not", "self", ".", "decreasing", ")", "# sort in descending order if a lower metric is not better", "\n", "\n", "checkpoints_str", "=", "\"Current checkpoints:\\n\"", "\n", "for", "c", "in", "self", ".", "checkpoint_files", ":", "\n", "                ", "checkpoints_str", "+=", "' {}\\n'", ".", "format", "(", "c", ")", "\n", "", "_logger", ".", "info", "(", "checkpoints_str", ")", "\n", "\n", "if", "metric", "is", "not", "None", "and", "(", "self", ".", "best_metric", "is", "None", "or", "self", ".", "cmp", "(", "metric", ",", "self", ".", "best_metric", ")", ")", ":", "\n", "                ", "self", ".", "best_epoch", "=", "epoch", "\n", "self", ".", "best_metric", "=", "metric", "\n", "best_save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoint_dir", ",", "'model_best'", "+", "self", ".", "extension", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "best_save_path", ")", ":", "\n", "                    ", "os", ".", "unlink", "(", "best_save_path", ")", "\n", "", "os", ".", "link", "(", "last_save_path", ",", "best_save_path", ")", "\n", "\n", "", "", "return", "(", "None", ",", "None", ")", "if", "self", ".", "best_metric", "is", "None", "else", "(", "self", ".", "best_metric", ",", "self", ".", "best_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.utils.checkpoint_saver.CheckpointSaverUSI._save": [[98, 118], ["torch.save", "type().__name__.lower", "timm.utils.model.get_state_dict", "timm.utils.model.get_state_dict", "type"], "methods", ["None"], ["", "def", "_save", "(", "self", ",", "save_path", ",", "epoch", ",", "metric", "=", "None", ",", "metric_ema", "=", "None", ")", ":", "\n", "        ", "save_state", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'arch'", ":", "type", "(", "self", ".", "model", ")", ".", "__name__", ".", "lower", "(", ")", ",", "\n", "'state_dict'", ":", "get_state_dict", "(", "self", ".", "model", ",", "self", ".", "unwrap_fn", ")", ",", "\n", "# 'optimizer': self.optimizer.state_dict(),", "\n", "'version'", ":", "2", ",", "# version < 2 increments epoch before save", "\n", "}", "\n", "if", "self", ".", "args", "is", "not", "None", ":", "\n", "            ", "save_state", "[", "'arch'", "]", "=", "self", ".", "args", ".", "model", "\n", "save_state", "[", "'args'", "]", "=", "self", ".", "args", "\n", "# if self.amp_scaler is not None:", "\n", "#     save_state[self.amp_scaler.state_dict_key] = self.amp_scaler.state_dict()", "\n", "", "if", "self", ".", "model_ema", "is", "not", "None", ":", "\n", "            ", "if", "metric_ema", ">", "metric", ":", "# save EMA weights instead of regular weights", "\n", "                ", "save_state", "[", "'state_dict'", "]", "=", "get_state_dict", "(", "self", ".", "model_ema", ",", "self", ".", "unwrap_fn", ")", "\n", "# save_state['state_dict_ema'] = get_state_dict(self.model_ema, self.unwrap_fn)", "\n", "", "", "if", "metric", "is", "not", "None", ":", "\n", "            ", "save_state", "[", "'metric'", "]", "=", "metric", "\n", "", "torch", ".", "save", "(", "save_state", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.utils.checkpoint_saver.CheckpointSaverUSI._cleanup_checkpoints": [[119, 132], ["min", "len", "len", "_logger.debug", "os.remove", "_logger.error"], "methods", ["None"], ["", "def", "_cleanup_checkpoints", "(", "self", ",", "trim", "=", "0", ")", ":", "\n", "        ", "trim", "=", "min", "(", "len", "(", "self", ".", "checkpoint_files", ")", ",", "trim", ")", "\n", "delete_index", "=", "self", ".", "max_history", "-", "trim", "\n", "if", "delete_index", "<", "0", "or", "len", "(", "self", ".", "checkpoint_files", ")", "<=", "delete_index", ":", "\n", "            ", "return", "\n", "", "to_delete", "=", "self", ".", "checkpoint_files", "[", "delete_index", ":", "]", "\n", "for", "d", "in", "to_delete", ":", "\n", "            ", "try", ":", "\n", "                ", "_logger", ".", "debug", "(", "\"Cleaning checkpoint: {}\"", ".", "format", "(", "d", ")", ")", "\n", "os", ".", "remove", "(", "d", "[", "0", "]", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "_logger", ".", "error", "(", "\"Exception '{}' while deleting checkpoint\"", ".", "format", "(", "e", ")", ")", "\n", "", "", "self", ".", "checkpoint_files", "=", "self", ".", "checkpoint_files", "[", ":", "delete_index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.utils.checkpoint_saver.CheckpointSaverUSI.save_recovery": [[133, 146], ["os.path.join", "checkpoint_saver.CheckpointSaverUSI._save", "os.path.exists", "_logger.debug", "os.remove", "str", "str", "_logger.error"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.utils.checkpoint_saver.CheckpointSaverUSI._save"], ["", "def", "save_recovery", "(", "self", ",", "epoch", ",", "batch_idx", "=", "0", ")", ":", "\n", "        ", "assert", "epoch", ">=", "0", "\n", "filename", "=", "'-'", ".", "join", "(", "[", "self", ".", "recovery_prefix", ",", "str", "(", "epoch", ")", ",", "str", "(", "batch_idx", ")", "]", ")", "+", "self", ".", "extension", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "recovery_dir", ",", "filename", ")", "\n", "self", ".", "_save", "(", "save_path", ",", "epoch", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "last_recovery_file", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "_logger", ".", "debug", "(", "\"Cleaning recovery: {}\"", ".", "format", "(", "self", ".", "last_recovery_file", ")", ")", "\n", "os", ".", "remove", "(", "self", ".", "last_recovery_file", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "_logger", ".", "error", "(", "\"Exception '{}' while removing {}\"", ".", "format", "(", "e", ",", "self", ".", "last_recovery_file", ")", ")", "\n", "", "", "self", ".", "last_recovery_file", "=", "self", ".", "curr_recovery_file", "\n", "self", ".", "curr_recovery_file", "=", "save_path", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.utils.checkpoint_saver.CheckpointSaverUSI.find_recovery": [[147, 152], ["os.path.join", "glob.glob", "sorted", "len"], "methods", ["None"], ["", "def", "find_recovery", "(", "self", ")", ":", "\n", "        ", "recovery_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "recovery_dir", ",", "self", ".", "recovery_prefix", ")", "\n", "files", "=", "glob", ".", "glob", "(", "recovery_path", "+", "'*'", "+", "self", ".", "extension", ")", "\n", "files", "=", "sorted", "(", "files", ")", "\n", "return", "files", "[", "0", "]", "if", "len", "(", "files", ")", "else", "''", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.GPSA.__init__": [[64, 82], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "qkv_bias", "=", "False", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ",", "locality_strength", "=", "1.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dim", "=", "dim", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "self", ".", "scale", "=", "head_dim", "**", "-", "0.5", "\n", "self", ".", "locality_strength", "=", "locality_strength", "\n", "\n", "self", ".", "qk", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", "*", "2", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "qkv_bias", ")", "\n", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "pos_proj", "=", "nn", ".", "Linear", "(", "3", ",", "num_heads", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "self", ".", "gating_param", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "self", ".", "num_heads", ")", ")", "\n", "self", ".", "rel_indices", ":", "torch", ".", "Tensor", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "1", ",", "3", ")", "# silly torchscript hack, won't work with None", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.GPSA.forward": [[83, 93], ["convit.GPSA.get_attention", "convit.GPSA.v().reshape().permute", "convit.GPSA.proj", "convit.GPSA.proj_drop", "convit.GPSA.get_rel_indices", "convit.GPSA.v().reshape", "convit.GPSA.v"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.GPSA.get_attention", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.GPSA.get_rel_indices"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "if", "self", ".", "rel_indices", "is", "None", "or", "self", ".", "rel_indices", ".", "shape", "[", "1", "]", "!=", "N", ":", "\n", "            ", "self", ".", "rel_indices", "=", "self", ".", "get_rel_indices", "(", "N", ")", "\n", "", "attn", "=", "self", ".", "get_attention", "(", "x", ")", "\n", "v", "=", "self", ".", "v", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "N", ",", "C", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.GPSA.get_attention": [[94, 109], ["convit.GPSA.qk().reshape().permute", "convit.GPSA.rel_indices.expand", "convit.GPSA.pos_proj().permute", "patch_score.softmax.softmax.softmax", "pos_score.softmax.softmax.softmax", "convit.GPSA.gating_param.view", "convit.GPSA.sum().unsqueeze", "convit.GPSA.attn_drop", "convit.GPSA.qk().reshape", "convit.GPSA.pos_proj", "k.transpose", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "convit.GPSA.sum", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "convit.GPSA.qk"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid"], ["", "def", "get_attention", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "qk", "=", "self", ".", "qk", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "2", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", "=", "qk", "[", "0", "]", ",", "qk", "[", "1", "]", "\n", "pos_score", "=", "self", ".", "rel_indices", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "pos_score", "=", "self", ".", "pos_proj", "(", "pos_score", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "patch_score", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "*", "self", ".", "scale", "\n", "patch_score", "=", "patch_score", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "pos_score", "=", "pos_score", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "gating", "=", "self", ".", "gating_param", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "attn", "=", "(", "1.", "-", "torch", ".", "sigmoid", "(", "gating", ")", ")", "*", "patch_score", "+", "torch", ".", "sigmoid", "(", "gating", ")", "*", "pos_score", "\n", "attn", "/=", "attn", ".", "sum", "(", "dim", "=", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "return", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.GPSA.get_attention_map": [[110, 118], ["convit.GPSA.get_attention().mean", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "distances.size", "convit.GPSA.get_attention", "convit.GPSA.rel_indices.squeeze"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.GPSA.get_attention"], ["", "def", "get_attention_map", "(", "self", ",", "x", ",", "return_map", "=", "False", ")", ":", "\n", "        ", "attn_map", "=", "self", ".", "get_attention", "(", "x", ")", ".", "mean", "(", "0", ")", "# average over batch", "\n", "distances", "=", "self", ".", "rel_indices", ".", "squeeze", "(", ")", "[", ":", ",", ":", ",", "-", "1", "]", "**", ".5", "\n", "dist", "=", "torch", ".", "einsum", "(", "'nm,hnm->h'", ",", "(", "distances", ",", "attn_map", ")", ")", "/", "distances", ".", "size", "(", "0", ")", "\n", "if", "return_map", ":", "\n", "            ", "return", "dist", ",", "attn_map", "\n", "", "else", ":", "\n", "            ", "return", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.GPSA.local_init": [[119, 132], ["convit.GPSA.v.weight.data.copy_", "int", "range", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "range"], "methods", ["None"], ["", "", "def", "local_init", "(", "self", ")", ":", "\n", "        ", "self", ".", "v", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "eye", "(", "self", ".", "dim", ")", ")", "\n", "locality_distance", "=", "1", "# max(1,1/locality_strength**.5)", "\n", "\n", "kernel_size", "=", "int", "(", "self", ".", "num_heads", "**", ".5", ")", "\n", "center", "=", "(", "kernel_size", "-", "1", ")", "/", "2", "if", "kernel_size", "%", "2", "==", "0", "else", "kernel_size", "//", "2", "\n", "for", "h1", "in", "range", "(", "kernel_size", ")", ":", "\n", "            ", "for", "h2", "in", "range", "(", "kernel_size", ")", ":", "\n", "                ", "position", "=", "h1", "+", "kernel_size", "*", "h2", "\n", "self", ".", "pos_proj", ".", "weight", ".", "data", "[", "position", ",", "2", "]", "=", "-", "1", "\n", "self", ".", "pos_proj", ".", "weight", ".", "data", "[", "position", ",", "1", "]", "=", "2", "*", "(", "h1", "-", "center", ")", "*", "locality_distance", "\n", "self", ".", "pos_proj", ".", "weight", ".", "data", "[", "position", ",", "0", "]", "=", "2", "*", "(", "h2", "-", "center", ")", "*", "locality_distance", "\n", "", "", "self", ".", "pos_proj", ".", "weight", ".", "data", "*=", "self", ".", "locality_strength", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.GPSA.get_rel_indices": [[133, 145], ["int", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "ind.repeat", "ind.repeat_interleave().repeat_interleave", "indd.unsqueeze", "ind.repeat_interleave().repeat_interleave.unsqueeze", "ind.repeat.unsqueeze", "torch.zeros.to", "torch.zeros.to", "torch.zeros.to", "torch.zeros.to", "torch.zeros.to", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "ind.repeat_interleave", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["None"], ["", "def", "get_rel_indices", "(", "self", ",", "num_patches", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "img_size", "=", "int", "(", "num_patches", "**", ".5", ")", "\n", "rel_indices", "=", "torch", ".", "zeros", "(", "1", ",", "num_patches", ",", "num_patches", ",", "3", ")", "\n", "ind", "=", "torch", ".", "arange", "(", "img_size", ")", ".", "view", "(", "1", ",", "-", "1", ")", "-", "torch", ".", "arange", "(", "img_size", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "indx", "=", "ind", ".", "repeat", "(", "img_size", ",", "img_size", ")", "\n", "indy", "=", "ind", ".", "repeat_interleave", "(", "img_size", ",", "dim", "=", "0", ")", ".", "repeat_interleave", "(", "img_size", ",", "dim", "=", "1", ")", "\n", "indd", "=", "indx", "**", "2", "+", "indy", "**", "2", "\n", "rel_indices", "[", ":", ",", ":", ",", ":", ",", "2", "]", "=", "indd", ".", "unsqueeze", "(", "0", ")", "\n", "rel_indices", "[", ":", ",", ":", ",", ":", ",", "1", "]", "=", "indy", ".", "unsqueeze", "(", "0", ")", "\n", "rel_indices", "[", ":", ",", ":", ",", ":", ",", "0", "]", "=", "indx", ".", "unsqueeze", "(", "0", ")", "\n", "device", "=", "self", ".", "qk", ".", "weight", ".", "device", "\n", "return", "rel_indices", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.MHSA.__init__": [[148, 158], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "qkv_bias", "=", "False", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "self", ".", "scale", "=", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", "*", "3", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.MHSA.get_attention_map": [[159, 179], ["convit.MHSA.qkv().reshape().permute", "attn_map.softmax().mean.softmax().mean.softmax().mean", "int", "ind.repeat", "ind.repeat_interleave().repeat_interleave", "distances.to.to.to", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "convit.MHSA.qkv().reshape", "k.transpose", "attn_map.softmax().mean.softmax().mean.softmax", "ind.repeat_interleave", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "convit.MHSA.qkv"], "methods", ["None"], ["", "def", "get_attention_map", "(", "self", ",", "x", ",", "return_map", "=", "False", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "3", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", "[", "0", "]", ",", "qkv", "[", "1", "]", ",", "qkv", "[", "2", "]", "\n", "attn_map", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "*", "self", ".", "scale", "\n", "attn_map", "=", "attn_map", ".", "softmax", "(", "dim", "=", "-", "1", ")", ".", "mean", "(", "0", ")", "\n", "\n", "img_size", "=", "int", "(", "N", "**", ".5", ")", "\n", "ind", "=", "torch", ".", "arange", "(", "img_size", ")", ".", "view", "(", "1", ",", "-", "1", ")", "-", "torch", ".", "arange", "(", "img_size", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "indx", "=", "ind", ".", "repeat", "(", "img_size", ",", "img_size", ")", "\n", "indy", "=", "ind", ".", "repeat_interleave", "(", "img_size", ",", "dim", "=", "0", ")", ".", "repeat_interleave", "(", "img_size", ",", "dim", "=", "1", ")", "\n", "indd", "=", "indx", "**", "2", "+", "indy", "**", "2", "\n", "distances", "=", "indd", "**", ".5", "\n", "distances", "=", "distances", ".", "to", "(", "x", ".", "device", ")", "\n", "\n", "dist", "=", "torch", ".", "einsum", "(", "'nm,hnm->h'", ",", "(", "distances", ",", "attn_map", ")", ")", "/", "N", "\n", "if", "return_map", ":", "\n", "            ", "return", "dist", ",", "attn_map", "\n", "", "else", ":", "\n", "            ", "return", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.MHSA.forward": [[180, 193], ["convit.MHSA.qkv().reshape().permute", "convit.MHSA.unbind", "convit.MHSA.softmax", "convit.MHSA.attn_drop", "convit.MHSA.proj", "convit.MHSA.proj_drop", "convit.MHSA.qkv().reshape", "k.transpose", "convit.MHSA.qkv"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "3", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", ".", "unbind", "(", "0", ")", "\n", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "*", "self", ".", "scale", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "N", ",", "C", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.Block.__init__": [[197, 212], ["torch.Module.__init__", "norm_layer", "norm_layer", "int", "layers.Mlp", "convit.GPSA", "convit.MHSA", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dim", ",", "num_heads", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "\n", "drop_path", "=", "0.", ",", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "use_gpsa", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "use_gpsa", "=", "use_gpsa", "\n", "if", "self", ".", "use_gpsa", ":", "\n", "            ", "self", ".", "attn", "=", "GPSA", "(", "\n", "dim", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "attn", "=", "MHSA", "(", "dim", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ")", "\n", "", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "mlp_hidden_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "in_features", "=", "dim", ",", "hidden_features", "=", "mlp_hidden_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.Block.forward": [[213, 217], ["convit.Block.drop_path", "convit.Block.drop_path", "convit.Block.attn", "convit.Block.mlp", "convit.Block.norm1", "convit.Block.norm2"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "attn", "(", "self", ".", "norm1", "(", "x", ")", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.ConViT.__init__": [[223, 278], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "norm_layer", "layers.trunc_normal_", "convit.ConViT.apply", "convit.ConViT.named_modules", "vision_transformer_hybrid.HybridEmbed", "layers.PatchEmbed", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "layers.trunc_normal_", "x.item", "dict", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "hasattr", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "m.local_init", "convit.Block", "convit.Block", "range"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.GPSA.local_init"], ["def", "__init__", "(", "\n", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "global_pool", "=", "'token'", ",", "\n", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.", ",", "hybrid_backbone", "=", "None", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "\n", "local_up_to_layer", "=", "3", ",", "locality_strength", "=", "1.", ",", "use_pos_embed", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "global_pool", "in", "(", "''", ",", "'avg'", ",", "'token'", ")", "\n", "embed_dim", "*=", "num_heads", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "self", ".", "local_up_to_layer", "=", "local_up_to_layer", "\n", "self", ".", "num_features", "=", "self", ".", "embed_dim", "=", "embed_dim", "# num_features for consistency with other models", "\n", "self", ".", "locality_strength", "=", "locality_strength", "\n", "self", ".", "use_pos_embed", "=", "use_pos_embed", "\n", "\n", "if", "hybrid_backbone", "is", "not", "None", ":", "\n", "            ", "self", ".", "patch_embed", "=", "HybridEmbed", "(", "\n", "hybrid_backbone", ",", "img_size", "=", "img_size", ",", "in_chans", "=", "in_chans", ",", "embed_dim", "=", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "patch_embed", "=", "PatchEmbed", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "embed_dim", "=", "embed_dim", ")", "\n", "", "num_patches", "=", "self", ".", "patch_embed", ".", "num_patches", "\n", "self", ".", "num_patches", "=", "num_patches", "\n", "\n", "self", ".", "cls_token", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "self", ".", "pos_drop", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", "\n", "\n", "if", "self", ".", "use_pos_embed", ":", "\n", "            ", "self", ".", "pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "num_patches", ",", "embed_dim", ")", ")", "\n", "trunc_normal_", "(", "self", ".", "pos_embed", ",", "std", "=", ".02", ")", "\n", "\n", "", "dpr", "=", "[", "x", ".", "item", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "depth", ")", "]", "# stochastic depth decay rule", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "[", "\n", "Block", "(", "\n", "dim", "=", "embed_dim", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", "[", "i", "]", ",", "norm_layer", "=", "norm_layer", ",", "\n", "use_gpsa", "=", "True", ",", "\n", "locality_strength", "=", "locality_strength", ")", "\n", "if", "i", "<", "local_up_to_layer", "else", "\n", "Block", "(", "\n", "dim", "=", "embed_dim", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", "[", "i", "]", ",", "norm_layer", "=", "norm_layer", ",", "\n", "use_gpsa", "=", "False", ")", "\n", "for", "i", "in", "range", "(", "depth", ")", "]", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "\n", "\n", "# Classifier head", "\n", "self", ".", "feature_info", "=", "[", "dict", "(", "num_chs", "=", "embed_dim", ",", "reduction", "=", "0", ",", "module", "=", "'head'", ")", "]", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "trunc_normal_", "(", "self", ".", "cls_token", ",", "std", "=", ".02", ")", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "for", "n", ",", "m", "in", "self", ".", "named_modules", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'local_init'", ")", ":", "\n", "                ", "m", ".", "local_init", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.ConViT._init_weights": [[279, 287], ["isinstance", "layers.trunc_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "", "", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", ".02", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.ConViT.no_weight_decay": [[288, 291], ["None"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "{", "'pos_embed'", ",", "'cls_token'", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.ConViT.group_matcher": [[292, 297], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^cls_token|pos_embed|patch_embed'", ",", "# stem and embed", "\n", "blocks", "=", "[", "(", "r'^blocks\\.(\\d+)'", ",", "None", ")", ",", "(", "r'^norm'", ",", "(", "99999", ",", ")", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.ConViT.set_grad_checkpointing": [[299, 302], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "'gradient checkpointing not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.ConViT.get_classifier": [[303, 306], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.ConViT.reset_classifier": [[307, 313], ["torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "None", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "if", "global_pool", "is", "not", "None", ":", "\n", "            ", "assert", "global_pool", "in", "(", "''", ",", "'token'", ",", "'avg'", ")", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.ConViT.forward_features": [[314, 326], ["convit.ConViT.patch_embed", "convit.ConViT.pos_drop", "convit.ConViT.cls_token.expand", "enumerate", "convit.ConViT.norm", "blk", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "if", "self", ".", "use_pos_embed", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "pos_embed", "\n", "", "x", "=", "self", ".", "pos_drop", "(", "x", ")", "\n", "cls_tokens", "=", "self", ".", "cls_token", ".", "expand", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "-", "1", ")", "\n", "for", "u", ",", "blk", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "            ", "if", "u", "==", "self", ".", "local_up_to_layer", ":", "\n", "                ", "x", "=", "torch", ".", "cat", "(", "(", "cls_tokens", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "", "x", "=", "blk", "(", "x", ")", "\n", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.ConViT.forward_head": [[327, 331], ["convit.ConViT.head", "x[].mean"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "global_pool", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", "1", ":", "]", ".", "mean", "(", "dim", "=", "1", ")", "if", "self", ".", "global_pool", "==", "'avg'", "else", "x", "[", ":", ",", "0", "]", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.ConViT.forward": [[332, 336], ["convit.ConViT.forward_features", "convit.ConViT.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit._cfg": [[41, 48], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'first_conv'", ":", "'patch_embed.proj'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit._create_convit": [[338, 343], ["kwargs.get", "helpers.build_model_with_cfg", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_convit", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", ".", "get", "(", "'features_only'", ",", "None", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'features_only not implemented for Vision Transformer models.'", ")", "\n", "\n", "", "return", "build_model_with_cfg", "(", "ConViT", ",", "variant", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.convit_tiny": [[345, 352], ["dict", "convit._create_convit", "functools.partial"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit._create_convit"], ["", "@", "register_model", "\n", "def", "convit_tiny", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "local_up_to_layer", "=", "10", ",", "locality_strength", "=", "1.0", ",", "embed_dim", "=", "48", ",", "\n", "num_heads", "=", "4", ",", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convit", "(", "variant", "=", "'convit_tiny'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.convit_small": [[354, 361], ["dict", "convit._create_convit", "functools.partial"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit._create_convit"], ["", "@", "register_model", "\n", "def", "convit_small", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "local_up_to_layer", "=", "10", ",", "locality_strength", "=", "1.0", ",", "embed_dim", "=", "48", ",", "\n", "num_heads", "=", "9", ",", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convit", "(", "variant", "=", "'convit_small'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit.convit_base": [[363, 370], ["dict", "convit._create_convit", "functools.partial"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convit._create_convit"], ["", "@", "register_model", "\n", "def", "convit_base", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "local_up_to_layer", "=", "10", ",", "locality_strength", "=", "1.0", ",", "embed_dim", "=", "48", ",", "\n", "num_heads", "=", "16", ",", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convit", "(", "variant", "=", "'convit_base'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.LocallyGroupedAttn.__init__": [[70, 85], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ",", "ws", "=", "1", ")", ":", "\n", "        ", "assert", "ws", "!=", "1", "\n", "super", "(", "LocallyGroupedAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "dim", "%", "num_heads", "==", "0", ",", "f\"dim {dim} should be divided by num_heads {num_heads}.\"", "\n", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "self", ".", "scale", "=", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", "*", "3", ",", "bias", "=", "True", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "self", ".", "ws", "=", "ws", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.LocallyGroupedAttn.forward": [[86, 114], ["x[].contiguous.view", "torch.pad", "torch.pad", "torch.pad", "x[].contiguous.reshape().transpose", "twins.LocallyGroupedAttn.qkv().reshape().permute", "twins.LocallyGroupedAttn.softmax", "twins.LocallyGroupedAttn.attn_drop", "twins.LocallyGroupedAttn.transpose().reshape", "x[].contiguous.reshape", "twins.LocallyGroupedAttn.proj", "twins.LocallyGroupedAttn.proj_drop", "x[].contiguous", "x[].contiguous.reshape", "twins.LocallyGroupedAttn.qkv().reshape", "k.transpose", "twins.LocallyGroupedAttn.transpose", "twins.LocallyGroupedAttn.qkv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "size", ":", "Size_", ")", ":", "\n", "# There are two implementations for this function, zero padding or mask. We don't observe obvious difference for", "\n", "# both. You can choose any one, we recommend forward_padding because it's neat. However,", "\n", "# the masking implementation is more reasonable and accurate.", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "H", ",", "W", "=", "size", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "H", ",", "W", ",", "C", ")", "\n", "pad_l", "=", "pad_t", "=", "0", "\n", "pad_r", "=", "(", "self", ".", "ws", "-", "W", "%", "self", ".", "ws", ")", "%", "self", ".", "ws", "\n", "pad_b", "=", "(", "self", ".", "ws", "-", "H", "%", "self", ".", "ws", ")", "%", "self", ".", "ws", "\n", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "pad_l", ",", "pad_r", ",", "pad_t", ",", "pad_b", ")", ")", "\n", "_", ",", "Hp", ",", "Wp", ",", "_", "=", "x", ".", "shape", "\n", "_h", ",", "_w", "=", "Hp", "//", "self", ".", "ws", ",", "Wp", "//", "self", ".", "ws", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "_h", ",", "self", ".", "ws", ",", "_w", ",", "self", ".", "ws", ",", "C", ")", ".", "transpose", "(", "2", ",", "3", ")", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "\n", "B", ",", "_h", "*", "_w", ",", "self", ".", "ws", "*", "self", ".", "ws", ",", "3", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "4", ",", "2", ",", "5", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", "[", "0", "]", ",", "qkv", "[", "1", "]", ",", "qkv", "[", "2", "]", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "*", "self", ".", "scale", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "attn", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "2", ",", "3", ")", ".", "reshape", "(", "B", ",", "_h", ",", "_w", ",", "self", ".", "ws", ",", "self", ".", "ws", ",", "C", ")", "\n", "x", "=", "attn", ".", "transpose", "(", "2", ",", "3", ")", ".", "reshape", "(", "B", ",", "_h", "*", "self", ".", "ws", ",", "_w", "*", "self", ".", "ws", ",", "C", ")", "\n", "if", "pad_r", ">", "0", "or", "pad_b", ">", "0", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", "H", ",", ":", "W", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "x", "=", "x", ".", "reshape", "(", "B", ",", "N", ",", "C", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.GlobalSubSampleAttn.__init__": [[154, 176], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ",", "sr_ratio", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "dim", "%", "num_heads", "==", "0", ",", "f\"dim {dim} should be divided by num_heads {num_heads}.\"", "\n", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "self", ".", "scale", "=", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "q", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "kv", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", "*", "2", ",", "bias", "=", "True", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n", "self", ".", "sr_ratio", "=", "sr_ratio", "\n", "if", "sr_ratio", ">", "1", ":", "\n", "            ", "self", ".", "sr", "=", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "sr_ratio", ",", "stride", "=", "sr_ratio", ")", "\n", "self", ".", "norm", "=", "nn", ".", "LayerNorm", "(", "dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "sr", "=", "None", "\n", "self", ".", "norm", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.GlobalSubSampleAttn.forward": [[177, 197], ["twins.GlobalSubSampleAttn.q().reshape().permute", "twins.GlobalSubSampleAttn.kv().reshape().permute", "twins.GlobalSubSampleAttn.softmax", "twins.GlobalSubSampleAttn.attn_drop", "twins.GlobalSubSampleAttn.proj", "twins.GlobalSubSampleAttn.proj_drop", "twins.GlobalSubSampleAttn.permute().reshape", "twins.GlobalSubSampleAttn.sr().reshape().permute", "twins.GlobalSubSampleAttn.norm", "twins.GlobalSubSampleAttn.q().reshape", "twins.GlobalSubSampleAttn.kv().reshape", "k.transpose", "twins.GlobalSubSampleAttn.permute", "twins.GlobalSubSampleAttn.sr().reshape", "twins.GlobalSubSampleAttn.q", "twins.GlobalSubSampleAttn.kv", "twins.GlobalSubSampleAttn.sr"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "size", ":", "Size_", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "q", "=", "self", ".", "q", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n", "if", "self", ".", "sr", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "reshape", "(", "B", ",", "C", ",", "*", "size", ")", "\n", "x", "=", "self", ".", "sr", "(", "x", ")", ".", "reshape", "(", "B", ",", "C", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "", "kv", "=", "self", ".", "kv", "(", "x", ")", ".", "reshape", "(", "B", ",", "-", "1", ",", "2", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "k", ",", "v", "=", "kv", "[", "0", "]", ",", "kv", "[", "1", "]", "\n", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "*", "self", ".", "scale", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "N", ",", "C", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.Block.__init__": [[201, 216], ["torch.Module.__init__", "norm_layer", "norm_layer", "int", "layers.Mlp", "vision_transformer.Attention", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "twins.GlobalSubSampleAttn", "twins.LocallyGroupedAttn"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dim", ",", "num_heads", ",", "mlp_ratio", "=", "4.", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "drop_path", "=", "0.", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "sr_ratio", "=", "1", ",", "ws", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "if", "ws", "is", "None", ":", "\n", "            ", "self", ".", "attn", "=", "Attention", "(", "dim", ",", "num_heads", ",", "False", ",", "None", ",", "attn_drop", ",", "drop", ")", "\n", "", "elif", "ws", "==", "1", ":", "\n", "            ", "self", ".", "attn", "=", "GlobalSubSampleAttn", "(", "dim", ",", "num_heads", ",", "attn_drop", ",", "drop", ",", "sr_ratio", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "attn", "=", "LocallyGroupedAttn", "(", "dim", ",", "num_heads", ",", "attn_drop", ",", "drop", ",", "ws", ")", "\n", "", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "mlp_hidden_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "in_features", "=", "dim", ",", "hidden_features", "=", "mlp_hidden_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.Block.forward": [[217, 221], ["twins.Block.drop_path", "twins.Block.drop_path", "twins.Block.attn", "twins.Block.mlp", "twins.Block.norm1", "twins.Block.norm2"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ",", "size", ":", "Size_", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "attn", "(", "self", ".", "norm1", "(", "x", ")", ",", "size", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.PosConv.__init__": [[225, 229], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_chans", ",", "embed_dim", "=", "768", ",", "stride", "=", "1", ")", ":", "\n", "        ", "super", "(", "PosConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "in_chans", ",", "embed_dim", ",", "3", ",", "stride", ",", "1", ",", "bias", "=", "True", ",", "groups", "=", "embed_dim", ")", ",", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.PosConv.forward": [[230, 238], ["x.flatten().transpose.flatten().transpose.transpose().view", "twins.PosConv.proj", "x.flatten().transpose.flatten().transpose.flatten().transpose", "x.flatten().transpose.flatten().transpose.transpose", "x.flatten().transpose.flatten().transpose.flatten"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "size", ":", "Size_", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "cnn_feat_token", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "view", "(", "B", ",", "C", ",", "*", "size", ")", "\n", "x", "=", "self", ".", "proj", "(", "cnn_feat_token", ")", "\n", "if", "self", ".", "stride", "==", "1", ":", "\n", "            ", "x", "+=", "cnn_feat_token", "\n", "", "x", "=", "x", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.PosConv.no_weight_decay": [[239, 241], ["range"], "methods", ["None"], ["", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "[", "'proj.%d.weight'", "%", "i", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.PatchEmbed.__init__": [[247, 260], ["torch.Module.__init__", "layers.to_2tuple", "layers.to_2tuple", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "embed_dim", "=", "768", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "patch_size", "=", "to_2tuple", "(", "patch_size", ")", "\n", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "assert", "img_size", "[", "0", "]", "%", "patch_size", "[", "0", "]", "==", "0", "and", "img_size", "[", "1", "]", "%", "patch_size", "[", "1", "]", "==", "0", ",", "f\"img_size {img_size} should be divided by patch_size {patch_size}.\"", "\n", "self", ".", "H", ",", "self", ".", "W", "=", "img_size", "[", "0", "]", "//", "patch_size", "[", "0", "]", ",", "img_size", "[", "1", "]", "//", "patch_size", "[", "1", "]", "\n", "self", ".", "num_patches", "=", "self", ".", "H", "*", "self", ".", "W", "\n", "self", ".", "proj", "=", "nn", ".", "Conv2d", "(", "in_chans", ",", "embed_dim", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "patch_size", ")", "\n", "self", ".", "norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.PatchEmbed.forward": [[261, 269], ["twins.PatchEmbed.proj().flatten().transpose", "twins.PatchEmbed.norm", "twins.PatchEmbed.proj().flatten", "twins.PatchEmbed.proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "Size_", "]", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "out_size", "=", "(", "H", "//", "self", ".", "patch_size", "[", "0", "]", ",", "W", "//", "self", ".", "patch_size", "[", "1", "]", ")", "\n", "\n", "return", "x", ",", "out_size", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.Twins.__init__": [[276, 320], ["functools.partial", "torch.Module.__init__", "layers.to_2tuple", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "norm_layer", "twins.Twins.apply", "len", "twins.Twins.patch_embeds.append", "twins.Twins.pos_drops.append", "tuple", "x.item", "len", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "twins.Twins.blocks.append", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "twins.PatchEmbed", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "twins.PosConv", "sum", "block_cls", "range"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "4", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "global_pool", "=", "'avg'", ",", "\n", "embed_dims", "=", "(", "64", ",", "128", ",", "256", ",", "512", ")", ",", "num_heads", "=", "(", "1", ",", "2", ",", "4", ",", "8", ")", ",", "mlp_ratios", "=", "(", "4", ",", "4", ",", "4", ",", "4", ")", ",", "depths", "=", "(", "3", ",", "4", ",", "6", ",", "3", ")", ",", "\n", "sr_ratios", "=", "(", "8", ",", "4", ",", "2", ",", "1", ")", ",", "wss", "=", "None", ",", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "block_cls", "=", "Block", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "self", ".", "depths", "=", "depths", "\n", "self", ".", "embed_dims", "=", "embed_dims", "\n", "self", ".", "num_features", "=", "embed_dims", "[", "-", "1", "]", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "prev_chs", "=", "in_chans", "\n", "self", ".", "patch_embeds", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "pos_drops", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "depths", ")", ")", ":", "\n", "            ", "self", ".", "patch_embeds", ".", "append", "(", "PatchEmbed", "(", "img_size", ",", "patch_size", ",", "prev_chs", ",", "embed_dims", "[", "i", "]", ")", ")", "\n", "self", ".", "pos_drops", ".", "append", "(", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", ")", "\n", "prev_chs", "=", "embed_dims", "[", "i", "]", "\n", "img_size", "=", "tuple", "(", "t", "//", "patch_size", "for", "t", "in", "img_size", ")", "\n", "patch_size", "=", "2", "\n", "\n", "", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "dpr", "=", "[", "x", ".", "item", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "sum", "(", "depths", ")", ")", "]", "# stochastic depth decay rule", "\n", "cur", "=", "0", "\n", "for", "k", "in", "range", "(", "len", "(", "depths", ")", ")", ":", "\n", "            ", "_block", "=", "nn", ".", "ModuleList", "(", "[", "block_cls", "(", "\n", "dim", "=", "embed_dims", "[", "k", "]", ",", "num_heads", "=", "num_heads", "[", "k", "]", ",", "mlp_ratio", "=", "mlp_ratios", "[", "k", "]", ",", "drop", "=", "drop_rate", ",", "\n", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", "[", "cur", "+", "i", "]", ",", "norm_layer", "=", "norm_layer", ",", "sr_ratio", "=", "sr_ratios", "[", "k", "]", ",", "\n", "ws", "=", "1", "if", "wss", "is", "None", "or", "i", "%", "2", "==", "1", "else", "wss", "[", "k", "]", ")", "for", "i", "in", "range", "(", "depths", "[", "k", "]", ")", "]", ")", "\n", "self", ".", "blocks", ".", "append", "(", "_block", ")", "\n", "cur", "+=", "depths", "[", "k", "]", "\n", "\n", "", "self", ".", "pos_block", "=", "nn", ".", "ModuleList", "(", "[", "PosConv", "(", "embed_dim", ",", "embed_dim", ")", "for", "embed_dim", "in", "embed_dims", "]", ")", "\n", "\n", "self", ".", "norm", "=", "norm_layer", "(", "self", ".", "num_features", ")", "\n", "\n", "# classification head", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "# init weights", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.Twins.no_weight_decay": [[321, 324], ["set", "twins.Twins.pos_block.named_parameters"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "set", "(", "[", "'pos_block.'", "+", "n", "for", "n", ",", "p", "in", "self", ".", "pos_block", ".", "named_parameters", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.Twins.group_matcher": [[325, 339], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem", "=", "r'^patch_embeds.0'", ",", "# stem and embed", "\n", "blocks", "=", "[", "\n", "(", "r'^(?:blocks|patch_embeds|pos_block)\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "'^norm'", ",", "(", "99999", ",", ")", ")", "\n", "]", "if", "coarse", "else", "[", "\n", "(", "r'^blocks\\.(\\d+)\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^(?:patch_embeds|pos_block)\\.(\\d+)'", ",", "(", "0", ",", ")", ")", ",", "\n", "(", "r'^norm'", ",", "(", "99999", ",", ")", ")", "\n", "]", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.Twins.set_grad_checkpointing": [[340, 343], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "'gradient checkpointing not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.Twins.get_classifier": [[344, 347], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.Twins.reset_classifier": [[348, 354], ["torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "None", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "if", "global_pool", "is", "not", "None", ":", "\n", "            ", "assert", "global_pool", "in", "(", "''", ",", "'avg'", ")", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.Twins._init_weights": [[355, 369], ["isinstance", "layers.trunc_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "isinstance", "m.weight.data.normal_", "math.sqrt", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", ".02", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "fan_out", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "fan_out", "//=", "m", ".", "groups", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.0", "/", "fan_out", ")", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.Twins.forward_features": [[370, 384], ["enumerate", "twins.Twins.norm", "zip", "embed", "drop", "enumerate", "blk", "pos_blk.reshape().permute().contiguous", "pos_blk", "len", "pos_blk.reshape().permute", "pos_blk.reshape"], "methods", ["None"], ["", "", "", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", "=", "x", ".", "shape", "[", "0", "]", "\n", "for", "i", ",", "(", "embed", ",", "drop", ",", "blocks", ",", "pos_blk", ")", "in", "enumerate", "(", "\n", "zip", "(", "self", ".", "patch_embeds", ",", "self", ".", "pos_drops", ",", "self", ".", "blocks", ",", "self", ".", "pos_block", ")", ")", ":", "\n", "            ", "x", ",", "size", "=", "embed", "(", "x", ")", "\n", "x", "=", "drop", "(", "x", ")", "\n", "for", "j", ",", "blk", "in", "enumerate", "(", "blocks", ")", ":", "\n", "                ", "x", "=", "blk", "(", "x", ",", "size", ")", "\n", "if", "j", "==", "0", ":", "\n", "                    ", "x", "=", "pos_blk", "(", "x", ",", "size", ")", "# PEG here", "\n", "", "", "if", "i", "<", "len", "(", "self", ".", "depths", ")", "-", "1", ":", "\n", "                ", "x", "=", "x", ".", "reshape", "(", "B", ",", "*", "size", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.Twins.forward_head": [[385, 389], ["x.mean.mean.mean", "twins.Twins.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "global_pool", "==", "'avg'", ":", "\n", "            ", "x", "=", "x", ".", "mean", "(", "dim", "=", "1", ")", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.Twins.forward": [[390, 394], ["twins.Twins.forward_features", "twins.Twins.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins._cfg": [[31, 39], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", ".9", ",", "'interpolation'", ":", "'bicubic'", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'patch_embeds.0.proj'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins._create_twins": [[396, 402], ["kwargs.get", "helpers.build_model_with_cfg", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_twins", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", ".", "get", "(", "'features_only'", ",", "None", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'features_only not implemented for Vision Transformer models.'", ")", "\n", "\n", "", "model", "=", "build_model_with_cfg", "(", "Twins", ",", "variant", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.twins_pcpvt_small": [[404, 410], ["dict", "twins._create_twins"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins._create_twins"], ["", "@", "register_model", "\n", "def", "twins_pcpvt_small", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "embed_dims", "=", "[", "64", ",", "128", ",", "320", ",", "512", "]", ",", "num_heads", "=", "[", "1", ",", "2", ",", "5", ",", "8", "]", ",", "mlp_ratios", "=", "[", "8", ",", "8", ",", "4", ",", "4", "]", ",", "\n", "depths", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "sr_ratios", "=", "[", "8", ",", "4", ",", "2", ",", "1", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_twins", "(", "'twins_pcpvt_small'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.twins_pcpvt_base": [[412, 418], ["dict", "twins._create_twins"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins._create_twins"], ["", "@", "register_model", "\n", "def", "twins_pcpvt_base", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "embed_dims", "=", "[", "64", ",", "128", ",", "320", ",", "512", "]", ",", "num_heads", "=", "[", "1", ",", "2", ",", "5", ",", "8", "]", ",", "mlp_ratios", "=", "[", "8", ",", "8", ",", "4", ",", "4", "]", ",", "\n", "depths", "=", "[", "3", ",", "4", ",", "18", ",", "3", "]", ",", "sr_ratios", "=", "[", "8", ",", "4", ",", "2", ",", "1", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_twins", "(", "'twins_pcpvt_base'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.twins_pcpvt_large": [[420, 426], ["dict", "twins._create_twins"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins._create_twins"], ["", "@", "register_model", "\n", "def", "twins_pcpvt_large", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "embed_dims", "=", "[", "64", ",", "128", ",", "320", ",", "512", "]", ",", "num_heads", "=", "[", "1", ",", "2", ",", "5", ",", "8", "]", ",", "mlp_ratios", "=", "[", "8", ",", "8", ",", "4", ",", "4", "]", ",", "\n", "depths", "=", "[", "3", ",", "8", ",", "27", ",", "3", "]", ",", "sr_ratios", "=", "[", "8", ",", "4", ",", "2", ",", "1", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_twins", "(", "'twins_pcpvt_large'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.twins_svt_small": [[428, 434], ["dict", "twins._create_twins"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins._create_twins"], ["", "@", "register_model", "\n", "def", "twins_svt_small", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "embed_dims", "=", "[", "64", ",", "128", ",", "256", ",", "512", "]", ",", "num_heads", "=", "[", "2", ",", "4", ",", "8", ",", "16", "]", ",", "mlp_ratios", "=", "[", "4", ",", "4", ",", "4", ",", "4", "]", ",", "\n", "depths", "=", "[", "2", ",", "2", ",", "10", ",", "4", "]", ",", "wss", "=", "[", "7", ",", "7", ",", "7", ",", "7", "]", ",", "sr_ratios", "=", "[", "8", ",", "4", ",", "2", ",", "1", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_twins", "(", "'twins_svt_small'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.twins_svt_base": [[436, 442], ["dict", "twins._create_twins"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins._create_twins"], ["", "@", "register_model", "\n", "def", "twins_svt_base", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "embed_dims", "=", "[", "96", ",", "192", ",", "384", ",", "768", "]", ",", "num_heads", "=", "[", "3", ",", "6", ",", "12", ",", "24", "]", ",", "mlp_ratios", "=", "[", "4", ",", "4", ",", "4", ",", "4", "]", ",", "\n", "depths", "=", "[", "2", ",", "2", ",", "18", ",", "2", "]", ",", "wss", "=", "[", "7", ",", "7", ",", "7", ",", "7", "]", ",", "sr_ratios", "=", "[", "8", ",", "4", ",", "2", ",", "1", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_twins", "(", "'twins_svt_base'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins.twins_svt_large": [[444, 450], ["dict", "twins._create_twins"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.twins._create_twins"], ["", "@", "register_model", "\n", "def", "twins_svt_large", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "embed_dims", "=", "[", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "num_heads", "=", "[", "4", ",", "8", ",", "16", ",", "32", "]", ",", "mlp_ratios", "=", "[", "4", ",", "4", ",", "4", ",", "4", "]", ",", "\n", "depths", "=", "[", "2", ",", "2", ",", "18", ",", "2", "]", ",", "wss", "=", "[", "7", ",", "7", ",", "7", ",", "7", "]", ",", "sr_ratios", "=", "[", "8", ",", "4", ",", "2", ",", "1", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_twins", "(", "'twins_svt_large'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.SqueezeExcite.__init__": [[38, 50], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "layers.create_act_layer", "torch.Conv2d", "torch.Conv2d", "layers.create_act_layer", "rd_round_fn"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "rd_ratio", "=", "0.25", ",", "rd_channels", "=", "None", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "\n", "gate_layer", "=", "nn", ".", "Sigmoid", ",", "force_act_layer", "=", "None", ",", "rd_round_fn", "=", "None", ")", ":", "\n", "        ", "super", "(", "SqueezeExcite", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "rd_channels", "is", "None", ":", "\n", "            ", "rd_round_fn", "=", "rd_round_fn", "or", "round", "\n", "rd_channels", "=", "rd_round_fn", "(", "in_chs", "*", "rd_ratio", ")", "\n", "", "act_layer", "=", "force_act_layer", "or", "act_layer", "\n", "self", ".", "conv_reduce", "=", "nn", ".", "Conv2d", "(", "in_chs", ",", "rd_channels", ",", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "act1", "=", "create_act_layer", "(", "act_layer", ",", "inplace", "=", "True", ")", "\n", "self", ".", "conv_expand", "=", "nn", ".", "Conv2d", "(", "rd_channels", ",", "in_chs", ",", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "gate", "=", "create_act_layer", "(", "gate_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.SqueezeExcite.forward": [[51, 57], ["x.mean", "efficientnet_blocks.SqueezeExcite.conv_reduce", "efficientnet_blocks.SqueezeExcite.act1", "efficientnet_blocks.SqueezeExcite.conv_expand", "efficientnet_blocks.SqueezeExcite.gate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_se", "=", "x", ".", "mean", "(", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "x_se", "=", "self", ".", "conv_reduce", "(", "x_se", ")", "\n", "x_se", "=", "self", ".", "act1", "(", "x_se", ")", "\n", "x_se", "=", "self", ".", "conv_expand", "(", "x_se", ")", "\n", "return", "x", "*", "self", ".", "gate", "(", "x_se", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.ConvBnAct.__init__": [[62, 74], ["torch.Module.__init__", "layers.get_norm_act_layer", "efficientnet_blocks.num_groups", "layers.create_conv2d", "layers.get_norm_act_layer.", "layers.DropPath", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.num_groups", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "kernel_size", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "group_size", "=", "0", ",", "pad_type", "=", "''", ",", "\n", "skip", "=", "False", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", "ConvBnAct", ",", "self", ")", ".", "__init__", "(", ")", "\n", "norm_act_layer", "=", "get_norm_act_layer", "(", "norm_layer", ",", "act_layer", ")", "\n", "groups", "=", "num_groups", "(", "group_size", ",", "in_chs", ")", "\n", "self", ".", "has_skip", "=", "skip", "and", "stride", "==", "1", "and", "in_chs", "==", "out_chs", "\n", "\n", "self", ".", "conv", "=", "create_conv2d", "(", "\n", "in_chs", ",", "out_chs", ",", "kernel_size", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "groups", "=", "groups", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "bn1", "=", "norm_act_layer", "(", "out_chs", ",", "inplace", "=", "True", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path_rate", ")", "if", "drop_path_rate", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.ConvBnAct.feature_info": [[75, 80], ["dict", "dict"], "methods", ["None"], ["", "def", "feature_info", "(", "self", ",", "location", ")", ":", "\n", "        ", "if", "location", "==", "'expansion'", ":", "# output of conv after act, same as block coutput", "\n", "            ", "return", "dict", "(", "module", "=", "'bn1'", ",", "hook_type", "=", "'forward'", ",", "num_chs", "=", "self", ".", "conv", ".", "out_channels", ")", "\n", "", "else", ":", "# location == 'bottleneck', block output", "\n", "            ", "return", "dict", "(", "module", "=", "''", ",", "hook_type", "=", "''", ",", "num_chs", "=", "self", ".", "conv", ".", "out_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.ConvBnAct.forward": [[81, 88], ["efficientnet_blocks.ConvBnAct.conv", "efficientnet_blocks.ConvBnAct.bn1", "efficientnet_blocks.ConvBnAct.drop_path"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "if", "self", ".", "has_skip", ":", "\n", "            ", "x", "=", "self", ".", "drop_path", "(", "x", ")", "+", "shortcut", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.DepthwiseSeparableConv.__init__": [[95, 115], ["torch.Module.__init__", "layers.get_norm_act_layer", "efficientnet_blocks.num_groups", "layers.create_conv2d", "layers.get_norm_act_layer.", "layers.create_conv2d", "layers.get_norm_act_layer.", "se_layer", "torch.Identity", "torch.Identity", "layers.DropPath", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.num_groups", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "dw_kernel_size", "=", "3", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "group_size", "=", "1", ",", "pad_type", "=", "''", ",", "\n", "noskip", "=", "False", ",", "pw_kernel_size", "=", "1", ",", "pw_act", "=", "False", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "\n", "se_layer", "=", "None", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", "DepthwiseSeparableConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "norm_act_layer", "=", "get_norm_act_layer", "(", "norm_layer", ",", "act_layer", ")", "\n", "groups", "=", "num_groups", "(", "group_size", ",", "in_chs", ")", "\n", "self", ".", "has_skip", "=", "(", "stride", "==", "1", "and", "in_chs", "==", "out_chs", ")", "and", "not", "noskip", "\n", "self", ".", "has_pw_act", "=", "pw_act", "# activation after point-wise conv", "\n", "\n", "self", ".", "conv_dw", "=", "create_conv2d", "(", "\n", "in_chs", ",", "in_chs", ",", "dw_kernel_size", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "padding", "=", "pad_type", ",", "groups", "=", "groups", ")", "\n", "self", ".", "bn1", "=", "norm_act_layer", "(", "in_chs", ",", "inplace", "=", "True", ")", "\n", "\n", "# Squeeze-and-excitation", "\n", "self", ".", "se", "=", "se_layer", "(", "in_chs", ",", "act_layer", "=", "act_layer", ")", "if", "se_layer", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "conv_pw", "=", "create_conv2d", "(", "in_chs", ",", "out_chs", ",", "pw_kernel_size", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "bn2", "=", "norm_act_layer", "(", "out_chs", ",", "inplace", "=", "True", ",", "apply_act", "=", "self", ".", "has_pw_act", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path_rate", ")", "if", "drop_path_rate", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.DepthwiseSeparableConv.feature_info": [[116, 121], ["dict", "dict"], "methods", ["None"], ["", "def", "feature_info", "(", "self", ",", "location", ")", ":", "\n", "        ", "if", "location", "==", "'expansion'", ":", "# after SE, input to PW", "\n", "            ", "return", "dict", "(", "module", "=", "'conv_pw'", ",", "hook_type", "=", "'forward_pre'", ",", "num_chs", "=", "self", ".", "conv_pw", ".", "in_channels", ")", "\n", "", "else", ":", "# location == 'bottleneck', block output", "\n", "            ", "return", "dict", "(", "module", "=", "''", ",", "hook_type", "=", "''", ",", "num_chs", "=", "self", ".", "conv_pw", ".", "out_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.DepthwiseSeparableConv.forward": [[122, 132], ["efficientnet_blocks.DepthwiseSeparableConv.conv_dw", "efficientnet_blocks.DepthwiseSeparableConv.bn1", "efficientnet_blocks.DepthwiseSeparableConv.se", "efficientnet_blocks.DepthwiseSeparableConv.conv_pw", "efficientnet_blocks.DepthwiseSeparableConv.bn2", "efficientnet_blocks.DepthwiseSeparableConv.drop_path"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "conv_dw", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "se", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_pw", "(", "x", ")", "\n", "x", "=", "self", ".", "bn2", "(", "x", ")", "\n", "if", "self", ".", "has_skip", ":", "\n", "            ", "x", "=", "self", ".", "drop_path", "(", "x", ")", "+", "shortcut", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.InvertedResidual.__init__": [[144, 172], ["torch.Module.__init__", "layers.get_norm_act_layer", "layers.make_divisible", "efficientnet_blocks.num_groups", "layers.create_conv2d", "layers.get_norm_act_layer.", "layers.create_conv2d", "layers.get_norm_act_layer.", "layers.create_conv2d", "layers.get_norm_act_layer.", "se_layer", "torch.Identity", "torch.Identity", "layers.DropPath", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.num_groups", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "dw_kernel_size", "=", "3", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "group_size", "=", "1", ",", "pad_type", "=", "''", ",", "\n", "noskip", "=", "False", ",", "exp_ratio", "=", "1.0", ",", "exp_kernel_size", "=", "1", ",", "pw_kernel_size", "=", "1", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "\n", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "se_layer", "=", "None", ",", "conv_kwargs", "=", "None", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", "InvertedResidual", ",", "self", ")", ".", "__init__", "(", ")", "\n", "norm_act_layer", "=", "get_norm_act_layer", "(", "norm_layer", ",", "act_layer", ")", "\n", "conv_kwargs", "=", "conv_kwargs", "or", "{", "}", "\n", "mid_chs", "=", "make_divisible", "(", "in_chs", "*", "exp_ratio", ")", "\n", "groups", "=", "num_groups", "(", "group_size", ",", "mid_chs", ")", "\n", "self", ".", "has_skip", "=", "(", "in_chs", "==", "out_chs", "and", "stride", "==", "1", ")", "and", "not", "noskip", "\n", "\n", "# Point-wise expansion", "\n", "self", ".", "conv_pw", "=", "create_conv2d", "(", "in_chs", ",", "mid_chs", ",", "exp_kernel_size", ",", "padding", "=", "pad_type", ",", "**", "conv_kwargs", ")", "\n", "self", ".", "bn1", "=", "norm_act_layer", "(", "mid_chs", ",", "inplace", "=", "True", ")", "\n", "\n", "# Depth-wise convolution", "\n", "self", ".", "conv_dw", "=", "create_conv2d", "(", "\n", "mid_chs", ",", "mid_chs", ",", "dw_kernel_size", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "\n", "groups", "=", "groups", ",", "padding", "=", "pad_type", ",", "**", "conv_kwargs", ")", "\n", "self", ".", "bn2", "=", "norm_act_layer", "(", "mid_chs", ",", "inplace", "=", "True", ")", "\n", "\n", "# Squeeze-and-excitation", "\n", "self", ".", "se", "=", "se_layer", "(", "mid_chs", ",", "act_layer", "=", "act_layer", ")", "if", "se_layer", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "# Point-wise linear projection", "\n", "self", ".", "conv_pwl", "=", "create_conv2d", "(", "mid_chs", ",", "out_chs", ",", "pw_kernel_size", ",", "padding", "=", "pad_type", ",", "**", "conv_kwargs", ")", "\n", "self", ".", "bn3", "=", "norm_act_layer", "(", "out_chs", ",", "apply_act", "=", "False", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path_rate", ")", "if", "drop_path_rate", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.InvertedResidual.feature_info": [[173, 178], ["dict", "dict"], "methods", ["None"], ["", "def", "feature_info", "(", "self", ",", "location", ")", ":", "\n", "        ", "if", "location", "==", "'expansion'", ":", "# after SE, input to PWL", "\n", "            ", "return", "dict", "(", "module", "=", "'conv_pwl'", ",", "hook_type", "=", "'forward_pre'", ",", "num_chs", "=", "self", ".", "conv_pwl", ".", "in_channels", ")", "\n", "", "else", ":", "# location == 'bottleneck', block output", "\n", "            ", "return", "dict", "(", "module", "=", "''", ",", "hook_type", "=", "''", ",", "num_chs", "=", "self", ".", "conv_pwl", ".", "out_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.InvertedResidual.forward": [[179, 191], ["efficientnet_blocks.InvertedResidual.conv_pw", "efficientnet_blocks.InvertedResidual.bn1", "efficientnet_blocks.InvertedResidual.conv_dw", "efficientnet_blocks.InvertedResidual.bn2", "efficientnet_blocks.InvertedResidual.se", "efficientnet_blocks.InvertedResidual.conv_pwl", "efficientnet_blocks.InvertedResidual.bn3", "efficientnet_blocks.InvertedResidual.drop_path"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "conv_pw", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_dw", "(", "x", ")", "\n", "x", "=", "self", ".", "bn2", "(", "x", ")", "\n", "x", "=", "self", ".", "se", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_pwl", "(", "x", ")", "\n", "x", "=", "self", ".", "bn3", "(", "x", ")", "\n", "if", "self", ".", "has_skip", ":", "\n", "            ", "x", "=", "self", ".", "drop_path", "(", "x", ")", "+", "shortcut", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.CondConvResidual.__init__": [[196, 211], ["dict", "efficientnet_blocks.InvertedResidual.__init__", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "dw_kernel_size", "=", "3", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "group_size", "=", "1", ",", "pad_type", "=", "''", ",", "\n", "noskip", "=", "False", ",", "exp_ratio", "=", "1.0", ",", "exp_kernel_size", "=", "1", ",", "pw_kernel_size", "=", "1", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "\n", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "se_layer", "=", "None", ",", "num_experts", "=", "0", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "\n", "        ", "self", ".", "num_experts", "=", "num_experts", "\n", "conv_kwargs", "=", "dict", "(", "num_experts", "=", "self", ".", "num_experts", ")", "\n", "\n", "super", "(", "CondConvResidual", ",", "self", ")", ".", "__init__", "(", "\n", "in_chs", ",", "out_chs", ",", "dw_kernel_size", "=", "dw_kernel_size", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "group_size", "=", "group_size", ",", "\n", "pad_type", "=", "pad_type", ",", "act_layer", "=", "act_layer", ",", "noskip", "=", "noskip", ",", "exp_ratio", "=", "exp_ratio", ",", "exp_kernel_size", "=", "exp_kernel_size", ",", "\n", "pw_kernel_size", "=", "pw_kernel_size", ",", "se_layer", "=", "se_layer", ",", "norm_layer", "=", "norm_layer", ",", "conv_kwargs", "=", "conv_kwargs", ",", "\n", "drop_path_rate", "=", "drop_path_rate", ")", "\n", "\n", "self", ".", "routing_fn", "=", "nn", ".", "Linear", "(", "in_chs", ",", "self", ".", "num_experts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.CondConvResidual.forward": [[212, 226], ["torch.nn.functional.adaptive_avg_pool2d().flatten", "torch.nn.functional.adaptive_avg_pool2d().flatten", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "efficientnet_blocks.CondConvResidual.conv_pw", "efficientnet_blocks.CondConvResidual.bn1", "efficientnet_blocks.CondConvResidual.conv_dw", "efficientnet_blocks.CondConvResidual.bn2", "efficientnet_blocks.CondConvResidual.se", "efficientnet_blocks.CondConvResidual.conv_pwl", "efficientnet_blocks.CondConvResidual.bn3", "efficientnet_blocks.CondConvResidual.routing_fn", "torch.nn.functional.adaptive_avg_pool2d", "torch.nn.functional.adaptive_avg_pool2d", "efficientnet_blocks.CondConvResidual.drop_path"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "pooled_inputs", "=", "F", ".", "adaptive_avg_pool2d", "(", "x", ",", "1", ")", ".", "flatten", "(", "1", ")", "# CondConv routing", "\n", "routing_weights", "=", "torch", ".", "sigmoid", "(", "self", ".", "routing_fn", "(", "pooled_inputs", ")", ")", "\n", "x", "=", "self", ".", "conv_pw", "(", "x", ",", "routing_weights", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_dw", "(", "x", ",", "routing_weights", ")", "\n", "x", "=", "self", ".", "bn2", "(", "x", ")", "\n", "x", "=", "self", ".", "se", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_pwl", "(", "x", ",", "routing_weights", ")", "\n", "x", "=", "self", ".", "bn3", "(", "x", ")", "\n", "if", "self", ".", "has_skip", ":", "\n", "            ", "x", "=", "self", ".", "drop_path", "(", "x", ")", "+", "shortcut", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.EdgeResidual.__init__": [[240, 265], ["torch.Module.__init__", "layers.get_norm_act_layer", "efficientnet_blocks.num_groups", "layers.create_conv2d", "layers.get_norm_act_layer.", "layers.create_conv2d", "layers.get_norm_act_layer.", "layers.make_divisible", "layers.make_divisible", "se_layer", "torch.Identity", "torch.Identity", "layers.DropPath", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.num_groups", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "exp_kernel_size", "=", "3", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "group_size", "=", "0", ",", "pad_type", "=", "''", ",", "\n", "force_in_chs", "=", "0", ",", "noskip", "=", "False", ",", "exp_ratio", "=", "1.0", ",", "pw_kernel_size", "=", "1", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "\n", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "se_layer", "=", "None", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", "EdgeResidual", ",", "self", ")", ".", "__init__", "(", ")", "\n", "norm_act_layer", "=", "get_norm_act_layer", "(", "norm_layer", ",", "act_layer", ")", "\n", "if", "force_in_chs", ">", "0", ":", "\n", "            ", "mid_chs", "=", "make_divisible", "(", "force_in_chs", "*", "exp_ratio", ")", "\n", "", "else", ":", "\n", "            ", "mid_chs", "=", "make_divisible", "(", "in_chs", "*", "exp_ratio", ")", "\n", "", "groups", "=", "num_groups", "(", "group_size", ",", "in_chs", ")", "\n", "self", ".", "has_skip", "=", "(", "in_chs", "==", "out_chs", "and", "stride", "==", "1", ")", "and", "not", "noskip", "\n", "\n", "# Expansion convolution", "\n", "self", ".", "conv_exp", "=", "create_conv2d", "(", "\n", "in_chs", ",", "mid_chs", ",", "exp_kernel_size", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "groups", "=", "groups", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "bn1", "=", "norm_act_layer", "(", "mid_chs", ",", "inplace", "=", "True", ")", "\n", "\n", "# Squeeze-and-excitation", "\n", "self", ".", "se", "=", "se_layer", "(", "mid_chs", ",", "act_layer", "=", "act_layer", ")", "if", "se_layer", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "# Point-wise linear projection", "\n", "self", ".", "conv_pwl", "=", "create_conv2d", "(", "mid_chs", ",", "out_chs", ",", "pw_kernel_size", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "bn2", "=", "norm_act_layer", "(", "out_chs", ",", "apply_act", "=", "False", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path_rate", ")", "if", "drop_path_rate", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.EdgeResidual.feature_info": [[266, 271], ["dict", "dict"], "methods", ["None"], ["", "def", "feature_info", "(", "self", ",", "location", ")", ":", "\n", "        ", "if", "location", "==", "'expansion'", ":", "# after SE, before PWL", "\n", "            ", "return", "dict", "(", "module", "=", "'conv_pwl'", ",", "hook_type", "=", "'forward_pre'", ",", "num_chs", "=", "self", ".", "conv_pwl", ".", "in_channels", ")", "\n", "", "else", ":", "# location == 'bottleneck', block output", "\n", "            ", "return", "dict", "(", "module", "=", "''", ",", "hook_type", "=", "''", ",", "num_chs", "=", "self", ".", "conv_pwl", ".", "out_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.EdgeResidual.forward": [[272, 282], ["efficientnet_blocks.EdgeResidual.conv_exp", "efficientnet_blocks.EdgeResidual.bn1", "efficientnet_blocks.EdgeResidual.se", "efficientnet_blocks.EdgeResidual.conv_pwl", "efficientnet_blocks.EdgeResidual.bn2", "efficientnet_blocks.EdgeResidual.drop_path"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "conv_exp", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "se", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_pwl", "(", "x", ")", "\n", "x", "=", "self", ".", "bn2", "(", "x", ")", "\n", "if", "self", ".", "has_skip", ":", "\n", "            ", "x", "=", "self", ".", "drop_path", "(", "x", ")", "+", "shortcut", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.num_groups": [[17, 24], ["None"], "function", ["None"], ["def", "num_groups", "(", "group_size", ",", "channels", ")", ":", "\n", "    ", "if", "not", "group_size", ":", "# 0 or None", "\n", "        ", "return", "1", "# normal conv with 1 group", "\n", "", "else", ":", "\n", "# NOTE group_size == 1 -> depthwise conv", "\n", "        ", "assert", "channels", "%", "group_size", "==", "0", "\n", "return", "channels", "//", "group_size", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.BasicConv2d.__init__": [[29, 35], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_planes", ",", "out_planes", ",", "kernel_size", ",", "stride", ",", "padding", "=", "0", ")", ":", "\n", "        ", "super", "(", "BasicConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "\n", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm2d", "(", "out_planes", ",", "eps", "=", "0.001", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.BasicConv2d.forward": [[36, 41], ["inception_v4.BasicConv2d.conv", "inception_v4.BasicConv2d.bn", "inception_v4.BasicConv2d.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.Mixed3a.__init__": [[44, 48], ["torch.Module.__init__", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "inception_v4.BasicConv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Mixed3a", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "stride", "=", "2", ")", "\n", "self", ".", "conv", "=", "BasicConv2d", "(", "64", ",", "96", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.Mixed3a.forward": [[49, 54], ["inception_v4.Mixed3a.maxpool", "inception_v4.Mixed3a.conv", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "x1", "=", "self", ".", "conv", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ")", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.Mixed4a.__init__": [[57, 70], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Mixed4a", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "branch0", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "160", ",", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "64", ",", "96", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", ")", "\n", "\n", "self", ".", "branch1", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "160", ",", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "(", "1", ",", "7", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "0", ",", "3", ")", ")", ",", "\n", "BasicConv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "(", "7", ",", "1", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "3", ",", "0", ")", ")", ",", "\n", "BasicConv2d", "(", "64", ",", "96", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "stride", "=", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.Mixed4a.forward": [[72, 77], ["inception_v4.Mixed4a.branch0", "inception_v4.Mixed4a.branch1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "x1", "=", "self", ".", "branch1", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ")", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.Mixed5a.__init__": [[80, 84], ["torch.Module.__init__", "inception_v4.BasicConv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Mixed5a", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "BasicConv2d", "(", "192", ",", "192", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "stride", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.Mixed5a.forward": [[85, 90], ["inception_v4.Mixed5a.conv", "inception_v4.Mixed5a.maxpool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "conv", "(", "x", ")", "\n", "x1", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ")", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.InceptionA.__init__": [[93, 111], ["torch.Module.__init__", "inception_v4.BasicConv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "inception_v4.BasicConv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "InceptionA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "branch0", "=", "BasicConv2d", "(", "384", ",", "96", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "branch1", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "384", ",", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "64", ",", "96", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", ")", "\n", "\n", "self", ".", "branch2", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "384", ",", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "64", ",", "96", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "96", ",", "96", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", ")", "\n", "\n", "self", ".", "branch3", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "AvgPool2d", "(", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "count_include_pad", "=", "False", ")", ",", "\n", "BasicConv2d", "(", "384", ",", "96", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.InceptionA.forward": [[113, 120], ["inception_v4.InceptionA.branch0", "inception_v4.InceptionA.branch1", "inception_v4.InceptionA.branch2", "inception_v4.InceptionA.branch3", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "x1", "=", "self", ".", "branch1", "(", "x", ")", "\n", "x2", "=", "self", ".", "branch2", "(", "x", ")", "\n", "x3", "=", "self", ".", "branch3", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ",", "x2", ",", "x3", ")", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.ReductionA.__init__": [[123, 134], ["torch.Module.__init__", "inception_v4.BasicConv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "ReductionA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "branch0", "=", "BasicConv2d", "(", "384", ",", "384", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "\n", "self", ".", "branch1", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "384", ",", "192", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "192", ",", "224", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "224", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", ")", "\n", "\n", "self", ".", "branch2", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "stride", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.ReductionA.forward": [[135, 141], ["inception_v4.ReductionA.branch0", "inception_v4.ReductionA.branch1", "inception_v4.ReductionA.branch2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "x1", "=", "self", ".", "branch1", "(", "x", ")", "\n", "x2", "=", "self", ".", "branch2", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ",", "x2", ")", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.InceptionB.__init__": [[144, 165], ["torch.Module.__init__", "inception_v4.BasicConv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "inception_v4.BasicConv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "InceptionB", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "branch0", "=", "BasicConv2d", "(", "1024", ",", "384", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "branch1", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "1024", ",", "192", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "192", ",", "224", ",", "kernel_size", "=", "(", "1", ",", "7", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "0", ",", "3", ")", ")", ",", "\n", "BasicConv2d", "(", "224", ",", "256", ",", "kernel_size", "=", "(", "7", ",", "1", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "3", ",", "0", ")", ")", "\n", ")", "\n", "\n", "self", ".", "branch2", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "1024", ",", "192", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "192", ",", "192", ",", "kernel_size", "=", "(", "7", ",", "1", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "3", ",", "0", ")", ")", ",", "\n", "BasicConv2d", "(", "192", ",", "224", ",", "kernel_size", "=", "(", "1", ",", "7", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "0", ",", "3", ")", ")", ",", "\n", "BasicConv2d", "(", "224", ",", "224", ",", "kernel_size", "=", "(", "7", ",", "1", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "3", ",", "0", ")", ")", ",", "\n", "BasicConv2d", "(", "224", ",", "256", ",", "kernel_size", "=", "(", "1", ",", "7", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "0", ",", "3", ")", ")", "\n", ")", "\n", "\n", "self", ".", "branch3", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "AvgPool2d", "(", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "count_include_pad", "=", "False", ")", ",", "\n", "BasicConv2d", "(", "1024", ",", "128", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.InceptionB.forward": [[167, 174], ["inception_v4.InceptionB.branch0", "inception_v4.InceptionB.branch1", "inception_v4.InceptionB.branch2", "inception_v4.InceptionB.branch3", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "x1", "=", "self", ".", "branch1", "(", "x", ")", "\n", "x2", "=", "self", ".", "branch2", "(", "x", ")", "\n", "x3", "=", "self", ".", "branch3", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ",", "x2", ",", "x3", ")", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.ReductionB.__init__": [[177, 193], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "ReductionB", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "branch0", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "1024", ",", "192", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "192", ",", "192", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", ")", "\n", "\n", "self", ".", "branch1", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "1024", ",", "256", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "(", "1", ",", "7", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "0", ",", "3", ")", ")", ",", "\n", "BasicConv2d", "(", "256", ",", "320", ",", "kernel_size", "=", "(", "7", ",", "1", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "3", ",", "0", ")", ")", ",", "\n", "BasicConv2d", "(", "320", ",", "320", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", ")", "\n", "\n", "self", ".", "branch2", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "stride", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.ReductionB.forward": [[194, 200], ["inception_v4.ReductionB.branch0", "inception_v4.ReductionB.branch1", "inception_v4.ReductionB.branch2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "x1", "=", "self", ".", "branch1", "(", "x", ")", "\n", "x2", "=", "self", ".", "branch2", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ",", "x2", ")", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.InceptionC.__init__": [[203, 221], ["torch.Module.__init__", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "inception_v4.BasicConv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "InceptionC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "branch0", "=", "BasicConv2d", "(", "1536", ",", "256", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "branch1_0", "=", "BasicConv2d", "(", "1536", ",", "384", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "branch1_1a", "=", "BasicConv2d", "(", "384", ",", "256", ",", "kernel_size", "=", "(", "1", ",", "3", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "0", ",", "1", ")", ")", "\n", "self", ".", "branch1_1b", "=", "BasicConv2d", "(", "384", ",", "256", ",", "kernel_size", "=", "(", "3", ",", "1", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "1", ",", "0", ")", ")", "\n", "\n", "self", ".", "branch2_0", "=", "BasicConv2d", "(", "1536", ",", "384", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "branch2_1", "=", "BasicConv2d", "(", "384", ",", "448", ",", "kernel_size", "=", "(", "3", ",", "1", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "1", ",", "0", ")", ")", "\n", "self", ".", "branch2_2", "=", "BasicConv2d", "(", "448", ",", "512", ",", "kernel_size", "=", "(", "1", ",", "3", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "0", ",", "1", ")", ")", "\n", "self", ".", "branch2_3a", "=", "BasicConv2d", "(", "512", ",", "256", ",", "kernel_size", "=", "(", "1", ",", "3", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "0", ",", "1", ")", ")", "\n", "self", ".", "branch2_3b", "=", "BasicConv2d", "(", "512", ",", "256", ",", "kernel_size", "=", "(", "3", ",", "1", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "1", ",", "0", ")", ")", "\n", "\n", "self", ".", "branch3", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "AvgPool2d", "(", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "count_include_pad", "=", "False", ")", ",", "\n", "BasicConv2d", "(", "1536", ",", "256", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.InceptionC.forward": [[223, 242], ["inception_v4.InceptionC.branch0", "inception_v4.InceptionC.branch1_0", "inception_v4.InceptionC.branch1_1a", "inception_v4.InceptionC.branch1_1b", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception_v4.InceptionC.branch2_0", "inception_v4.InceptionC.branch2_1", "inception_v4.InceptionC.branch2_2", "inception_v4.InceptionC.branch2_3a", "inception_v4.InceptionC.branch2_3b", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception_v4.InceptionC.branch3", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "\n", "x1_0", "=", "self", ".", "branch1_0", "(", "x", ")", "\n", "x1_1a", "=", "self", ".", "branch1_1a", "(", "x1_0", ")", "\n", "x1_1b", "=", "self", ".", "branch1_1b", "(", "x1_0", ")", "\n", "x1", "=", "torch", ".", "cat", "(", "(", "x1_1a", ",", "x1_1b", ")", ",", "1", ")", "\n", "\n", "x2_0", "=", "self", ".", "branch2_0", "(", "x", ")", "\n", "x2_1", "=", "self", ".", "branch2_1", "(", "x2_0", ")", "\n", "x2_2", "=", "self", ".", "branch2_2", "(", "x2_1", ")", "\n", "x2_3a", "=", "self", ".", "branch2_3a", "(", "x2_2", ")", "\n", "x2_3b", "=", "self", ".", "branch2_3b", "(", "x2_2", ")", "\n", "x2", "=", "torch", ".", "cat", "(", "(", "x2_3a", ",", "x2_3b", ")", ",", "1", ")", "\n", "\n", "x3", "=", "self", ".", "branch3", "(", "x", ")", "\n", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ",", "x2", ",", "x3", ")", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.InceptionV4.__init__": [[245, 285], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.create_classifier", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.BasicConv2d", "inception_v4.Mixed3a", "inception_v4.Mixed4a", "inception_v4.Mixed5a", "inception_v4.InceptionA", "inception_v4.InceptionA", "inception_v4.InceptionA", "inception_v4.InceptionA", "inception_v4.ReductionA", "inception_v4.InceptionB", "inception_v4.InceptionB", "inception_v4.InceptionB", "inception_v4.InceptionB", "inception_v4.InceptionB", "inception_v4.InceptionB", "inception_v4.InceptionB", "inception_v4.ReductionB", "inception_v4.InceptionC", "inception_v4.InceptionC", "inception_v4.InceptionC", "dict", "dict", "dict", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["    ", "def", "__init__", "(", "self", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "output_stride", "=", "32", ",", "drop_rate", "=", "0.", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "super", "(", "InceptionV4", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "output_stride", "==", "32", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_features", "=", "1536", "\n", "\n", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "in_chans", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "BasicConv2d", "(", "32", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "Mixed3a", "(", ")", ",", "\n", "Mixed4a", "(", ")", ",", "\n", "Mixed5a", "(", ")", ",", "\n", "InceptionA", "(", ")", ",", "\n", "InceptionA", "(", ")", ",", "\n", "InceptionA", "(", ")", ",", "\n", "InceptionA", "(", ")", ",", "\n", "ReductionA", "(", ")", ",", "# Mixed6a", "\n", "InceptionB", "(", ")", ",", "\n", "InceptionB", "(", ")", ",", "\n", "InceptionB", "(", ")", ",", "\n", "InceptionB", "(", ")", ",", "\n", "InceptionB", "(", ")", ",", "\n", "InceptionB", "(", ")", ",", "\n", "InceptionB", "(", ")", ",", "\n", "ReductionB", "(", ")", ",", "# Mixed7a", "\n", "InceptionC", "(", ")", ",", "\n", "InceptionC", "(", ")", ",", "\n", "InceptionC", "(", ")", ",", "\n", ")", "\n", "self", ".", "feature_info", "=", "[", "\n", "dict", "(", "num_chs", "=", "64", ",", "reduction", "=", "2", ",", "module", "=", "'features.2'", ")", ",", "\n", "dict", "(", "num_chs", "=", "160", ",", "reduction", "=", "4", ",", "module", "=", "'features.3'", ")", ",", "\n", "dict", "(", "num_chs", "=", "384", ",", "reduction", "=", "8", ",", "module", "=", "'features.9'", ")", ",", "\n", "dict", "(", "num_chs", "=", "1024", ",", "reduction", "=", "16", ",", "module", "=", "'features.17'", ")", ",", "\n", "dict", "(", "num_chs", "=", "1536", ",", "reduction", "=", "32", ",", "module", "=", "'features.21'", ")", ",", "\n", "]", "\n", "self", ".", "global_pool", ",", "self", ".", "last_linear", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.InceptionV4.group_matcher": [[286, 291], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^features\\.[012]\\.'", ",", "\n", "blocks", "=", "r'^features\\.(\\d+)'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.InceptionV4.set_grad_checkpointing": [[293, 296], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "'gradient checkpointing not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.InceptionV4.get_classifier": [[297, 300], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "last_linear", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.InceptionV4.reset_classifier": [[301, 305], ["layers.create_classifier"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "last_linear", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.InceptionV4.forward_features": [[306, 308], ["inception_v4.InceptionV4.features"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "features", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.InceptionV4.forward_head": [[309, 314], ["inception_v4.InceptionV4.global_pool", "torch.dropout", "torch.dropout", "torch.dropout", "inception_v4.InceptionV4.last_linear"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ">", "0", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "last_linear", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.InceptionV4.forward": [[315, 319], ["inception_v4.InceptionV4.forward_features", "inception_v4.InceptionV4.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4._create_inception_v4": [[321, 326], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_inception_v4", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "\n", "InceptionV4", ",", "variant", ",", "pretrained", ",", "\n", "feature_cfg", "=", "dict", "(", "flatten_sequential", "=", "True", ")", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4.inception_v4": [[328, 331], ["inception_v4._create_inception_v4"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v4._create_inception_v4"], ["", "@", "register_model", "\n", "def", "inception_v4", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_inception_v4", "(", "'inception_v4'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.PatchEmbed.__init__": [[69, 76], ["torch.Module.__init__", "layers.to_2tuple", "layers.to_2tuple", "layers.to_2tuple", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "in_chs", "=", "3", ",", "embed_dim", "=", "768", ",", "patch_size", "=", "16", ",", "stride", "=", "16", ",", "padding", "=", "0", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "patch_size", "=", "to_2tuple", "(", "patch_size", ")", "\n", "stride", "=", "to_2tuple", "(", "stride", ")", "\n", "padding", "=", "to_2tuple", "(", "padding", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Conv2d", "(", "in_chs", ",", "embed_dim", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "if", "norm_layer", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.PatchEmbed.forward": [[77, 81], ["poolformer.PatchEmbed.proj", "poolformer.PatchEmbed.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.GroupNorm1.__init__": [[88, 90], ["torch.GroupNorm.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "num_channels", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "1", ",", "num_channels", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.Pooling.__init__": [[93, 96], ["torch.Module.__init__", "torch.AvgPool2d", "torch.AvgPool2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "pool_size", "=", "3", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pool", "=", "nn", ".", "AvgPool2d", "(", "pool_size", ",", "stride", "=", "1", ",", "padding", "=", "pool_size", "//", "2", ",", "count_include_pad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.Pooling.forward": [[97, 99], ["poolformer.Pooling.pool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "pool", "(", "x", ")", "-", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.PoolFormerBlock.__init__": [[114, 134], ["torch.Module.__init__", "norm_layer", "poolformer.Pooling", "norm_layer", "layers.ConvMlp", "layers.DropPath", "torch.Identity", "torch.Identity", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "int", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "dim", ",", "pool_size", "=", "3", ",", "mlp_ratio", "=", "4.", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "GroupNorm1", ",", "\n", "drop", "=", "0.", ",", "drop_path", "=", "0.", ",", "layer_scale_init_value", "=", "1e-5", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "token_mixer", "=", "Pooling", "(", "pool_size", "=", "pool_size", ")", "\n", "self", ".", "drop_path1", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "mlp", "=", "ConvMlp", "(", "dim", ",", "hidden_features", "=", "int", "(", "dim", "*", "mlp_ratio", ")", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "self", ".", "drop_path2", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "if", "layer_scale_init_value", ":", "\n", "            ", "self", ".", "layer_scale_1", "=", "nn", ".", "Parameter", "(", "layer_scale_init_value", "*", "torch", ".", "ones", "(", "dim", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "layer_scale_2", "=", "nn", ".", "Parameter", "(", "layer_scale_init_value", "*", "torch", ".", "ones", "(", "dim", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_scale_1", "=", "None", "\n", "self", ".", "layer_scale_2", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.PoolFormerBlock.forward": [[135, 143], ["poolformer.PoolFormerBlock.drop_path1", "poolformer.PoolFormerBlock.drop_path2", "poolformer.PoolFormerBlock.drop_path1", "poolformer.PoolFormerBlock.drop_path2", "poolformer.PoolFormerBlock.token_mixer", "poolformer.PoolFormerBlock.mlp", "poolformer.PoolFormerBlock.layer_scale_1.unsqueeze().unsqueeze", "poolformer.PoolFormerBlock.token_mixer", "poolformer.PoolFormerBlock.layer_scale_2.unsqueeze().unsqueeze", "poolformer.PoolFormerBlock.mlp", "poolformer.PoolFormerBlock.norm1", "poolformer.PoolFormerBlock.norm2", "poolformer.PoolFormerBlock.norm1", "poolformer.PoolFormerBlock.norm2", "poolformer.PoolFormerBlock.layer_scale_1.unsqueeze", "poolformer.PoolFormerBlock.layer_scale_2.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "layer_scale_1", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "drop_path1", "(", "self", ".", "layer_scale_1", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "*", "self", ".", "token_mixer", "(", "self", ".", "norm1", "(", "x", ")", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path2", "(", "self", ".", "layer_scale_2", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "*", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "drop_path1", "(", "self", ".", "token_mixer", "(", "self", ".", "norm1", "(", "x", ")", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path2", "(", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.PoolFormer.__init__": [[170, 224], ["torch.Module.__init__", "poolformer.PatchEmbed", "range", "torch.Sequential", "torch.Sequential", "norm_layer", "poolformer.PoolFormer.apply", "len", "network.append", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "poolformer.basic_blocks", "network.append", "poolformer.PatchEmbed", "len"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.basic_blocks"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layers", ",", "\n", "embed_dims", "=", "(", "64", ",", "128", ",", "320", ",", "512", ")", ",", "\n", "mlp_ratios", "=", "(", "4", ",", "4", ",", "4", ",", "4", ")", ",", "\n", "downsamples", "=", "(", "True", ",", "True", ",", "True", ",", "True", ")", ",", "\n", "pool_size", "=", "3", ",", "\n", "in_chans", "=", "3", ",", "\n", "num_classes", "=", "1000", ",", "\n", "global_pool", "=", "'avg'", ",", "\n", "norm_layer", "=", "GroupNorm1", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "\n", "in_patch_size", "=", "7", ",", "\n", "in_stride", "=", "4", ",", "\n", "in_pad", "=", "2", ",", "\n", "down_patch_size", "=", "3", ",", "\n", "down_stride", "=", "2", ",", "\n", "down_pad", "=", "1", ",", "\n", "drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "\n", "layer_scale_init_value", "=", "1e-5", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "self", ".", "num_features", "=", "embed_dims", "[", "-", "1", "]", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "self", ".", "patch_embed", "=", "PatchEmbed", "(", "\n", "patch_size", "=", "in_patch_size", ",", "stride", "=", "in_stride", ",", "padding", "=", "in_pad", ",", "\n", "in_chs", "=", "in_chans", ",", "embed_dim", "=", "embed_dims", "[", "0", "]", ")", "\n", "\n", "# set the main block in network", "\n", "network", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "layers", ")", ")", ":", "\n", "            ", "network", ".", "append", "(", "basic_blocks", "(", "\n", "embed_dims", "[", "i", "]", ",", "i", ",", "layers", ",", "\n", "pool_size", "=", "pool_size", ",", "mlp_ratio", "=", "mlp_ratios", "[", "i", "]", ",", "\n", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ",", "\n", "drop_rate", "=", "drop_rate", ",", "drop_path_rate", "=", "drop_path_rate", ",", "\n", "layer_scale_init_value", "=", "layer_scale_init_value", ")", "\n", ")", "\n", "if", "i", "<", "len", "(", "layers", ")", "-", "1", "and", "(", "downsamples", "[", "i", "]", "or", "embed_dims", "[", "i", "]", "!=", "embed_dims", "[", "i", "+", "1", "]", ")", ":", "\n", "# downsampling between stages", "\n", "                ", "network", ".", "append", "(", "PatchEmbed", "(", "\n", "in_chs", "=", "embed_dims", "[", "i", "]", ",", "embed_dim", "=", "embed_dims", "[", "i", "+", "1", "]", ",", "\n", "patch_size", "=", "down_patch_size", ",", "stride", "=", "down_stride", ",", "padding", "=", "down_pad", ")", "\n", ")", "\n", "\n", "", "", "self", ".", "network", "=", "nn", ".", "Sequential", "(", "*", "network", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "self", ".", "num_features", ")", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.PoolFormer._init_weights": [[226, 231], ["isinstance", "layers.trunc_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", ".02", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.PoolFormer.group_matcher": [[232, 240], ["dict"], "methods", ["None"], ["", "", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^patch_embed'", ",", "# stem and embed", "\n", "blocks", "=", "[", "\n", "(", "r'^network\\.(\\d+)\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^network\\.(\\d+)'", ",", "(", "0", ",", ")", ")", ",", "\n", "(", "r'^norm'", ",", "(", "99999", ",", ")", ")", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.PoolFormer.set_grad_checkpointing": [[243, 246], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.PoolFormer.get_classifier": [[247, 250], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.PoolFormer.reset_classifier": [[251, 256], ["torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "None", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "if", "global_pool", "is", "not", "None", ":", "\n", "            ", "self", ".", "global_pool", "=", "global_pool", "\n", "", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.PoolFormer.forward_features": [[257, 262], ["poolformer.PoolFormer.patch_embed", "poolformer.PoolFormer.network", "poolformer.PoolFormer.norm"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "x", "=", "self", ".", "network", "(", "x", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.PoolFormer.forward_head": [[263, 267], ["x.mean.mean.mean", "poolformer.PoolFormer.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "global_pool", "==", "'avg'", ":", "\n", "            ", "x", "=", "x", ".", "mean", "(", "[", "-", "2", ",", "-", "1", "]", ")", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.PoolFormer.forward": [[268, 272], ["poolformer.PoolFormer.forward_features", "poolformer.PoolFormer.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer._cfg": [[33, 41], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", ".95", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'patch_embed.proj'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.basic_blocks": [[145, 164], ["range", "torch.Sequential", "nn.Sequential.append", "poolformer.PoolFormerBlock", "sum", "sum"], "function", ["None"], ["", "", "def", "basic_blocks", "(", "\n", "dim", ",", "index", ",", "layers", ",", "\n", "pool_size", "=", "3", ",", "mlp_ratio", "=", "4.", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "GroupNorm1", ",", "\n", "drop_rate", "=", ".0", ",", "drop_path_rate", "=", "0.", ",", "\n", "layer_scale_init_value", "=", "1e-5", ",", "\n", ")", ":", "\n", "    ", "\"\"\" generate PoolFormer blocks for a stage \"\"\"", "\n", "blocks", "=", "[", "]", "\n", "for", "block_idx", "in", "range", "(", "layers", "[", "index", "]", ")", ":", "\n", "        ", "block_dpr", "=", "drop_path_rate", "*", "(", "block_idx", "+", "sum", "(", "layers", "[", ":", "index", "]", ")", ")", "/", "(", "sum", "(", "layers", ")", "-", "1", ")", "\n", "blocks", ".", "append", "(", "PoolFormerBlock", "(", "\n", "dim", ",", "pool_size", "=", "pool_size", ",", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ",", "\n", "drop", "=", "drop_rate", ",", "drop_path", "=", "block_dpr", ",", "\n", "layer_scale_init_value", "=", "layer_scale_init_value", ",", "\n", ")", ")", "\n", "", "blocks", "=", "nn", ".", "Sequential", "(", "*", "blocks", ")", "\n", "return", "blocks", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer._create_poolformer": [[274, 279], ["kwargs.get", "helpers.build_model_with_cfg", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_poolformer", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", ".", "get", "(", "'features_only'", ",", "None", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'features_only not implemented for Vision Transformer models.'", ")", "\n", "", "model", "=", "build_model_with_cfg", "(", "PoolFormer", ",", "variant", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.poolformer_s12": [[281, 286], ["poolformer._create_poolformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer._create_poolformer"], ["", "@", "register_model", "\n", "def", "poolformer_s12", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" PoolFormer-S12 model, Params: 12M \"\"\"", "\n", "model", "=", "_create_poolformer", "(", "'poolformer_s12'", ",", "pretrained", "=", "pretrained", ",", "layers", "=", "(", "2", ",", "2", ",", "6", ",", "2", ")", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.poolformer_s24": [[288, 293], ["poolformer._create_poolformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer._create_poolformer"], ["", "@", "register_model", "\n", "def", "poolformer_s24", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" PoolFormer-S24 model, Params: 21M \"\"\"", "\n", "model", "=", "_create_poolformer", "(", "'poolformer_s24'", ",", "pretrained", "=", "pretrained", ",", "layers", "=", "(", "4", ",", "4", ",", "12", ",", "4", ")", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.poolformer_s36": [[295, 301], ["poolformer._create_poolformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer._create_poolformer"], ["", "@", "register_model", "\n", "def", "poolformer_s36", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" PoolFormer-S36 model, Params: 31M \"\"\"", "\n", "model", "=", "_create_poolformer", "(", "\n", "'poolformer_s36'", ",", "pretrained", "=", "pretrained", ",", "layers", "=", "(", "6", ",", "6", ",", "18", ",", "6", ")", ",", "layer_scale_init_value", "=", "1e-6", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.poolformer_m36": [[303, 312], ["poolformer._create_poolformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer._create_poolformer"], ["", "@", "register_model", "\n", "def", "poolformer_m36", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" PoolFormer-M36 model, Params: 56M \"\"\"", "\n", "layers", "=", "(", "6", ",", "6", ",", "18", ",", "6", ")", "\n", "embed_dims", "=", "(", "96", ",", "192", ",", "384", ",", "768", ")", "\n", "model", "=", "_create_poolformer", "(", "\n", "'poolformer_m36'", ",", "pretrained", "=", "pretrained", ",", "layers", "=", "layers", ",", "embed_dims", "=", "embed_dims", ",", "\n", "layer_scale_init_value", "=", "1e-6", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer.poolformer_m48": [[314, 323], ["poolformer._create_poolformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.poolformer._create_poolformer"], ["", "@", "register_model", "\n", "def", "poolformer_m48", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" PoolFormer-M48 model, Params: 73M \"\"\"", "\n", "layers", "=", "(", "8", ",", "8", ",", "24", ",", "8", ")", "\n", "embed_dims", "=", "(", "96", ",", "192", ",", "384", ",", "768", ")", "\n", "model", "=", "_create_poolformer", "(", "\n", "'poolformer_m48'", ",", "pretrained", "=", "pretrained", ",", "layers", "=", "layers", ",", "embed_dims", "=", "embed_dims", ",", "\n", "layer_scale_init_value", "=", "1e-6", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionA.__init__": [[54, 68], ["torch.Module.__init__", "conv_block", "conv_block", "conv_block", "conv_block", "conv_block", "conv_block", "conv_block"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "pool_features", ",", "conv_block", "=", "None", ")", ":", "\n", "        ", "super", "(", "InceptionA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "conv_block", "is", "None", ":", "\n", "            ", "conv_block", "=", "BasicConv2d", "\n", "", "self", ".", "branch1x1", "=", "conv_block", "(", "in_channels", ",", "64", ",", "kernel_size", "=", "1", ")", "\n", "\n", "self", ".", "branch5x5_1", "=", "conv_block", "(", "in_channels", ",", "48", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "branch5x5_2", "=", "conv_block", "(", "48", ",", "64", ",", "kernel_size", "=", "5", ",", "padding", "=", "2", ")", "\n", "\n", "self", ".", "branch3x3dbl_1", "=", "conv_block", "(", "in_channels", ",", "64", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "branch3x3dbl_2", "=", "conv_block", "(", "64", ",", "96", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "branch3x3dbl_3", "=", "conv_block", "(", "96", ",", "96", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "\n", "self", ".", "branch_pool", "=", "conv_block", "(", "in_channels", ",", "pool_features", ",", "kernel_size", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionA._forward": [[69, 84], ["inception_v3.InceptionA.branch1x1", "inception_v3.InceptionA.branch5x5_1", "inception_v3.InceptionA.branch5x5_2", "inception_v3.InceptionA.branch3x3dbl_1", "inception_v3.InceptionA.branch3x3dbl_2", "inception_v3.InceptionA.branch3x3dbl_3", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "inception_v3.InceptionA.branch_pool"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch1x1", "=", "self", ".", "branch1x1", "(", "x", ")", "\n", "\n", "branch5x5", "=", "self", ".", "branch5x5_1", "(", "x", ")", "\n", "branch5x5", "=", "self", ".", "branch5x5_2", "(", "branch5x5", ")", "\n", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_1", "(", "x", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_2", "(", "branch3x3dbl", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_3", "(", "branch3x3dbl", ")", "\n", "\n", "branch_pool", "=", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "branch_pool", "=", "self", ".", "branch_pool", "(", "branch_pool", ")", "\n", "\n", "outputs", "=", "[", "branch1x1", ",", "branch5x5", ",", "branch3x3dbl", ",", "branch_pool", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionA.forward": [[85, 88], ["inception_v3.InceptionA._forward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.ParallelBlock._forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "_forward", "(", "x", ")", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionB.__init__": [[92, 101], ["torch.Module.__init__", "conv_block", "conv_block", "conv_block", "conv_block"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "conv_block", "=", "None", ")", ":", "\n", "        ", "super", "(", "InceptionB", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "conv_block", "is", "None", ":", "\n", "            ", "conv_block", "=", "BasicConv2d", "\n", "", "self", ".", "branch3x3", "=", "conv_block", "(", "in_channels", ",", "384", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "\n", "self", ".", "branch3x3dbl_1", "=", "conv_block", "(", "in_channels", ",", "64", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "branch3x3dbl_2", "=", "conv_block", "(", "64", ",", "96", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "branch3x3dbl_3", "=", "conv_block", "(", "96", ",", "96", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionB._forward": [[102, 113], ["inception_v3.InceptionB.branch3x3", "inception_v3.InceptionB.branch3x3dbl_1", "inception_v3.InceptionB.branch3x3dbl_2", "inception_v3.InceptionB.branch3x3dbl_3", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch3x3", "=", "self", ".", "branch3x3", "(", "x", ")", "\n", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_1", "(", "x", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_2", "(", "branch3x3dbl", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_3", "(", "branch3x3dbl", ")", "\n", "\n", "branch_pool", "=", "F", ".", "max_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "\n", "outputs", "=", "[", "branch3x3", ",", "branch3x3dbl", ",", "branch_pool", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionB.forward": [[114, 117], ["inception_v3.InceptionB._forward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.ParallelBlock._forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "_forward", "(", "x", ")", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionC.__init__": [[121, 139], ["torch.Module.__init__", "conv_block", "conv_block", "conv_block", "conv_block", "conv_block", "conv_block", "conv_block", "conv_block", "conv_block", "conv_block"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "channels_7x7", ",", "conv_block", "=", "None", ")", ":", "\n", "        ", "super", "(", "InceptionC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "conv_block", "is", "None", ":", "\n", "            ", "conv_block", "=", "BasicConv2d", "\n", "", "self", ".", "branch1x1", "=", "conv_block", "(", "in_channels", ",", "192", ",", "kernel_size", "=", "1", ")", "\n", "\n", "c7", "=", "channels_7x7", "\n", "self", ".", "branch7x7_1", "=", "conv_block", "(", "in_channels", ",", "c7", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "branch7x7_2", "=", "conv_block", "(", "c7", ",", "c7", ",", "kernel_size", "=", "(", "1", ",", "7", ")", ",", "padding", "=", "(", "0", ",", "3", ")", ")", "\n", "self", ".", "branch7x7_3", "=", "conv_block", "(", "c7", ",", "192", ",", "kernel_size", "=", "(", "7", ",", "1", ")", ",", "padding", "=", "(", "3", ",", "0", ")", ")", "\n", "\n", "self", ".", "branch7x7dbl_1", "=", "conv_block", "(", "in_channels", ",", "c7", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "branch7x7dbl_2", "=", "conv_block", "(", "c7", ",", "c7", ",", "kernel_size", "=", "(", "7", ",", "1", ")", ",", "padding", "=", "(", "3", ",", "0", ")", ")", "\n", "self", ".", "branch7x7dbl_3", "=", "conv_block", "(", "c7", ",", "c7", ",", "kernel_size", "=", "(", "1", ",", "7", ")", ",", "padding", "=", "(", "0", ",", "3", ")", ")", "\n", "self", ".", "branch7x7dbl_4", "=", "conv_block", "(", "c7", ",", "c7", ",", "kernel_size", "=", "(", "7", ",", "1", ")", ",", "padding", "=", "(", "3", ",", "0", ")", ")", "\n", "self", ".", "branch7x7dbl_5", "=", "conv_block", "(", "c7", ",", "192", ",", "kernel_size", "=", "(", "1", ",", "7", ")", ",", "padding", "=", "(", "0", ",", "3", ")", ")", "\n", "\n", "self", ".", "branch_pool", "=", "conv_block", "(", "in_channels", ",", "192", ",", "kernel_size", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionC._forward": [[140, 158], ["inception_v3.InceptionC.branch1x1", "inception_v3.InceptionC.branch7x7_1", "inception_v3.InceptionC.branch7x7_2", "inception_v3.InceptionC.branch7x7_3", "inception_v3.InceptionC.branch7x7dbl_1", "inception_v3.InceptionC.branch7x7dbl_2", "inception_v3.InceptionC.branch7x7dbl_3", "inception_v3.InceptionC.branch7x7dbl_4", "inception_v3.InceptionC.branch7x7dbl_5", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "inception_v3.InceptionC.branch_pool"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch1x1", "=", "self", ".", "branch1x1", "(", "x", ")", "\n", "\n", "branch7x7", "=", "self", ".", "branch7x7_1", "(", "x", ")", "\n", "branch7x7", "=", "self", ".", "branch7x7_2", "(", "branch7x7", ")", "\n", "branch7x7", "=", "self", ".", "branch7x7_3", "(", "branch7x7", ")", "\n", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_1", "(", "x", ")", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_2", "(", "branch7x7dbl", ")", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_3", "(", "branch7x7dbl", ")", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_4", "(", "branch7x7dbl", ")", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_5", "(", "branch7x7dbl", ")", "\n", "\n", "branch_pool", "=", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "branch_pool", "=", "self", ".", "branch_pool", "(", "branch_pool", ")", "\n", "\n", "outputs", "=", "[", "branch1x1", ",", "branch7x7", ",", "branch7x7dbl", ",", "branch_pool", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionC.forward": [[159, 162], ["inception_v3.InceptionC._forward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.ParallelBlock._forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "_forward", "(", "x", ")", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionD.__init__": [[166, 177], ["torch.Module.__init__", "conv_block", "conv_block", "conv_block", "conv_block", "conv_block", "conv_block"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "conv_block", "=", "None", ")", ":", "\n", "        ", "super", "(", "InceptionD", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "conv_block", "is", "None", ":", "\n", "            ", "conv_block", "=", "BasicConv2d", "\n", "", "self", ".", "branch3x3_1", "=", "conv_block", "(", "in_channels", ",", "192", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "branch3x3_2", "=", "conv_block", "(", "192", ",", "320", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "\n", "self", ".", "branch7x7x3_1", "=", "conv_block", "(", "in_channels", ",", "192", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "branch7x7x3_2", "=", "conv_block", "(", "192", ",", "192", ",", "kernel_size", "=", "(", "1", ",", "7", ")", ",", "padding", "=", "(", "0", ",", "3", ")", ")", "\n", "self", ".", "branch7x7x3_3", "=", "conv_block", "(", "192", ",", "192", ",", "kernel_size", "=", "(", "7", ",", "1", ")", ",", "padding", "=", "(", "3", ",", "0", ")", ")", "\n", "self", ".", "branch7x7x3_4", "=", "conv_block", "(", "192", ",", "192", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionD._forward": [[178, 190], ["inception_v3.InceptionD.branch3x3_1", "inception_v3.InceptionD.branch3x3_2", "inception_v3.InceptionD.branch7x7x3_1", "inception_v3.InceptionD.branch7x7x3_2", "inception_v3.InceptionD.branch7x7x3_3", "inception_v3.InceptionD.branch7x7x3_4", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch3x3", "=", "self", ".", "branch3x3_1", "(", "x", ")", "\n", "branch3x3", "=", "self", ".", "branch3x3_2", "(", "branch3x3", ")", "\n", "\n", "branch7x7x3", "=", "self", ".", "branch7x7x3_1", "(", "x", ")", "\n", "branch7x7x3", "=", "self", ".", "branch7x7x3_2", "(", "branch7x7x3", ")", "\n", "branch7x7x3", "=", "self", ".", "branch7x7x3_3", "(", "branch7x7x3", ")", "\n", "branch7x7x3", "=", "self", ".", "branch7x7x3_4", "(", "branch7x7x3", ")", "\n", "\n", "branch_pool", "=", "F", ".", "max_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "outputs", "=", "[", "branch3x3", ",", "branch7x7x3", ",", "branch_pool", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionD.forward": [[191, 194], ["inception_v3.InceptionD._forward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.ParallelBlock._forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "_forward", "(", "x", ")", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionE.__init__": [[198, 214], ["torch.Module.__init__", "conv_block", "conv_block", "conv_block", "conv_block", "conv_block", "conv_block", "conv_block", "conv_block", "conv_block"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "conv_block", "=", "None", ")", ":", "\n", "        ", "super", "(", "InceptionE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "conv_block", "is", "None", ":", "\n", "            ", "conv_block", "=", "BasicConv2d", "\n", "", "self", ".", "branch1x1", "=", "conv_block", "(", "in_channels", ",", "320", ",", "kernel_size", "=", "1", ")", "\n", "\n", "self", ".", "branch3x3_1", "=", "conv_block", "(", "in_channels", ",", "384", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "branch3x3_2a", "=", "conv_block", "(", "384", ",", "384", ",", "kernel_size", "=", "(", "1", ",", "3", ")", ",", "padding", "=", "(", "0", ",", "1", ")", ")", "\n", "self", ".", "branch3x3_2b", "=", "conv_block", "(", "384", ",", "384", ",", "kernel_size", "=", "(", "3", ",", "1", ")", ",", "padding", "=", "(", "1", ",", "0", ")", ")", "\n", "\n", "self", ".", "branch3x3dbl_1", "=", "conv_block", "(", "in_channels", ",", "448", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "branch3x3dbl_2", "=", "conv_block", "(", "448", ",", "384", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "branch3x3dbl_3a", "=", "conv_block", "(", "384", ",", "384", ",", "kernel_size", "=", "(", "1", ",", "3", ")", ",", "padding", "=", "(", "0", ",", "1", ")", ")", "\n", "self", ".", "branch3x3dbl_3b", "=", "conv_block", "(", "384", ",", "384", ",", "kernel_size", "=", "(", "3", ",", "1", ")", ",", "padding", "=", "(", "1", ",", "0", ")", ")", "\n", "\n", "self", ".", "branch_pool", "=", "conv_block", "(", "in_channels", ",", "192", ",", "kernel_size", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionE._forward": [[215, 238], ["inception_v3.InceptionE.branch1x1", "inception_v3.InceptionE.branch3x3_1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception_v3.InceptionE.branch3x3dbl_1", "inception_v3.InceptionE.branch3x3dbl_2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "inception_v3.InceptionE.branch_pool", "inception_v3.InceptionE.branch3x3_2a", "inception_v3.InceptionE.branch3x3_2b", "inception_v3.InceptionE.branch3x3dbl_3a", "inception_v3.InceptionE.branch3x3dbl_3b"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch1x1", "=", "self", ".", "branch1x1", "(", "x", ")", "\n", "\n", "branch3x3", "=", "self", ".", "branch3x3_1", "(", "x", ")", "\n", "branch3x3", "=", "[", "\n", "self", ".", "branch3x3_2a", "(", "branch3x3", ")", ",", "\n", "self", ".", "branch3x3_2b", "(", "branch3x3", ")", ",", "\n", "]", "\n", "branch3x3", "=", "torch", ".", "cat", "(", "branch3x3", ",", "1", ")", "\n", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_1", "(", "x", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_2", "(", "branch3x3dbl", ")", "\n", "branch3x3dbl", "=", "[", "\n", "self", ".", "branch3x3dbl_3a", "(", "branch3x3dbl", ")", ",", "\n", "self", ".", "branch3x3dbl_3b", "(", "branch3x3dbl", ")", ",", "\n", "]", "\n", "branch3x3dbl", "=", "torch", ".", "cat", "(", "branch3x3dbl", ",", "1", ")", "\n", "\n", "branch_pool", "=", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "branch_pool", "=", "self", ".", "branch_pool", "(", "branch_pool", ")", "\n", "\n", "outputs", "=", "[", "branch1x1", ",", "branch3x3", ",", "branch3x3dbl", ",", "branch_pool", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionE.forward": [[239, 242], ["inception_v3.InceptionE._forward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.ParallelBlock._forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "_forward", "(", "x", ")", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionAux.__init__": [[246, 255], ["torch.Module.__init__", "conv_block", "conv_block", "layers.Linear"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "num_classes", ",", "conv_block", "=", "None", ")", ":", "\n", "        ", "super", "(", "InceptionAux", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "conv_block", "is", "None", ":", "\n", "            ", "conv_block", "=", "BasicConv2d", "\n", "", "self", ".", "conv0", "=", "conv_block", "(", "in_channels", ",", "128", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "conv1", "=", "conv_block", "(", "128", ",", "768", ",", "kernel_size", "=", "5", ")", "\n", "self", ".", "conv1", ".", "stddev", "=", "0.01", "\n", "self", ".", "fc", "=", "Linear", "(", "768", ",", "num_classes", ")", "\n", "self", ".", "fc", ".", "stddev", "=", "0.001", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionAux.forward": [[256, 272], ["torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "inception_v3.InceptionAux.conv0", "inception_v3.InceptionAux.conv1", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "inception_v3.InceptionAux.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# N x 768 x 17 x 17", "\n", "        ", "x", "=", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", "=", "5", ",", "stride", "=", "3", ")", "\n", "# N x 768 x 5 x 5", "\n", "x", "=", "self", ".", "conv0", "(", "x", ")", "\n", "# N x 128 x 5 x 5", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "# N x 768 x 1 x 1", "\n", "# Adaptive average pooling", "\n", "x", "=", "F", ".", "adaptive_avg_pool2d", "(", "x", ",", "(", "1", ",", "1", ")", ")", "\n", "# N x 768 x 1 x 1", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "# N x 768", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "# N x 1000", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.BasicConv2d.__init__": [[276, 280], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BasicConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "bias", "=", "False", ",", "**", "kwargs", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm2d", "(", "out_channels", ",", "eps", "=", "0.001", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.BasicConv2d.forward": [[281, 285], ["inception_v3.BasicConv2d.conv", "inception_v3.BasicConv2d.bn", "torch.relu", "torch.relu", "torch.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "return", "F", ".", "relu", "(", "x", ",", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3.__init__": [[292, 338], ["torch.Module.__init__", "inception_v3.BasicConv2d", "inception_v3.BasicConv2d", "inception_v3.BasicConv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "inception_v3.BasicConv2d", "inception_v3.BasicConv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "inception_v3.InceptionA", "inception_v3.InceptionA", "inception_v3.InceptionA", "inception_v3.InceptionB", "inception_v3.InceptionC", "inception_v3.InceptionC", "inception_v3.InceptionC", "inception_v3.InceptionC", "inception_v3.InceptionD", "inception_v3.InceptionE", "inception_v3.InceptionE", "layers.create_classifier", "inception_v3.InceptionV3.modules", "inception_v3.InceptionAux", "dict", "dict", "dict", "dict", "dict", "isinstance", "isinstance", "layers.trunc_normal_", "isinstance", "hasattr", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["def", "__init__", "(", "self", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "drop_rate", "=", "0.", ",", "global_pool", "=", "'avg'", ",", "aux_logits", "=", "False", ")", ":", "\n", "        ", "super", "(", "InceptionV3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "aux_logits", "=", "aux_logits", "\n", "\n", "self", ".", "Conv2d_1a_3x3", "=", "BasicConv2d", "(", "in_chans", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "self", ".", "Conv2d_2a_3x3", "=", "BasicConv2d", "(", "32", ",", "32", ",", "kernel_size", "=", "3", ")", "\n", "self", ".", "Conv2d_2b_3x3", "=", "BasicConv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "Pool1", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "self", ".", "Conv2d_3b_1x1", "=", "BasicConv2d", "(", "64", ",", "80", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "Conv2d_4a_3x3", "=", "BasicConv2d", "(", "80", ",", "192", ",", "kernel_size", "=", "3", ")", "\n", "self", ".", "Pool2", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "self", ".", "Mixed_5b", "=", "InceptionA", "(", "192", ",", "pool_features", "=", "32", ")", "\n", "self", ".", "Mixed_5c", "=", "InceptionA", "(", "256", ",", "pool_features", "=", "64", ")", "\n", "self", ".", "Mixed_5d", "=", "InceptionA", "(", "288", ",", "pool_features", "=", "64", ")", "\n", "self", ".", "Mixed_6a", "=", "InceptionB", "(", "288", ")", "\n", "self", ".", "Mixed_6b", "=", "InceptionC", "(", "768", ",", "channels_7x7", "=", "128", ")", "\n", "self", ".", "Mixed_6c", "=", "InceptionC", "(", "768", ",", "channels_7x7", "=", "160", ")", "\n", "self", ".", "Mixed_6d", "=", "InceptionC", "(", "768", ",", "channels_7x7", "=", "160", ")", "\n", "self", ".", "Mixed_6e", "=", "InceptionC", "(", "768", ",", "channels_7x7", "=", "192", ")", "\n", "if", "aux_logits", ":", "\n", "            ", "self", ".", "AuxLogits", "=", "InceptionAux", "(", "768", ",", "num_classes", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "AuxLogits", "=", "None", "\n", "", "self", ".", "Mixed_7a", "=", "InceptionD", "(", "768", ")", "\n", "self", ".", "Mixed_7b", "=", "InceptionE", "(", "1280", ")", "\n", "self", ".", "Mixed_7c", "=", "InceptionE", "(", "2048", ")", "\n", "self", ".", "feature_info", "=", "[", "\n", "dict", "(", "num_chs", "=", "64", ",", "reduction", "=", "2", ",", "module", "=", "'Conv2d_2b_3x3'", ")", ",", "\n", "dict", "(", "num_chs", "=", "192", ",", "reduction", "=", "4", ",", "module", "=", "'Conv2d_4a_3x3'", ")", ",", "\n", "dict", "(", "num_chs", "=", "288", ",", "reduction", "=", "8", ",", "module", "=", "'Mixed_5d'", ")", ",", "\n", "dict", "(", "num_chs", "=", "768", ",", "reduction", "=", "16", ",", "module", "=", "'Mixed_6e'", ")", ",", "\n", "dict", "(", "num_chs", "=", "2048", ",", "reduction", "=", "32", ",", "module", "=", "'Mixed_7c'", ")", ",", "\n", "]", "\n", "\n", "self", ".", "num_features", "=", "2048", "\n", "self", ".", "global_pool", ",", "self", ".", "fc", "=", "create_classifier", "(", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "stddev", "=", "m", ".", "stddev", "if", "hasattr", "(", "m", ",", "'stddev'", ")", "else", "0.1", "\n", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", "stddev", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3.group_matcher": [[339, 355], ["module_map.pop", "any", "enumerate", "any", "helpers.flatten_modules", "name.startswith", "module_map.keys", "float", "inception_v3.InceptionV3.named_children", "name.startswith", "tuple", "name.split", "len"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.flatten_modules"], ["", "", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "module_map", "=", "{", "k", ":", "i", "for", "i", ",", "(", "k", ",", "_", ")", "in", "enumerate", "(", "flatten_modules", "(", "self", ".", "named_children", "(", ")", ",", "prefix", "=", "(", ")", ")", ")", "}", "\n", "module_map", ".", "pop", "(", "(", "'fc'", ",", ")", ")", "\n", "\n", "def", "_matcher", "(", "name", ")", ":", "\n", "            ", "if", "any", "(", "[", "name", ".", "startswith", "(", "n", ")", "for", "n", "in", "(", "'Conv2d_1'", ",", "'Conv2d_2'", ")", "]", ")", ":", "\n", "                ", "return", "0", "\n", "", "elif", "any", "(", "[", "name", ".", "startswith", "(", "n", ")", "for", "n", "in", "(", "'Conv2d_3'", ",", "'Conv2d_4'", ")", "]", ")", ":", "\n", "                ", "return", "1", "\n", "", "else", ":", "\n", "                ", "for", "k", "in", "module_map", ".", "keys", "(", ")", ":", "\n", "                    ", "if", "k", "==", "tuple", "(", "name", ".", "split", "(", "'.'", ")", "[", ":", "len", "(", "k", ")", "]", ")", ":", "\n", "                        ", "return", "module_map", "[", "k", "]", "\n", "", "", "return", "float", "(", "'inf'", ")", "\n", "", "", "return", "_matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3.set_grad_checkpointing": [[356, 359], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "'gradient checkpointing not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3.get_classifier": [[360, 363], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3.reset_classifier": [[364, 367], ["layers.create_classifier"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "fc", "=", "create_classifier", "(", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3.forward_preaux": [[368, 385], ["inception_v3.InceptionV3.Conv2d_1a_3x3", "inception_v3.InceptionV3.Conv2d_2a_3x3", "inception_v3.InceptionV3.Conv2d_2b_3x3", "inception_v3.InceptionV3.Pool1", "inception_v3.InceptionV3.Conv2d_3b_1x1", "inception_v3.InceptionV3.Conv2d_4a_3x3", "inception_v3.InceptionV3.Pool2", "inception_v3.InceptionV3.Mixed_5b", "inception_v3.InceptionV3.Mixed_5c", "inception_v3.InceptionV3.Mixed_5d", "inception_v3.InceptionV3.Mixed_6a", "inception_v3.InceptionV3.Mixed_6b", "inception_v3.InceptionV3.Mixed_6c", "inception_v3.InceptionV3.Mixed_6d", "inception_v3.InceptionV3.Mixed_6e"], "methods", ["None"], ["", "def", "forward_preaux", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "Conv2d_1a_3x3", "(", "x", ")", "# N x 32 x 149 x 149", "\n", "x", "=", "self", ".", "Conv2d_2a_3x3", "(", "x", ")", "# N x 32 x 147 x 147", "\n", "x", "=", "self", ".", "Conv2d_2b_3x3", "(", "x", ")", "# N x 64 x 147 x 147", "\n", "x", "=", "self", ".", "Pool1", "(", "x", ")", "# N x 64 x 73 x 73", "\n", "x", "=", "self", ".", "Conv2d_3b_1x1", "(", "x", ")", "# N x 80 x 73 x 73", "\n", "x", "=", "self", ".", "Conv2d_4a_3x3", "(", "x", ")", "# N x 192 x 71 x 71", "\n", "x", "=", "self", ".", "Pool2", "(", "x", ")", "# N x 192 x 35 x 35", "\n", "x", "=", "self", ".", "Mixed_5b", "(", "x", ")", "# N x 256 x 35 x 35", "\n", "x", "=", "self", ".", "Mixed_5c", "(", "x", ")", "# N x 288 x 35 x 35", "\n", "x", "=", "self", ".", "Mixed_5d", "(", "x", ")", "# N x 288 x 35 x 35", "\n", "x", "=", "self", ".", "Mixed_6a", "(", "x", ")", "# N x 768 x 17 x 17", "\n", "x", "=", "self", ".", "Mixed_6b", "(", "x", ")", "# N x 768 x 17 x 17", "\n", "x", "=", "self", ".", "Mixed_6c", "(", "x", ")", "# N x 768 x 17 x 17", "\n", "x", "=", "self", ".", "Mixed_6d", "(", "x", ")", "# N x 768 x 17 x 17", "\n", "x", "=", "self", ".", "Mixed_6e", "(", "x", ")", "# N x 768 x 17 x 17", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3.forward_postaux": [[386, 391], ["inception_v3.InceptionV3.Mixed_7a", "inception_v3.InceptionV3.Mixed_7b", "inception_v3.InceptionV3.Mixed_7c"], "methods", ["None"], ["", "def", "forward_postaux", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "Mixed_7a", "(", "x", ")", "# N x 1280 x 8 x 8", "\n", "x", "=", "self", ".", "Mixed_7b", "(", "x", ")", "# N x 2048 x 8 x 8", "\n", "x", "=", "self", ".", "Mixed_7c", "(", "x", ")", "# N x 2048 x 8 x 8", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3.forward_features": [[392, 396], ["inception_v3.InceptionV3.forward_preaux", "inception_v3.InceptionV3.forward_postaux"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3.forward_preaux", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3.forward_postaux"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_preaux", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_postaux", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3.forward_head": [[397, 403], ["inception_v3.InceptionV3.global_pool", "inception_v3.InceptionV3.fc", "torch.dropout", "torch.dropout", "torch.dropout"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ">", "0", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3.forward": [[404, 408], ["inception_v3.InceptionV3.forward_features", "inception_v3.InceptionV3.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3Aux.__init__": [[414, 417], ["inception_v3.InceptionV3.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "drop_rate", "=", "0.", ",", "global_pool", "=", "'avg'", ",", "aux_logits", "=", "True", ")", ":", "\n", "        ", "super", "(", "InceptionV3Aux", ",", "self", ")", ".", "__init__", "(", "\n", "num_classes", ",", "in_chans", ",", "drop_rate", ",", "global_pool", ",", "aux_logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3Aux.forward_features": [[418, 423], ["inception_v3.InceptionV3Aux.forward_preaux", "inception_v3.InceptionV3Aux.forward_postaux", "inception_v3.InceptionV3Aux.AuxLogits"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3.forward_preaux", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3.forward_postaux"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_preaux", "(", "x", ")", "\n", "aux", "=", "self", ".", "AuxLogits", "(", "x", ")", "if", "self", ".", "training", "else", "None", "\n", "x", "=", "self", ".", "forward_postaux", "(", "x", ")", "\n", "return", "x", ",", "aux", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.InceptionV3Aux.forward": [[424, 428], ["inception_v3.InceptionV3Aux.forward_features", "inception_v3.InceptionV3Aux.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", ",", "aux", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", ",", "aux", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3._cfg": [[16, 24], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "299", ",", "299", ")", ",", "'pool_size'", ":", "(", "8", ",", "8", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_INCEPTION_MEAN", ",", "'std'", ":", "IMAGENET_INCEPTION_STD", ",", "\n", "'first_conv'", ":", "'Conv2d_1a_3x3.conv'", ",", "'classifier'", ":", "'fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3._create_inception_v3": [[430, 446], ["helpers.resolve_pretrained_cfg", "kwargs.pop", "helpers.build_model_with_cfg", "kwargs.pop"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.resolve_pretrained_cfg", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_inception_v3", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "pretrained_cfg", "=", "resolve_pretrained_cfg", "(", "variant", ",", "kwargs", "=", "kwargs", ")", "\n", "aux_logits", "=", "kwargs", ".", "pop", "(", "'aux_logits'", ",", "False", ")", "\n", "if", "aux_logits", ":", "\n", "        ", "assert", "not", "kwargs", ".", "pop", "(", "'features_only'", ",", "False", ")", "\n", "model_cls", "=", "InceptionV3Aux", "\n", "load_strict", "=", "pretrained_cfg", "[", "'has_aux'", "]", "\n", "", "else", ":", "\n", "        ", "model_cls", "=", "InceptionV3", "\n", "load_strict", "=", "not", "pretrained_cfg", "[", "'has_aux'", "]", "\n", "\n", "", "return", "build_model_with_cfg", "(", "\n", "model_cls", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_cfg", "=", "pretrained_cfg", ",", "\n", "pretrained_strict", "=", "load_strict", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.inception_v3": [[448, 453], ["inception_v3._create_inception_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3._create_inception_v3"], ["", "@", "register_model", "\n", "def", "inception_v3", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "# original PyTorch weights, ported from Tensorflow but modified", "\n", "    ", "model", "=", "_create_inception_v3", "(", "'inception_v3'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.tf_inception_v3": [[455, 460], ["inception_v3._create_inception_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3._create_inception_v3"], ["", "@", "register_model", "\n", "def", "tf_inception_v3", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "# my port of Tensorflow SLIM weights (http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz)", "\n", "    ", "model", "=", "_create_inception_v3", "(", "'tf_inception_v3'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.adv_inception_v3": [[462, 468], ["inception_v3._create_inception_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3._create_inception_v3"], ["", "@", "register_model", "\n", "def", "adv_inception_v3", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "# my port of Tensorflow adversarially trained Inception V3 from", "\n", "# http://download.tensorflow.org/models/adv_inception_v3_2017_08_18.tar.gz", "\n", "    ", "model", "=", "_create_inception_v3", "(", "'adv_inception_v3'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3.gluon_inception_v3": [[470, 476], ["inception_v3._create_inception_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_v3._create_inception_v3"], ["", "@", "register_model", "\n", "def", "gluon_inception_v3", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "# from gluon pretrained models, best performing in terms of accuracy/loss metrics", "\n", "# https://gluon-cv.mxnet.io/model_zoo/classification.html", "\n", "    ", "model", "=", "_create_inception_v3", "(", "'gluon_inception_v3'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.EfficientNetBuilder.__init__": [[285, 311], ["layers.get_attn", "efficientnet_builder.EfficientNetBuilder.se_layer", "_logger.warning"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.get_attn"], ["def", "__init__", "(", "self", ",", "output_stride", "=", "32", ",", "pad_type", "=", "''", ",", "round_chs_fn", "=", "round_channels", ",", "se_from_exp", "=", "False", ",", "\n", "act_layer", "=", "None", ",", "norm_layer", "=", "None", ",", "se_layer", "=", "None", ",", "drop_path_rate", "=", "0.", ",", "feature_location", "=", "''", ")", ":", "\n", "        ", "self", ".", "output_stride", "=", "output_stride", "\n", "self", ".", "pad_type", "=", "pad_type", "\n", "self", ".", "round_chs_fn", "=", "round_chs_fn", "\n", "self", ".", "se_from_exp", "=", "se_from_exp", "# calculate se channel reduction from expanded (mid) chs", "\n", "self", ".", "act_layer", "=", "act_layer", "\n", "self", ".", "norm_layer", "=", "norm_layer", "\n", "self", ".", "se_layer", "=", "get_attn", "(", "se_layer", ")", "\n", "try", ":", "\n", "            ", "self", ".", "se_layer", "(", "8", ",", "rd_ratio", "=", "1.0", ")", "# test if attn layer accepts rd_ratio arg", "\n", "self", ".", "se_has_ratio", "=", "True", "\n", "", "except", "TypeError", ":", "\n", "            ", "self", ".", "se_has_ratio", "=", "False", "\n", "", "self", ".", "drop_path_rate", "=", "drop_path_rate", "\n", "if", "feature_location", "==", "'depthwise'", ":", "\n", "# old 'depthwise' mode renamed 'expansion' to match TF impl, old expansion mode didn't make sense", "\n", "            ", "_logger", ".", "warning", "(", "\"feature_location=='depthwise' is deprecated, using 'expansion'\"", ")", "\n", "feature_location", "=", "'expansion'", "\n", "", "self", ".", "feature_location", "=", "feature_location", "\n", "assert", "feature_location", "in", "(", "'bottleneck'", ",", "'expansion'", ",", "''", ")", "\n", "self", ".", "verbose", "=", "_DEBUG_BUILDER", "\n", "\n", "# state updated during build, consumed by model", "\n", "self", ".", "in_chs", "=", "None", "\n", "self", ".", "features", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.EfficientNetBuilder._make_block": [[312, 354], ["ba.pop", "efficientnet_builder.EfficientNetBuilder.round_chs_fn", "efficientnet_builder.EfficientNetBuilder.round_chs_fn", "ba.pop", "efficientnet_builder._log_info_if", "ba.get", "efficientnet_blocks.CondConvResidual", "efficientnet_blocks.InvertedResidual", "efficientnet_builder._log_info_if", "efficientnet_blocks.DepthwiseSeparableConv", "ba.get", "functools.partial", "str", "efficientnet_builder._log_info_if", "efficientnet_blocks.EdgeResidual", "str", "efficientnet_builder._log_info_if", "efficientnet_blocks.ConvBnAct", "str", "str"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._log_info_if", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._log_info_if", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._log_info_if", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._log_info_if"], ["", "def", "_make_block", "(", "self", ",", "ba", ",", "block_idx", ",", "block_count", ")", ":", "\n", "        ", "drop_path_rate", "=", "self", ".", "drop_path_rate", "*", "block_idx", "/", "block_count", "\n", "bt", "=", "ba", ".", "pop", "(", "'block_type'", ")", "\n", "ba", "[", "'in_chs'", "]", "=", "self", ".", "in_chs", "\n", "ba", "[", "'out_chs'", "]", "=", "self", ".", "round_chs_fn", "(", "ba", "[", "'out_chs'", "]", ")", "\n", "if", "'force_in_chs'", "in", "ba", "and", "ba", "[", "'force_in_chs'", "]", ":", "\n", "# NOTE this is a hack to work around mismatch in TF EdgeEffNet impl", "\n", "            ", "ba", "[", "'force_in_chs'", "]", "=", "self", ".", "round_chs_fn", "(", "ba", "[", "'force_in_chs'", "]", ")", "\n", "", "ba", "[", "'pad_type'", "]", "=", "self", ".", "pad_type", "\n", "# block act fn overrides the model default", "\n", "ba", "[", "'act_layer'", "]", "=", "ba", "[", "'act_layer'", "]", "if", "ba", "[", "'act_layer'", "]", "is", "not", "None", "else", "self", ".", "act_layer", "\n", "assert", "ba", "[", "'act_layer'", "]", "is", "not", "None", "\n", "ba", "[", "'norm_layer'", "]", "=", "self", ".", "norm_layer", "\n", "ba", "[", "'drop_path_rate'", "]", "=", "drop_path_rate", "\n", "if", "bt", "!=", "'cn'", ":", "\n", "            ", "se_ratio", "=", "ba", ".", "pop", "(", "'se_ratio'", ")", "\n", "if", "se_ratio", "and", "self", ".", "se_layer", "is", "not", "None", ":", "\n", "                ", "if", "not", "self", ".", "se_from_exp", ":", "\n", "# adjust se_ratio by expansion ratio if calculating se channels from block input", "\n", "                    ", "se_ratio", "/=", "ba", ".", "get", "(", "'exp_ratio'", ",", "1.0", ")", "\n", "", "if", "self", ".", "se_has_ratio", ":", "\n", "                    ", "ba", "[", "'se_layer'", "]", "=", "partial", "(", "self", ".", "se_layer", ",", "rd_ratio", "=", "se_ratio", ")", "\n", "", "else", ":", "\n", "                    ", "ba", "[", "'se_layer'", "]", "=", "self", ".", "se_layer", "\n", "\n", "", "", "", "if", "bt", "==", "'ir'", ":", "\n", "            ", "_log_info_if", "(", "'  InvertedResidual {}, Args: {}'", ".", "format", "(", "block_idx", ",", "str", "(", "ba", ")", ")", ",", "self", ".", "verbose", ")", "\n", "block", "=", "CondConvResidual", "(", "**", "ba", ")", "if", "ba", ".", "get", "(", "'num_experts'", ",", "0", ")", "else", "InvertedResidual", "(", "**", "ba", ")", "\n", "", "elif", "bt", "==", "'ds'", "or", "bt", "==", "'dsa'", ":", "\n", "            ", "_log_info_if", "(", "'  DepthwiseSeparable {}, Args: {}'", ".", "format", "(", "block_idx", ",", "str", "(", "ba", ")", ")", ",", "self", ".", "verbose", ")", "\n", "block", "=", "DepthwiseSeparableConv", "(", "**", "ba", ")", "\n", "", "elif", "bt", "==", "'er'", ":", "\n", "            ", "_log_info_if", "(", "'  EdgeResidual {}, Args: {}'", ".", "format", "(", "block_idx", ",", "str", "(", "ba", ")", ")", ",", "self", ".", "verbose", ")", "\n", "block", "=", "EdgeResidual", "(", "**", "ba", ")", "\n", "", "elif", "bt", "==", "'cn'", ":", "\n", "            ", "_log_info_if", "(", "'  ConvBnAct {}, Args: {}'", ".", "format", "(", "block_idx", ",", "str", "(", "ba", ")", ")", ",", "self", ".", "verbose", ")", "\n", "block", "=", "ConvBnAct", "(", "**", "ba", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "'Uknkown block type (%s) while building model.'", "%", "bt", "\n", "\n", "", "self", ".", "in_chs", "=", "ba", "[", "'out_chs'", "]", "# update in_chs for arg of next block", "\n", "return", "block", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.EfficientNetBuilder.__call__": [[355, 430], ["efficientnet_builder._log_info_if", "sum", "enumerate", "dict", "efficientnet_builder.EfficientNetBuilder.features.append", "efficientnet_builder._log_info_if", "isinstance", "enumerate", "stages.append", "len", "len", "len", "efficientnet_builder._log_info_if", "efficientnet_builder.EfficientNetBuilder._make_block", "blocks.append", "torch.Sequential", "len", "dict", "dict.get", "efficientnet_builder.EfficientNetBuilder.features.append", "efficientnet_builder._log_info_if", "len", "efficientnet_builder.EfficientNetBuilder.feature_info"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._log_info_if", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._log_info_if", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._log_info_if", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.EfficientNetBuilder._make_block", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._log_info_if", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_blocks.EdgeResidual.feature_info"], ["", "def", "__call__", "(", "self", ",", "in_chs", ",", "model_block_args", ")", ":", "\n", "        ", "\"\"\" Build the blocks\n        Args:\n            in_chs: Number of input-channels passed to first block\n            model_block_args: A list of lists, outer list defines stages, inner\n                list contains strings defining block configuration(s)\n        Return:\n             List of block stacks (each stack wrapped in nn.Sequential)\n        \"\"\"", "\n", "_log_info_if", "(", "'Building model trunk with %d stages...'", "%", "len", "(", "model_block_args", ")", ",", "self", ".", "verbose", ")", "\n", "self", ".", "in_chs", "=", "in_chs", "\n", "total_block_count", "=", "sum", "(", "[", "len", "(", "x", ")", "for", "x", "in", "model_block_args", "]", ")", "\n", "total_block_idx", "=", "0", "\n", "current_stride", "=", "2", "\n", "current_dilation", "=", "1", "\n", "stages", "=", "[", "]", "\n", "if", "model_block_args", "[", "0", "]", "[", "0", "]", "[", "'stride'", "]", ">", "1", ":", "\n", "# if the first block starts with a stride, we need to extract first level feat from stem", "\n", "            ", "feature_info", "=", "dict", "(", "\n", "module", "=", "'act1'", ",", "num_chs", "=", "in_chs", ",", "stage", "=", "0", ",", "reduction", "=", "current_stride", ",", "\n", "hook_type", "=", "'forward'", "if", "self", ".", "feature_location", "!=", "'bottleneck'", "else", "''", ")", "\n", "self", ".", "features", ".", "append", "(", "feature_info", ")", "\n", "\n", "# outer list of block_args defines the stacks", "\n", "", "for", "stack_idx", ",", "stack_args", "in", "enumerate", "(", "model_block_args", ")", ":", "\n", "            ", "last_stack", "=", "stack_idx", "+", "1", "==", "len", "(", "model_block_args", ")", "\n", "_log_info_if", "(", "'Stack: {}'", ".", "format", "(", "stack_idx", ")", ",", "self", ".", "verbose", ")", "\n", "assert", "isinstance", "(", "stack_args", ",", "list", ")", "\n", "\n", "blocks", "=", "[", "]", "\n", "# each stack (stage of blocks) contains a list of block arguments", "\n", "for", "block_idx", ",", "block_args", "in", "enumerate", "(", "stack_args", ")", ":", "\n", "                ", "last_block", "=", "block_idx", "+", "1", "==", "len", "(", "stack_args", ")", "\n", "_log_info_if", "(", "' Block: {}'", ".", "format", "(", "block_idx", ")", ",", "self", ".", "verbose", ")", "\n", "\n", "assert", "block_args", "[", "'stride'", "]", "in", "(", "1", ",", "2", ")", "\n", "if", "block_idx", ">=", "1", ":", "# only the first block in any stack can have a stride > 1", "\n", "                    ", "block_args", "[", "'stride'", "]", "=", "1", "\n", "\n", "", "extract_features", "=", "False", "\n", "if", "last_block", ":", "\n", "                    ", "next_stack_idx", "=", "stack_idx", "+", "1", "\n", "extract_features", "=", "next_stack_idx", ">=", "len", "(", "model_block_args", ")", "or", "model_block_args", "[", "next_stack_idx", "]", "[", "0", "]", "[", "'stride'", "]", ">", "1", "\n", "\n", "", "next_dilation", "=", "current_dilation", "\n", "if", "block_args", "[", "'stride'", "]", ">", "1", ":", "\n", "                    ", "next_output_stride", "=", "current_stride", "*", "block_args", "[", "'stride'", "]", "\n", "if", "next_output_stride", ">", "self", ".", "output_stride", ":", "\n", "                        ", "next_dilation", "=", "current_dilation", "*", "block_args", "[", "'stride'", "]", "\n", "block_args", "[", "'stride'", "]", "=", "1", "\n", "_log_info_if", "(", "'  Converting stride to dilation to maintain output_stride=={}'", ".", "format", "(", "\n", "self", ".", "output_stride", ")", ",", "self", ".", "verbose", ")", "\n", "", "else", ":", "\n", "                        ", "current_stride", "=", "next_output_stride", "\n", "", "", "block_args", "[", "'dilation'", "]", "=", "current_dilation", "\n", "if", "next_dilation", "!=", "current_dilation", ":", "\n", "                    ", "current_dilation", "=", "next_dilation", "\n", "\n", "# create the block", "\n", "", "block", "=", "self", ".", "_make_block", "(", "block_args", ",", "total_block_idx", ",", "total_block_count", ")", "\n", "blocks", ".", "append", "(", "block", ")", "\n", "\n", "# stash feature module name and channel info for model feature extraction", "\n", "if", "extract_features", ":", "\n", "                    ", "feature_info", "=", "dict", "(", "\n", "stage", "=", "stack_idx", "+", "1", ",", "reduction", "=", "current_stride", ",", "**", "block", ".", "feature_info", "(", "self", ".", "feature_location", ")", ")", "\n", "module_name", "=", "f'blocks.{stack_idx}.{block_idx}'", "\n", "leaf_name", "=", "feature_info", ".", "get", "(", "'module'", ",", "''", ")", "\n", "feature_info", "[", "'module'", "]", "=", "'.'", ".", "join", "(", "[", "module_name", ",", "leaf_name", "]", ")", "if", "leaf_name", "else", "module_name", "\n", "self", ".", "features", ".", "append", "(", "feature_info", ")", "\n", "\n", "", "total_block_idx", "+=", "1", "# incr global block idx (across all stacks)", "\n", "", "stages", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "blocks", ")", ")", "\n", "", "return", "stages", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.get_bn_args_tf": [[38, 40], ["_BN_ARGS_TF.copy"], "function", ["None"], ["def", "get_bn_args_tf", "(", ")", ":", "\n", "    ", "return", "_BN_ARGS_TF", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args": [[42, 51], ["kwargs.pop", "kwargs.pop"], "function", ["None"], ["", "def", "resolve_bn_args", "(", "kwargs", ")", ":", "\n", "    ", "bn_args", "=", "{", "}", "\n", "bn_momentum", "=", "kwargs", ".", "pop", "(", "'bn_momentum'", ",", "None", ")", "\n", "if", "bn_momentum", "is", "not", "None", ":", "\n", "        ", "bn_args", "[", "'momentum'", "]", "=", "bn_momentum", "\n", "", "bn_eps", "=", "kwargs", ".", "pop", "(", "'bn_eps'", ",", "None", ")", "\n", "if", "bn_eps", "is", "not", "None", ":", "\n", "        ", "bn_args", "[", "'eps'", "]", "=", "bn_eps", "\n", "", "return", "bn_args", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer": [[53, 55], ["layers.get_act_layer", "kwargs.pop"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer"], ["", "def", "resolve_act_layer", "(", "kwargs", ",", "default", "=", "'relu'", ")", ":", "\n", "    ", "return", "get_act_layer", "(", "kwargs", ".", "pop", "(", "'act_layer'", ",", "default", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.round_channels": [[57, 62], ["layers.make_divisible"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["", "def", "round_channels", "(", "channels", ",", "multiplier", "=", "1.0", ",", "divisor", "=", "8", ",", "channel_min", "=", "None", ",", "round_limit", "=", "0.9", ")", ":", "\n", "    ", "\"\"\"Round number of filters based on depth multiplier.\"\"\"", "\n", "if", "not", "multiplier", ":", "\n", "        ", "return", "channels", "\n", "", "return", "make_divisible", "(", "channels", "*", "multiplier", ",", "divisor", ",", "channel_min", ",", "round_limit", "=", "round_limit", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._log_info_if": [[64, 67], ["_logger.info"], "function", ["None"], ["", "def", "_log_info_if", "(", "msg", ",", "condition", ")", ":", "\n", "    ", "if", "condition", ":", "\n", "        ", "_logger", ".", "info", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._parse_ksize": [[69, 74], ["ss.isdigit", "int", "int", "ss.split"], "function", ["None"], ["", "", "def", "_parse_ksize", "(", "ss", ")", ":", "\n", "    ", "if", "ss", ".", "isdigit", "(", ")", ":", "\n", "        ", "return", "int", "(", "ss", ")", "\n", "", "else", ":", "\n", "        ", "return", "[", "int", "(", "k", ")", "for", "k", "in", "ss", ".", "split", "(", "'.'", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._decode_block_str": [[76, 190], ["isinstance", "block_str.split", "int", "dict", "efficientnet_builder._parse_ksize", "efficientnet_builder._parse_ksize", "int", "dict.update", "int", "int", "dict", "int", "dict.update", "op.startswith", "dict", "dict.update", "re.split", "efficientnet_builder._parse_ksize", "float", "dict", "dict.update", "layers.get_act_layer", "len", "float", "efficientnet_builder._parse_ksize", "dict", "layers.get_act_layer", "float", "efficientnet_builder._parse_ksize", "float", "layers.get_act_layer", "float", "int", "layers.get_act_layer", "layers.get_act_layer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._parse_ksize", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._parse_ksize", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._parse_ksize", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._parse_ksize", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._parse_ksize", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer"], ["", "", "def", "_decode_block_str", "(", "block_str", ")", ":", "\n", "    ", "\"\"\" Decode block definition string\n\n    Gets a list of block arg (dicts) through a string notation of arguments.\n    E.g. ir_r2_k3_s2_e1_i32_o16_se0.25_noskip\n\n    All args can exist in any order with the exception of the leading string which\n    is assumed to indicate the block type.\n\n    leading string - block type (\n      ir = InvertedResidual, ds = DepthwiseSep, dsa = DeptwhiseSep with pw act, cn = ConvBnAct)\n    r - number of repeat blocks,\n    k - kernel size,\n    s - strides (1-9),\n    e - expansion ratio,\n    c - output channels,\n    se - squeeze/excitation ratio\n    n - activation fn ('re', 'r6', 'hs', or 'sw')\n    Args:\n        block_str: a string representation of block arguments.\n    Returns:\n        A list of block args (dicts)\n    Raises:\n        ValueError: if the string def not properly specified (TODO)\n    \"\"\"", "\n", "assert", "isinstance", "(", "block_str", ",", "str", ")", "\n", "ops", "=", "block_str", ".", "split", "(", "'_'", ")", "\n", "block_type", "=", "ops", "[", "0", "]", "# take the block type off the front", "\n", "ops", "=", "ops", "[", "1", ":", "]", "\n", "options", "=", "{", "}", "\n", "skip", "=", "None", "\n", "for", "op", "in", "ops", ":", "\n", "# string options being checked on individual basis, combine if they grow", "\n", "        ", "if", "op", "==", "'noskip'", ":", "\n", "            ", "skip", "=", "False", "# force no skip connection", "\n", "", "elif", "op", "==", "'skip'", ":", "\n", "            ", "skip", "=", "True", "# force a skip connection", "\n", "", "elif", "op", ".", "startswith", "(", "'n'", ")", ":", "\n", "# activation fn", "\n", "            ", "key", "=", "op", "[", "0", "]", "\n", "v", "=", "op", "[", "1", ":", "]", "\n", "if", "v", "==", "'re'", ":", "\n", "                ", "value", "=", "get_act_layer", "(", "'relu'", ")", "\n", "", "elif", "v", "==", "'r6'", ":", "\n", "                ", "value", "=", "get_act_layer", "(", "'relu6'", ")", "\n", "", "elif", "v", "==", "'hs'", ":", "\n", "                ", "value", "=", "get_act_layer", "(", "'hard_swish'", ")", "\n", "", "elif", "v", "==", "'sw'", ":", "\n", "                ", "value", "=", "get_act_layer", "(", "'swish'", ")", "# aka SiLU", "\n", "", "elif", "v", "==", "'mi'", ":", "\n", "                ", "value", "=", "get_act_layer", "(", "'mish'", ")", "\n", "", "else", ":", "\n", "                ", "continue", "\n", "", "options", "[", "key", "]", "=", "value", "\n", "", "else", ":", "\n", "# all numeric options", "\n", "            ", "splits", "=", "re", ".", "split", "(", "r'(\\d.*)'", ",", "op", ")", "\n", "if", "len", "(", "splits", ")", ">=", "2", ":", "\n", "                ", "key", ",", "value", "=", "splits", "[", ":", "2", "]", "\n", "options", "[", "key", "]", "=", "value", "\n", "\n", "# if act_layer is None, the model default (passed to model init) will be used", "\n", "", "", "", "act_layer", "=", "options", "[", "'n'", "]", "if", "'n'", "in", "options", "else", "None", "\n", "exp_kernel_size", "=", "_parse_ksize", "(", "options", "[", "'a'", "]", ")", "if", "'a'", "in", "options", "else", "1", "\n", "pw_kernel_size", "=", "_parse_ksize", "(", "options", "[", "'p'", "]", ")", "if", "'p'", "in", "options", "else", "1", "\n", "force_in_chs", "=", "int", "(", "options", "[", "'fc'", "]", ")", "if", "'fc'", "in", "options", "else", "0", "# FIXME hack to deal with in_chs issue in TPU def", "\n", "num_repeat", "=", "int", "(", "options", "[", "'r'", "]", ")", "\n", "\n", "# each type of block has different valid arguments, fill accordingly", "\n", "block_args", "=", "dict", "(", "\n", "block_type", "=", "block_type", ",", "\n", "out_chs", "=", "int", "(", "options", "[", "'c'", "]", ")", ",", "\n", "stride", "=", "int", "(", "options", "[", "'s'", "]", ")", ",", "\n", "act_layer", "=", "act_layer", ",", "\n", ")", "\n", "if", "block_type", "==", "'ir'", ":", "\n", "        ", "block_args", ".", "update", "(", "dict", "(", "\n", "dw_kernel_size", "=", "_parse_ksize", "(", "options", "[", "'k'", "]", ")", ",", "\n", "exp_kernel_size", "=", "exp_kernel_size", ",", "\n", "pw_kernel_size", "=", "pw_kernel_size", ",", "\n", "exp_ratio", "=", "float", "(", "options", "[", "'e'", "]", ")", ",", "\n", "se_ratio", "=", "float", "(", "options", "[", "'se'", "]", ")", "if", "'se'", "in", "options", "else", "0.", ",", "\n", "noskip", "=", "skip", "is", "False", ",", "\n", ")", ")", "\n", "if", "'cc'", "in", "options", ":", "\n", "            ", "block_args", "[", "'num_experts'", "]", "=", "int", "(", "options", "[", "'cc'", "]", ")", "\n", "", "", "elif", "block_type", "==", "'ds'", "or", "block_type", "==", "'dsa'", ":", "\n", "        ", "block_args", ".", "update", "(", "dict", "(", "\n", "dw_kernel_size", "=", "_parse_ksize", "(", "options", "[", "'k'", "]", ")", ",", "\n", "pw_kernel_size", "=", "pw_kernel_size", ",", "\n", "se_ratio", "=", "float", "(", "options", "[", "'se'", "]", ")", "if", "'se'", "in", "options", "else", "0.", ",", "\n", "pw_act", "=", "block_type", "==", "'dsa'", ",", "\n", "noskip", "=", "block_type", "==", "'dsa'", "or", "skip", "is", "False", ",", "\n", ")", ")", "\n", "", "elif", "block_type", "==", "'er'", ":", "\n", "        ", "block_args", ".", "update", "(", "dict", "(", "\n", "exp_kernel_size", "=", "_parse_ksize", "(", "options", "[", "'k'", "]", ")", ",", "\n", "pw_kernel_size", "=", "pw_kernel_size", ",", "\n", "exp_ratio", "=", "float", "(", "options", "[", "'e'", "]", ")", ",", "\n", "force_in_chs", "=", "force_in_chs", ",", "\n", "se_ratio", "=", "float", "(", "options", "[", "'se'", "]", ")", "if", "'se'", "in", "options", "else", "0.", ",", "\n", "noskip", "=", "skip", "is", "False", ",", "\n", ")", ")", "\n", "", "elif", "block_type", "==", "'cn'", ":", "\n", "        ", "block_args", ".", "update", "(", "dict", "(", "\n", "kernel_size", "=", "int", "(", "options", "[", "'k'", "]", ")", ",", "\n", "skip", "=", "skip", "is", "True", ",", "\n", ")", ")", "\n", "", "else", ":", "\n", "        ", "assert", "False", ",", "'Unknown block type (%s)'", "%", "block_type", "\n", "", "if", "'gs'", "in", "options", ":", "\n", "        ", "block_args", "[", "'group_size'", "]", "=", "options", "[", "'gs'", "]", "\n", "\n", "", "return", "block_args", ",", "num_repeat", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._scale_stage_depth": [[192, 228], ["sum", "zip", "max", "int", "max", "repeats_scaled.append", "sa_scaled.extend", "round", "math.ceil", "round", "copy.deepcopy", "range"], "function", ["None"], ["", "def", "_scale_stage_depth", "(", "stack_args", ",", "repeats", ",", "depth_multiplier", "=", "1.0", ",", "depth_trunc", "=", "'ceil'", ")", ":", "\n", "    ", "\"\"\" Per-stage depth scaling\n    Scales the block repeats in each stage. This depth scaling impl maintains\n    compatibility with the EfficientNet scaling method, while allowing sensible\n    scaling for other models that may have multiple block arg definitions in each stage.\n    \"\"\"", "\n", "\n", "# We scale the total repeat count for each stage, there may be multiple", "\n", "# block arg defs per stage so we need to sum.", "\n", "num_repeat", "=", "sum", "(", "repeats", ")", "\n", "if", "depth_trunc", "==", "'round'", ":", "\n", "# Truncating to int by rounding allows stages with few repeats to remain", "\n", "# proportionally smaller for longer. This is a good choice when stage definitions", "\n", "# include single repeat stages that we'd prefer to keep that way as long as possible", "\n", "        ", "num_repeat_scaled", "=", "max", "(", "1", ",", "round", "(", "num_repeat", "*", "depth_multiplier", ")", ")", "\n", "", "else", ":", "\n", "# The default for EfficientNet truncates repeats to int via 'ceil'.", "\n", "# Any multiplier > 1.0 will result in an increased depth for every stage.", "\n", "        ", "num_repeat_scaled", "=", "int", "(", "math", ".", "ceil", "(", "num_repeat", "*", "depth_multiplier", ")", ")", "\n", "\n", "# Proportionally distribute repeat count scaling to each block definition in the stage.", "\n", "# Allocation is done in reverse as it results in the first block being less likely to be scaled.", "\n", "# The first block makes less sense to repeat in most of the arch definitions.", "\n", "", "repeats_scaled", "=", "[", "]", "\n", "for", "r", "in", "repeats", "[", ":", ":", "-", "1", "]", ":", "\n", "        ", "rs", "=", "max", "(", "1", ",", "round", "(", "(", "r", "/", "num_repeat", "*", "num_repeat_scaled", ")", ")", ")", "\n", "repeats_scaled", ".", "append", "(", "rs", ")", "\n", "num_repeat", "-=", "r", "\n", "num_repeat_scaled", "-=", "rs", "\n", "", "repeats_scaled", "=", "repeats_scaled", "[", ":", ":", "-", "1", "]", "\n", "\n", "# Apply the calculated scaling to each block arg in the stage", "\n", "sa_scaled", "=", "[", "]", "\n", "for", "ba", ",", "rep", "in", "zip", "(", "stack_args", ",", "repeats_scaled", ")", ":", "\n", "        ", "sa_scaled", ".", "extend", "(", "[", "deepcopy", "(", "ba", ")", "for", "_", "in", "range", "(", "rep", ")", "]", ")", "\n", "", "return", "sa_scaled", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def": [[230, 274], ["isinstance", "enumerate", "zip", "isinstance", "len", "len", "len", "isinstance", "efficientnet_builder._decode_block_str", "stack_args.append", "repeats.append", "arch_args.append", "arch_args.append", "ba.setdefault", "efficientnet_builder._scale_stage_depth", "efficientnet_builder._scale_stage_depth", "ba.get", "len"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._decode_block_str", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._scale_stage_depth", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._scale_stage_depth", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["", "def", "decode_arch_def", "(", "\n", "arch_def", ",", "\n", "depth_multiplier", "=", "1.0", ",", "\n", "depth_trunc", "=", "'ceil'", ",", "\n", "experts_multiplier", "=", "1", ",", "\n", "fix_first_last", "=", "False", ",", "\n", "group_size", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\" Decode block architecture definition strings -> block kwargs\n\n    Args:\n        arch_def: architecture definition strings, list of list of strings\n        depth_multiplier: network depth multiplier\n        depth_trunc: networ depth truncation mode when applying multiplier\n        experts_multiplier: CondConv experts multiplier\n        fix_first_last: fix first and last block depths when multiplier is applied\n        group_size: group size override for all blocks that weren't explicitly set in arch string\n\n    Returns:\n        list of list of block kwargs\n    \"\"\"", "\n", "arch_args", "=", "[", "]", "\n", "if", "isinstance", "(", "depth_multiplier", ",", "tuple", ")", ":", "\n", "        ", "assert", "len", "(", "depth_multiplier", ")", "==", "len", "(", "arch_def", ")", "\n", "", "else", ":", "\n", "        ", "depth_multiplier", "=", "(", "depth_multiplier", ",", ")", "*", "len", "(", "arch_def", ")", "\n", "", "for", "stack_idx", ",", "(", "block_strings", ",", "multiplier", ")", "in", "enumerate", "(", "zip", "(", "arch_def", ",", "depth_multiplier", ")", ")", ":", "\n", "        ", "assert", "isinstance", "(", "block_strings", ",", "list", ")", "\n", "stack_args", "=", "[", "]", "\n", "repeats", "=", "[", "]", "\n", "for", "block_str", "in", "block_strings", ":", "\n", "            ", "assert", "isinstance", "(", "block_str", ",", "str", ")", "\n", "ba", ",", "rep", "=", "_decode_block_str", "(", "block_str", ")", "\n", "if", "ba", ".", "get", "(", "'num_experts'", ",", "0", ")", ">", "0", "and", "experts_multiplier", ">", "1", ":", "\n", "                ", "ba", "[", "'num_experts'", "]", "*=", "experts_multiplier", "\n", "", "if", "group_size", "is", "not", "None", ":", "\n", "                ", "ba", ".", "setdefault", "(", "'group_size'", ",", "group_size", ")", "\n", "", "stack_args", ".", "append", "(", "ba", ")", "\n", "repeats", ".", "append", "(", "rep", ")", "\n", "", "if", "fix_first_last", "and", "(", "stack_idx", "==", "0", "or", "stack_idx", "==", "len", "(", "arch_def", ")", "-", "1", ")", ":", "\n", "            ", "arch_args", ".", "append", "(", "_scale_stage_depth", "(", "stack_args", ",", "repeats", ",", "1.0", ",", "depth_trunc", ")", ")", "\n", "", "else", ":", "\n", "            ", "arch_args", ".", "append", "(", "_scale_stage_depth", "(", "stack_args", ",", "repeats", ",", "multiplier", ",", "depth_trunc", ")", ")", "\n", "", "", "return", "arch_args", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder._init_weight_goog": [[432, 471], ["isinstance", "layers.get_condconv_initializer", "layers.get_condconv_initializer.", "isinstance", "torch.init.zeros_", "torch.init.normal_", "isinstance", "torch.init.normal_", "math.sqrt", "torch.init.zeros_", "torch.init.ones_", "torch.init.zeros_", "isinstance", "math.sqrt", "m.weight.size", "torch.init.uniform_", "torch.init.zeros_", "m.weight.size", "math.sqrt"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cond_conv2d.get_condconv_initializer"], ["", "", "def", "_init_weight_goog", "(", "m", ",", "n", "=", "''", ",", "fix_group_fanout", "=", "True", ")", ":", "\n", "    ", "\"\"\" Weight initialization as per Tensorflow official implementations.\n\n    Args:\n        m (nn.Module): module to init\n        n (str): module name\n        fix_group_fanout (bool): enable correct (matching Tensorflow TPU impl) fanout calculation w/ group convs\n\n    Handles layers in EfficientNet, EfficientNet-CondConv, MixNet, MnasNet, MobileNetV3, etc:\n    * https://github.com/tensorflow/tpu/blob/master/models/official/mnasnet/mnasnet_model.py\n    * https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/efficientnet_model.py\n    \"\"\"", "\n", "if", "isinstance", "(", "m", ",", "CondConv2d", ")", ":", "\n", "        ", "fan_out", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "if", "fix_group_fanout", ":", "\n", "            ", "fan_out", "//=", "m", ".", "groups", "\n", "", "init_weight_fn", "=", "get_condconv_initializer", "(", "\n", "lambda", "w", ":", "nn", ".", "init", ".", "normal_", "(", "w", ",", "0", ",", "math", ".", "sqrt", "(", "2.0", "/", "fan_out", ")", ")", ",", "m", ".", "num_experts", ",", "m", ".", "weight_shape", ")", "\n", "init_weight_fn", "(", "m", ".", "weight", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "        ", "fan_out", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "if", "fix_group_fanout", ":", "\n", "            ", "fan_out", "//=", "m", ".", "groups", "\n", "", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "0", ",", "math", ".", "sqrt", "(", "2.0", "/", "fan_out", ")", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "nn", ".", "init", ".", "ones_", "(", "m", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "fan_out", "=", "m", ".", "weight", ".", "size", "(", "0", ")", "# fan-out", "\n", "fan_in", "=", "0", "\n", "if", "'routing_fn'", "in", "n", ":", "\n", "            ", "fan_in", "=", "m", ".", "weight", ".", "size", "(", "1", ")", "\n", "", "init_range", "=", "1.0", "/", "math", ".", "sqrt", "(", "fan_in", "+", "fan_out", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "m", ".", "weight", ",", "-", "init_range", ",", "init_range", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.efficientnet_init_weights": [[473, 477], ["model.named_modules", "init_fn"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules"], ["", "", "def", "efficientnet_init_weights", "(", "model", ":", "nn", ".", "Module", ",", "init_fn", "=", "None", ")", ":", "\n", "    ", "init_fn", "=", "init_fn", "or", "_init_weight_goog", "\n", "for", "n", ",", "m", "in", "model", ".", "named_modules", "(", ")", ":", "\n", "        ", "init_fn", "(", "m", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.HybridEmbed.__init__": [[103, 133], ["torch.Module.__init__", "isinstance", "layers.to_2tuple", "layers.to_2tuple", "torch.Conv2d", "torch.Conv2d", "layers.to_2tuple", "hasattr", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "vision_transformer_hybrid.HybridEmbed.backbone", "isinstance", "backbone.train", "backbone.eval", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "vision_transformer_hybrid.HybridEmbed.backbone.feature_info.channels"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.AttentionSubsample.train", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.channels"], ["def", "__init__", "(", "self", ",", "backbone", ",", "img_size", "=", "224", ",", "patch_size", "=", "1", ",", "feature_size", "=", "None", ",", "in_chans", "=", "3", ",", "embed_dim", "=", "768", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "backbone", ",", "nn", ".", "Module", ")", "\n", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "patch_size", "=", "to_2tuple", "(", "patch_size", ")", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "self", ".", "backbone", "=", "backbone", "\n", "if", "feature_size", "is", "None", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# NOTE Most reliable way of determining output dims is to run forward pass", "\n", "                ", "training", "=", "backbone", ".", "training", "\n", "if", "training", ":", "\n", "                    ", "backbone", ".", "eval", "(", ")", "\n", "", "o", "=", "self", ".", "backbone", "(", "torch", ".", "zeros", "(", "1", ",", "in_chans", ",", "img_size", "[", "0", "]", ",", "img_size", "[", "1", "]", ")", ")", "\n", "if", "isinstance", "(", "o", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                    ", "o", "=", "o", "[", "-", "1", "]", "# last feature if backbone outputs list/tuple of features", "\n", "", "feature_size", "=", "o", ".", "shape", "[", "-", "2", ":", "]", "\n", "feature_dim", "=", "o", ".", "shape", "[", "1", "]", "\n", "backbone", ".", "train", "(", "training", ")", "\n", "", "", "else", ":", "\n", "            ", "feature_size", "=", "to_2tuple", "(", "feature_size", ")", "\n", "if", "hasattr", "(", "self", ".", "backbone", ",", "'feature_info'", ")", ":", "\n", "                ", "feature_dim", "=", "self", ".", "backbone", ".", "feature_info", ".", "channels", "(", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "feature_dim", "=", "self", ".", "backbone", ".", "num_features", "\n", "", "", "assert", "feature_size", "[", "0", "]", "%", "patch_size", "[", "0", "]", "==", "0", "and", "feature_size", "[", "1", "]", "%", "patch_size", "[", "1", "]", "==", "0", "\n", "self", ".", "grid_size", "=", "(", "feature_size", "[", "0", "]", "//", "patch_size", "[", "0", "]", ",", "feature_size", "[", "1", "]", "//", "patch_size", "[", "1", "]", ")", "\n", "self", ".", "num_patches", "=", "self", ".", "grid_size", "[", "0", "]", "*", "self", ".", "grid_size", "[", "1", "]", "\n", "self", ".", "proj", "=", "nn", ".", "Conv2d", "(", "feature_dim", ",", "embed_dim", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "patch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.HybridEmbed.forward": [[134, 140], ["vision_transformer_hybrid.HybridEmbed.backbone", "isinstance", "vision_transformer_hybrid.HybridEmbed.proj().flatten().transpose", "vision_transformer_hybrid.HybridEmbed.proj().flatten", "vision_transformer_hybrid.HybridEmbed.proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "backbone", "(", "x", ")", "\n", "if", "isinstance", "(", "x", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "x", "=", "x", "[", "-", "1", "]", "# last feature if backbone outputs list/tuple of features", "\n", "", "x", "=", "self", ".", "proj", "(", "x", ")", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._cfg": [[29, 37], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", ".9", ",", "'interpolation'", ":", "'bicubic'", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'mean'", ":", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "'std'", ":", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "\n", "'first_conv'", ":", "'patch_embed.backbone.stem.conv'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid": [[142, 146], ["functools.partial", "kwargs.setdefault", "models.vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "", "def", "_create_vision_transformer_hybrid", "(", "variant", ",", "backbone", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "embed_layer", "=", "partial", "(", "HybridEmbed", ",", "backbone", "=", "backbone", ")", "\n", "kwargs", ".", "setdefault", "(", "'patch_size'", ",", "1", ")", "# default patch size for hybrid models if not set", "\n", "return", "_create_vision_transformer", "(", "variant", ",", "pretrained", "=", "pretrained", ",", "embed_layer", "=", "embed_layer", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._resnetv2": [[148, 161], ["kwargs.get", "len", "functools.partial", "functools.partial", "resnetv2.ResNetV2", "resnetv2.create_resnetv2_stem", "kwargs.get", "kwargs.get"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.create_resnetv2_stem", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["", "def", "_resnetv2", "(", "layers", "=", "(", "3", ",", "4", ",", "9", ")", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResNet-V2 backbone helper\"\"\"", "\n", "padding_same", "=", "kwargs", ".", "get", "(", "'padding_same'", ",", "True", ")", "\n", "stem_type", "=", "'same'", "if", "padding_same", "else", "''", "\n", "conv_layer", "=", "partial", "(", "StdConv2dSame", ",", "eps", "=", "1e-8", ")", "if", "padding_same", "else", "partial", "(", "StdConv2d", ",", "eps", "=", "1e-8", ")", "\n", "if", "len", "(", "layers", ")", ":", "\n", "        ", "backbone", "=", "ResNetV2", "(", "\n", "layers", "=", "layers", ",", "num_classes", "=", "0", ",", "global_pool", "=", "''", ",", "in_chans", "=", "kwargs", ".", "get", "(", "'in_chans'", ",", "3", ")", ",", "\n", "preact", "=", "False", ",", "stem_type", "=", "stem_type", ",", "conv_layer", "=", "conv_layer", ")", "\n", "", "else", ":", "\n", "        ", "backbone", "=", "create_resnetv2_stem", "(", "\n", "kwargs", ".", "get", "(", "'in_chans'", ",", "3", ")", ",", "stem_type", "=", "stem_type", ",", "preact", "=", "False", ",", "conv_layer", "=", "conv_layer", ")", "\n", "", "return", "backbone", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_tiny_r_s16_p8_224": [[163, 172], ["vision_transformer_hybrid._resnetv2", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._resnetv2", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid"], ["", "@", "register_model", "\n", "def", "vit_tiny_r_s16_p8_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" R+ViT-Ti/S16 w/ 8x8 patch hybrid @ 224 x 224.\n    \"\"\"", "\n", "backbone", "=", "_resnetv2", "(", "layers", "=", "(", ")", ",", "**", "kwargs", ")", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "8", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "3", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_tiny_r_s16_p8_224'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_tiny_r_s16_p8_384": [[174, 183], ["vision_transformer_hybrid._resnetv2", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._resnetv2", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid"], ["", "@", "register_model", "\n", "def", "vit_tiny_r_s16_p8_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" R+ViT-Ti/S16 w/ 8x8 patch hybrid @ 384 x 384.\n    \"\"\"", "\n", "backbone", "=", "_resnetv2", "(", "layers", "=", "(", ")", ",", "**", "kwargs", ")", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "8", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "3", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_tiny_r_s16_p8_384'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_small_r26_s32_224": [[185, 194], ["vision_transformer_hybrid._resnetv2", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._resnetv2", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid"], ["", "@", "register_model", "\n", "def", "vit_small_r26_s32_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" R26+ViT-S/S32 hybrid.\n    \"\"\"", "\n", "backbone", "=", "_resnetv2", "(", "(", "2", ",", "2", ",", "2", ",", "2", ")", ",", "**", "kwargs", ")", "\n", "model_kwargs", "=", "dict", "(", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_small_r26_s32_224'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_small_r26_s32_384": [[196, 205], ["vision_transformer_hybrid._resnetv2", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._resnetv2", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid"], ["", "@", "register_model", "\n", "def", "vit_small_r26_s32_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" R26+ViT-S/S32 hybrid.\n    \"\"\"", "\n", "backbone", "=", "_resnetv2", "(", "(", "2", ",", "2", ",", "2", ",", "2", ")", ",", "**", "kwargs", ")", "\n", "model_kwargs", "=", "dict", "(", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_small_r26_s32_384'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_base_r26_s32_224": [[207, 216], ["vision_transformer_hybrid._resnetv2", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._resnetv2", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid"], ["", "@", "register_model", "\n", "def", "vit_base_r26_s32_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" R26+ViT-B/S32 hybrid.\n    \"\"\"", "\n", "backbone", "=", "_resnetv2", "(", "(", "2", ",", "2", ",", "2", ",", "2", ")", ",", "**", "kwargs", ")", "\n", "model_kwargs", "=", "dict", "(", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_base_r26_s32_224'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_base_r50_s16_224": [[218, 227], ["vision_transformer_hybrid._resnetv2", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._resnetv2", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid"], ["", "@", "register_model", "\n", "def", "vit_base_r50_s16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" R50+ViT-B/S16 hybrid from original paper (https://arxiv.org/abs/2010.11929).\n    \"\"\"", "\n", "backbone", "=", "_resnetv2", "(", "(", "3", ",", "4", ",", "9", ")", ",", "**", "kwargs", ")", "\n", "model_kwargs", "=", "dict", "(", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_base_r50_s16_224'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_base_r50_s16_384": [[229, 239], ["vision_transformer_hybrid._resnetv2", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._resnetv2", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid"], ["", "@", "register_model", "\n", "def", "vit_base_r50_s16_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" R50+ViT-B/16 hybrid from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 384x384, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "backbone", "=", "_resnetv2", "(", "(", "3", ",", "4", ",", "9", ")", ",", "**", "kwargs", ")", "\n", "model_kwargs", "=", "dict", "(", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_base_r50_s16_384'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_base_resnet50_384": [[241, 245], ["vision_transformer_hybrid.vit_base_r50_s16_384"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_base_r50_s16_384"], ["", "@", "register_model", "\n", "def", "vit_base_resnet50_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "# DEPRECATED this is forwarding to model def above for backwards compatibility", "\n", "    ", "return", "vit_base_r50_s16_384", "(", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_large_r50_s32_224": [[247, 256], ["vision_transformer_hybrid._resnetv2", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._resnetv2", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid"], ["", "@", "register_model", "\n", "def", "vit_large_r50_s32_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" R50+ViT-L/S32 hybrid.\n    \"\"\"", "\n", "backbone", "=", "_resnetv2", "(", "(", "3", ",", "4", ",", "6", ",", "3", ")", ",", "**", "kwargs", ")", "\n", "model_kwargs", "=", "dict", "(", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_large_r50_s32_224'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_large_r50_s32_384": [[258, 267], ["vision_transformer_hybrid._resnetv2", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._resnetv2", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid"], ["", "@", "register_model", "\n", "def", "vit_large_r50_s32_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" R50+ViT-L/S32 hybrid.\n    \"\"\"", "\n", "backbone", "=", "_resnetv2", "(", "(", "3", ",", "4", ",", "6", ",", "3", ")", ",", "**", "kwargs", ")", "\n", "model_kwargs", "=", "dict", "(", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_large_r50_s32_384'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_tiny_r_s16_p8_224_in21k": [[269, 278], ["vision_transformer_hybrid._resnetv2", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._resnetv2", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid"], ["", "@", "register_model", "\n", "def", "vit_tiny_r_s16_p8_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" R+ViT-Ti/S16 w/ 8x8 patch hybrid.  ImageNet-21k.\n    \"\"\"", "\n", "backbone", "=", "_resnetv2", "(", "layers", "=", "(", ")", ",", "**", "kwargs", ")", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "8", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "3", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_tiny_r_s16_p8_224_in21k'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_small_r26_s32_224_in21k": [[280, 289], ["vision_transformer_hybrid._resnetv2", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._resnetv2", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid"], ["", "@", "register_model", "\n", "def", "vit_small_r26_s32_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" R26+ViT-S/S32 hybrid. ImageNet-21k.\n    \"\"\"", "\n", "backbone", "=", "_resnetv2", "(", "(", "2", ",", "2", ",", "2", ",", "2", ")", ",", "**", "kwargs", ")", "\n", "model_kwargs", "=", "dict", "(", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_small_r26_s32_224_in21k'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_base_r50_s16_224_in21k": [[291, 301], ["vision_transformer_hybrid._resnetv2", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._resnetv2", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid"], ["", "@", "register_model", "\n", "def", "vit_base_r50_s16_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" R50+ViT-B/16 hybrid model from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "backbone", "=", "_resnetv2", "(", "layers", "=", "(", "3", ",", "4", ",", "9", ")", ",", "**", "kwargs", ")", "\n", "model_kwargs", "=", "dict", "(", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "representation_size", "=", "768", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_base_r50_s16_224_in21k'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_base_resnet50_224_in21k": [[303, 307], ["vision_transformer_hybrid.vit_base_r50_s16_224_in21k"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_base_r50_s16_224_in21k"], ["", "@", "register_model", "\n", "def", "vit_base_resnet50_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "# DEPRECATED this is forwarding to model def above for backwards compatibility", "\n", "    ", "return", "vit_base_r50_s16_224_in21k", "(", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_large_r50_s32_224_in21k": [[309, 318], ["vision_transformer_hybrid._resnetv2", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._resnetv2", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid"], ["", "@", "register_model", "\n", "def", "vit_large_r50_s32_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" R50+ViT-L/S32 hybrid. ImageNet-21k.\n    \"\"\"", "\n", "backbone", "=", "_resnetv2", "(", "(", "3", ",", "4", ",", "6", ",", "3", ")", ",", "**", "kwargs", ")", "\n", "model_kwargs", "=", "dict", "(", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_large_r50_s32_224_in21k'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_small_resnet26d_224": [[320, 329], ["resnet.resnet26d", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid", "kwargs.get"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet26d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["", "@", "register_model", "\n", "def", "vit_small_resnet26d_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Custom ViT small hybrid w/ ResNet26D stride 32. No pretrained weights.\n    \"\"\"", "\n", "backbone", "=", "resnet26d", "(", "pretrained", "=", "pretrained", ",", "in_chans", "=", "kwargs", ".", "get", "(", "'in_chans'", ",", "3", ")", ",", "features_only", "=", "True", ",", "out_indices", "=", "[", "4", "]", ")", "\n", "model_kwargs", "=", "dict", "(", "embed_dim", "=", "768", ",", "depth", "=", "8", ",", "num_heads", "=", "8", ",", "mlp_ratio", "=", "3", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_small_resnet26d_224'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_small_resnet50d_s16_224": [[331, 340], ["resnet.resnet50d", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid", "kwargs.get"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet50d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["", "@", "register_model", "\n", "def", "vit_small_resnet50d_s16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Custom ViT small hybrid w/ ResNet50D 3-stages, stride 16. No pretrained weights.\n    \"\"\"", "\n", "backbone", "=", "resnet50d", "(", "pretrained", "=", "pretrained", ",", "in_chans", "=", "kwargs", ".", "get", "(", "'in_chans'", ",", "3", ")", ",", "features_only", "=", "True", ",", "out_indices", "=", "[", "3", "]", ")", "\n", "model_kwargs", "=", "dict", "(", "embed_dim", "=", "768", ",", "depth", "=", "8", ",", "num_heads", "=", "8", ",", "mlp_ratio", "=", "3", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_small_resnet50d_s16_224'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_base_resnet26d_224": [[342, 351], ["resnet.resnet26d", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid", "kwargs.get"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet26d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["", "@", "register_model", "\n", "def", "vit_base_resnet26d_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Custom ViT base hybrid w/ ResNet26D stride 32. No pretrained weights.\n    \"\"\"", "\n", "backbone", "=", "resnet26d", "(", "pretrained", "=", "pretrained", ",", "in_chans", "=", "kwargs", ".", "get", "(", "'in_chans'", ",", "3", ")", ",", "features_only", "=", "True", ",", "out_indices", "=", "[", "4", "]", ")", "\n", "model_kwargs", "=", "dict", "(", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_base_resnet26d_224'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid.vit_base_resnet50d_224": [[353, 362], ["resnet.resnet50d", "dict", "vision_transformer_hybrid._create_vision_transformer_hybrid", "kwargs.get"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet50d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer_hybrid._create_vision_transformer_hybrid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["", "@", "register_model", "\n", "def", "vit_base_resnet50d_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Custom ViT base hybrid w/ ResNet50D stride 32. No pretrained weights.\n    \"\"\"", "\n", "backbone", "=", "resnet50d", "(", "pretrained", "=", "pretrained", ",", "in_chans", "=", "kwargs", ".", "get", "(", "'in_chans'", ",", "3", ")", ",", "features_only", "=", "True", ",", "out_indices", "=", "[", "4", "]", ")", "\n", "model_kwargs", "=", "dict", "(", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer_hybrid", "(", "\n", "'vit_base_resnet50d_224'", ",", "backbone", "=", "backbone", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.ConvMlp.__init__": [[59, 70], ["torch.Module.__init__", "int", "conv_layer", "act_layer", "torch.Dropout", "torch.Dropout", "torch.Dropout", "conv_layer", "act_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_features", "=", "512", ",", "out_features", "=", "4096", ",", "kernel_size", "=", "7", ",", "mlp_ratio", "=", "1.0", ",", "\n", "drop_rate", ":", "float", "=", "0.2", ",", "act_layer", ":", "nn", ".", "Module", "=", "None", ",", "conv_layer", ":", "nn", ".", "Module", "=", "None", ")", ":", "\n", "        ", "super", "(", "ConvMlp", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_kernel_size", "=", "kernel_size", "\n", "mid_features", "=", "int", "(", "out_features", "*", "mlp_ratio", ")", "\n", "self", ".", "fc1", "=", "conv_layer", "(", "in_features", ",", "mid_features", ",", "kernel_size", ",", "bias", "=", "True", ")", "\n", "self", ".", "act1", "=", "act_layer", "(", "True", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "drop_rate", ")", "\n", "self", ".", "fc2", "=", "conv_layer", "(", "mid_features", ",", "out_features", ",", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "act2", "=", "act_layer", "(", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.ConvMlp.forward": [[71, 82], ["vgg.ConvMlp.fc1", "vgg.ConvMlp.act1", "vgg.ConvMlp.drop", "vgg.ConvMlp.fc2", "vgg.ConvMlp.act2", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "max", "max"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "x", ".", "shape", "[", "-", "2", "]", "<", "self", ".", "input_kernel_size", "or", "x", ".", "shape", "[", "-", "1", "]", "<", "self", ".", "input_kernel_size", ":", "\n", "# keep the input size >= 7x7", "\n", "            ", "output_size", "=", "(", "max", "(", "self", ".", "input_kernel_size", ",", "x", ".", "shape", "[", "-", "2", "]", ")", ",", "max", "(", "self", ".", "input_kernel_size", ",", "x", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "x", "=", "F", ".", "adaptive_avg_pool2d", "(", "x", ",", "output_size", ")", "\n", "", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "self", ".", "act1", "(", "x", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "act2", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.VGG.__init__": [[86, 135], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "vgg.VGG.feature_info.append", "vgg.ConvMlp", "layers.ClassifierHead", "vgg.VGG._initialize_weights", "dict", "len", "vgg.VGG.feature_info.append", "typing.cast", "conv_layer", "dict", "pool_layer", "norm_layer", "act_layer", "act_layer", "len"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.VGG._initialize_weights"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ":", "List", "[", "Any", "]", ",", "\n", "num_classes", ":", "int", "=", "1000", ",", "\n", "in_chans", ":", "int", "=", "3", ",", "\n", "output_stride", ":", "int", "=", "32", ",", "\n", "mlp_ratio", ":", "float", "=", "1.0", ",", "\n", "act_layer", ":", "nn", ".", "Module", "=", "nn", ".", "ReLU", ",", "\n", "conv_layer", ":", "nn", ".", "Module", "=", "nn", ".", "Conv2d", ",", "\n", "norm_layer", ":", "nn", ".", "Module", "=", "None", ",", "\n", "global_pool", ":", "str", "=", "'avg'", ",", "\n", "drop_rate", ":", "float", "=", "0.", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "VGG", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "output_stride", "==", "32", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_features", "=", "4096", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "self", ".", "use_norm", "=", "norm_layer", "is", "not", "None", "\n", "self", ".", "feature_info", "=", "[", "]", "\n", "prev_chs", "=", "in_chans", "\n", "net_stride", "=", "1", "\n", "pool_layer", "=", "nn", ".", "MaxPool2d", "\n", "layers", ":", "List", "[", "nn", ".", "Module", "]", "=", "[", "]", "\n", "for", "v", "in", "cfg", ":", "\n", "            ", "last_idx", "=", "len", "(", "layers", ")", "-", "1", "\n", "if", "v", "==", "'M'", ":", "\n", "                ", "self", ".", "feature_info", ".", "append", "(", "dict", "(", "num_chs", "=", "prev_chs", ",", "reduction", "=", "net_stride", ",", "module", "=", "f'features.{last_idx}'", ")", ")", "\n", "layers", "+=", "[", "pool_layer", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", "]", "\n", "net_stride", "*=", "2", "\n", "", "else", ":", "\n", "                ", "v", "=", "cast", "(", "int", ",", "v", ")", "\n", "conv2d", "=", "conv_layer", "(", "prev_chs", ",", "v", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "if", "norm_layer", "is", "not", "None", ":", "\n", "                    ", "layers", "+=", "[", "conv2d", ",", "norm_layer", "(", "v", ")", ",", "act_layer", "(", "inplace", "=", "True", ")", "]", "\n", "", "else", ":", "\n", "                    ", "layers", "+=", "[", "conv2d", ",", "act_layer", "(", "inplace", "=", "True", ")", "]", "\n", "", "prev_chs", "=", "v", "\n", "", "", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "self", ".", "feature_info", ".", "append", "(", "dict", "(", "num_chs", "=", "prev_chs", ",", "reduction", "=", "net_stride", ",", "module", "=", "f'features.{len(layers) - 1}'", ")", ")", "\n", "\n", "self", ".", "pre_logits", "=", "ConvMlp", "(", "\n", "prev_chs", ",", "self", ".", "num_features", ",", "7", ",", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "drop_rate", "=", "drop_rate", ",", "act_layer", "=", "act_layer", ",", "conv_layer", "=", "conv_layer", ")", "\n", "self", ".", "head", "=", "ClassifierHead", "(", "\n", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "drop_rate", ")", "\n", "\n", "self", ".", "_initialize_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.VGG.group_matcher": [[136, 140], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "# this treats BN layers as separate groups for bn variants, a lot of effort to fix that", "\n", "        ", "return", "dict", "(", "stem", "=", "r'^features\\.0'", ",", "blocks", "=", "r'^features\\.(\\d+)'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.VGG.set_grad_checkpointing": [[141, 144], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "'gradient checkpointing not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.VGG.get_classifier": [[145, 148], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.VGG.reset_classifier": [[149, 153], ["layers.ClassifierHead"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "head", "=", "ClassifierHead", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "self", ".", "drop_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.VGG.forward_features": [[154, 157], ["vgg.VGG.features"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.VGG.forward_head": [[158, 161], ["vgg.VGG.pre_logits", "vgg.VGG.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "pre_logits", "(", "x", ")", "\n", "return", "x", "if", "pre_logits", "else", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.VGG.forward": [[162, 166], ["vgg.VGG.forward_features", "vgg.VGG.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.VGG._initialize_weights": [[167, 179], ["vgg.VGG.modules", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "isinstance", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "_initialize_weights", "(", "self", ")", "->", "None", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "0", ",", "0.01", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg._cfg": [[25, 33], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bilinear'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'features.0'", ",", "'classifier'", ":", "'head.fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg._filter_fn": [[181, 195], ["state_dict.items", "k_r.replace.replace", "k_r.replace.replace", "k_r.replace.replace", "v.reshape.reshape", "v.reshape.reshape"], "function", ["None"], ["", "", "", "", "def", "_filter_fn", "(", "state_dict", ")", ":", "\n", "    ", "\"\"\" convert patch embedding weight from manual patchify + linear proj to conv\"\"\"", "\n", "out_dict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "k_r", "=", "k", "\n", "k_r", "=", "k_r", ".", "replace", "(", "'classifier.0'", ",", "'pre_logits.fc1'", ")", "\n", "k_r", "=", "k_r", ".", "replace", "(", "'classifier.3'", ",", "'pre_logits.fc2'", ")", "\n", "k_r", "=", "k_r", ".", "replace", "(", "'classifier.6'", ",", "'head.fc'", ")", "\n", "if", "'classifier.0.weight'", "in", "k", ":", "\n", "            ", "v", "=", "v", ".", "reshape", "(", "-", "1", ",", "512", ",", "7", ",", "7", ")", "\n", "", "if", "'classifier.3.weight'", "in", "k", ":", "\n", "            ", "v", "=", "v", ".", "reshape", "(", "-", "1", ",", "4096", ",", "1", ",", "1", ")", "\n", "", "out_dict", "[", "k_r", "]", "=", "v", "\n", "", "return", "out_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg._create_vgg": [[197, 208], ["kwargs.pop", "helpers.build_model_with_cfg", "variant.split", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "def", "_create_vgg", "(", "variant", ":", "str", ",", "pretrained", ":", "bool", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "cfg", "=", "variant", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "# NOTE: VGG is one of few models with stride==1 features w/ 6 out_indices [0..5]", "\n", "out_indices", "=", "kwargs", ".", "pop", "(", "'out_indices'", ",", "(", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", ")", ")", "\n", "model", "=", "build_model_with_cfg", "(", "\n", "VGG", ",", "variant", ",", "pretrained", ",", "\n", "model_cfg", "=", "cfgs", "[", "cfg", "]", ",", "\n", "feature_cfg", "=", "dict", "(", "flatten_sequential", "=", "True", ",", "out_indices", "=", "out_indices", ")", ",", "\n", "pretrained_filter_fn", "=", "_filter_fn", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.vgg11": [[210, 217], ["dict", "vgg._create_vgg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg._create_vgg"], ["", "@", "register_model", "\n", "def", "vgg11", "(", "pretrained", ":", "bool", "=", "False", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "r\"\"\"VGG 11-layer model (configuration \"A\") from\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "**", "kwargs", ")", "\n", "return", "_create_vgg", "(", "'vgg11'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.vgg11_bn": [[219, 226], ["dict", "vgg._create_vgg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg._create_vgg"], ["", "@", "register_model", "\n", "def", "vgg11_bn", "(", "pretrained", ":", "bool", "=", "False", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "r\"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "**", "kwargs", ")", "\n", "return", "_create_vgg", "(", "'vgg11_bn'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.vgg13": [[228, 235], ["dict", "vgg._create_vgg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg._create_vgg"], ["", "@", "register_model", "\n", "def", "vgg13", "(", "pretrained", ":", "bool", "=", "False", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "r\"\"\"VGG 13-layer model (configuration \"B\")\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "**", "kwargs", ")", "\n", "return", "_create_vgg", "(", "'vgg13'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.vgg13_bn": [[237, 244], ["dict", "vgg._create_vgg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg._create_vgg"], ["", "@", "register_model", "\n", "def", "vgg13_bn", "(", "pretrained", ":", "bool", "=", "False", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "r\"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "**", "kwargs", ")", "\n", "return", "_create_vgg", "(", "'vgg13_bn'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.vgg16": [[246, 253], ["dict", "vgg._create_vgg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg._create_vgg"], ["", "@", "register_model", "\n", "def", "vgg16", "(", "pretrained", ":", "bool", "=", "False", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "r\"\"\"VGG 16-layer model (configuration \"D\")\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "**", "kwargs", ")", "\n", "return", "_create_vgg", "(", "'vgg16'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.vgg16_bn": [[255, 262], ["dict", "vgg._create_vgg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg._create_vgg"], ["", "@", "register_model", "\n", "def", "vgg16_bn", "(", "pretrained", ":", "bool", "=", "False", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "r\"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "**", "kwargs", ")", "\n", "return", "_create_vgg", "(", "'vgg16_bn'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.vgg19": [[264, 271], ["dict", "vgg._create_vgg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg._create_vgg"], ["", "@", "register_model", "\n", "def", "vgg19", "(", "pretrained", ":", "bool", "=", "False", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "r\"\"\"VGG 19-layer model (configuration \"E\")\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "**", "kwargs", ")", "\n", "return", "_create_vgg", "(", "'vgg19'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg.vgg19_bn": [[273, 280], ["dict", "vgg._create_vgg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vgg._create_vgg"], ["", "@", "register_model", "\n", "def", "vgg19_bn", "(", "pretrained", ":", "bool", "=", "False", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "r\"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "**", "kwargs", ")", "\n", "return", "_create_vgg", "(", "'vgg19_bn'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.WindowMultiHeadAttention.__init__": [[153, 185], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "layers.Mlp", "swin_transformer_v2_cr.WindowMultiHeadAttention.register_parameter", "swin_transformer_v2_cr.WindowMultiHeadAttention._make_pair_wise_relative_positions", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.WindowMultiHeadAttention._make_pair_wise_relative_positions"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dim", ":", "int", ",", "\n", "num_heads", ":", "int", ",", "\n", "window_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "\n", "drop_attn", ":", "float", "=", "0.0", ",", "\n", "drop_proj", ":", "float", "=", "0.0", ",", "\n", "meta_hidden_dim", ":", "int", "=", "384", ",", "# FIXME what's the optimal value?", "\n", "sequential_attn", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "WindowMultiHeadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "dim", "%", "num_heads", "==", "0", ",", "\"The number of input features (in_features) are not divisible by the number of heads (num_heads).\"", "\n", "self", ".", "in_features", ":", "int", "=", "dim", "\n", "self", ".", "window_size", ":", "Tuple", "[", "int", ",", "int", "]", "=", "window_size", "\n", "self", ".", "num_heads", ":", "int", "=", "num_heads", "\n", "self", ".", "sequential_attn", ":", "bool", "=", "sequential_attn", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "in_features", "=", "dim", ",", "out_features", "=", "dim", "*", "3", ",", "bias", "=", "True", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "drop_attn", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "in_features", "=", "dim", ",", "out_features", "=", "dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "drop_proj", ")", "\n", "# meta network for positional encodings", "\n", "self", ".", "meta_mlp", "=", "Mlp", "(", "\n", "2", ",", "# x, y", "\n", "hidden_features", "=", "meta_hidden_dim", ",", "\n", "out_features", "=", "num_heads", ",", "\n", "act_layer", "=", "nn", ".", "ReLU", ",", "\n", "drop", "=", "0.1", "# FIXME should there be stochasticity, appears to 'overfit' without?", "\n", ")", "\n", "self", ".", "register_parameter", "(", "\"tau\"", ",", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_heads", ")", ")", ")", "\n", "self", ".", "_make_pair_wise_relative_positions", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.WindowMultiHeadAttention._make_pair_wise_relative_positions": [[186, 197], ["torch.stack().flatten", "torch.stack().flatten", "torch.stack().flatten", "torch.stack().flatten", "torch.stack().flatten", "torch.stack().flatten", "torch.stack().flatten", "torch.stack().flatten", "torch.stack().flatten", "relative_coordinates.permute().reshape().float.permute().reshape().float.permute().reshape().float", "swin_transformer_v2_cr.WindowMultiHeadAttention.register_buffer", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "relative_coordinates.permute().reshape().float.permute().reshape().float.permute().reshape", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "relative_coordinates.permute().reshape().float.permute().reshape().float.abs", "relative_coordinates.permute().reshape().float.permute().reshape().float.permute", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["None"], ["", "def", "_make_pair_wise_relative_positions", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"Method initializes the pair-wise relative positions to compute the positional biases.\"\"\"", "\n", "device", "=", "self", ".", "tau", ".", "device", "\n", "coordinates", "=", "torch", ".", "stack", "(", "torch", ".", "meshgrid", "(", "[", "\n", "torch", ".", "arange", "(", "self", ".", "window_size", "[", "0", "]", ",", "device", "=", "device", ")", ",", "\n", "torch", ".", "arange", "(", "self", ".", "window_size", "[", "1", "]", ",", "device", "=", "device", ")", "]", ")", ",", "dim", "=", "0", ")", ".", "flatten", "(", "1", ")", "\n", "relative_coordinates", "=", "coordinates", "[", ":", ",", ":", ",", "None", "]", "-", "coordinates", "[", ":", ",", "None", ",", ":", "]", "\n", "relative_coordinates", "=", "relative_coordinates", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "reshape", "(", "-", "1", ",", "2", ")", ".", "float", "(", ")", "\n", "relative_coordinates_log", "=", "torch", ".", "sign", "(", "relative_coordinates", ")", "*", "torch", ".", "log", "(", "\n", "1.0", "+", "relative_coordinates", ".", "abs", "(", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"relative_coordinates_log\"", ",", "relative_coordinates_log", ",", "persistent", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.WindowMultiHeadAttention.update_input_size": [[198, 208], ["swin_transformer_v2_cr.WindowMultiHeadAttention._make_pair_wise_relative_positions"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.WindowMultiHeadAttention._make_pair_wise_relative_positions"], ["", "def", "update_input_size", "(", "self", ",", "new_window_size", ":", "int", ",", "**", "kwargs", ":", "Any", ")", "->", "None", ":", "\n", "        ", "\"\"\"Method updates the window size and so the pair-wise relative positions\n\n        Args:\n            new_window_size (int): New window size\n            kwargs (Any): Unused\n        \"\"\"", "\n", "# Set new window size and new pair-wise relative positions", "\n", "self", ".", "window_size", ":", "int", "=", "new_window_size", "\n", "self", ".", "_make_pair_wise_relative_positions", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.WindowMultiHeadAttention._relative_positional_encodings": [[209, 223], ["swin_transformer_v2_cr.WindowMultiHeadAttention.meta_mlp", "relative_position_bias.unsqueeze.unsqueeze.transpose().reshape", "relative_position_bias.unsqueeze.unsqueeze.unsqueeze", "relative_position_bias.unsqueeze.unsqueeze.transpose"], "methods", ["None"], ["", "def", "_relative_positional_encodings", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Method computes the relative positional encodings\n\n        Returns:\n            relative_position_bias (torch.Tensor): Relative positional encodings\n            (1, number of heads, window size ** 2, window size ** 2)\n        \"\"\"", "\n", "window_area", "=", "self", ".", "window_size", "[", "0", "]", "*", "self", ".", "window_size", "[", "1", "]", "\n", "relative_position_bias", "=", "self", ".", "meta_mlp", "(", "self", ".", "relative_coordinates_log", ")", "\n", "relative_position_bias", "=", "relative_position_bias", ".", "transpose", "(", "1", ",", "0", ")", ".", "reshape", "(", "\n", "self", ".", "num_heads", ",", "window_area", ",", "window_area", "\n", ")", "\n", "relative_position_bias", "=", "relative_position_bias", ".", "unsqueeze", "(", "0", ")", "\n", "return", "relative_position_bias", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.WindowMultiHeadAttention._forward_sequential": [[224, 233], ["None"], "methods", ["None"], ["", "def", "_forward_sequential", "(", "\n", "self", ",", "\n", "x", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "# FIXME TODO figure out 'sequential' attention mentioned in paper (should reduce GPU memory)", "\n", "assert", "False", ",", "\"not implemented\"", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.WindowMultiHeadAttention._forward_batch": [[234, 264], ["swin_transformer_v2_cr.WindowMultiHeadAttention.qkv().view().permute", "swin_transformer_v2_cr.WindowMultiHeadAttention.unbind", "attn.view.view.softmax", "swin_transformer_v2_cr.WindowMultiHeadAttention.attn_drop", "swin_transformer_v2_cr.WindowMultiHeadAttention.proj", "swin_transformer_v2_cr.WindowMultiHeadAttention.proj_drop", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm().transpose", "torch.norm().transpose", "torch.norm().transpose", "torch.norm().transpose", "torch.norm().transpose", "torch.norm().transpose", "torch.norm().transpose", "torch.norm().transpose", "torch.norm().transpose", "denom.clamp", "swin_transformer_v2_cr.WindowMultiHeadAttention.tau.clamp().reshape", "swin_transformer_v2_cr.WindowMultiHeadAttention._relative_positional_encodings", "attn.view.view.view", "attn.view.view.view", "swin_transformer_v2_cr.WindowMultiHeadAttention.qkv().view", "key.transpose", "mask.unsqueeze().unsqueeze", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "swin_transformer_v2_cr.WindowMultiHeadAttention.tau.clamp", "swin_transformer_v2_cr.WindowMultiHeadAttention.qkv", "mask.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.WindowMultiHeadAttention._relative_positional_encodings"], ["", "def", "_forward_batch", "(", "\n", "self", ",", "\n", "x", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"This function performs standard (non-sequential) scaled cosine self-attention.\n        \"\"\"", "\n", "Bw", ",", "L", ",", "C", "=", "x", ".", "shape", "\n", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", ".", "view", "(", "Bw", ",", "L", ",", "3", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "query", ",", "key", ",", "value", "=", "qkv", ".", "unbind", "(", "0", ")", "\n", "\n", "# compute attention map with scaled cosine attention", "\n", "denom", "=", "torch", ".", "norm", "(", "query", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "@", "torch", ".", "norm", "(", "key", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", "\n", "attn", "=", "query", "@", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", "/", "denom", ".", "clamp", "(", "min", "=", "1e-6", ")", "\n", "attn", "=", "attn", "/", "self", ".", "tau", ".", "clamp", "(", "min", "=", "0.01", ")", ".", "reshape", "(", "1", ",", "self", ".", "num_heads", ",", "1", ",", "1", ")", "\n", "attn", "=", "attn", "+", "self", ".", "_relative_positional_encodings", "(", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "# Apply mask if utilized", "\n", "            ", "num_win", ":", "int", "=", "mask", ".", "shape", "[", "0", "]", "\n", "attn", "=", "attn", ".", "view", "(", "Bw", "//", "num_win", ",", "num_win", ",", "self", ".", "num_heads", ",", "L", ",", "L", ")", "\n", "attn", "=", "attn", "+", "mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "0", ")", "\n", "attn", "=", "attn", ".", "view", "(", "-", "1", ",", "self", ".", "num_heads", ",", "L", ",", "L", ")", "\n", "", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "value", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "Bw", ",", "L", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.WindowMultiHeadAttention.forward": [[265, 278], ["swin_transformer_v2_cr.WindowMultiHeadAttention._forward_sequential", "swin_transformer_v2_cr.WindowMultiHeadAttention._forward_batch"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.WindowMultiHeadAttention._forward_sequential", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.WindowMultiHeadAttention._forward_batch"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\" Forward pass.\n        Args:\n            x (torch.Tensor): Input tensor of the shape (B * windows, N, C)\n            mask (Optional[torch.Tensor]): Attention mask for the shift case\n\n        Returns:\n            Output tensor of the shape [B * windows, N, C]\n        \"\"\"", "\n", "if", "self", ".", "sequential_attn", ":", "\n", "            ", "return", "self", ".", "_forward_sequential", "(", "x", ",", "mask", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_forward_batch", "(", "x", ",", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerBlock.__init__": [[298, 347], ["torch.Module.__init__", "layers.to_2tuple", "swin_transformer_v2_cr.SwinTransformerBlock._calc_window_shift", "swin_transformer_v2_cr.WindowMultiHeadAttention", "norm_layer", "layers.Mlp", "norm_layer", "swin_transformer_v2_cr.SwinTransformerBlock._make_attention_mask", "layers.to_2tuple", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "norm_layer", "torch.Identity", "torch.Identity", "torch.Identity", "int"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerBlock._calc_window_shift", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerBlock._make_attention_mask"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dim", ":", "int", ",", "\n", "num_heads", ":", "int", ",", "\n", "feat_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "\n", "window_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "\n", "shift_size", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "0", ",", "0", ")", ",", "\n", "mlp_ratio", ":", "float", "=", "4.0", ",", "\n", "drop", ":", "float", "=", "0.0", ",", "\n", "drop_attn", ":", "float", "=", "0.0", ",", "\n", "drop_path", ":", "float", "=", "0.0", ",", "\n", "extra_norm", ":", "bool", "=", "False", ",", "\n", "sequential_attn", ":", "bool", "=", "False", ",", "\n", "norm_layer", ":", "Type", "[", "nn", ".", "Module", "]", "=", "nn", ".", "LayerNorm", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "SwinTransformerBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", ":", "int", "=", "dim", "\n", "self", ".", "feat_size", ":", "Tuple", "[", "int", ",", "int", "]", "=", "feat_size", "\n", "self", ".", "target_shift_size", ":", "Tuple", "[", "int", ",", "int", "]", "=", "to_2tuple", "(", "shift_size", ")", "\n", "self", ".", "window_size", ",", "self", ".", "shift_size", "=", "self", ".", "_calc_window_shift", "(", "to_2tuple", "(", "window_size", ")", ")", "\n", "self", ".", "window_area", "=", "self", ".", "window_size", "[", "0", "]", "*", "self", ".", "window_size", "[", "1", "]", "\n", "\n", "# attn branch", "\n", "self", ".", "attn", "=", "WindowMultiHeadAttention", "(", "\n", "dim", "=", "dim", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "window_size", "=", "self", ".", "window_size", ",", "\n", "drop_attn", "=", "drop_attn", ",", "\n", "drop_proj", "=", "drop", ",", "\n", "sequential_attn", "=", "sequential_attn", ",", "\n", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "drop_path1", "=", "DropPath", "(", "drop_prob", "=", "drop_path", ")", "if", "drop_path", ">", "0.0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "# mlp branch", "\n", "self", ".", "mlp", "=", "Mlp", "(", "\n", "in_features", "=", "dim", ",", "\n", "hidden_features", "=", "int", "(", "dim", "*", "mlp_ratio", ")", ",", "\n", "drop", "=", "drop", ",", "\n", "out_features", "=", "dim", ",", "\n", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "drop_path2", "=", "DropPath", "(", "drop_prob", "=", "drop_path", ")", "if", "drop_path", ">", "0.0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "# Extra main branch norm layer mentioned for Huge/Giant models in V2 paper.", "\n", "# Also being used as final network norm and optional stage ending norm while still in a C-last format.", "\n", "self", ".", "norm3", "=", "norm_layer", "(", "dim", ")", "if", "extra_norm", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "_make_attention_mask", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerBlock._calc_window_shift": [[348, 352], ["tuple", "tuple", "zip", "zip"], "methods", ["None"], ["", "def", "_calc_window_shift", "(", "self", ",", "target_window_size", ")", ":", "\n", "        ", "window_size", "=", "[", "f", "if", "f", "<=", "w", "else", "w", "for", "f", ",", "w", "in", "zip", "(", "self", ".", "feat_size", ",", "target_window_size", ")", "]", "\n", "shift_size", "=", "[", "0", "if", "f", "<=", "w", "else", "s", "for", "f", ",", "w", ",", "s", "in", "zip", "(", "self", ".", "feat_size", ",", "window_size", ",", "self", ".", "target_shift_size", ")", "]", "\n", "return", "tuple", "(", "window_size", ")", ",", "tuple", "(", "shift_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerBlock._make_attention_mask": [[353, 378], ["any", "swin_transformer_v2_cr.SwinTransformerBlock.register_buffer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "swin_transformer_v2_cr.window_partition", "mask_windows.view.view.view", "attn_mask.masked_fill().masked_fill.masked_fill().masked_fill.masked_fill().masked_fill", "slice", "slice", "slice", "mask_windows.view.view.unsqueeze", "mask_windows.view.view.unsqueeze", "float", "slice", "slice", "slice", "attn_mask.masked_fill().masked_fill.masked_fill().masked_fill.masked_fill", "float"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.window_partition"], ["", "def", "_make_attention_mask", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"Method generates the attention mask used in shift case.\"\"\"", "\n", "# Make masks for shift case", "\n", "if", "any", "(", "self", ".", "shift_size", ")", ":", "\n", "# calculate attention mask for SW-MSA", "\n", "            ", "H", ",", "W", "=", "self", ".", "feat_size", "\n", "img_mask", "=", "torch", ".", "zeros", "(", "(", "1", ",", "H", ",", "W", ",", "1", ")", ")", "# 1 H W 1", "\n", "cnt", "=", "0", "\n", "for", "h", "in", "(", "\n", "slice", "(", "0", ",", "-", "self", ".", "window_size", "[", "0", "]", ")", ",", "\n", "slice", "(", "-", "self", ".", "window_size", "[", "0", "]", ",", "-", "self", ".", "shift_size", "[", "0", "]", ")", ",", "\n", "slice", "(", "-", "self", ".", "shift_size", "[", "0", "]", ",", "None", ")", ")", ":", "\n", "                ", "for", "w", "in", "(", "\n", "slice", "(", "0", ",", "-", "self", ".", "window_size", "[", "1", "]", ")", ",", "\n", "slice", "(", "-", "self", ".", "window_size", "[", "1", "]", ",", "-", "self", ".", "shift_size", "[", "1", "]", ")", ",", "\n", "slice", "(", "-", "self", ".", "shift_size", "[", "1", "]", ",", "None", ")", ")", ":", "\n", "                    ", "img_mask", "[", ":", ",", "h", ",", "w", ",", ":", "]", "=", "cnt", "\n", "cnt", "+=", "1", "\n", "", "", "mask_windows", "=", "window_partition", "(", "img_mask", ",", "self", ".", "window_size", ")", "# num_windows, window_size, window_size, 1", "\n", "mask_windows", "=", "mask_windows", ".", "view", "(", "-", "1", ",", "self", ".", "window_area", ")", "\n", "attn_mask", "=", "mask_windows", ".", "unsqueeze", "(", "1", ")", "-", "mask_windows", ".", "unsqueeze", "(", "2", ")", "\n", "attn_mask", "=", "attn_mask", ".", "masked_fill", "(", "attn_mask", "!=", "0", ",", "float", "(", "-", "100.0", ")", ")", ".", "masked_fill", "(", "attn_mask", "==", "0", ",", "float", "(", "0.0", ")", ")", "\n", "", "else", ":", "\n", "            ", "attn_mask", "=", "None", "\n", "", "self", ".", "register_buffer", "(", "\"attn_mask\"", ",", "attn_mask", ",", "persistent", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerBlock.update_input_size": [[379, 392], ["swin_transformer_v2_cr.SwinTransformerBlock._calc_window_shift", "swin_transformer_v2_cr.SwinTransformerBlock.attn.update_input_size", "swin_transformer_v2_cr.SwinTransformerBlock._make_attention_mask", "layers.to_2tuple"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerBlock._calc_window_shift", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerV2Cr.update_input_size", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerBlock._make_attention_mask"], ["", "def", "update_input_size", "(", "self", ",", "new_window_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "new_feat_size", ":", "Tuple", "[", "int", ",", "int", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"Method updates the image resolution to be processed and window size and so the pair-wise relative positions.\n\n        Args:\n            new_window_size (int): New window size\n            new_feat_size (Tuple[int, int]): New input resolution\n        \"\"\"", "\n", "# Update input resolution", "\n", "self", ".", "feat_size", ":", "Tuple", "[", "int", ",", "int", "]", "=", "new_feat_size", "\n", "self", ".", "window_size", ",", "self", ".", "shift_size", "=", "self", ".", "_calc_window_shift", "(", "to_2tuple", "(", "new_window_size", ")", ")", "\n", "self", ".", "window_area", "=", "self", ".", "window_size", "[", "0", "]", "*", "self", ".", "window_size", "[", "1", "]", "\n", "self", ".", "attn", ".", "update_input_size", "(", "new_window_size", "=", "self", ".", "window_size", ")", "\n", "self", ".", "_make_attention_mask", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerBlock._shifted_window_attn": [[393, 427], ["torch.roll.view", "torch.roll.view", "torch.roll.view", "any", "swin_transformer_v2_cr.window_partition", "x_windows.view.view.view", "swin_transformer_v2_cr.SwinTransformerBlock.attn", "attn_windows.view.view.view", "swin_transformer_v2_cr.window_reverse", "torch.roll.view", "torch.roll.view", "torch.roll.view", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.window_partition", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.window_reverse"], ["", "def", "_shifted_window_attn", "(", "self", ",", "x", ")", ":", "\n", "        ", "H", ",", "W", "=", "self", ".", "feat_size", "\n", "B", ",", "L", ",", "C", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "H", ",", "W", ",", "C", ")", "\n", "\n", "# cyclic shift", "\n", "sh", ",", "sw", "=", "self", ".", "shift_size", "\n", "do_shift", ":", "bool", "=", "any", "(", "self", ".", "shift_size", ")", "\n", "if", "do_shift", ":", "\n", "# FIXME PyTorch XLA needs cat impl, roll not lowered", "\n", "# x = torch.cat([x[:, sh:], x[:, :sh]], dim=1)", "\n", "# x = torch.cat([x[:, :, sw:], x[:, :, :sw]], dim=2)", "\n", "            ", "x", "=", "torch", ".", "roll", "(", "x", ",", "shifts", "=", "(", "-", "sh", ",", "-", "sw", ")", ",", "dims", "=", "(", "1", ",", "2", ")", ")", "\n", "\n", "# partition windows", "\n", "", "x_windows", "=", "window_partition", "(", "x", ",", "self", ".", "window_size", ")", "# num_windows * B, window_size, window_size, C", "\n", "x_windows", "=", "x_windows", ".", "view", "(", "-", "1", ",", "self", ".", "window_size", "[", "0", "]", "*", "self", ".", "window_size", "[", "1", "]", ",", "C", ")", "\n", "\n", "# W-MSA/SW-MSA", "\n", "attn_windows", "=", "self", ".", "attn", "(", "x_windows", ",", "mask", "=", "self", ".", "attn_mask", ")", "# num_windows * B, window_size * window_size, C", "\n", "\n", "# merge windows", "\n", "attn_windows", "=", "attn_windows", ".", "view", "(", "-", "1", ",", "self", ".", "window_size", "[", "0", "]", ",", "self", ".", "window_size", "[", "1", "]", ",", "C", ")", "\n", "x", "=", "window_reverse", "(", "attn_windows", ",", "self", ".", "window_size", ",", "self", ".", "feat_size", ")", "# B H' W' C", "\n", "\n", "# reverse cyclic shift", "\n", "if", "do_shift", ":", "\n", "# FIXME PyTorch XLA needs cat impl, roll not lowered", "\n", "# x = torch.cat([x[:, -sh:], x[:, :-sh]], dim=1)", "\n", "# x = torch.cat([x[:, :, -sw:], x[:, :, :-sw]], dim=2)", "\n", "            ", "x", "=", "torch", ".", "roll", "(", "x", ",", "shifts", "=", "(", "sh", ",", "sw", ")", ",", "dims", "=", "(", "1", ",", "2", ")", ")", "\n", "\n", "", "x", "=", "x", ".", "view", "(", "B", ",", "L", ",", "C", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerBlock.forward": [[428, 442], ["swin_transformer_v2_cr.SwinTransformerBlock.norm3", "swin_transformer_v2_cr.SwinTransformerBlock.drop_path1", "swin_transformer_v2_cr.SwinTransformerBlock.drop_path2", "swin_transformer_v2_cr.SwinTransformerBlock.norm1", "swin_transformer_v2_cr.SwinTransformerBlock.norm2", "swin_transformer_v2_cr.SwinTransformerBlock._shifted_window_attn", "swin_transformer_v2_cr.SwinTransformerBlock.mlp"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerBlock._shifted_window_attn"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Forward pass.\n\n        Args:\n            x (torch.Tensor): Input tensor of the shape [B, C, H, W]\n\n        Returns:\n            output (torch.Tensor): Output tensor of the shape [B, C, H, W]\n        \"\"\"", "\n", "# NOTE post-norm branches (op -> norm -> drop)", "\n", "x", "=", "x", "+", "self", ".", "drop_path1", "(", "self", ".", "norm1", "(", "self", ".", "_shifted_window_attn", "(", "x", ")", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path2", "(", "self", ".", "norm2", "(", "self", ".", "mlp", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "norm3", "(", "x", ")", "# main-branch norm enabled for some blocks / stages (every 6 for Huge/Giant)", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.PatchMerging.__init__": [[451, 455], ["torch.Module.__init__", "norm_layer", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ":", "int", ",", "norm_layer", ":", "Type", "[", "nn", ".", "Module", "]", "=", "nn", ".", "LayerNorm", ")", "->", "None", ":", "\n", "        ", "super", "(", "PatchMerging", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "4", "*", "dim", ")", "\n", "self", ".", "reduction", "=", "nn", ".", "Linear", "(", "in_features", "=", "4", "*", "dim", ",", "out_features", "=", "2", "*", "dim", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.PatchMerging.forward": [[456, 470], ["bhwc_to_bchw.reshape().permute().flatten", "swin_transformer_v2_cr.PatchMerging.norm", "swin_transformer_v2_cr.bhwc_to_bchw", "swin_transformer_v2_cr.PatchMerging.reduction", "bhwc_to_bchw.reshape().permute", "bhwc_to_bchw.reshape"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.bhwc_to_bchw", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.reduction"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\" Forward pass.\n        Args:\n            x (torch.Tensor): Input tensor of the shape [B, C, H, W]\n        Returns:\n            output (torch.Tensor): Output tensor of the shape [B, 2 * C, H // 2, W // 2]\n        \"\"\"", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "# unfold + BCHW -> BHWC together", "\n", "# ordering, 5, 3, 1 instead of 3, 5, 1 maintains compat with original swin v1 merge", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "C", ",", "H", "//", "2", ",", "2", ",", "W", "//", "2", ",", "2", ")", ".", "permute", "(", "0", ",", "2", ",", "4", ",", "5", ",", "3", ",", "1", ")", ".", "flatten", "(", "3", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "x", "=", "bhwc_to_bchw", "(", "self", ".", "reduction", "(", "x", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.PatchEmbed.__init__": [[474, 485], ["torch.Module.__init__", "layers.to_2tuple", "layers.to_2tuple", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "embed_dim", "=", "768", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "patch_size", "=", "to_2tuple", "(", "patch_size", ")", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "self", ".", "grid_size", "=", "(", "img_size", "[", "0", "]", "//", "patch_size", "[", "0", "]", ",", "img_size", "[", "1", "]", "//", "patch_size", "[", "1", "]", ")", "\n", "self", ".", "num_patches", "=", "self", ".", "grid_size", "[", "0", "]", "*", "self", ".", "grid_size", "[", "1", "]", "\n", "\n", "self", ".", "proj", "=", "nn", ".", "Conv2d", "(", "in_chans", ",", "embed_dim", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "patch_size", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "if", "norm_layer", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.PatchEmbed.forward": [[486, 493], ["layers._assert", "layers._assert", "swin_transformer_v2_cr.PatchEmbed.proj", "swin_transformer_v2_cr.PatchEmbed.norm().permute", "swin_transformer_v2_cr.PatchEmbed.norm", "swin_transformer_v2_cr.PatchEmbed.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "_assert", "(", "H", "==", "self", ".", "img_size", "[", "0", "]", ",", "f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\"", ")", "\n", "_assert", "(", "W", "==", "self", ".", "img_size", "[", "1", "]", ",", "f\"Input image width ({W}) doesn't match model ({self.img_size[1]}).\"", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerStage.__init__": [[515, 562], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "swin_transformer_v2_cr.PatchMerging", "torch.Identity", "torch.Identity", "torch.Identity", "swin_transformer_v2_cr.SwinTransformerBlock", "range", "tuple", "swin_transformer_v2_cr.SwinTransformerStage.__init__._extra_norm"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed_dim", ":", "int", ",", "\n", "depth", ":", "int", ",", "\n", "downscale", ":", "bool", ",", "\n", "num_heads", ":", "int", ",", "\n", "feat_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "\n", "window_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "\n", "mlp_ratio", ":", "float", "=", "4.0", ",", "\n", "drop", ":", "float", "=", "0.0", ",", "\n", "drop_attn", ":", "float", "=", "0.0", ",", "\n", "drop_path", ":", "Union", "[", "List", "[", "float", "]", ",", "float", "]", "=", "0.0", ",", "\n", "norm_layer", ":", "Type", "[", "nn", ".", "Module", "]", "=", "nn", ".", "LayerNorm", ",", "\n", "extra_norm_period", ":", "int", "=", "0", ",", "\n", "extra_norm_stage", ":", "bool", "=", "False", ",", "\n", "sequential_attn", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "SwinTransformerStage", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "downscale", ":", "bool", "=", "downscale", "\n", "self", ".", "grad_checkpointing", ":", "bool", "=", "False", "\n", "self", ".", "feat_size", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "feat_size", "[", "0", "]", "//", "2", ",", "feat_size", "[", "1", "]", "//", "2", ")", "if", "downscale", "else", "feat_size", "\n", "\n", "self", ".", "downsample", "=", "PatchMerging", "(", "embed_dim", ",", "norm_layer", "=", "norm_layer", ")", "if", "downscale", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "def", "_extra_norm", "(", "index", ")", ":", "\n", "            ", "i", "=", "index", "+", "1", "\n", "if", "extra_norm_period", "and", "i", "%", "extra_norm_period", "==", "0", ":", "\n", "                ", "return", "True", "\n", "", "return", "i", "==", "depth", "if", "extra_norm_stage", "else", "False", "\n", "\n", "", "embed_dim", "=", "embed_dim", "*", "2", "if", "downscale", "else", "embed_dim", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "SwinTransformerBlock", "(", "\n", "dim", "=", "embed_dim", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "feat_size", "=", "self", ".", "feat_size", ",", "\n", "window_size", "=", "window_size", ",", "\n", "shift_size", "=", "tuple", "(", "[", "0", "if", "(", "(", "index", "%", "2", ")", "==", "0", ")", "else", "w", "//", "2", "for", "w", "in", "window_size", "]", ")", ",", "\n", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "drop", "=", "drop", ",", "\n", "drop_attn", "=", "drop_attn", ",", "\n", "drop_path", "=", "drop_path", "[", "index", "]", "if", "isinstance", "(", "drop_path", ",", "list", ")", "else", "drop_path", ",", "\n", "extra_norm", "=", "_extra_norm", "(", "index", ")", ",", "\n", "sequential_attn", "=", "sequential_attn", ",", "\n", "norm_layer", "=", "norm_layer", ",", "\n", ")", "\n", "for", "index", "in", "range", "(", "depth", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerStage.update_input_size": [[564, 576], ["block.update_input_size"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerV2Cr.update_input_size"], ["", "def", "update_input_size", "(", "self", ",", "new_window_size", ":", "int", ",", "new_feat_size", ":", "Tuple", "[", "int", ",", "int", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"Method updates the resolution to utilize and the window size and so the pair-wise relative positions.\n\n        Args:\n            new_window_size (int): New window size\n            new_feat_size (Tuple[int, int]): New input resolution\n        \"\"\"", "\n", "self", ".", "feat_size", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "\n", "(", "new_feat_size", "[", "0", "]", "//", "2", ",", "new_feat_size", "[", "1", "]", "//", "2", ")", "if", "self", ".", "downscale", "else", "new_feat_size", "\n", ")", "\n", "for", "block", "in", "self", ".", "blocks", ":", "\n", "            ", "block", ".", "update_input_size", "(", "new_window_size", "=", "new_window_size", ",", "new_feat_size", "=", "self", ".", "feat_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerStage.forward": [[577, 597], ["swin_transformer_v2_cr.SwinTransformerStage.downsample", "bchw_to_bhwc().reshape", "swin_transformer_v2_cr.bhwc_to_bchw", "block.reshape", "swin_transformer_v2_cr.bchw_to_bhwc", "torch.checkpoint", "torch.checkpoint", "torch.checkpoint", "block", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.bhwc_to_bchw", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.bchw_to_bhwc"], ["", "", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Forward pass.\n        Args:\n            x (torch.Tensor): Input tensor of the shape [B, C, H, W] or [B, L, C]\n        Returns:\n            output (torch.Tensor): Output tensor of the shape [B, 2 * C, H // 2, W // 2]\n        \"\"\"", "\n", "x", "=", "self", ".", "downsample", "(", "x", ")", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "L", "=", "H", "*", "W", "\n", "\n", "x", "=", "bchw_to_bhwc", "(", "x", ")", ".", "reshape", "(", "B", ",", "L", ",", "C", ")", "\n", "for", "block", "in", "self", ".", "blocks", ":", "\n", "# Perform checkpointing if utilized", "\n", "            ", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "                ", "x", "=", "checkpoint", ".", "checkpoint", "(", "block", ",", "x", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "block", "(", "x", ")", "\n", "", "", "x", "=", "bhwc_to_bchw", "(", "x", ".", "reshape", "(", "B", ",", "H", ",", "W", ",", "-", "1", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerV2Cr.__init__": [[624, 694], ["torch.Module.__init__", "layers.to_2tuple", "int", "swin_transformer_v2_cr.PatchEmbed", "torch.linspace().tolist", "torch.linspace().tolist", "torch.linspace().tolist", "torch.linspace().tolist", "torch.linspace().tolist", "torch.linspace().tolist", "torch.linspace().tolist", "torch.linspace().tolist", "torch.linspace().tolist", "enumerate", "torch.Sequential", "torch.Sequential", "torch.Sequential", "tuple", "layers.to_2tuple", "zip", "stages.append", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "helpers.named_apply", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "max", "swin_transformer_v2_cr.SwinTransformerStage", "sum", "len", "sum", "sum", "len"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_apply"], ["def", "__init__", "(", "\n", "self", ",", "\n", "img_size", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "224", ",", "224", ")", ",", "\n", "patch_size", ":", "int", "=", "4", ",", "\n", "window_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "img_window_ratio", ":", "int", "=", "32", ",", "\n", "in_chans", ":", "int", "=", "3", ",", "\n", "num_classes", ":", "int", "=", "1000", ",", "\n", "embed_dim", ":", "int", "=", "96", ",", "\n", "depths", ":", "Tuple", "[", "int", ",", "...", "]", "=", "(", "2", ",", "2", ",", "6", ",", "2", ")", ",", "\n", "num_heads", ":", "Tuple", "[", "int", ",", "...", "]", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "\n", "mlp_ratio", ":", "float", "=", "4.0", ",", "\n", "drop_rate", ":", "float", "=", "0.0", ",", "\n", "attn_drop_rate", ":", "float", "=", "0.0", ",", "\n", "drop_path_rate", ":", "float", "=", "0.0", ",", "\n", "norm_layer", ":", "Type", "[", "nn", ".", "Module", "]", "=", "nn", ".", "LayerNorm", ",", "\n", "extra_norm_period", ":", "int", "=", "0", ",", "\n", "extra_norm_stage", ":", "bool", "=", "False", ",", "\n", "sequential_attn", ":", "bool", "=", "False", ",", "\n", "global_pool", ":", "str", "=", "'avg'", ",", "\n", "weight_init", "=", "'skip'", ",", "\n", "**", "kwargs", ":", "Any", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "SwinTransformerV2Cr", ",", "self", ")", ".", "__init__", "(", ")", "\n", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "window_size", "=", "tuple", "(", "[", "\n", "s", "//", "img_window_ratio", "for", "s", "in", "img_size", "]", ")", "if", "window_size", "is", "None", "else", "to_2tuple", "(", "window_size", ")", "\n", "\n", "self", ".", "num_classes", ":", "int", "=", "num_classes", "\n", "self", ".", "patch_size", ":", "int", "=", "patch_size", "\n", "self", ".", "img_size", ":", "Tuple", "[", "int", ",", "int", "]", "=", "img_size", "\n", "self", ".", "window_size", ":", "int", "=", "window_size", "\n", "self", ".", "num_features", ":", "int", "=", "int", "(", "embed_dim", "*", "2", "**", "(", "len", "(", "depths", ")", "-", "1", ")", ")", "\n", "\n", "self", ".", "patch_embed", "=", "PatchEmbed", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "\n", "embed_dim", "=", "embed_dim", ",", "norm_layer", "=", "norm_layer", ")", "\n", "patch_grid_size", ":", "Tuple", "[", "int", ",", "int", "]", "=", "self", ".", "patch_embed", ".", "grid_size", "\n", "\n", "drop_path_rate", "=", "torch", ".", "linspace", "(", "0.0", ",", "drop_path_rate", ",", "sum", "(", "depths", ")", ")", ".", "tolist", "(", ")", "\n", "stages", "=", "[", "]", "\n", "for", "index", ",", "(", "depth", ",", "num_heads", ")", "in", "enumerate", "(", "zip", "(", "depths", ",", "num_heads", ")", ")", ":", "\n", "            ", "stage_scale", "=", "2", "**", "max", "(", "index", "-", "1", ",", "0", ")", "\n", "stages", ".", "append", "(", "\n", "SwinTransformerStage", "(", "\n", "embed_dim", "=", "embed_dim", "*", "stage_scale", ",", "\n", "depth", "=", "depth", ",", "\n", "downscale", "=", "index", "!=", "0", ",", "\n", "feat_size", "=", "(", "patch_grid_size", "[", "0", "]", "//", "stage_scale", ",", "patch_grid_size", "[", "1", "]", "//", "stage_scale", ")", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "window_size", "=", "window_size", ",", "\n", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "drop", "=", "drop_rate", ",", "\n", "drop_attn", "=", "attn_drop_rate", ",", "\n", "drop_path", "=", "drop_path_rate", "[", "sum", "(", "depths", "[", ":", "index", "]", ")", ":", "sum", "(", "depths", "[", ":", "index", "+", "1", "]", ")", "]", ",", "\n", "extra_norm_period", "=", "extra_norm_period", ",", "\n", "extra_norm_stage", "=", "extra_norm_stage", "or", "(", "index", "+", "1", ")", "==", "len", "(", "depths", ")", ",", "# last stage ends w/ norm", "\n", "sequential_attn", "=", "sequential_attn", ",", "\n", "norm_layer", "=", "norm_layer", ",", "\n", ")", "\n", ")", "\n", "", "self", ".", "stages", "=", "nn", ".", "Sequential", "(", "*", "stages", ")", "\n", "\n", "self", ".", "global_pool", ":", "str", "=", "global_pool", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "# current weight init skips custom init and uses pytorch layer defaults, seems to work well", "\n", "# FIXME more experiments needed", "\n", "if", "weight_init", "!=", "'skip'", ":", "\n", "            ", "named_apply", "(", "init_weights", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerV2Cr.update_input_size": [[695, 722], ["enumerate", "layers.to_2tuple", "tuple", "stage.update_input_size", "max"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerV2Cr.update_input_size"], ["", "", "def", "update_input_size", "(", "\n", "self", ",", "\n", "new_img_size", ":", "Optional", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", "new_window_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "img_window_ratio", ":", "int", "=", "32", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Method updates the image resolution to be processed and window size and so the pair-wise relative positions.\n\n        Args:\n            new_window_size (Optional[int]): New window size, if None based on new_img_size // window_div\n            new_img_size (Optional[Tuple[int, int]]): New input resolution, if None current resolution is used\n            img_window_ratio (int): divisor for calculating window size from image size\n        \"\"\"", "\n", "# Check parameters", "\n", "if", "new_img_size", "is", "None", ":", "\n", "            ", "new_img_size", "=", "self", ".", "img_size", "\n", "", "else", ":", "\n", "            ", "new_img_size", "=", "to_2tuple", "(", "new_img_size", ")", "\n", "", "if", "new_window_size", "is", "None", ":", "\n", "            ", "new_window_size", "=", "tuple", "(", "[", "s", "//", "img_window_ratio", "for", "s", "in", "new_img_size", "]", ")", "\n", "# Compute new patch resolution & update resolution of each stage", "\n", "", "new_patch_grid_size", "=", "(", "new_img_size", "[", "0", "]", "//", "self", ".", "patch_size", ",", "new_img_size", "[", "1", "]", "//", "self", ".", "patch_size", ")", "\n", "for", "index", ",", "stage", "in", "enumerate", "(", "self", ".", "stages", ")", ":", "\n", "            ", "stage_scale", "=", "2", "**", "max", "(", "index", "-", "1", ",", "0", ")", "\n", "stage", ".", "update_input_size", "(", "\n", "new_window_size", "=", "new_window_size", ",", "\n", "new_img_size", "=", "(", "new_patch_grid_size", "[", "0", "]", "//", "stage_scale", ",", "new_patch_grid_size", "[", "1", "]", "//", "stage_scale", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerV2Cr.group_matcher": [[724, 731], ["dict"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^patch_embed'", ",", "# stem and embed", "\n", "blocks", "=", "r'^stages\\.(\\d+)'", "if", "coarse", "else", "[", "\n", "(", "r'^stages\\.(\\d+).downsample'", ",", "(", "0", ",", ")", ")", ",", "\n", "(", "r'^stages\\.(\\d+)\\.\\w+\\.(\\d+)'", ",", "None", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerV2Cr.set_grad_checkpointing": [[734, 738], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "for", "s", "in", "self", ".", "stages", ":", "\n", "            ", "s", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerV2Cr.get_classifier": [[739, 746], ["torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "(", ")", "\n", "def", "get_classifier", "(", "self", ")", "->", "nn", ".", "Module", ":", "\n", "        ", "\"\"\"Method returns the classification head of the model.\n        Returns:\n            head (nn.Module): Current classification head\n        \"\"\"", "\n", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerV2Cr.reset_classifier": [[747, 758], ["torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ":", "int", ",", "global_pool", ":", "Optional", "[", "str", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"Method results the classification head\n\n        Args:\n            num_classes (int): Number of classes to be predicted\n            global_pool (str): Unused\n        \"\"\"", "\n", "self", ".", "num_classes", ":", "int", "=", "num_classes", "\n", "if", "global_pool", "is", "not", "None", ":", "\n", "            ", "self", ".", "global_pool", "=", "global_pool", "\n", "", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerV2Cr.forward_features": [[759, 763], ["swin_transformer_v2_cr.SwinTransformerV2Cr.patch_embed", "swin_transformer_v2_cr.SwinTransformerV2Cr.stages"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.stages"], ["", "def", "forward_features", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "x", "=", "self", ".", "stages", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerV2Cr.forward_head": [[764, 768], ["x.mean.mean.mean", "swin_transformer_v2_cr.SwinTransformerV2Cr.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "global_pool", "==", "'avg'", ":", "\n", "            ", "x", "=", "x", ".", "mean", "(", "dim", "=", "(", "2", ",", "3", ")", ")", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.SwinTransformerV2Cr.forward": [[769, 773], ["swin_transformer_v2_cr.SwinTransformerV2Cr.forward_features", "swin_transformer_v2_cr.SwinTransformerV2Cr.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr._cfg": [[49, 63], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "\n", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "\n", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", "0.9", ",", "\n", "'interpolation'", ":", "'bicubic'", ",", "\n", "'fixed_input_size'", ":", "True", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "\n", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'patch_embed.proj'", ",", "\n", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.bchw_to_bhwc": [[97, 100], ["x.permute"], "function", ["None"], ["def", "bchw_to_bhwc", "(", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Permutes a tensor from the shape (B, C, H, W) to (B, H, W, C). \"\"\"", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.bhwc_to_bchw": [[102, 105], ["x.permute"], "function", ["None"], ["", "def", "bhwc_to_bchw", "(", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Permutes a tensor from the shape (B, H, W, C) to (B, C, H, W). \"\"\"", "\n", "return", "x", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.window_partition": [[107, 120], ["x.view.view", "x.view.permute().contiguous().view", "x.view.permute().contiguous", "x.view.permute"], "function", ["None"], ["", "def", "window_partition", "(", "x", ",", "window_size", ":", "Tuple", "[", "int", ",", "int", "]", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        x: (B, H, W, C)\n        window_size (int): window size\n\n    Returns:\n        windows: (num_windows*B, window_size, window_size, C)\n    \"\"\"", "\n", "B", ",", "H", ",", "W", ",", "C", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "H", "//", "window_size", "[", "0", "]", ",", "window_size", "[", "0", "]", ",", "W", "//", "window_size", "[", "1", "]", ",", "window_size", "[", "1", "]", ",", "C", ")", "\n", "windows", "=", "x", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ",", "5", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "window_size", "[", "0", "]", ",", "window_size", "[", "1", "]", ",", "C", ")", "\n", "return", "windows", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.window_reverse": [[122, 138], ["int", "windows.view", "x.permute().contiguous().view.permute().contiguous().view", "x.permute().contiguous().view.permute().contiguous", "x.permute().contiguous().view.permute"], "function", ["None"], ["", "@", "register_notrace_function", "# reason: int argument is a Proxy", "\n", "def", "window_reverse", "(", "windows", ",", "window_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "img_size", ":", "Tuple", "[", "int", ",", "int", "]", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        windows: (num_windows * B, window_size[0], window_size[1], C)\n        window_size (Tuple[int, int]): Window size\n        img_size (Tuple[int, int]): Image size\n\n    Returns:\n        x: (B, H, W, C)\n    \"\"\"", "\n", "H", ",", "W", "=", "img_size", "\n", "B", "=", "int", "(", "windows", ".", "shape", "[", "0", "]", "/", "(", "H", "*", "W", "/", "window_size", "[", "0", "]", "/", "window_size", "[", "1", "]", ")", ")", "\n", "x", "=", "windows", ".", "view", "(", "B", ",", "H", "//", "window_size", "[", "0", "]", ",", "W", "//", "window_size", "[", "1", "]", ",", "window_size", "[", "0", "]", ",", "window_size", "[", "1", "]", ",", "-", "1", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ",", "5", ")", ".", "contiguous", "(", ")", ".", "view", "(", "B", ",", "H", ",", "W", ",", "-", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.init_weights": [[775, 788], ["isinstance", "math.sqrt", "torch.init.uniform_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.xavier_uniform_", "float"], "function", ["None"], ["", "", "def", "init_weights", "(", "module", ":", "nn", ".", "Module", ",", "name", ":", "str", "=", "''", ")", ":", "\n", "# FIXME WIP determining if there's a better weight init", "\n", "    ", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "if", "'qkv'", "in", "name", ":", "\n", "# treat the weights of Q, K, V separately", "\n", "            ", "val", "=", "math", ".", "sqrt", "(", "6.", "/", "float", "(", "module", ".", "weight", ".", "shape", "[", "0", "]", "//", "3", "+", "module", ".", "weight", ".", "shape", "[", "1", "]", ")", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "module", ".", "weight", ",", "-", "val", ",", "val", ")", "\n", "", "elif", "'head'", "in", "name", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "weight", ")", "\n", "", "else", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "module", ".", "weight", ")", "\n", "", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr._create_swin_transformer_v2_cr": [[790, 799], ["kwargs.get", "helpers.build_model_with_cfg", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "", "def", "_create_swin_transformer_v2_cr", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", ".", "get", "(", "'features_only'", ",", "None", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'features_only not implemented for Vision Transformer models.'", ")", "\n", "", "model", "=", "build_model_with_cfg", "(", "\n", "SwinTransformerV2Cr", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_filter_fn", "=", "checkpoint_filter_fn", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.swin_v2_cr_tiny_384": [[801, 811], ["dict", "swin_transformer_v2_cr._create_swin_transformer_v2_cr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr._create_swin_transformer_v2_cr"], ["", "@", "register_model", "\n", "def", "swin_v2_cr_tiny_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Swin-T V2 CR @ 384x384, trained ImageNet-1k\"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "96", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "6", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_swin_transformer_v2_cr", "(", "'swin_v2_cr_tiny_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.swin_v2_cr_tiny_224": [[813, 823], ["dict", "swin_transformer_v2_cr._create_swin_transformer_v2_cr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr._create_swin_transformer_v2_cr"], ["", "@", "register_model", "\n", "def", "swin_v2_cr_tiny_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Swin-T V2 CR @ 224x224, trained ImageNet-1k\"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "96", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "6", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_swin_transformer_v2_cr", "(", "'swin_v2_cr_tiny_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.swin_v2_cr_tiny_ns_224": [[825, 838], ["dict", "swin_transformer_v2_cr._create_swin_transformer_v2_cr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr._create_swin_transformer_v2_cr"], ["", "@", "register_model", "\n", "def", "swin_v2_cr_tiny_ns_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Swin-T V2 CR @ 224x224, trained ImageNet-1k w/ extra stage norms.\n    ** Experimental, may make default if results are improved. **\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "96", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "6", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "\n", "extra_norm_stage", "=", "True", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_swin_transformer_v2_cr", "(", "'swin_v2_cr_tiny_ns_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.swin_v2_cr_small_384": [[840, 850], ["dict", "swin_transformer_v2_cr._create_swin_transformer_v2_cr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr._create_swin_transformer_v2_cr"], ["", "@", "register_model", "\n", "def", "swin_v2_cr_small_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Swin-S V2 CR @ 384x384, trained ImageNet-1k\"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "96", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_swin_transformer_v2_cr", "(", "'swin_v2_cr_small_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.swin_v2_cr_small_224": [[853, 863], ["dict", "swin_transformer_v2_cr._create_swin_transformer_v2_cr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr._create_swin_transformer_v2_cr"], ["", "@", "register_model", "\n", "def", "swin_v2_cr_small_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Swin-S V2 CR @ 224x224, trained ImageNet-1k\"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "96", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_swin_transformer_v2_cr", "(", "'swin_v2_cr_small_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.swin_v2_cr_base_384": [[865, 875], ["dict", "swin_transformer_v2_cr._create_swin_transformer_v2_cr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr._create_swin_transformer_v2_cr"], ["", "@", "register_model", "\n", "def", "swin_v2_cr_base_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Swin-B V2 CR @ 384x384, trained ImageNet-1k\"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "128", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "4", ",", "8", ",", "16", ",", "32", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_swin_transformer_v2_cr", "(", "'swin_v2_cr_base_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.swin_v2_cr_base_224": [[877, 887], ["dict", "swin_transformer_v2_cr._create_swin_transformer_v2_cr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr._create_swin_transformer_v2_cr"], ["", "@", "register_model", "\n", "def", "swin_v2_cr_base_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Swin-B V2 CR @ 224x224, trained ImageNet-1k\"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "128", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "4", ",", "8", ",", "16", ",", "32", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_swin_transformer_v2_cr", "(", "'swin_v2_cr_base_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.swin_v2_cr_large_384": [[889, 899], ["dict", "swin_transformer_v2_cr._create_swin_transformer_v2_cr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr._create_swin_transformer_v2_cr"], ["", "@", "register_model", "\n", "def", "swin_v2_cr_large_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Swin-L V2 CR @ 384x384, trained ImageNet-1k\"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "192", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "6", ",", "12", ",", "24", ",", "48", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_swin_transformer_v2_cr", "(", "'swin_v2_cr_large_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.swin_v2_cr_large_224": [[902, 912], ["dict", "swin_transformer_v2_cr._create_swin_transformer_v2_cr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr._create_swin_transformer_v2_cr"], ["", "@", "register_model", "\n", "def", "swin_v2_cr_large_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Swin-L V2 CR @ 224x224, trained ImageNet-1k\"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "192", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "6", ",", "12", ",", "24", ",", "48", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_swin_transformer_v2_cr", "(", "'swin_v2_cr_large_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.swin_v2_cr_huge_384": [[914, 925], ["dict", "swin_transformer_v2_cr._create_swin_transformer_v2_cr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr._create_swin_transformer_v2_cr"], ["", "@", "register_model", "\n", "def", "swin_v2_cr_huge_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Swin-H V2 CR @ 384x384, trained ImageNet-1k\"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "352", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "11", ",", "22", ",", "44", ",", "88", ")", ",", "# head count not certain for Huge, 384 & 224 trying diff values", "\n", "extra_norm_period", "=", "6", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_swin_transformer_v2_cr", "(", "'swin_v2_cr_huge_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.swin_v2_cr_huge_224": [[927, 938], ["dict", "swin_transformer_v2_cr._create_swin_transformer_v2_cr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr._create_swin_transformer_v2_cr"], ["", "@", "register_model", "\n", "def", "swin_v2_cr_huge_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Swin-H V2 CR @ 224x224, trained ImageNet-1k\"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "352", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "8", ",", "16", ",", "32", ",", "64", ")", ",", "# head count not certain for Huge, 384 & 224 trying diff values", "\n", "extra_norm_period", "=", "6", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_swin_transformer_v2_cr", "(", "'swin_v2_cr_huge_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.swin_v2_cr_giant_384": [[940, 951], ["dict", "swin_transformer_v2_cr._create_swin_transformer_v2_cr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr._create_swin_transformer_v2_cr"], ["", "@", "register_model", "\n", "def", "swin_v2_cr_giant_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Swin-G V2 CR @ 384x384, trained ImageNet-1k\"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "512", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "42", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "16", ",", "32", ",", "64", ",", "128", ")", ",", "\n", "extra_norm_period", "=", "6", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_swin_transformer_v2_cr", "(", "'swin_v2_cr_giant_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr.swin_v2_cr_giant_224": [[954, 965], ["dict", "swin_transformer_v2_cr._create_swin_transformer_v2_cr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer_v2_cr._create_swin_transformer_v2_cr"], ["", "@", "register_model", "\n", "def", "swin_v2_cr_giant_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Swin-G V2 CR @ 224x224, trained ImageNet-1k\"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dim", "=", "512", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "42", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "16", ",", "32", ",", "64", ",", "128", ")", ",", "\n", "extra_norm_period", "=", "6", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_swin_transformer_v2_cr", "(", "'swin_v2_cr_giant_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_xception.SeparableConv2d.__init__": [[46, 59], ["torch.Module.__init__", "layers.get_padding", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_padding"], ["    ", "def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "bias", "=", "False", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "SeparableConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "dilation", "=", "dilation", "\n", "\n", "# depthwise convolution", "\n", "padding", "=", "get_padding", "(", "kernel_size", ",", "stride", ",", "dilation", ")", "\n", "self", ".", "conv_dw", "=", "nn", ".", "Conv2d", "(", "\n", "inplanes", ",", "inplanes", ",", "kernel_size", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "groups", "=", "inplanes", ",", "bias", "=", "bias", ")", "\n", "self", ".", "bn", "=", "norm_layer", "(", "num_features", "=", "inplanes", ")", "\n", "# pointwise convolution", "\n", "self", ".", "conv_pw", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_xception.SeparableConv2d.forward": [[60, 65], ["gluon_xception.SeparableConv2d.conv_dw", "gluon_xception.SeparableConv2d.bn", "gluon_xception.SeparableConv2d.conv_pw"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv_dw", "(", "x", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_pw", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_xception.Block.__init__": [[68, 97], ["torch.Module.__init__", "isinstance", "collections.OrderedDict", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "gluon_xception.Block.skip.add_module", "torch.ReLU", "torch.ReLU", "torch.ReLU", "gluon_xception.SeparableConv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "len", "gluon_xception.Block.skip.add_module", "norm_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "start_with_relu", "=", "True", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "planes", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "assert", "len", "(", "planes", ")", "==", "3", "\n", "", "else", ":", "\n", "            ", "planes", "=", "(", "planes", ",", ")", "*", "3", "\n", "", "outplanes", "=", "planes", "[", "-", "1", "]", "\n", "\n", "if", "outplanes", "!=", "inplanes", "or", "stride", "!=", "1", ":", "\n", "            ", "self", ".", "skip", "=", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "skip", ".", "add_module", "(", "'conv1'", ",", "nn", ".", "Conv2d", "(", "\n", "inplanes", ",", "outplanes", ",", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ")", ",", "\n", "self", ".", "skip", ".", "add_module", "(", "'bn1'", ",", "norm_layer", "(", "num_features", "=", "outplanes", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "skip", "=", "None", "\n", "\n", "", "rep", "=", "OrderedDict", "(", ")", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "rep", "[", "'act%d'", "%", "(", "i", "+", "1", ")", "]", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "rep", "[", "'conv%d'", "%", "(", "i", "+", "1", ")", "]", "=", "SeparableConv2d", "(", "\n", "inplanes", ",", "planes", "[", "i", "]", ",", "3", ",", "stride", "=", "stride", "if", "i", "==", "2", "else", "1", ",", "dilation", "=", "dilation", ",", "norm_layer", "=", "norm_layer", ")", "\n", "rep", "[", "'bn%d'", "%", "(", "i", "+", "1", ")", "]", "=", "norm_layer", "(", "planes", "[", "i", "]", ")", "\n", "inplanes", "=", "planes", "[", "i", "]", "\n", "\n", "", "if", "not", "start_with_relu", ":", "\n", "            ", "del", "rep", "[", "'act1'", "]", "\n", "", "else", ":", "\n", "            ", "rep", "[", "'act1'", "]", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", "\n", "", "self", ".", "rep", "=", "nn", ".", "Sequential", "(", "rep", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_xception.Block.forward": [[98, 104], ["gluon_xception.Block.skip", "gluon_xception.Block.rep"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "skip", "=", "x", "\n", "if", "self", ".", "skip", "is", "not", "None", ":", "\n", "            ", "skip", "=", "self", ".", "skip", "(", "skip", ")", "\n", "", "x", "=", "self", ".", "rep", "(", "x", ")", "+", "skip", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_xception.Xception65.__init__": [[113, 181], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "gluon_xception.Block", "torch.ReLU", "torch.ReLU", "torch.ReLU", "gluon_xception.Block", "gluon_xception.Block", "torch.Sequential", "torch.Sequential", "torch.Sequential", "gluon_xception.Block", "torch.ReLU", "torch.ReLU", "torch.ReLU", "gluon_xception.SeparableConv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "gluon_xception.SeparableConv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "gluon_xception.SeparableConv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "layers.create_classifier", "collections.OrderedDict", "dict", "dict", "dict", "dict", "dict", "gluon_xception.Block", "range"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["def", "__init__", "(", "self", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "output_stride", "=", "32", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "\n", "drop_rate", "=", "0.", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "super", "(", "Xception65", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "if", "output_stride", "==", "32", ":", "\n", "            ", "entry_block3_stride", "=", "2", "\n", "exit_block20_stride", "=", "2", "\n", "middle_dilation", "=", "1", "\n", "exit_dilation", "=", "(", "1", ",", "1", ")", "\n", "", "elif", "output_stride", "==", "16", ":", "\n", "            ", "entry_block3_stride", "=", "2", "\n", "exit_block20_stride", "=", "1", "\n", "middle_dilation", "=", "1", "\n", "exit_dilation", "=", "(", "1", ",", "2", ")", "\n", "", "elif", "output_stride", "==", "8", ":", "\n", "            ", "entry_block3_stride", "=", "1", "\n", "exit_block20_stride", "=", "1", "\n", "middle_dilation", "=", "2", "\n", "exit_dilation", "=", "(", "2", ",", "4", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "# Entry flow", "\n", "", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_chans", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "num_features", "=", "32", ")", "\n", "self", ".", "act1", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "num_features", "=", "64", ")", "\n", "self", ".", "act2", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "block1", "=", "Block", "(", "64", ",", "128", ",", "stride", "=", "2", ",", "start_with_relu", "=", "False", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "block1_act", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "block2", "=", "Block", "(", "128", ",", "256", ",", "stride", "=", "2", ",", "start_with_relu", "=", "False", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "block3", "=", "Block", "(", "256", ",", "728", ",", "stride", "=", "entry_block3_stride", ",", "norm_layer", "=", "norm_layer", ")", "\n", "\n", "# Middle flow", "\n", "self", ".", "mid", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "(", "'block%d'", "%", "i", ",", "Block", "(", "\n", "728", ",", "728", ",", "stride", "=", "1", ",", "dilation", "=", "middle_dilation", ",", "norm_layer", "=", "norm_layer", ")", ")", "for", "i", "in", "range", "(", "4", ",", "20", ")", "]", ")", ")", "\n", "\n", "# Exit flow", "\n", "self", ".", "block20", "=", "Block", "(", "\n", "728", ",", "(", "728", ",", "1024", ",", "1024", ")", ",", "stride", "=", "exit_block20_stride", ",", "dilation", "=", "exit_dilation", "[", "0", "]", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "block20_act", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "conv3", "=", "SeparableConv2d", "(", "1024", ",", "1536", ",", "3", ",", "stride", "=", "1", ",", "dilation", "=", "exit_dilation", "[", "1", "]", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "bn3", "=", "norm_layer", "(", "num_features", "=", "1536", ")", "\n", "self", ".", "act3", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "conv4", "=", "SeparableConv2d", "(", "1536", ",", "1536", ",", "3", ",", "stride", "=", "1", ",", "dilation", "=", "exit_dilation", "[", "1", "]", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "bn4", "=", "norm_layer", "(", "num_features", "=", "1536", ")", "\n", "self", ".", "act4", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "num_features", "=", "2048", "\n", "self", ".", "conv5", "=", "SeparableConv2d", "(", "\n", "1536", ",", "self", ".", "num_features", ",", "3", ",", "stride", "=", "1", ",", "dilation", "=", "exit_dilation", "[", "1", "]", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "bn5", "=", "norm_layer", "(", "num_features", "=", "self", ".", "num_features", ")", "\n", "self", ".", "act5", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "feature_info", "=", "[", "\n", "dict", "(", "num_chs", "=", "64", ",", "reduction", "=", "2", ",", "module", "=", "'act2'", ")", ",", "\n", "dict", "(", "num_chs", "=", "128", ",", "reduction", "=", "4", ",", "module", "=", "'block1_act'", ")", ",", "\n", "dict", "(", "num_chs", "=", "256", ",", "reduction", "=", "8", ",", "module", "=", "'block3.rep.act1'", ")", ",", "\n", "dict", "(", "num_chs", "=", "728", ",", "reduction", "=", "16", ",", "module", "=", "'block20.rep.act1'", ")", ",", "\n", "dict", "(", "num_chs", "=", "2048", ",", "reduction", "=", "32", ",", "module", "=", "'act5'", ")", ",", "\n", "]", "\n", "\n", "self", ".", "global_pool", ",", "self", ".", "fc", "=", "create_classifier", "(", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_xception.Xception65.group_matcher": [[182, 193], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem", "=", "r'^conv[12]|bn[12]'", ",", "\n", "blocks", "=", "[", "\n", "(", "r'^mid\\.block(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^block(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^conv[345]|bn[345]'", ",", "(", "99", ",", ")", ")", ",", "\n", "]", ",", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_xception.Xception65.set_grad_checkpointing": [[194, 197], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "\"gradient checkpointing not supported\"", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_xception.Xception65.get_classifier": [[198, 201], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_xception.Xception65.reset_classifier": [[202, 205], ["layers.create_classifier"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "fc", "=", "create_classifier", "(", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_xception.Xception65.forward_features": [[206, 242], ["gluon_xception.Xception65.conv1", "gluon_xception.Xception65.bn1", "gluon_xception.Xception65.act1", "gluon_xception.Xception65.conv2", "gluon_xception.Xception65.bn2", "gluon_xception.Xception65.act2", "gluon_xception.Xception65.block1", "gluon_xception.Xception65.block1_act", "gluon_xception.Xception65.block2", "gluon_xception.Xception65.block3", "gluon_xception.Xception65.mid", "gluon_xception.Xception65.block20", "gluon_xception.Xception65.block20_act", "gluon_xception.Xception65.conv3", "gluon_xception.Xception65.bn3", "gluon_xception.Xception65.act3", "gluon_xception.Xception65.conv4", "gluon_xception.Xception65.bn4", "gluon_xception.Xception65.act4", "gluon_xception.Xception65.conv5", "gluon_xception.Xception65.bn5", "gluon_xception.Xception65.act5"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "# Entry flow", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "act1", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "bn2", "(", "x", ")", "\n", "x", "=", "self", ".", "act2", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "block1", "(", "x", ")", "\n", "x", "=", "self", ".", "block1_act", "(", "x", ")", "\n", "# c1 = x", "\n", "x", "=", "self", ".", "block2", "(", "x", ")", "\n", "# c2 = x", "\n", "x", "=", "self", ".", "block3", "(", "x", ")", "\n", "\n", "# Middle flow", "\n", "x", "=", "self", ".", "mid", "(", "x", ")", "\n", "# c3 = x", "\n", "\n", "# Exit flow", "\n", "x", "=", "self", ".", "block20", "(", "x", ")", "\n", "x", "=", "self", ".", "block20_act", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3", "(", "x", ")", "\n", "x", "=", "self", ".", "bn3", "(", "x", ")", "\n", "x", "=", "self", ".", "act3", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv4", "(", "x", ")", "\n", "x", "=", "self", ".", "bn4", "(", "x", ")", "\n", "x", "=", "self", ".", "act4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv5", "(", "x", ")", "\n", "x", "=", "self", ".", "bn5", "(", "x", ")", "\n", "x", "=", "self", ".", "act5", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_xception.Xception65.forward_head": [[243, 249], ["gluon_xception.Xception65.global_pool", "gluon_xception.Xception65.fc", "torch.dropout", "torch.dropout", "torch.dropout"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ":", "\n", "            ", "F", ".", "dropout", "(", "x", ",", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_xception.Xception65.forward": [[250, 254], ["gluon_xception.Xception65.forward_features", "gluon_xception.Xception65.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_xception._create_gluon_xception": [[256, 261], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_gluon_xception", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "\n", "Xception65", ",", "variant", ",", "pretrained", ",", "\n", "feature_cfg", "=", "dict", "(", "feature_cls", "=", "'hook'", ")", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_xception.gluon_xception65": [[263, 268], ["gluon_xception._create_gluon_xception"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_xception._create_gluon_xception"], ["", "@", "register_model", "\n", "def", "gluon_xception65", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Modified Aligned Xception-65\n    \"\"\"", "\n", "return", "_create_gluon_xception", "(", "'gluon_xception65'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.EfficientNet.__init__": [[473, 508], ["torch.Module.__init__", "layers.get_norm_act_layer", "layers.create_conv2d", "layers.get_norm_act_layer.", "efficientnet_builder.EfficientNetBuilder", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.create_conv2d", "layers.get_norm_act_layer.", "layers.create_classifier", "efficientnet_builder.efficientnet_init_weights", "round_chs_fn", "efficientnet_builder.EfficientNetBuilder."], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.efficientnet_init_weights"], ["def", "__init__", "(", "\n", "self", ",", "block_args", ",", "num_classes", "=", "1000", ",", "num_features", "=", "1280", ",", "in_chans", "=", "3", ",", "stem_size", "=", "32", ",", "fix_stem", "=", "False", ",", "\n", "output_stride", "=", "32", ",", "pad_type", "=", "''", ",", "round_chs_fn", "=", "round_channels", ",", "act_layer", "=", "None", ",", "norm_layer", "=", "None", ",", "\n", "se_layer", "=", "None", ",", "drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "super", "(", "EfficientNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "act_layer", "=", "act_layer", "or", "nn", ".", "ReLU", "\n", "norm_layer", "=", "norm_layer", "or", "nn", ".", "BatchNorm2d", "\n", "norm_act_layer", "=", "get_norm_act_layer", "(", "norm_layer", ",", "act_layer", ")", "\n", "se_layer", "=", "se_layer", "or", "SqueezeExcite", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "# Stem", "\n", "if", "not", "fix_stem", ":", "\n", "            ", "stem_size", "=", "round_chs_fn", "(", "stem_size", ")", "\n", "", "self", ".", "conv_stem", "=", "create_conv2d", "(", "in_chans", ",", "stem_size", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "bn1", "=", "norm_act_layer", "(", "stem_size", ",", "inplace", "=", "True", ")", "\n", "\n", "# Middle stages (IR/ER/DS Blocks)", "\n", "builder", "=", "EfficientNetBuilder", "(", "\n", "output_stride", "=", "output_stride", ",", "pad_type", "=", "pad_type", ",", "round_chs_fn", "=", "round_chs_fn", ",", "\n", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ",", "se_layer", "=", "se_layer", ",", "drop_path_rate", "=", "drop_path_rate", ")", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "*", "builder", "(", "stem_size", ",", "block_args", ")", ")", "\n", "self", ".", "feature_info", "=", "builder", ".", "features", "\n", "head_chs", "=", "builder", ".", "in_chs", "\n", "\n", "# Head + Pooling", "\n", "self", ".", "conv_head", "=", "create_conv2d", "(", "head_chs", ",", "self", ".", "num_features", ",", "1", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "bn2", "=", "norm_act_layer", "(", "self", ".", "num_features", ",", "inplace", "=", "True", ")", "\n", "self", ".", "global_pool", ",", "self", ".", "classifier", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n", "efficientnet_init_weights", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.EfficientNet.as_sequential": [[509, 515], ["layers.extend", "layers.extend", "layers.extend", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["None"], ["", "def", "as_sequential", "(", "self", ")", ":", "\n", "        ", "layers", "=", "[", "self", ".", "conv_stem", ",", "self", ".", "bn1", "]", "\n", "layers", ".", "extend", "(", "self", ".", "blocks", ")", "\n", "layers", ".", "extend", "(", "[", "self", ".", "conv_head", ",", "self", ".", "bn2", ",", "self", ".", "global_pool", "]", ")", "\n", "layers", ".", "extend", "(", "[", "nn", ".", "Dropout", "(", "self", ".", "drop_rate", ")", ",", "self", ".", "classifier", "]", ")", "\n", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.EfficientNet.group_matcher": [[516, 523], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^conv_stem|bn1'", ",", "\n", "blocks", "=", "[", "\n", "(", "r'^blocks\\.(\\d+)'", "if", "coarse", "else", "r'^blocks\\.(\\d+)\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'conv_head|bn2'", ",", "(", "99999", ",", ")", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.EfficientNet.set_grad_checkpointing": [[526, 529], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.EfficientNet.get_classifier": [[530, 533], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.EfficientNet.reset_classifier": [[534, 538], ["layers.create_classifier"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "classifier", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.EfficientNet.forward_features": [[539, 549], ["efficientnet.EfficientNet.conv_stem", "efficientnet.EfficientNet.bn1", "efficientnet.EfficientNet.conv_head", "efficientnet.EfficientNet.bn2", "helpers.checkpoint_seq", "efficientnet.EfficientNet.blocks", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv_stem", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "blocks", ",", "x", ",", "flatten", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "blocks", "(", "x", ")", "\n", "", "x", "=", "self", ".", "conv_head", "(", "x", ")", "\n", "x", "=", "self", ".", "bn2", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.EfficientNet.forward_head": [[550, 555], ["efficientnet.EfficientNet.global_pool", "torch.dropout", "torch.dropout", "torch.dropout", "efficientnet.EfficientNet.classifier"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ">", "0.", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "classifier", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.EfficientNet.forward": [[556, 560], ["efficientnet.EfficientNet.forward_features", "efficientnet.EfficientNet.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.EfficientNetFeatures.__init__": [[569, 602], ["torch.Module.__init__", "layers.get_norm_act_layer", "layers.create_conv2d", "layers.get_norm_act_layer.", "efficientnet_builder.EfficientNetBuilder", "torch.Sequential", "torch.Sequential", "torch.Sequential", "features.FeatureInfo", "efficientnet_builder.efficientnet_init_weights", "round_chs_fn", "efficientnet.EfficientNetFeatures.feature_info.get_dicts", "features.FeatureHooks", "efficientnet_builder.EfficientNetBuilder.", "enumerate", "efficientnet.EfficientNetFeatures.named_modules"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.efficientnet_init_weights", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get_dicts", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules"], ["def", "__init__", "(", "\n", "self", ",", "block_args", ",", "out_indices", "=", "(", "0", ",", "1", ",", "2", ",", "3", ",", "4", ")", ",", "feature_location", "=", "'bottleneck'", ",", "in_chans", "=", "3", ",", "\n", "stem_size", "=", "32", ",", "fix_stem", "=", "False", ",", "output_stride", "=", "32", ",", "pad_type", "=", "''", ",", "round_chs_fn", "=", "round_channels", ",", "\n", "act_layer", "=", "None", ",", "norm_layer", "=", "None", ",", "se_layer", "=", "None", ",", "drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", "EfficientNetFeatures", ",", "self", ")", ".", "__init__", "(", ")", "\n", "act_layer", "=", "act_layer", "or", "nn", ".", "ReLU", "\n", "norm_layer", "=", "norm_layer", "or", "nn", ".", "BatchNorm2d", "\n", "norm_act_layer", "=", "get_norm_act_layer", "(", "norm_layer", ",", "act_layer", ")", "\n", "se_layer", "=", "se_layer", "or", "SqueezeExcite", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "\n", "# Stem", "\n", "if", "not", "fix_stem", ":", "\n", "            ", "stem_size", "=", "round_chs_fn", "(", "stem_size", ")", "\n", "", "self", ".", "conv_stem", "=", "create_conv2d", "(", "in_chans", ",", "stem_size", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "bn1", "=", "norm_act_layer", "(", "stem_size", ",", "inplace", "=", "True", ")", "\n", "\n", "# Middle stages (IR/ER/DS Blocks)", "\n", "builder", "=", "EfficientNetBuilder", "(", "\n", "output_stride", "=", "output_stride", ",", "pad_type", "=", "pad_type", ",", "round_chs_fn", "=", "round_chs_fn", ",", "\n", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ",", "se_layer", "=", "se_layer", ",", "drop_path_rate", "=", "drop_path_rate", ",", "\n", "feature_location", "=", "feature_location", ")", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "*", "builder", "(", "stem_size", ",", "block_args", ")", ")", "\n", "self", ".", "feature_info", "=", "FeatureInfo", "(", "builder", ".", "features", ",", "out_indices", ")", "\n", "self", ".", "_stage_out_idx", "=", "{", "v", "[", "'stage'", "]", ":", "i", "for", "i", ",", "v", "in", "enumerate", "(", "self", ".", "feature_info", ")", "if", "i", "in", "out_indices", "}", "\n", "\n", "efficientnet_init_weights", "(", "self", ")", "\n", "\n", "# Register feature extraction hooks with FeatureHooks helper", "\n", "self", ".", "feature_hooks", "=", "None", "\n", "if", "feature_location", "!=", "'bottleneck'", ":", "\n", "            ", "hooks", "=", "self", ".", "feature_info", ".", "get_dicts", "(", "keys", "=", "(", "'module'", ",", "'hook_type'", ")", ")", "\n", "self", ".", "feature_hooks", "=", "FeatureHooks", "(", "hooks", ",", "self", ".", "named_modules", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.EfficientNetFeatures.forward": [[603, 619], ["efficientnet.EfficientNetFeatures.conv_stem", "efficientnet.EfficientNetFeatures.bn1", "enumerate", "efficientnet.EfficientNetFeatures.blocks", "efficientnet.EfficientNetFeatures.feature_hooks.get_output", "list", "features.append", "b", "efficientnet.EfficientNetFeatures.values", "features.append"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureHooks.get_output"], ["", "", "def", "forward", "(", "self", ",", "x", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "        ", "x", "=", "self", ".", "conv_stem", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "if", "self", ".", "feature_hooks", "is", "None", ":", "\n", "            ", "features", "=", "[", "]", "\n", "if", "0", "in", "self", ".", "_stage_out_idx", ":", "\n", "                ", "features", ".", "append", "(", "x", ")", "# add stem out", "\n", "", "for", "i", ",", "b", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "                ", "x", "=", "b", "(", "x", ")", "\n", "if", "i", "+", "1", "in", "self", ".", "_stage_out_idx", ":", "\n", "                    ", "features", ".", "append", "(", "x", ")", "\n", "", "", "return", "features", "\n", "", "else", ":", "\n", "            ", "self", ".", "blocks", "(", "x", ")", "\n", "out", "=", "self", ".", "feature_hooks", ".", "get_output", "(", "x", ".", "device", ")", "\n", "return", "list", "(", "out", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._cfg": [[58, 65], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'conv_stem'", ",", "'classifier'", ":", "'classifier'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet": [[621, 637], ["kwargs.pop", "helpers.build_model_with_cfg", "helpers.pretrained_cfg_for_features"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.pretrained_cfg_for_features"], ["", "", "", "def", "_create_effnet", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "features_only", "=", "False", "\n", "model_cls", "=", "EfficientNet", "\n", "kwargs_filter", "=", "None", "\n", "if", "kwargs", ".", "pop", "(", "'features_only'", ",", "False", ")", ":", "\n", "        ", "features_only", "=", "True", "\n", "kwargs_filter", "=", "(", "'num_classes'", ",", "'num_features'", ",", "'head_conv'", ",", "'global_pool'", ")", "\n", "model_cls", "=", "EfficientNetFeatures", "\n", "", "model", "=", "build_model_with_cfg", "(", "\n", "model_cls", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_strict", "=", "not", "features_only", ",", "\n", "kwargs_filter", "=", "kwargs_filter", ",", "\n", "**", "kwargs", ")", "\n", "if", "features_only", ":", "\n", "        ", "model", ".", "default_cfg", "=", "pretrained_cfg_for_features", "(", "model", ".", "default_cfg", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mnasnet_a1": [[639, 673], ["dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "functools.partial", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_mnasnet_a1", "(", "variant", ",", "channel_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a mnasnet-a1 model.\n\n    Ref impl: https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet\n    Paper: https://arxiv.org/pdf/1807.11626.pdf.\n\n    Args:\n      channel_multiplier: multiplier to number of channels per layer.\n    \"\"\"", "\n", "arch_def", "=", "[", "\n", "# stage 0, 112x112 in", "\n", "[", "'ds_r1_k3_s1_e1_c16_noskip'", "]", ",", "\n", "# stage 1, 112x112 in", "\n", "[", "'ir_r2_k3_s2_e6_c24'", "]", ",", "\n", "# stage 2, 56x56 in", "\n", "[", "'ir_r3_k5_s2_e3_c40_se0.25'", "]", ",", "\n", "# stage 3, 28x28 in", "\n", "[", "'ir_r4_k3_s2_e6_c80'", "]", ",", "\n", "# stage 4, 14x14in", "\n", "[", "'ir_r2_k3_s1_e6_c112_se0.25'", "]", ",", "\n", "# stage 5, 14x14in", "\n", "[", "'ir_r3_k5_s2_e6_c160_se0.25'", "]", ",", "\n", "# stage 6, 7x7 in", "\n", "[", "'ir_r1_k3_s1_e6_c320'", "]", ",", "\n", "]", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ")", ",", "\n", "stem_size", "=", "32", ",", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mnasnet_b1": [[675, 709], ["dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "functools.partial", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_mnasnet_b1", "(", "variant", ",", "channel_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a mnasnet-b1 model.\n\n    Ref impl: https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet\n    Paper: https://arxiv.org/pdf/1807.11626.pdf.\n\n    Args:\n      channel_multiplier: multiplier to number of channels per layer.\n    \"\"\"", "\n", "arch_def", "=", "[", "\n", "# stage 0, 112x112 in", "\n", "[", "'ds_r1_k3_s1_c16_noskip'", "]", ",", "\n", "# stage 1, 112x112 in", "\n", "[", "'ir_r3_k3_s2_e3_c24'", "]", ",", "\n", "# stage 2, 56x56 in", "\n", "[", "'ir_r3_k5_s2_e3_c40'", "]", ",", "\n", "# stage 3, 28x28 in", "\n", "[", "'ir_r3_k5_s2_e6_c80'", "]", ",", "\n", "# stage 4, 14x14in", "\n", "[", "'ir_r2_k3_s1_e6_c96'", "]", ",", "\n", "# stage 5, 14x14in", "\n", "[", "'ir_r4_k5_s2_e6_c192'", "]", ",", "\n", "# stage 6, 7x7 in", "\n", "[", "'ir_r1_k3_s1_e6_c320_noskip'", "]", "\n", "]", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ")", ",", "\n", "stem_size", "=", "32", ",", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mnasnet_small": [[711, 738], ["dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "functools.partial", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_mnasnet_small", "(", "variant", ",", "channel_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a mnasnet-b1 model.\n\n    Ref impl: https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet\n    Paper: https://arxiv.org/pdf/1807.11626.pdf.\n\n    Args:\n      channel_multiplier: multiplier to number of channels per layer.\n    \"\"\"", "\n", "arch_def", "=", "[", "\n", "[", "'ds_r1_k3_s1_c8'", "]", ",", "\n", "[", "'ir_r1_k3_s2_e3_c16'", "]", ",", "\n", "[", "'ir_r2_k3_s2_e6_c16'", "]", ",", "\n", "[", "'ir_r4_k5_s2_e6_c32_se0.25'", "]", ",", "\n", "[", "'ir_r3_k3_s1_e6_c32_se0.25'", "]", ",", "\n", "[", "'ir_r3_k5_s2_e6_c88_se0.25'", "]", ",", "\n", "[", "'ir_r1_k3_s1_e6_c144'", "]", "\n", "]", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ")", ",", "\n", "stem_size", "=", "8", ",", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mobilenet_v2": [[740, 768], ["functools.partial", "dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "efficientnet_builder.resolve_act_layer", "max", "kwargs.pop", "functools.partial", "functools.partial.", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_mobilenet_v2", "(", "\n", "variant", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "fix_stem_head", "=", "False", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Generate MobileNet-V2 network\n    Ref impl: https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet_v2.py\n    Paper: https://arxiv.org/abs/1801.04381\n    \"\"\"", "\n", "arch_def", "=", "[", "\n", "[", "'ds_r1_k3_s1_c16'", "]", ",", "\n", "[", "'ir_r2_k3_s2_e6_c24'", "]", ",", "\n", "[", "'ir_r3_k3_s2_e6_c32'", "]", ",", "\n", "[", "'ir_r4_k3_s2_e6_c64'", "]", ",", "\n", "[", "'ir_r3_k3_s1_e6_c96'", "]", ",", "\n", "[", "'ir_r3_k3_s2_e6_c160'", "]", ",", "\n", "[", "'ir_r1_k3_s1_e6_c320'", "]", ",", "\n", "]", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ",", "depth_multiplier", "=", "depth_multiplier", ",", "fix_first_last", "=", "fix_stem_head", ")", ",", "\n", "num_features", "=", "1280", "if", "fix_stem_head", "else", "max", "(", "1280", ",", "round_chs_fn", "(", "1280", ")", ")", ",", "\n", "stem_size", "=", "32", ",", "\n", "fix_stem", "=", "fix_stem_head", ",", "\n", "round_chs_fn", "=", "round_chs_fn", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'relu6'", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_fbnetc": [[770, 798], ["dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "functools.partial", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_fbnetc", "(", "variant", ",", "channel_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" FBNet-C\n\n        Paper: https://arxiv.org/abs/1812.03443\n        Ref Impl: https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/maskrcnn_benchmark/modeling/backbone/fbnet_modeldef.py\n\n        NOTE: the impl above does not relate to the 'C' variant here, that was derived from paper,\n        it was used to confirm some building block details\n    \"\"\"", "\n", "arch_def", "=", "[", "\n", "[", "'ir_r1_k3_s1_e1_c16'", "]", ",", "\n", "[", "'ir_r1_k3_s2_e6_c24'", ",", "'ir_r2_k3_s1_e1_c24'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e6_c32'", ",", "'ir_r1_k5_s1_e3_c32'", ",", "'ir_r1_k5_s1_e6_c32'", ",", "'ir_r1_k3_s1_e6_c32'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e6_c64'", ",", "'ir_r1_k5_s1_e3_c64'", ",", "'ir_r2_k5_s1_e6_c64'", "]", ",", "\n", "[", "'ir_r3_k5_s1_e6_c112'", ",", "'ir_r1_k5_s1_e3_c112'", "]", ",", "\n", "[", "'ir_r4_k5_s2_e6_c184'", "]", ",", "\n", "[", "'ir_r1_k3_s1_e6_c352'", "]", ",", "\n", "]", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ")", ",", "\n", "stem_size", "=", "16", ",", "\n", "num_features", "=", "1984", ",", "# paper suggests this, but is not 100% clear", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_spnasnet": [[800, 833], ["dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "functools.partial", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_spnasnet", "(", "variant", ",", "channel_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates the Single-Path NAS model from search targeted for Pixel1 phone.\n\n    Paper: https://arxiv.org/abs/1904.02877\n\n    Args:\n      channel_multiplier: multiplier to number of channels per layer.\n    \"\"\"", "\n", "arch_def", "=", "[", "\n", "# stage 0, 112x112 in", "\n", "[", "'ds_r1_k3_s1_c16_noskip'", "]", ",", "\n", "# stage 1, 112x112 in", "\n", "[", "'ir_r3_k3_s2_e3_c24'", "]", ",", "\n", "# stage 2, 56x56 in", "\n", "[", "'ir_r1_k5_s2_e6_c40'", ",", "'ir_r3_k3_s1_e3_c40'", "]", ",", "\n", "# stage 3, 28x28 in", "\n", "[", "'ir_r1_k5_s2_e6_c80'", ",", "'ir_r3_k3_s1_e3_c80'", "]", ",", "\n", "# stage 4, 14x14in", "\n", "[", "'ir_r1_k5_s1_e6_c96'", ",", "'ir_r3_k5_s1_e3_c96'", "]", ",", "\n", "# stage 5, 14x14in", "\n", "[", "'ir_r4_k5_s2_e6_c192'", "]", ",", "\n", "# stage 6, 7x7 in", "\n", "[", "'ir_r1_k3_s1_e6_c320_noskip'", "]", "\n", "]", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ")", ",", "\n", "stem_size", "=", "32", ",", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet": [[835, 882], ["functools.partial", "dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "functools.partial.", "efficientnet_builder.resolve_act_layer", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_efficientnet", "(", "\n", "variant", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "channel_divisor", "=", "8", ",", "\n", "group_size", "=", "None", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates an EfficientNet model.\n\n    Ref impl: https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/efficientnet_model.py\n    Paper: https://arxiv.org/abs/1905.11946\n\n    EfficientNet params\n    name: (channel_multiplier, depth_multiplier, resolution, dropout_rate)\n    'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n    'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n    'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n    'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n    'efficientnet-b4': (1.4, 1.8, 380, 0.4),\n    'efficientnet-b5': (1.6, 2.2, 456, 0.4),\n    'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n    'efficientnet-b7': (2.0, 3.1, 600, 0.5),\n    'efficientnet-b8': (2.2, 3.6, 672, 0.5),\n    'efficientnet-l2': (4.3, 5.3, 800, 0.5),\n\n    Args:\n      channel_multiplier: multiplier to number of channels per layer\n      depth_multiplier: multiplier to number of repeats per stage\n\n    \"\"\"", "\n", "arch_def", "=", "[", "\n", "[", "'ds_r1_k3_s1_e1_c16_se0.25'", "]", ",", "\n", "[", "'ir_r2_k3_s2_e6_c24_se0.25'", "]", ",", "\n", "[", "'ir_r2_k5_s2_e6_c40_se0.25'", "]", ",", "\n", "[", "'ir_r3_k3_s2_e6_c80_se0.25'", "]", ",", "\n", "[", "'ir_r3_k5_s1_e6_c112_se0.25'", "]", ",", "\n", "[", "'ir_r4_k5_s2_e6_c192_se0.25'", "]", ",", "\n", "[", "'ir_r1_k3_s1_e6_c320_se0.25'", "]", ",", "\n", "]", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ",", "divisor", "=", "channel_divisor", ")", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ",", "depth_multiplier", ",", "group_size", "=", "group_size", ")", ",", "\n", "num_features", "=", "round_chs_fn", "(", "1280", ")", ",", "\n", "stem_size", "=", "32", ",", "\n", "round_chs_fn", "=", "round_chs_fn", ",", "\n", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'swish'", ")", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_edge": [[884, 913], ["functools.partial", "dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "functools.partial.", "efficientnet_builder.resolve_act_layer", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_efficientnet_edge", "(", "\n", "variant", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "group_size", "=", "None", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Creates an EfficientNet-EdgeTPU model\n\n    Ref impl: https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/edgetpu\n    \"\"\"", "\n", "\n", "arch_def", "=", "[", "\n", "# NOTE `fc` is present to override a mismatch between stem channels and in chs not", "\n", "# present in other models", "\n", "[", "'er_r1_k3_s1_e4_c24_fc24_noskip'", "]", ",", "\n", "[", "'er_r2_k3_s2_e8_c32'", "]", ",", "\n", "[", "'er_r4_k3_s2_e8_c48'", "]", ",", "\n", "[", "'ir_r5_k5_s2_e8_c96'", "]", ",", "\n", "[", "'ir_r4_k5_s1_e8_c144'", "]", ",", "\n", "[", "'ir_r2_k5_s2_e8_c192'", "]", ",", "\n", "]", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ",", "depth_multiplier", ",", "group_size", "=", "group_size", ")", ",", "\n", "num_features", "=", "round_chs_fn", "(", "1280", ")", ",", "\n", "stem_size", "=", "32", ",", "\n", "round_chs_fn", "=", "round_chs_fn", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'relu'", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_condconv": [[915, 944], ["functools.partial", "dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "functools.partial.", "efficientnet_builder.resolve_act_layer", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_efficientnet_condconv", "(", "\n", "variant", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "experts_multiplier", "=", "1", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates an EfficientNet-CondConv model.\n\n    Ref impl: https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/condconv\n    \"\"\"", "\n", "arch_def", "=", "[", "\n", "[", "'ds_r1_k3_s1_e1_c16_se0.25'", "]", ",", "\n", "[", "'ir_r2_k3_s2_e6_c24_se0.25'", "]", ",", "\n", "[", "'ir_r2_k5_s2_e6_c40_se0.25'", "]", ",", "\n", "[", "'ir_r3_k3_s2_e6_c80_se0.25'", "]", ",", "\n", "[", "'ir_r3_k5_s1_e6_c112_se0.25_cc4'", "]", ",", "\n", "[", "'ir_r4_k5_s2_e6_c192_se0.25_cc4'", "]", ",", "\n", "[", "'ir_r1_k3_s1_e6_c320_se0.25_cc4'", "]", ",", "\n", "]", "\n", "# NOTE unlike official impl, this one uses `cc<x>` option where x is the base number of experts for each stage and", "\n", "# the expert_multiplier increases that on a per-model basis as with depth/channel multipliers", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ",", "depth_multiplier", ",", "experts_multiplier", "=", "experts_multiplier", ")", ",", "\n", "num_features", "=", "round_chs_fn", "(", "1280", ")", ",", "\n", "stem_size", "=", "32", ",", "\n", "round_chs_fn", "=", "round_chs_fn", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'swish'", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_lite": [[946, 985], ["dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "functools.partial", "efficientnet_builder.resolve_act_layer", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_efficientnet_lite", "(", "variant", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates an EfficientNet-Lite model.\n\n    Ref impl: https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite\n    Paper: https://arxiv.org/abs/1905.11946\n\n    EfficientNet params\n    name: (channel_multiplier, depth_multiplier, resolution, dropout_rate)\n      'efficientnet-lite0': (1.0, 1.0, 224, 0.2),\n      'efficientnet-lite1': (1.0, 1.1, 240, 0.2),\n      'efficientnet-lite2': (1.1, 1.2, 260, 0.3),\n      'efficientnet-lite3': (1.2, 1.4, 280, 0.3),\n      'efficientnet-lite4': (1.4, 1.8, 300, 0.3),\n\n    Args:\n      channel_multiplier: multiplier to number of channels per layer\n      depth_multiplier: multiplier to number of repeats per stage\n    \"\"\"", "\n", "arch_def", "=", "[", "\n", "[", "'ds_r1_k3_s1_e1_c16'", "]", ",", "\n", "[", "'ir_r2_k3_s2_e6_c24'", "]", ",", "\n", "[", "'ir_r2_k5_s2_e6_c40'", "]", ",", "\n", "[", "'ir_r3_k3_s2_e6_c80'", "]", ",", "\n", "[", "'ir_r3_k5_s1_e6_c112'", "]", ",", "\n", "[", "'ir_r4_k5_s2_e6_c192'", "]", ",", "\n", "[", "'ir_r1_k3_s1_e6_c320'", "]", ",", "\n", "]", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ",", "depth_multiplier", ",", "fix_first_last", "=", "True", ")", ",", "\n", "num_features", "=", "1280", ",", "\n", "stem_size", "=", "32", ",", "\n", "fix_stem", "=", "True", ",", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", ",", "\n", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'relu6'", ")", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_base": [[987, 1014], ["functools.partial", "dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "functools.partial.", "efficientnet_builder.resolve_act_layer", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_efficientnetv2_base", "(", "\n", "variant", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Creates an EfficientNet-V2 base model\n\n    Ref impl: https://github.com/google/automl/tree/master/efficientnetv2\n    Paper: `EfficientNetV2: Smaller Models and Faster Training` - https://arxiv.org/abs/2104.00298\n    \"\"\"", "\n", "arch_def", "=", "[", "\n", "[", "'cn_r1_k3_s1_e1_c16_skip'", "]", ",", "\n", "[", "'er_r2_k3_s2_e4_c32'", "]", ",", "\n", "[", "'er_r2_k3_s2_e4_c48'", "]", ",", "\n", "[", "'ir_r3_k3_s2_e4_c96_se0.25'", "]", ",", "\n", "[", "'ir_r5_k3_s1_e6_c112_se0.25'", "]", ",", "\n", "[", "'ir_r8_k3_s2_e6_c192_se0.25'", "]", ",", "\n", "]", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ",", "round_limit", "=", "0.", ")", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ",", "depth_multiplier", ")", ",", "\n", "num_features", "=", "round_chs_fn", "(", "1280", ")", ",", "\n", "stem_size", "=", "32", ",", "\n", "round_chs_fn", "=", "round_chs_fn", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'silu'", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_s": [[1016, 1053], ["functools.partial", "dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "functools.partial.", "efficientnet_builder.resolve_act_layer", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_efficientnetv2_s", "(", "\n", "variant", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "group_size", "=", "None", ",", "rw", "=", "False", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Creates an EfficientNet-V2 Small model\n\n    Ref impl: https://github.com/google/automl/tree/master/efficientnetv2\n    Paper: `EfficientNetV2: Smaller Models and Faster Training` - https://arxiv.org/abs/2104.00298\n\n    NOTE: `rw` flag sets up 'small' variant to behave like my initial v2 small model,\n        before ref the impl was released.\n    \"\"\"", "\n", "arch_def", "=", "[", "\n", "[", "'cn_r2_k3_s1_e1_c24_skip'", "]", ",", "\n", "[", "'er_r4_k3_s2_e4_c48'", "]", ",", "\n", "[", "'er_r4_k3_s2_e4_c64'", "]", ",", "\n", "[", "'ir_r6_k3_s2_e4_c128_se0.25'", "]", ",", "\n", "[", "'ir_r9_k3_s1_e6_c160_se0.25'", "]", ",", "\n", "[", "'ir_r15_k3_s2_e6_c256_se0.25'", "]", ",", "\n", "]", "\n", "num_features", "=", "1280", "\n", "if", "rw", ":", "\n", "# my original variant, based on paper figure differs from the official release", "\n", "        ", "arch_def", "[", "0", "]", "=", "[", "'er_r2_k3_s1_e1_c24'", "]", "\n", "arch_def", "[", "-", "1", "]", "=", "[", "'ir_r15_k3_s2_e6_c272_se0.25'", "]", "\n", "num_features", "=", "1792", "\n", "\n", "", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ",", "depth_multiplier", ",", "group_size", "=", "group_size", ")", ",", "\n", "num_features", "=", "round_chs_fn", "(", "num_features", ")", ",", "\n", "stem_size", "=", "24", ",", "\n", "round_chs_fn", "=", "round_chs_fn", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'silu'", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_m": [[1055, 1083], ["dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "functools.partial", "efficientnet_builder.resolve_act_layer", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_efficientnetv2_m", "(", "variant", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Creates an EfficientNet-V2 Medium model\n\n    Ref impl: https://github.com/google/automl/tree/master/efficientnetv2\n    Paper: `EfficientNetV2: Smaller Models and Faster Training` - https://arxiv.org/abs/2104.00298\n    \"\"\"", "\n", "\n", "arch_def", "=", "[", "\n", "[", "'cn_r3_k3_s1_e1_c24_skip'", "]", ",", "\n", "[", "'er_r5_k3_s2_e4_c48'", "]", ",", "\n", "[", "'er_r5_k3_s2_e4_c80'", "]", ",", "\n", "[", "'ir_r7_k3_s2_e4_c160_se0.25'", "]", ",", "\n", "[", "'ir_r14_k3_s1_e6_c176_se0.25'", "]", ",", "\n", "[", "'ir_r18_k3_s2_e6_c304_se0.25'", "]", ",", "\n", "[", "'ir_r5_k3_s1_e6_c512_se0.25'", "]", ",", "\n", "]", "\n", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ",", "depth_multiplier", ")", ",", "\n", "num_features", "=", "1280", ",", "\n", "stem_size", "=", "24", ",", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'silu'", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_l": [[1085, 1113], ["dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "functools.partial", "efficientnet_builder.resolve_act_layer", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_efficientnetv2_l", "(", "variant", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Creates an EfficientNet-V2 Large model\n\n    Ref impl: https://github.com/google/automl/tree/master/efficientnetv2\n    Paper: `EfficientNetV2: Smaller Models and Faster Training` - https://arxiv.org/abs/2104.00298\n    \"\"\"", "\n", "\n", "arch_def", "=", "[", "\n", "[", "'cn_r4_k3_s1_e1_c32_skip'", "]", ",", "\n", "[", "'er_r7_k3_s2_e4_c64'", "]", ",", "\n", "[", "'er_r7_k3_s2_e4_c96'", "]", ",", "\n", "[", "'ir_r10_k3_s2_e4_c192_se0.25'", "]", ",", "\n", "[", "'ir_r19_k3_s1_e6_c224_se0.25'", "]", ",", "\n", "[", "'ir_r25_k3_s2_e6_c384_se0.25'", "]", ",", "\n", "[", "'ir_r7_k3_s1_e6_c640_se0.25'", "]", ",", "\n", "]", "\n", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ",", "depth_multiplier", ")", ",", "\n", "num_features", "=", "1280", ",", "\n", "stem_size", "=", "32", ",", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'silu'", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_xl": [[1115, 1143], ["dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "functools.partial", "efficientnet_builder.resolve_act_layer", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_efficientnetv2_xl", "(", "variant", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Creates an EfficientNet-V2 Xtra-Large model\n\n    Ref impl: https://github.com/google/automl/tree/master/efficientnetv2\n    Paper: `EfficientNetV2: Smaller Models and Faster Training` - https://arxiv.org/abs/2104.00298\n    \"\"\"", "\n", "\n", "arch_def", "=", "[", "\n", "[", "'cn_r4_k3_s1_e1_c32_skip'", "]", ",", "\n", "[", "'er_r8_k3_s2_e4_c64'", "]", ",", "\n", "[", "'er_r8_k3_s2_e4_c96'", "]", ",", "\n", "[", "'ir_r16_k3_s2_e4_c192_se0.25'", "]", ",", "\n", "[", "'ir_r24_k3_s1_e6_c256_se0.25'", "]", ",", "\n", "[", "'ir_r32_k3_s2_e6_c512_se0.25'", "]", ",", "\n", "[", "'ir_r8_k3_s1_e6_c640_se0.25'", "]", ",", "\n", "]", "\n", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ",", "depth_multiplier", ")", ",", "\n", "num_features", "=", "1280", ",", "\n", "stem_size", "=", "32", ",", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'silu'", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mixnet_s": [[1145, 1176], ["dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "functools.partial", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_mixnet_s", "(", "variant", ",", "channel_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a MixNet Small model.\n\n    Ref impl: https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet/mixnet\n    Paper: https://arxiv.org/abs/1907.09595\n    \"\"\"", "\n", "arch_def", "=", "[", "\n", "# stage 0, 112x112 in", "\n", "[", "'ds_r1_k3_s1_e1_c16'", "]", ",", "# relu", "\n", "# stage 1, 112x112 in", "\n", "[", "'ir_r1_k3_a1.1_p1.1_s2_e6_c24'", ",", "'ir_r1_k3_a1.1_p1.1_s1_e3_c24'", "]", ",", "# relu", "\n", "# stage 2, 56x56 in", "\n", "[", "'ir_r1_k3.5.7_s2_e6_c40_se0.5_nsw'", ",", "'ir_r3_k3.5_a1.1_p1.1_s1_e6_c40_se0.5_nsw'", "]", ",", "# swish", "\n", "# stage 3, 28x28 in", "\n", "[", "'ir_r1_k3.5.7_p1.1_s2_e6_c80_se0.25_nsw'", ",", "'ir_r2_k3.5_p1.1_s1_e6_c80_se0.25_nsw'", "]", ",", "# swish", "\n", "# stage 4, 14x14in", "\n", "[", "'ir_r1_k3.5.7_a1.1_p1.1_s1_e6_c120_se0.5_nsw'", ",", "'ir_r2_k3.5.7.9_a1.1_p1.1_s1_e3_c120_se0.5_nsw'", "]", ",", "# swish", "\n", "# stage 5, 14x14in", "\n", "[", "'ir_r1_k3.5.7.9.11_s2_e6_c200_se0.5_nsw'", ",", "'ir_r2_k3.5.7.9_p1.1_s1_e6_c200_se0.5_nsw'", "]", ",", "# swish", "\n", "# 7x7", "\n", "]", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ")", ",", "\n", "num_features", "=", "1536", ",", "\n", "stem_size", "=", "16", ",", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mixnet_m": [[1178, 1209], ["dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "functools.partial", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_mixnet_m", "(", "variant", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a MixNet Medium-Large model.\n\n    Ref impl: https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet/mixnet\n    Paper: https://arxiv.org/abs/1907.09595\n    \"\"\"", "\n", "arch_def", "=", "[", "\n", "# stage 0, 112x112 in", "\n", "[", "'ds_r1_k3_s1_e1_c24'", "]", ",", "# relu", "\n", "# stage 1, 112x112 in", "\n", "[", "'ir_r1_k3.5.7_a1.1_p1.1_s2_e6_c32'", ",", "'ir_r1_k3_a1.1_p1.1_s1_e3_c32'", "]", ",", "# relu", "\n", "# stage 2, 56x56 in", "\n", "[", "'ir_r1_k3.5.7.9_s2_e6_c40_se0.5_nsw'", ",", "'ir_r3_k3.5_a1.1_p1.1_s1_e6_c40_se0.5_nsw'", "]", ",", "# swish", "\n", "# stage 3, 28x28 in", "\n", "[", "'ir_r1_k3.5.7_s2_e6_c80_se0.25_nsw'", ",", "'ir_r3_k3.5.7.9_a1.1_p1.1_s1_e6_c80_se0.25_nsw'", "]", ",", "# swish", "\n", "# stage 4, 14x14in", "\n", "[", "'ir_r1_k3_s1_e6_c120_se0.5_nsw'", ",", "'ir_r3_k3.5.7.9_a1.1_p1.1_s1_e3_c120_se0.5_nsw'", "]", ",", "# swish", "\n", "# stage 5, 14x14in", "\n", "[", "'ir_r1_k3.5.7.9_s2_e6_c200_se0.5_nsw'", ",", "'ir_r3_k3.5.7.9_p1.1_s1_e6_c200_se0.5_nsw'", "]", ",", "# swish", "\n", "# 7x7", "\n", "]", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ",", "depth_multiplier", ",", "depth_trunc", "=", "'round'", ")", ",", "\n", "num_features", "=", "1536", ",", "\n", "stem_size", "=", "24", ",", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_tinynet": [[1211, 1234], ["dict", "efficientnet._create_effnet", "efficientnet_builder.decode_arch_def", "max", "functools.partial", "efficientnet_builder.resolve_act_layer", "efficientnet_builder.round_channels", "kwargs.pop", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._create_effnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.round_channels", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_tinynet", "(", "\n", "variant", ",", "model_width", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", "\n", ")", ":", "\n", "    ", "\"\"\"Creates a TinyNet model.\n    \"\"\"", "\n", "arch_def", "=", "[", "\n", "[", "'ds_r1_k3_s1_e1_c16_se0.25'", "]", ",", "[", "'ir_r2_k3_s2_e6_c24_se0.25'", "]", ",", "\n", "[", "'ir_r2_k5_s2_e6_c40_se0.25'", "]", ",", "[", "'ir_r3_k3_s2_e6_c80_se0.25'", "]", ",", "\n", "[", "'ir_r3_k5_s1_e6_c112_se0.25'", "]", ",", "[", "'ir_r4_k5_s2_e6_c192_se0.25'", "]", ",", "\n", "[", "'ir_r1_k3_s1_e6_c320_se0.25'", "]", ",", "\n", "]", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ",", "depth_multiplier", ",", "depth_trunc", "=", "'round'", ")", ",", "\n", "num_features", "=", "max", "(", "1280", ",", "round_channels", "(", "1280", ",", "model_width", ",", "8", ",", "None", ")", ")", ",", "\n", "stem_size", "=", "32", ",", "\n", "fix_stem", "=", "True", ",", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "model_width", ")", ",", "\n", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'swish'", ")", ",", "\n", "norm_layer", "=", "kwargs", ".", "pop", "(", "'norm_layer'", ",", "None", ")", "or", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_effnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mnasnet_050": [[1236, 1241], ["efficientnet._gen_mnasnet_b1"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mnasnet_b1"], ["", "@", "register_model", "\n", "def", "mnasnet_050", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MNASNet B1, depth multiplier of 0.5. \"\"\"", "\n", "model", "=", "_gen_mnasnet_b1", "(", "'mnasnet_050'", ",", "0.5", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mnasnet_075": [[1243, 1248], ["efficientnet._gen_mnasnet_b1"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mnasnet_b1"], ["", "@", "register_model", "\n", "def", "mnasnet_075", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MNASNet B1, depth multiplier of 0.75. \"\"\"", "\n", "model", "=", "_gen_mnasnet_b1", "(", "'mnasnet_075'", ",", "0.75", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mnasnet_100": [[1250, 1255], ["efficientnet._gen_mnasnet_b1"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mnasnet_b1"], ["", "@", "register_model", "\n", "def", "mnasnet_100", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MNASNet B1, depth multiplier of 1.0. \"\"\"", "\n", "model", "=", "_gen_mnasnet_b1", "(", "'mnasnet_100'", ",", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mnasnet_b1": [[1257, 1261], ["efficientnet.mnasnet_100"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mnasnet_100"], ["", "@", "register_model", "\n", "def", "mnasnet_b1", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MNASNet B1, depth multiplier of 1.0. \"\"\"", "\n", "return", "mnasnet_100", "(", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mnasnet_140": [[1263, 1268], ["efficientnet._gen_mnasnet_b1"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mnasnet_b1"], ["", "@", "register_model", "\n", "def", "mnasnet_140", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MNASNet B1,  depth multiplier of 1.4 \"\"\"", "\n", "model", "=", "_gen_mnasnet_b1", "(", "'mnasnet_140'", ",", "1.4", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.semnasnet_050": [[1270, 1275], ["efficientnet._gen_mnasnet_a1"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mnasnet_a1"], ["", "@", "register_model", "\n", "def", "semnasnet_050", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MNASNet A1 (w/ SE), depth multiplier of 0.5 \"\"\"", "\n", "model", "=", "_gen_mnasnet_a1", "(", "'semnasnet_050'", ",", "0.5", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.semnasnet_075": [[1277, 1282], ["efficientnet._gen_mnasnet_a1"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mnasnet_a1"], ["", "@", "register_model", "\n", "def", "semnasnet_075", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MNASNet A1 (w/ SE),  depth multiplier of 0.75. \"\"\"", "\n", "model", "=", "_gen_mnasnet_a1", "(", "'semnasnet_075'", ",", "0.75", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.semnasnet_100": [[1284, 1289], ["efficientnet._gen_mnasnet_a1"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mnasnet_a1"], ["", "@", "register_model", "\n", "def", "semnasnet_100", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MNASNet A1 (w/ SE), depth multiplier of 1.0. \"\"\"", "\n", "model", "=", "_gen_mnasnet_a1", "(", "'semnasnet_100'", ",", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mnasnet_a1": [[1291, 1295], ["efficientnet.semnasnet_100"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.semnasnet_100"], ["", "@", "register_model", "\n", "def", "mnasnet_a1", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MNASNet A1 (w/ SE), depth multiplier of 1.0. \"\"\"", "\n", "return", "semnasnet_100", "(", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.semnasnet_140": [[1297, 1302], ["efficientnet._gen_mnasnet_a1"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mnasnet_a1"], ["", "@", "register_model", "\n", "def", "semnasnet_140", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MNASNet A1 (w/ SE), depth multiplier of 1.4. \"\"\"", "\n", "model", "=", "_gen_mnasnet_a1", "(", "'semnasnet_140'", ",", "1.4", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mnasnet_small": [[1304, 1309], ["efficientnet._gen_mnasnet_small"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mnasnet_small"], ["", "@", "register_model", "\n", "def", "mnasnet_small", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MNASNet Small,  depth multiplier of 1.0. \"\"\"", "\n", "model", "=", "_gen_mnasnet_small", "(", "'mnasnet_small'", ",", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mobilenetv2_035": [[1311, 1316], ["efficientnet._gen_mobilenet_v2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mobilenet_v2"], ["", "@", "register_model", "\n", "def", "mobilenetv2_035", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V2 w/ 0.35 channel multiplier \"\"\"", "\n", "model", "=", "_gen_mobilenet_v2", "(", "'mobilenetv2_035'", ",", "0.35", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mobilenetv2_050": [[1318, 1323], ["efficientnet._gen_mobilenet_v2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mobilenet_v2"], ["", "@", "register_model", "\n", "def", "mobilenetv2_050", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V2 w/ 0.5 channel multiplier \"\"\"", "\n", "model", "=", "_gen_mobilenet_v2", "(", "'mobilenetv2_050'", ",", "0.5", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mobilenetv2_075": [[1325, 1330], ["efficientnet._gen_mobilenet_v2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mobilenet_v2"], ["", "@", "register_model", "\n", "def", "mobilenetv2_075", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V2 w/ 0.75 channel multiplier \"\"\"", "\n", "model", "=", "_gen_mobilenet_v2", "(", "'mobilenetv2_075'", ",", "0.75", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mobilenetv2_100": [[1332, 1337], ["efficientnet._gen_mobilenet_v2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mobilenet_v2"], ["", "@", "register_model", "\n", "def", "mobilenetv2_100", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V2 w/ 1.0 channel multiplier \"\"\"", "\n", "model", "=", "_gen_mobilenet_v2", "(", "'mobilenetv2_100'", ",", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mobilenetv2_140": [[1339, 1344], ["efficientnet._gen_mobilenet_v2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mobilenet_v2"], ["", "@", "register_model", "\n", "def", "mobilenetv2_140", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V2 w/ 1.4 channel multiplier \"\"\"", "\n", "model", "=", "_gen_mobilenet_v2", "(", "'mobilenetv2_140'", ",", "1.4", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mobilenetv2_110d": [[1346, 1352], ["efficientnet._gen_mobilenet_v2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mobilenet_v2"], ["", "@", "register_model", "\n", "def", "mobilenetv2_110d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V2 w/ 1.1 channel, 1.2 depth multipliers\"\"\"", "\n", "model", "=", "_gen_mobilenet_v2", "(", "\n", "'mobilenetv2_110d'", ",", "1.1", ",", "depth_multiplier", "=", "1.2", ",", "fix_stem_head", "=", "True", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mobilenetv2_120d": [[1354, 1360], ["efficientnet._gen_mobilenet_v2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mobilenet_v2"], ["", "@", "register_model", "\n", "def", "mobilenetv2_120d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V2 w/ 1.2 channel, 1.4 depth multipliers \"\"\"", "\n", "model", "=", "_gen_mobilenet_v2", "(", "\n", "'mobilenetv2_120d'", ",", "1.2", ",", "depth_multiplier", "=", "1.4", ",", "fix_stem_head", "=", "True", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.fbnetc_100": [[1362, 1370], ["efficientnet._gen_fbnetc"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_fbnetc"], ["", "@", "register_model", "\n", "def", "fbnetc_100", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" FBNet-C \"\"\"", "\n", "if", "pretrained", ":", "\n", "# pretrained model trained with non-default BN epsilon", "\n", "        ", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "", "model", "=", "_gen_fbnetc", "(", "'fbnetc_100'", ",", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.spnasnet_100": [[1372, 1377], ["efficientnet._gen_spnasnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_spnasnet"], ["", "@", "register_model", "\n", "def", "spnasnet_100", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Single-Path NAS Pixel1\"\"\"", "\n", "model", "=", "_gen_spnasnet", "(", "'spnasnet_100'", ",", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b0": [[1379, 1386], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b0", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B0 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_b0'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b1": [[1388, 1395], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b1", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B1 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_b1'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.1", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b2": [[1397, 1404], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B2 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_b2'", ",", "channel_multiplier", "=", "1.1", ",", "depth_multiplier", "=", "1.2", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b2a": [[1406, 1411], ["efficientnet.efficientnet_b2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b2"], ["", "@", "register_model", "\n", "def", "efficientnet_b2a", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B2 @ 288x288 w/ 1.0 test crop\"\"\"", "\n", "# WARN this model def is deprecated, different train/test res + test crop handled by default_cfg now", "\n", "return", "efficientnet_b2", "(", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b3": [[1413, 1420], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b3", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B3 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_b3'", ",", "channel_multiplier", "=", "1.2", ",", "depth_multiplier", "=", "1.4", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b3a": [[1422, 1427], ["efficientnet.efficientnet_b3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b3"], ["", "@", "register_model", "\n", "def", "efficientnet_b3a", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B3 @ 320x320 w/ 1.0 test crop-pct \"\"\"", "\n", "# WARN this model def is deprecated, different train/test res + test crop handled by default_cfg now", "\n", "return", "efficientnet_b3", "(", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b4": [[1429, 1436], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b4", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B4 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.4, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_b4'", ",", "channel_multiplier", "=", "1.4", ",", "depth_multiplier", "=", "1.8", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b5": [[1438, 1445], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b5", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B5 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.4, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_b5'", ",", "channel_multiplier", "=", "1.6", ",", "depth_multiplier", "=", "2.2", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b6": [[1447, 1454], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b6", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B6 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.5, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_b6'", ",", "channel_multiplier", "=", "1.8", ",", "depth_multiplier", "=", "2.6", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b7": [[1456, 1463], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b7", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B7 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.5, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_b7'", ",", "channel_multiplier", "=", "2.0", ",", "depth_multiplier", "=", "3.1", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b8": [[1465, 1472], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b8", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B8 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.5, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_b8'", ",", "channel_multiplier", "=", "2.2", ",", "depth_multiplier", "=", "3.6", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_l2": [[1474, 1481], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_l2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-L2.\"\"\"", "\n", "# NOTE for train, drop_rate should be 0.5, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_l2'", ",", "channel_multiplier", "=", "4.3", ",", "depth_multiplier", "=", "5.3", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b0_gn": [[1484, 1490], ["efficientnet._gen_efficientnet", "functools.partial"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b0_gn", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B0 + GroupNorm\"\"\"", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_b0_gn'", ",", "norm_layer", "=", "partial", "(", "GroupNormAct", ",", "group_size", "=", "8", ")", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b0_g8_gn": [[1492, 1499], ["efficientnet._gen_efficientnet", "functools.partial"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b0_g8_gn", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B0 w/ group conv + GroupNorm\"\"\"", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_b0_g8_gn'", ",", "group_size", "=", "8", ",", "norm_layer", "=", "partial", "(", "GroupNormAct", ",", "group_size", "=", "8", ")", ",", "\n", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b0_g16_evos": [[1501, 1508], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b0_g16_evos", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B0 w/ group 16 conv + EvoNorm\"\"\"", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_b0_g16_evos'", ",", "group_size", "=", "16", ",", "channel_divisor", "=", "16", ",", "\n", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "#norm_layer=partial(EvoNorm2dS0, group_size=16),", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b3_gn": [[1510, 1518], ["efficientnet._gen_efficientnet", "functools.partial"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b3_gn", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B3 w/ GroupNorm \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_b3_gn'", ",", "channel_multiplier", "=", "1.2", ",", "depth_multiplier", "=", "1.4", ",", "channel_divisor", "=", "16", ",", "\n", "norm_layer", "=", "partial", "(", "GroupNormAct", ",", "group_size", "=", "16", ")", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b3_g8_gn": [[1520, 1528], ["efficientnet._gen_efficientnet", "functools.partial"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b3_g8_gn", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B3 w/ grouped conv + BN\"\"\"", "\n", "# NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_b3_g8_gn'", ",", "channel_multiplier", "=", "1.2", ",", "depth_multiplier", "=", "1.4", ",", "group_size", "=", "8", ",", "channel_divisor", "=", "16", ",", "\n", "norm_layer", "=", "partial", "(", "GroupNormAct", ",", "group_size", "=", "16", ")", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_es": [[1530, 1536], ["efficientnet._gen_efficientnet_edge"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_edge"], ["", "@", "register_model", "\n", "def", "efficientnet_es", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Edge Small. \"\"\"", "\n", "model", "=", "_gen_efficientnet_edge", "(", "\n", "'efficientnet_es'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_es_pruned": [[1538, 1544], ["efficientnet._gen_efficientnet_edge"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_edge"], ["", "@", "register_model", "\n", "def", "efficientnet_es_pruned", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Edge Small Pruned. For more info: https://github.com/DeGirum/pruned-models/releases/tag/efficientnet_v1.0\"\"\"", "\n", "model", "=", "_gen_efficientnet_edge", "(", "\n", "'efficientnet_es_pruned'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_em": [[1545, 1551], ["efficientnet._gen_efficientnet_edge"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_edge"], ["", "@", "register_model", "\n", "def", "efficientnet_em", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Edge-Medium. \"\"\"", "\n", "model", "=", "_gen_efficientnet_edge", "(", "\n", "'efficientnet_em'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.1", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_el": [[1553, 1559], ["efficientnet._gen_efficientnet_edge"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_edge"], ["", "@", "register_model", "\n", "def", "efficientnet_el", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Edge-Large. \"\"\"", "\n", "model", "=", "_gen_efficientnet_edge", "(", "\n", "'efficientnet_el'", ",", "channel_multiplier", "=", "1.2", ",", "depth_multiplier", "=", "1.4", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_el_pruned": [[1560, 1566], ["efficientnet._gen_efficientnet_edge"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_edge"], ["", "@", "register_model", "\n", "def", "efficientnet_el_pruned", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Edge-Large pruned. For more info: https://github.com/DeGirum/pruned-models/releases/tag/efficientnet_v1.0\"\"\"", "\n", "model", "=", "_gen_efficientnet_edge", "(", "\n", "'efficientnet_el_pruned'", ",", "channel_multiplier", "=", "1.2", ",", "depth_multiplier", "=", "1.4", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_cc_b0_4e": [[1567, 1574], ["efficientnet._gen_efficientnet_condconv"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_condconv"], ["", "@", "register_model", "\n", "def", "efficientnet_cc_b0_4e", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-CondConv-B0 w/ 8 Experts \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet_condconv", "(", "\n", "'efficientnet_cc_b0_4e'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_cc_b0_8e": [[1576, 1584], ["efficientnet._gen_efficientnet_condconv"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_condconv"], ["", "@", "register_model", "\n", "def", "efficientnet_cc_b0_8e", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-CondConv-B0 w/ 8 Experts \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet_condconv", "(", "\n", "'efficientnet_cc_b0_8e'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "experts_multiplier", "=", "2", ",", "\n", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_cc_b1_8e": [[1586, 1594], ["efficientnet._gen_efficientnet_condconv"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_condconv"], ["", "@", "register_model", "\n", "def", "efficientnet_cc_b1_8e", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-CondConv-B1 w/ 8 Experts \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet_condconv", "(", "\n", "'efficientnet_cc_b1_8e'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.1", ",", "experts_multiplier", "=", "2", ",", "\n", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_lite0": [[1596, 1603], ["efficientnet._gen_efficientnet_lite"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_lite"], ["", "@", "register_model", "\n", "def", "efficientnet_lite0", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Lite0 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet_lite", "(", "\n", "'efficientnet_lite0'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_lite1": [[1605, 1612], ["efficientnet._gen_efficientnet_lite"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_lite"], ["", "@", "register_model", "\n", "def", "efficientnet_lite1", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Lite1 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet_lite", "(", "\n", "'efficientnet_lite1'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.1", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_lite2": [[1614, 1621], ["efficientnet._gen_efficientnet_lite"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_lite"], ["", "@", "register_model", "\n", "def", "efficientnet_lite2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Lite2 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet_lite", "(", "\n", "'efficientnet_lite2'", ",", "channel_multiplier", "=", "1.1", ",", "depth_multiplier", "=", "1.2", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_lite3": [[1623, 1630], ["efficientnet._gen_efficientnet_lite"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_lite"], ["", "@", "register_model", "\n", "def", "efficientnet_lite3", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Lite3 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet_lite", "(", "\n", "'efficientnet_lite3'", ",", "channel_multiplier", "=", "1.2", ",", "depth_multiplier", "=", "1.4", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_lite4": [[1632, 1639], ["efficientnet._gen_efficientnet_lite"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_lite"], ["", "@", "register_model", "\n", "def", "efficientnet_lite4", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Lite4 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.4, drop_path_rate should be 0.2", "\n", "model", "=", "_gen_efficientnet_lite", "(", "\n", "'efficientnet_lite4'", ",", "channel_multiplier", "=", "1.4", ",", "depth_multiplier", "=", "1.8", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b1_pruned": [[1641, 1650], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b1_pruned", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B1 Pruned. The pruning has been obtained using https://arxiv.org/pdf/2002.08258.pdf  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "variant", "=", "'efficientnet_b1_pruned'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "variant", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.1", ",", "pruned", "=", "True", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b2_pruned": [[1652, 1661], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b2_pruned", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B2 Pruned. The pruning has been obtained using https://arxiv.org/pdf/2002.08258.pdf \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_b2_pruned'", ",", "channel_multiplier", "=", "1.1", ",", "depth_multiplier", "=", "1.2", ",", "pruned", "=", "True", ",", "\n", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnet_b3_pruned": [[1663, 1672], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "efficientnet_b3_pruned", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B3 Pruned. The pruning has been obtained using https://arxiv.org/pdf/2002.08258.pdf \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'efficientnet_b3_pruned'", ",", "channel_multiplier", "=", "1.2", ",", "depth_multiplier", "=", "1.4", ",", "pruned", "=", "True", ",", "\n", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnetv2_rw_t": [[1674, 1680], ["efficientnet._gen_efficientnetv2_s"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_s"], ["", "@", "register_model", "\n", "def", "efficientnetv2_rw_t", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Tiny (Custom variant, tiny not in paper). \"\"\"", "\n", "model", "=", "_gen_efficientnetv2_s", "(", "\n", "'efficientnetv2_rw_t'", ",", "channel_multiplier", "=", "0.8", ",", "depth_multiplier", "=", "0.9", ",", "rw", "=", "False", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.gc_efficientnetv2_rw_t": [[1682, 1689], ["efficientnet._gen_efficientnetv2_s"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_s"], ["", "@", "register_model", "\n", "def", "gc_efficientnetv2_rw_t", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Tiny w/ Global Context Attn (Custom variant, tiny not in paper). \"\"\"", "\n", "model", "=", "_gen_efficientnetv2_s", "(", "\n", "'gc_efficientnetv2_rw_t'", ",", "channel_multiplier", "=", "0.8", ",", "depth_multiplier", "=", "0.9", ",", "\n", "rw", "=", "False", ",", "se_layer", "=", "'gc'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnetv2_rw_s": [[1691, 1699], ["efficientnet._gen_efficientnetv2_s"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_s"], ["", "@", "register_model", "\n", "def", "efficientnetv2_rw_s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Small (RW variant).\n    NOTE: This is my initial (pre official code release) w/ some differences.\n    See efficientnetv2_s and tf_efficientnetv2_s for versions that match the official w/ PyTorch vs TF padding\n    \"\"\"", "\n", "model", "=", "_gen_efficientnetv2_s", "(", "'efficientnetv2_rw_s'", ",", "rw", "=", "True", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnetv2_rw_m": [[1701, 1709], ["efficientnet._gen_efficientnetv2_s"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_s"], ["", "@", "register_model", "\n", "def", "efficientnetv2_rw_m", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Medium (RW variant).\n    \"\"\"", "\n", "model", "=", "_gen_efficientnetv2_s", "(", "\n", "'efficientnetv2_rw_m'", ",", "channel_multiplier", "=", "1.2", ",", "depth_multiplier", "=", "(", "1.2", ",", ")", "*", "4", "+", "(", "1.6", ",", ")", "*", "2", ",", "rw", "=", "True", ",", "\n", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnetv2_s": [[1711, 1716], ["efficientnet._gen_efficientnetv2_s"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_s"], ["", "@", "register_model", "\n", "def", "efficientnetv2_s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Small. \"\"\"", "\n", "model", "=", "_gen_efficientnetv2_s", "(", "'efficientnetv2_s'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnetv2_m": [[1718, 1723], ["efficientnet._gen_efficientnetv2_m"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_m"], ["", "@", "register_model", "\n", "def", "efficientnetv2_m", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Medium. \"\"\"", "\n", "model", "=", "_gen_efficientnetv2_m", "(", "'efficientnetv2_m'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnetv2_l": [[1725, 1730], ["efficientnet._gen_efficientnetv2_l"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_l"], ["", "@", "register_model", "\n", "def", "efficientnetv2_l", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Large. \"\"\"", "\n", "model", "=", "_gen_efficientnetv2_l", "(", "'efficientnetv2_l'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.efficientnetv2_xl": [[1732, 1737], ["efficientnet._gen_efficientnetv2_xl"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_xl"], ["", "@", "register_model", "\n", "def", "efficientnetv2_xl", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Xtra-Large. \"\"\"", "\n", "model", "=", "_gen_efficientnetv2_xl", "(", "'efficientnetv2_xl'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b0": [[1739, 1747], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b0", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B0. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b0'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b1": [[1749, 1757], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b1", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B1. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b1'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.1", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b2": [[1759, 1767], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B2. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b2'", ",", "channel_multiplier", "=", "1.1", ",", "depth_multiplier", "=", "1.2", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b3": [[1769, 1777], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b3", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B3. Tensorflow compatible variant \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b3'", ",", "channel_multiplier", "=", "1.2", ",", "depth_multiplier", "=", "1.4", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b4": [[1779, 1787], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b4", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B4. Tensorflow compatible variant \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b4'", ",", "channel_multiplier", "=", "1.4", ",", "depth_multiplier", "=", "1.8", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b5": [[1789, 1797], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b5", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B5. Tensorflow compatible variant \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b5'", ",", "channel_multiplier", "=", "1.6", ",", "depth_multiplier", "=", "2.2", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b6": [[1799, 1808], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b6", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B6. Tensorflow compatible variant \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.5", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b6'", ",", "channel_multiplier", "=", "1.8", ",", "depth_multiplier", "=", "2.6", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b7": [[1810, 1819], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b7", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B7. Tensorflow compatible variant \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.5", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b7'", ",", "channel_multiplier", "=", "2.0", ",", "depth_multiplier", "=", "3.1", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b8": [[1821, 1830], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b8", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B8. Tensorflow compatible variant \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.5", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b8'", ",", "channel_multiplier", "=", "2.2", ",", "depth_multiplier", "=", "3.6", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b0_ap": [[1832, 1840], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b0_ap", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B0 AdvProp. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b0_ap'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b1_ap": [[1842, 1850], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b1_ap", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B1 AdvProp. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b1_ap'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.1", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b2_ap": [[1852, 1860], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b2_ap", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B2 AdvProp. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b2_ap'", ",", "channel_multiplier", "=", "1.1", ",", "depth_multiplier", "=", "1.2", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b3_ap": [[1862, 1870], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b3_ap", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B3 AdvProp. Tensorflow compatible variant \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b3_ap'", ",", "channel_multiplier", "=", "1.2", ",", "depth_multiplier", "=", "1.4", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b4_ap": [[1872, 1880], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b4_ap", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B4 AdvProp. Tensorflow compatible variant \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b4_ap'", ",", "channel_multiplier", "=", "1.4", ",", "depth_multiplier", "=", "1.8", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b5_ap": [[1882, 1890], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b5_ap", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B5 AdvProp. Tensorflow compatible variant \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b5_ap'", ",", "channel_multiplier", "=", "1.6", ",", "depth_multiplier", "=", "2.2", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b6_ap": [[1892, 1901], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b6_ap", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B6 AdvProp. Tensorflow compatible variant \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.5", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b6_ap'", ",", "channel_multiplier", "=", "1.8", ",", "depth_multiplier", "=", "2.6", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b7_ap": [[1903, 1912], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b7_ap", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B7 AdvProp. Tensorflow compatible variant \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.5", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b7_ap'", ",", "channel_multiplier", "=", "2.0", ",", "depth_multiplier", "=", "3.1", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b8_ap": [[1914, 1923], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b8_ap", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B8 AdvProp. Tensorflow compatible variant \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.5", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b8_ap'", ",", "channel_multiplier", "=", "2.2", ",", "depth_multiplier", "=", "3.6", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b0_ns": [[1925, 1933], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b0_ns", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B0 NoisyStudent. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b0_ns'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b1_ns": [[1935, 1943], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b1_ns", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B1 NoisyStudent. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b1_ns'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.1", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b2_ns": [[1945, 1953], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b2_ns", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B2 NoisyStudent. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b2_ns'", ",", "channel_multiplier", "=", "1.1", ",", "depth_multiplier", "=", "1.2", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b3_ns": [[1955, 1963], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b3_ns", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B3 NoisyStudent. Tensorflow compatible variant \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b3_ns'", ",", "channel_multiplier", "=", "1.2", ",", "depth_multiplier", "=", "1.4", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b4_ns": [[1965, 1973], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b4_ns", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B4 NoisyStudent. Tensorflow compatible variant \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b4_ns'", ",", "channel_multiplier", "=", "1.4", ",", "depth_multiplier", "=", "1.8", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b5_ns": [[1975, 1983], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b5_ns", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B5 NoisyStudent. Tensorflow compatible variant \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b5_ns'", ",", "channel_multiplier", "=", "1.6", ",", "depth_multiplier", "=", "2.2", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b6_ns": [[1985, 1994], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b6_ns", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B6 NoisyStudent. Tensorflow compatible variant \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.5", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b6_ns'", ",", "channel_multiplier", "=", "1.8", ",", "depth_multiplier", "=", "2.6", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_b7_ns": [[1996, 2005], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_b7_ns", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-B7 NoisyStudent. Tensorflow compatible variant \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.5", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_b7_ns'", ",", "channel_multiplier", "=", "2.0", ",", "depth_multiplier", "=", "3.1", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_l2_ns_475": [[2007, 2016], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_l2_ns_475", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-L2 NoisyStudent @ 475x475. Tensorflow compatible variant \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.5", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_l2_ns_475'", ",", "channel_multiplier", "=", "4.3", ",", "depth_multiplier", "=", "5.3", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_l2_ns": [[2018, 2027], ["efficientnet._gen_efficientnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_l2_ns", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-L2 NoisyStudent. Tensorflow compatible variant \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.5", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet", "(", "\n", "'tf_efficientnet_l2_ns'", ",", "channel_multiplier", "=", "4.3", ",", "depth_multiplier", "=", "5.3", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_es": [[2029, 2037], ["efficientnet._gen_efficientnet_edge"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_edge"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_es", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Edge Small. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet_edge", "(", "\n", "'tf_efficientnet_es'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_em": [[2039, 2047], ["efficientnet._gen_efficientnet_edge"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_edge"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_em", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Edge-Medium. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet_edge", "(", "\n", "'tf_efficientnet_em'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.1", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_el": [[2049, 2057], ["efficientnet._gen_efficientnet_edge"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_edge"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_el", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Edge-Large. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet_edge", "(", "\n", "'tf_efficientnet_el'", ",", "channel_multiplier", "=", "1.2", ",", "depth_multiplier", "=", "1.4", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_cc_b0_4e": [[2059, 2068], ["efficientnet._gen_efficientnet_condconv"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_condconv"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_cc_b0_4e", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-CondConv-B0 w/ 4 Experts. Tensorflow compatible variant \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet_condconv", "(", "\n", "'tf_efficientnet_cc_b0_4e'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_cc_b0_8e": [[2070, 2080], ["efficientnet._gen_efficientnet_condconv"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_condconv"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_cc_b0_8e", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-CondConv-B0 w/ 8 Experts. Tensorflow compatible variant \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet_condconv", "(", "\n", "'tf_efficientnet_cc_b0_8e'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "experts_multiplier", "=", "2", ",", "\n", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_cc_b1_8e": [[2082, 2092], ["efficientnet._gen_efficientnet_condconv"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_condconv"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_cc_b1_8e", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-CondConv-B1 w/ 8 Experts. Tensorflow compatible variant \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet_condconv", "(", "\n", "'tf_efficientnet_cc_b1_8e'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.1", ",", "experts_multiplier", "=", "2", ",", "\n", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_lite0": [[2094, 2103], ["efficientnet._gen_efficientnet_lite"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_lite"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_lite0", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Lite0 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet_lite", "(", "\n", "'tf_efficientnet_lite0'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_lite1": [[2105, 2114], ["efficientnet._gen_efficientnet_lite"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_lite"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_lite1", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Lite1 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet_lite", "(", "\n", "'tf_efficientnet_lite1'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.1", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_lite2": [[2116, 2125], ["efficientnet._gen_efficientnet_lite"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_lite"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_lite2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Lite2 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet_lite", "(", "\n", "'tf_efficientnet_lite2'", ",", "channel_multiplier", "=", "1.1", ",", "depth_multiplier", "=", "1.2", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_lite3": [[2127, 2136], ["efficientnet._gen_efficientnet_lite"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_lite"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_lite3", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Lite3 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet_lite", "(", "\n", "'tf_efficientnet_lite3'", ",", "channel_multiplier", "=", "1.2", ",", "depth_multiplier", "=", "1.4", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnet_lite4": [[2138, 2147], ["efficientnet._gen_efficientnet_lite"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnet_lite"], ["", "@", "register_model", "\n", "def", "tf_efficientnet_lite4", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-Lite4 \"\"\"", "\n", "# NOTE for train, drop_rate should be 0.4, drop_path_rate should be 0.2", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnet_lite", "(", "\n", "'tf_efficientnet_lite4'", ",", "channel_multiplier", "=", "1.4", ",", "depth_multiplier", "=", "1.8", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnetv2_s": [[2150, 2157], ["efficientnet._gen_efficientnetv2_s"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_s"], ["", "@", "register_model", "\n", "def", "tf_efficientnetv2_s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Small. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnetv2_s", "(", "'tf_efficientnetv2_s'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnetv2_m": [[2159, 2166], ["efficientnet._gen_efficientnetv2_m"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_m"], ["", "@", "register_model", "\n", "def", "tf_efficientnetv2_m", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Medium. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnetv2_m", "(", "'tf_efficientnetv2_m'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnetv2_l": [[2168, 2175], ["efficientnet._gen_efficientnetv2_l"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_l"], ["", "@", "register_model", "\n", "def", "tf_efficientnetv2_l", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Large. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnetv2_l", "(", "'tf_efficientnetv2_l'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnetv2_s_in21ft1k": [[2177, 2185], ["efficientnet._gen_efficientnetv2_s"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_s"], ["", "@", "register_model", "\n", "def", "tf_efficientnetv2_s_in21ft1k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Small. Pretrained on ImageNet-21k, fine-tuned on 1k. Tensorflow compatible variant\n    \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnetv2_s", "(", "'tf_efficientnetv2_s_in21ft1k'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnetv2_m_in21ft1k": [[2187, 2195], ["efficientnet._gen_efficientnetv2_m"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_m"], ["", "@", "register_model", "\n", "def", "tf_efficientnetv2_m_in21ft1k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Medium. Pretrained on ImageNet-21k, fine-tuned on 1k. Tensorflow compatible variant\n    \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnetv2_m", "(", "'tf_efficientnetv2_m_in21ft1k'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnetv2_l_in21ft1k": [[2197, 2205], ["efficientnet._gen_efficientnetv2_l"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_l"], ["", "@", "register_model", "\n", "def", "tf_efficientnetv2_l_in21ft1k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Large. Pretrained on ImageNet-21k, fine-tuned on 1k. Tensorflow compatible variant\n    \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnetv2_l", "(", "'tf_efficientnetv2_l_in21ft1k'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnetv2_xl_in21ft1k": [[2207, 2215], ["efficientnet._gen_efficientnetv2_xl"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_xl"], ["", "@", "register_model", "\n", "def", "tf_efficientnetv2_xl_in21ft1k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Xtra-Large. Pretrained on ImageNet-21k, fine-tuned on 1k. Tensorflow compatible variant\n    \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnetv2_xl", "(", "'tf_efficientnetv2_xl_in21ft1k'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnetv2_s_in21k": [[2217, 2225], ["efficientnet._gen_efficientnetv2_s"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_s"], ["", "@", "register_model", "\n", "def", "tf_efficientnetv2_s_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Small w/ ImageNet-21k pretrained weights. Tensorflow compatible variant\n    \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnetv2_s", "(", "'tf_efficientnetv2_s_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnetv2_m_in21k": [[2227, 2235], ["efficientnet._gen_efficientnetv2_m"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_m"], ["", "@", "register_model", "\n", "def", "tf_efficientnetv2_m_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Medium w/ ImageNet-21k pretrained weights. Tensorflow compatible variant\n    \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnetv2_m", "(", "'tf_efficientnetv2_m_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnetv2_l_in21k": [[2237, 2245], ["efficientnet._gen_efficientnetv2_l"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_l"], ["", "@", "register_model", "\n", "def", "tf_efficientnetv2_l_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Large w/ ImageNet-21k pretrained weights. Tensorflow compatible variant\n    \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnetv2_l", "(", "'tf_efficientnetv2_l_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnetv2_xl_in21k": [[2247, 2255], ["efficientnet._gen_efficientnetv2_xl"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_xl"], ["", "@", "register_model", "\n", "def", "tf_efficientnetv2_xl_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2 Xtra-Large w/ ImageNet-21k pretrained weights. Tensorflow compatible variant\n    \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnetv2_xl", "(", "'tf_efficientnetv2_xl_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnetv2_b0": [[2257, 2264], ["efficientnet._gen_efficientnetv2_base"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_base"], ["", "@", "register_model", "\n", "def", "tf_efficientnetv2_b0", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2-B0. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnetv2_base", "(", "'tf_efficientnetv2_b0'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnetv2_b1": [[2266, 2274], ["efficientnet._gen_efficientnetv2_base"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_base"], ["", "@", "register_model", "\n", "def", "tf_efficientnetv2_b1", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2-B1. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnetv2_base", "(", "\n", "'tf_efficientnetv2_b1'", ",", "channel_multiplier", "=", "1.0", ",", "depth_multiplier", "=", "1.1", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnetv2_b2": [[2276, 2284], ["efficientnet._gen_efficientnetv2_base"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_base"], ["", "@", "register_model", "\n", "def", "tf_efficientnetv2_b2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2-B2. Tensorflow compatible variant  \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnetv2_base", "(", "\n", "'tf_efficientnetv2_b2'", ",", "channel_multiplier", "=", "1.1", ",", "depth_multiplier", "=", "1.2", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_efficientnetv2_b3": [[2286, 2294], ["efficientnet._gen_efficientnetv2_base"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_efficientnetv2_base"], ["", "@", "register_model", "\n", "def", "tf_efficientnetv2_b3", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EfficientNet-V2-B3. Tensorflow compatible variant \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_efficientnetv2_base", "(", "\n", "'tf_efficientnetv2_b3'", ",", "channel_multiplier", "=", "1.2", ",", "depth_multiplier", "=", "1.4", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mixnet_s": [[2296, 2303], ["efficientnet._gen_mixnet_s"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mixnet_s"], ["", "@", "register_model", "\n", "def", "mixnet_s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a MixNet Small model.\n    \"\"\"", "\n", "model", "=", "_gen_mixnet_s", "(", "\n", "'mixnet_s'", ",", "channel_multiplier", "=", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mixnet_m": [[2305, 2312], ["efficientnet._gen_mixnet_m"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mixnet_m"], ["", "@", "register_model", "\n", "def", "mixnet_m", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a MixNet Medium model.\n    \"\"\"", "\n", "model", "=", "_gen_mixnet_m", "(", "\n", "'mixnet_m'", ",", "channel_multiplier", "=", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mixnet_l": [[2314, 2321], ["efficientnet._gen_mixnet_m"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mixnet_m"], ["", "@", "register_model", "\n", "def", "mixnet_l", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a MixNet Large model.\n    \"\"\"", "\n", "model", "=", "_gen_mixnet_m", "(", "\n", "'mixnet_l'", ",", "channel_multiplier", "=", "1.3", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mixnet_xl": [[2323, 2331], ["efficientnet._gen_mixnet_m"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mixnet_m"], ["", "@", "register_model", "\n", "def", "mixnet_xl", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a MixNet Extra-Large model.\n    Not a paper spec, experimental def by RW w/ depth scaling.\n    \"\"\"", "\n", "model", "=", "_gen_mixnet_m", "(", "\n", "'mixnet_xl'", ",", "channel_multiplier", "=", "1.6", ",", "depth_multiplier", "=", "1.2", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.mixnet_xxl": [[2333, 2341], ["efficientnet._gen_mixnet_m"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mixnet_m"], ["", "@", "register_model", "\n", "def", "mixnet_xxl", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a MixNet Double Extra Large model.\n    Not a paper spec, experimental def by RW w/ depth scaling.\n    \"\"\"", "\n", "model", "=", "_gen_mixnet_m", "(", "\n", "'mixnet_xxl'", ",", "channel_multiplier", "=", "2.4", ",", "depth_multiplier", "=", "1.3", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_mixnet_s": [[2343, 2352], ["efficientnet._gen_mixnet_s"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mixnet_s"], ["", "@", "register_model", "\n", "def", "tf_mixnet_s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a MixNet Small model. Tensorflow compatible variant\n    \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_mixnet_s", "(", "\n", "'tf_mixnet_s'", ",", "channel_multiplier", "=", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_mixnet_m": [[2354, 2363], ["efficientnet._gen_mixnet_m"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mixnet_m"], ["", "@", "register_model", "\n", "def", "tf_mixnet_m", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a MixNet Medium model. Tensorflow compatible variant\n    \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_mixnet_m", "(", "\n", "'tf_mixnet_m'", ",", "channel_multiplier", "=", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tf_mixnet_l": [[2365, 2374], ["efficientnet._gen_mixnet_m"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_mixnet_m"], ["", "@", "register_model", "\n", "def", "tf_mixnet_l", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a MixNet Large model. Tensorflow compatible variant\n    \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_mixnet_m", "(", "\n", "'tf_mixnet_l'", ",", "channel_multiplier", "=", "1.3", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tinynet_a": [[2376, 2380], ["efficientnet._gen_tinynet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_tinynet"], ["", "@", "register_model", "\n", "def", "tinynet_a", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "_gen_tinynet", "(", "'tinynet_a'", ",", "1.0", ",", "1.2", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tinynet_b": [[2382, 2386], ["efficientnet._gen_tinynet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_tinynet"], ["", "@", "register_model", "\n", "def", "tinynet_b", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "_gen_tinynet", "(", "'tinynet_b'", ",", "0.75", ",", "1.1", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tinynet_c": [[2388, 2392], ["efficientnet._gen_tinynet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_tinynet"], ["", "@", "register_model", "\n", "def", "tinynet_c", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "_gen_tinynet", "(", "'tinynet_c'", ",", "0.54", ",", "0.85", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tinynet_d": [[2394, 2398], ["efficientnet._gen_tinynet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_tinynet"], ["", "@", "register_model", "\n", "def", "tinynet_d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "_gen_tinynet", "(", "'tinynet_d'", ",", "0.54", ",", "0.695", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet.tinynet_e": [[2400, 2404], ["efficientnet._gen_tinynet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet._gen_tinynet"], ["", "@", "register_model", "\n", "def", "tinynet_e", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "_gen_tinynet", "(", "'tinynet_e'", ",", "0.51", ",", "0.6", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.LayerNorm2d.__init__": [[106, 108], ["torch.LayerNorm.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "normalized_shape", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "normalized_shape", ",", "eps", "=", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.LayerNorm2d.forward": [[109, 118], ["convnext._is_contiguous", "torch.layer_norm().permute", "torch.layer_norm().permute", "torch.layer_norm().permute", "torch.var_mean", "torch.var_mean", "torch.var_mean", "torch.var_mean", "torch.var_mean", "torch.var_mean", "torch.var_mean", "torch.var_mean", "torch.var_mean", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.layer_norm", "torch.layer_norm", "torch.layer_norm", "x.permute"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._is_contiguous"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "_is_contiguous", "(", "x", ")", ":", "\n", "            ", "return", "F", ".", "layer_norm", "(", "\n", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ",", "self", ".", "normalized_shape", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "eps", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "", "else", ":", "\n", "            ", "s", ",", "u", "=", "torch", ".", "var_mean", "(", "x", ",", "dim", "=", "1", ",", "unbiased", "=", "False", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "(", "x", "-", "u", ")", "*", "torch", ".", "rsqrt", "(", "s", "+", "self", ".", "eps", ")", "\n", "x", "=", "x", "*", "self", ".", "weight", "[", ":", ",", "None", ",", "None", "]", "+", "self", ".", "bias", "[", ":", ",", "None", ",", "None", "]", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.ConvNeXtBlock.__init__": [[136, 147], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "mlp_layer", "int", "torch.Parameter", "torch.Parameter", "torch.Parameter", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "functools.partial", "functools.partial", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "drop_path", "=", "0.", ",", "ls_init_value", "=", "1e-6", ",", "conv_mlp", "=", "False", ",", "mlp_ratio", "=", "4", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "not", "norm_layer", ":", "\n", "            ", "norm_layer", "=", "partial", "(", "LayerNorm2d", ",", "eps", "=", "1e-6", ")", "if", "conv_mlp", "else", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", "\n", "", "mlp_layer", "=", "ConvMlp", "if", "conv_mlp", "else", "Mlp", "\n", "self", ".", "use_conv_mlp", "=", "conv_mlp", "\n", "self", ".", "conv_dw", "=", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "7", ",", "padding", "=", "3", ",", "groups", "=", "dim", ")", "# depthwise conv", "\n", "self", ".", "norm", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "mlp", "=", "mlp_layer", "(", "dim", ",", "int", "(", "mlp_ratio", "*", "dim", ")", ",", "act_layer", "=", "nn", ".", "GELU", ")", "\n", "self", ".", "gamma", "=", "nn", ".", "Parameter", "(", "ls_init_value", "*", "torch", ".", "ones", "(", "dim", ")", ")", "if", "ls_init_value", ">", "0", "else", "None", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.ConvNeXtBlock.forward": [[148, 163], ["convnext.ConvNeXtBlock.conv_dw", "convnext.ConvNeXtBlock.norm", "convnext.ConvNeXtBlock.mlp", "x.mul.mul.permute", "convnext.ConvNeXtBlock.norm", "convnext.ConvNeXtBlock.mlp", "x.mul.mul.permute", "x.mul.mul.mul", "convnext.ConvNeXtBlock.drop_path", "convnext.ConvNeXtBlock.gamma.reshape"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "conv_dw", "(", "x", ")", "\n", "if", "self", ".", "use_conv_mlp", ":", "\n", "            ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "x", "=", "self", ".", "mlp", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "x", "=", "self", ".", "mlp", "(", "x", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "", "if", "self", ".", "gamma", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", ".", "mul", "(", "self", ".", "gamma", ".", "reshape", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ")", "\n", "", "x", "=", "self", ".", "drop_path", "(", "x", ")", "+", "shortcut", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.ConvNeXtStage.__init__": [[167, 186], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Identity", "torch.Identity", "torch.Identity", "norm_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "convnext.ConvNeXtBlock", "range"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "stride", "=", "2", ",", "depth", "=", "2", ",", "dp_rates", "=", "None", ",", "ls_init_value", "=", "1.0", ",", "conv_mlp", "=", "False", ",", "\n", "norm_layer", "=", "None", ",", "cl_norm_layer", "=", "None", ",", "cross_stage", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "if", "in_chs", "!=", "out_chs", "or", "stride", ">", "1", ":", "\n", "            ", "self", ".", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "norm_layer", "(", "in_chs", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "stride", ",", "stride", "=", "stride", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "downsample", "=", "nn", ".", "Identity", "(", ")", "\n", "\n", "", "dp_rates", "=", "dp_rates", "or", "[", "0.", "]", "*", "depth", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "*", "[", "ConvNeXtBlock", "(", "\n", "dim", "=", "out_chs", ",", "drop_path", "=", "dp_rates", "[", "j", "]", ",", "ls_init_value", "=", "ls_init_value", ",", "conv_mlp", "=", "conv_mlp", ",", "\n", "norm_layer", "=", "norm_layer", "if", "conv_mlp", "else", "cl_norm_layer", ")", "\n", "for", "j", "in", "range", "(", "depth", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.ConvNeXtStage.forward": [[188, 195], ["convnext.ConvNeXtStage.downsample", "helpers.checkpoint_seq", "convnext.ConvNeXtStage.blocks", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "downsample", "(", "x", ")", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "blocks", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "blocks", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.ConvNeXt.__init__": [[212, 280], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "helpers.named_apply", "functools.partial", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "x.tolist", "stages.append", "functools.partial.", "torch.Identity", "torch.Identity", "torch.Identity", "collections.OrderedDict", "functools.partial", "functools.partial", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "functools.partial.", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "functools.partial.", "torch.GELU", "torch.GELU", "torch.GELU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.linspace().split", "torch.linspace().split", "torch.linspace().split", "torch.linspace().split", "torch.linspace().split", "torch.linspace().split", "torch.linspace().split", "torch.linspace().split", "torch.linspace().split", "convnext.ConvNeXtStage", "dict", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "layers.SelectAdaptivePool2d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "sum", "torch.Identity", "torch.Identity", "torch.Identity", "functools.partial.", "torch.Flatten", "torch.Flatten", "torch.Flatten", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_apply"], ["def", "__init__", "(", "\n", "self", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "global_pool", "=", "'avg'", ",", "output_stride", "=", "32", ",", "patch_size", "=", "4", ",", "\n", "depths", "=", "(", "3", ",", "3", ",", "9", ",", "3", ")", ",", "dims", "=", "(", "96", ",", "192", ",", "384", ",", "768", ")", ",", "ls_init_value", "=", "1e-6", ",", "conv_mlp", "=", "False", ",", "stem_type", "=", "'patch'", ",", "\n", "head_init_scale", "=", "1.", ",", "head_norm_first", "=", "False", ",", "norm_layer", "=", "None", ",", "drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "output_stride", "==", "32", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "partial", "(", "LayerNorm2d", ",", "eps", "=", "1e-6", ")", "\n", "cl_norm_layer", "=", "norm_layer", "if", "conv_mlp", "else", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", "\n", "", "else", ":", "\n", "            ", "assert", "conv_mlp", ",", "'If a norm_layer is specified, conv MLP must be used so all norm expect rank-4, channels-first input'", "\n", "cl_norm_layer", "=", "norm_layer", "\n", "\n", "", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "feature_info", "=", "[", "]", "\n", "\n", "# NOTE: this stem is a minimal form of ViT PatchEmbed, as used in SwinTransformer w/ patch_size = 4", "\n", "if", "stem_type", "==", "'patch'", ":", "\n", "            ", "self", ".", "stem", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_chans", ",", "dims", "[", "0", "]", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "patch_size", ")", ",", "\n", "norm_layer", "(", "dims", "[", "0", "]", ")", "\n", ")", "\n", "curr_stride", "=", "patch_size", "\n", "prev_chs", "=", "dims", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "stem", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_chans", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "norm_layer", "(", "32", ")", ",", "\n", "nn", ".", "GELU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", ")", "\n", "curr_stride", "=", "2", "\n", "prev_chs", "=", "64", "\n", "\n", "", "self", ".", "stages", "=", "nn", ".", "Sequential", "(", ")", "\n", "dp_rates", "=", "[", "x", ".", "tolist", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "sum", "(", "depths", ")", ")", ".", "split", "(", "depths", ")", "]", "\n", "stages", "=", "[", "]", "\n", "# 4 feature resolution stages, each consisting of multiple residual blocks", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "            ", "stride", "=", "2", "if", "curr_stride", "==", "2", "or", "i", ">", "0", "else", "1", "\n", "# FIXME support dilation / output_stride", "\n", "curr_stride", "*=", "stride", "\n", "out_chs", "=", "dims", "[", "i", "]", "\n", "stages", ".", "append", "(", "ConvNeXtStage", "(", "\n", "prev_chs", ",", "out_chs", ",", "stride", "=", "stride", ",", "\n", "depth", "=", "depths", "[", "i", "]", ",", "dp_rates", "=", "dp_rates", "[", "i", "]", ",", "ls_init_value", "=", "ls_init_value", ",", "conv_mlp", "=", "conv_mlp", ",", "\n", "norm_layer", "=", "norm_layer", ",", "cl_norm_layer", "=", "cl_norm_layer", ")", "\n", ")", "\n", "prev_chs", "=", "out_chs", "\n", "# NOTE feature_info use currently assumes stage 0 == stride 1, rest are stride 2", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "prev_chs", ",", "reduction", "=", "curr_stride", ",", "module", "=", "f'stages.{i}'", ")", "]", "\n", "", "self", ".", "stages", "=", "nn", ".", "Sequential", "(", "*", "stages", ")", "\n", "\n", "self", ".", "num_features", "=", "prev_chs", "\n", "# if head_norm_first == true, norm -> global pool -> fc ordering, like most other nets", "\n", "# otherwise pool -> norm -> fc, the default ConvNeXt ordering (pretrained FB weights)", "\n", "self", ".", "norm_pre", "=", "norm_layer", "(", "self", ".", "num_features", ")", "if", "head_norm_first", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "head", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'global_pool'", ",", "SelectAdaptivePool2d", "(", "pool_type", "=", "global_pool", ")", ")", ",", "\n", "(", "'norm'", ",", "nn", ".", "Identity", "(", ")", "if", "head_norm_first", "else", "norm_layer", "(", "self", ".", "num_features", ")", ")", ",", "\n", "(", "'flatten'", ",", "nn", ".", "Flatten", "(", "1", ")", "if", "global_pool", "else", "nn", ".", "Identity", "(", ")", ")", ",", "\n", "(", "'drop'", ",", "nn", ".", "Dropout", "(", "self", ".", "drop_rate", ")", ")", ",", "\n", "(", "'fc'", ",", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", ")", "]", ")", ")", "\n", "\n", "named_apply", "(", "partial", "(", "_init_weights", ",", "head_init_scale", "=", "head_init_scale", ")", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.ConvNeXt.group_matcher": [[281, 289], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^stem'", ",", "\n", "blocks", "=", "r'^stages\\.(\\d+)'", "if", "coarse", "else", "[", "\n", "(", "r'^stages\\.(\\d+)\\.downsample'", ",", "(", "0", ",", ")", ")", ",", "# blocks", "\n", "(", "r'^stages\\.(\\d+)\\.blocks\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^norm_pre'", ",", "(", "99999", ",", ")", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.ConvNeXt.set_grad_checkpointing": [[292, 296], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "for", "s", "in", "self", ".", "stages", ":", "\n", "            ", "s", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.ConvNeXt.get_classifier": [[297, 300], ["None"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.ConvNeXt.reset_classifier": [[301, 306], ["layers.SelectAdaptivePool2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Flatten", "torch.Flatten", "torch.Flatten", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", "=", "0", ",", "global_pool", "=", "None", ")", ":", "\n", "        ", "if", "global_pool", "is", "not", "None", ":", "\n", "            ", "self", ".", "head", ".", "global_pool", "=", "SelectAdaptivePool2d", "(", "pool_type", "=", "global_pool", ")", "\n", "self", ".", "head", ".", "flatten", "=", "nn", ".", "Flatten", "(", "1", ")", "if", "global_pool", "else", "nn", ".", "Identity", "(", ")", "\n", "", "self", ".", "head", ".", "fc", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.ConvNeXt.forward_features": [[307, 312], ["convnext.ConvNeXt.stem", "convnext.ConvNeXt.stages", "convnext.ConvNeXt.norm_pre"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.stages"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "x", "=", "self", ".", "stages", "(", "x", ")", "\n", "x", "=", "self", ".", "norm_pre", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.ConvNeXt.forward_head": [[313, 320], ["convnext.ConvNeXt.head.global_pool", "convnext.ConvNeXt.head.norm", "convnext.ConvNeXt.head.flatten", "convnext.ConvNeXt.head.drop", "convnext.ConvNeXt.head.fc"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "# NOTE nn.Sequential in head broken down since can't call head[:-1](x) in torchscript :(", "\n", "        ", "x", "=", "self", ".", "head", ".", "global_pool", "(", "x", ")", "\n", "x", "=", "self", ".", "head", ".", "norm", "(", "x", ")", "\n", "x", "=", "self", ".", "head", ".", "flatten", "(", "x", ")", "\n", "x", "=", "self", ".", "head", ".", "drop", "(", "x", ")", "\n", "return", "x", "if", "pre_logits", "else", "self", ".", "head", ".", "fc", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.ConvNeXt.forward": [[321, 325], ["convnext.ConvNeXt.forward_features", "convnext.ConvNeXt.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._cfg": [[29, 37], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'stem.0'", ",", "'classifier'", ":", "'head.fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._is_contiguous": [[91, 99], ["torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "tensor.is_contiguous", "tensor.is_contiguous"], "function", ["None"], ["def", "_is_contiguous", "(", "tensor", ":", "torch", ".", "Tensor", ")", "->", "bool", ":", "\n", "# jit is oh so lovely :/", "\n", "# if torch.jit.is_tracing():", "\n", "#     return True", "\n", "    ", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "        ", "return", "tensor", ".", "is_contiguous", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "tensor", ".", "is_contiguous", "(", "memory_format", "=", "torch", ".", "contiguous_format", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._init_weights": [[327, 337], ["isinstance", "layers.trunc_normal_", "torch.init.constant_", "isinstance", "layers.trunc_normal_", "torch.init.constant_", "module.weight.data.mul_", "module.bias.data.mul_"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "", "def", "_init_weights", "(", "module", ",", "name", "=", "None", ",", "head_init_scale", "=", "1.0", ")", ":", "\n", "    ", "if", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", ":", "\n", "        ", "trunc_normal_", "(", "module", ".", "weight", ",", "std", "=", ".02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "module", ".", "bias", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "trunc_normal_", "(", "module", ".", "weight", ",", "std", "=", ".02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "module", ".", "bias", ",", "0", ")", "\n", "if", "name", "and", "'head.'", "in", "name", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "mul_", "(", "head_init_scale", ")", "\n", "module", ".", "bias", ".", "data", ".", "mul_", "(", "head_init_scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.checkpoint_filter_fn": [[339, 361], ["state_dict.items", "k.replace.replace", "re.sub", "re.sub", "k.replace.replace", "k.replace.replace", "k.replace.replace", "k.replace.startswith", "k.replace.replace", "v.reshape.reshape", "model.state_dict"], "function", ["None"], ["", "", "", "def", "checkpoint_filter_fn", "(", "state_dict", ",", "model", ")", ":", "\n", "    ", "\"\"\" Remap FB checkpoints -> timm \"\"\"", "\n", "if", "'head.norm.weight'", "in", "state_dict", "or", "'norm_pre.weight'", "in", "state_dict", ":", "\n", "        ", "return", "state_dict", "# non-FB checkpoint", "\n", "", "if", "'model'", "in", "state_dict", ":", "\n", "        ", "state_dict", "=", "state_dict", "[", "'model'", "]", "\n", "", "out_dict", "=", "{", "}", "\n", "import", "re", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "k", "=", "k", ".", "replace", "(", "'downsample_layers.0.'", ",", "'stem.'", ")", "\n", "k", "=", "re", ".", "sub", "(", "r'stages.([0-9]+).([0-9]+)'", ",", "r'stages.\\1.blocks.\\2'", ",", "k", ")", "\n", "k", "=", "re", ".", "sub", "(", "r'downsample_layers.([0-9]+).([0-9]+)'", ",", "r'stages.\\1.downsample.\\2'", ",", "k", ")", "\n", "k", "=", "k", ".", "replace", "(", "'dwconv'", ",", "'conv_dw'", ")", "\n", "k", "=", "k", ".", "replace", "(", "'pwconv'", ",", "'mlp.fc'", ")", "\n", "k", "=", "k", ".", "replace", "(", "'head.'", ",", "'head.fc.'", ")", "\n", "if", "k", ".", "startswith", "(", "'norm.'", ")", ":", "\n", "            ", "k", "=", "k", ".", "replace", "(", "'norm'", ",", "'head.norm'", ")", "\n", "", "if", "v", ".", "ndim", "==", "2", "and", "'head'", "not", "in", "k", ":", "\n", "            ", "model_shape", "=", "model", ".", "state_dict", "(", ")", "[", "k", "]", ".", "shape", "\n", "v", "=", "v", ".", "reshape", "(", "model_shape", ")", "\n", "", "out_dict", "[", "k", "]", "=", "v", "\n", "", "return", "out_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext": [[363, 370], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "def", "_create_convnext", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "build_model_with_cfg", "(", "\n", "ConvNeXt", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_filter_fn", "=", "checkpoint_filter_fn", ",", "\n", "feature_cfg", "=", "dict", "(", "out_indices", "=", "(", "0", ",", "1", ",", "2", ",", "3", ")", ",", "flatten_sequential", "=", "True", ")", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_nano_hnf": [[372, 377], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_nano_hnf", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "(", "2", ",", "2", ",", "8", ",", "2", ")", ",", "dims", "=", "(", "80", ",", "160", ",", "320", ",", "640", ")", ",", "head_norm_first", "=", "True", ",", "conv_mlp", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_nano_hnf'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_tiny_hnf": [[379, 384], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_tiny_hnf", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "(", "3", ",", "3", ",", "9", ",", "3", ")", ",", "dims", "=", "(", "96", ",", "192", ",", "384", ",", "768", ")", ",", "head_norm_first", "=", "True", ",", "conv_mlp", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_tiny_hnf'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_tiny_hnfd": [[386, 392], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_tiny_hnfd", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "depths", "=", "(", "3", ",", "3", ",", "9", ",", "3", ")", ",", "dims", "=", "(", "96", ",", "192", ",", "384", ",", "768", ")", ",", "head_norm_first", "=", "True", ",", "conv_mlp", "=", "True", ",", "stem_type", "=", "'dual'", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_tiny_hnf'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_tiny": [[394, 399], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_tiny", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "(", "3", ",", "3", ",", "9", ",", "3", ")", ",", "dims", "=", "(", "96", ",", "192", ",", "384", ",", "768", ")", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_tiny'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_small": [[401, 406], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_small", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "96", ",", "192", ",", "384", ",", "768", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_small'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_base": [[408, 413], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_base", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_base'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_large": [[415, 420], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_large", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "192", ",", "384", ",", "768", ",", "1536", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_large'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_tiny_in22ft1k": [[422, 427], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_tiny_in22ft1k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_tiny_in22ft1k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_small_in22ft1k": [[429, 434], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_small_in22ft1k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_small_in22ft1k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_base_in22ft1k": [[436, 441], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_base_in22ft1k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_base_in22ft1k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_large_in22ft1k": [[443, 448], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_large_in22ft1k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "192", ",", "384", ",", "768", ",", "1536", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_large_in22ft1k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_xlarge_in22ft1k": [[450, 455], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_xlarge_in22ft1k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "256", ",", "512", ",", "1024", ",", "2048", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_xlarge_in22ft1k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_tiny_384_in22ft1k": [[457, 462], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_tiny_384_in22ft1k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_tiny_384_in22ft1k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_small_384_in22ft1k": [[464, 469], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_small_384_in22ft1k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_small_384_in22ft1k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_base_384_in22ft1k": [[471, 476], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_base_384_in22ft1k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_base_384_in22ft1k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_large_384_in22ft1k": [[478, 483], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_large_384_in22ft1k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "192", ",", "384", ",", "768", ",", "1536", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_large_384_in22ft1k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_xlarge_384_in22ft1k": [[485, 490], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_xlarge_384_in22ft1k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "256", ",", "512", ",", "1024", ",", "2048", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_xlarge_384_in22ft1k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_tiny_in22k": [[492, 497], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_tiny_in22k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_tiny_in22k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_small_in22k": [[499, 504], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_small_in22k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_small_in22k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_base_in22k": [[506, 511], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_base_in22k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_base_in22k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_large_in22k": [[513, 518], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_large_in22k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "192", ",", "384", ",", "768", ",", "1536", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_large_in22k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext.convnext_xlarge_in22k": [[520, 525], ["dict", "convnext._create_convnext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convnext._create_convnext"], ["", "@", "register_model", "\n", "def", "convnext_xlarge_in22k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "256", ",", "512", ",", "1024", ",", "2048", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "'convnext_xlarge_in22k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net.Bottle2neck.__init__": [[53, 90], ["torch.Module.__init__", "max", "torch.Conv2d", "torch.Conv2d", "norm_layer", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Conv2d", "torch.Conv2d", "norm_layer", "act_layer", "int", "convs.append", "bns.append", "torch.AvgPool2d", "torch.AvgPool2d", "attn_layer", "math.floor", "torch.Conv2d", "torch.Conv2d", "norm_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "\n", "cardinality", "=", "1", ",", "base_width", "=", "26", ",", "scale", "=", "4", ",", "dilation", "=", "1", ",", "first_dilation", "=", "None", ",", "\n", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "None", ",", "attn_layer", "=", "None", ",", "**", "_", ")", ":", "\n", "        ", "super", "(", "Bottle2neck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "is_first", "=", "stride", ">", "1", "or", "downsample", "is", "not", "None", "\n", "self", ".", "num_scales", "=", "max", "(", "1", ",", "scale", "-", "1", ")", "\n", "width", "=", "int", "(", "math", ".", "floor", "(", "planes", "*", "(", "base_width", "/", "64.0", ")", ")", ")", "*", "cardinality", "\n", "self", ".", "width", "=", "width", "\n", "outplanes", "=", "planes", "*", "self", ".", "expansion", "\n", "first_dilation", "=", "first_dilation", "or", "dilation", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "width", "*", "scale", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "width", "*", "scale", ")", "\n", "\n", "convs", "=", "[", "]", "\n", "bns", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_scales", ")", ":", "\n", "            ", "convs", ".", "append", "(", "nn", ".", "Conv2d", "(", "\n", "width", ",", "width", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "first_dilation", ",", "\n", "dilation", "=", "first_dilation", ",", "groups", "=", "cardinality", ",", "bias", "=", "False", ")", ")", "\n", "bns", ".", "append", "(", "norm_layer", "(", "width", ")", ")", "\n", "", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", "convs", ")", "\n", "self", ".", "bns", "=", "nn", ".", "ModuleList", "(", "bns", ")", "\n", "if", "self", ".", "is_first", ":", "\n", "# FIXME this should probably have count_include_pad=False, but hurts original weights", "\n", "            ", "self", ".", "pool", "=", "nn", ".", "AvgPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "pool", "=", "None", "\n", "\n", "", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "width", "*", "scale", ",", "outplanes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "norm_layer", "(", "outplanes", ")", "\n", "self", ".", "se", "=", "attn_layer", "(", "outplanes", ")", "if", "attn_layer", "is", "not", "None", "else", "None", "\n", "\n", "self", ".", "relu", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net.Bottle2neck.zero_init_last": [[91, 93], ["torch.init.zeros_", "torch.init.zeros_"], "methods", ["None"], ["", "def", "zero_init_last", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "bn3", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net.Bottle2neck.forward": [[94, 133], ["res2net.Bottle2neck.conv1", "res2net.Bottle2neck.bn1", "res2net.Bottle2neck.relu", "torch.split", "torch.split", "torch.split", "torch.split", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "res2net.Bottle2neck.conv3", "res2net.Bottle2neck.bn3", "res2net.Bottle2neck.relu", "zip", "conv", "bn", "res2net.Bottle2neck.relu", "spo.append", "res2net.Bottle2neck.se", "res2net.Bottle2neck.downsample", "spo.append", "spo.append", "res2net.Bottle2neck.pool"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "spx", "=", "torch", ".", "split", "(", "out", ",", "self", ".", "width", ",", "1", ")", "\n", "spo", "=", "[", "]", "\n", "sp", "=", "spx", "[", "0", "]", "# redundant, for torchscript", "\n", "for", "i", ",", "(", "conv", ",", "bn", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "convs", ",", "self", ".", "bns", ")", ")", ":", "\n", "            ", "if", "i", "==", "0", "or", "self", ".", "is_first", ":", "\n", "                ", "sp", "=", "spx", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "sp", "=", "sp", "+", "spx", "[", "i", "]", "\n", "", "sp", "=", "conv", "(", "sp", ")", "\n", "sp", "=", "bn", "(", "sp", ")", "\n", "sp", "=", "self", ".", "relu", "(", "sp", ")", "\n", "spo", ".", "append", "(", "sp", ")", "\n", "", "if", "self", ".", "scale", ">", "1", ":", "\n", "            ", "if", "self", ".", "pool", "is", "not", "None", ":", "# self.is_first == True, None check for torchscript", "\n", "                ", "spo", ".", "append", "(", "self", ".", "pool", "(", "spx", "[", "-", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "spo", ".", "append", "(", "spx", "[", "-", "1", "]", ")", "\n", "", "", "out", "=", "torch", ".", "cat", "(", "spo", ",", "1", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "se", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "se", "(", "out", ")", "\n", "\n", "", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "shortcut", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net._cfg": [[18, 26], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bilinear'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'conv1'", ",", "'classifier'", ":", "'fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net._create_res2net": [[135, 137], ["helpers.build_model_with_cfg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_res2net", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "ResNet", ",", "variant", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net.res2net50_26w_4s": [[139, 148], ["dict", "res2net._create_res2net", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net._create_res2net"], ["", "@", "register_model", "\n", "def", "res2net50_26w_4s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a Res2Net-50 26w4s model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottle2neck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "base_width", "=", "26", ",", "block_args", "=", "dict", "(", "scale", "=", "4", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_res2net", "(", "'res2net50_26w_4s'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net.res2net101_26w_4s": [[150, 159], ["dict", "res2net._create_res2net", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net._create_res2net"], ["", "@", "register_model", "\n", "def", "res2net101_26w_4s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a Res2Net-101 26w4s model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottle2neck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "base_width", "=", "26", ",", "block_args", "=", "dict", "(", "scale", "=", "4", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_res2net", "(", "'res2net101_26w_4s'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net.res2net50_26w_6s": [[161, 170], ["dict", "res2net._create_res2net", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net._create_res2net"], ["", "@", "register_model", "\n", "def", "res2net50_26w_6s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a Res2Net-50 26w6s model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottle2neck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "base_width", "=", "26", ",", "block_args", "=", "dict", "(", "scale", "=", "6", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_res2net", "(", "'res2net50_26w_6s'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net.res2net50_26w_8s": [[172, 181], ["dict", "res2net._create_res2net", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net._create_res2net"], ["", "@", "register_model", "\n", "def", "res2net50_26w_8s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a Res2Net-50 26w8s model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottle2neck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "base_width", "=", "26", ",", "block_args", "=", "dict", "(", "scale", "=", "8", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_res2net", "(", "'res2net50_26w_8s'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net.res2net50_48w_2s": [[183, 192], ["dict", "res2net._create_res2net", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net._create_res2net"], ["", "@", "register_model", "\n", "def", "res2net50_48w_2s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a Res2Net-50 48w2s model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottle2neck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "base_width", "=", "48", ",", "block_args", "=", "dict", "(", "scale", "=", "2", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_res2net", "(", "'res2net50_48w_2s'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net.res2net50_14w_8s": [[194, 203], ["dict", "res2net._create_res2net", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net._create_res2net"], ["", "@", "register_model", "\n", "def", "res2net50_14w_8s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a Res2Net-50 14w8s model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottle2neck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "base_width", "=", "14", ",", "block_args", "=", "dict", "(", "scale", "=", "8", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_res2net", "(", "'res2net50_14w_8s'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net.res2next50": [[205, 214], ["dict", "res2net._create_res2net", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.res2net._create_res2net"], ["", "@", "register_model", "\n", "def", "res2next50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Construct Res2NeXt-50 4s\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottle2neck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "base_width", "=", "4", ",", "cardinality", "=", "8", ",", "block_args", "=", "dict", "(", "scale", "=", "4", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_res2net", "(", "'res2next50'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.SeparableConv2d.__init__": [[55, 73], ["torch.Module.__init__", "layers.create_conv2d", "norm_layer", "layers.create_conv2d", "norm_layer", "act_layer", "torch.Identity", "torch.Identity", "act_layer", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "padding", "=", "''", ",", "\n", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "SeparableConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "dilation", "=", "dilation", "\n", "\n", "# depthwise convolution", "\n", "self", ".", "conv_dw", "=", "create_conv2d", "(", "\n", "in_chs", ",", "in_chs", ",", "kernel_size", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "depthwise", "=", "True", ")", "\n", "self", ".", "bn_dw", "=", "norm_layer", "(", "in_chs", ")", "\n", "self", ".", "act_dw", "=", "act_layer", "(", "inplace", "=", "True", ")", "if", "act_layer", "is", "not", "None", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "# pointwise convolution", "\n", "self", ".", "conv_pw", "=", "create_conv2d", "(", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "bn_pw", "=", "norm_layer", "(", "out_chs", ")", "\n", "self", ".", "act_pw", "=", "act_layer", "(", "inplace", "=", "True", ")", "if", "act_layer", "is", "not", "None", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.SeparableConv2d.forward": [[74, 82], ["xception_aligned.SeparableConv2d.conv_dw", "xception_aligned.SeparableConv2d.bn_dw", "xception_aligned.SeparableConv2d.act_dw", "xception_aligned.SeparableConv2d.conv_pw", "xception_aligned.SeparableConv2d.bn_pw", "xception_aligned.SeparableConv2d.act_pw"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv_dw", "(", "x", ")", "\n", "x", "=", "self", ".", "bn_dw", "(", "x", ")", "\n", "x", "=", "self", ".", "act_dw", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_pw", "(", "x", ")", "\n", "x", "=", "self", ".", "bn_pw", "(", "x", ")", "\n", "x", "=", "self", ".", "act_pw", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.PreSeparableConv2d.__init__": [[85, 101], ["torch.Module.__init__", "layers.get_norm_act_layer", "layers.create_conv2d", "layers.create_conv2d", "layers.get_norm_act_layer.", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "padding", "=", "''", ",", "\n", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "first_act", "=", "True", ")", ":", "\n", "        ", "super", "(", "PreSeparableConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "norm_act_layer", "=", "get_norm_act_layer", "(", "norm_layer", ",", "act_layer", "=", "act_layer", ")", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "dilation", "=", "dilation", "\n", "\n", "self", ".", "norm", "=", "norm_act_layer", "(", "in_chs", ",", "inplace", "=", "True", ")", "if", "first_act", "else", "nn", ".", "Identity", "(", ")", "\n", "# depthwise convolution", "\n", "self", ".", "conv_dw", "=", "create_conv2d", "(", "\n", "in_chs", ",", "in_chs", ",", "kernel_size", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "depthwise", "=", "True", ")", "\n", "\n", "# pointwise convolution", "\n", "self", ".", "conv_pw", "=", "create_conv2d", "(", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.PreSeparableConv2d.forward": [[102, 107], ["xception_aligned.PreSeparableConv2d.norm", "xception_aligned.PreSeparableConv2d.conv_dw", "xception_aligned.PreSeparableConv2d.conv_pw"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_dw", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_pw", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.XceptionModule.__init__": [[110, 133], ["torch.Module.__init__", "layers.helpers.to_3tuple", "torch.Sequential", "torch.Sequential", "range", "layers.ConvNormAct", "xception_aligned.XceptionModule.stack.add_module", "xception_aligned.XceptionModule.stack.add_module", "xception_aligned.SeparableConv2d", "act_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "pad_type", "=", "''", ",", "\n", "start_with_relu", "=", "True", ",", "no_skip", "=", "False", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "XceptionModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "out_chs", "=", "to_3tuple", "(", "out_chs", ")", "\n", "self", ".", "in_channels", "=", "in_chs", "\n", "self", ".", "out_channels", "=", "out_chs", "[", "-", "1", "]", "\n", "self", ".", "no_skip", "=", "no_skip", "\n", "if", "not", "no_skip", "and", "(", "self", ".", "out_channels", "!=", "self", ".", "in_channels", "or", "stride", "!=", "1", ")", ":", "\n", "            ", "self", ".", "shortcut", "=", "ConvNormAct", "(", "\n", "in_chs", ",", "self", ".", "out_channels", ",", "1", ",", "stride", "=", "stride", ",", "norm_layer", "=", "norm_layer", ",", "apply_act", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "shortcut", "=", "None", "\n", "\n", "", "separable_act_layer", "=", "None", "if", "start_with_relu", "else", "act_layer", "\n", "self", ".", "stack", "=", "nn", ".", "Sequential", "(", ")", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "if", "start_with_relu", ":", "\n", "                ", "self", ".", "stack", ".", "add_module", "(", "f'act{i + 1}'", ",", "act_layer", "(", "inplace", "=", "i", ">", "0", ")", ")", "\n", "", "self", ".", "stack", ".", "add_module", "(", "f'conv{i + 1}'", ",", "SeparableConv2d", "(", "\n", "in_chs", ",", "out_chs", "[", "i", "]", ",", "3", ",", "stride", "=", "stride", "if", "i", "==", "2", "else", "1", ",", "dilation", "=", "dilation", ",", "padding", "=", "pad_type", ",", "\n", "act_layer", "=", "separable_act_layer", ",", "norm_layer", "=", "norm_layer", ")", ")", "\n", "in_chs", "=", "out_chs", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.XceptionModule.forward": [[134, 142], ["xception_aligned.XceptionModule.stack", "xception_aligned.XceptionModule.shortcut"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "skip", "=", "x", "\n", "x", "=", "self", ".", "stack", "(", "x", ")", "\n", "if", "self", ".", "shortcut", "is", "not", "None", ":", "\n", "            ", "skip", "=", "self", ".", "shortcut", "(", "skip", ")", "\n", "", "if", "not", "self", ".", "no_skip", ":", "\n", "            ", "x", "=", "x", "+", "skip", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.PreXceptionModule.__init__": [[145, 165], ["torch.Module.__init__", "layers.helpers.to_3tuple", "torch.Sequential", "torch.Sequential", "range", "layers.create_conv2d", "torch.Identity", "torch.Identity", "layers.get_norm_act_layer", "xception_aligned.PreXceptionModule.stack.add_module", "xception_aligned.PreSeparableConv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "pad_type", "=", "''", ",", "\n", "no_skip", "=", "False", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "PreXceptionModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "out_chs", "=", "to_3tuple", "(", "out_chs", ")", "\n", "self", ".", "in_channels", "=", "in_chs", "\n", "self", ".", "out_channels", "=", "out_chs", "[", "-", "1", "]", "\n", "self", ".", "no_skip", "=", "no_skip", "\n", "if", "not", "no_skip", "and", "(", "self", ".", "out_channels", "!=", "self", ".", "in_channels", "or", "stride", "!=", "1", ")", ":", "\n", "            ", "self", ".", "shortcut", "=", "create_conv2d", "(", "in_chs", ",", "self", ".", "out_channels", ",", "1", ",", "stride", "=", "stride", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Identity", "(", ")", "\n", "\n", "", "self", ".", "norm", "=", "get_norm_act_layer", "(", "norm_layer", ",", "act_layer", "=", "act_layer", ")", "(", "in_chs", ",", "inplace", "=", "True", ")", "\n", "self", ".", "stack", "=", "nn", ".", "Sequential", "(", ")", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "self", ".", "stack", ".", "add_module", "(", "f'conv{i + 1}'", ",", "PreSeparableConv2d", "(", "\n", "in_chs", ",", "out_chs", "[", "i", "]", ",", "3", ",", "stride", "=", "stride", "if", "i", "==", "2", "else", "1", ",", "dilation", "=", "dilation", ",", "padding", "=", "pad_type", ",", "\n", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ",", "first_act", "=", "i", ">", "0", ")", ")", "\n", "in_chs", "=", "out_chs", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.PreXceptionModule.forward": [[166, 173], ["xception_aligned.PreXceptionModule.norm", "xception_aligned.PreXceptionModule.stack", "xception_aligned.PreXceptionModule.shortcut"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "skip", "=", "x", "\n", "x", "=", "self", ".", "stack", "(", "x", ")", "\n", "if", "not", "self", ".", "no_skip", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "shortcut", "(", "skip", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.XceptionAligned.__init__": [[179, 219], ["torch.Module.__init__", "dict", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "enumerate", "layers.ClassifierHead", "xception_aligned.XceptionAligned.blocks.add_module", "dict", "act_layer", "torch.Identity", "torch.Identity", "str", "module_fn", "layers.ConvNormAct", "dict", "layers.create_conv2d", "layers.ConvNormAct", "str", "layers.helpers.to_3tuple", "len"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["def", "__init__", "(", "\n", "self", ",", "block_cfg", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "output_stride", "=", "32", ",", "preact", "=", "False", ",", "\n", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "drop_rate", "=", "0.", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "super", "(", "XceptionAligned", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "output_stride", "in", "(", "8", ",", "16", ",", "32", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "layer_args", "=", "dict", "(", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "stem", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "ConvNormAct", "(", "in_chans", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "**", "layer_args", ")", ",", "\n", "create_conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "if", "preact", "else", "\n", "ConvNormAct", "(", "32", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "**", "layer_args", ")", "\n", "]", ")", "\n", "\n", "curr_dilation", "=", "1", "\n", "curr_stride", "=", "2", "\n", "self", ".", "feature_info", "=", "[", "]", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", ")", "\n", "module_fn", "=", "PreXceptionModule", "if", "preact", "else", "XceptionModule", "\n", "for", "i", ",", "b", "in", "enumerate", "(", "block_cfg", ")", ":", "\n", "            ", "b", "[", "'dilation'", "]", "=", "curr_dilation", "\n", "if", "b", "[", "'stride'", "]", ">", "1", ":", "\n", "                ", "name", "=", "f'blocks.{i}.stack.conv2'", "if", "preact", "else", "f'blocks.{i}.stack.act3'", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "to_3tuple", "(", "b", "[", "'out_chs'", "]", ")", "[", "-", "2", "]", ",", "reduction", "=", "curr_stride", ",", "module", "=", "name", ")", "]", "\n", "next_stride", "=", "curr_stride", "*", "b", "[", "'stride'", "]", "\n", "if", "next_stride", ">", "output_stride", ":", "\n", "                    ", "curr_dilation", "*=", "b", "[", "'stride'", "]", "\n", "b", "[", "'stride'", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "curr_stride", "=", "next_stride", "\n", "", "", "self", ".", "blocks", ".", "add_module", "(", "str", "(", "i", ")", ",", "module_fn", "(", "**", "b", ",", "**", "layer_args", ")", ")", "\n", "self", ".", "num_features", "=", "self", ".", "blocks", "[", "-", "1", "]", ".", "out_channels", "\n", "\n", "", "self", ".", "feature_info", "+=", "[", "dict", "(", "\n", "num_chs", "=", "self", ".", "num_features", ",", "reduction", "=", "curr_stride", ",", "module", "=", "'blocks.'", "+", "str", "(", "len", "(", "self", ".", "blocks", ")", "-", "1", ")", ")", "]", "\n", "self", ".", "act", "=", "act_layer", "(", "inplace", "=", "True", ")", "if", "preact", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "head", "=", "ClassifierHead", "(", "\n", "in_chs", "=", "self", ".", "num_features", ",", "num_classes", "=", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "drop_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.XceptionAligned.group_matcher": [[220, 225], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^stem'", ",", "\n", "blocks", "=", "r'^blocks\\.(\\d+)'", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.XceptionAligned.set_grad_checkpointing": [[227, 230], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.XceptionAligned.get_classifier": [[231, 234], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.XceptionAligned.reset_classifier": [[235, 237], ["layers.ClassifierHead"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "head", "=", "ClassifierHead", "(", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "self", ".", "drop_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.XceptionAligned.forward_features": [[238, 246], ["xception_aligned.XceptionAligned.stem", "xception_aligned.XceptionAligned.act", "helpers.checkpoint_seq", "xception_aligned.XceptionAligned.blocks", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "blocks", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "blocks", "(", "x", ")", "\n", "", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.XceptionAligned.forward_head": [[247, 249], ["xception_aligned.XceptionAligned.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "head", "(", "x", ",", "pre_logits", "=", "pre_logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.XceptionAligned.forward": [[250, 254], ["xception_aligned.XceptionAligned.forward_features", "xception_aligned.XceptionAligned.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned._cfg": [[22, 30], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "299", ",", "299", ")", ",", "'pool_size'", ":", "(", "10", ",", "10", ")", ",", "\n", "'crop_pct'", ":", "0.903", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_INCEPTION_MEAN", ",", "'std'", ":", "IMAGENET_INCEPTION_STD", ",", "\n", "'first_conv'", ":", "'stem.0.conv'", ",", "'classifier'", ":", "'head.fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned._xception": [[256, 261], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_xception", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "\n", "XceptionAligned", ",", "variant", ",", "pretrained", ",", "\n", "feature_cfg", "=", "dict", "(", "flatten_sequential", "=", "True", ",", "feature_cls", "=", "'hook'", ")", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.xception41": [[263, 280], ["dict", "xception_aligned._xception", "dict", "dict", "dict", "dict", "dict", "functools.partial", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception._xception"], ["", "@", "register_model", "\n", "def", "xception41", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Modified Aligned Xception-41\n    \"\"\"", "\n", "block_cfg", "=", "[", "\n", "# entry flow", "\n", "dict", "(", "in_chs", "=", "64", ",", "out_chs", "=", "128", ",", "stride", "=", "2", ")", ",", "\n", "dict", "(", "in_chs", "=", "128", ",", "out_chs", "=", "256", ",", "stride", "=", "2", ")", ",", "\n", "dict", "(", "in_chs", "=", "256", ",", "out_chs", "=", "728", ",", "stride", "=", "2", ")", ",", "\n", "# middle flow", "\n", "*", "(", "[", "dict", "(", "in_chs", "=", "728", ",", "out_chs", "=", "728", ",", "stride", "=", "1", ")", "]", "*", "8", ")", ",", "\n", "# exit flow", "\n", "dict", "(", "in_chs", "=", "728", ",", "out_chs", "=", "(", "728", ",", "1024", ",", "1024", ")", ",", "stride", "=", "2", ")", ",", "\n", "dict", "(", "in_chs", "=", "1024", ",", "out_chs", "=", "(", "1536", ",", "1536", ",", "2048", ")", ",", "stride", "=", "1", ",", "no_skip", "=", "True", ",", "start_with_relu", "=", "False", ")", ",", "\n", "]", "\n", "model_args", "=", "dict", "(", "block_cfg", "=", "block_cfg", ",", "norm_layer", "=", "partial", "(", "nn", ".", "BatchNorm2d", ",", "eps", "=", ".001", ",", "momentum", "=", ".1", ")", ",", "**", "kwargs", ")", "\n", "return", "_xception", "(", "'xception41'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.xception65": [[282, 299], ["dict", "xception_aligned._xception", "dict", "dict", "dict", "dict", "dict", "functools.partial", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception._xception"], ["", "@", "register_model", "\n", "def", "xception65", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Modified Aligned Xception-65\n    \"\"\"", "\n", "block_cfg", "=", "[", "\n", "# entry flow", "\n", "dict", "(", "in_chs", "=", "64", ",", "out_chs", "=", "128", ",", "stride", "=", "2", ")", ",", "\n", "dict", "(", "in_chs", "=", "128", ",", "out_chs", "=", "256", ",", "stride", "=", "2", ")", ",", "\n", "dict", "(", "in_chs", "=", "256", ",", "out_chs", "=", "728", ",", "stride", "=", "2", ")", ",", "\n", "# middle flow", "\n", "*", "(", "[", "dict", "(", "in_chs", "=", "728", ",", "out_chs", "=", "728", ",", "stride", "=", "1", ")", "]", "*", "16", ")", ",", "\n", "# exit flow", "\n", "dict", "(", "in_chs", "=", "728", ",", "out_chs", "=", "(", "728", ",", "1024", ",", "1024", ")", ",", "stride", "=", "2", ")", ",", "\n", "dict", "(", "in_chs", "=", "1024", ",", "out_chs", "=", "(", "1536", ",", "1536", ",", "2048", ")", ",", "stride", "=", "1", ",", "no_skip", "=", "True", ",", "start_with_relu", "=", "False", ")", ",", "\n", "]", "\n", "model_args", "=", "dict", "(", "block_cfg", "=", "block_cfg", ",", "norm_layer", "=", "partial", "(", "nn", ".", "BatchNorm2d", ",", "eps", "=", ".001", ",", "momentum", "=", ".1", ")", ",", "**", "kwargs", ")", "\n", "return", "_xception", "(", "'xception65'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.xception71": [[301, 320], ["dict", "xception_aligned._xception", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "functools.partial", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception._xception"], ["", "@", "register_model", "\n", "def", "xception71", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Modified Aligned Xception-71\n    \"\"\"", "\n", "block_cfg", "=", "[", "\n", "# entry flow", "\n", "dict", "(", "in_chs", "=", "64", ",", "out_chs", "=", "128", ",", "stride", "=", "2", ")", ",", "\n", "dict", "(", "in_chs", "=", "128", ",", "out_chs", "=", "256", ",", "stride", "=", "1", ")", ",", "\n", "dict", "(", "in_chs", "=", "256", ",", "out_chs", "=", "256", ",", "stride", "=", "2", ")", ",", "\n", "dict", "(", "in_chs", "=", "256", ",", "out_chs", "=", "728", ",", "stride", "=", "1", ")", ",", "\n", "dict", "(", "in_chs", "=", "728", ",", "out_chs", "=", "728", ",", "stride", "=", "2", ")", ",", "\n", "# middle flow", "\n", "*", "(", "[", "dict", "(", "in_chs", "=", "728", ",", "out_chs", "=", "728", ",", "stride", "=", "1", ")", "]", "*", "16", ")", ",", "\n", "# exit flow", "\n", "dict", "(", "in_chs", "=", "728", ",", "out_chs", "=", "(", "728", ",", "1024", ",", "1024", ")", ",", "stride", "=", "2", ")", ",", "\n", "dict", "(", "in_chs", "=", "1024", ",", "out_chs", "=", "(", "1536", ",", "1536", ",", "2048", ")", ",", "stride", "=", "1", ",", "no_skip", "=", "True", ",", "start_with_relu", "=", "False", ")", ",", "\n", "]", "\n", "model_args", "=", "dict", "(", "block_cfg", "=", "block_cfg", ",", "norm_layer", "=", "partial", "(", "nn", ".", "BatchNorm2d", ",", "eps", "=", ".001", ",", "momentum", "=", ".1", ")", ",", "**", "kwargs", ")", "\n", "return", "_xception", "(", "'xception71'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.xception41p": [[322, 339], ["dict", "xception_aligned._xception", "dict", "dict", "dict", "dict", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception._xception"], ["", "@", "register_model", "\n", "def", "xception41p", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Modified Aligned Xception-41 w/ Pre-Act\n    \"\"\"", "\n", "block_cfg", "=", "[", "\n", "# entry flow", "\n", "dict", "(", "in_chs", "=", "64", ",", "out_chs", "=", "128", ",", "stride", "=", "2", ")", ",", "\n", "dict", "(", "in_chs", "=", "128", ",", "out_chs", "=", "256", ",", "stride", "=", "2", ")", ",", "\n", "dict", "(", "in_chs", "=", "256", ",", "out_chs", "=", "728", ",", "stride", "=", "2", ")", ",", "\n", "# middle flow", "\n", "*", "(", "[", "dict", "(", "in_chs", "=", "728", ",", "out_chs", "=", "728", ",", "stride", "=", "1", ")", "]", "*", "8", ")", ",", "\n", "# exit flow", "\n", "dict", "(", "in_chs", "=", "728", ",", "out_chs", "=", "(", "728", ",", "1024", ",", "1024", ")", ",", "stride", "=", "2", ")", ",", "\n", "dict", "(", "in_chs", "=", "1024", ",", "out_chs", "=", "(", "1536", ",", "1536", ",", "2048", ")", ",", "no_skip", "=", "True", ",", "stride", "=", "1", ")", ",", "\n", "]", "\n", "model_args", "=", "dict", "(", "block_cfg", "=", "block_cfg", ",", "preact", "=", "True", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "**", "kwargs", ")", "\n", "return", "_xception", "(", "'xception41p'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception_aligned.xception65p": [[341, 359], ["dict", "xception_aligned._xception", "dict", "dict", "dict", "dict", "dict", "functools.partial", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception._xception"], ["", "@", "register_model", "\n", "def", "xception65p", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Modified Aligned Xception-65 w/ Pre-Act\n    \"\"\"", "\n", "block_cfg", "=", "[", "\n", "# entry flow", "\n", "dict", "(", "in_chs", "=", "64", ",", "out_chs", "=", "128", ",", "stride", "=", "2", ")", ",", "\n", "dict", "(", "in_chs", "=", "128", ",", "out_chs", "=", "256", ",", "stride", "=", "2", ")", ",", "\n", "dict", "(", "in_chs", "=", "256", ",", "out_chs", "=", "728", ",", "stride", "=", "2", ")", ",", "\n", "# middle flow", "\n", "*", "(", "[", "dict", "(", "in_chs", "=", "728", ",", "out_chs", "=", "728", ",", "stride", "=", "1", ")", "]", "*", "16", ")", ",", "\n", "# exit flow", "\n", "dict", "(", "in_chs", "=", "728", ",", "out_chs", "=", "(", "728", ",", "1024", ",", "1024", ")", ",", "stride", "=", "2", ")", ",", "\n", "dict", "(", "in_chs", "=", "1024", ",", "out_chs", "=", "(", "1536", ",", "1536", ",", "2048", ")", ",", "stride", "=", "1", ",", "no_skip", "=", "True", ")", ",", "\n", "]", "\n", "model_args", "=", "dict", "(", "\n", "block_cfg", "=", "block_cfg", ",", "preact", "=", "True", ",", "norm_layer", "=", "partial", "(", "nn", ".", "BatchNorm2d", ",", "eps", "=", ".001", ",", "momentum", "=", ".1", ")", ",", "**", "kwargs", ")", "\n", "return", "_xception", "(", "'xception65p'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.get_cache_dir": [[27, 40], ["os.getenv", "get_dir", "os.path.join", "os.makedirs", "_logger.warning"], "function", ["None"], ["def", "get_cache_dir", "(", "child_dir", "=", "''", ")", ":", "\n", "    ", "\"\"\"\n    Returns the location of the directory where models are cached (and creates it if necessary).\n    \"\"\"", "\n", "# Issue warning to move data if old env is set", "\n", "if", "os", ".", "getenv", "(", "'TORCH_MODEL_ZOO'", ")", ":", "\n", "        ", "_logger", ".", "warning", "(", "'TORCH_MODEL_ZOO is deprecated, please use env TORCH_HOME instead'", ")", "\n", "\n", "", "hub_dir", "=", "get_dir", "(", ")", "\n", "child_dir", "=", "(", ")", "if", "not", "child_dir", "else", "(", "child_dir", ",", ")", "\n", "model_dir", "=", "os", ".", "path", ".", "join", "(", "hub_dir", ",", "'checkpoints'", ",", "*", "child_dir", ")", "\n", "os", ".", "makedirs", "(", "model_dir", ",", "exist_ok", "=", "True", ")", "\n", "return", "model_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.download_cached_file": [[42, 54], ["torch.hub.urlparse", "os.path.basename", "os.path.join", "hub.get_cache_dir", "os.path.exists", "_logger.info", "torch.hub.download_url_to_file", "torch.hub.HASH_REGEX.search", "HASH_REGEX.search.group"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.get_cache_dir"], ["", "def", "download_cached_file", "(", "url", ",", "check_hash", "=", "True", ",", "progress", "=", "False", ")", ":", "\n", "    ", "parts", "=", "urlparse", "(", "url", ")", "\n", "filename", "=", "os", ".", "path", ".", "basename", "(", "parts", ".", "path", ")", "\n", "cached_file", "=", "os", ".", "path", ".", "join", "(", "get_cache_dir", "(", ")", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cached_file", ")", ":", "\n", "        ", "_logger", ".", "info", "(", "'Downloading: \"{}\" to {}\\n'", ".", "format", "(", "url", ",", "cached_file", ")", ")", "\n", "hash_prefix", "=", "None", "\n", "if", "check_hash", ":", "\n", "            ", "r", "=", "HASH_REGEX", ".", "search", "(", "filename", ")", "# r is Optional[Match[str]]", "\n", "hash_prefix", "=", "r", ".", "group", "(", "1", ")", "if", "r", "else", "None", "\n", "", "download_url_to_file", "(", "url", ",", "cached_file", ",", "hash_prefix", ",", "progress", "=", "progress", ")", "\n", "", "return", "cached_file", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.has_hf_hub": [[56, 62], ["RuntimeError"], "function", ["None"], ["", "def", "has_hf_hub", "(", "necessary", "=", "False", ")", ":", "\n", "    ", "if", "not", "_has_hf_hub", "and", "necessary", ":", "\n", "# if no HF Hub module installed and it is necessary to continue, raise error", "\n", "        ", "raise", "RuntimeError", "(", "\n", "'Hugging Face hub model specified but package not installed. Run `pip install huggingface_hub`.'", ")", "\n", "", "return", "_has_hf_hub", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.hf_split": [[64, 71], ["hf_id.split", "len", "len"], "function", ["None"], ["", "def", "hf_split", "(", "hf_id", ")", ":", "\n", "# FIXME I may change @ -> # and be parsed as fragment in a URI model name scheme", "\n", "    ", "rev_split", "=", "hf_id", ".", "split", "(", "'@'", ")", "\n", "assert", "0", "<", "len", "(", "rev_split", ")", "<=", "2", ",", "'hf_hub id should only contain one @ character to identify revision.'", "\n", "hf_model_id", "=", "rev_split", "[", "0", "]", "\n", "hf_revision", "=", "rev_split", "[", "-", "1", "]", "if", "len", "(", "rev_split", ")", ">", "1", "else", "None", "\n", "return", "hf_model_id", ",", "hf_revision", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.load_cfg_from_json": [[73, 77], ["json.loads", "open", "reader.read"], "function", ["None"], ["", "def", "load_cfg_from_json", "(", "json_file", ":", "Union", "[", "str", ",", "os", ".", "PathLike", "]", ")", ":", "\n", "    ", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "        ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "json", ".", "loads", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub._download_from_hf": [[79, 83], ["hub.hf_split", "hf_hub_url", "cached_download", "hub.get_cache_dir"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.hf_split", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.get_cache_dir"], ["", "def", "_download_from_hf", "(", "model_id", ":", "str", ",", "filename", ":", "str", ")", ":", "\n", "    ", "hf_model_id", ",", "hf_revision", "=", "hf_split", "(", "model_id", ")", "\n", "url", "=", "hf_hub_url", "(", "hf_model_id", ",", "filename", ",", "revision", "=", "hf_revision", ")", "\n", "return", "cached_download", "(", "url", ",", "cache_dir", "=", "get_cache_dir", "(", "'hf'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.load_model_config_from_hf": [[85, 93], ["hub.has_hf_hub", "hub._download_from_hf", "hub.load_cfg_from_json", "load_cfg_from_json.get"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.has_hf_hub", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub._download_from_hf", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.load_cfg_from_json", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["", "def", "load_model_config_from_hf", "(", "model_id", ":", "str", ")", ":", "\n", "    ", "assert", "has_hf_hub", "(", "True", ")", "\n", "cached_file", "=", "_download_from_hf", "(", "model_id", ",", "'config.json'", ")", "\n", "pretrained_cfg", "=", "load_cfg_from_json", "(", "cached_file", ")", "\n", "pretrained_cfg", "[", "'hf_hub_id'", "]", "=", "model_id", "# insert hf_hub id for pretrained weight load during model creation", "\n", "pretrained_cfg", "[", "'source'", "]", "=", "'hf-hub'", "\n", "model_name", "=", "pretrained_cfg", ".", "get", "(", "'architecture'", ")", "\n", "return", "pretrained_cfg", ",", "model_name", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.load_state_dict_from_hf": [[95, 100], ["hub.has_hf_hub", "hub._download_from_hf", "torch.load"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.has_hf_hub", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub._download_from_hf"], ["", "def", "load_state_dict_from_hf", "(", "model_id", ":", "str", ")", ":", "\n", "    ", "assert", "has_hf_hub", "(", "True", ")", "\n", "cached_file", "=", "_download_from_hf", "(", "model_id", ",", "'pytorch_model.bin'", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "cached_file", ",", "map_location", "=", "'cpu'", ")", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.save_for_hf": [[102, 120], ["hub.has_hf_hub", "pathlib.Path", "pathlib.Path.mkdir", "torch.save", "model_config.pop", "model_config.pop", "model_config.pop", "hf_config.update", "model.state_dict", "config_path.open", "json.dump", "range"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.has_hf_hub"], ["", "def", "save_for_hf", "(", "model", ",", "save_directory", ",", "model_config", "=", "None", ")", ":", "\n", "    ", "assert", "has_hf_hub", "(", "True", ")", "\n", "model_config", "=", "model_config", "or", "{", "}", "\n", "save_directory", "=", "Path", "(", "save_directory", ")", "\n", "save_directory", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "\n", "weights_path", "=", "save_directory", "/", "'pytorch_model.bin'", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "weights_path", ")", "\n", "\n", "config_path", "=", "save_directory", "/", "'config.json'", "\n", "hf_config", "=", "model", ".", "pretrained_cfg", "\n", "hf_config", "[", "'num_classes'", "]", "=", "model_config", ".", "pop", "(", "'num_classes'", ",", "model", ".", "num_classes", ")", "\n", "hf_config", "[", "'num_features'", "]", "=", "model_config", ".", "pop", "(", "'num_features'", ",", "model", ".", "num_features", ")", "\n", "hf_config", "[", "'labels'", "]", "=", "model_config", ".", "pop", "(", "'labels'", ",", "[", "f\"LABEL_{i}\"", "for", "i", "in", "range", "(", "hf_config", "[", "'num_classes'", "]", ")", "]", ")", "\n", "hf_config", ".", "update", "(", "model_config", ")", "\n", "\n", "with", "config_path", ".", "open", "(", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "hf_config", ",", "f", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.push_to_hf_hub": [[122, 174], ["Repository", "Repository.git_remote_url", "isinstance", "Repository.commit", "hub.save_for_hf", "repo_namespace_or_url.rstrip().split", "HfFolder.get_token", "ValueError", "HfApi().whoami", "pathlib.Path", "pathlib.Path", "readme_path.exists", "readme_path.write_text", "repo_namespace_or_url.rstrip", "HfApi"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.save_for_hf"], ["", "", "def", "push_to_hf_hub", "(", "\n", "model", ",", "\n", "local_dir", ",", "\n", "repo_namespace_or_url", "=", "None", ",", "\n", "commit_message", "=", "'Add model'", ",", "\n", "use_auth_token", "=", "True", ",", "\n", "git_email", "=", "None", ",", "\n", "git_user", "=", "None", ",", "\n", "revision", "=", "None", ",", "\n", "model_config", "=", "None", ",", "\n", ")", ":", "\n", "    ", "if", "repo_namespace_or_url", ":", "\n", "        ", "repo_owner", ",", "repo_name", "=", "repo_namespace_or_url", ".", "rstrip", "(", "'/'", ")", ".", "split", "(", "'/'", ")", "[", "-", "2", ":", "]", "\n", "", "else", ":", "\n", "        ", "if", "isinstance", "(", "use_auth_token", ",", "str", ")", ":", "\n", "            ", "token", "=", "use_auth_token", "\n", "", "else", ":", "\n", "            ", "token", "=", "HfFolder", ".", "get_token", "(", ")", "\n", "\n", "", "if", "token", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"You must login to the Hugging Face hub on this computer by typing `transformers-cli login` and \"", "\n", "\"entering your credentials to use `use_auth_token=True`. Alternatively, you can pass your own \"", "\n", "\"token as the `use_auth_token` argument.\"", "\n", ")", "\n", "\n", "", "repo_owner", "=", "HfApi", "(", ")", ".", "whoami", "(", "token", ")", "[", "'name'", "]", "\n", "repo_name", "=", "Path", "(", "local_dir", ")", ".", "name", "\n", "\n", "", "repo_url", "=", "f'https://huggingface.co/{repo_owner}/{repo_name}'", "\n", "\n", "repo", "=", "Repository", "(", "\n", "local_dir", ",", "\n", "clone_from", "=", "repo_url", ",", "\n", "use_auth_token", "=", "use_auth_token", ",", "\n", "git_user", "=", "git_user", ",", "\n", "git_email", "=", "git_email", ",", "\n", "revision", "=", "revision", ",", "\n", ")", "\n", "\n", "# Prepare a default model card that includes the necessary tags to enable inference.", "\n", "readme_text", "=", "f'---\\ntags:\\n- image-classification\\n- timm\\nlibrary_tag: timm\\n---\\n# Model card for {repo_name}'", "\n", "with", "repo", ".", "commit", "(", "commit_message", ")", ":", "\n", "# Save model weights and config.", "\n", "        ", "save_for_hf", "(", "model", ",", "repo", ".", "local_dir", ",", "model_config", "=", "model_config", ")", "\n", "\n", "# Save a model card if it doesn't exist.", "\n", "readme_path", "=", "Path", "(", "repo", ".", "local_dir", ")", "/", "'README.md'", "\n", "if", "not", "readme_path", ".", "exists", "(", ")", ":", "\n", "            ", "readme_path", ".", "write_text", "(", "readme_text", ")", "\n", "\n", "", "", "return", "repo", ".", "git_remote_url", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.SpatialMlp.__init__": [[44, 74], ["torch.Module.__init__", "layers.to_2tuple", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "act_layer", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "act_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_features", ",", "hidden_features", "=", "None", ",", "out_features", "=", "None", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "drop", "=", "0.", ",", "group", "=", "8", ",", "spatial_conv", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "out_features", "=", "out_features", "or", "in_features", "\n", "hidden_features", "=", "hidden_features", "or", "in_features", "\n", "drop_probs", "=", "to_2tuple", "(", "drop", ")", "\n", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "spatial_conv", "=", "spatial_conv", "\n", "if", "self", ".", "spatial_conv", ":", "\n", "            ", "if", "group", "<", "2", ":", "# net setting", "\n", "                ", "hidden_features", "=", "in_features", "*", "5", "//", "6", "\n", "", "else", ":", "\n", "                ", "hidden_features", "=", "in_features", "*", "2", "\n", "", "", "self", ".", "hidden_features", "=", "hidden_features", "\n", "self", ".", "group", "=", "group", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_features", ",", "hidden_features", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "act1", "=", "act_layer", "(", ")", "\n", "self", ".", "drop1", "=", "nn", ".", "Dropout", "(", "drop_probs", "[", "0", "]", ")", "\n", "if", "self", ".", "spatial_conv", ":", "\n", "            ", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "\n", "hidden_features", ",", "hidden_features", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "groups", "=", "self", ".", "group", ",", "bias", "=", "False", ")", "\n", "self", ".", "act2", "=", "act_layer", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv2", "=", "None", "\n", "self", ".", "act2", "=", "None", "\n", "", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "hidden_features", ",", "out_features", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "drop3", "=", "nn", ".", "Dropout", "(", "drop_probs", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.SpatialMlp.forward": [[75, 85], ["visformer.SpatialMlp.conv1", "visformer.SpatialMlp.act1", "visformer.SpatialMlp.drop1", "visformer.SpatialMlp.conv3", "visformer.SpatialMlp.drop3", "visformer.SpatialMlp.conv2", "visformer.SpatialMlp.act2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "act1", "(", "x", ")", "\n", "x", "=", "self", ".", "drop1", "(", "x", ")", "\n", "if", "self", ".", "conv2", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "act2", "(", "x", ")", "\n", "", "x", "=", "self", ".", "conv3", "(", "x", ")", "\n", "x", "=", "self", ".", "drop3", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.Attention.__init__": [[88, 99], ["torch.Module.__init__", "round", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "head_dim_ratio", "=", "1.", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "round", "(", "dim", "//", "num_heads", "*", "head_dim_ratio", ")", "\n", "self", ".", "head_dim", "=", "head_dim", "\n", "self", ".", "scale", "=", "head_dim", "**", "-", "0.5", "\n", "self", ".", "qkv", "=", "nn", ".", "Conv2d", "(", "dim", ",", "head_dim", "*", "num_heads", "*", "3", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Conv2d", "(", "self", ".", "head_dim", "*", "self", ".", "num_heads", ",", "dim", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.Attention.forward": [[100, 114], ["visformer.Attention.qkv().reshape().permute", "visformer.Attention.unbind", "visformer.Attention.softmax", "visformer.Attention.attn_drop", "visformer.Attention.permute().reshape", "visformer.Attention.proj", "visformer.Attention.proj_drop", "visformer.Attention.qkv().reshape", "k.transpose", "visformer.Attention.permute", "visformer.Attention.qkv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "x", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "B", ",", "3", ",", "self", ".", "num_heads", ",", "self", ".", "head_dim", ",", "-", "1", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "4", ",", "3", ")", "\n", "q", ",", "k", ",", "v", "=", "x", ".", "unbind", "(", "0", ")", "\n", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "*", "self", ".", "scale", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "x", "=", "attn", "@", "v", "\n", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ")", ".", "reshape", "(", "B", ",", "-", "1", ",", "H", ",", "W", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.Block.__init__": [[117, 136], ["torch.Module.__init__", "norm_layer", "visformer.SpatialMlp", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "norm_layer", "visformer.Attention", "int"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dim", ",", "num_heads", ",", "head_dim_ratio", "=", "1.", ",", "mlp_ratio", "=", "4.", ",", "\n", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "drop_path", "=", "0.", ",", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "LayerNorm2d", ",", "\n", "group", "=", "8", ",", "attn_disabled", "=", "False", ",", "spatial_conv", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "spatial_conv", "=", "spatial_conv", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "if", "attn_disabled", ":", "\n", "            ", "self", ".", "norm1", "=", "None", "\n", "self", ".", "attn", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "\n", "dim", ",", "num_heads", "=", "num_heads", ",", "head_dim_ratio", "=", "head_dim_ratio", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ")", "\n", "\n", "", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "mlp", "=", "SpatialMlp", "(", "\n", "in_features", "=", "dim", ",", "hidden_features", "=", "int", "(", "dim", "*", "mlp_ratio", ")", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ",", "\n", "group", "=", "group", ",", "spatial_conv", "=", "spatial_conv", ")", "# new setting", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.Block.forward": [[137, 142], ["visformer.Block.drop_path", "visformer.Block.drop_path", "visformer.Block.mlp", "visformer.Block.attn", "visformer.Block.norm2", "visformer.Block.norm1"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "attn", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "attn", "(", "self", ".", "norm1", "(", "x", ")", ")", ")", "\n", "", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.Visformer.__init__": [[145, 255], ["torch.Module.__init__", "layers.to_2tuple", "isinstance", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "norm_layer", "layers.create_classifier", "visformer.Visformer.apply", "sum", "x.item", "layers.PatchEmbed", "torch.Dropout", "torch.Dropout", "torch.Dropout", "layers.PatchEmbed", "layers.PatchEmbed", "layers.trunc_normal_", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "layers.PatchEmbed", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.PatchEmbed", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "layers.trunc_normal_", "layers.trunc_normal_", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "visformer.Block", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "visformer.Block", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "visformer.Block", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["    ", "def", "__init__", "(", "\n", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "init_channels", "=", "32", ",", "embed_dim", "=", "384", ",", "\n", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "mlp_ratio", "=", "4.", ",", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "\n", "norm_layer", "=", "LayerNorm2d", ",", "attn_stage", "=", "'111'", ",", "pos_embed", "=", "True", ",", "spatial_conv", "=", "'111'", ",", "\n", "vit_stem", "=", "False", ",", "group", "=", "8", ",", "global_pool", "=", "'avg'", ",", "conv_init", "=", "False", ",", "embed_norm", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "init_channels", "=", "init_channels", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "vit_stem", "=", "vit_stem", "\n", "self", ".", "conv_init", "=", "conv_init", "\n", "if", "isinstance", "(", "depth", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "self", ".", "stage_num1", ",", "self", ".", "stage_num2", ",", "self", ".", "stage_num3", "=", "depth", "\n", "depth", "=", "sum", "(", "depth", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "stage_num1", "=", "self", ".", "stage_num3", "=", "depth", "//", "3", "\n", "self", ".", "stage_num2", "=", "depth", "-", "self", ".", "stage_num1", "-", "self", ".", "stage_num3", "\n", "", "self", ".", "pos_embed", "=", "pos_embed", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "dpr", "=", "[", "x", ".", "item", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "depth", ")", "]", "\n", "# stage 1", "\n", "if", "self", ".", "vit_stem", ":", "\n", "            ", "self", ".", "stem", "=", "None", "\n", "self", ".", "patch_embed1", "=", "PatchEmbed", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "\n", "embed_dim", "=", "embed_dim", ",", "norm_layer", "=", "embed_norm", ",", "flatten", "=", "False", ")", "\n", "img_size", "=", "[", "x", "//", "patch_size", "for", "x", "in", "img_size", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "init_channels", "is", "None", ":", "\n", "                ", "self", ".", "stem", "=", "None", "\n", "self", ".", "patch_embed1", "=", "PatchEmbed", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", "//", "2", ",", "in_chans", "=", "in_chans", ",", "\n", "embed_dim", "=", "embed_dim", "//", "2", ",", "norm_layer", "=", "embed_norm", ",", "flatten", "=", "False", ")", "\n", "img_size", "=", "[", "x", "//", "(", "patch_size", "//", "2", ")", "for", "x", "in", "img_size", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "stem", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_chans", ",", "self", ".", "init_channels", ",", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "init_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", ")", "\n", "img_size", "=", "[", "x", "//", "2", "for", "x", "in", "img_size", "]", "\n", "self", ".", "patch_embed1", "=", "PatchEmbed", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", "//", "4", ",", "in_chans", "=", "self", ".", "init_channels", ",", "\n", "embed_dim", "=", "embed_dim", "//", "2", ",", "norm_layer", "=", "embed_norm", ",", "flatten", "=", "False", ")", "\n", "img_size", "=", "[", "x", "//", "(", "patch_size", "//", "4", ")", "for", "x", "in", "img_size", "]", "\n", "\n", "", "", "if", "self", ".", "pos_embed", ":", "\n", "            ", "if", "self", ".", "vit_stem", ":", "\n", "                ", "self", ".", "pos_embed1", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "embed_dim", ",", "*", "img_size", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "pos_embed1", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "embed_dim", "//", "2", ",", "*", "img_size", ")", ")", "\n", "", "self", ".", "pos_drop", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", "\n", "", "self", ".", "stage1", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "Block", "(", "\n", "dim", "=", "embed_dim", "//", "2", ",", "num_heads", "=", "num_heads", ",", "head_dim_ratio", "=", "0.5", ",", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", "[", "i", "]", ",", "norm_layer", "=", "norm_layer", ",", "\n", "group", "=", "group", ",", "attn_disabled", "=", "(", "attn_stage", "[", "0", "]", "==", "'0'", ")", ",", "spatial_conv", "=", "(", "spatial_conv", "[", "0", "]", "==", "'1'", ")", "\n", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "stage_num1", ")", "\n", "]", ")", "\n", "\n", "# stage2", "\n", "if", "not", "self", ".", "vit_stem", ":", "\n", "            ", "self", ".", "patch_embed2", "=", "PatchEmbed", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", "//", "8", ",", "in_chans", "=", "embed_dim", "//", "2", ",", "\n", "embed_dim", "=", "embed_dim", ",", "norm_layer", "=", "embed_norm", ",", "flatten", "=", "False", ")", "\n", "img_size", "=", "[", "x", "//", "(", "patch_size", "//", "8", ")", "for", "x", "in", "img_size", "]", "\n", "if", "self", ".", "pos_embed", ":", "\n", "                ", "self", ".", "pos_embed2", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "embed_dim", ",", "*", "img_size", ")", ")", "\n", "", "", "self", ".", "stage2", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "Block", "(", "\n", "dim", "=", "embed_dim", ",", "num_heads", "=", "num_heads", ",", "head_dim_ratio", "=", "1.0", ",", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", "[", "i", "]", ",", "norm_layer", "=", "norm_layer", ",", "\n", "group", "=", "group", ",", "attn_disabled", "=", "(", "attn_stage", "[", "1", "]", "==", "'0'", ")", ",", "spatial_conv", "=", "(", "spatial_conv", "[", "1", "]", "==", "'1'", ")", "\n", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "stage_num1", ",", "self", ".", "stage_num1", "+", "self", ".", "stage_num2", ")", "\n", "]", ")", "\n", "\n", "# stage 3", "\n", "if", "not", "self", ".", "vit_stem", ":", "\n", "            ", "self", ".", "patch_embed3", "=", "PatchEmbed", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", "//", "8", ",", "in_chans", "=", "embed_dim", ",", "\n", "embed_dim", "=", "embed_dim", "*", "2", ",", "norm_layer", "=", "embed_norm", ",", "flatten", "=", "False", ")", "\n", "img_size", "=", "[", "x", "//", "(", "patch_size", "//", "8", ")", "for", "x", "in", "img_size", "]", "\n", "if", "self", ".", "pos_embed", ":", "\n", "                ", "self", ".", "pos_embed3", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "embed_dim", "*", "2", ",", "*", "img_size", ")", ")", "\n", "", "", "self", ".", "stage3", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "Block", "(", "\n", "dim", "=", "embed_dim", "*", "2", ",", "num_heads", "=", "num_heads", ",", "head_dim_ratio", "=", "1.0", ",", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", "[", "i", "]", ",", "norm_layer", "=", "norm_layer", ",", "\n", "group", "=", "group", ",", "attn_disabled", "=", "(", "attn_stage", "[", "2", "]", "==", "'0'", ")", ",", "spatial_conv", "=", "(", "spatial_conv", "[", "2", "]", "==", "'1'", ")", "\n", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "stage_num1", "+", "self", ".", "stage_num2", ",", "depth", ")", "\n", "]", ")", "\n", "\n", "# head", "\n", "self", ".", "num_features", "=", "embed_dim", "if", "self", ".", "vit_stem", "else", "embed_dim", "*", "2", "\n", "self", ".", "norm", "=", "norm_layer", "(", "self", ".", "num_features", ")", "\n", "self", ".", "global_pool", ",", "self", ".", "head", "=", "create_classifier", "(", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n", "# weights init", "\n", "if", "self", ".", "pos_embed", ":", "\n", "            ", "trunc_normal_", "(", "self", ".", "pos_embed1", ",", "std", "=", "0.02", ")", "\n", "if", "not", "self", ".", "vit_stem", ":", "\n", "                ", "trunc_normal_", "(", "self", ".", "pos_embed2", ",", "std", "=", "0.02", ")", "\n", "trunc_normal_", "(", "self", ".", "pos_embed3", ",", "std", "=", "0.02", ")", "\n", "", "", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.Visformer._init_weights": [[256, 268], ["isinstance", "layers.trunc_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "layers.trunc_normal_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "if", "self", ".", "conv_init", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "else", ":", "\n", "                ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.Visformer.group_matcher": [[269, 277], ["dict"], "methods", ["None"], ["", "", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^patch_embed1|pos_embed1|stem'", ",", "# stem and embed", "\n", "blocks", "=", "[", "\n", "(", "r'^stage(\\d+)\\.(\\d+)'", "if", "coarse", "else", "r'^stage(\\d+)\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^(?:patch_embed|pos_embed)(\\d+)'", ",", "(", "0", ",", ")", ")", ",", "\n", "(", "r'^norm'", ",", "(", "99999", ",", ")", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.Visformer.set_grad_checkpointing": [[280, 283], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.Visformer.get_classifier": [[284, 287], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.Visformer.reset_classifier": [[288, 291], ["layers.create_classifier"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "head", "=", "create_classifier", "(", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.Visformer.forward_features": [[292, 327], ["visformer.Visformer.patch_embed1", "visformer.Visformer.norm", "visformer.Visformer.stem", "visformer.Visformer.pos_drop", "helpers.checkpoint_seq", "visformer.Visformer.stage1", "visformer.Visformer.patch_embed2", "helpers.checkpoint_seq", "visformer.Visformer.stage2", "visformer.Visformer.patch_embed3", "helpers.checkpoint_seq", "visformer.Visformer.stage3", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "visformer.Visformer.pos_drop", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "visformer.Visformer.pos_drop", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "stem", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "\n", "# stage 1", "\n", "", "x", "=", "self", ".", "patch_embed1", "(", "x", ")", "\n", "if", "self", ".", "pos_embed", ":", "\n", "            ", "x", "=", "self", ".", "pos_drop", "(", "x", "+", "self", ".", "pos_embed1", ")", "\n", "", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "stage1", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "stage1", "(", "x", ")", "\n", "\n", "# stage 2", "\n", "", "if", "not", "self", ".", "vit_stem", ":", "\n", "            ", "x", "=", "self", ".", "patch_embed2", "(", "x", ")", "\n", "if", "self", ".", "pos_embed", ":", "\n", "                ", "x", "=", "self", ".", "pos_drop", "(", "x", "+", "self", ".", "pos_embed2", ")", "\n", "", "", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "stage2", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "stage2", "(", "x", ")", "\n", "\n", "# stage3", "\n", "", "if", "not", "self", ".", "vit_stem", ":", "\n", "            ", "x", "=", "self", ".", "patch_embed3", "(", "x", ")", "\n", "if", "self", ".", "pos_embed", ":", "\n", "                ", "x", "=", "self", ".", "pos_drop", "(", "x", "+", "self", ".", "pos_embed3", ")", "\n", "", "", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "stage3", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "stage3", "(", "x", ")", "\n", "\n", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.Visformer.forward_head": [[328, 331], ["visformer.Visformer.global_pool", "visformer.Visformer.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "return", "x", "if", "pre_logits", "else", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.Visformer.forward": [[332, 336], ["visformer.Visformer.forward_features", "visformer.Visformer.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer._cfg": [[24, 32], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", ".9", ",", "'interpolation'", ":", "'bicubic'", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'stem.0'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer._create_visformer": [[338, 343], ["kwargs.get", "helpers.build_model_with_cfg", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_visformer", "(", "variant", ",", "pretrained", "=", "False", ",", "default_cfg", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", ".", "get", "(", "'features_only'", ",", "None", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'features_only not implemented for Vision Transformer models.'", ")", "\n", "", "model", "=", "build_model_with_cfg", "(", "Visformer", ",", "variant", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.visformer_tiny": [[345, 353], ["dict", "visformer._create_visformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer._create_visformer"], ["", "@", "register_model", "\n", "def", "visformer_tiny", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_cfg", "=", "dict", "(", "\n", "init_channels", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "(", "7", ",", "4", ",", "4", ")", ",", "num_heads", "=", "3", ",", "mlp_ratio", "=", "4.", ",", "group", "=", "8", ",", "\n", "attn_stage", "=", "'011'", ",", "spatial_conv", "=", "'100'", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "conv_init", "=", "True", ",", "\n", "embed_norm", "=", "nn", ".", "BatchNorm2d", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_visformer", "(", "'visformer_tiny'", ",", "pretrained", "=", "pretrained", ",", "**", "model_cfg", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer.visformer_small": [[355, 363], ["dict", "visformer._create_visformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.visformer._create_visformer"], ["", "@", "register_model", "\n", "def", "visformer_small", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_cfg", "=", "dict", "(", "\n", "init_channels", "=", "32", ",", "embed_dim", "=", "384", ",", "depth", "=", "(", "7", ",", "4", ",", "4", ")", ",", "num_heads", "=", "6", ",", "mlp_ratio", "=", "4.", ",", "group", "=", "8", ",", "\n", "attn_stage", "=", "'011'", ",", "spatial_conv", "=", "'100'", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "conv_init", "=", "True", ",", "\n", "embed_norm", "=", "nn", ".", "BatchNorm2d", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_visformer", "(", "'visformer_small'", ",", "pretrained", "=", "pretrained", ",", "**", "model_cfg", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.SeparableConv2d.__init__": [[40, 47], ["torch.Module.__init__", "layers.create_conv2d", "layers.create_conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "padding", "=", "''", ")", ":", "\n", "        ", "super", "(", "SeparableConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "depthwise_conv2d", "=", "create_conv2d", "(", "\n", "in_channels", ",", "in_channels", ",", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "groups", "=", "in_channels", ")", "\n", "self", ".", "pointwise_conv2d", "=", "create_conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ",", "padding", "=", "padding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.SeparableConv2d.forward": [[48, 52], ["pnasnet.SeparableConv2d.depthwise_conv2d", "pnasnet.SeparableConv2d.pointwise_conv2d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "depthwise_conv2d", "(", "x", ")", "\n", "x", "=", "self", ".", "pointwise_conv2d", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.BranchSeparables.__init__": [[56, 67], ["torch.Module.__init__", "torch.ReLU", "torch.ReLU", "torch.ReLU", "pnasnet.SeparableConv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "pnasnet.SeparableConv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "stem_cell", "=", "False", ",", "padding", "=", "''", ")", ":", "\n", "        ", "super", "(", "BranchSeparables", ",", "self", ")", ".", "__init__", "(", ")", "\n", "middle_channels", "=", "out_channels", "if", "stem_cell", "else", "in_channels", "\n", "self", ".", "act_1", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "separable_1", "=", "SeparableConv2d", "(", "\n", "in_channels", ",", "middle_channels", ",", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ")", "\n", "self", ".", "bn_sep_1", "=", "nn", ".", "BatchNorm2d", "(", "middle_channels", ",", "eps", "=", "0.001", ")", "\n", "self", ".", "act_2", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "separable_2", "=", "SeparableConv2d", "(", "\n", "middle_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "padding", ")", "\n", "self", ".", "bn_sep_2", "=", "nn", ".", "BatchNorm2d", "(", "out_channels", ",", "eps", "=", "0.001", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.BranchSeparables.forward": [[68, 76], ["pnasnet.BranchSeparables.act_1", "pnasnet.BranchSeparables.separable_1", "pnasnet.BranchSeparables.bn_sep_1", "pnasnet.BranchSeparables.act_2", "pnasnet.BranchSeparables.separable_2", "pnasnet.BranchSeparables.bn_sep_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "act_1", "(", "x", ")", "\n", "x", "=", "self", ".", "separable_1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn_sep_1", "(", "x", ")", "\n", "x", "=", "self", ".", "act_2", "(", "x", ")", "\n", "x", "=", "self", ".", "separable_2", "(", "x", ")", "\n", "x", "=", "self", ".", "bn_sep_2", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.ActConvBn.__init__": [[80, 86], ["torch.Module.__init__", "torch.ReLU", "torch.ReLU", "torch.ReLU", "layers.create_conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "''", ")", ":", "\n", "        ", "super", "(", "ActConvBn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "act", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "conv", "=", "create_conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm2d", "(", "out_channels", ",", "eps", "=", "0.001", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.ActConvBn.forward": [[87, 92], ["pnasnet.ActConvBn.act", "pnasnet.ActConvBn.conv", "pnasnet.ActConvBn.bn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.FactorizedReduction.__init__": [[96, 109], ["torch.Module.__init__", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "collections.OrderedDict", "collections.OrderedDict", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "layers.create_conv2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "layers.create_conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "padding", "=", "''", ")", ":", "\n", "        ", "super", "(", "FactorizedReduction", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "act", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "path_1", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'avgpool'", ",", "nn", ".", "AvgPool2d", "(", "1", ",", "stride", "=", "2", ",", "count_include_pad", "=", "False", ")", ")", ",", "\n", "(", "'conv'", ",", "create_conv2d", "(", "in_channels", ",", "out_channels", "//", "2", ",", "kernel_size", "=", "1", ",", "padding", "=", "padding", ")", ")", ",", "\n", "]", ")", ")", "\n", "self", ".", "path_2", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'pad'", ",", "nn", ".", "ZeroPad2d", "(", "(", "-", "1", ",", "1", ",", "-", "1", ",", "1", ")", ")", ")", ",", "# shift", "\n", "(", "'avgpool'", ",", "nn", ".", "AvgPool2d", "(", "1", ",", "stride", "=", "2", ",", "count_include_pad", "=", "False", ")", ")", ",", "\n", "(", "'conv'", ",", "create_conv2d", "(", "in_channels", ",", "out_channels", "//", "2", ",", "kernel_size", "=", "1", ",", "padding", "=", "padding", ")", ")", ",", "\n", "]", ")", ")", "\n", "self", ".", "final_path_bn", "=", "nn", ".", "BatchNorm2d", "(", "out_channels", ",", "eps", "=", "0.001", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.FactorizedReduction.forward": [[110, 116], ["pnasnet.FactorizedReduction.act", "pnasnet.FactorizedReduction.path_1", "pnasnet.FactorizedReduction.path_2", "pnasnet.FactorizedReduction.final_path_bn", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x_path1", "=", "self", ".", "path_1", "(", "x", ")", "\n", "x_path2", "=", "self", ".", "path_2", "(", "x", ")", "\n", "out", "=", "self", ".", "final_path_bn", "(", "torch", ".", "cat", "(", "[", "x_path1", ",", "x_path2", "]", ",", "1", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.CellBase.cell_forward": [[120, 146], ["pnasnet.CellBase.comb_iter_0_left", "pnasnet.CellBase.comb_iter_0_right", "pnasnet.CellBase.comb_iter_1_left", "pnasnet.CellBase.comb_iter_1_right", "pnasnet.CellBase.comb_iter_2_left", "pnasnet.CellBase.comb_iter_2_right", "pnasnet.CellBase.comb_iter_3_left", "pnasnet.CellBase.comb_iter_3_right", "pnasnet.CellBase.comb_iter_4_left", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pnasnet.CellBase.comb_iter_4_right"], "methods", ["None"], ["    ", "def", "cell_forward", "(", "self", ",", "x_left", ",", "x_right", ")", ":", "\n", "        ", "x_comb_iter_0_left", "=", "self", ".", "comb_iter_0_left", "(", "x_left", ")", "\n", "x_comb_iter_0_right", "=", "self", ".", "comb_iter_0_right", "(", "x_left", ")", "\n", "x_comb_iter_0", "=", "x_comb_iter_0_left", "+", "x_comb_iter_0_right", "\n", "\n", "x_comb_iter_1_left", "=", "self", ".", "comb_iter_1_left", "(", "x_right", ")", "\n", "x_comb_iter_1_right", "=", "self", ".", "comb_iter_1_right", "(", "x_right", ")", "\n", "x_comb_iter_1", "=", "x_comb_iter_1_left", "+", "x_comb_iter_1_right", "\n", "\n", "x_comb_iter_2_left", "=", "self", ".", "comb_iter_2_left", "(", "x_right", ")", "\n", "x_comb_iter_2_right", "=", "self", ".", "comb_iter_2_right", "(", "x_right", ")", "\n", "x_comb_iter_2", "=", "x_comb_iter_2_left", "+", "x_comb_iter_2_right", "\n", "\n", "x_comb_iter_3_left", "=", "self", ".", "comb_iter_3_left", "(", "x_comb_iter_2", ")", "\n", "x_comb_iter_3_right", "=", "self", ".", "comb_iter_3_right", "(", "x_right", ")", "\n", "x_comb_iter_3", "=", "x_comb_iter_3_left", "+", "x_comb_iter_3_right", "\n", "\n", "x_comb_iter_4_left", "=", "self", ".", "comb_iter_4_left", "(", "x_left", ")", "\n", "if", "self", ".", "comb_iter_4_right", "is", "not", "None", ":", "\n", "            ", "x_comb_iter_4_right", "=", "self", ".", "comb_iter_4_right", "(", "x_right", ")", "\n", "", "else", ":", "\n", "            ", "x_comb_iter_4_right", "=", "x_right", "\n", "", "x_comb_iter_4", "=", "x_comb_iter_4_left", "+", "x_comb_iter_4_right", "\n", "\n", "x_out", "=", "torch", ".", "cat", "(", "[", "x_comb_iter_0", ",", "x_comb_iter_1", ",", "x_comb_iter_2", ",", "x_comb_iter_3", ",", "x_comb_iter_4", "]", ",", "1", ")", "\n", "return", "x_out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.CellStem0.__init__": [[150, 179], ["torch.Module.__init__", "pnasnet.ActConvBn", "pnasnet.BranchSeparables", "torch.Sequential", "torch.Sequential", "torch.Sequential", "pnasnet.BranchSeparables", "layers.create_pool2d", "pnasnet.BranchSeparables", "pnasnet.BranchSeparables", "pnasnet.BranchSeparables", "layers.create_pool2d", "pnasnet.BranchSeparables", "pnasnet.ActConvBn", "collections.OrderedDict", "layers.create_pool2d", "layers.create_conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["    ", "def", "__init__", "(", "self", ",", "in_chs_left", ",", "out_chs_left", ",", "in_chs_right", ",", "out_chs_right", ",", "pad_type", "=", "''", ")", ":", "\n", "        ", "super", "(", "CellStem0", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_1x1", "=", "ActConvBn", "(", "in_chs_right", ",", "out_chs_right", ",", "kernel_size", "=", "1", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_0_left", "=", "BranchSeparables", "(", "\n", "in_chs_left", ",", "out_chs_left", ",", "kernel_size", "=", "5", ",", "stride", "=", "2", ",", "stem_cell", "=", "True", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_0_right", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'max_pool'", ",", "create_pool2d", "(", "'max'", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "pad_type", ")", ")", ",", "\n", "(", "'conv'", ",", "create_conv2d", "(", "in_chs_left", ",", "out_chs_left", ",", "kernel_size", "=", "1", ",", "padding", "=", "pad_type", ")", ")", ",", "\n", "(", "'bn'", ",", "nn", ".", "BatchNorm2d", "(", "out_chs_left", ",", "eps", "=", "0.001", ")", ")", ",", "\n", "]", ")", ")", "\n", "\n", "self", ".", "comb_iter_1_left", "=", "BranchSeparables", "(", "\n", "out_chs_right", ",", "out_chs_right", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_1_right", "=", "create_pool2d", "(", "'max'", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_2_left", "=", "BranchSeparables", "(", "\n", "out_chs_right", ",", "out_chs_right", ",", "kernel_size", "=", "5", ",", "stride", "=", "2", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_2_right", "=", "BranchSeparables", "(", "\n", "out_chs_right", ",", "out_chs_right", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_3_left", "=", "BranchSeparables", "(", "\n", "out_chs_right", ",", "out_chs_right", ",", "kernel_size", "=", "3", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_3_right", "=", "create_pool2d", "(", "'max'", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_4_left", "=", "BranchSeparables", "(", "\n", "in_chs_right", ",", "out_chs_right", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "stem_cell", "=", "True", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_4_right", "=", "ActConvBn", "(", "\n", "out_chs_right", ",", "out_chs_right", ",", "kernel_size", "=", "1", ",", "stride", "=", "2", ",", "padding", "=", "pad_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.CellStem0.forward": [[180, 184], ["pnasnet.CellStem0.conv_1x1", "pnasnet.CellStem0.cell_forward"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.CellBase.cell_forward"], ["", "def", "forward", "(", "self", ",", "x_left", ")", ":", "\n", "        ", "x_right", "=", "self", ".", "conv_1x1", "(", "x_left", ")", "\n", "x_out", "=", "self", ".", "cell_forward", "(", "x_left", ",", "x_right", ")", "\n", "return", "x_out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.Cell.__init__": [[188, 230], ["torch.Module.__init__", "pnasnet.ActConvBn", "pnasnet.BranchSeparables", "layers.create_pool2d", "pnasnet.BranchSeparables", "layers.create_pool2d", "pnasnet.BranchSeparables", "pnasnet.BranchSeparables", "pnasnet.BranchSeparables", "layers.create_pool2d", "pnasnet.BranchSeparables", "pnasnet.FactorizedReduction", "pnasnet.ActConvBn", "pnasnet.ActConvBn"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d"], ["    ", "def", "__init__", "(", "self", ",", "in_chs_left", ",", "out_chs_left", ",", "in_chs_right", ",", "out_chs_right", ",", "pad_type", "=", "''", ",", "\n", "is_reduction", "=", "False", ",", "match_prev_layer_dims", "=", "False", ")", ":", "\n", "        ", "super", "(", "Cell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# If `is_reduction` is set to `True` stride 2 is used for", "\n", "# convolution and pooling layers to reduce the spatial size of", "\n", "# the output of a cell approximately by a factor of 2.", "\n", "stride", "=", "2", "if", "is_reduction", "else", "1", "\n", "\n", "# If `match_prev_layer_dimensions` is set to `True`", "\n", "# `FactorizedReduction` is used to reduce the spatial size", "\n", "# of the left input of a cell approximately by a factor of 2.", "\n", "self", ".", "match_prev_layer_dimensions", "=", "match_prev_layer_dims", "\n", "if", "match_prev_layer_dims", ":", "\n", "            ", "self", ".", "conv_prev_1x1", "=", "FactorizedReduction", "(", "in_chs_left", ",", "out_chs_left", ",", "padding", "=", "pad_type", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv_prev_1x1", "=", "ActConvBn", "(", "in_chs_left", ",", "out_chs_left", ",", "kernel_size", "=", "1", ",", "padding", "=", "pad_type", ")", "\n", "", "self", ".", "conv_1x1", "=", "ActConvBn", "(", "in_chs_right", ",", "out_chs_right", ",", "kernel_size", "=", "1", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_0_left", "=", "BranchSeparables", "(", "\n", "out_chs_left", ",", "out_chs_left", ",", "kernel_size", "=", "5", ",", "stride", "=", "stride", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_0_right", "=", "create_pool2d", "(", "'max'", ",", "3", ",", "stride", "=", "stride", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_1_left", "=", "BranchSeparables", "(", "\n", "out_chs_right", ",", "out_chs_right", ",", "kernel_size", "=", "7", ",", "stride", "=", "stride", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_1_right", "=", "create_pool2d", "(", "'max'", ",", "3", ",", "stride", "=", "stride", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_2_left", "=", "BranchSeparables", "(", "\n", "out_chs_right", ",", "out_chs_right", ",", "kernel_size", "=", "5", ",", "stride", "=", "stride", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_2_right", "=", "BranchSeparables", "(", "\n", "out_chs_right", ",", "out_chs_right", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_3_left", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "kernel_size", "=", "3", ")", "\n", "self", ".", "comb_iter_3_right", "=", "create_pool2d", "(", "'max'", ",", "3", ",", "stride", "=", "stride", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_4_left", "=", "BranchSeparables", "(", "\n", "out_chs_left", ",", "out_chs_left", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "pad_type", ")", "\n", "if", "is_reduction", ":", "\n", "            ", "self", ".", "comb_iter_4_right", "=", "ActConvBn", "(", "\n", "out_chs_right", ",", "out_chs_right", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "padding", "=", "pad_type", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "comb_iter_4_right", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.Cell.forward": [[231, 236], ["pnasnet.Cell.conv_prev_1x1", "pnasnet.Cell.conv_1x1", "pnasnet.Cell.cell_forward"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.CellBase.cell_forward"], ["", "", "def", "forward", "(", "self", ",", "x_left", ",", "x_right", ")", ":", "\n", "        ", "x_left", "=", "self", ".", "conv_prev_1x1", "(", "x_left", ")", "\n", "x_right", "=", "self", ".", "conv_1x1", "(", "x_right", ")", "\n", "x_out", "=", "self", ".", "cell_forward", "(", "x_left", ",", "x_right", ")", "\n", "return", "x_out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.PNASNet5Large.__init__": [[239, 298], ["torch.Module.__init__", "layers.ConvNormAct", "pnasnet.CellStem0", "pnasnet.Cell", "pnasnet.Cell", "pnasnet.Cell", "pnasnet.Cell", "pnasnet.Cell", "pnasnet.Cell", "pnasnet.Cell", "pnasnet.Cell", "pnasnet.Cell", "pnasnet.Cell", "pnasnet.Cell", "pnasnet.Cell", "pnasnet.Cell", "torch.ReLU", "torch.ReLU", "torch.ReLU", "layers.create_classifier", "dict", "dict", "dict", "dict", "dict", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["    ", "def", "__init__", "(", "self", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "output_stride", "=", "32", ",", "drop_rate", "=", "0.", ",", "global_pool", "=", "'avg'", ",", "pad_type", "=", "''", ")", ":", "\n", "        ", "super", "(", "PNASNet5Large", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "num_features", "=", "4320", "\n", "assert", "output_stride", "==", "32", "\n", "\n", "self", ".", "conv_0", "=", "ConvNormAct", "(", "\n", "in_chans", ",", "96", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "0", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "BatchNorm2d", ",", "eps", "=", "0.001", ",", "momentum", "=", "0.1", ")", ",", "apply_act", "=", "False", ")", "\n", "\n", "self", ".", "cell_stem_0", "=", "CellStem0", "(", "\n", "in_chs_left", "=", "96", ",", "out_chs_left", "=", "54", ",", "in_chs_right", "=", "96", ",", "out_chs_right", "=", "54", ",", "pad_type", "=", "pad_type", ")", "\n", "\n", "self", ".", "cell_stem_1", "=", "Cell", "(", "\n", "in_chs_left", "=", "96", ",", "out_chs_left", "=", "108", ",", "in_chs_right", "=", "270", ",", "out_chs_right", "=", "108", ",", "pad_type", "=", "pad_type", ",", "\n", "match_prev_layer_dims", "=", "True", ",", "is_reduction", "=", "True", ")", "\n", "self", ".", "cell_0", "=", "Cell", "(", "\n", "in_chs_left", "=", "270", ",", "out_chs_left", "=", "216", ",", "in_chs_right", "=", "540", ",", "out_chs_right", "=", "216", ",", "pad_type", "=", "pad_type", ",", "\n", "match_prev_layer_dims", "=", "True", ")", "\n", "self", ".", "cell_1", "=", "Cell", "(", "\n", "in_chs_left", "=", "540", ",", "out_chs_left", "=", "216", ",", "in_chs_right", "=", "1080", ",", "out_chs_right", "=", "216", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_2", "=", "Cell", "(", "\n", "in_chs_left", "=", "1080", ",", "out_chs_left", "=", "216", ",", "in_chs_right", "=", "1080", ",", "out_chs_right", "=", "216", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_3", "=", "Cell", "(", "\n", "in_chs_left", "=", "1080", ",", "out_chs_left", "=", "216", ",", "in_chs_right", "=", "1080", ",", "out_chs_right", "=", "216", ",", "pad_type", "=", "pad_type", ")", "\n", "\n", "self", ".", "cell_4", "=", "Cell", "(", "\n", "in_chs_left", "=", "1080", ",", "out_chs_left", "=", "432", ",", "in_chs_right", "=", "1080", ",", "out_chs_right", "=", "432", ",", "pad_type", "=", "pad_type", ",", "\n", "is_reduction", "=", "True", ")", "\n", "self", ".", "cell_5", "=", "Cell", "(", "\n", "in_chs_left", "=", "1080", ",", "out_chs_left", "=", "432", ",", "in_chs_right", "=", "2160", ",", "out_chs_right", "=", "432", ",", "pad_type", "=", "pad_type", ",", "\n", "match_prev_layer_dims", "=", "True", ")", "\n", "self", ".", "cell_6", "=", "Cell", "(", "\n", "in_chs_left", "=", "2160", ",", "out_chs_left", "=", "432", ",", "in_chs_right", "=", "2160", ",", "out_chs_right", "=", "432", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_7", "=", "Cell", "(", "\n", "in_chs_left", "=", "2160", ",", "out_chs_left", "=", "432", ",", "in_chs_right", "=", "2160", ",", "out_chs_right", "=", "432", ",", "pad_type", "=", "pad_type", ")", "\n", "\n", "self", ".", "cell_8", "=", "Cell", "(", "\n", "in_chs_left", "=", "2160", ",", "out_chs_left", "=", "864", ",", "in_chs_right", "=", "2160", ",", "out_chs_right", "=", "864", ",", "pad_type", "=", "pad_type", ",", "\n", "is_reduction", "=", "True", ")", "\n", "self", ".", "cell_9", "=", "Cell", "(", "\n", "in_chs_left", "=", "2160", ",", "out_chs_left", "=", "864", ",", "in_chs_right", "=", "4320", ",", "out_chs_right", "=", "864", ",", "pad_type", "=", "pad_type", ",", "\n", "match_prev_layer_dims", "=", "True", ")", "\n", "self", ".", "cell_10", "=", "Cell", "(", "\n", "in_chs_left", "=", "4320", ",", "out_chs_left", "=", "864", ",", "in_chs_right", "=", "4320", ",", "out_chs_right", "=", "864", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_11", "=", "Cell", "(", "\n", "in_chs_left", "=", "4320", ",", "out_chs_left", "=", "864", ",", "in_chs_right", "=", "4320", ",", "out_chs_right", "=", "864", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "act", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "feature_info", "=", "[", "\n", "dict", "(", "num_chs", "=", "96", ",", "reduction", "=", "2", ",", "module", "=", "'conv_0'", ")", ",", "\n", "dict", "(", "num_chs", "=", "270", ",", "reduction", "=", "4", ",", "module", "=", "'cell_stem_1.conv_1x1.act'", ")", ",", "\n", "dict", "(", "num_chs", "=", "1080", ",", "reduction", "=", "8", ",", "module", "=", "'cell_4.conv_1x1.act'", ")", ",", "\n", "dict", "(", "num_chs", "=", "2160", ",", "reduction", "=", "16", ",", "module", "=", "'cell_8.conv_1x1.act'", ")", ",", "\n", "dict", "(", "num_chs", "=", "4320", ",", "reduction", "=", "32", ",", "module", "=", "'act'", ")", ",", "\n", "]", "\n", "\n", "self", ".", "global_pool", ",", "self", ".", "last_linear", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.PNASNet5Large.group_matcher": [[299, 302], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "stem", "=", "r'^conv_0|cell_stem_[01]'", ",", "blocks", "=", "r'^cell_(\\d+)'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.PNASNet5Large.set_grad_checkpointing": [[303, 306], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "'gradient checkpointing not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.PNASNet5Large.get_classifier": [[307, 310], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "last_linear", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.PNASNet5Large.reset_classifier": [[311, 315], ["layers.create_classifier"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "last_linear", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.PNASNet5Large.forward_features": [[316, 334], ["pnasnet.PNASNet5Large.conv_0", "pnasnet.PNASNet5Large.cell_stem_0", "pnasnet.PNASNet5Large.cell_stem_1", "pnasnet.PNASNet5Large.cell_0", "pnasnet.PNASNet5Large.cell_1", "pnasnet.PNASNet5Large.cell_2", "pnasnet.PNASNet5Large.cell_3", "pnasnet.PNASNet5Large.cell_4", "pnasnet.PNASNet5Large.cell_5", "pnasnet.PNASNet5Large.cell_6", "pnasnet.PNASNet5Large.cell_7", "pnasnet.PNASNet5Large.cell_8", "pnasnet.PNASNet5Large.cell_9", "pnasnet.PNASNet5Large.cell_10", "pnasnet.PNASNet5Large.cell_11", "pnasnet.PNASNet5Large.act"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_conv_0", "=", "self", ".", "conv_0", "(", "x", ")", "\n", "x_stem_0", "=", "self", ".", "cell_stem_0", "(", "x_conv_0", ")", "\n", "x_stem_1", "=", "self", ".", "cell_stem_1", "(", "x_conv_0", ",", "x_stem_0", ")", "\n", "x_cell_0", "=", "self", ".", "cell_0", "(", "x_stem_0", ",", "x_stem_1", ")", "\n", "x_cell_1", "=", "self", ".", "cell_1", "(", "x_stem_1", ",", "x_cell_0", ")", "\n", "x_cell_2", "=", "self", ".", "cell_2", "(", "x_cell_0", ",", "x_cell_1", ")", "\n", "x_cell_3", "=", "self", ".", "cell_3", "(", "x_cell_1", ",", "x_cell_2", ")", "\n", "x_cell_4", "=", "self", ".", "cell_4", "(", "x_cell_2", ",", "x_cell_3", ")", "\n", "x_cell_5", "=", "self", ".", "cell_5", "(", "x_cell_3", ",", "x_cell_4", ")", "\n", "x_cell_6", "=", "self", ".", "cell_6", "(", "x_cell_4", ",", "x_cell_5", ")", "\n", "x_cell_7", "=", "self", ".", "cell_7", "(", "x_cell_5", ",", "x_cell_6", ")", "\n", "x_cell_8", "=", "self", ".", "cell_8", "(", "x_cell_6", ",", "x_cell_7", ")", "\n", "x_cell_9", "=", "self", ".", "cell_9", "(", "x_cell_7", ",", "x_cell_8", ")", "\n", "x_cell_10", "=", "self", ".", "cell_10", "(", "x_cell_8", ",", "x_cell_9", ")", "\n", "x_cell_11", "=", "self", ".", "cell_11", "(", "x_cell_9", ",", "x_cell_10", ")", "\n", "x", "=", "self", ".", "act", "(", "x_cell_11", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.PNASNet5Large.forward_head": [[335, 340], ["pnasnet.PNASNet5Large.global_pool", "torch.dropout", "torch.dropout", "torch.dropout", "pnasnet.PNASNet5Large.last_linear"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ">", "0", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "x", ",", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "last_linear", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.PNASNet5Large.forward": [[341, 345], ["pnasnet.PNASNet5Large.forward_features", "pnasnet.PNASNet5Large.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet._create_pnasnet": [[347, 352], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_pnasnet", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "\n", "PNASNet5Large", ",", "variant", ",", "pretrained", ",", "\n", "feature_cfg", "=", "dict", "(", "feature_cls", "=", "'hook'", ",", "no_rewrite", "=", "True", ")", ",", "# not possible to re-write this model", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet.pnasnet5large": [[354, 362], ["dict", "pnasnet._create_pnasnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pnasnet._create_pnasnet"], ["", "@", "register_model", "\n", "def", "pnasnet5large", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"PNASNet-5 model architecture from the\n    `\"Progressive Neural Architecture Search\"\n    <https://arxiv.org/abs/1712.00559>`_ paper.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "pad_type", "=", "'same'", ",", "**", "kwargs", ")", "\n", "return", "_create_pnasnet", "(", "'pnasnet5large'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.MixerBlock.__init__": [[150, 160], ["functools.partial", "torch.Module.__init__", "norm_layer", "mlp_layer", "norm_layer", "mlp_layer", "int", "layers.DropPath", "torch.Identity", "torch.Identity", "layers.to_2tuple"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "dim", ",", "seq_len", ",", "mlp_ratio", "=", "(", "0.5", ",", "4.0", ")", ",", "mlp_layer", "=", "Mlp", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "act_layer", "=", "nn", ".", "GELU", ",", "drop", "=", "0.", ",", "drop_path", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "tokens_dim", ",", "channels_dim", "=", "[", "int", "(", "x", "*", "dim", ")", "for", "x", "in", "to_2tuple", "(", "mlp_ratio", ")", "]", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "mlp_tokens", "=", "mlp_layer", "(", "seq_len", ",", "tokens_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "mlp_channels", "=", "mlp_layer", "(", "dim", ",", "channels_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.MixerBlock.forward": [[161, 165], ["mlp_mixer.MixerBlock.drop_path", "mlp_mixer.MixerBlock.drop_path", "mlp_mixer.MixerBlock.mlp_tokens().transpose", "mlp_mixer.MixerBlock.mlp_channels", "mlp_mixer.MixerBlock.norm2", "mlp_mixer.MixerBlock.mlp_tokens", "mlp_mixer.MixerBlock.norm1().transpose", "mlp_mixer.MixerBlock.norm1"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "mlp_tokens", "(", "self", ".", "norm1", "(", "x", ")", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "mlp_channels", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.Affine.__init__": [[168, 172], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "alpha", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "(", "1", ",", "1", ",", "dim", ")", ")", ")", "\n", "self", ".", "beta", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "(", "1", ",", "1", ",", "dim", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.Affine.forward": [[173, 175], ["torch.addcmul", "torch.addcmul", "torch.addcmul", "torch.addcmul"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "addcmul", "(", "self", ".", "beta", ",", "self", ".", "alpha", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.ResBlock.__init__": [[182, 194], ["torch.Module.__init__", "int", "norm_layer", "torch.Linear", "torch.Linear", "norm_layer", "mlp_layer", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "dim", ",", "seq_len", ",", "mlp_ratio", "=", "4", ",", "mlp_layer", "=", "Mlp", ",", "norm_layer", "=", "Affine", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "init_values", "=", "1e-4", ",", "drop", "=", "0.", ",", "drop_path", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "channel_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "linear_tokens", "=", "nn", ".", "Linear", "(", "seq_len", ",", "seq_len", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "mlp_channels", "=", "mlp_layer", "(", "dim", ",", "channel_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "self", ".", "ls1", "=", "nn", ".", "Parameter", "(", "init_values", "*", "torch", ".", "ones", "(", "dim", ")", ")", "\n", "self", ".", "ls2", "=", "nn", ".", "Parameter", "(", "init_values", "*", "torch", ".", "ones", "(", "dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.ResBlock.forward": [[195, 199], ["mlp_mixer.ResBlock.drop_path", "mlp_mixer.ResBlock.drop_path", "mlp_mixer.ResBlock.linear_tokens().transpose", "mlp_mixer.ResBlock.mlp_channels", "mlp_mixer.ResBlock.norm2", "mlp_mixer.ResBlock.linear_tokens", "mlp_mixer.ResBlock.norm1().transpose", "mlp_mixer.ResBlock.norm1"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "ls1", "*", "self", ".", "linear_tokens", "(", "self", ".", "norm1", "(", "x", ")", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "ls2", "*", "self", ".", "mlp_channels", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.SpatialGatingUnit.__init__": [[206, 211], ["torch.Module.__init__", "norm_layer", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "seq_len", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "gate_dim", "=", "dim", "//", "2", "\n", "self", ".", "norm", "=", "norm_layer", "(", "gate_dim", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "seq_len", ",", "seq_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.SpatialGatingUnit.init_weights": [[212, 216], ["torch.init.normal_", "torch.init.normal_", "torch.init.ones_", "torch.init.ones_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "# special init for the projection gate, called as override by base model init", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "proj", ".", "weight", ",", "std", "=", "1e-6", ")", "\n", "nn", ".", "init", ".", "ones_", "(", "self", ".", "proj", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.SpatialGatingUnit.forward": [[217, 222], ["x.chunk", "mlp_mixer.SpatialGatingUnit.norm", "mlp_mixer.SpatialGatingUnit.proj", "mlp_mixer.SpatialGatingUnit.transpose", "mlp_mixer.SpatialGatingUnit.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "u", ",", "v", "=", "x", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "v", "=", "self", ".", "norm", "(", "v", ")", "\n", "v", "=", "self", ".", "proj", "(", "v", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "return", "u", "*", "v", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.SpatialGatingBlock.__init__": [[229, 238], ["functools.partial", "torch.Module.__init__", "int", "norm_layer", "functools.partial", "mlp_layer", "layers.DropPath", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "dim", ",", "seq_len", ",", "mlp_ratio", "=", "4", ",", "mlp_layer", "=", "GatedMlp", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "act_layer", "=", "nn", ".", "GELU", ",", "drop", "=", "0.", ",", "drop_path", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "channel_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "dim", ")", "\n", "sgu", "=", "partial", "(", "SpatialGatingUnit", ",", "seq_len", "=", "seq_len", ")", "\n", "self", ".", "mlp_channels", "=", "mlp_layer", "(", "dim", ",", "channel_dim", ",", "act_layer", "=", "act_layer", ",", "gate_layer", "=", "sgu", ",", "drop", "=", "drop", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.SpatialGatingBlock.forward": [[239, 242], ["mlp_mixer.SpatialGatingBlock.drop_path", "mlp_mixer.SpatialGatingBlock.mlp_channels", "mlp_mixer.SpatialGatingBlock.norm"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "mlp_channels", "(", "self", ".", "norm", "(", "x", ")", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.MlpMixer.__init__": [[246, 284], ["functools.partial", "torch.Module.__init__", "layers.PatchEmbed", "torch.Sequential", "torch.Sequential", "norm_layer", "mlp_mixer.MlpMixer.init_weights", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "block_layer", "range"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.GluMlp.init_weights"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "num_classes", "=", "1000", ",", "\n", "img_size", "=", "224", ",", "\n", "in_chans", "=", "3", ",", "\n", "patch_size", "=", "16", ",", "\n", "num_blocks", "=", "8", ",", "\n", "embed_dim", "=", "512", ",", "\n", "mlp_ratio", "=", "(", "0.5", ",", "4.0", ")", ",", "\n", "block_layer", "=", "MixerBlock", ",", "\n", "mlp_layer", "=", "Mlp", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "\n", "drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.", ",", "\n", "nlhb", "=", "False", ",", "\n", "stem_norm", "=", "False", ",", "\n", "global_pool", "=", "'avg'", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "self", ".", "num_features", "=", "self", ".", "embed_dim", "=", "embed_dim", "# num_features for consistency with other models", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "self", ".", "stem", "=", "PatchEmbed", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "\n", "embed_dim", "=", "embed_dim", ",", "norm_layer", "=", "norm_layer", "if", "stem_norm", "else", "None", ")", "\n", "# FIXME drop_path (stochastic depth scaling rule or all the same?)", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "block_layer", "(", "\n", "embed_dim", ",", "self", ".", "stem", ".", "num_patches", ",", "mlp_ratio", ",", "mlp_layer", "=", "mlp_layer", ",", "norm_layer", "=", "norm_layer", ",", "\n", "act_layer", "=", "act_layer", ",", "drop", "=", "drop_rate", ",", "drop_path", "=", "drop_path_rate", ")", "\n", "for", "_", "in", "range", "(", "num_blocks", ")", "]", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "self", ".", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "init_weights", "(", "nlhb", "=", "nlhb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.MlpMixer.init_weights": [[285, 289], ["helpers.named_apply", "functools.partial", "math.log"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_apply"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "init_weights", "(", "self", ",", "nlhb", "=", "False", ")", ":", "\n", "        ", "head_bias", "=", "-", "math", ".", "log", "(", "self", ".", "num_classes", ")", "if", "nlhb", "else", "0.", "\n", "named_apply", "(", "partial", "(", "_init_weights", ",", "head_bias", "=", "head_bias", ")", ",", "module", "=", "self", ")", "# depth-first", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.MlpMixer.group_matcher": [[290, 295], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^stem'", ",", "# stem and embed", "\n", "blocks", "=", "[", "(", "r'^blocks\\.(\\d+)'", ",", "None", ")", ",", "(", "r'^norm'", ",", "(", "99999", ",", ")", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.MlpMixer.set_grad_checkpointing": [[297, 300], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.MlpMixer.get_classifier": [[301, 304], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.MlpMixer.reset_classifier": [[305, 311], ["torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "None", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "if", "global_pool", "is", "not", "None", ":", "\n", "            ", "assert", "global_pool", "in", "(", "''", ",", "'avg'", ")", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.MlpMixer.forward_features": [[312, 320], ["mlp_mixer.MlpMixer.stem", "mlp_mixer.MlpMixer.norm", "helpers.checkpoint_seq", "mlp_mixer.MlpMixer.blocks", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "blocks", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "blocks", "(", "x", ")", "\n", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.MlpMixer.forward": [[321, 327], ["mlp_mixer.MlpMixer.forward_features", "mlp_mixer.MlpMixer.head", "x.mean.mean.mean"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "if", "self", ".", "global_pool", "==", "'avg'", ":", "\n", "            ", "x", "=", "x", ".", "mean", "(", "dim", "=", "1", ")", "\n", "", "x", "=", "self", ".", "head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._cfg": [[54, 62], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bicubic'", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'mean'", ":", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "'std'", ":", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "\n", "'first_conv'", ":", "'stem.proj'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._init_weights": [[329, 361], ["isinstance", "name.startswith", "isinstance", "torch.init.zeros_", "torch.init.constant_", "layers.lecun_normal_", "isinstance", "layers.lecun_normal_", "torch.init.xavier_uniform_", "torch.init.zeros_", "torch.init.ones_", "torch.init.zeros_", "hasattr", "torch.init.zeros_", "module.init_weights", "torch.init.normal_", "torch.init.zeros_"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.lecun_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.lecun_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.GluMlp.init_weights"], ["", "", "def", "_init_weights", "(", "module", ":", "nn", ".", "Module", ",", "name", ":", "str", ",", "head_bias", ":", "float", "=", "0.", ",", "flax", "=", "False", ")", ":", "\n", "    ", "\"\"\" Mixer weight initialization (trying to match Flax defaults)\n    \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "if", "name", ".", "startswith", "(", "'head'", ")", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "weight", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "module", ".", "bias", ",", "head_bias", ")", "\n", "", "else", ":", "\n", "            ", "if", "flax", ":", "\n", "# Flax defaults", "\n", "                ", "lecun_normal_", "(", "module", ".", "weight", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "", "", "else", ":", "\n", "# like MLP init in vit (my original init)", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "module", ".", "weight", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "if", "'mlp'", "in", "name", ":", "\n", "                        ", "nn", ".", "init", ".", "normal_", "(", "module", ".", "bias", ",", "std", "=", "1e-6", ")", "\n", "", "else", ":", "\n", "                        ", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "", "", "", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", ":", "\n", "        ", "lecun_normal_", "(", "module", ".", "weight", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "(", "nn", ".", "LayerNorm", ",", "nn", ".", "BatchNorm2d", ",", "nn", ".", "GroupNorm", ")", ")", ":", "\n", "        ", "nn", ".", "init", ".", "ones_", "(", "module", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "", "elif", "hasattr", "(", "module", ",", "'init_weights'", ")", ":", "\n", "# NOTE if a parent module contains init_weights method, it can override the init of the", "\n", "# child modules as this will be called in depth-first order.", "\n", "        ", "module", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.checkpoint_filter_fn": [[363, 378], ["state_dict.items", "k.replace.replace", "k.replace.replace", "k.replace.replace", "k.replace.replace", "k.replace.endswith", "k.replace.endswith", "v.reshape.reshape"], "function", ["None"], ["", "", "def", "checkpoint_filter_fn", "(", "state_dict", ",", "model", ")", ":", "\n", "    ", "\"\"\" Remap checkpoints if needed \"\"\"", "\n", "if", "'patch_embed.proj.weight'", "in", "state_dict", ":", "\n", "# Remap FB ResMlp models -> timm", "\n", "        ", "out_dict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "k", "=", "k", ".", "replace", "(", "'patch_embed.'", ",", "'stem.'", ")", "\n", "k", "=", "k", ".", "replace", "(", "'attn.'", ",", "'linear_tokens.'", ")", "\n", "k", "=", "k", ".", "replace", "(", "'mlp.'", ",", "'mlp_channels.'", ")", "\n", "k", "=", "k", ".", "replace", "(", "'gamma_'", ",", "'ls'", ")", "\n", "if", "k", ".", "endswith", "(", "'.alpha'", ")", "or", "k", ".", "endswith", "(", "'.beta'", ")", ":", "\n", "                ", "v", "=", "v", ".", "reshape", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "", "out_dict", "[", "k", "]", "=", "v", "\n", "", "return", "out_dict", "\n", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer": [[380, 389], ["kwargs.get", "helpers.build_model_with_cfg", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "def", "_create_mixer", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", ".", "get", "(", "'features_only'", ",", "None", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'features_only not implemented for MLP-Mixer models.'", ")", "\n", "\n", "", "model", "=", "build_model_with_cfg", "(", "\n", "MlpMixer", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_filter_fn", "=", "checkpoint_filter_fn", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.mixer_s32_224": [[391, 399], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "mixer_s32_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Mixer-S/32 224x224\n    Paper: 'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "patch_size", "=", "32", ",", "num_blocks", "=", "8", ",", "embed_dim", "=", "512", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'mixer_s32_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.mixer_s16_224": [[401, 409], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "mixer_s16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Mixer-S/16 224x224\n    Paper:  'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "num_blocks", "=", "8", ",", "embed_dim", "=", "512", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'mixer_s16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.mixer_b32_224": [[411, 419], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "mixer_b32_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Mixer-B/32 224x224\n    Paper:  'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "patch_size", "=", "32", ",", "num_blocks", "=", "12", ",", "embed_dim", "=", "768", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'mixer_b32_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.mixer_b16_224": [[421, 429], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "mixer_b16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Mixer-B/16 224x224. ImageNet-1k pretrained weights.\n    Paper:  'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "num_blocks", "=", "12", ",", "embed_dim", "=", "768", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'mixer_b16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.mixer_b16_224_in21k": [[431, 439], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "mixer_b16_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Mixer-B/16 224x224. ImageNet-21k pretrained weights.\n    Paper:  'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "num_blocks", "=", "12", ",", "embed_dim", "=", "768", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'mixer_b16_224_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.mixer_l32_224": [[441, 449], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "mixer_l32_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Mixer-L/32 224x224.\n    Paper:  'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "patch_size", "=", "32", ",", "num_blocks", "=", "24", ",", "embed_dim", "=", "1024", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'mixer_l32_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.mixer_l16_224": [[451, 459], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "mixer_l16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Mixer-L/16 224x224. ImageNet-1k pretrained weights.\n    Paper:  'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "num_blocks", "=", "24", ",", "embed_dim", "=", "1024", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'mixer_l16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.mixer_l16_224_in21k": [[461, 469], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "mixer_l16_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Mixer-L/16 224x224. ImageNet-21k pretrained weights.\n    Paper:  'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "num_blocks", "=", "24", ",", "embed_dim", "=", "1024", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'mixer_l16_224_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.mixer_b16_224_miil": [[471, 479], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "mixer_b16_224_miil", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Mixer-B/16 224x224. ImageNet-21k pretrained weights.\n    Weights taken from: https://github.com/Alibaba-MIIL/ImageNet21K\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "num_blocks", "=", "12", ",", "embed_dim", "=", "768", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'mixer_b16_224_miil'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.mixer_b16_224_miil_in21k": [[481, 489], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "mixer_b16_224_miil_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Mixer-B/16 224x224. ImageNet-1k pretrained weights.\n    Weights taken from: https://github.com/Alibaba-MIIL/ImageNet21K\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "num_blocks", "=", "12", ",", "embed_dim", "=", "768", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'mixer_b16_224_miil_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.gmixer_12_224": [[491, 501], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "gmixer_12_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Glu-Mixer-12 224x224\n    Experiment by Ross Wightman, adding (Si)GLU to MLP-Mixer\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "num_blocks", "=", "12", ",", "embed_dim", "=", "384", ",", "mlp_ratio", "=", "(", "1.0", ",", "4.0", ")", ",", "\n", "mlp_layer", "=", "GluMlp", ",", "act_layer", "=", "nn", ".", "SiLU", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'gmixer_12_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.gmixer_24_224": [[503, 513], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "gmixer_24_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Glu-Mixer-24 224x224\n    Experiment by Ross Wightman, adding (Si)GLU to MLP-Mixer\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "num_blocks", "=", "24", ",", "embed_dim", "=", "384", ",", "mlp_ratio", "=", "(", "1.0", ",", "4.0", ")", ",", "\n", "mlp_layer", "=", "GluMlp", ",", "act_layer", "=", "nn", ".", "SiLU", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'gmixer_24_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.resmlp_12_224": [[515, 524], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "resmlp_12_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResMLP-12\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "num_blocks", "=", "12", ",", "embed_dim", "=", "384", ",", "mlp_ratio", "=", "4", ",", "block_layer", "=", "ResBlock", ",", "norm_layer", "=", "Affine", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'resmlp_12_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.resmlp_24_224": [[526, 536], ["dict", "mlp_mixer._create_mixer", "functools.partial"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "resmlp_24_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResMLP-24\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "num_blocks", "=", "24", ",", "embed_dim", "=", "384", ",", "mlp_ratio", "=", "4", ",", "\n", "block_layer", "=", "partial", "(", "ResBlock", ",", "init_values", "=", "1e-5", ")", ",", "norm_layer", "=", "Affine", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'resmlp_24_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.resmlp_36_224": [[538, 548], ["dict", "mlp_mixer._create_mixer", "functools.partial"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "resmlp_36_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResMLP-36\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "num_blocks", "=", "36", ",", "embed_dim", "=", "384", ",", "mlp_ratio", "=", "4", ",", "\n", "block_layer", "=", "partial", "(", "ResBlock", ",", "init_values", "=", "1e-6", ")", ",", "norm_layer", "=", "Affine", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'resmlp_36_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.resmlp_big_24_224": [[550, 560], ["dict", "mlp_mixer._create_mixer", "functools.partial"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "resmlp_big_24_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResMLP-B-24\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "num_blocks", "=", "24", ",", "embed_dim", "=", "768", ",", "mlp_ratio", "=", "4", ",", "\n", "block_layer", "=", "partial", "(", "ResBlock", ",", "init_values", "=", "1e-6", ")", ",", "norm_layer", "=", "Affine", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'resmlp_big_24_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.resmlp_12_distilled_224": [[562, 571], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "resmlp_12_distilled_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResMLP-12\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "num_blocks", "=", "12", ",", "embed_dim", "=", "384", ",", "mlp_ratio", "=", "4", ",", "block_layer", "=", "ResBlock", ",", "norm_layer", "=", "Affine", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'resmlp_12_distilled_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.resmlp_24_distilled_224": [[573, 583], ["dict", "mlp_mixer._create_mixer", "functools.partial"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "resmlp_24_distilled_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResMLP-24\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "num_blocks", "=", "24", ",", "embed_dim", "=", "384", ",", "mlp_ratio", "=", "4", ",", "\n", "block_layer", "=", "partial", "(", "ResBlock", ",", "init_values", "=", "1e-5", ")", ",", "norm_layer", "=", "Affine", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'resmlp_24_distilled_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.resmlp_36_distilled_224": [[585, 595], ["dict", "mlp_mixer._create_mixer", "functools.partial"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "resmlp_36_distilled_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResMLP-36\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "num_blocks", "=", "36", ",", "embed_dim", "=", "384", ",", "mlp_ratio", "=", "4", ",", "\n", "block_layer", "=", "partial", "(", "ResBlock", ",", "init_values", "=", "1e-6", ")", ",", "norm_layer", "=", "Affine", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'resmlp_36_distilled_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.resmlp_big_24_distilled_224": [[597, 607], ["dict", "mlp_mixer._create_mixer", "functools.partial"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "resmlp_big_24_distilled_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResMLP-B-24\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "num_blocks", "=", "24", ",", "embed_dim", "=", "768", ",", "mlp_ratio", "=", "4", ",", "\n", "block_layer", "=", "partial", "(", "ResBlock", ",", "init_values", "=", "1e-6", ")", ",", "norm_layer", "=", "Affine", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'resmlp_big_24_distilled_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.resmlp_big_24_224_in22ft1k": [[609, 619], ["dict", "mlp_mixer._create_mixer", "functools.partial"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "resmlp_big_24_224_in22ft1k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResMLP-B-24\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "num_blocks", "=", "24", ",", "embed_dim", "=", "768", ",", "mlp_ratio", "=", "4", ",", "\n", "block_layer", "=", "partial", "(", "ResBlock", ",", "init_values", "=", "1e-6", ")", ",", "norm_layer", "=", "Affine", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'resmlp_big_24_224_in22ft1k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.resmlp_12_224_dino": [[621, 632], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "resmlp_12_224_dino", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResMLP-12\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n\n    Model pretrained via DINO (self-supervised) - https://arxiv.org/abs/2104.14294\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "num_blocks", "=", "12", ",", "embed_dim", "=", "384", ",", "mlp_ratio", "=", "4", ",", "block_layer", "=", "ResBlock", ",", "norm_layer", "=", "Affine", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'resmlp_12_224_dino'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.resmlp_24_224_dino": [[634, 646], ["dict", "mlp_mixer._create_mixer", "functools.partial"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "resmlp_24_224_dino", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResMLP-24\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n\n    Model pretrained via DINO (self-supervised) - https://arxiv.org/abs/2104.14294\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "num_blocks", "=", "24", ",", "embed_dim", "=", "384", ",", "mlp_ratio", "=", "4", ",", "\n", "block_layer", "=", "partial", "(", "ResBlock", ",", "init_values", "=", "1e-5", ")", ",", "norm_layer", "=", "Affine", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'resmlp_24_224_dino'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.gmlp_ti16_224": [[648, 658], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "gmlp_ti16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" gMLP-Tiny\n    Paper: `Pay Attention to MLPs` - https://arxiv.org/abs/2105.08050\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "num_blocks", "=", "30", ",", "embed_dim", "=", "128", ",", "mlp_ratio", "=", "6", ",", "block_layer", "=", "SpatialGatingBlock", ",", "\n", "mlp_layer", "=", "GatedMlp", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'gmlp_ti16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.gmlp_s16_224": [[660, 670], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "gmlp_s16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" gMLP-Small\n    Paper: `Pay Attention to MLPs` - https://arxiv.org/abs/2105.08050\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "num_blocks", "=", "30", ",", "embed_dim", "=", "256", ",", "mlp_ratio", "=", "6", ",", "block_layer", "=", "SpatialGatingBlock", ",", "\n", "mlp_layer", "=", "GatedMlp", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'gmlp_s16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer.gmlp_b16_224": [[672, 682], ["dict", "mlp_mixer._create_mixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mlp_mixer._create_mixer"], ["", "@", "register_model", "\n", "def", "gmlp_b16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" gMLP-Base\n    Paper: `Pay Attention to MLPs` - https://arxiv.org/abs/2105.08050\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "num_blocks", "=", "30", ",", "embed_dim", "=", "512", ",", "mlp_ratio", "=", "6", ",", "block_layer", "=", "SpatialGatingBlock", ",", "\n", "mlp_layer", "=", "GatedMlp", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_mixer", "(", "'gmlp_b16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.ClassAttn.__init__": [[78, 90], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "qkv_bias", "=", "False", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "self", ".", "scale", "=", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "q", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "k", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.ClassAttn.forward": [[91, 108], ["cait.ClassAttn.q().unsqueeze().reshape().permute", "cait.ClassAttn.k().reshape().permute", "cait.ClassAttn.v().reshape().permute", "cait.ClassAttn.softmax", "cait.ClassAttn.attn_drop", "cait.ClassAttn.proj", "cait.ClassAttn.proj_drop", "cait.ClassAttn.transpose", "cait.ClassAttn.q().unsqueeze().reshape", "cait.ClassAttn.k().reshape", "cait.ClassAttn.v().reshape", "cait.ClassAttn.q().unsqueeze", "cait.ClassAttn.k", "cait.ClassAttn.v", "cait.ClassAttn.q"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "q", "=", "self", ".", "q", "(", "x", "[", ":", ",", "0", "]", ")", ".", "unsqueeze", "(", "1", ")", ".", "reshape", "(", "B", ",", "1", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "k", "=", "self", ".", "k", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n", "q", "=", "q", "*", "self", ".", "scale", "\n", "v", "=", "self", ".", "v", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x_cls", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "1", ",", "C", ")", "\n", "x_cls", "=", "self", ".", "proj", "(", "x_cls", ")", "\n", "x_cls", "=", "self", ".", "proj_drop", "(", "x_cls", ")", "\n", "\n", "return", "x_cls", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.LayerScaleBlockClassAttn.__init__": [[113, 127], ["torch.Module.__init__", "norm_layer", "attn_block", "norm_layer", "int", "mlp_block", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dim", ",", "num_heads", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "\n", "drop_path", "=", "0.", ",", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "attn_block", "=", "ClassAttn", ",", "\n", "mlp_block", "=", "Mlp", ",", "init_values", "=", "1e-4", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn", "=", "attn_block", "(", "\n", "dim", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "mlp_hidden_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "mlp_block", "(", "in_features", "=", "dim", ",", "hidden_features", "=", "mlp_hidden_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "self", ".", "gamma_1", "=", "nn", ".", "Parameter", "(", "init_values", "*", "torch", ".", "ones", "(", "(", "dim", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "gamma_2", "=", "nn", ".", "Parameter", "(", "init_values", "*", "torch", ".", "ones", "(", "(", "dim", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.LayerScaleBlockClassAttn.forward": [[128, 133], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "cait.LayerScaleBlockClassAttn.drop_path", "cait.LayerScaleBlockClassAttn.drop_path", "cait.LayerScaleBlockClassAttn.attn", "cait.LayerScaleBlockClassAttn.mlp", "cait.LayerScaleBlockClassAttn.norm1", "cait.LayerScaleBlockClassAttn.norm2"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_cls", ")", ":", "\n", "        ", "u", "=", "torch", ".", "cat", "(", "(", "x_cls", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "x_cls", "=", "x_cls", "+", "self", ".", "drop_path", "(", "self", ".", "gamma_1", "*", "self", ".", "attn", "(", "self", ".", "norm1", "(", "u", ")", ")", ")", "\n", "x_cls", "=", "x_cls", "+", "self", ".", "drop_path", "(", "self", ".", "gamma_2", "*", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x_cls", ")", ")", ")", "\n", "return", "x_cls", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.TalkingHeadAttn.__init__": [[138, 156], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "qkv_bias", "=", "False", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "\n", "self", ".", "scale", "=", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", "*", "3", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "\n", "self", ".", "proj_l", "=", "nn", ".", "Linear", "(", "num_heads", ",", "num_heads", ")", "\n", "self", ".", "proj_w", "=", "nn", ".", "Linear", "(", "num_heads", ",", "num_heads", ")", "\n", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.TalkingHeadAttn.forward": [[157, 175], ["cait.TalkingHeadAttn.qkv().reshape().permute", "cait.TalkingHeadAttn.proj_l().permute", "cait.TalkingHeadAttn.softmax", "cait.TalkingHeadAttn.proj_w().permute", "cait.TalkingHeadAttn.attn_drop", "cait.TalkingHeadAttn.proj", "cait.TalkingHeadAttn.proj_drop", "k.transpose", "cait.TalkingHeadAttn.qkv().reshape", "cait.TalkingHeadAttn.proj_l", "cait.TalkingHeadAttn.proj_w", "cait.TalkingHeadAttn.permute", "cait.TalkingHeadAttn.permute", "cait.TalkingHeadAttn.qkv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "3", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", "[", "0", "]", "*", "self", ".", "scale", ",", "qkv", "[", "1", "]", ",", "qkv", "[", "2", "]", "\n", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "attn", "=", "self", ".", "proj_l", "(", "attn", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "attn", "=", "self", ".", "proj_w", "(", "attn", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "N", ",", "C", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.LayerScaleBlock.__init__": [[180, 194], ["torch.Module.__init__", "norm_layer", "attn_block", "norm_layer", "int", "mlp_block", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dim", ",", "num_heads", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "\n", "drop_path", "=", "0.", ",", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "attn_block", "=", "TalkingHeadAttn", ",", "\n", "mlp_block", "=", "Mlp", ",", "init_values", "=", "1e-4", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn", "=", "attn_block", "(", "\n", "dim", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "mlp_hidden_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "mlp_block", "(", "in_features", "=", "dim", ",", "hidden_features", "=", "mlp_hidden_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "self", ".", "gamma_1", "=", "nn", ".", "Parameter", "(", "init_values", "*", "torch", ".", "ones", "(", "(", "dim", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "gamma_2", "=", "nn", ".", "Parameter", "(", "init_values", "*", "torch", ".", "ones", "(", "(", "dim", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.LayerScaleBlock.forward": [[195, 199], ["cait.LayerScaleBlock.drop_path", "cait.LayerScaleBlock.drop_path", "cait.LayerScaleBlock.attn", "cait.LayerScaleBlock.mlp", "cait.LayerScaleBlock.norm1", "cait.LayerScaleBlock.norm2"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "gamma_1", "*", "self", ".", "attn", "(", "self", ".", "norm1", "(", "x", ")", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "gamma_2", "*", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.Cait.__init__": [[204, 262], ["functools.partial", "torch.Module.__init__", "patch_layer", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Dropout", "torch.Dropout", "torch.Sequential", "torch.Sequential", "torch.ModuleList", "torch.ModuleList", "norm_layer", "layers.trunc_normal_", "layers.trunc_normal_", "cait.Cait.apply", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "dict", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "range", "block_layers_token", "block_layers", "range", "range"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["    ", "def", "__init__", "(", "\n", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "global_pool", "=", "'token'", ",", "\n", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "True", ",", "\n", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "\n", "block_layers", "=", "LayerScaleBlock", ",", "\n", "block_layers_token", "=", "LayerScaleBlockClassAttn", ",", "\n", "patch_layer", "=", "PatchEmbed", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "\n", "attn_block", "=", "TalkingHeadAttn", ",", "\n", "mlp_block", "=", "Mlp", ",", "\n", "init_values", "=", "1e-4", ",", "\n", "attn_block_token_only", "=", "ClassAttn", ",", "\n", "mlp_block_token_only", "=", "Mlp", ",", "\n", "depth_token_only", "=", "2", ",", "\n", "mlp_ratio_token_only", "=", "4.0", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "global_pool", "in", "(", "''", ",", "'token'", ",", "'avg'", ")", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "self", ".", "num_features", "=", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "self", ".", "patch_embed", "=", "patch_layer", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "embed_dim", "=", "embed_dim", ")", "\n", "\n", "num_patches", "=", "self", ".", "patch_embed", ".", "num_patches", "\n", "\n", "self", ".", "cls_token", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "self", ".", "pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "num_patches", ",", "embed_dim", ")", ")", "\n", "self", ".", "pos_drop", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", "\n", "\n", "dpr", "=", "[", "drop_path_rate", "for", "i", "in", "range", "(", "depth", ")", "]", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "block_layers", "(", "\n", "dim", "=", "embed_dim", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", "[", "i", "]", ",", "norm_layer", "=", "norm_layer", ",", "\n", "act_layer", "=", "act_layer", ",", "attn_block", "=", "attn_block", ",", "mlp_block", "=", "mlp_block", ",", "init_values", "=", "init_values", ")", "\n", "for", "i", "in", "range", "(", "depth", ")", "]", ")", "\n", "\n", "self", ".", "blocks_token_only", "=", "nn", ".", "ModuleList", "(", "[", "\n", "block_layers_token", "(", "\n", "dim", "=", "embed_dim", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio_token_only", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "drop", "=", "0.0", ",", "attn_drop", "=", "0.0", ",", "drop_path", "=", "0.0", ",", "norm_layer", "=", "norm_layer", ",", "\n", "act_layer", "=", "act_layer", ",", "attn_block", "=", "attn_block_token_only", ",", "\n", "mlp_block", "=", "mlp_block_token_only", ",", "init_values", "=", "init_values", ")", "\n", "for", "i", "in", "range", "(", "depth_token_only", ")", "]", ")", "\n", "\n", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "\n", "\n", "self", ".", "feature_info", "=", "[", "dict", "(", "num_chs", "=", "embed_dim", ",", "reduction", "=", "0", ",", "module", "=", "'head'", ")", "]", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "trunc_normal_", "(", "self", ".", "pos_embed", ",", "std", "=", ".02", ")", "\n", "trunc_normal_", "(", "self", ".", "cls_token", ",", "std", "=", ".02", ")", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.Cait._init_weights": [[263, 271], ["isinstance", "layers.trunc_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", ".02", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.Cait.no_weight_decay": [[272, 275], ["None"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "{", "'pos_embed'", ",", "'cls_token'", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.Cait.set_grad_checkpointing": [[276, 279], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.Cait.group_matcher": [[280, 296], ["any", "name.startswith", "name.startswith", "name.startswith", "int", "name.startswith", "int", "len", "float", "name.split", "len", "len", "name.split"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "def", "_matcher", "(", "name", ")", ":", "\n", "            ", "if", "any", "(", "[", "name", ".", "startswith", "(", "n", ")", "for", "n", "in", "(", "'cls_token'", ",", "'pos_embed'", ",", "'patch_embed'", ")", "]", ")", ":", "\n", "                ", "return", "0", "\n", "", "elif", "name", ".", "startswith", "(", "'blocks.'", ")", ":", "\n", "                ", "return", "int", "(", "name", ".", "split", "(", "'.'", ")", "[", "1", "]", ")", "+", "1", "\n", "", "elif", "name", ".", "startswith", "(", "'blocks_token_only.'", ")", ":", "\n", "# overlap token only blocks with last blocks", "\n", "                ", "to_offset", "=", "len", "(", "self", ".", "blocks", ")", "-", "len", "(", "self", ".", "blocks_token_only", ")", "+", "1", "\n", "return", "int", "(", "name", ".", "split", "(", "'.'", ")", "[", "1", "]", ")", "+", "to_offset", "\n", "", "elif", "name", ".", "startswith", "(", "'norm.'", ")", ":", "\n", "                ", "return", "len", "(", "self", ".", "blocks", ")", "\n", "", "else", ":", "\n", "                ", "return", "float", "(", "'inf'", ")", "\n", "", "", "return", "_matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.Cait.get_classifier": [[297, 300], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.Cait.reset_classifier": [[301, 307], ["torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "None", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "if", "global_pool", "is", "not", "None", ":", "\n", "            ", "assert", "global_pool", "in", "(", "''", ",", "'token'", ",", "'avg'", ")", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.Cait.forward_features": [[308, 322], ["cait.Cait.patch_embed", "cait.Cait.pos_drop", "cait.Cait.cls_token.expand", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "cait.Cait.norm", "helpers.checkpoint_seq", "cait.Cait.blocks", "blk", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "x", "=", "x", "+", "self", ".", "pos_embed", "\n", "x", "=", "self", ".", "pos_drop", "(", "x", ")", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "blocks", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "blocks", "(", "x", ")", "\n", "", "cls_tokens", "=", "self", ".", "cls_token", ".", "expand", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "-", "1", ")", "\n", "for", "i", ",", "blk", "in", "enumerate", "(", "self", ".", "blocks_token_only", ")", ":", "\n", "            ", "cls_tokens", "=", "blk", "(", "x", ",", "cls_tokens", ")", "\n", "", "x", "=", "torch", ".", "cat", "(", "(", "cls_tokens", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.Cait.forward_head": [[323, 327], ["cait.Cait.head", "x[].mean"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "global_pool", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", "1", ":", "]", ".", "mean", "(", "dim", "=", "1", ")", "if", "self", ".", "global_pool", "==", "'avg'", "else", "x", "[", ":", ",", "0", "]", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.Cait.forward": [[328, 332], ["cait.Cait.forward_features", "cait.Cait.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait._cfg": [[26, 34], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "384", ",", "384", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", "1.0", ",", "'interpolation'", ":", "'bicubic'", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'patch_embed.proj'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.checkpoint_filter_fn": [[334, 341], ["state_dict.items", "k.replace"], "function", ["None"], ["", "", "def", "checkpoint_filter_fn", "(", "state_dict", ",", "model", "=", "None", ")", ":", "\n", "    ", "if", "'model'", "in", "state_dict", ":", "\n", "        ", "state_dict", "=", "state_dict", "[", "'model'", "]", "\n", "", "checkpoint_no_module", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "checkpoint_no_module", "[", "k", ".", "replace", "(", "'module.'", ",", "''", ")", "]", "=", "v", "\n", "", "return", "checkpoint_no_module", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait._create_cait": [[343, 352], ["kwargs.get", "helpers.build_model_with_cfg", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "def", "_create_cait", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", ".", "get", "(", "'features_only'", ",", "None", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'features_only not implemented for Vision Transformer models.'", ")", "\n", "\n", "", "model", "=", "build_model_with_cfg", "(", "\n", "Cait", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_filter_fn", "=", "checkpoint_filter_fn", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.cait_xxs24_224": [[354, 359], ["dict", "cait._create_cait"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait._create_cait"], ["", "@", "register_model", "\n", "def", "cait_xxs24_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "24", ",", "num_heads", "=", "4", ",", "init_values", "=", "1e-5", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_cait", "(", "'cait_xxs24_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.cait_xxs24_384": [[361, 366], ["dict", "cait._create_cait"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait._create_cait"], ["", "@", "register_model", "\n", "def", "cait_xxs24_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "24", ",", "num_heads", "=", "4", ",", "init_values", "=", "1e-5", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_cait", "(", "'cait_xxs24_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.cait_xxs36_224": [[368, 373], ["dict", "cait._create_cait"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait._create_cait"], ["", "@", "register_model", "\n", "def", "cait_xxs36_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "36", ",", "num_heads", "=", "4", ",", "init_values", "=", "1e-5", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_cait", "(", "'cait_xxs36_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.cait_xxs36_384": [[375, 380], ["dict", "cait._create_cait"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait._create_cait"], ["", "@", "register_model", "\n", "def", "cait_xxs36_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "36", ",", "num_heads", "=", "4", ",", "init_values", "=", "1e-5", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_cait", "(", "'cait_xxs36_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.cait_xs24_384": [[382, 387], ["dict", "cait._create_cait"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait._create_cait"], ["", "@", "register_model", "\n", "def", "cait_xs24_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "288", ",", "depth", "=", "24", ",", "num_heads", "=", "6", ",", "init_values", "=", "1e-5", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_cait", "(", "'cait_xs24_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.cait_s24_224": [[389, 394], ["dict", "cait._create_cait"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait._create_cait"], ["", "@", "register_model", "\n", "def", "cait_s24_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "24", ",", "num_heads", "=", "8", ",", "init_values", "=", "1e-5", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_cait", "(", "'cait_s24_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.cait_s24_384": [[396, 401], ["dict", "cait._create_cait"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait._create_cait"], ["", "@", "register_model", "\n", "def", "cait_s24_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "24", ",", "num_heads", "=", "8", ",", "init_values", "=", "1e-5", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_cait", "(", "'cait_s24_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.cait_s36_384": [[403, 408], ["dict", "cait._create_cait"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait._create_cait"], ["", "@", "register_model", "\n", "def", "cait_s36_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "36", ",", "num_heads", "=", "8", ",", "init_values", "=", "1e-6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_cait", "(", "'cait_s36_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.cait_m36_384": [[410, 415], ["dict", "cait._create_cait"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait._create_cait"], ["", "@", "register_model", "\n", "def", "cait_m36_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "36", ",", "num_heads", "=", "16", ",", "init_values", "=", "1e-6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_cait", "(", "'cait_m36_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait.cait_m48_448": [[417, 422], ["dict", "cait._create_cait"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cait._create_cait"], ["", "@", "register_model", "\n", "def", "cait_m48_448", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "48", ",", "num_heads", "=", "16", ",", "init_values", "=", "1e-6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_cait", "(", "'cait_m48_448'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest.ResNestBottleneck.__init__": [[60, 105], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "norm_layer", "act_layer", "torch.nn.Conv2d", "norm_layer", "act_layer", "int", "torch.nn.AvgPool2d", "layers.SplitAttn", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Conv2d", "norm_layer", "act_layer", "torch.nn.AvgPool2d", "drop_block", "torch.nn.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "\n", "radix", "=", "1", ",", "cardinality", "=", "1", ",", "base_width", "=", "64", ",", "avd", "=", "False", ",", "avd_first", "=", "False", ",", "is_first", "=", "False", ",", "\n", "reduce_first", "=", "1", ",", "dilation", "=", "1", ",", "first_dilation", "=", "None", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "\n", "attn_layer", "=", "None", ",", "aa_layer", "=", "None", ",", "drop_block", "=", "None", ",", "drop_path", "=", "None", ")", ":", "\n", "        ", "super", "(", "ResNestBottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "reduce_first", "==", "1", "# not supported", "\n", "assert", "attn_layer", "is", "None", "# not supported", "\n", "assert", "aa_layer", "is", "None", "# TODO not yet supported", "\n", "assert", "drop_path", "is", "None", "# TODO not yet supported", "\n", "\n", "group_width", "=", "int", "(", "planes", "*", "(", "base_width", "/", "64.", ")", ")", "*", "cardinality", "\n", "first_dilation", "=", "first_dilation", "or", "dilation", "\n", "if", "avd", "and", "(", "stride", ">", "1", "or", "is_first", ")", ":", "\n", "            ", "avd_stride", "=", "stride", "\n", "stride", "=", "1", "\n", "", "else", ":", "\n", "            ", "avd_stride", "=", "0", "\n", "", "self", ".", "radix", "=", "radix", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "group_width", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "group_width", ")", "\n", "self", ".", "act1", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "avd_first", "=", "nn", ".", "AvgPool2d", "(", "3", ",", "avd_stride", ",", "padding", "=", "1", ")", "if", "avd_stride", ">", "0", "and", "avd_first", "else", "None", "\n", "\n", "if", "self", ".", "radix", ">=", "1", ":", "\n", "            ", "self", ".", "conv2", "=", "SplitAttn", "(", "\n", "group_width", ",", "group_width", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "first_dilation", ",", "\n", "dilation", "=", "first_dilation", ",", "groups", "=", "cardinality", ",", "radix", "=", "radix", ",", "norm_layer", "=", "norm_layer", ",", "drop_layer", "=", "drop_block", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "drop_block", "=", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "act2", "=", "nn", ".", "Identity", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "\n", "group_width", ",", "group_width", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "first_dilation", ",", "\n", "dilation", "=", "first_dilation", ",", "groups", "=", "cardinality", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "group_width", ")", "\n", "self", ".", "drop_block", "=", "drop_block", "(", ")", "if", "drop_block", "is", "not", "None", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "act2", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "", "self", ".", "avd_last", "=", "nn", ".", "AvgPool2d", "(", "3", ",", "avd_stride", ",", "padding", "=", "1", ")", "if", "avd_stride", ">", "0", "and", "not", "avd_first", "else", "None", "\n", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "group_width", ",", "planes", "*", "4", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "norm_layer", "(", "planes", "*", "4", ")", "\n", "self", ".", "act3", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest.ResNestBottleneck.zero_init_last": [[106, 108], ["torch.nn.init.zeros_"], "methods", ["None"], ["", "def", "zero_init_last", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "bn3", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest.ResNestBottleneck.forward": [[109, 136], ["resnest.ResNestBottleneck.conv1", "resnest.ResNestBottleneck.bn1", "resnest.ResNestBottleneck.act1", "resnest.ResNestBottleneck.conv2", "resnest.ResNestBottleneck.bn2", "resnest.ResNestBottleneck.drop_block", "resnest.ResNestBottleneck.act2", "resnest.ResNestBottleneck.conv3", "resnest.ResNestBottleneck.bn3", "resnest.ResNestBottleneck.act3", "resnest.ResNestBottleneck.avd_first", "resnest.ResNestBottleneck.avd_last", "resnest.ResNestBottleneck.downsample"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "act1", "(", "out", ")", "\n", "\n", "if", "self", ".", "avd_first", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "avd_first", "(", "out", ")", "\n", "\n", "", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "drop_block", "(", "out", ")", "\n", "out", "=", "self", ".", "act2", "(", "out", ")", "\n", "\n", "if", "self", ".", "avd_last", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "avd_last", "(", "out", ")", "\n", "\n", "", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "shortcut", "\n", "out", "=", "self", ".", "act3", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest._cfg": [[19, 27], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bilinear'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'conv1.0'", ",", "'classifier'", ":", "'fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest._create_resnest": [[138, 140], ["helpers.build_model_with_cfg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_resnest", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "ResNet", ",", "variant", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest.resnest14d": [[142, 151], ["dict", "resnest._create_resnest", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest._create_resnest"], ["", "@", "register_model", "\n", "def", "resnest14d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResNeSt-14d model. Weights ported from GluonCV.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "block", "=", "ResNestBottleneck", ",", "layers", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "stem_type", "=", "'deep'", ",", "stem_width", "=", "32", ",", "avg_down", "=", "True", ",", "base_width", "=", "64", ",", "cardinality", "=", "1", ",", "\n", "block_args", "=", "dict", "(", "radix", "=", "2", ",", "avd", "=", "True", ",", "avd_first", "=", "False", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnest", "(", "'resnest14d'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest.resnest26d": [[153, 162], ["dict", "resnest._create_resnest", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest._create_resnest"], ["", "@", "register_model", "\n", "def", "resnest26d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResNeSt-26d model. Weights ported from GluonCV.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "block", "=", "ResNestBottleneck", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "stem_type", "=", "'deep'", ",", "stem_width", "=", "32", ",", "avg_down", "=", "True", ",", "base_width", "=", "64", ",", "cardinality", "=", "1", ",", "\n", "block_args", "=", "dict", "(", "radix", "=", "2", ",", "avd", "=", "True", ",", "avd_first", "=", "False", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnest", "(", "'resnest26d'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest.resnest50d": [[164, 174], ["dict", "resnest._create_resnest", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest._create_resnest"], ["", "@", "register_model", "\n", "def", "resnest50d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResNeSt-50d model. Matches paper ResNeSt-50 model, https://arxiv.org/abs/2004.08955\n    Since this codebase supports all possible variations, 'd' for deep stem, stem_width 32, avg in downsample.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "block", "=", "ResNestBottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "stem_type", "=", "'deep'", ",", "stem_width", "=", "32", ",", "avg_down", "=", "True", ",", "base_width", "=", "64", ",", "cardinality", "=", "1", ",", "\n", "block_args", "=", "dict", "(", "radix", "=", "2", ",", "avd", "=", "True", ",", "avd_first", "=", "False", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnest", "(", "'resnest50d'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest.resnest101e": [[176, 186], ["dict", "resnest._create_resnest", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest._create_resnest"], ["", "@", "register_model", "\n", "def", "resnest101e", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResNeSt-101e model. Matches paper ResNeSt-101 model, https://arxiv.org/abs/2004.08955\n     Since this codebase supports all possible variations, 'e' for deep stem, stem_width 64, avg in downsample.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "block", "=", "ResNestBottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "\n", "stem_type", "=", "'deep'", ",", "stem_width", "=", "64", ",", "avg_down", "=", "True", ",", "base_width", "=", "64", ",", "cardinality", "=", "1", ",", "\n", "block_args", "=", "dict", "(", "radix", "=", "2", ",", "avd", "=", "True", ",", "avd_first", "=", "False", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnest", "(", "'resnest101e'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest.resnest200e": [[188, 198], ["dict", "resnest._create_resnest", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest._create_resnest"], ["", "@", "register_model", "\n", "def", "resnest200e", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResNeSt-200e model. Matches paper ResNeSt-200 model, https://arxiv.org/abs/2004.08955\n    Since this codebase supports all possible variations, 'e' for deep stem, stem_width 64, avg in downsample.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "block", "=", "ResNestBottleneck", ",", "layers", "=", "[", "3", ",", "24", ",", "36", ",", "3", "]", ",", "\n", "stem_type", "=", "'deep'", ",", "stem_width", "=", "64", ",", "avg_down", "=", "True", ",", "base_width", "=", "64", ",", "cardinality", "=", "1", ",", "\n", "block_args", "=", "dict", "(", "radix", "=", "2", ",", "avd", "=", "True", ",", "avd_first", "=", "False", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnest", "(", "'resnest200e'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest.resnest269e": [[200, 210], ["dict", "resnest._create_resnest", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest._create_resnest"], ["", "@", "register_model", "\n", "def", "resnest269e", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResNeSt-269e model. Matches paper ResNeSt-269 model, https://arxiv.org/abs/2004.08955\n    Since this codebase supports all possible variations, 'e' for deep stem, stem_width 64, avg in downsample.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "block", "=", "ResNestBottleneck", ",", "layers", "=", "[", "3", ",", "30", ",", "48", ",", "8", "]", ",", "\n", "stem_type", "=", "'deep'", ",", "stem_width", "=", "64", ",", "avg_down", "=", "True", ",", "base_width", "=", "64", ",", "cardinality", "=", "1", ",", "\n", "block_args", "=", "dict", "(", "radix", "=", "2", ",", "avd", "=", "True", ",", "avd_first", "=", "False", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnest", "(", "'resnest269e'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest.resnest50d_4s2x40d": [[212, 221], ["dict", "resnest._create_resnest", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest._create_resnest"], ["", "@", "register_model", "\n", "def", "resnest50d_4s2x40d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"ResNeSt-50 4s2x40d from https://github.com/zhanghang1989/ResNeSt/blob/master/ablation.md\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "block", "=", "ResNestBottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "stem_type", "=", "'deep'", ",", "stem_width", "=", "32", ",", "avg_down", "=", "True", ",", "base_width", "=", "40", ",", "cardinality", "=", "2", ",", "\n", "block_args", "=", "dict", "(", "radix", "=", "4", ",", "avd", "=", "True", ",", "avd_first", "=", "True", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnest", "(", "'resnest50d_4s2x40d'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest.resnest50d_1s4x24d": [[223, 232], ["dict", "resnest._create_resnest", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnest._create_resnest"], ["", "@", "register_model", "\n", "def", "resnest50d_1s4x24d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"ResNeSt-50 1s4x24d from https://github.com/zhanghang1989/ResNeSt/blob/master/ablation.md\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "block", "=", "ResNestBottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "stem_type", "=", "'deep'", ",", "stem_width", "=", "32", ",", "avg_down", "=", "True", ",", "base_width", "=", "24", ",", "cardinality", "=", "4", ",", "\n", "block_args", "=", "dict", "(", "radix", "=", "1", ",", "avd", "=", "True", ",", "avd_first", "=", "True", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnest", "(", "'resnest50d_1s4x24d'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.OutlookAttention.__init__": [[54, 73], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Unfold", "torch.Unfold", "torch.Unfold", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "num_heads", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "stride", "=", "1", ",", "\n", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "scale", "=", "qk_scale", "or", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn", "=", "nn", ".", "Linear", "(", "dim", ",", "kernel_size", "**", "4", "*", "num_heads", ")", "\n", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n", "self", ".", "unfold", "=", "nn", ".", "Unfold", "(", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", ",", "stride", "=", "stride", ")", "\n", "self", ".", "pool", "=", "nn", ".", "AvgPool2d", "(", "kernel_size", "=", "stride", ",", "stride", "=", "stride", ",", "ceil_mode", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.OutlookAttention.forward": [[74, 101], ["volo.OutlookAttention.v().permute", "volo.OutlookAttention.unfold().reshape().permute", "volo.OutlookAttention.pool().permute", "volo.OutlookAttention.attn().reshape().permute", "volo.OutlookAttention.softmax", "volo.OutlookAttention.attn_drop", "torch.fold", "torch.fold", "torch.fold", "volo.OutlookAttention.proj", "volo.OutlookAttention.proj_drop", "math.ceil", "math.ceil", "volo.OutlookAttention.permute", "volo.OutlookAttention.v", "volo.OutlookAttention.unfold().reshape", "volo.OutlookAttention.pool", "volo.OutlookAttention.attn().reshape", "volo.OutlookAttention.permute", "volo.OutlookAttention.unfold", "volo.OutlookAttention.attn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "H", ",", "W", ",", "C", "=", "x", ".", "shape", "\n", "\n", "v", "=", "self", ".", "v", "(", "x", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "# B, C, H, W", "\n", "\n", "h", ",", "w", "=", "math", ".", "ceil", "(", "H", "/", "self", ".", "stride", ")", ",", "math", ".", "ceil", "(", "W", "/", "self", ".", "stride", ")", "\n", "v", "=", "self", ".", "unfold", "(", "v", ")", ".", "reshape", "(", "B", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ",", "\n", "self", ".", "kernel_size", "*", "self", ".", "kernel_size", ",", "\n", "h", "*", "w", ")", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "3", ",", "2", ")", "# B,H,N,kxk,C/H", "\n", "\n", "attn", "=", "self", ".", "pool", "(", "x", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "attn", "=", "self", ".", "attn", "(", "attn", ")", ".", "reshape", "(", "\n", "B", ",", "h", "*", "w", ",", "self", ".", "num_heads", ",", "self", ".", "kernel_size", "*", "self", ".", "kernel_size", ",", "\n", "self", ".", "kernel_size", "*", "self", ".", "kernel_size", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ",", "4", ")", "# B,H,N,kxk,kxk", "\n", "attn", "=", "attn", "*", "self", ".", "scale", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "3", ",", "2", ")", ".", "reshape", "(", "\n", "B", ",", "C", "*", "self", ".", "kernel_size", "*", "self", ".", "kernel_size", ",", "h", "*", "w", ")", "\n", "x", "=", "F", ".", "fold", "(", "x", ",", "output_size", "=", "(", "H", ",", "W", ")", ",", "kernel_size", "=", "self", ".", "kernel_size", ",", "\n", "padding", "=", "self", ".", "padding", ",", "stride", "=", "self", ".", "stride", ")", "\n", "\n", "x", "=", "self", ".", "proj", "(", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.Outlooker.__init__": [[113, 133], ["torch.Module.__init__", "norm_layer", "volo.OutlookAttention", "norm_layer", "int", "volo.Mlp", "models.layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "kernel_size", ",", "padding", ",", "stride", "=", "1", ",", "\n", "num_heads", "=", "1", ",", "mlp_ratio", "=", "3.", ",", "attn_drop", "=", "0.", ",", "\n", "drop_path", "=", "0.", ",", "act_layer", "=", "nn", ".", "GELU", ",", "\n", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "qkv_bias", "=", "False", ",", "\n", "qk_scale", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn", "=", "OutlookAttention", "(", "dim", ",", "num_heads", ",", "kernel_size", "=", "kernel_size", ",", "\n", "padding", "=", "padding", ",", "stride", "=", "stride", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "qk_scale", "=", "qk_scale", ",", "\n", "attn_drop", "=", "attn_drop", ")", "\n", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "\n", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "mlp_hidden_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "in_features", "=", "dim", ",", "\n", "hidden_features", "=", "mlp_hidden_dim", ",", "\n", "act_layer", "=", "act_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.Outlooker.forward": [[134, 138], ["volo.Outlooker.drop_path", "volo.Outlooker.drop_path", "volo.Outlooker.attn", "volo.Outlooker.mlp", "volo.Outlooker.norm1", "volo.Outlooker.norm2"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "attn", "(", "self", ".", "norm1", "(", "x", ")", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.Mlp.__init__": [[143, 153], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "act_layer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "hidden_features", "=", "None", ",", "\n", "out_features", "=", "None", ",", "act_layer", "=", "nn", ".", "GELU", ",", "\n", "drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "out_features", "=", "out_features", "or", "in_features", "\n", "hidden_features", "=", "hidden_features", "or", "in_features", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_features", ",", "hidden_features", ")", "\n", "self", ".", "act", "=", "act_layer", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_features", ",", "out_features", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.Mlp.forward": [[154, 161], ["volo.Mlp.fc1", "volo.Mlp.act", "volo.Mlp.drop", "volo.Mlp.fc2", "volo.Mlp.drop"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.Attention.__init__": [[166, 177], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "qkv_bias", "=", "False", ",", "\n", "qk_scale", "=", "None", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "self", ".", "scale", "=", "qk_scale", "or", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", "*", "3", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.Attention.forward": [[178, 195], ["volo.Attention.qkv().reshape().permute", "volo.Attention.softmax", "volo.Attention.attn_drop", "volo.Attention.proj", "volo.Attention.proj_drop", "volo.Attention.qkv().reshape", "k.transpose", "volo.Attention.qkv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "H", ",", "W", ",", "C", "=", "x", ".", "shape", "\n", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "B", ",", "H", "*", "W", ",", "3", ",", "self", ".", "num_heads", ",", "\n", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", "[", "0", "]", ",", "qkv", "[", "1", "]", ",", "qkv", "[", "\n", "2", "]", "# make torchscript happy (cannot use tensor as tuple)", "\n", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "*", "self", ".", "scale", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "H", ",", "W", ",", "C", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.Transformer.__init__": [[202, 219], ["torch.Module.__init__", "norm_layer", "volo.Attention", "norm_layer", "int", "volo.Mlp", "models.layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "num_heads", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "\n", "qk_scale", "=", "None", ",", "attn_drop", "=", "0.", ",", "drop_path", "=", "0.", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "dim", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "qk_scale", "=", "qk_scale", ",", "attn_drop", "=", "attn_drop", ")", "\n", "\n", "# NOTE: drop path for stochastic depth, we shall see if this is better than dropout here", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "\n", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "mlp_hidden_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "in_features", "=", "dim", ",", "\n", "hidden_features", "=", "mlp_hidden_dim", ",", "\n", "act_layer", "=", "act_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.Transformer.forward": [[220, 224], ["volo.Transformer.drop_path", "volo.Transformer.drop_path", "volo.Transformer.attn", "volo.Transformer.mlp", "volo.Transformer.norm1", "volo.Transformer.norm2"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "attn", "(", "self", ".", "norm1", "(", "x", ")", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.ClassAttention.__init__": [[231, 249], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "head_dim", "=", "None", ",", "qkv_bias", "=", "False", ",", "\n", "qk_scale", "=", "None", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "if", "head_dim", "is", "not", "None", ":", "\n", "            ", "self", ".", "head_dim", "=", "head_dim", "\n", "", "else", ":", "\n", "            ", "head_dim", "=", "dim", "//", "num_heads", "\n", "self", ".", "head_dim", "=", "head_dim", "\n", "", "self", ".", "scale", "=", "qk_scale", "or", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "kv", "=", "nn", ".", "Linear", "(", "dim", ",", "\n", "self", ".", "head_dim", "*", "self", ".", "num_heads", "*", "2", ",", "\n", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "q", "=", "nn", ".", "Linear", "(", "dim", ",", "self", ".", "head_dim", "*", "self", ".", "num_heads", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "self", ".", "head_dim", "*", "self", ".", "num_heads", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.ClassAttention.forward": [[250, 267], ["volo.ClassAttention.kv().reshape().permute", "volo.ClassAttention.q().reshape", "volo.ClassAttention.softmax", "volo.ClassAttention.attn_drop", "volo.ClassAttention.proj", "volo.ClassAttention.proj_drop", "k.transpose", "volo.ClassAttention.kv().reshape", "volo.ClassAttention.q", "volo.ClassAttention.kv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "\n", "kv", "=", "self", ".", "kv", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "2", ",", "self", ".", "num_heads", ",", "\n", "self", ".", "head_dim", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "k", ",", "v", "=", "kv", "[", "0", "]", ",", "kv", "[", "\n", "1", "]", "# make torchscript happy (cannot use tensor as tuple)", "\n", "q", "=", "self", ".", "q", "(", "x", "[", ":", ",", ":", "1", ",", ":", "]", ")", ".", "reshape", "(", "B", ",", "self", ".", "num_heads", ",", "1", ",", "self", ".", "head_dim", ")", "\n", "attn", "=", "(", "(", "q", "*", "self", ".", "scale", ")", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "cls_embed", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "\n", "B", ",", "1", ",", "self", ".", "head_dim", "*", "self", ".", "num_heads", ")", "\n", "cls_embed", "=", "self", ".", "proj", "(", "cls_embed", ")", "\n", "cls_embed", "=", "self", ".", "proj_drop", "(", "cls_embed", ")", "\n", "return", "cls_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.ClassBlock.__init__": [[275, 292], ["torch.Module.__init__", "norm_layer", "volo.ClassAttention", "norm_layer", "int", "volo.Mlp", "models.layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "num_heads", ",", "head_dim", "=", "None", ",", "mlp_ratio", "=", "4.", ",", "\n", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "\n", "drop_path", "=", "0.", ",", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn", "=", "ClassAttention", "(", "\n", "dim", ",", "num_heads", "=", "num_heads", ",", "head_dim", "=", "head_dim", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "qk_scale", "=", "qk_scale", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ")", "\n", "# NOTE: drop path for stochastic depth", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "\n", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "mlp_hidden_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "in_features", "=", "dim", ",", "\n", "hidden_features", "=", "mlp_hidden_dim", ",", "\n", "act_layer", "=", "act_layer", ",", "\n", "drop", "=", "drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.ClassBlock.forward": [[293, 298], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "volo.ClassBlock.drop_path", "volo.ClassBlock.drop_path", "volo.ClassBlock.attn", "volo.ClassBlock.mlp", "volo.ClassBlock.norm1", "volo.ClassBlock.norm2"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "cls_embed", "=", "x", "[", ":", ",", ":", "1", "]", "\n", "cls_embed", "=", "cls_embed", "+", "self", ".", "drop_path", "(", "self", ".", "attn", "(", "self", ".", "norm1", "(", "x", ")", ")", ")", "\n", "cls_embed", "=", "cls_embed", "+", "self", ".", "drop_path", "(", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "cls_embed", ")", ")", ")", "\n", "return", "torch", ".", "cat", "(", "[", "cls_embed", ",", "x", "[", ":", ",", "1", ":", "]", "]", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.PatchEmbed.__init__": [[337, 364], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "img_size", "=", "224", ",", "stem_conv", "=", "False", ",", "stem_stride", "=", "1", ",", "\n", "patch_size", "=", "8", ",", "in_chans", "=", "3", ",", "hidden_dim", "=", "64", ",", "embed_dim", "=", "384", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "patch_size", "in", "[", "4", ",", "8", ",", "16", "]", "\n", "\n", "self", ".", "stem_conv", "=", "stem_conv", "\n", "if", "stem_conv", ":", "\n", "            ", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_chans", ",", "hidden_dim", ",", "kernel_size", "=", "7", ",", "stride", "=", "stem_stride", ",", "\n", "padding", "=", "3", ",", "bias", "=", "False", ")", ",", "# 112x112", "\n", "nn", ".", "BatchNorm2d", "(", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "hidden_dim", ",", "hidden_dim", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "# 112x112", "\n", "nn", ".", "BatchNorm2d", "(", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "hidden_dim", ",", "hidden_dim", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "# 112x112", "\n", "nn", ".", "BatchNorm2d", "(", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", ")", "\n", "\n", "", "self", ".", "proj", "=", "nn", ".", "Conv2d", "(", "hidden_dim", ",", "\n", "embed_dim", ",", "\n", "kernel_size", "=", "patch_size", "//", "stem_stride", ",", "\n", "stride", "=", "patch_size", "//", "stem_stride", ")", "\n", "self", ".", "num_patches", "=", "(", "img_size", "//", "patch_size", ")", "*", "(", "img_size", "//", "patch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.PatchEmbed.forward": [[365, 370], ["volo.PatchEmbed.proj", "volo.PatchEmbed.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "stem_conv", ":", "\n", "            ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "", "x", "=", "self", ".", "proj", "(", "x", ")", "# B, C, H, W", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.Downsample.__init__": [[376, 380], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "in_embed_dim", ",", "out_embed_dim", ",", "patch_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Conv2d", "(", "in_embed_dim", ",", "out_embed_dim", ",", "\n", "kernel_size", "=", "patch_size", ",", "stride", "=", "patch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.Downsample.forward": [[381, 386], ["x.permute.permute.permute", "volo.Downsample.proj", "x.permute.permute.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "# B, C, H, W", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.VOLO.__init__": [[458, 547], ["torch.Module.__init__", "volo.PatchEmbed", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Dropout", "torch.Dropout", "torch.Dropout", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "norm_layer", "models.layers.trunc_normal_", "volo.VOLO.apply", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Parameter", "torch.Parameter", "torch.Parameter", "models.layers.trunc_normal_", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "volo.outlooker_blocks", "network.append", "volo.transformer_blocks", "network.append", "network.append", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "volo.Downsample", "volo.get_block", "range", "len"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.outlooker_blocks", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.transformer_blocks", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.get_block"], ["def", "__init__", "(", "self", ",", "layers", ",", "img_size", "=", "224", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "patch_size", "=", "8", ",", "\n", "stem_hidden_dim", "=", "64", ",", "embed_dims", "=", "None", ",", "num_heads", "=", "None", ",", "downsamples", "=", "None", ",", "\n", "outlook_attention", "=", "None", ",", "mlp_ratios", "=", "None", ",", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "\n", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "\n", "post_layers", "=", "None", ",", "return_mean", "=", "False", ",", "return_dense", "=", "True", ",", "mix_token", "=", "True", ",", "\n", "pooling_scale", "=", "2", ",", "out_kernel", "=", "3", ",", "out_stride", "=", "2", ",", "out_padding", "=", "1", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "patch_embed", "=", "PatchEmbed", "(", "stem_conv", "=", "True", ",", "stem_stride", "=", "2", ",", "patch_size", "=", "patch_size", ",", "\n", "in_chans", "=", "in_chans", ",", "hidden_dim", "=", "stem_hidden_dim", ",", "\n", "embed_dim", "=", "embed_dims", "[", "0", "]", ")", "\n", "\n", "# inital positional encoding, we add positional encoding after outlooker blocks", "\n", "self", ".", "pos_embed", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "1", ",", "img_size", "//", "patch_size", "//", "pooling_scale", ",", "\n", "img_size", "//", "patch_size", "//", "pooling_scale", ",", "\n", "embed_dims", "[", "-", "1", "]", ")", ")", "\n", "\n", "self", ".", "pos_drop", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", "\n", "\n", "# set the main block in network", "\n", "network", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "layers", ")", ")", ":", "\n", "            ", "if", "outlook_attention", "[", "i", "]", ":", "\n", "# stage 1", "\n", "                ", "stage", "=", "outlooker_blocks", "(", "Outlooker", ",", "i", ",", "embed_dims", "[", "i", "]", ",", "layers", ",", "\n", "downsample", "=", "downsamples", "[", "i", "]", ",", "num_heads", "=", "num_heads", "[", "i", "]", ",", "\n", "kernel_size", "=", "out_kernel", ",", "stride", "=", "out_stride", ",", "\n", "padding", "=", "out_padding", ",", "mlp_ratio", "=", "mlp_ratios", "[", "i", "]", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "qk_scale", "=", "qk_scale", ",", "\n", "attn_drop", "=", "attn_drop_rate", ",", "norm_layer", "=", "norm_layer", ")", "\n", "network", ".", "append", "(", "stage", ")", "\n", "", "else", ":", "\n", "# stage 2", "\n", "                ", "stage", "=", "transformer_blocks", "(", "Transformer", ",", "i", ",", "embed_dims", "[", "i", "]", ",", "layers", ",", "\n", "num_heads", "[", "i", "]", ",", "mlp_ratio", "=", "mlp_ratios", "[", "i", "]", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "qk_scale", "=", "qk_scale", ",", "\n", "drop_path_rate", "=", "drop_path_rate", ",", "\n", "attn_drop", "=", "attn_drop_rate", ",", "\n", "norm_layer", "=", "norm_layer", ")", "\n", "network", ".", "append", "(", "stage", ")", "\n", "\n", "", "if", "downsamples", "[", "i", "]", ":", "\n", "# downsampling between two stages", "\n", "                ", "network", ".", "append", "(", "Downsample", "(", "embed_dims", "[", "i", "]", ",", "embed_dims", "[", "i", "+", "1", "]", ",", "2", ")", ")", "\n", "\n", "", "", "self", ".", "network", "=", "nn", ".", "ModuleList", "(", "network", ")", "\n", "\n", "# set post block, for example, class attention layers", "\n", "self", ".", "post_network", "=", "None", "\n", "if", "post_layers", "is", "not", "None", ":", "\n", "            ", "self", ".", "post_network", "=", "nn", ".", "ModuleList", "(", "[", "\n", "get_block", "(", "post_layers", "[", "i", "]", ",", "\n", "dim", "=", "embed_dims", "[", "-", "1", "]", ",", "\n", "num_heads", "=", "num_heads", "[", "-", "1", "]", ",", "\n", "mlp_ratio", "=", "mlp_ratios", "[", "-", "1", "]", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "\n", "qk_scale", "=", "qk_scale", ",", "\n", "attn_drop", "=", "attn_drop_rate", ",", "\n", "drop_path", "=", "0.", ",", "\n", "norm_layer", "=", "norm_layer", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "post_layers", ")", ")", "\n", "]", ")", "\n", "self", ".", "cls_token", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "embed_dims", "[", "-", "1", "]", ")", ")", "\n", "trunc_normal_", "(", "self", ".", "cls_token", ",", "std", "=", ".02", ")", "\n", "\n", "# set output type", "\n", "", "self", ".", "return_mean", "=", "return_mean", "# if yes, return mean, not use class token", "\n", "self", ".", "return_dense", "=", "return_dense", "# if yes, return class token and all feature tokens", "\n", "if", "return_dense", ":", "\n", "            ", "assert", "not", "return_mean", ",", "\"cannot return both mean and dense\"", "\n", "", "self", ".", "mix_token", "=", "mix_token", "\n", "self", ".", "pooling_scale", "=", "pooling_scale", "\n", "if", "mix_token", ":", "# enable token mixing, see token labeling for details.", "\n", "            ", "self", ".", "beta", "=", "1.0", "\n", "assert", "return_dense", ",", "\"return all tokens if mix_token is enabled\"", "\n", "", "if", "return_dense", ":", "\n", "            ", "self", ".", "aux_head", "=", "nn", ".", "Linear", "(", "\n", "embed_dims", "[", "-", "1", "]", ",", "\n", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "", "self", ".", "norm", "=", "norm_layer", "(", "embed_dims", "[", "-", "1", "]", ")", "\n", "\n", "# Classifier head", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "\n", "embed_dims", "[", "-", "1", "]", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "trunc_normal_", "(", "self", ".", "pos_embed", ",", "std", "=", ".02", ")", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.VOLO._init_weights": [[548, 556], ["isinstance", "models.layers.trunc_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", ".02", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.VOLO.no_weight_decay": [[557, 560], ["None"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "{", "'pos_embed'", ",", "'cls_token'", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.VOLO.get_classifier": [[561, 563], ["None"], "methods", ["None"], ["", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.VOLO.reset_classifier": [[564, 568], ["torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "\n", "self", ".", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.VOLO.forward_embeddings": [[569, 575], ["volo.VOLO.patch_embed", "x.permute.permute.permute"], "methods", ["None"], ["", "def", "forward_embeddings", "(", "self", ",", "x", ")", ":", "\n", "# patch embedding", "\n", "        ", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "# B,C,H,W-> B,H,W,C", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.VOLO.forward_tokens": [[576, 586], ["enumerate", "volo.VOLO.reshape", "block", "volo.VOLO.pos_drop"], "methods", ["None"], ["", "def", "forward_tokens", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "idx", ",", "block", "in", "enumerate", "(", "self", ".", "network", ")", ":", "\n", "            ", "if", "idx", "==", "2", ":", "# add positional encoding after outlooker blocks", "\n", "                ", "x", "=", "x", "+", "self", ".", "pos_embed", "\n", "x", "=", "self", ".", "pos_drop", "(", "x", ")", "\n", "", "x", "=", "block", "(", "x", ")", "\n", "\n", "", "B", ",", "H", ",", "W", ",", "C", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "-", "1", ",", "C", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.VOLO.forward_cls": [[587, 594], ["volo.VOLO.cls_token.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "block"], "methods", ["None"], ["", "def", "forward_cls", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "cls_tokens", "=", "self", ".", "cls_token", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "cls_tokens", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "for", "block", "in", "self", ".", "post_network", ":", "\n", "            ", "x", "=", "block", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.VOLO.forward": [[595, 646], ["volo.VOLO.forward_embeddings", "volo.VOLO.forward_tokens", "volo.VOLO.norm", "volo.VOLO.head", "volo.VOLO.aux_head", "numpy.random.beta", "volo.rand_bbox", "volo.VOLO.clone", "volo.VOLO.forward_cls", "volo.VOLO.head", "x_aux.reshape.reshape.reshape", "x_aux.reshape.reshape.clone", "x_aux.reshape.reshape.reshape", "volo.VOLO.size", "volo.VOLO.flip", "volo.VOLO.mean", "x_aux.reshape.reshape.flip", "x_aux.reshape.reshape.max"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.VOLO.forward_embeddings", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.VOLO.forward_tokens", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.rand_bbox", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.VOLO.forward_cls"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# step1: patch embedding", "\n", "        ", "x", "=", "self", ".", "forward_embeddings", "(", "x", ")", "\n", "\n", "# mix token, see token labeling for details.", "\n", "if", "self", ".", "mix_token", "and", "self", ".", "training", ":", "\n", "            ", "lam", "=", "np", ".", "random", ".", "beta", "(", "self", ".", "beta", ",", "self", ".", "beta", ")", "\n", "patch_h", ",", "patch_w", "=", "x", ".", "shape", "[", "1", "]", "//", "self", ".", "pooling_scale", ",", "x", ".", "shape", "[", "\n", "2", "]", "//", "self", ".", "pooling_scale", "\n", "bbx1", ",", "bby1", ",", "bbx2", ",", "bby2", "=", "rand_bbox", "(", "x", ".", "size", "(", ")", ",", "lam", ",", "scale", "=", "self", ".", "pooling_scale", ")", "\n", "temp_x", "=", "x", ".", "clone", "(", ")", "\n", "sbbx1", ",", "sbby1", ",", "sbbx2", ",", "sbby2", "=", "self", ".", "pooling_scale", "*", "bbx1", ",", "self", ".", "pooling_scale", "*", "bby1", ",", "self", ".", "pooling_scale", "*", "bbx2", ",", "self", ".", "pooling_scale", "*", "bby2", "\n", "temp_x", "[", ":", ",", "sbbx1", ":", "sbbx2", ",", "sbby1", ":", "sbby2", ",", ":", "]", "=", "x", ".", "flip", "(", "0", ")", "[", ":", ",", "sbbx1", ":", "sbbx2", ",", "sbby1", ":", "sbby2", ",", ":", "]", "\n", "x", "=", "temp_x", "\n", "", "else", ":", "\n", "            ", "bbx1", ",", "bby1", ",", "bbx2", ",", "bby2", "=", "0", ",", "0", ",", "0", ",", "0", "\n", "\n", "# step2: tokens learning in the two stages", "\n", "", "x", "=", "self", ".", "forward_tokens", "(", "x", ")", "\n", "\n", "# step3: post network, apply class attention or not", "\n", "if", "self", ".", "post_network", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "forward_cls", "(", "x", ")", "\n", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "\n", "if", "self", ".", "return_mean", ":", "# if no class token, return mean", "\n", "            ", "return", "self", ".", "head", "(", "x", ".", "mean", "(", "1", ")", ")", "\n", "\n", "", "x_cls", "=", "self", ".", "head", "(", "x", "[", ":", ",", "0", "]", ")", "\n", "if", "not", "self", ".", "return_dense", ":", "\n", "            ", "return", "x_cls", "\n", "\n", "", "x_aux", "=", "self", ".", "aux_head", "(", "\n", "x", "[", ":", ",", "1", ":", "]", "\n", ")", "# generate classes in all feature tokens, see token labeling", "\n", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "return", "x_cls", "+", "0.5", "*", "x_aux", ".", "max", "(", "1", ")", "[", "0", "]", "\n", "\n", "", "if", "self", ".", "mix_token", "and", "self", ".", "training", ":", "# reverse \"mix token\", see token labeling for details.", "\n", "            ", "x_aux", "=", "x_aux", ".", "reshape", "(", "x_aux", ".", "shape", "[", "0", "]", ",", "patch_h", ",", "patch_w", ",", "x_aux", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "temp_x", "=", "x_aux", ".", "clone", "(", ")", "\n", "temp_x", "[", ":", ",", "bbx1", ":", "bbx2", ",", "bby1", ":", "bby2", ",", ":", "]", "=", "x_aux", ".", "flip", "(", "0", ")", "[", ":", ",", "bbx1", ":", "bbx2", ",", "bby1", ":", "bby2", ",", ":", "]", "\n", "x_aux", "=", "temp_x", "\n", "\n", "x_aux", "=", "x_aux", ".", "reshape", "(", "x_aux", ".", "shape", "[", "0", "]", ",", "patch_h", "*", "patch_w", ",", "x_aux", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "# return these: 1. class token, 2. classes from all feature tokens, 3. bounding box", "\n", "", "return", "x_cls", ",", "x_aux", ",", "(", "bbx1", ",", "bby1", ",", "bbx2", ",", "bby2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo._cfg": [[28, 36], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", ".96", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'patch_embed.proj'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.get_block": [[300, 306], ["volo.ClassBlock"], "function", ["None"], ["", "", "def", "get_block", "(", "block_type", ",", "**", "kargs", ")", ":", "\n", "    ", "\"\"\"\n    get block by name, specifically for class attention block in here\n    \"\"\"", "\n", "if", "block_type", "==", "'ca'", ":", "\n", "        ", "return", "ClassBlock", "(", "**", "kargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.rand_bbox": [[308, 329], ["numpy.sqrt", "numpy.int", "numpy.int", "numpy.random.randint", "numpy.random.randint", "numpy.clip", "numpy.clip", "numpy.clip", "numpy.clip"], "function", ["None"], ["", "", "def", "rand_bbox", "(", "size", ",", "lam", ",", "scale", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    get bounding box as token labeling (https://github.com/zihangJiang/TokenLabeling)\n    return: bounding box\n    \"\"\"", "\n", "W", "=", "size", "[", "1", "]", "//", "scale", "\n", "H", "=", "size", "[", "2", "]", "//", "scale", "\n", "cut_rat", "=", "np", ".", "sqrt", "(", "1.", "-", "lam", ")", "\n", "cut_w", "=", "np", ".", "int", "(", "W", "*", "cut_rat", ")", "\n", "cut_h", "=", "np", ".", "int", "(", "H", "*", "cut_rat", ")", "\n", "\n", "# uniform", "\n", "cx", "=", "np", ".", "random", ".", "randint", "(", "W", ")", "\n", "cy", "=", "np", ".", "random", ".", "randint", "(", "H", ")", "\n", "\n", "bbx1", "=", "np", ".", "clip", "(", "cx", "-", "cut_w", "//", "2", ",", "0", ",", "W", ")", "\n", "bby1", "=", "np", ".", "clip", "(", "cy", "-", "cut_h", "//", "2", ",", "0", ",", "H", ")", "\n", "bbx2", "=", "np", ".", "clip", "(", "cx", "+", "cut_w", "//", "2", ",", "0", ",", "W", ")", "\n", "bby2", "=", "np", ".", "clip", "(", "cy", "+", "cut_h", "//", "2", ",", "0", ",", "H", ")", "\n", "\n", "return", "bbx1", ",", "bby1", ",", "bbx2", ",", "bby2", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.outlooker_blocks": [[388, 407], ["range", "torch.Sequential", "nn.Sequential.append", "block_fn", "sum", "sum"], "function", ["None"], ["", "", "def", "outlooker_blocks", "(", "block_fn", ",", "index", ",", "dim", ",", "layers", ",", "num_heads", "=", "1", ",", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "stride", "=", "1", ",", "mlp_ratio", "=", "3.", ",", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "\n", "attn_drop", "=", "0", ",", "drop_path_rate", "=", "0.", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    generate outlooker layer in stage1\n    return: outlooker layers\n    \"\"\"", "\n", "blocks", "=", "[", "]", "\n", "for", "block_idx", "in", "range", "(", "layers", "[", "index", "]", ")", ":", "\n", "        ", "block_dpr", "=", "drop_path_rate", "*", "(", "block_idx", "+", "\n", "sum", "(", "layers", "[", ":", "index", "]", ")", ")", "/", "(", "sum", "(", "layers", ")", "-", "1", ")", "\n", "blocks", ".", "append", "(", "block_fn", "(", "dim", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", ",", "\n", "stride", "=", "stride", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "qk_scale", "=", "qk_scale", ",", "attn_drop", "=", "attn_drop", ",", "\n", "drop_path", "=", "block_dpr", ")", ")", "\n", "\n", "", "blocks", "=", "nn", ".", "Sequential", "(", "*", "blocks", ")", "\n", "\n", "return", "blocks", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.transformer_blocks": [[409, 431], ["range", "torch.Sequential", "nn.Sequential.append", "block_fn", "sum", "sum"], "function", ["None"], ["", "def", "transformer_blocks", "(", "block_fn", ",", "index", ",", "dim", ",", "layers", ",", "num_heads", ",", "mlp_ratio", "=", "3.", ",", "\n", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "attn_drop", "=", "0", ",", "\n", "drop_path_rate", "=", "0.", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    generate transformer layers in stage2\n    return: transformer layers\n    \"\"\"", "\n", "blocks", "=", "[", "]", "\n", "for", "block_idx", "in", "range", "(", "layers", "[", "index", "]", ")", ":", "\n", "        ", "block_dpr", "=", "drop_path_rate", "*", "(", "block_idx", "+", "\n", "sum", "(", "layers", "[", ":", "index", "]", ")", ")", "/", "(", "sum", "(", "layers", ")", "-", "1", ")", "\n", "blocks", ".", "append", "(", "\n", "block_fn", "(", "dim", ",", "num_heads", ",", "\n", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "\n", "qk_scale", "=", "qk_scale", ",", "\n", "attn_drop", "=", "attn_drop", ",", "\n", "drop_path", "=", "block_dpr", ")", ")", "\n", "\n", "", "blocks", "=", "nn", ".", "Sequential", "(", "*", "blocks", ")", "\n", "\n", "return", "blocks", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.volo_d1": [[648, 679], ["volo.VOLO"], "function", ["None"], ["", "", "@", "register_model", "\n", "def", "volo_d1", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    VOLO-D1 model, Params: 27M\n    --layers: [x,x,x,x], four blocks in two stages, the first stage(block) is outlooker,\n            the other three blocks are transformer, we set four blocks, which are easily\n             applied to downstream tasks\n    --embed_dims, --num_heads,: embedding dim, number of heads in each block\n    --downsamples: flags to apply downsampling or not in four blocks\n    --outlook_attention: flags to apply outlook attention or not\n    --mlp_ratios: mlp ratio in four blocks\n    --post_layers: post layers like two class attention layers using [ca, ca]\n    See detail for all args in the class VOLO()\n    \"\"\"", "\n", "layers", "=", "[", "4", ",", "4", ",", "8", ",", "2", "]", "# num of layers in the four blocks", "\n", "embed_dims", "=", "[", "192", ",", "384", ",", "384", ",", "384", "]", "\n", "num_heads", "=", "[", "6", ",", "12", ",", "12", ",", "12", "]", "\n", "mlp_ratios", "=", "[", "3", ",", "3", ",", "3", ",", "3", "]", "\n", "downsamples", "=", "[", "True", ",", "False", ",", "False", ",", "False", "]", "# do downsampling after first block", "\n", "outlook_attention", "=", "[", "True", ",", "False", ",", "False", ",", "False", "]", "\n", "# first block is outlooker (stage1), the other three are transformer (stage2)", "\n", "model", "=", "VOLO", "(", "layers", ",", "\n", "embed_dims", "=", "embed_dims", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "mlp_ratios", "=", "mlp_ratios", ",", "\n", "downsamples", "=", "downsamples", ",", "\n", "outlook_attention", "=", "outlook_attention", ",", "\n", "post_layers", "=", "[", "'ca'", ",", "'ca'", "]", ",", "\n", "**", "kwargs", ")", "\n", "model", ".", "default_cfg", "=", "default_cfgs", "[", "'volo'", "]", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.volo_d2": [[681, 702], ["volo.VOLO"], "function", ["None"], ["", "@", "register_model", "\n", "def", "volo_d2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    VOLO-D2 model, Params: 59M\n    \"\"\"", "\n", "layers", "=", "[", "6", ",", "4", ",", "10", ",", "4", "]", "\n", "embed_dims", "=", "[", "256", ",", "512", ",", "512", ",", "512", "]", "\n", "num_heads", "=", "[", "8", ",", "16", ",", "16", ",", "16", "]", "\n", "mlp_ratios", "=", "[", "3", ",", "3", ",", "3", ",", "3", "]", "\n", "downsamples", "=", "[", "True", ",", "False", ",", "False", ",", "False", "]", "\n", "outlook_attention", "=", "[", "True", ",", "False", ",", "False", ",", "False", "]", "\n", "model", "=", "VOLO", "(", "layers", ",", "\n", "embed_dims", "=", "embed_dims", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "mlp_ratios", "=", "mlp_ratios", ",", "\n", "downsamples", "=", "downsamples", ",", "\n", "outlook_attention", "=", "outlook_attention", ",", "\n", "post_layers", "=", "[", "'ca'", ",", "'ca'", "]", ",", "\n", "**", "kwargs", ")", "\n", "model", ".", "default_cfg", "=", "default_cfgs", "[", "'volo'", "]", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.volo_d3": [[704, 725], ["volo.VOLO"], "function", ["None"], ["", "@", "register_model", "\n", "def", "volo_d3", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    VOLO-D3 model, Params: 86M\n    \"\"\"", "\n", "layers", "=", "[", "8", ",", "8", ",", "16", ",", "4", "]", "\n", "embed_dims", "=", "[", "256", ",", "512", ",", "512", ",", "512", "]", "\n", "num_heads", "=", "[", "8", ",", "16", ",", "16", ",", "16", "]", "\n", "mlp_ratios", "=", "[", "3", ",", "3", ",", "3", ",", "3", "]", "\n", "downsamples", "=", "[", "True", ",", "False", ",", "False", ",", "False", "]", "\n", "outlook_attention", "=", "[", "True", ",", "False", ",", "False", ",", "False", "]", "\n", "model", "=", "VOLO", "(", "layers", ",", "\n", "embed_dims", "=", "embed_dims", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "mlp_ratios", "=", "mlp_ratios", ",", "\n", "downsamples", "=", "downsamples", ",", "\n", "outlook_attention", "=", "outlook_attention", ",", "\n", "post_layers", "=", "[", "'ca'", ",", "'ca'", "]", ",", "\n", "**", "kwargs", ")", "\n", "model", ".", "default_cfg", "=", "default_cfgs", "[", "'volo'", "]", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.volo_d4": [[727, 748], ["volo.VOLO"], "function", ["None"], ["", "@", "register_model", "\n", "def", "volo_d4", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    VOLO-D4 model, Params: 193M\n    \"\"\"", "\n", "layers", "=", "[", "8", ",", "8", ",", "16", ",", "4", "]", "\n", "embed_dims", "=", "[", "384", ",", "768", ",", "768", ",", "768", "]", "\n", "num_heads", "=", "[", "12", ",", "16", ",", "16", ",", "16", "]", "\n", "mlp_ratios", "=", "[", "3", ",", "3", ",", "3", ",", "3", "]", "\n", "downsamples", "=", "[", "True", ",", "False", ",", "False", ",", "False", "]", "\n", "outlook_attention", "=", "[", "True", ",", "False", ",", "False", ",", "False", "]", "\n", "model", "=", "VOLO", "(", "layers", ",", "\n", "embed_dims", "=", "embed_dims", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "mlp_ratios", "=", "mlp_ratios", ",", "\n", "downsamples", "=", "downsamples", ",", "\n", "outlook_attention", "=", "outlook_attention", ",", "\n", "post_layers", "=", "[", "'ca'", ",", "'ca'", "]", ",", "\n", "**", "kwargs", ")", "\n", "model", ".", "default_cfg", "=", "default_cfgs", "[", "'volo_large'", "]", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.volo.volo_d5": [[750, 773], ["volo.VOLO"], "function", ["None"], ["", "@", "register_model", "\n", "def", "volo_d5", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    VOLO-D5 model, Params: 296M\n    stem_hidden_dim=128, the dim in patch embedding is 128 for VOLO-D5\n    \"\"\"", "\n", "layers", "=", "[", "12", ",", "12", ",", "20", ",", "4", "]", "\n", "embed_dims", "=", "[", "384", ",", "768", ",", "768", ",", "768", "]", "\n", "num_heads", "=", "[", "12", ",", "16", ",", "16", ",", "16", "]", "\n", "mlp_ratios", "=", "[", "4", ",", "4", ",", "4", ",", "4", "]", "\n", "downsamples", "=", "[", "True", ",", "False", ",", "False", ",", "False", "]", "\n", "outlook_attention", "=", "[", "True", ",", "False", ",", "False", ",", "False", "]", "\n", "model", "=", "VOLO", "(", "layers", ",", "\n", "embed_dims", "=", "embed_dims", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "mlp_ratios", "=", "mlp_ratios", ",", "\n", "downsamples", "=", "downsamples", ",", "\n", "outlook_attention", "=", "outlook_attention", ",", "\n", "post_layers", "=", "[", "'ca'", ",", "'ca'", "]", ",", "\n", "stem_hidden_dim", "=", "128", ",", "\n", "**", "kwargs", ")", "\n", "model", ".", "default_cfg", "=", "default_cfgs", "[", "'volo_large'", "]", "\n", "return", "model", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionModule.__init__": [[389, 405], ["torch.Module.__init__", "hrnet.HighResolutionModule._check_branches", "hrnet.HighResolutionModule._make_branches", "hrnet.HighResolutionModule._make_fuse_layers", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionModule._check_branches", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionModule._make_branches", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionModule._make_fuse_layers"], ["    ", "def", "__init__", "(", "self", ",", "num_branches", ",", "blocks", ",", "num_blocks", ",", "num_in_chs", ",", "\n", "num_channels", ",", "fuse_method", ",", "multi_scale_output", "=", "True", ")", ":", "\n", "        ", "super", "(", "HighResolutionModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_check_branches", "(", "\n", "num_branches", ",", "blocks", ",", "num_blocks", ",", "num_in_chs", ",", "num_channels", ")", "\n", "\n", "self", ".", "num_in_chs", "=", "num_in_chs", "\n", "self", ".", "fuse_method", "=", "fuse_method", "\n", "self", ".", "num_branches", "=", "num_branches", "\n", "\n", "self", ".", "multi_scale_output", "=", "multi_scale_output", "\n", "\n", "self", ".", "branches", "=", "self", ".", "_make_branches", "(", "\n", "num_branches", ",", "blocks", ",", "num_blocks", ",", "num_channels", ")", "\n", "self", ".", "fuse_layers", "=", "self", ".", "_make_fuse_layers", "(", ")", "\n", "self", ".", "fuse_act", "=", "nn", ".", "ReLU", "(", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionModule._check_branches": [[406, 417], ["len", "_logger.error", "ValueError", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "_check_branches", "(", "self", ",", "num_branches", ",", "blocks", ",", "num_blocks", ",", "num_in_chs", ",", "num_channels", ")", ":", "\n", "        ", "error_msg", "=", "''", "\n", "if", "num_branches", "!=", "len", "(", "num_blocks", ")", ":", "\n", "            ", "error_msg", "=", "'NUM_BRANCHES({}) <> NUM_BLOCKS({})'", ".", "format", "(", "num_branches", ",", "len", "(", "num_blocks", ")", ")", "\n", "", "elif", "num_branches", "!=", "len", "(", "num_channels", ")", ":", "\n", "            ", "error_msg", "=", "'NUM_BRANCHES({}) <> NUM_CHANNELS({})'", ".", "format", "(", "num_branches", ",", "len", "(", "num_channels", ")", ")", "\n", "", "elif", "num_branches", "!=", "len", "(", "num_in_chs", ")", ":", "\n", "            ", "error_msg", "=", "'NUM_BRANCHES({}) <> num_in_chs({})'", ".", "format", "(", "num_branches", ",", "len", "(", "num_in_chs", ")", ")", "\n", "", "if", "error_msg", ":", "\n", "            ", "_logger", ".", "error", "(", "error_msg", ")", "\n", "raise", "ValueError", "(", "error_msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionModule._make_one_branch": [[418, 434], ["range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "", "def", "_make_one_branch", "(", "self", ",", "branch_index", ",", "block", ",", "num_blocks", ",", "num_channels", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "num_in_chs", "[", "branch_index", "]", "!=", "num_channels", "[", "branch_index", "]", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "self", ".", "num_in_chs", "[", "branch_index", "]", ",", "num_channels", "[", "branch_index", "]", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "num_channels", "[", "branch_index", "]", "*", "block", ".", "expansion", ",", "momentum", "=", "_BN_MOMENTUM", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "block", "(", "self", ".", "num_in_chs", "[", "branch_index", "]", ",", "num_channels", "[", "branch_index", "]", ",", "stride", ",", "downsample", ")", "]", "\n", "self", ".", "num_in_chs", "[", "branch_index", "]", "=", "num_channels", "[", "branch_index", "]", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "num_blocks", "[", "branch_index", "]", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "num_in_chs", "[", "branch_index", "]", ",", "num_channels", "[", "branch_index", "]", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionModule._make_branches": [[435, 441], ["range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "branches.append", "hrnet.HighResolutionModule._make_one_branch"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionModule._make_one_branch"], ["", "def", "_make_branches", "(", "self", ",", "num_branches", ",", "block", ",", "num_blocks", ",", "num_channels", ")", ":", "\n", "        ", "branches", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_branches", ")", ":", "\n", "            ", "branches", ".", "append", "(", "self", ".", "_make_one_branch", "(", "i", ",", "block", ",", "num_blocks", ",", "num_channels", ")", ")", "\n", "\n", "", "return", "nn", ".", "ModuleList", "(", "branches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionModule._make_fuse_layers": [[442, 477], ["range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Identity", "torch.Identity", "torch.Identity", "range", "fuse_layers.append", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "fuse_layer.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "fuse_layer.append", "range", "fuse_layer.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Sequential", "torch.Sequential", "torch.Sequential", "conv3x3s.append", "conv3x3s.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["None"], ["", "def", "_make_fuse_layers", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "num_branches", "==", "1", ":", "\n", "            ", "return", "nn", ".", "Identity", "(", ")", "\n", "\n", "", "num_branches", "=", "self", ".", "num_branches", "\n", "num_in_chs", "=", "self", ".", "num_in_chs", "\n", "fuse_layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_branches", "if", "self", ".", "multi_scale_output", "else", "1", ")", ":", "\n", "            ", "fuse_layer", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "num_branches", ")", ":", "\n", "                ", "if", "j", ">", "i", ":", "\n", "                    ", "fuse_layer", ".", "append", "(", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "num_in_chs", "[", "j", "]", ",", "num_in_chs", "[", "i", "]", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "num_in_chs", "[", "i", "]", ",", "momentum", "=", "_BN_MOMENTUM", ")", ",", "\n", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", "**", "(", "j", "-", "i", ")", ",", "mode", "=", "'nearest'", ")", ")", ")", "\n", "", "elif", "j", "==", "i", ":", "\n", "                    ", "fuse_layer", ".", "append", "(", "nn", ".", "Identity", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "conv3x3s", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "i", "-", "j", ")", ":", "\n", "                        ", "if", "k", "==", "i", "-", "j", "-", "1", ":", "\n", "                            ", "num_outchannels_conv3x3", "=", "num_in_chs", "[", "i", "]", "\n", "conv3x3s", ".", "append", "(", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "num_in_chs", "[", "j", "]", ",", "num_outchannels_conv3x3", ",", "3", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "num_outchannels_conv3x3", ",", "momentum", "=", "_BN_MOMENTUM", ")", ")", ")", "\n", "", "else", ":", "\n", "                            ", "num_outchannels_conv3x3", "=", "num_in_chs", "[", "j", "]", "\n", "conv3x3s", ".", "append", "(", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "num_in_chs", "[", "j", "]", ",", "num_outchannels_conv3x3", ",", "3", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "num_outchannels_conv3x3", ",", "momentum", "=", "_BN_MOMENTUM", ")", ",", "\n", "nn", ".", "ReLU", "(", "False", ")", ")", ")", "\n", "", "", "fuse_layer", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "conv3x3s", ")", ")", "\n", "", "", "fuse_layers", ".", "append", "(", "nn", ".", "ModuleList", "(", "fuse_layer", ")", ")", "\n", "\n", "", "return", "nn", ".", "ModuleList", "(", "fuse_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionModule.get_num_in_chs": [[478, 480], ["None"], "methods", ["None"], ["", "def", "get_num_in_chs", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_in_chs", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionModule.forward": [[481, 499], ["enumerate", "enumerate", "branch", "range", "x_fuse.append", "hrnet.HighResolutionModule.fuse_act"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "if", "self", ".", "num_branches", "==", "1", ":", "\n", "            ", "return", "[", "self", ".", "branches", "[", "0", "]", "(", "x", "[", "0", "]", ")", "]", "\n", "\n", "", "for", "i", ",", "branch", "in", "enumerate", "(", "self", ".", "branches", ")", ":", "\n", "            ", "x", "[", "i", "]", "=", "branch", "(", "x", "[", "i", "]", ")", "\n", "\n", "", "x_fuse", "=", "[", "]", "\n", "for", "i", ",", "fuse_outer", "in", "enumerate", "(", "self", ".", "fuse_layers", ")", ":", "\n", "            ", "y", "=", "x", "[", "0", "]", "if", "i", "==", "0", "else", "fuse_outer", "[", "0", "]", "(", "x", "[", "0", "]", ")", "\n", "for", "j", "in", "range", "(", "1", ",", "self", ".", "num_branches", ")", ":", "\n", "                ", "if", "i", "==", "j", ":", "\n", "                    ", "y", "=", "y", "+", "x", "[", "j", "]", "\n", "", "else", ":", "\n", "                    ", "y", "=", "y", "+", "fuse_outer", "[", "j", "]", "(", "x", "[", "j", "]", ")", "\n", "", "", "x_fuse", ".", "append", "(", "self", ".", "fuse_act", "(", "y", ")", ")", "\n", "\n", "", "return", "x_fuse", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.__init__": [[509, 574], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "hrnet.HighResolutionNet._make_layer", "hrnet.HighResolutionNet._make_transition_layer", "hrnet.HighResolutionNet._make_stage", "hrnet.HighResolutionNet._make_transition_layer", "hrnet.HighResolutionNet._make_stage", "hrnet.HighResolutionNet._make_transition_layer", "hrnet.HighResolutionNet._make_stage", "enumerate", "hrnet.HighResolutionNet.init_weights", "hrnet.HighResolutionNet._make_head", "layers.create_classifier", "dict", "range", "range", "range", "hrnet.HighResolutionNet._make_head", "dict", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet._make_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet._make_transition_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet._make_stage", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet._make_transition_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet._make_stage", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet._make_transition_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet._make_stage", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.GluMlp.init_weights", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet._make_head", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet._make_head"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "global_pool", "=", "'avg'", ",", "drop_rate", "=", "0.0", ",", "head", "=", "'classification'", ")", ":", "\n", "        ", "super", "(", "HighResolutionNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "\n", "stem_width", "=", "cfg", "[", "'STEM_WIDTH'", "]", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_chans", ",", "stem_width", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "stem_width", ",", "momentum", "=", "_BN_MOMENTUM", ")", "\n", "self", ".", "act1", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "stem_width", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "64", ",", "momentum", "=", "_BN_MOMENTUM", ")", "\n", "self", ".", "act2", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "stage1_cfg", "=", "cfg", "[", "'STAGE1'", "]", "\n", "num_channels", "=", "self", ".", "stage1_cfg", "[", "'NUM_CHANNELS'", "]", "[", "0", "]", "\n", "block", "=", "blocks_dict", "[", "self", ".", "stage1_cfg", "[", "'BLOCK'", "]", "]", "\n", "num_blocks", "=", "self", ".", "stage1_cfg", "[", "'NUM_BLOCKS'", "]", "[", "0", "]", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "num_channels", ",", "num_blocks", ")", "\n", "stage1_out_channel", "=", "block", ".", "expansion", "*", "num_channels", "\n", "\n", "self", ".", "stage2_cfg", "=", "cfg", "[", "'STAGE2'", "]", "\n", "num_channels", "=", "self", ".", "stage2_cfg", "[", "'NUM_CHANNELS'", "]", "\n", "block", "=", "blocks_dict", "[", "self", ".", "stage2_cfg", "[", "'BLOCK'", "]", "]", "\n", "num_channels", "=", "[", "num_channels", "[", "i", "]", "*", "block", ".", "expansion", "for", "i", "in", "range", "(", "len", "(", "num_channels", ")", ")", "]", "\n", "self", ".", "transition1", "=", "self", ".", "_make_transition_layer", "(", "[", "stage1_out_channel", "]", ",", "num_channels", ")", "\n", "self", ".", "stage2", ",", "pre_stage_channels", "=", "self", ".", "_make_stage", "(", "self", ".", "stage2_cfg", ",", "num_channels", ")", "\n", "\n", "self", ".", "stage3_cfg", "=", "cfg", "[", "'STAGE3'", "]", "\n", "num_channels", "=", "self", ".", "stage3_cfg", "[", "'NUM_CHANNELS'", "]", "\n", "block", "=", "blocks_dict", "[", "self", ".", "stage3_cfg", "[", "'BLOCK'", "]", "]", "\n", "num_channels", "=", "[", "num_channels", "[", "i", "]", "*", "block", ".", "expansion", "for", "i", "in", "range", "(", "len", "(", "num_channels", ")", ")", "]", "\n", "self", ".", "transition2", "=", "self", ".", "_make_transition_layer", "(", "pre_stage_channels", ",", "num_channels", ")", "\n", "self", ".", "stage3", ",", "pre_stage_channels", "=", "self", ".", "_make_stage", "(", "self", ".", "stage3_cfg", ",", "num_channels", ")", "\n", "\n", "self", ".", "stage4_cfg", "=", "cfg", "[", "'STAGE4'", "]", "\n", "num_channels", "=", "self", ".", "stage4_cfg", "[", "'NUM_CHANNELS'", "]", "\n", "block", "=", "blocks_dict", "[", "self", ".", "stage4_cfg", "[", "'BLOCK'", "]", "]", "\n", "num_channels", "=", "[", "num_channels", "[", "i", "]", "*", "block", ".", "expansion", "for", "i", "in", "range", "(", "len", "(", "num_channels", ")", ")", "]", "\n", "self", ".", "transition3", "=", "self", ".", "_make_transition_layer", "(", "pre_stage_channels", ",", "num_channels", ")", "\n", "self", ".", "stage4", ",", "pre_stage_channels", "=", "self", ".", "_make_stage", "(", "self", ".", "stage4_cfg", ",", "num_channels", ",", "multi_scale_output", "=", "True", ")", "\n", "\n", "self", ".", "head", "=", "head", "\n", "self", ".", "head_channels", "=", "None", "# set if _make_head called", "\n", "if", "head", "==", "'classification'", ":", "\n", "# Classification Head", "\n", "            ", "self", ".", "num_features", "=", "2048", "\n", "self", ".", "incre_modules", ",", "self", ".", "downsamp_modules", ",", "self", ".", "final_layer", "=", "self", ".", "_make_head", "(", "pre_stage_channels", ")", "\n", "self", ".", "global_pool", ",", "self", ".", "classifier", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "", "elif", "head", "==", "'incre'", ":", "\n", "            ", "self", ".", "num_features", "=", "2048", "\n", "self", ".", "incre_modules", ",", "_", ",", "_", "=", "self", ".", "_make_head", "(", "pre_stage_channels", ",", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "incre_modules", "=", "None", "\n", "self", ".", "num_features", "=", "256", "\n", "\n", "", "curr_stride", "=", "2", "\n", "# module names aren't actually valid here, hook or FeatureNet based extraction would not work", "\n", "self", ".", "feature_info", "=", "[", "dict", "(", "num_chs", "=", "64", ",", "reduction", "=", "curr_stride", ",", "module", "=", "'stem'", ")", "]", "\n", "for", "i", ",", "c", "in", "enumerate", "(", "self", ".", "head_channels", "if", "self", ".", "head_channels", "else", "num_channels", ")", ":", "\n", "            ", "curr_stride", "*=", "2", "\n", "c", "=", "c", "*", "4", "if", "self", ".", "head_channels", "else", "c", "# head block expansion factor of 4", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "c", ",", "reduction", "=", "curr_stride", ",", "module", "=", "f'stage{i + 1}'", ")", "]", "\n", "\n", "", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet._make_head": [[575, 612], ["enumerate", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ModuleList.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ModuleList.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "hrnet.HighResolutionNet._make_layer", "len", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet._make_layer"], ["", "def", "_make_head", "(", "self", ",", "pre_stage_channels", ",", "incre_only", "=", "False", ")", ":", "\n", "        ", "head_block", "=", "Bottleneck", "\n", "self", ".", "head_channels", "=", "[", "32", ",", "64", ",", "128", ",", "256", "]", "\n", "\n", "# Increasing the #channels on each resolution", "\n", "# from C, 2C, 4C, 8C to 128, 256, 512, 1024", "\n", "incre_modules", "=", "[", "]", "\n", "for", "i", ",", "channels", "in", "enumerate", "(", "pre_stage_channels", ")", ":", "\n", "            ", "incre_modules", ".", "append", "(", "self", ".", "_make_layer", "(", "head_block", ",", "channels", ",", "self", ".", "head_channels", "[", "i", "]", ",", "1", ",", "stride", "=", "1", ")", ")", "\n", "", "incre_modules", "=", "nn", ".", "ModuleList", "(", "incre_modules", ")", "\n", "if", "incre_only", ":", "\n", "            ", "return", "incre_modules", ",", "None", ",", "None", "\n", "\n", "# downsampling modules", "\n", "", "downsamp_modules", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "pre_stage_channels", ")", "-", "1", ")", ":", "\n", "            ", "in_channels", "=", "self", ".", "head_channels", "[", "i", "]", "*", "head_block", ".", "expansion", "\n", "out_channels", "=", "self", ".", "head_channels", "[", "i", "+", "1", "]", "*", "head_block", ".", "expansion", "\n", "downsamp_module", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_channels", ",", "momentum", "=", "_BN_MOMENTUM", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", ")", "\n", "downsamp_modules", ".", "append", "(", "downsamp_module", ")", "\n", "", "downsamp_modules", "=", "nn", ".", "ModuleList", "(", "downsamp_modules", ")", "\n", "\n", "final_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "self", ".", "head_channels", "[", "3", "]", "*", "head_block", ".", "expansion", ",", "\n", "out_channels", "=", "self", ".", "num_features", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", "\n", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "num_features", ",", "momentum", "=", "_BN_MOMENTUM", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", ")", "\n", "\n", "return", "incre_modules", ",", "downsamp_modules", ",", "final_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet._make_transition_layer": [[613, 639], ["len", "len", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "transition_layers.append", "transition_layers.append", "transition_layers.append", "conv3x3s.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["None"], ["", "def", "_make_transition_layer", "(", "self", ",", "num_channels_pre_layer", ",", "num_channels_cur_layer", ")", ":", "\n", "        ", "num_branches_cur", "=", "len", "(", "num_channels_cur_layer", ")", "\n", "num_branches_pre", "=", "len", "(", "num_channels_pre_layer", ")", "\n", "\n", "transition_layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_branches_cur", ")", ":", "\n", "            ", "if", "i", "<", "num_branches_pre", ":", "\n", "                ", "if", "num_channels_cur_layer", "[", "i", "]", "!=", "num_channels_pre_layer", "[", "i", "]", ":", "\n", "                    ", "transition_layers", ".", "append", "(", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "num_channels_pre_layer", "[", "i", "]", ",", "num_channels_cur_layer", "[", "i", "]", ",", "3", ",", "1", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "num_channels_cur_layer", "[", "i", "]", ",", "momentum", "=", "_BN_MOMENTUM", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "transition_layers", ".", "append", "(", "nn", ".", "Identity", "(", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "conv3x3s", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "i", "+", "1", "-", "num_branches_pre", ")", ":", "\n", "                    ", "inchannels", "=", "num_channels_pre_layer", "[", "-", "1", "]", "\n", "outchannels", "=", "num_channels_cur_layer", "[", "i", "]", "if", "j", "==", "i", "-", "num_branches_pre", "else", "inchannels", "\n", "conv3x3s", ".", "append", "(", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "inchannels", ",", "outchannels", ",", "3", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "outchannels", ",", "momentum", "=", "_BN_MOMENTUM", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", ")", "\n", "", "transition_layers", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "conv3x3s", ")", ")", "\n", "\n", "", "", "return", "nn", ".", "ModuleList", "(", "transition_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet._make_layer": [[640, 654], ["range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "block", ",", "inplanes", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ",", "momentum", "=", "_BN_MOMENTUM", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "block", "(", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", "]", "\n", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet._make_stage": [[655, 673], ["range", "modules.append", "modules[].get_num_in_chs", "torch.Sequential", "torch.Sequential", "torch.Sequential", "hrnet.HighResolutionModule"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionModule.get_num_in_chs"], ["", "def", "_make_stage", "(", "self", ",", "layer_config", ",", "num_in_chs", ",", "multi_scale_output", "=", "True", ")", ":", "\n", "        ", "num_modules", "=", "layer_config", "[", "'NUM_MODULES'", "]", "\n", "num_branches", "=", "layer_config", "[", "'NUM_BRANCHES'", "]", "\n", "num_blocks", "=", "layer_config", "[", "'NUM_BLOCKS'", "]", "\n", "num_channels", "=", "layer_config", "[", "'NUM_CHANNELS'", "]", "\n", "block", "=", "blocks_dict", "[", "layer_config", "[", "'BLOCK'", "]", "]", "\n", "fuse_method", "=", "layer_config", "[", "'FUSE_METHOD'", "]", "\n", "\n", "modules", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_modules", ")", ":", "\n", "# multi_scale_output is only used last module", "\n", "            ", "reset_multi_scale_output", "=", "multi_scale_output", "or", "i", "<", "num_modules", "-", "1", "\n", "modules", ".", "append", "(", "HighResolutionModule", "(", "\n", "num_branches", ",", "block", ",", "num_blocks", ",", "num_in_chs", ",", "num_channels", ",", "fuse_method", ",", "reset_multi_scale_output", ")", "\n", ")", "\n", "num_in_chs", "=", "modules", "[", "-", "1", "]", ".", "get_num_in_chs", "(", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "modules", ")", ",", "num_in_chs", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.init_weights": [[674, 683], ["hrnet.HighResolutionNet.modules", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "\n", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.group_matcher": [[684, 695], ["dict"], "methods", ["None"], ["", "", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem", "=", "r'^conv[12]|bn[12]'", ",", "\n", "blocks", "=", "r'^(?:layer|stage|transition)(\\d+)'", "if", "coarse", "else", "[", "\n", "(", "r'^layer(\\d+)\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^stage(\\d+)\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^transition(\\d+)'", ",", "(", "99999", ",", ")", ")", ",", "\n", "]", ",", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.set_grad_checkpointing": [[696, 699], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "\"gradient checkpointing not supported\"", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.get_classifier": [[700, 703], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.reset_classifier": [[704, 708], ["layers.create_classifier"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "classifier", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.stages": [[709, 721], ["hrnet.HighResolutionNet.layer1", "hrnet.HighResolutionNet.stage2", "hrnet.HighResolutionNet.stage3", "hrnet.HighResolutionNet.stage4", "t", "enumerate", "t", "enumerate", "t", "enumerate", "isinstance", "isinstance"], "methods", ["None"], ["", "def", "stages", "(", "self", ",", "x", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "        ", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "\n", "xl", "=", "[", "t", "(", "x", ")", "for", "i", ",", "t", "in", "enumerate", "(", "self", ".", "transition1", ")", "]", "\n", "yl", "=", "self", ".", "stage2", "(", "xl", ")", "\n", "\n", "xl", "=", "[", "t", "(", "yl", "[", "-", "1", "]", ")", "if", "not", "isinstance", "(", "t", ",", "nn", ".", "Identity", ")", "else", "yl", "[", "i", "]", "for", "i", ",", "t", "in", "enumerate", "(", "self", ".", "transition2", ")", "]", "\n", "yl", "=", "self", ".", "stage3", "(", "xl", ")", "\n", "\n", "xl", "=", "[", "t", "(", "yl", "[", "-", "1", "]", ")", "if", "not", "isinstance", "(", "t", ",", "nn", ".", "Identity", ")", "else", "yl", "[", "i", "]", "for", "i", ",", "t", "in", "enumerate", "(", "self", ".", "transition3", ")", "]", "\n", "yl", "=", "self", ".", "stage4", "(", "xl", ")", "\n", "return", "yl", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.forward_features": [[722, 740], ["hrnet.HighResolutionNet.conv1", "hrnet.HighResolutionNet.bn1", "hrnet.HighResolutionNet.act1", "hrnet.HighResolutionNet.conv2", "hrnet.HighResolutionNet.bn2", "hrnet.HighResolutionNet.act2", "hrnet.HighResolutionNet.stages", "enumerate", "hrnet.HighResolutionNet.final_layer", "down"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.stages"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "# Stem", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "act1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "bn2", "(", "x", ")", "\n", "x", "=", "self", ".", "act2", "(", "x", ")", "\n", "\n", "# Stages", "\n", "yl", "=", "self", ".", "stages", "(", "x", ")", "\n", "if", "self", ".", "incre_modules", "is", "None", "or", "self", ".", "downsamp_modules", "is", "None", ":", "\n", "            ", "return", "yl", "\n", "", "y", "=", "self", ".", "incre_modules", "[", "0", "]", "(", "yl", "[", "0", "]", ")", "\n", "for", "i", ",", "down", "in", "enumerate", "(", "self", ".", "downsamp_modules", ")", ":", "\n", "            ", "y", "=", "self", ".", "incre_modules", "[", "i", "+", "1", "]", "(", "yl", "[", "i", "+", "1", "]", ")", "+", "down", "(", "y", ")", "\n", "", "y", "=", "self", ".", "final_layer", "(", "y", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.forward_head": [[741, 747], ["hrnet.HighResolutionNet.global_pool", "torch.dropout", "torch.dropout", "torch.dropout", "hrnet.HighResolutionNet.classifier"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "# Classification Head", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ">", "0.", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "classifier", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.forward": [[748, 752], ["hrnet.HighResolutionNet.forward_features", "hrnet.HighResolutionNet.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "y", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "y", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNetFeatures.__init__": [[765, 773], ["hrnet.HighResolutionNet.__init__", "features.FeatureInfo"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "global_pool", "=", "'avg'", ",", "drop_rate", "=", "0.0", ",", "\n", "feature_location", "=", "'incre'", ",", "out_indices", "=", "(", "0", ",", "1", ",", "2", ",", "3", ",", "4", ")", ")", ":", "\n", "        ", "assert", "feature_location", "in", "(", "'incre'", ",", "''", ")", "\n", "super", "(", "HighResolutionNetFeatures", ",", "self", ")", ".", "__init__", "(", "\n", "cfg", ",", "in_chans", "=", "in_chans", ",", "num_classes", "=", "num_classes", ",", "global_pool", "=", "global_pool", ",", "\n", "drop_rate", "=", "drop_rate", ",", "head", "=", "feature_location", ")", "\n", "self", ".", "feature_info", "=", "FeatureInfo", "(", "self", ".", "feature_info", ",", "out_indices", ")", "\n", "self", ".", "_out_idx", "=", "{", "i", "for", "i", "in", "out_indices", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNetFeatures.forward_features": [[774, 776], ["None"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "False", ",", "'Not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNetFeatures.forward": [[777, 794], ["hrnet.HighResolutionNetFeatures.conv1", "hrnet.HighResolutionNetFeatures.bn1", "hrnet.HighResolutionNetFeatures.act1", "hrnet.HighResolutionNetFeatures.conv2", "hrnet.HighResolutionNetFeatures.bn2", "hrnet.HighResolutionNetFeatures.act2", "hrnet.HighResolutionNetFeatures.stages", "enumerate", "out.append", "incre", "out.append", "zip"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.stages"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "List", "[", "torch", ".", "tensor", "]", ":", "\n", "        ", "out", "=", "[", "]", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "act1", "(", "x", ")", "\n", "if", "0", "in", "self", ".", "_out_idx", ":", "\n", "            ", "out", ".", "append", "(", "x", ")", "\n", "", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "bn2", "(", "x", ")", "\n", "x", "=", "self", ".", "act2", "(", "x", ")", "\n", "x", "=", "self", ".", "stages", "(", "x", ")", "\n", "if", "self", ".", "incre_modules", "is", "not", "None", ":", "\n", "            ", "x", "=", "[", "incre", "(", "f", ")", "for", "f", ",", "incre", "in", "zip", "(", "x", ",", "self", ".", "incre_modules", ")", "]", "\n", "", "for", "i", ",", "f", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "i", "+", "1", "in", "self", ".", "_out_idx", ":", "\n", "                ", "out", ".", "append", "(", "f", ")", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet._cfg": [[29, 37], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bilinear'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'conv1'", ",", "'classifier'", ":", "'classifier'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet._create_hrnet": [[796, 814], ["model_kwargs.pop", "helpers.build_model_with_cfg", "helpers.pretrained_cfg_for_features"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.pretrained_cfg_for_features"], ["", "", "def", "_create_hrnet", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", ":", "\n", "    ", "model_cls", "=", "HighResolutionNet", "\n", "features_only", "=", "False", "\n", "kwargs_filter", "=", "None", "\n", "if", "model_kwargs", ".", "pop", "(", "'features_only'", ",", "False", ")", ":", "\n", "        ", "model_cls", "=", "HighResolutionNetFeatures", "\n", "kwargs_filter", "=", "(", "'num_classes'", ",", "'global_pool'", ")", "\n", "features_only", "=", "True", "\n", "", "model", "=", "build_model_with_cfg", "(", "\n", "model_cls", ",", "variant", ",", "pretrained", ",", "\n", "model_cfg", "=", "cfg_cls", "[", "variant", "]", ",", "\n", "pretrained_strict", "=", "not", "features_only", ",", "\n", "kwargs_filter", "=", "kwargs_filter", ",", "\n", "**", "model_kwargs", ")", "\n", "if", "features_only", ":", "\n", "        ", "model", ".", "pretrained_cfg", "=", "pretrained_cfg_for_features", "(", "model", ".", "default_cfg", ")", "\n", "model", ".", "default_cfg", "=", "model", ".", "pretrained_cfg", "# backwards compat", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.hrnet_w18_small": [[816, 819], ["hrnet._create_hrnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet._create_hrnet"], ["", "@", "register_model", "\n", "def", "hrnet_w18_small", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_hrnet", "(", "'hrnet_w18_small'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.hrnet_w18_small_v2": [[821, 824], ["hrnet._create_hrnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet._create_hrnet"], ["", "@", "register_model", "\n", "def", "hrnet_w18_small_v2", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_hrnet", "(", "'hrnet_w18_small_v2'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.hrnet_w18": [[826, 829], ["hrnet._create_hrnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet._create_hrnet"], ["", "@", "register_model", "\n", "def", "hrnet_w18", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_hrnet", "(", "'hrnet_w18'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.hrnet_w30": [[831, 834], ["hrnet._create_hrnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet._create_hrnet"], ["", "@", "register_model", "\n", "def", "hrnet_w30", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_hrnet", "(", "'hrnet_w30'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.hrnet_w32": [[836, 839], ["hrnet._create_hrnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet._create_hrnet"], ["", "@", "register_model", "\n", "def", "hrnet_w32", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_hrnet", "(", "'hrnet_w32'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.hrnet_w40": [[841, 844], ["hrnet._create_hrnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet._create_hrnet"], ["", "@", "register_model", "\n", "def", "hrnet_w40", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_hrnet", "(", "'hrnet_w40'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.hrnet_w44": [[846, 849], ["hrnet._create_hrnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet._create_hrnet"], ["", "@", "register_model", "\n", "def", "hrnet_w44", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_hrnet", "(", "'hrnet_w44'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.hrnet_w48": [[851, 854], ["hrnet._create_hrnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet._create_hrnet"], ["", "@", "register_model", "\n", "def", "hrnet_w48", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_hrnet", "(", "'hrnet_w48'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.hrnet_w64": [[856, 859], ["hrnet._create_hrnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet._create_hrnet"], ["", "@", "register_model", "\n", "def", "hrnet_w64", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_hrnet", "(", "'hrnet_w64'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet_v2.BasicBlock.__init__": [[54, 72], ["torch.Module.__init__", "tresnet_v2.conv2d_iabn", "torch.ReLU", "torch.ReLU", "max", "tresnet_v2.conv2d_iabn", "layers.SEModule", "tresnet_v2.conv2d_iabn", "torch.Sequential", "torch.Sequential", "tresnet_v2.conv2d_iabn", "aa_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "use_se", "=", "True", ",", "aa_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "stride", "==", "1", ":", "\n", "            ", "self", ".", "conv1", "=", "conv2d_iabn", "(", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "act_param", "=", "1e-3", ")", "\n", "", "else", ":", "\n", "            ", "if", "aa_layer", "is", "None", ":", "\n", "                ", "self", ".", "conv1", "=", "conv2d_iabn", "(", "inplanes", ",", "planes", ",", "stride", "=", "2", ",", "act_param", "=", "1e-3", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "conv1", "=", "nn", ".", "Sequential", "(", "\n", "conv2d_iabn", "(", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "act_param", "=", "1e-3", ")", ",", "\n", "aa_layer", "(", "channels", "=", "planes", ",", "filt_size", "=", "3", ",", "stride", "=", "2", ")", ")", "\n", "\n", "", "", "self", ".", "conv2", "=", "conv2d_iabn", "(", "planes", ",", "planes", ",", "stride", "=", "1", ",", "act_layer", "=", "\"identity\"", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "rd_chs", "=", "max", "(", "planes", "*", "self", ".", "expansion", "//", "4", ",", "64", ")", "\n", "self", ".", "se", "=", "SEModule", "(", "planes", "*", "self", ".", "expansion", ",", "rd_channels", "=", "rd_chs", ")", "if", "use_se", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet_v2.BasicBlock.forward": [[73, 88], ["tresnet_v2.BasicBlock.conv1", "tresnet_v2.BasicBlock.conv2", "tresnet_v2.BasicBlock.relu", "tresnet_v2.BasicBlock.downsample", "tresnet_v2.BasicBlock.se"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "downsample", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "shortcut", "=", "x", "\n", "\n", "", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "\n", "if", "self", ".", "se", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "se", "(", "out", ")", "\n", "\n", "", "out", "+=", "shortcut", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet_v2.Bottleneck.__init__": [[93, 119], ["torch.Module.__init__", "tresnet_v2.conv2d_iabn", "max", "tresnet_v2.conv2d_iabn", "torch.ReLU", "torch.ReLU", "tresnet_v2.conv2d_iabn", "layers.SEModule", "tresnet_v2.conv2d_iabn", "torch.Sequential", "torch.Sequential", "tresnet_v2.conv2d_iabn", "aa_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "use_se", "=", "True", ",", "\n", "act_layer", "=", "\"leaky_relu\"", ",", "aa_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv2d_iabn", "(", "\n", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "act_layer", "=", "act_layer", ",", "act_param", "=", "1e-3", ")", "\n", "if", "stride", "==", "1", ":", "\n", "            ", "self", ".", "conv2", "=", "conv2d_iabn", "(", "\n", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "act_layer", "=", "act_layer", ",", "act_param", "=", "1e-3", ")", "\n", "", "else", ":", "\n", "            ", "if", "aa_layer", "is", "None", ":", "\n", "                ", "self", ".", "conv2", "=", "conv2d_iabn", "(", "\n", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "act_layer", "=", "act_layer", ",", "act_param", "=", "1e-3", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "conv2", "=", "nn", ".", "Sequential", "(", "\n", "conv2d_iabn", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "act_layer", "=", "act_layer", ",", "act_param", "=", "1e-3", ")", ",", "\n", "aa_layer", "(", "channels", "=", "planes", ",", "filt_size", "=", "3", ",", "stride", "=", "2", ")", ")", "\n", "\n", "", "", "reduction_chs", "=", "max", "(", "planes", "*", "self", ".", "expansion", "//", "8", ",", "64", ")", "\n", "self", ".", "se", "=", "SEModule", "(", "planes", ",", "rd_channels", "=", "reduction_chs", ")", "if", "use_se", "else", "None", "\n", "\n", "self", ".", "conv3", "=", "conv2d_iabn", "(", "\n", "planes", ",", "planes", "*", "self", ".", "expansion", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "act_layer", "=", "\"identity\"", ")", "\n", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet_v2.Bottleneck.forward": [[120, 136], ["tresnet_v2.Bottleneck.conv1", "tresnet_v2.Bottleneck.conv2", "tresnet_v2.Bottleneck.conv3", "tresnet_v2.Bottleneck.relu", "tresnet_v2.Bottleneck.downsample", "tresnet_v2.Bottleneck.se"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "downsample", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "shortcut", "=", "x", "\n", "\n", "", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "if", "self", ".", "se", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "se", "(", "out", ")", "\n", "\n", "", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "out", "+", "shortcut", "# no inplace", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet_v2.TResNet.__init__": [[139, 197], ["torch.Module.__init__", "int", "int", "tresnet_v2.conv2d_iabn", "tresnet_v2.TResNet._make_layer", "tresnet_v2.TResNet._make_layer", "tresnet_v2.TResNet._make_layer", "tresnet_v2.TResNet._make_layer", "torch.Sequential", "torch.Sequential", "layers.ClassifierHead", "tresnet_v2.TResNet.modules", "tresnet_v2.TResNet.modules", "collections.OrderedDict", "isinstance", "isinstance", "isinstance", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "m.weight.data.normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "layers.SpaceToDepthModule"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet._make_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet._make_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet._make_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "layers", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "width_factor", "=", "1.0", ",", "global_pool", "=", "'fast'", ",", "drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "super", "(", "TResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "aa_layer", "=", "BlurPool2d", "\n", "\n", "# TResnet stages", "\n", "self", ".", "inplanes", "=", "int", "(", "64", "*", "width_factor", ")", "\n", "self", ".", "planes", "=", "int", "(", "64", "*", "width_factor", ")", "\n", "conv1", "=", "conv2d_iabn", "(", "in_chans", "*", "16", ",", "self", ".", "planes", ",", "stride", "=", "1", ",", "kernel_size", "=", "3", ")", "\n", "layer1", "=", "self", ".", "_make_layer", "(", "\n", "Bottleneck", ",", "self", ".", "planes", ",", "layers", "[", "0", "]", ",", "stride", "=", "1", ",", "use_se", "=", "True", ",", "aa_layer", "=", "aa_layer", ")", "# 56x56", "\n", "layer2", "=", "self", ".", "_make_layer", "(", "\n", "Bottleneck", ",", "self", ".", "planes", "*", "2", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ",", "use_se", "=", "True", ",", "aa_layer", "=", "aa_layer", ")", "# 28x28", "\n", "layer3", "=", "self", ".", "_make_layer", "(", "\n", "Bottleneck", ",", "self", ".", "planes", "*", "4", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ",", "use_se", "=", "True", ",", "aa_layer", "=", "aa_layer", ")", "# 14x14", "\n", "layer4", "=", "self", ".", "_make_layer", "(", "\n", "Bottleneck", ",", "self", ".", "planes", "*", "8", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ",", "use_se", "=", "False", ",", "aa_layer", "=", "aa_layer", ")", "# 7x7", "\n", "\n", "# body", "\n", "self", ".", "body", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'SpaceToDepth'", ",", "SpaceToDepthModule", "(", ")", ")", ",", "\n", "(", "'conv1'", ",", "conv1", ")", ",", "\n", "(", "'layer1'", ",", "layer1", ")", ",", "\n", "(", "'layer2'", ",", "layer2", ")", ",", "\n", "(", "'layer3'", ",", "layer3", ")", ",", "\n", "(", "'layer4'", ",", "layer4", ")", "]", ")", ")", "\n", "\n", "# self.feature_info = [", "\n", "#     dict(num_chs=self.planes, reduction=2, module=''),  # Not with S2D?", "\n", "#     dict(num_chs=self.planes, reduction=4, module='body.layer1'),", "\n", "#     dict(num_chs=self.planes * 2, reduction=8, module='body.layer2'),", "\n", "#     dict(num_chs=self.planes * 4 * Bottleneck.expansion, reduction=16, module='body.layer3'),", "\n", "#     dict(num_chs=self.planes * 8 * Bottleneck.expansion, reduction=32, module='body.layer4'),", "\n", "# ]", "\n", "\n", "# head", "\n", "self", ".", "num_features", "=", "(", "self", ".", "planes", "*", "8", ")", "*", "Bottleneck", ".", "expansion", "\n", "self", ".", "head", "=", "ClassifierHead", "(", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "drop_rate", ")", "\n", "\n", "# model initilization", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'leaky_relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", "or", "isinstance", "(", "m", ",", "InplaceAbn", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n", "# residual connections special initialization", "\n", "", "", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "BasicBlock", ")", ":", "\n", "                ", "m", ".", "conv2", "[", "1", "]", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros_like", "(", "m", ".", "conv2", "[", "1", "]", ".", "weight", ")", ")", "# BN to zero", "\n", "", "if", "isinstance", "(", "m", ",", "Bottleneck", ")", ":", "\n", "                ", "m", ".", "conv3", "[", "1", "]", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros_like", "(", "m", ".", "conv3", "[", "1", "]", ".", "weight", ")", ")", "# BN to zero", "\n", "", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.01", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet_v2.TResNet._make_layer": [[198, 217], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "layers.append", "tresnet_v2.conv2d_iabn", "block", "torch.AvgPool2d", "torch.AvgPool2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ",", "use_se", "=", "True", ",", "aa_layer", "=", "None", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "layers", "=", "[", "]", "\n", "if", "stride", "==", "2", ":", "\n", "# avg pooling before 1x1 conv", "\n", "                ", "layers", ".", "append", "(", "nn", ".", "AvgPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "ceil_mode", "=", "True", ",", "count_include_pad", "=", "False", ")", ")", "\n", "", "layers", "+=", "[", "conv2d_iabn", "(", "\n", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "act_layer", "=", "\"identity\"", ")", "]", "\n", "downsample", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "\n", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ",", "use_se", "=", "use_se", ",", "aa_layer", "=", "aa_layer", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "use_se", "=", "use_se", ",", "aa_layer", "=", "aa_layer", ")", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet_v2.TResNet.get_classifier": [[218, 220], ["None"], "methods", ["None"], ["", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet_v2.TResNet.reset_classifier": [[221, 224], ["layers.ClassifierHead"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'fast'", ")", ":", "\n", "        ", "self", ".", "head", "=", "ClassifierHead", "(", "\n", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "self", ".", "drop_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet_v2.TResNet.forward_features": [[225, 227], ["tresnet_v2.TResNet.body"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "body", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet_v2.TResNet.forward": [[228, 232], ["tresnet_v2.TResNet.forward_features", "tresnet_v2.TResNet.head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet_v2._cfg": [[19, 26], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bilinear'", ",", "\n", "'mean'", ":", "(", "0", ",", "0", ",", "0", ")", ",", "'std'", ":", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "'first_conv'", ":", "'body.conv1.0'", ",", "'classifier'", ":", "'head.fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet_v2.IABN2Float": [[34, 41], ["isinstance", "module.children", "module.float", "tresnet_v2.IABN2Float"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.IABN2Float"], ["def", "IABN2Float", "(", "module", ":", "nn", ".", "Module", ")", "->", "nn", ".", "Module", ":", "\n", "    ", "\"\"\"If `module` is IABN don't use half precision.\"\"\"", "\n", "if", "isinstance", "(", "module", ",", "InplaceAbn", ")", ":", "\n", "        ", "module", ".", "float", "(", ")", "\n", "", "for", "child", "in", "module", ".", "children", "(", ")", ":", "\n", "        ", "IABN2Float", "(", "child", ")", "\n", "", "return", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet_v2.conv2d_iabn": [[43, 48], ["torch.Sequential", "torch.Conv2d", "layers.InplaceAbn"], "function", ["None"], ["", "def", "conv2d_iabn", "(", "ni", ",", "nf", ",", "stride", ",", "kernel_size", "=", "3", ",", "groups", "=", "1", ",", "act_layer", "=", "\"leaky_relu\"", ",", "act_param", "=", "1e-2", ")", ":", "\n", "    ", "return", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "ni", ",", "nf", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "kernel_size", "//", "2", ",", "groups", "=", "groups", ",", "bias", "=", "False", ")", ",", "\n", "InplaceAbn", "(", "nf", ",", "act_layer", "=", "act_layer", ",", "act_param", "=", "act_param", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet_v2._create_tresnet": [[234, 239], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_tresnet", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "\n", "TResNet", ",", "variant", ",", "pretrained", ",", "\n", "feature_cfg", "=", "dict", "(", "out_indices", "=", "(", "1", ",", "2", ",", "3", ",", "4", ")", ",", "flatten_sequential", "=", "True", ")", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet_v2.tresnet_l_v2": [[241, 245], ["dict", "tresnet_v2._create_tresnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet._create_tresnet"], ["", "@", "register_model", "\n", "def", "tresnet_l_v2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "width_factor", "=", "1.0", ",", "**", "kwargs", ")", "\n", "return", "_create_tresnet", "(", "'tresnet_l_v2'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.SequentialTuple.__init__": [[68, 70], ["torch.nn.Sequential.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "super", "(", "SequentialTuple", ",", "self", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.SequentialTuple.forward": [[71, 75], ["module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "for", "module", "in", "self", ":", "\n", "            ", "x", "=", "module", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.Transformer.__init__": [[78, 98], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.Sequential", "vision_transformer.Block", "range", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "base_dim", ",", "depth", ",", "heads", ",", "mlp_ratio", ",", "pool", "=", "None", ",", "drop_rate", "=", ".0", ",", "attn_drop_rate", "=", ".0", ",", "drop_path_prob", "=", "None", ")", ":", "\n", "        ", "super", "(", "Transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "embed_dim", "=", "base_dim", "*", "heads", "\n", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "Block", "(", "\n", "dim", "=", "embed_dim", ",", "\n", "num_heads", "=", "heads", ",", "\n", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "qkv_bias", "=", "True", ",", "\n", "drop", "=", "drop_rate", ",", "\n", "attn_drop", "=", "attn_drop_rate", ",", "\n", "drop_path", "=", "drop_path_prob", "[", "i", "]", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", "\n", ")", "\n", "for", "i", "in", "range", "(", "depth", ")", "]", ")", "\n", "\n", "self", ".", "pool", "=", "pool", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.Transformer.forward": [[99, 116], ["x.transpose().reshape.transpose().reshape.flatten().transpose", "torch.cat", "pit.Transformer.blocks", "x.transpose().reshape.transpose().reshape.transpose().reshape", "pit.Transformer.pool", "x.transpose().reshape.transpose().reshape.flatten", "x.transpose().reshape.transpose().reshape.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "x", ",", "cls_tokens", "=", "x", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "token_length", "=", "cls_tokens", ".", "shape", "[", "1", "]", "\n", "\n", "x", "=", "x", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "cls_tokens", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "\n", "x", "=", "self", ".", "blocks", "(", "x", ")", "\n", "\n", "cls_tokens", "=", "x", "[", ":", ",", ":", "token_length", "]", "\n", "x", "=", "x", "[", ":", ",", "token_length", ":", "]", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "C", ",", "H", ",", "W", ")", "\n", "\n", "if", "self", ".", "pool", "is", "not", "None", ":", "\n", "            ", "x", ",", "cls_tokens", "=", "self", ".", "pool", "(", "x", ",", "cls_tokens", ")", "\n", "", "return", "x", ",", "cls_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.ConvHeadPooling.__init__": [[119, 126], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_feature", ",", "out_feature", ",", "stride", ",", "padding_mode", "=", "'zeros'", ")", ":", "\n", "        ", "super", "(", "ConvHeadPooling", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "\n", "in_feature", ",", "out_feature", ",", "kernel_size", "=", "stride", "+", "1", ",", "padding", "=", "stride", "//", "2", ",", "stride", "=", "stride", ",", "\n", "padding_mode", "=", "padding_mode", ",", "groups", "=", "in_feature", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "in_feature", ",", "out_feature", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.ConvHeadPooling.forward": [[127, 131], ["pit.ConvHeadPooling.conv", "pit.ConvHeadPooling.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "cls_token", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "cls_token", "=", "self", ".", "fc", "(", "cls_token", ")", "\n", "return", "x", ",", "cls_token", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.ConvEmbedding.__init__": [[134, 138], ["torch.nn.Module.__init__", "torch.nn.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "patch_size", ",", "stride", ",", "padding", ")", ":", "\n", "        ", "super", "(", "ConvEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.ConvEmbedding.forward": [[139, 142], ["pit.ConvEmbedding.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.PoolingVisionTransformer.__init__": [[150, 202], ["torch.nn.Module.__init__", "layers.to_2tuple", "layers.to_2tuple", "math.floor", "math.floor", "torch.nn.Parameter", "pit.ConvEmbedding", "torch.nn.Parameter", "torch.nn.Dropout", "range", "pit.SequentialTuple", "torch.nn.LayerNorm", "layers.trunc_normal_", "layers.trunc_normal_", "pit.PoolingVisionTransformer.apply", "torch.randn", "torch.randn", "x.tolist", "len", "torch.nn.Linear", "torch.nn.Identity", "torch.linspace().split", "pit.ConvHeadPooling", "pit.Transformer", "torch.nn.Linear", "torch.nn.Identity", "len", "torch.linspace", "sum"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["def", "__init__", "(", "\n", "self", ",", "img_size", ",", "patch_size", ",", "stride", ",", "base_dims", ",", "depth", ",", "heads", ",", "\n", "mlp_ratio", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "global_pool", "=", "'token'", ",", "\n", "distilled", "=", "False", ",", "attn_drop_rate", "=", ".0", ",", "drop_rate", "=", ".0", ",", "drop_path_rate", "=", ".0", ")", ":", "\n", "        ", "super", "(", "PoolingVisionTransformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "global_pool", "in", "(", "'token'", ",", ")", "\n", "\n", "padding", "=", "0", "\n", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "patch_size", "=", "to_2tuple", "(", "patch_size", ")", "\n", "height", "=", "math", ".", "floor", "(", "(", "img_size", "[", "0", "]", "+", "2", "*", "padding", "-", "patch_size", "[", "0", "]", ")", "/", "stride", "+", "1", ")", "\n", "width", "=", "math", ".", "floor", "(", "(", "img_size", "[", "1", "]", "+", "2", "*", "padding", "-", "patch_size", "[", "1", "]", ")", "/", "stride", "+", "1", ")", "\n", "\n", "self", ".", "base_dims", "=", "base_dims", "\n", "self", ".", "heads", "=", "heads", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "self", ".", "num_tokens", "=", "2", "if", "distilled", "else", "1", "\n", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "self", ".", "pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "1", ",", "base_dims", "[", "0", "]", "*", "heads", "[", "0", "]", ",", "height", ",", "width", ")", ")", "\n", "self", ".", "patch_embed", "=", "ConvEmbedding", "(", "in_chans", ",", "base_dims", "[", "0", "]", "*", "heads", "[", "0", "]", ",", "patch_size", ",", "stride", ",", "padding", ")", "\n", "\n", "self", ".", "cls_token", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "1", ",", "self", ".", "num_tokens", ",", "base_dims", "[", "0", "]", "*", "heads", "[", "0", "]", ")", ")", "\n", "self", ".", "pos_drop", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", "\n", "\n", "transformers", "=", "[", "]", "\n", "# stochastic depth decay rule", "\n", "dpr", "=", "[", "x", ".", "tolist", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "sum", "(", "depth", ")", ")", ".", "split", "(", "depth", ")", "]", "\n", "for", "stage", "in", "range", "(", "len", "(", "depth", ")", ")", ":", "\n", "            ", "pool", "=", "None", "\n", "if", "stage", "<", "len", "(", "heads", ")", "-", "1", ":", "\n", "                ", "pool", "=", "ConvHeadPooling", "(", "\n", "base_dims", "[", "stage", "]", "*", "heads", "[", "stage", "]", ",", "base_dims", "[", "stage", "+", "1", "]", "*", "heads", "[", "stage", "+", "1", "]", ",", "stride", "=", "2", ")", "\n", "", "transformers", "+=", "[", "Transformer", "(", "\n", "base_dims", "[", "stage", "]", ",", "depth", "[", "stage", "]", ",", "heads", "[", "stage", "]", ",", "mlp_ratio", ",", "pool", "=", "pool", ",", "\n", "drop_rate", "=", "drop_rate", ",", "attn_drop_rate", "=", "attn_drop_rate", ",", "drop_path_prob", "=", "dpr", "[", "stage", "]", ")", "\n", "]", "\n", "", "self", ".", "transformers", "=", "SequentialTuple", "(", "*", "transformers", ")", "\n", "self", ".", "norm", "=", "nn", ".", "LayerNorm", "(", "base_dims", "[", "-", "1", "]", "*", "heads", "[", "-", "1", "]", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "num_features", "=", "self", ".", "embed_dim", "=", "base_dims", "[", "-", "1", "]", "*", "heads", "[", "-", "1", "]", "\n", "\n", "# Classifier head", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "head_dist", "=", "None", "\n", "if", "distilled", ":", "\n", "            ", "self", ".", "head_dist", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "", "self", ".", "distilled_training", "=", "False", "# must set this True to train w/ distillation token", "\n", "\n", "trunc_normal_", "(", "self", ".", "pos_embed", ",", "std", "=", ".02", ")", "\n", "trunc_normal_", "(", "self", ".", "cls_token", ",", "std", "=", ".02", ")", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.PoolingVisionTransformer._init_weights": [[203, 207], ["isinstance", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.PoolingVisionTransformer.no_weight_decay": [[208, 211], ["None"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "{", "'pos_embed'", ",", "'cls_token'", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.PoolingVisionTransformer.set_distilled_training": [[212, 215], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_distilled_training", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "distilled_training", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.PoolingVisionTransformer.set_grad_checkpointing": [[216, 219], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "'gradient checkpointing not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.PoolingVisionTransformer.get_classifier": [[220, 225], ["None"], "methods", ["None"], ["", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "head_dist", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "head", ",", "self", ".", "head_dist", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.PoolingVisionTransformer.reset_classifier": [[226, 231], ["torch.nn.Linear", "torch.nn.Identity", "torch.nn.Linear", "torch.nn.Identity"], "methods", ["None"], ["", "", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "None", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "if", "self", ".", "head_dist", "is", "not", "None", ":", "\n", "            ", "self", ".", "head_dist", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.PoolingVisionTransformer.forward_features": [[232, 239], ["pit.PoolingVisionTransformer.patch_embed", "pit.PoolingVisionTransformer.pos_drop", "pit.PoolingVisionTransformer.cls_token.expand", "pit.PoolingVisionTransformer.transformers", "pit.PoolingVisionTransformer.norm"], "methods", ["None"], ["", "", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "x", "=", "self", ".", "pos_drop", "(", "x", "+", "self", ".", "pos_embed", ")", "\n", "cls_tokens", "=", "self", ".", "cls_token", ".", "expand", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "-", "1", ")", "\n", "x", ",", "cls_tokens", "=", "self", ".", "transformers", "(", "(", "x", ",", "cls_tokens", ")", ")", "\n", "cls_tokens", "=", "self", ".", "norm", "(", "cls_tokens", ")", "\n", "return", "cls_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.PoolingVisionTransformer.forward_head": [[240, 259], ["pit.PoolingVisionTransformer.head", "pit.PoolingVisionTransformer.head_dist", "pit.PoolingVisionTransformer.head", "torch.jit.is_scripting"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "self", ".", "head_dist", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "global_pool", "==", "'token'", "\n", "x", ",", "x_dist", "=", "x", "[", ":", ",", "0", "]", ",", "x", "[", ":", ",", "1", "]", "\n", "if", "not", "pre_logits", ":", "\n", "                ", "x", "=", "self", ".", "head", "(", "x", ")", "\n", "x_dist", "=", "self", ".", "head_dist", "(", "x_dist", ")", "\n", "", "if", "self", ".", "distilled_training", "and", "self", ".", "training", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "# only return separate classification predictions when training in distilled mode", "\n", "                ", "return", "x", ",", "x_dist", "\n", "", "else", ":", "\n", "# during standard train / finetune, inference average the classifier predictions", "\n", "                ", "return", "(", "x", "+", "x_dist", ")", "/", "2", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "global_pool", "==", "'token'", ":", "\n", "                ", "x", "=", "x", "[", ":", ",", "0", "]", "\n", "", "if", "not", "pre_logits", ":", "\n", "                ", "x", "=", "self", ".", "head", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.PoolingVisionTransformer.forward": [[260, 264], ["pit.PoolingVisionTransformer.forward_features", "pit.PoolingVisionTransformer.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit._cfg": [[30, 38], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", ".9", ",", "'interpolation'", ":", "'bicubic'", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'patch_embed.conv'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.checkpoint_filter_fn": [[266, 278], ["re.compile", "state_dict.items", "re.compile.sub", "int", "exp.group"], "function", ["None"], ["", "", "def", "checkpoint_filter_fn", "(", "state_dict", ",", "model", ")", ":", "\n", "    ", "\"\"\" preprocess checkpoints \"\"\"", "\n", "out_dict", "=", "{", "}", "\n", "p_blocks", "=", "re", ".", "compile", "(", "r'pools\\.(\\d)\\.'", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "# FIXME need to update resize for PiT impl", "\n", "# if k == 'pos_embed' and v.shape != model.pos_embed.shape:", "\n", "#     # To resize pos embedding when using model at different size from pretrained weights", "\n", "#     v = resize_pos_embed(v, model.pos_embed)", "\n", "        ", "k", "=", "p_blocks", ".", "sub", "(", "lambda", "exp", ":", "f'transformers.{int(exp.group(1))}.pool.'", ",", "k", ")", "\n", "out_dict", "[", "k", "]", "=", "v", "\n", "", "return", "out_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit._create_pit": [[280, 289], ["kwargs.get", "helpers.build_model_with_cfg", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "def", "_create_pit", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", ".", "get", "(", "'features_only'", ",", "None", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'features_only not implemented for Vision Transformer models.'", ")", "\n", "\n", "", "model", "=", "build_model_with_cfg", "(", "\n", "PoolingVisionTransformer", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_filter_fn", "=", "checkpoint_filter_fn", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.pit_b_224": [[291, 303], ["dict", "pit._create_pit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit._create_pit"], ["", "@", "register_model", "\n", "def", "pit_b_224", "(", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "14", ",", "\n", "stride", "=", "7", ",", "\n", "base_dims", "=", "[", "64", ",", "64", ",", "64", "]", ",", "\n", "depth", "=", "[", "3", ",", "6", ",", "4", "]", ",", "\n", "heads", "=", "[", "4", ",", "8", ",", "16", "]", ",", "\n", "mlp_ratio", "=", "4", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_pit", "(", "'pit_b_224'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.pit_s_224": [[305, 317], ["dict", "pit._create_pit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit._create_pit"], ["", "@", "register_model", "\n", "def", "pit_s_224", "(", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "\n", "stride", "=", "8", ",", "\n", "base_dims", "=", "[", "48", ",", "48", ",", "48", "]", ",", "\n", "depth", "=", "[", "2", ",", "6", ",", "4", "]", ",", "\n", "heads", "=", "[", "3", ",", "6", ",", "12", "]", ",", "\n", "mlp_ratio", "=", "4", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_pit", "(", "'pit_s_224'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.pit_xs_224": [[319, 331], ["dict", "pit._create_pit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit._create_pit"], ["", "@", "register_model", "\n", "def", "pit_xs_224", "(", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "\n", "stride", "=", "8", ",", "\n", "base_dims", "=", "[", "48", ",", "48", ",", "48", "]", ",", "\n", "depth", "=", "[", "2", ",", "6", ",", "4", "]", ",", "\n", "heads", "=", "[", "2", ",", "4", ",", "8", "]", ",", "\n", "mlp_ratio", "=", "4", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_pit", "(", "'pit_xs_224'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.pit_ti_224": [[333, 345], ["dict", "pit._create_pit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit._create_pit"], ["", "@", "register_model", "\n", "def", "pit_ti_224", "(", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "\n", "stride", "=", "8", ",", "\n", "base_dims", "=", "[", "32", ",", "32", ",", "32", "]", ",", "\n", "depth", "=", "[", "2", ",", "6", ",", "4", "]", ",", "\n", "heads", "=", "[", "2", ",", "4", ",", "8", "]", ",", "\n", "mlp_ratio", "=", "4", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_pit", "(", "'pit_ti_224'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.pit_b_distilled_224": [[347, 360], ["dict", "pit._create_pit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit._create_pit"], ["", "@", "register_model", "\n", "def", "pit_b_distilled_224", "(", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "14", ",", "\n", "stride", "=", "7", ",", "\n", "base_dims", "=", "[", "64", ",", "64", ",", "64", "]", ",", "\n", "depth", "=", "[", "3", ",", "6", ",", "4", "]", ",", "\n", "heads", "=", "[", "4", ",", "8", ",", "16", "]", ",", "\n", "mlp_ratio", "=", "4", ",", "\n", "distilled", "=", "True", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_pit", "(", "'pit_b_distilled_224'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.pit_s_distilled_224": [[362, 375], ["dict", "pit._create_pit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit._create_pit"], ["", "@", "register_model", "\n", "def", "pit_s_distilled_224", "(", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "\n", "stride", "=", "8", ",", "\n", "base_dims", "=", "[", "48", ",", "48", ",", "48", "]", ",", "\n", "depth", "=", "[", "2", ",", "6", ",", "4", "]", ",", "\n", "heads", "=", "[", "3", ",", "6", ",", "12", "]", ",", "\n", "mlp_ratio", "=", "4", ",", "\n", "distilled", "=", "True", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_pit", "(", "'pit_s_distilled_224'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.pit_xs_distilled_224": [[377, 390], ["dict", "pit._create_pit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit._create_pit"], ["", "@", "register_model", "\n", "def", "pit_xs_distilled_224", "(", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "\n", "stride", "=", "8", ",", "\n", "base_dims", "=", "[", "48", ",", "48", ",", "48", "]", ",", "\n", "depth", "=", "[", "2", ",", "6", ",", "4", "]", ",", "\n", "heads", "=", "[", "2", ",", "4", ",", "8", "]", ",", "\n", "mlp_ratio", "=", "4", ",", "\n", "distilled", "=", "True", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_pit", "(", "'pit_xs_distilled_224'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit.pit_ti_distilled_224": [[392, 405], ["dict", "pit._create_pit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.pit._create_pit"], ["", "@", "register_model", "\n", "def", "pit_ti_distilled_224", "(", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "\n", "stride", "=", "8", ",", "\n", "base_dims", "=", "[", "32", ",", "32", ",", "32", "]", ",", "\n", "depth", "=", "[", "2", ",", "6", ",", "4", "]", ",", "\n", "heads", "=", "[", "2", ",", "4", ",", "8", "]", ",", "\n", "mlp_ratio", "=", "4", ",", "\n", "distilled", "=", "True", ",", "\n", "**", "kwargs", "\n", ")", "\n", "return", "_create_pit", "(", "'pit_ti_distilled_224'", ",", "pretrained", ",", "**", "model_kwargs", ")", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.MobileNetV3.__init__": [[125, 162], ["torch.Module.__init__", "layers.get_norm_act_layer", "layers.create_conv2d", "layers.get_norm_act_layer.", "efficientnet_builder.EfficientNetBuilder", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.SelectAdaptivePool2d", "layers.create_conv2d", "act_layer", "efficientnet_builder.efficientnet_init_weights", "round_chs_fn", "mobilenetv3.MobileNetV3.global_pool.feat_mult", "torch.Flatten", "torch.Flatten", "torch.Flatten", "torch.Identity", "torch.Identity", "torch.Identity", "layers.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "efficientnet_builder.EfficientNetBuilder."], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.efficientnet_init_weights", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.SelectAdaptivePool2d.feat_mult"], ["def", "__init__", "(", "\n", "self", ",", "block_args", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "stem_size", "=", "16", ",", "fix_stem", "=", "False", ",", "num_features", "=", "1280", ",", "\n", "head_bias", "=", "True", ",", "pad_type", "=", "''", ",", "act_layer", "=", "None", ",", "norm_layer", "=", "None", ",", "se_layer", "=", "None", ",", "se_from_exp", "=", "True", ",", "\n", "round_chs_fn", "=", "round_channels", ",", "drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "super", "(", "MobileNetV3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "act_layer", "=", "act_layer", "or", "nn", ".", "ReLU", "\n", "norm_layer", "=", "norm_layer", "or", "nn", ".", "BatchNorm2d", "\n", "norm_act_layer", "=", "get_norm_act_layer", "(", "norm_layer", ",", "act_layer", ")", "\n", "se_layer", "=", "se_layer", "or", "SqueezeExcite", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "# Stem", "\n", "if", "not", "fix_stem", ":", "\n", "            ", "stem_size", "=", "round_chs_fn", "(", "stem_size", ")", "\n", "", "self", ".", "conv_stem", "=", "create_conv2d", "(", "in_chans", ",", "stem_size", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "bn1", "=", "norm_act_layer", "(", "stem_size", ",", "inplace", "=", "True", ")", "\n", "\n", "# Middle stages (IR/ER/DS Blocks)", "\n", "builder", "=", "EfficientNetBuilder", "(", "\n", "output_stride", "=", "32", ",", "pad_type", "=", "pad_type", ",", "round_chs_fn", "=", "round_chs_fn", ",", "se_from_exp", "=", "se_from_exp", ",", "\n", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ",", "se_layer", "=", "se_layer", ",", "drop_path_rate", "=", "drop_path_rate", ")", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "*", "builder", "(", "stem_size", ",", "block_args", ")", ")", "\n", "self", ".", "feature_info", "=", "builder", ".", "features", "\n", "head_chs", "=", "builder", ".", "in_chs", "\n", "\n", "# Head + Pooling", "\n", "self", ".", "global_pool", "=", "SelectAdaptivePool2d", "(", "pool_type", "=", "global_pool", ")", "\n", "num_pooled_chs", "=", "head_chs", "*", "self", ".", "global_pool", ".", "feat_mult", "(", ")", "\n", "self", ".", "conv_head", "=", "create_conv2d", "(", "num_pooled_chs", ",", "self", ".", "num_features", ",", "1", ",", "padding", "=", "pad_type", ",", "bias", "=", "head_bias", ")", "\n", "self", ".", "act2", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "flatten", "=", "nn", ".", "Flatten", "(", "1", ")", "if", "global_pool", "else", "nn", ".", "Identity", "(", ")", "# don't flatten if pooling disabled", "\n", "self", ".", "classifier", "=", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "efficientnet_init_weights", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.MobileNetV3.as_sequential": [[163, 169], ["layers.extend", "layers.extend", "layers.extend", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Flatten", "torch.Flatten", "torch.Flatten", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["None"], ["", "def", "as_sequential", "(", "self", ")", ":", "\n", "        ", "layers", "=", "[", "self", ".", "conv_stem", ",", "self", ".", "bn1", "]", "\n", "layers", ".", "extend", "(", "self", ".", "blocks", ")", "\n", "layers", ".", "extend", "(", "[", "self", ".", "global_pool", ",", "self", ".", "conv_head", ",", "self", ".", "act2", "]", ")", "\n", "layers", ".", "extend", "(", "[", "nn", ".", "Flatten", "(", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "drop_rate", ")", ",", "self", ".", "classifier", "]", ")", "\n", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.MobileNetV3.group_matcher": [[170, 175], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^conv_stem|bn1'", ",", "\n", "blocks", "=", "r'^blocks\\.(\\d+)'", "if", "coarse", "else", "r'^blocks\\.(\\d+)\\.(\\d+)'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.MobileNetV3.set_grad_checkpointing": [[177, 180], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.MobileNetV3.get_classifier": [[181, 184], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.MobileNetV3.reset_classifier": [[185, 191], ["layers.SelectAdaptivePool2d", "torch.Flatten", "torch.Flatten", "torch.Flatten", "torch.Identity", "torch.Identity", "torch.Identity", "layers.Linear", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "# cannot meaningfully change pooling of efficient head after creation", "\n", "self", ".", "global_pool", "=", "SelectAdaptivePool2d", "(", "pool_type", "=", "global_pool", ")", "\n", "self", ".", "flatten", "=", "nn", ".", "Flatten", "(", "1", ")", "if", "global_pool", "else", "nn", ".", "Identity", "(", ")", "# don't flatten if pooling disabled", "\n", "self", ".", "classifier", "=", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.MobileNetV3.forward_features": [[192, 200], ["mobilenetv3.MobileNetV3.conv_stem", "mobilenetv3.MobileNetV3.bn1", "helpers.checkpoint_seq", "mobilenetv3.MobileNetV3.blocks", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv_stem", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "blocks", ",", "x", ",", "flatten", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "blocks", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.MobileNetV3.forward_head": [[201, 212], ["mobilenetv3.MobileNetV3.global_pool", "mobilenetv3.MobileNetV3.conv_head", "mobilenetv3.MobileNetV3.act2", "torch.dropout.flatten", "mobilenetv3.MobileNetV3.flatten", "mobilenetv3.MobileNetV3.classifier", "torch.dropout", "torch.dropout", "torch.dropout"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_head", "(", "x", ")", "\n", "x", "=", "self", ".", "act2", "(", "x", ")", "\n", "if", "pre_logits", ":", "\n", "            ", "return", "x", ".", "flatten", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "flatten", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ">", "0.", ":", "\n", "                ", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "self", ".", "classifier", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.MobileNetV3.forward": [[213, 217], ["mobilenetv3.MobileNetV3.forward_features", "mobilenetv3.MobileNetV3.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.MobileNetV3Features.__init__": [[226, 259], ["torch.Module.__init__", "layers.create_conv2d", "norm_layer", "act_layer", "efficientnet_builder.EfficientNetBuilder", "torch.Sequential", "torch.Sequential", "torch.Sequential", "features.FeatureInfo", "efficientnet_builder.efficientnet_init_weights", "round_chs_fn", "mobilenetv3.MobileNetV3Features.feature_info.get_dicts", "features.FeatureHooks", "efficientnet_builder.EfficientNetBuilder.", "enumerate", "mobilenetv3.MobileNetV3Features.named_modules"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.efficientnet_init_weights", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get_dicts", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules"], ["def", "__init__", "(", "\n", "self", ",", "block_args", ",", "out_indices", "=", "(", "0", ",", "1", ",", "2", ",", "3", ",", "4", ")", ",", "feature_location", "=", "'bottleneck'", ",", "in_chans", "=", "3", ",", "\n", "stem_size", "=", "16", ",", "fix_stem", "=", "False", ",", "output_stride", "=", "32", ",", "pad_type", "=", "''", ",", "round_chs_fn", "=", "round_channels", ",", "\n", "se_from_exp", "=", "True", ",", "act_layer", "=", "None", ",", "norm_layer", "=", "None", ",", "se_layer", "=", "None", ",", "drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", "MobileNetV3Features", ",", "self", ")", ".", "__init__", "(", ")", "\n", "act_layer", "=", "act_layer", "or", "nn", ".", "ReLU", "\n", "norm_layer", "=", "norm_layer", "or", "nn", ".", "BatchNorm2d", "\n", "se_layer", "=", "se_layer", "or", "SqueezeExcite", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "\n", "# Stem", "\n", "if", "not", "fix_stem", ":", "\n", "            ", "stem_size", "=", "round_chs_fn", "(", "stem_size", ")", "\n", "", "self", ".", "conv_stem", "=", "create_conv2d", "(", "in_chans", ",", "stem_size", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "stem_size", ")", "\n", "self", ".", "act1", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "\n", "# Middle stages (IR/ER/DS Blocks)", "\n", "builder", "=", "EfficientNetBuilder", "(", "\n", "output_stride", "=", "output_stride", ",", "pad_type", "=", "pad_type", ",", "round_chs_fn", "=", "round_chs_fn", ",", "se_from_exp", "=", "se_from_exp", ",", "\n", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ",", "se_layer", "=", "se_layer", ",", "\n", "drop_path_rate", "=", "drop_path_rate", ",", "feature_location", "=", "feature_location", ")", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "*", "builder", "(", "stem_size", ",", "block_args", ")", ")", "\n", "self", ".", "feature_info", "=", "FeatureInfo", "(", "builder", ".", "features", ",", "out_indices", ")", "\n", "self", ".", "_stage_out_idx", "=", "{", "v", "[", "'stage'", "]", ":", "i", "for", "i", ",", "v", "in", "enumerate", "(", "self", ".", "feature_info", ")", "if", "i", "in", "out_indices", "}", "\n", "\n", "efficientnet_init_weights", "(", "self", ")", "\n", "\n", "# Register feature extraction hooks with FeatureHooks helper", "\n", "self", ".", "feature_hooks", "=", "None", "\n", "if", "feature_location", "!=", "'bottleneck'", ":", "\n", "            ", "hooks", "=", "self", ".", "feature_info", ".", "get_dicts", "(", "keys", "=", "(", "'module'", ",", "'hook_type'", ")", ")", "\n", "self", ".", "feature_hooks", "=", "FeatureHooks", "(", "hooks", ",", "self", ".", "named_modules", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.MobileNetV3Features.forward": [[260, 277], ["mobilenetv3.MobileNetV3Features.conv_stem", "mobilenetv3.MobileNetV3Features.bn1", "mobilenetv3.MobileNetV3Features.act1", "enumerate", "mobilenetv3.MobileNetV3Features.blocks", "mobilenetv3.MobileNetV3Features.feature_hooks.get_output", "list", "features.append", "b", "mobilenetv3.MobileNetV3Features.values", "features.append"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureHooks.get_output"], ["", "", "def", "forward", "(", "self", ",", "x", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "        ", "x", "=", "self", ".", "conv_stem", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "act1", "(", "x", ")", "\n", "if", "self", ".", "feature_hooks", "is", "None", ":", "\n", "            ", "features", "=", "[", "]", "\n", "if", "0", "in", "self", ".", "_stage_out_idx", ":", "\n", "                ", "features", ".", "append", "(", "x", ")", "# add stem out", "\n", "", "for", "i", ",", "b", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "                ", "x", "=", "b", "(", "x", ")", "\n", "if", "i", "+", "1", "in", "self", ".", "_stage_out_idx", ":", "\n", "                    ", "features", ".", "append", "(", "x", ")", "\n", "", "", "return", "features", "\n", "", "else", ":", "\n", "            ", "self", ".", "blocks", "(", "x", ")", "\n", "out", "=", "self", ".", "feature_hooks", ".", "get_output", "(", "x", ".", "device", ")", "\n", "return", "list", "(", "out", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._cfg": [[28, 35], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bilinear'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'conv_stem'", ",", "'classifier'", ":", "'classifier'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._create_mnv3": [[279, 295], ["kwargs.pop", "helpers.build_model_with_cfg", "helpers.pretrained_cfg_for_features"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.pretrained_cfg_for_features"], ["", "", "", "def", "_create_mnv3", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "features_only", "=", "False", "\n", "model_cls", "=", "MobileNetV3", "\n", "kwargs_filter", "=", "None", "\n", "if", "kwargs", ".", "pop", "(", "'features_only'", ",", "False", ")", ":", "\n", "        ", "features_only", "=", "True", "\n", "kwargs_filter", "=", "(", "'num_classes'", ",", "'num_features'", ",", "'head_conv'", ",", "'head_bias'", ",", "'global_pool'", ")", "\n", "model_cls", "=", "MobileNetV3Features", "\n", "", "model", "=", "build_model_with_cfg", "(", "\n", "model_cls", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_strict", "=", "not", "features_only", ",", "\n", "kwargs_filter", "=", "kwargs_filter", ",", "\n", "**", "kwargs", ")", "\n", "if", "features_only", ":", "\n", "        ", "model", ".", "default_cfg", "=", "pretrained_cfg_for_features", "(", "model", ".", "default_cfg", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_mobilenet_v3_rw": [[297, 333], ["dict", "mobilenetv3._create_mnv3", "efficientnet_builder.decode_arch_def", "functools.partial", "functools.partial", "efficientnet_builder.resolve_act_layer", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._create_mnv3", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_mobilenet_v3_rw", "(", "variant", ",", "channel_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a MobileNet-V3 model.\n\n    Ref impl: ?\n    Paper: https://arxiv.org/abs/1905.02244\n\n    Args:\n      channel_multiplier: multiplier to number of channels per layer.\n    \"\"\"", "\n", "arch_def", "=", "[", "\n", "# stage 0, 112x112 in", "\n", "[", "'ds_r1_k3_s1_e1_c16_nre_noskip'", "]", ",", "# relu", "\n", "# stage 1, 112x112 in", "\n", "[", "'ir_r1_k3_s2_e4_c24_nre'", ",", "'ir_r1_k3_s1_e3_c24_nre'", "]", ",", "# relu", "\n", "# stage 2, 56x56 in", "\n", "[", "'ir_r3_k5_s2_e3_c40_se0.25_nre'", "]", ",", "# relu", "\n", "# stage 3, 28x28 in", "\n", "[", "'ir_r1_k3_s2_e6_c80'", ",", "'ir_r1_k3_s1_e2.5_c80'", ",", "'ir_r2_k3_s1_e2.3_c80'", "]", ",", "# hard-swish", "\n", "# stage 4, 14x14in", "\n", "[", "'ir_r2_k3_s1_e6_c112_se0.25'", "]", ",", "# hard-swish", "\n", "# stage 5, 14x14in", "\n", "[", "'ir_r3_k5_s2_e6_c160_se0.25'", "]", ",", "# hard-swish", "\n", "# stage 6, 7x7 in", "\n", "[", "'cn_r1_k1_s1_c960'", "]", ",", "# hard-swish", "\n", "]", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ")", ",", "\n", "head_bias", "=", "False", ",", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'hard_swish'", ")", ",", "\n", "se_layer", "=", "partial", "(", "SqueezeExcite", ",", "gate_layer", "=", "'hard_sigmoid'", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_mnv3", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_mobilenet_v3": [[335, 430], ["functools.partial", "dict", "mobilenetv3._create_mnv3", "efficientnet_builder.resolve_act_layer", "efficientnet_builder.resolve_act_layer", "efficientnet_builder.resolve_act_layer", "efficientnet_builder.resolve_act_layer", "efficientnet_builder.decode_arch_def", "functools.partial", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._create_mnv3", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_mobilenet_v3", "(", "variant", ",", "channel_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a MobileNet-V3 model.\n\n    Ref impl: ?\n    Paper: https://arxiv.org/abs/1905.02244\n\n    Args:\n      channel_multiplier: multiplier to number of channels per layer.\n    \"\"\"", "\n", "if", "'small'", "in", "variant", ":", "\n", "        ", "num_features", "=", "1024", "\n", "if", "'minimal'", "in", "variant", ":", "\n", "            ", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'relu'", ")", "\n", "arch_def", "=", "[", "\n", "# stage 0, 112x112 in", "\n", "[", "'ds_r1_k3_s2_e1_c16'", "]", ",", "\n", "# stage 1, 56x56 in", "\n", "[", "'ir_r1_k3_s2_e4.5_c24'", ",", "'ir_r1_k3_s1_e3.67_c24'", "]", ",", "\n", "# stage 2, 28x28 in", "\n", "[", "'ir_r1_k3_s2_e4_c40'", ",", "'ir_r2_k3_s1_e6_c40'", "]", ",", "\n", "# stage 3, 14x14 in", "\n", "[", "'ir_r2_k3_s1_e3_c48'", "]", ",", "\n", "# stage 4, 14x14in", "\n", "[", "'ir_r3_k3_s2_e6_c96'", "]", ",", "\n", "# stage 6, 7x7 in", "\n", "[", "'cn_r1_k1_s1_c576'", "]", ",", "\n", "]", "\n", "", "else", ":", "\n", "            ", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'hard_swish'", ")", "\n", "arch_def", "=", "[", "\n", "# stage 0, 112x112 in", "\n", "[", "'ds_r1_k3_s2_e1_c16_se0.25_nre'", "]", ",", "# relu", "\n", "# stage 1, 56x56 in", "\n", "[", "'ir_r1_k3_s2_e4.5_c24_nre'", ",", "'ir_r1_k3_s1_e3.67_c24_nre'", "]", ",", "# relu", "\n", "# stage 2, 28x28 in", "\n", "[", "'ir_r1_k5_s2_e4_c40_se0.25'", ",", "'ir_r2_k5_s1_e6_c40_se0.25'", "]", ",", "# hard-swish", "\n", "# stage 3, 14x14 in", "\n", "[", "'ir_r2_k5_s1_e3_c48_se0.25'", "]", ",", "# hard-swish", "\n", "# stage 4, 14x14in", "\n", "[", "'ir_r3_k5_s2_e6_c96_se0.25'", "]", ",", "# hard-swish", "\n", "# stage 6, 7x7 in", "\n", "[", "'cn_r1_k1_s1_c576'", "]", ",", "# hard-swish", "\n", "]", "\n", "", "", "else", ":", "\n", "        ", "num_features", "=", "1280", "\n", "if", "'minimal'", "in", "variant", ":", "\n", "            ", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'relu'", ")", "\n", "arch_def", "=", "[", "\n", "# stage 0, 112x112 in", "\n", "[", "'ds_r1_k3_s1_e1_c16'", "]", ",", "\n", "# stage 1, 112x112 in", "\n", "[", "'ir_r1_k3_s2_e4_c24'", ",", "'ir_r1_k3_s1_e3_c24'", "]", ",", "\n", "# stage 2, 56x56 in", "\n", "[", "'ir_r3_k3_s2_e3_c40'", "]", ",", "\n", "# stage 3, 28x28 in", "\n", "[", "'ir_r1_k3_s2_e6_c80'", ",", "'ir_r1_k3_s1_e2.5_c80'", ",", "'ir_r2_k3_s1_e2.3_c80'", "]", ",", "\n", "# stage 4, 14x14in", "\n", "[", "'ir_r2_k3_s1_e6_c112'", "]", ",", "\n", "# stage 5, 14x14in", "\n", "[", "'ir_r3_k3_s2_e6_c160'", "]", ",", "\n", "# stage 6, 7x7 in", "\n", "[", "'cn_r1_k1_s1_c960'", "]", ",", "\n", "]", "\n", "", "else", ":", "\n", "            ", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'hard_swish'", ")", "\n", "arch_def", "=", "[", "\n", "# stage 0, 112x112 in", "\n", "[", "'ds_r1_k3_s1_e1_c16_nre'", "]", ",", "# relu", "\n", "# stage 1, 112x112 in", "\n", "[", "'ir_r1_k3_s2_e4_c24_nre'", ",", "'ir_r1_k3_s1_e3_c24_nre'", "]", ",", "# relu", "\n", "# stage 2, 56x56 in", "\n", "[", "'ir_r3_k5_s2_e3_c40_se0.25_nre'", "]", ",", "# relu", "\n", "# stage 3, 28x28 in", "\n", "[", "'ir_r1_k3_s2_e6_c80'", ",", "'ir_r1_k3_s1_e2.5_c80'", ",", "'ir_r2_k3_s1_e2.3_c80'", "]", ",", "# hard-swish", "\n", "# stage 4, 14x14in", "\n", "[", "'ir_r2_k3_s1_e6_c112_se0.25'", "]", ",", "# hard-swish", "\n", "# stage 5, 14x14in", "\n", "[", "'ir_r3_k5_s2_e6_c160_se0.25'", "]", ",", "# hard-swish", "\n", "# stage 6, 7x7 in", "\n", "[", "'cn_r1_k1_s1_c960'", "]", ",", "# hard-swish", "\n", "]", "\n", "", "", "se_layer", "=", "partial", "(", "SqueezeExcite", ",", "gate_layer", "=", "'hard_sigmoid'", ",", "force_act_layer", "=", "nn", ".", "ReLU", ",", "rd_round_fn", "=", "round_channels", ")", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ")", ",", "\n", "num_features", "=", "num_features", ",", "\n", "stem_size", "=", "16", ",", "\n", "fix_stem", "=", "channel_multiplier", "<", "0.75", ",", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "act_layer", "=", "act_layer", ",", "\n", "se_layer", "=", "se_layer", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_mnv3", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_fbnetv3": [[432, 491], ["functools.partial", "functools.partial", "efficientnet_builder.resolve_act_layer", "dict", "mobilenetv3._create_mnv3", "variant.split", "efficientnet_builder.decode_arch_def", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._create_mnv3", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_fbnetv3", "(", "variant", ",", "channel_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" FBNetV3\n    Paper: `FBNetV3: Joint Architecture-Recipe Search using Predictor Pretraining`\n        - https://arxiv.org/abs/2006.02049\n    FIXME untested, this is a preliminary impl of some FBNet-V3 variants.\n    \"\"\"", "\n", "vl", "=", "variant", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "\n", "if", "vl", "in", "(", "'a'", ",", "'b'", ")", ":", "\n", "        ", "stem_size", "=", "16", "\n", "arch_def", "=", "[", "\n", "[", "'ds_r2_k3_s1_e1_c16'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e4_c24'", ",", "'ir_r3_k5_s1_e2_c24'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e5_c40_se0.25'", ",", "'ir_r4_k5_s1_e3_c40_se0.25'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e5_c72'", ",", "'ir_r4_k3_s1_e3_c72'", "]", ",", "\n", "[", "'ir_r1_k3_s1_e5_c120_se0.25'", ",", "'ir_r5_k5_s1_e3_c120_se0.25'", "]", ",", "\n", "[", "'ir_r1_k3_s2_e6_c184_se0.25'", ",", "'ir_r5_k5_s1_e4_c184_se0.25'", ",", "'ir_r1_k5_s1_e6_c224_se0.25'", "]", ",", "\n", "[", "'cn_r1_k1_s1_c1344'", "]", ",", "\n", "]", "\n", "", "elif", "vl", "==", "'d'", ":", "\n", "        ", "stem_size", "=", "24", "\n", "arch_def", "=", "[", "\n", "[", "'ds_r2_k3_s1_e1_c16'", "]", ",", "\n", "[", "'ir_r1_k3_s2_e5_c24'", ",", "'ir_r5_k3_s1_e2_c24'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e4_c40_se0.25'", ",", "'ir_r4_k3_s1_e3_c40_se0.25'", "]", ",", "\n", "[", "'ir_r1_k3_s2_e5_c72'", ",", "'ir_r4_k3_s1_e3_c72'", "]", ",", "\n", "[", "'ir_r1_k3_s1_e5_c128_se0.25'", ",", "'ir_r6_k5_s1_e3_c128_se0.25'", "]", ",", "\n", "[", "'ir_r1_k3_s2_e6_c208_se0.25'", ",", "'ir_r5_k5_s1_e5_c208_se0.25'", ",", "'ir_r1_k5_s1_e6_c240_se0.25'", "]", ",", "\n", "[", "'cn_r1_k1_s1_c1440'", "]", ",", "\n", "]", "\n", "", "elif", "vl", "==", "'g'", ":", "\n", "        ", "stem_size", "=", "32", "\n", "arch_def", "=", "[", "\n", "[", "'ds_r3_k3_s1_e1_c24'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e4_c40'", ",", "'ir_r4_k5_s1_e2_c40'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e4_c56_se0.25'", ",", "'ir_r4_k5_s1_e3_c56_se0.25'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e5_c104'", ",", "'ir_r4_k3_s1_e3_c104'", "]", ",", "\n", "[", "'ir_r1_k3_s1_e5_c160_se0.25'", ",", "'ir_r8_k5_s1_e3_c160_se0.25'", "]", ",", "\n", "[", "'ir_r1_k3_s2_e6_c264_se0.25'", ",", "'ir_r6_k5_s1_e5_c264_se0.25'", ",", "'ir_r2_k5_s1_e6_c288_se0.25'", "]", ",", "\n", "[", "'cn_r1_k1_s1_c1728'", "]", ",", "\n", "]", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplemented", "\n", "", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ",", "round_limit", "=", "0.95", ")", "\n", "se_layer", "=", "partial", "(", "SqueezeExcite", ",", "gate_layer", "=", "'hard_sigmoid'", ",", "rd_round_fn", "=", "round_chs_fn", ")", "\n", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'hard_swish'", ")", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ")", ",", "\n", "num_features", "=", "1984", ",", "\n", "head_bias", "=", "False", ",", "\n", "stem_size", "=", "stem_size", ",", "\n", "round_chs_fn", "=", "round_chs_fn", ",", "\n", "se_from_exp", "=", "False", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "act_layer", "=", "act_layer", ",", "\n", "se_layer", "=", "se_layer", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_mnv3", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_lcnet": [[531, 567], ["dict", "mobilenetv3._create_mnv3", "efficientnet_builder.decode_arch_def", "functools.partial", "functools.partial", "efficientnet_builder.resolve_act_layer", "functools.partial", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._create_mnv3", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["", "def", "_gen_lcnet", "(", "variant", ",", "channel_multiplier", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" LCNet\n    Essentially a MobileNet-V3 crossed with a MobileNet-V1\n\n    Paper: `PP-LCNet: A Lightweight CPU Convolutional Neural Network` - https://arxiv.org/abs/2109.15099\n\n    Args:\n      channel_multiplier: multiplier to number of channels per layer.\n    \"\"\"", "\n", "arch_def", "=", "[", "\n", "# stage 0, 112x112 in", "\n", "[", "'dsa_r1_k3_s1_c32'", "]", ",", "\n", "# stage 1, 112x112 in", "\n", "[", "'dsa_r2_k3_s2_c64'", "]", ",", "\n", "# stage 2, 56x56 in", "\n", "[", "'dsa_r2_k3_s2_c128'", "]", ",", "\n", "# stage 3, 28x28 in", "\n", "[", "'dsa_r1_k3_s2_c256'", ",", "'dsa_r1_k5_s1_c256'", "]", ",", "\n", "# stage 4, 14x14in", "\n", "[", "'dsa_r4_k5_s1_c256'", "]", ",", "\n", "# stage 5, 14x14in", "\n", "[", "'dsa_r2_k5_s2_c512_se0.25'", "]", ",", "\n", "# 7x7", "\n", "]", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ")", ",", "\n", "stem_size", "=", "16", ",", "\n", "round_chs_fn", "=", "partial", "(", "round_channels", ",", "multiplier", "=", "channel_multiplier", ")", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'hard_swish'", ")", ",", "\n", "se_layer", "=", "partial", "(", "SqueezeExcite", ",", "gate_layer", "=", "'hard_sigmoid'", ",", "force_act_layer", "=", "nn", ".", "ReLU", ")", ",", "\n", "num_features", "=", "1280", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", "=", "_create_mnv3", "(", "variant", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.mobilenetv3_large_075": [[569, 574], ["mobilenetv3._gen_mobilenet_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_mobilenet_v3"], ["", "@", "register_model", "\n", "def", "mobilenetv3_large_075", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V3 \"\"\"", "\n", "model", "=", "_gen_mobilenet_v3", "(", "'mobilenetv3_large_075'", ",", "0.75", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.mobilenetv3_large_100": [[576, 581], ["mobilenetv3._gen_mobilenet_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_mobilenet_v3"], ["", "@", "register_model", "\n", "def", "mobilenetv3_large_100", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V3 \"\"\"", "\n", "model", "=", "_gen_mobilenet_v3", "(", "'mobilenetv3_large_100'", ",", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.mobilenetv3_large_100_miil": [[583, 590], ["mobilenetv3._gen_mobilenet_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_mobilenet_v3"], ["", "@", "register_model", "\n", "def", "mobilenetv3_large_100_miil", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V3\n    Weights taken from: https://github.com/Alibaba-MIIL/ImageNet21K\n    \"\"\"", "\n", "model", "=", "_gen_mobilenet_v3", "(", "'mobilenetv3_large_100_miil'", ",", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.mobilenetv3_large_100_miil_in21k": [[592, 599], ["mobilenetv3._gen_mobilenet_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_mobilenet_v3"], ["", "@", "register_model", "\n", "def", "mobilenetv3_large_100_miil_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V3, 21k pretraining\n    Weights taken from: https://github.com/Alibaba-MIIL/ImageNet21K\n    \"\"\"", "\n", "model", "=", "_gen_mobilenet_v3", "(", "'mobilenetv3_large_100_miil_in21k'", ",", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.mobilenetv3_small_050": [[601, 606], ["mobilenetv3._gen_mobilenet_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_mobilenet_v3"], ["", "@", "register_model", "\n", "def", "mobilenetv3_small_050", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V3 \"\"\"", "\n", "model", "=", "_gen_mobilenet_v3", "(", "'mobilenetv3_small_050'", ",", "0.50", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.mobilenetv3_small_075": [[608, 613], ["mobilenetv3._gen_mobilenet_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_mobilenet_v3"], ["", "@", "register_model", "\n", "def", "mobilenetv3_small_075", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V3 \"\"\"", "\n", "model", "=", "_gen_mobilenet_v3", "(", "'mobilenetv3_small_075'", ",", "0.75", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.mobilenetv3_small_100": [[615, 620], ["mobilenetv3._gen_mobilenet_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_mobilenet_v3"], ["", "@", "register_model", "\n", "def", "mobilenetv3_small_100", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V3 \"\"\"", "\n", "model", "=", "_gen_mobilenet_v3", "(", "'mobilenetv3_small_100'", ",", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.mobilenetv3_rw": [[622, 630], ["mobilenetv3._gen_mobilenet_v3_rw"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_mobilenet_v3_rw"], ["", "@", "register_model", "\n", "def", "mobilenetv3_rw", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V3 \"\"\"", "\n", "if", "pretrained", ":", "\n", "# pretrained model trained with non-default BN epsilon", "\n", "        ", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "", "model", "=", "_gen_mobilenet_v3_rw", "(", "'mobilenetv3_rw'", ",", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.tf_mobilenetv3_large_075": [[632, 639], ["mobilenetv3._gen_mobilenet_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_mobilenet_v3"], ["", "@", "register_model", "\n", "def", "tf_mobilenetv3_large_075", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V3 \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_mobilenet_v3", "(", "'tf_mobilenetv3_large_075'", ",", "0.75", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.tf_mobilenetv3_large_100": [[641, 648], ["mobilenetv3._gen_mobilenet_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_mobilenet_v3"], ["", "@", "register_model", "\n", "def", "tf_mobilenetv3_large_100", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V3 \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_mobilenet_v3", "(", "'tf_mobilenetv3_large_100'", ",", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.tf_mobilenetv3_large_minimal_100": [[650, 657], ["mobilenetv3._gen_mobilenet_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_mobilenet_v3"], ["", "@", "register_model", "\n", "def", "tf_mobilenetv3_large_minimal_100", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V3 \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_mobilenet_v3", "(", "'tf_mobilenetv3_large_minimal_100'", ",", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.tf_mobilenetv3_small_075": [[659, 666], ["mobilenetv3._gen_mobilenet_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_mobilenet_v3"], ["", "@", "register_model", "\n", "def", "tf_mobilenetv3_small_075", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V3 \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_mobilenet_v3", "(", "'tf_mobilenetv3_small_075'", ",", "0.75", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.tf_mobilenetv3_small_100": [[668, 675], ["mobilenetv3._gen_mobilenet_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_mobilenet_v3"], ["", "@", "register_model", "\n", "def", "tf_mobilenetv3_small_100", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V3 \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_mobilenet_v3", "(", "'tf_mobilenetv3_small_100'", ",", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.tf_mobilenetv3_small_minimal_100": [[677, 684], ["mobilenetv3._gen_mobilenet_v3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_mobilenet_v3"], ["", "@", "register_model", "\n", "def", "tf_mobilenetv3_small_minimal_100", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" MobileNet V3 \"\"\"", "\n", "kwargs", "[", "'bn_eps'", "]", "=", "BN_EPS_TF_DEFAULT", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model", "=", "_gen_mobilenet_v3", "(", "'tf_mobilenetv3_small_minimal_100'", ",", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.fbnetv3_b": [[686, 691], ["mobilenetv3._gen_fbnetv3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_fbnetv3"], ["", "@", "register_model", "\n", "def", "fbnetv3_b", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" FBNetV3-B \"\"\"", "\n", "model", "=", "_gen_fbnetv3", "(", "'fbnetv3_b'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.fbnetv3_d": [[693, 698], ["mobilenetv3._gen_fbnetv3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_fbnetv3"], ["", "@", "register_model", "\n", "def", "fbnetv3_d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" FBNetV3-D \"\"\"", "\n", "model", "=", "_gen_fbnetv3", "(", "'fbnetv3_d'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.fbnetv3_g": [[700, 705], ["mobilenetv3._gen_fbnetv3"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_fbnetv3"], ["", "@", "register_model", "\n", "def", "fbnetv3_g", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" FBNetV3-G \"\"\"", "\n", "model", "=", "_gen_fbnetv3", "(", "'fbnetv3_g'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.lcnet_035": [[707, 712], ["mobilenetv3._gen_lcnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_lcnet"], ["", "@", "register_model", "\n", "def", "lcnet_035", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" PP-LCNet 0.35\"\"\"", "\n", "model", "=", "_gen_lcnet", "(", "'lcnet_035'", ",", "0.35", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.lcnet_050": [[714, 719], ["mobilenetv3._gen_lcnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_lcnet"], ["", "@", "register_model", "\n", "def", "lcnet_050", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" PP-LCNet 0.5\"\"\"", "\n", "model", "=", "_gen_lcnet", "(", "'lcnet_050'", ",", "0.5", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.lcnet_075": [[721, 726], ["mobilenetv3._gen_lcnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_lcnet"], ["", "@", "register_model", "\n", "def", "lcnet_075", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" PP-LCNet 1.0\"\"\"", "\n", "model", "=", "_gen_lcnet", "(", "'lcnet_075'", ",", "0.75", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.lcnet_100": [[728, 733], ["mobilenetv3._gen_lcnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_lcnet"], ["", "@", "register_model", "\n", "def", "lcnet_100", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" PP-LCNet 1.0\"\"\"", "\n", "model", "=", "_gen_lcnet", "(", "'lcnet_100'", ",", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3.lcnet_150": [[735, 740], ["mobilenetv3._gen_lcnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilenetv3._gen_lcnet"], ["", "@", "register_model", "\n", "def", "lcnet_150", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" PP-LCNet 1.5\"\"\"", "\n", "model", "=", "_gen_lcnet", "(", "'lcnet_150'", ",", "1.5", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.CatBnAct.__init__": [[53, 56], ["torch.Module.__init__", "norm_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_chs", ",", "norm_layer", "=", "BatchNormAct2d", ")", ":", "\n", "        ", "super", "(", "CatBnAct", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bn", "=", "norm_layer", "(", "in_chs", ",", "eps", "=", "0.001", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.CatBnAct.forward": [[67, 71], ["isinstance", "dpn.CatBnAct.bn", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "tuple", ")", ":", "\n", "            ", "x", "=", "torch", ".", "cat", "(", "x", ",", "dim", "=", "1", ")", "\n", "", "return", "self", ".", "bn", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.BnActConv2d.__init__": [[74, 78], ["torch.Module.__init__", "norm_layer", "layers.create_conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["    ", "def", "__init__", "(", "self", ",", "in_chs", ",", "out_chs", ",", "kernel_size", ",", "stride", ",", "groups", "=", "1", ",", "norm_layer", "=", "BatchNormAct2d", ")", ":", "\n", "        ", "super", "(", "BnActConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bn", "=", "norm_layer", "(", "in_chs", ",", "eps", "=", "0.001", ")", "\n", "self", ".", "conv", "=", "create_conv2d", "(", "in_chs", ",", "out_chs", ",", "kernel_size", ",", "stride", "=", "stride", ",", "groups", "=", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.BnActConv2d.forward": [[79, 81], ["dpn.BnActConv2d.conv", "dpn.BnActConv2d.bn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "conv", "(", "self", ".", "bn", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.DualPathBlock.__init__": [[84, 123], ["torch.Module.__init__", "dpn.BnActConv2d", "dpn.BnActConv2d", "dpn.CatBnAct", "layers.create_conv2d", "layers.create_conv2d", "dpn.BnActConv2d", "dpn.BnActConv2d", "dpn.BnActConv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "num_1x1_a", ",", "num_3x3_b", ",", "num_1x1_c", ",", "inc", ",", "groups", ",", "block_type", "=", "'normal'", ",", "b", "=", "False", ")", ":", "\n", "        ", "super", "(", "DualPathBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_1x1_c", "=", "num_1x1_c", "\n", "self", ".", "inc", "=", "inc", "\n", "self", ".", "b", "=", "b", "\n", "if", "block_type", "==", "'proj'", ":", "\n", "            ", "self", ".", "key_stride", "=", "1", "\n", "self", ".", "has_proj", "=", "True", "\n", "", "elif", "block_type", "==", "'down'", ":", "\n", "            ", "self", ".", "key_stride", "=", "2", "\n", "self", ".", "has_proj", "=", "True", "\n", "", "else", ":", "\n", "            ", "assert", "block_type", "==", "'normal'", "\n", "self", ".", "key_stride", "=", "1", "\n", "self", ".", "has_proj", "=", "False", "\n", "\n", "", "self", ".", "c1x1_w_s1", "=", "None", "\n", "self", ".", "c1x1_w_s2", "=", "None", "\n", "if", "self", ".", "has_proj", ":", "\n", "# Using different member names here to allow easier parameter key matching for conversion", "\n", "            ", "if", "self", ".", "key_stride", "==", "2", ":", "\n", "                ", "self", ".", "c1x1_w_s2", "=", "BnActConv2d", "(", "\n", "in_chs", "=", "in_chs", ",", "out_chs", "=", "num_1x1_c", "+", "2", "*", "inc", ",", "kernel_size", "=", "1", ",", "stride", "=", "2", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "c1x1_w_s1", "=", "BnActConv2d", "(", "\n", "in_chs", "=", "in_chs", ",", "out_chs", "=", "num_1x1_c", "+", "2", "*", "inc", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "\n", "", "", "self", ".", "c1x1_a", "=", "BnActConv2d", "(", "in_chs", "=", "in_chs", ",", "out_chs", "=", "num_1x1_a", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "c3x3_b", "=", "BnActConv2d", "(", "\n", "in_chs", "=", "num_1x1_a", ",", "out_chs", "=", "num_3x3_b", ",", "kernel_size", "=", "3", ",", "stride", "=", "self", ".", "key_stride", ",", "groups", "=", "groups", ")", "\n", "if", "b", ":", "\n", "            ", "self", ".", "c1x1_c", "=", "CatBnAct", "(", "in_chs", "=", "num_3x3_b", ")", "\n", "self", ".", "c1x1_c1", "=", "create_conv2d", "(", "num_3x3_b", ",", "num_1x1_c", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "c1x1_c2", "=", "create_conv2d", "(", "num_3x3_b", ",", "inc", ",", "kernel_size", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "c1x1_c", "=", "BnActConv2d", "(", "in_chs", "=", "num_3x3_b", ",", "out_chs", "=", "num_1x1_c", "+", "inc", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "c1x1_c1", "=", "None", "\n", "self", ".", "c1x1_c2", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.DualPathBlock.forward": [[134, 166], ["isinstance", "dpn.DualPathBlock.c1x1_a", "dpn.DualPathBlock.c3x3_b", "dpn.DualPathBlock.c1x1_c", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dpn.DualPathBlock.c1x1_c1", "dpn.DualPathBlock.c1x1_c2", "dpn.DualPathBlock.c1x1_w_s1", "dpn.DualPathBlock.c1x1_w_s2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "tuple", ")", ":", "\n", "            ", "x_in", "=", "torch", ".", "cat", "(", "x", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "x_in", "=", "x", "\n", "", "if", "self", ".", "c1x1_w_s1", "is", "None", "and", "self", ".", "c1x1_w_s2", "is", "None", ":", "\n", "# self.has_proj == False, torchscript requires condition on module == None", "\n", "            ", "x_s1", "=", "x", "[", "0", "]", "\n", "x_s2", "=", "x", "[", "1", "]", "\n", "", "else", ":", "\n", "# self.has_proj == True", "\n", "            ", "if", "self", ".", "c1x1_w_s1", "is", "not", "None", ":", "\n", "# self.key_stride = 1", "\n", "                ", "x_s", "=", "self", ".", "c1x1_w_s1", "(", "x_in", ")", "\n", "", "else", ":", "\n", "# self.key_stride = 2", "\n", "                ", "x_s", "=", "self", ".", "c1x1_w_s2", "(", "x_in", ")", "\n", "", "x_s1", "=", "x_s", "[", ":", ",", ":", "self", ".", "num_1x1_c", ",", ":", ",", ":", "]", "\n", "x_s2", "=", "x_s", "[", ":", ",", "self", ".", "num_1x1_c", ":", ",", ":", ",", ":", "]", "\n", "", "x_in", "=", "self", ".", "c1x1_a", "(", "x_in", ")", "\n", "x_in", "=", "self", ".", "c3x3_b", "(", "x_in", ")", "\n", "x_in", "=", "self", ".", "c1x1_c", "(", "x_in", ")", "\n", "if", "self", ".", "c1x1_c1", "is", "not", "None", ":", "\n", "# self.b == True, using None check for torchscript compat", "\n", "            ", "out1", "=", "self", ".", "c1x1_c1", "(", "x_in", ")", "\n", "out2", "=", "self", ".", "c1x1_c2", "(", "x_in", ")", "\n", "", "else", ":", "\n", "            ", "out1", "=", "x_in", "[", ":", ",", ":", "self", ".", "num_1x1_c", ",", ":", ",", ":", "]", "\n", "out2", "=", "x_in", "[", ":", ",", "self", ".", "num_1x1_c", ":", ",", ":", ",", ":", "]", "\n", "", "resid", "=", "x_s1", "+", "out1", "\n", "dense", "=", "torch", ".", "cat", "(", "[", "x_s2", ",", "out2", "]", ",", "dim", "=", "1", ")", "\n", "return", "resid", ",", "dense", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.DPN.__init__": [[169, 242], ["torch.Module.__init__", "functools.partial", "functools.partial", "collections.OrderedDict", "layers.ConvNormAct", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "dpn.DualPathBlock", "range", "dpn.DualPathBlock", "range", "dpn.DualPathBlock", "range", "dpn.DualPathBlock", "range", "dpn.CatBnAct", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.create_classifier", "dict", "dpn.DualPathBlock", "dict", "dpn.DualPathBlock", "dict", "dpn.DualPathBlock", "dict", "dpn.DualPathBlock", "dict", "torch.Flatten", "torch.Flatten", "torch.Flatten", "torch.Identity", "torch.Identity", "torch.Identity", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["    ", "def", "__init__", "(", "\n", "self", ",", "small", "=", "False", ",", "num_init_features", "=", "64", ",", "k_r", "=", "96", ",", "groups", "=", "32", ",", "global_pool", "=", "'avg'", ",", "\n", "b", "=", "False", ",", "k_sec", "=", "(", "3", ",", "4", ",", "20", ",", "3", ")", ",", "inc_sec", "=", "(", "16", ",", "32", ",", "24", ",", "128", ")", ",", "output_stride", "=", "32", ",", "\n", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "drop_rate", "=", "0.", ",", "fc_act_layer", "=", "nn", ".", "ELU", ")", ":", "\n", "        ", "super", "(", "DPN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "b", "=", "b", "\n", "assert", "output_stride", "==", "32", "# FIXME look into dilation support", "\n", "norm_layer", "=", "partial", "(", "BatchNormAct2d", ",", "eps", "=", ".001", ")", "\n", "fc_norm_layer", "=", "partial", "(", "BatchNormAct2d", ",", "eps", "=", ".001", ",", "act_layer", "=", "fc_act_layer", ",", "inplace", "=", "False", ")", "\n", "bw_factor", "=", "1", "if", "small", "else", "4", "\n", "blocks", "=", "OrderedDict", "(", ")", "\n", "\n", "# conv1", "\n", "blocks", "[", "'conv1_1'", "]", "=", "ConvNormAct", "(", "\n", "in_chans", ",", "num_init_features", ",", "kernel_size", "=", "3", "if", "small", "else", "7", ",", "stride", "=", "2", ",", "norm_layer", "=", "norm_layer", ")", "\n", "blocks", "[", "'conv1_pool'", "]", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "feature_info", "=", "[", "dict", "(", "num_chs", "=", "num_init_features", ",", "reduction", "=", "2", ",", "module", "=", "'features.conv1_1'", ")", "]", "\n", "\n", "# conv2", "\n", "bw", "=", "64", "*", "bw_factor", "\n", "inc", "=", "inc_sec", "[", "0", "]", "\n", "r", "=", "(", "k_r", "*", "bw", ")", "//", "(", "64", "*", "bw_factor", ")", "\n", "blocks", "[", "'conv2_1'", "]", "=", "DualPathBlock", "(", "num_init_features", ",", "r", ",", "r", ",", "bw", ",", "inc", ",", "groups", ",", "'proj'", ",", "b", ")", "\n", "in_chs", "=", "bw", "+", "3", "*", "inc", "\n", "for", "i", "in", "range", "(", "2", ",", "k_sec", "[", "0", "]", "+", "1", ")", ":", "\n", "            ", "blocks", "[", "'conv2_'", "+", "str", "(", "i", ")", "]", "=", "DualPathBlock", "(", "in_chs", ",", "r", ",", "r", ",", "bw", ",", "inc", ",", "groups", ",", "'normal'", ",", "b", ")", "\n", "in_chs", "+=", "inc", "\n", "", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "in_chs", ",", "reduction", "=", "4", ",", "module", "=", "f'features.conv2_{k_sec[0]}'", ")", "]", "\n", "\n", "# conv3", "\n", "bw", "=", "128", "*", "bw_factor", "\n", "inc", "=", "inc_sec", "[", "1", "]", "\n", "r", "=", "(", "k_r", "*", "bw", ")", "//", "(", "64", "*", "bw_factor", ")", "\n", "blocks", "[", "'conv3_1'", "]", "=", "DualPathBlock", "(", "in_chs", ",", "r", ",", "r", ",", "bw", ",", "inc", ",", "groups", ",", "'down'", ",", "b", ")", "\n", "in_chs", "=", "bw", "+", "3", "*", "inc", "\n", "for", "i", "in", "range", "(", "2", ",", "k_sec", "[", "1", "]", "+", "1", ")", ":", "\n", "            ", "blocks", "[", "'conv3_'", "+", "str", "(", "i", ")", "]", "=", "DualPathBlock", "(", "in_chs", ",", "r", ",", "r", ",", "bw", ",", "inc", ",", "groups", ",", "'normal'", ",", "b", ")", "\n", "in_chs", "+=", "inc", "\n", "", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "in_chs", ",", "reduction", "=", "8", ",", "module", "=", "f'features.conv3_{k_sec[1]}'", ")", "]", "\n", "\n", "# conv4", "\n", "bw", "=", "256", "*", "bw_factor", "\n", "inc", "=", "inc_sec", "[", "2", "]", "\n", "r", "=", "(", "k_r", "*", "bw", ")", "//", "(", "64", "*", "bw_factor", ")", "\n", "blocks", "[", "'conv4_1'", "]", "=", "DualPathBlock", "(", "in_chs", ",", "r", ",", "r", ",", "bw", ",", "inc", ",", "groups", ",", "'down'", ",", "b", ")", "\n", "in_chs", "=", "bw", "+", "3", "*", "inc", "\n", "for", "i", "in", "range", "(", "2", ",", "k_sec", "[", "2", "]", "+", "1", ")", ":", "\n", "            ", "blocks", "[", "'conv4_'", "+", "str", "(", "i", ")", "]", "=", "DualPathBlock", "(", "in_chs", ",", "r", ",", "r", ",", "bw", ",", "inc", ",", "groups", ",", "'normal'", ",", "b", ")", "\n", "in_chs", "+=", "inc", "\n", "", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "in_chs", ",", "reduction", "=", "16", ",", "module", "=", "f'features.conv4_{k_sec[2]}'", ")", "]", "\n", "\n", "# conv5", "\n", "bw", "=", "512", "*", "bw_factor", "\n", "inc", "=", "inc_sec", "[", "3", "]", "\n", "r", "=", "(", "k_r", "*", "bw", ")", "//", "(", "64", "*", "bw_factor", ")", "\n", "blocks", "[", "'conv5_1'", "]", "=", "DualPathBlock", "(", "in_chs", ",", "r", ",", "r", ",", "bw", ",", "inc", ",", "groups", ",", "'down'", ",", "b", ")", "\n", "in_chs", "=", "bw", "+", "3", "*", "inc", "\n", "for", "i", "in", "range", "(", "2", ",", "k_sec", "[", "3", "]", "+", "1", ")", ":", "\n", "            ", "blocks", "[", "'conv5_'", "+", "str", "(", "i", ")", "]", "=", "DualPathBlock", "(", "in_chs", ",", "r", ",", "r", ",", "bw", ",", "inc", ",", "groups", ",", "'normal'", ",", "b", ")", "\n", "in_chs", "+=", "inc", "\n", "", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "in_chs", ",", "reduction", "=", "32", ",", "module", "=", "f'features.conv5_{k_sec[3]}'", ")", "]", "\n", "\n", "blocks", "[", "'conv5_bn_ac'", "]", "=", "CatBnAct", "(", "in_chs", ",", "norm_layer", "=", "fc_norm_layer", ")", "\n", "\n", "self", ".", "num_features", "=", "in_chs", "\n", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "blocks", ")", "\n", "\n", "# Using 1x1 conv for the FC layer to allow the extra pooling scheme", "\n", "self", ".", "global_pool", ",", "self", ".", "classifier", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ",", "use_conv", "=", "True", ")", "\n", "self", ".", "flatten", "=", "nn", ".", "Flatten", "(", "1", ")", "if", "global_pool", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.DPN.group_matcher": [[243, 253], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem", "=", "r'^features\\.conv1'", ",", "\n", "blocks", "=", "[", "\n", "(", "r'^features\\.conv(\\d+)'", "if", "coarse", "else", "r'^features\\.conv(\\d+)_(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^features\\.conv5_bn_ac'", ",", "(", "99999", ",", ")", ")", "\n", "]", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.DPN.set_grad_checkpointing": [[254, 257], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "'gradient checkpointing not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.DPN.get_classifier": [[258, 261], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.DPN.reset_classifier": [[262, 267], ["layers.create_classifier", "torch.Flatten", "torch.Flatten", "torch.Flatten", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "classifier", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ",", "use_conv", "=", "True", ")", "\n", "self", ".", "flatten", "=", "nn", ".", "Flatten", "(", "1", ")", "if", "global_pool", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.DPN.forward_features": [[268, 270], ["dpn.DPN.features"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "features", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.DPN.forward_head": [[271, 280], ["dpn.DPN.global_pool", "torch.dropout", "torch.dropout", "torch.dropout", "dpn.DPN.flatten", "dpn.DPN.classifier", "dpn.DPN.flatten"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ">", "0.", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "if", "pre_logits", ":", "\n", "            ", "return", "x", ".", "flatten", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "self", ".", "flatten", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.DPN.forward": [[281, 285], ["dpn.DPN.forward_features", "dpn.DPN.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn._cfg": [[25, 32], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_DPN_MEAN", ",", "'std'", ":", "IMAGENET_DPN_STD", ",", "\n", "'first_conv'", ":", "'features.conv1_1.conv'", ",", "'classifier'", ":", "'classifier'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn._create_dpn": [[287, 292], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_dpn", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "\n", "DPN", ",", "variant", ",", "pretrained", ",", "\n", "feature_cfg", "=", "dict", "(", "feature_concat", "=", "True", ",", "flatten_sequential", "=", "True", ")", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.dpn68": [[294, 300], ["dict", "dpn._create_dpn"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn._create_dpn"], ["", "@", "register_model", "\n", "def", "dpn68", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "small", "=", "True", ",", "num_init_features", "=", "10", ",", "k_r", "=", "128", ",", "groups", "=", "32", ",", "\n", "k_sec", "=", "(", "3", ",", "4", ",", "12", ",", "3", ")", ",", "inc_sec", "=", "(", "16", ",", "32", ",", "32", ",", "64", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_dpn", "(", "'dpn68'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.dpn68b": [[302, 308], ["dict", "dpn._create_dpn"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn._create_dpn"], ["", "@", "register_model", "\n", "def", "dpn68b", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "small", "=", "True", ",", "num_init_features", "=", "10", ",", "k_r", "=", "128", ",", "groups", "=", "32", ",", "\n", "b", "=", "True", ",", "k_sec", "=", "(", "3", ",", "4", ",", "12", ",", "3", ")", ",", "inc_sec", "=", "(", "16", ",", "32", ",", "32", ",", "64", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_dpn", "(", "'dpn68b'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.dpn92": [[310, 316], ["dict", "dpn._create_dpn"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn._create_dpn"], ["", "@", "register_model", "\n", "def", "dpn92", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "num_init_features", "=", "64", ",", "k_r", "=", "96", ",", "groups", "=", "32", ",", "\n", "k_sec", "=", "(", "3", ",", "4", ",", "20", ",", "3", ")", ",", "inc_sec", "=", "(", "16", ",", "32", ",", "24", ",", "128", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_dpn", "(", "'dpn92'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.dpn98": [[318, 324], ["dict", "dpn._create_dpn"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn._create_dpn"], ["", "@", "register_model", "\n", "def", "dpn98", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "num_init_features", "=", "96", ",", "k_r", "=", "160", ",", "groups", "=", "40", ",", "\n", "k_sec", "=", "(", "3", ",", "6", ",", "20", ",", "3", ")", ",", "inc_sec", "=", "(", "16", ",", "32", ",", "32", ",", "128", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_dpn", "(", "'dpn98'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.dpn131": [[326, 332], ["dict", "dpn._create_dpn"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn._create_dpn"], ["", "@", "register_model", "\n", "def", "dpn131", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "num_init_features", "=", "128", ",", "k_r", "=", "160", ",", "groups", "=", "40", ",", "\n", "k_sec", "=", "(", "4", ",", "8", ",", "28", ",", "3", ")", ",", "inc_sec", "=", "(", "16", ",", "32", ",", "32", ",", "128", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_dpn", "(", "'dpn131'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn.dpn107": [[334, 340], ["dict", "dpn._create_dpn"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dpn._create_dpn"], ["", "@", "register_model", "\n", "def", "dpn107", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "num_init_features", "=", "128", ",", "k_r", "=", "200", ",", "groups", "=", "50", ",", "\n", "k_sec", "=", "(", "4", ",", "8", ",", "20", ",", "3", ")", ",", "inc_sec", "=", "(", "20", ",", "64", ",", "64", ",", "128", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_dpn", "(", "'dpn107'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.ConvNorm.__init__": [[117, 125], ["torch.Sequential.__init__", "levit.ConvNorm.add_module", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "levit.ConvNorm.add_module", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "a", ",", "b", ",", "ks", "=", "1", ",", "stride", "=", "1", ",", "pad", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bn_weight_init", "=", "1", ",", "resolution", "=", "-", "10000", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "add_module", "(", "'c'", ",", "nn", ".", "Conv2d", "(", "a", ",", "b", ",", "ks", ",", "stride", ",", "pad", ",", "dilation", ",", "groups", ",", "bias", "=", "False", ")", ")", "\n", "bn", "=", "nn", ".", "BatchNorm2d", "(", "b", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "bn", ".", "weight", ",", "bn_weight_init", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "bn", ".", "bias", ",", "0", ")", "\n", "self", ".", "add_module", "(", "'bn'", ",", "bn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.ConvNorm.fuse": [[126, 138], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "levit.ConvNorm._modules.values", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d.weight.data.copy_", "torch.Conv2d.bias.data.copy_", "w.size", "w.size"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "fuse", "(", "self", ")", ":", "\n", "        ", "c", ",", "bn", "=", "self", ".", "_modules", ".", "values", "(", ")", "\n", "w", "=", "bn", ".", "weight", "/", "(", "bn", ".", "running_var", "+", "bn", ".", "eps", ")", "**", "0.5", "\n", "w", "=", "c", ".", "weight", "*", "w", "[", ":", ",", "None", ",", "None", ",", "None", "]", "\n", "b", "=", "bn", ".", "bias", "-", "bn", ".", "running_mean", "*", "bn", ".", "weight", "/", "(", "bn", ".", "running_var", "+", "bn", ".", "eps", ")", "**", "0.5", "\n", "m", "=", "nn", ".", "Conv2d", "(", "\n", "w", ".", "size", "(", "1", ")", ",", "w", ".", "size", "(", "0", ")", ",", "w", ".", "shape", "[", "2", ":", "]", ",", "stride", "=", "self", ".", "c", ".", "stride", ",", "\n", "padding", "=", "self", ".", "c", ".", "padding", ",", "dilation", "=", "self", ".", "c", ".", "dilation", ",", "groups", "=", "self", ".", "c", ".", "groups", ")", "\n", "m", ".", "weight", ".", "data", ".", "copy_", "(", "w", ")", "\n", "m", ".", "bias", ".", "data", ".", "copy_", "(", "b", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.LinearNorm.__init__": [[141, 148], ["torch.Sequential.__init__", "levit.LinearNorm.add_module", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "levit.LinearNorm.add_module", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "a", ",", "b", ",", "bn_weight_init", "=", "1", ",", "resolution", "=", "-", "100000", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "add_module", "(", "'c'", ",", "nn", ".", "Linear", "(", "a", ",", "b", ",", "bias", "=", "False", ")", ")", "\n", "bn", "=", "nn", ".", "BatchNorm1d", "(", "b", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "bn", ".", "weight", ",", "bn_weight_init", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "bn", ".", "bias", ",", "0", ")", "\n", "self", ".", "add_module", "(", "'bn'", ",", "bn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.LinearNorm.fuse": [[149, 159], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "levit.LinearNorm._modules.values", "torch.Linear", "torch.Linear", "torch.Linear.weight.data.copy_", "torch.Linear.bias.data.copy_", "w.size", "w.size"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "fuse", "(", "self", ")", ":", "\n", "        ", "l", ",", "bn", "=", "self", ".", "_modules", ".", "values", "(", ")", "\n", "w", "=", "bn", ".", "weight", "/", "(", "bn", ".", "running_var", "+", "bn", ".", "eps", ")", "**", "0.5", "\n", "w", "=", "l", ".", "weight", "*", "w", "[", ":", ",", "None", "]", "\n", "b", "=", "bn", ".", "bias", "-", "bn", ".", "running_mean", "*", "bn", ".", "weight", "/", "(", "bn", ".", "running_var", "+", "bn", ".", "eps", ")", "**", "0.5", "\n", "m", "=", "nn", ".", "Linear", "(", "w", ".", "size", "(", "1", ")", ",", "w", ".", "size", "(", "0", ")", ")", "\n", "m", ".", "weight", ".", "data", ".", "copy_", "(", "w", ")", "\n", "m", ".", "bias", ".", "data", ".", "copy_", "(", "b", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.LinearNorm.forward": [[160, 163], ["levit.LinearNorm.c", "levit.LinearNorm.bn().reshape_as", "levit.LinearNorm.bn", "levit.LinearNorm.flatten"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "c", "(", "x", ")", "\n", "return", "self", ".", "bn", "(", "x", ".", "flatten", "(", "0", ",", "1", ")", ")", ".", "reshape_as", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.NormLinear.__init__": [[166, 174], ["torch.Sequential.__init__", "levit.NormLinear.add_module", "torch.Linear", "torch.Linear", "vision_transformer.trunc_normal_", "levit.NormLinear.add_module", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["    ", "def", "__init__", "(", "self", ",", "a", ",", "b", ",", "bias", "=", "True", ",", "std", "=", "0.02", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "add_module", "(", "'bn'", ",", "nn", ".", "BatchNorm1d", "(", "a", ")", ")", "\n", "l", "=", "nn", ".", "Linear", "(", "a", ",", "b", ",", "bias", "=", "bias", ")", "\n", "trunc_normal_", "(", "l", ".", "weight", ",", "std", "=", "std", ")", "\n", "if", "bias", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n", "", "self", ".", "add_module", "(", "'l'", ",", "l", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.NormLinear.fuse": [[175, 189], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "levit.NormLinear._modules.values", "torch.Linear", "torch.Linear", "torch.Linear.weight.data.copy_", "torch.Linear.bias.data.copy_", "w.size", "w.size"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "fuse", "(", "self", ")", ":", "\n", "        ", "bn", ",", "l", "=", "self", ".", "_modules", ".", "values", "(", ")", "\n", "w", "=", "bn", ".", "weight", "/", "(", "bn", ".", "running_var", "+", "bn", ".", "eps", ")", "**", "0.5", "\n", "b", "=", "bn", ".", "bias", "-", "self", ".", "bn", ".", "running_mean", "*", "self", ".", "bn", ".", "weight", "/", "(", "bn", ".", "running_var", "+", "bn", ".", "eps", ")", "**", "0.5", "\n", "w", "=", "l", ".", "weight", "*", "w", "[", "None", ",", ":", "]", "\n", "if", "l", ".", "bias", "is", "None", ":", "\n", "            ", "b", "=", "b", "@", "self", ".", "l", ".", "weight", ".", "T", "\n", "", "else", ":", "\n", "            ", "b", "=", "(", "l", ".", "weight", "@", "b", "[", ":", ",", "None", "]", ")", ".", "view", "(", "-", "1", ")", "+", "self", ".", "l", ".", "bias", "\n", "", "m", "=", "nn", ".", "Linear", "(", "w", ".", "size", "(", "1", ")", ",", "w", ".", "size", "(", "0", ")", ")", "\n", "m", ".", "weight", ".", "data", ".", "copy_", "(", "w", ")", "\n", "m", ".", "bias", ".", "data", ".", "copy_", "(", "b", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.Residual.__init__": [[203, 207], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "m", ",", "drop", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "m", "=", "m", "\n", "self", ".", "drop", "=", "drop", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.Residual.forward": [[208, 214], ["levit.Residual.m", "levit.Residual.m", "torch.rand().ge_().div().detach", "torch.rand().ge_().div().detach", "torch.rand().ge_().div().detach", "torch.rand().ge_().div().detach", "torch.rand().ge_().div", "torch.rand().ge_().div", "torch.rand().ge_().div", "torch.rand().ge_().div", "torch.rand().ge_", "torch.rand().ge_", "torch.rand().ge_", "torch.rand().ge_", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "training", "and", "self", ".", "drop", ">", "0", ":", "\n", "            ", "return", "x", "+", "self", ".", "m", "(", "x", ")", "*", "torch", ".", "rand", "(", "\n", "x", ".", "size", "(", "0", ")", ",", "1", ",", "1", ",", "device", "=", "x", ".", "device", ")", ".", "ge_", "(", "self", ".", "drop", ")", ".", "div", "(", "1", "-", "self", ".", "drop", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "+", "self", ".", "m", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.Subsample.__init__": [[217, 221], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "stride", ",", "resolution", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "resolution", "=", "resolution", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.Subsample.forward": [[222, 226], ["x.reshape", "x.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "self", ".", "resolution", ",", "self", ".", "resolution", ",", "C", ")", "[", ":", ",", ":", ":", "self", ".", "stride", ",", ":", ":", "self", ".", "stride", "]", "\n", "return", "x", ".", "reshape", "(", "B", ",", "-", "1", ",", "C", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.Attention.__init__": [[231, 263], ["torch.Module.__init__", "int", "ln_layer", "torch.Sequential", "torch.Sequential", "list", "len", "torch.Parameter", "torch.Parameter", "levit.Attention.register_buffer", "int", "act_layer", "ln_layer", "itertools.product", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.LongTensor().view", "torch.LongTensor().view", "torch.LongTensor().view", "torch.LongTensor().view", "range", "range", "idxs.append", "len", "abs", "abs", "len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "dim", ",", "key_dim", ",", "num_heads", "=", "8", ",", "attn_ratio", "=", "4", ",", "act_layer", "=", "None", ",", "resolution", "=", "14", ",", "use_conv", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "scale", "=", "key_dim", "**", "-", "0.5", "\n", "self", ".", "key_dim", "=", "key_dim", "\n", "self", ".", "nh_kd", "=", "nh_kd", "=", "key_dim", "*", "num_heads", "\n", "self", ".", "d", "=", "int", "(", "attn_ratio", "*", "key_dim", ")", "\n", "self", ".", "dh", "=", "int", "(", "attn_ratio", "*", "key_dim", ")", "*", "num_heads", "\n", "self", ".", "attn_ratio", "=", "attn_ratio", "\n", "self", ".", "use_conv", "=", "use_conv", "\n", "ln_layer", "=", "ConvNorm", "if", "self", ".", "use_conv", "else", "LinearNorm", "\n", "h", "=", "self", ".", "dh", "+", "nh_kd", "*", "2", "\n", "self", ".", "qkv", "=", "ln_layer", "(", "dim", ",", "h", ",", "resolution", "=", "resolution", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Sequential", "(", "\n", "act_layer", "(", ")", ",", "\n", "ln_layer", "(", "self", ".", "dh", ",", "dim", ",", "bn_weight_init", "=", "0", ",", "resolution", "=", "resolution", ")", ")", "\n", "\n", "points", "=", "list", "(", "itertools", ".", "product", "(", "range", "(", "resolution", ")", ",", "range", "(", "resolution", ")", ")", ")", "\n", "N", "=", "len", "(", "points", ")", "\n", "attention_offsets", "=", "{", "}", "\n", "idxs", "=", "[", "]", "\n", "for", "p1", "in", "points", ":", "\n", "            ", "for", "p2", "in", "points", ":", "\n", "                ", "offset", "=", "(", "abs", "(", "p1", "[", "0", "]", "-", "p2", "[", "0", "]", ")", ",", "abs", "(", "p1", "[", "1", "]", "-", "p2", "[", "1", "]", ")", ")", "\n", "if", "offset", "not", "in", "attention_offsets", ":", "\n", "                    ", "attention_offsets", "[", "offset", "]", "=", "len", "(", "attention_offsets", ")", "\n", "", "idxs", ".", "append", "(", "attention_offsets", "[", "offset", "]", ")", "\n", "", "", "self", ".", "attention_biases", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_heads", ",", "len", "(", "attention_offsets", ")", ")", ")", "\n", "self", ".", "register_buffer", "(", "'attention_bias_idxs'", ",", "torch", ".", "LongTensor", "(", "idxs", ")", ".", "view", "(", "N", ",", "N", ")", ")", "\n", "self", ".", "ab", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.Attention.train": [[264, 269], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "super().train"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.AttentionSubsample.train"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "train", "(", "mode", ")", "\n", "if", "mode", "and", "self", ".", "ab", ":", "\n", "            ", "self", ".", "ab", "=", "{", "}", "# clear ab cache", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.Attention.get_attention_biases": [[270, 278], ["str"], "methods", ["None"], ["", "", "def", "get_attention_biases", "(", "self", ",", "device", ":", "torch", ".", "device", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "attention_biases", "[", ":", ",", "self", ".", "attention_bias_idxs", "]", "\n", "", "else", ":", "\n", "            ", "device_key", "=", "str", "(", "device", ")", "\n", "if", "device_key", "not", "in", "self", ".", "ab", ":", "\n", "                ", "self", ".", "ab", "[", "device_key", "]", "=", "self", ".", "attention_biases", "[", ":", ",", "self", ".", "attention_bias_idxs", "]", "\n", "", "return", "self", ".", "ab", "[", "device_key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.Attention.forward": [[279, 302], ["levit.Attention.proj", "levit.Attention.qkv().view().split", "attn.softmax.softmax.softmax", "levit.Attention.qkv", "levit.Attention.view().split", "q.permute.permute.permute", "k.permute.permute.permute", "v.permute.permute.permute", "attn.softmax.softmax.softmax", "levit.Attention.get_attention_biases", "levit.Attention.get_attention_biases", "levit.Attention.qkv().view", "levit.Attention.view", "q.permute.permute.transpose", "attn.softmax.softmax.transpose", "k.permute.permute.transpose", "levit.Attention.qkv"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.AttentionSubsample.get_attention_biases", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.AttentionSubsample.get_attention_biases"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "# x (B,C,H,W)", "\n", "        ", "if", "self", ".", "use_conv", ":", "\n", "            ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "q", ",", "k", ",", "v", "=", "self", ".", "qkv", "(", "x", ")", ".", "view", "(", "B", ",", "self", ".", "num_heads", ",", "-", "1", ",", "H", "*", "W", ")", ".", "split", "(", "[", "self", ".", "key_dim", ",", "self", ".", "key_dim", ",", "self", ".", "d", "]", ",", "dim", "=", "2", ")", "\n", "\n", "attn", "=", "(", "q", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", "@", "k", ")", "*", "self", ".", "scale", "+", "self", ".", "get_attention_biases", "(", "x", ".", "device", ")", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "x", "=", "(", "v", "@", "attn", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", ".", "view", "(", "B", ",", "-", "1", ",", "H", ",", "W", ")", "\n", "", "else", ":", "\n", "            ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", ".", "view", "(", "B", ",", "N", ",", "self", ".", "num_heads", ",", "-", "1", ")", ".", "split", "(", "[", "self", ".", "key_dim", ",", "self", ".", "key_dim", ",", "self", ".", "d", "]", ",", "dim", "=", "3", ")", "\n", "q", "=", "q", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "k", "=", "k", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "v", "=", "v", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n", "attn", "=", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", "*", "self", ".", "scale", "+", "self", ".", "get_attention_biases", "(", "x", ".", "device", ")", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "N", ",", "self", ".", "dh", ")", "\n", "", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.AttentionSubsample.__init__": [[307, 357], ["torch.Module.__init__", "int", "ln_layer", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "list", "list", "len", "len", "torch.Parameter", "torch.Parameter", "levit.AttentionSubsample.register_buffer", "functools.partial", "functools.partial", "functools.partial.", "ln_layer", "act_layer", "ln_layer", "itertools.product", "itertools.product", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.LongTensor().view", "torch.LongTensor().view", "torch.LongTensor().view", "torch.LongTensor().view", "range", "range", "range", "range", "idxs.append", "len", "abs", "abs", "len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "in_dim", ",", "out_dim", ",", "key_dim", ",", "num_heads", "=", "8", ",", "attn_ratio", "=", "2", ",", "\n", "act_layer", "=", "None", ",", "stride", "=", "2", ",", "resolution", "=", "14", ",", "resolution_", "=", "7", ",", "use_conv", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "scale", "=", "key_dim", "**", "-", "0.5", "\n", "self", ".", "key_dim", "=", "key_dim", "\n", "self", ".", "nh_kd", "=", "nh_kd", "=", "key_dim", "*", "num_heads", "\n", "self", ".", "d", "=", "int", "(", "attn_ratio", "*", "key_dim", ")", "\n", "self", ".", "dh", "=", "self", ".", "d", "*", "self", ".", "num_heads", "\n", "self", ".", "attn_ratio", "=", "attn_ratio", "\n", "self", ".", "resolution_", "=", "resolution_", "\n", "self", ".", "resolution_2", "=", "resolution_", "**", "2", "\n", "self", ".", "use_conv", "=", "use_conv", "\n", "if", "self", ".", "use_conv", ":", "\n", "            ", "ln_layer", "=", "ConvNorm", "\n", "sub_layer", "=", "partial", "(", "nn", ".", "AvgPool2d", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "ln_layer", "=", "LinearNorm", "\n", "sub_layer", "=", "partial", "(", "Subsample", ",", "resolution", "=", "resolution", ")", "\n", "\n", "", "h", "=", "self", ".", "dh", "+", "nh_kd", "\n", "self", ".", "kv", "=", "ln_layer", "(", "in_dim", ",", "h", ",", "resolution", "=", "resolution", ")", "\n", "self", ".", "q", "=", "nn", ".", "Sequential", "(", "\n", "sub_layer", "(", "stride", "=", "stride", ")", ",", "\n", "ln_layer", "(", "in_dim", ",", "nh_kd", ",", "resolution", "=", "resolution_", ")", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Sequential", "(", "\n", "act_layer", "(", ")", ",", "\n", "ln_layer", "(", "self", ".", "dh", ",", "out_dim", ",", "resolution", "=", "resolution_", ")", ")", "\n", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "resolution", "=", "resolution", "\n", "points", "=", "list", "(", "itertools", ".", "product", "(", "range", "(", "resolution", ")", ",", "range", "(", "resolution", ")", ")", ")", "\n", "points_", "=", "list", "(", "itertools", ".", "product", "(", "range", "(", "resolution_", ")", ",", "range", "(", "resolution_", ")", ")", ")", "\n", "N", "=", "len", "(", "points", ")", "\n", "N_", "=", "len", "(", "points_", ")", "\n", "attention_offsets", "=", "{", "}", "\n", "idxs", "=", "[", "]", "\n", "for", "p1", "in", "points_", ":", "\n", "            ", "for", "p2", "in", "points", ":", "\n", "                ", "size", "=", "1", "\n", "offset", "=", "(", "\n", "abs", "(", "p1", "[", "0", "]", "*", "stride", "-", "p2", "[", "0", "]", "+", "(", "size", "-", "1", ")", "/", "2", ")", ",", "\n", "abs", "(", "p1", "[", "1", "]", "*", "stride", "-", "p2", "[", "1", "]", "+", "(", "size", "-", "1", ")", "/", "2", ")", ")", "\n", "if", "offset", "not", "in", "attention_offsets", ":", "\n", "                    ", "attention_offsets", "[", "offset", "]", "=", "len", "(", "attention_offsets", ")", "\n", "", "idxs", ".", "append", "(", "attention_offsets", "[", "offset", "]", ")", "\n", "", "", "self", ".", "attention_biases", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_heads", ",", "len", "(", "attention_offsets", ")", ")", ")", "\n", "self", ".", "register_buffer", "(", "'attention_bias_idxs'", ",", "torch", ".", "LongTensor", "(", "idxs", ")", ".", "view", "(", "N_", ",", "N", ")", ")", "\n", "self", ".", "ab", "=", "{", "}", "# per-device attention_biases cache", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.AttentionSubsample.train": [[358, 363], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "super().train"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.AttentionSubsample.train"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "train", "(", "mode", ")", "\n", "if", "mode", "and", "self", ".", "ab", ":", "\n", "            ", "self", ".", "ab", "=", "{", "}", "# clear ab cache", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.AttentionSubsample.get_attention_biases": [[364, 372], ["str"], "methods", ["None"], ["", "", "def", "get_attention_biases", "(", "self", ",", "device", ":", "torch", ".", "device", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "attention_biases", "[", ":", ",", "self", ".", "attention_bias_idxs", "]", "\n", "", "else", ":", "\n", "            ", "device_key", "=", "str", "(", "device", ")", "\n", "if", "device_key", "not", "in", "self", ".", "ab", ":", "\n", "                ", "self", ".", "ab", "[", "device_key", "]", "=", "self", ".", "attention_biases", "[", ":", ",", "self", ".", "attention_bias_idxs", "]", "\n", "", "return", "self", ".", "ab", "[", "device_key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.AttentionSubsample.forward": [[373, 396], ["levit.AttentionSubsample.proj", "levit.AttentionSubsample.kv().view().split", "levit.AttentionSubsample.q().view", "attn.softmax.softmax.softmax", "levit.AttentionSubsample.kv().view().split", "k.permute.permute.permute", "v.permute.permute.permute", "levit.AttentionSubsample.q().view().permute", "attn.softmax.softmax.softmax", "levit.AttentionSubsample.get_attention_biases", "levit.AttentionSubsample.get_attention_biases", "levit.AttentionSubsample.kv().view", "levit.AttentionSubsample.q", "levit.AttentionSubsample.kv().view", "levit.AttentionSubsample.q().view", "levit.AttentionSubsample.transpose", "attn.softmax.softmax.transpose", "k.permute.permute.transpose", "levit.AttentionSubsample.kv", "levit.AttentionSubsample.kv", "levit.AttentionSubsample.q"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.AttentionSubsample.get_attention_biases", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.AttentionSubsample.get_attention_biases"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "use_conv", ":", "\n", "            ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "k", ",", "v", "=", "self", ".", "kv", "(", "x", ")", ".", "view", "(", "B", ",", "self", ".", "num_heads", ",", "-", "1", ",", "H", "*", "W", ")", ".", "split", "(", "[", "self", ".", "key_dim", ",", "self", ".", "d", "]", ",", "dim", "=", "2", ")", "\n", "q", "=", "self", ".", "q", "(", "x", ")", ".", "view", "(", "B", ",", "self", ".", "num_heads", ",", "self", ".", "key_dim", ",", "self", ".", "resolution_2", ")", "\n", "\n", "attn", "=", "(", "q", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", "@", "k", ")", "*", "self", ".", "scale", "+", "self", ".", "get_attention_biases", "(", "x", ".", "device", ")", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "x", "=", "(", "v", "@", "attn", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", ".", "reshape", "(", "B", ",", "-", "1", ",", "self", ".", "resolution_", ",", "self", ".", "resolution_", ")", "\n", "", "else", ":", "\n", "            ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "k", ",", "v", "=", "self", ".", "kv", "(", "x", ")", ".", "view", "(", "B", ",", "N", ",", "self", ".", "num_heads", ",", "-", "1", ")", ".", "split", "(", "[", "self", ".", "key_dim", ",", "self", ".", "d", "]", ",", "dim", "=", "3", ")", "\n", "k", "=", "k", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "# BHNC", "\n", "v", "=", "v", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "# BHNC", "\n", "q", "=", "self", ".", "q", "(", "x", ")", ".", "view", "(", "B", ",", "self", ".", "resolution_2", ",", "self", ".", "num_heads", ",", "self", ".", "key_dim", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n", "attn", "=", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", "*", "self", ".", "scale", "+", "self", ".", "get_attention_biases", "(", "x", ".", "device", ")", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "-", "1", ",", "self", ".", "dh", ")", "\n", "", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.Levit.__init__": [[405, 496], ["torch.Module.__init__", "layers.get_act_layer", "layers.get_act_layer", "isinstance", "len", "enumerate", "torch.Sequential", "torch.Sequential", "len", "len", "layers.to_ntuple", "layers.to_ntuple", "layers.to_ntuple", "levit.stem_b16", "zip", "range", "levit.NormLinear", "torch.Identity", "torch.Identity", "levit.Levit.blocks.append", "levit.Levit.blocks.append", "levit.NormLinear", "torch.Identity", "torch.Identity", "levit.Residual", "int", "levit.Levit.blocks.append", "levit.AttentionSubsample", "int", "levit.Levit.blocks.append", "levit.Attention", "levit.Residual", "levit.Residual", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "ln_layer", "layers.get_act_layer.", "ln_layer", "ln_layer", "layers.get_act_layer.", "ln_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.stem_b16"], ["def", "__init__", "(", "\n", "self", ",", "\n", "img_size", "=", "224", ",", "\n", "patch_size", "=", "16", ",", "\n", "in_chans", "=", "3", ",", "\n", "num_classes", "=", "1000", ",", "\n", "embed_dim", "=", "(", "192", ",", ")", ",", "\n", "key_dim", "=", "64", ",", "\n", "depth", "=", "(", "12", ",", ")", ",", "\n", "num_heads", "=", "(", "3", ",", ")", ",", "\n", "attn_ratio", "=", "2", ",", "\n", "mlp_ratio", "=", "2", ",", "\n", "hybrid_backbone", "=", "None", ",", "\n", "down_ops", "=", "None", ",", "\n", "act_layer", "=", "'hard_swish'", ",", "\n", "attn_act_layer", "=", "'hard_swish'", ",", "\n", "distillation", "=", "False", ",", "\n", "use_conv", "=", "False", ",", "\n", "drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "act_layer", "=", "get_act_layer", "(", "act_layer", ")", "\n", "attn_act_layer", "=", "get_act_layer", "(", "attn_act_layer", ")", "\n", "if", "isinstance", "(", "img_size", ",", "tuple", ")", ":", "\n", "# FIXME origin impl passes single img/res dim through whole hierarchy,", "\n", "# not sure this model will be used enough to spend time fixing it.", "\n", "            ", "assert", "img_size", "[", "0", "]", "==", "img_size", "[", "1", "]", "\n", "img_size", "=", "img_size", "[", "0", "]", "\n", "", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_features", "=", "embed_dim", "[", "-", "1", "]", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "N", "=", "len", "(", "embed_dim", ")", "\n", "assert", "len", "(", "depth", ")", "==", "len", "(", "num_heads", ")", "==", "N", "\n", "key_dim", "=", "to_ntuple", "(", "N", ")", "(", "key_dim", ")", "\n", "attn_ratio", "=", "to_ntuple", "(", "N", ")", "(", "attn_ratio", ")", "\n", "mlp_ratio", "=", "to_ntuple", "(", "N", ")", "(", "mlp_ratio", ")", "\n", "down_ops", "=", "down_ops", "or", "(", "\n", "# ('Subsample',key_dim, num_heads, attn_ratio, mlp_ratio, stride)", "\n", "(", "'Subsample'", ",", "key_dim", "[", "0", "]", ",", "embed_dim", "[", "0", "]", "//", "key_dim", "[", "0", "]", ",", "4", ",", "2", ",", "2", ")", ",", "\n", "(", "'Subsample'", ",", "key_dim", "[", "0", "]", ",", "embed_dim", "[", "1", "]", "//", "key_dim", "[", "1", "]", ",", "4", ",", "2", ",", "2", ")", ",", "\n", "(", "''", ",", ")", "\n", ")", "\n", "self", ".", "distillation", "=", "distillation", "\n", "self", ".", "use_conv", "=", "use_conv", "\n", "ln_layer", "=", "ConvNorm", "if", "self", ".", "use_conv", "else", "LinearNorm", "\n", "\n", "self", ".", "patch_embed", "=", "hybrid_backbone", "or", "stem_b16", "(", "in_chans", ",", "embed_dim", "[", "0", "]", ",", "activation", "=", "act_layer", ")", "\n", "\n", "self", ".", "blocks", "=", "[", "]", "\n", "resolution", "=", "img_size", "//", "patch_size", "\n", "for", "i", ",", "(", "ed", ",", "kd", ",", "dpth", ",", "nh", ",", "ar", ",", "mr", ",", "do", ")", "in", "enumerate", "(", "\n", "zip", "(", "embed_dim", ",", "key_dim", ",", "depth", ",", "num_heads", ",", "attn_ratio", ",", "mlp_ratio", ",", "down_ops", ")", ")", ":", "\n", "            ", "for", "_", "in", "range", "(", "dpth", ")", ":", "\n", "                ", "self", ".", "blocks", ".", "append", "(", "\n", "Residual", "(", "\n", "Attention", "(", "\n", "ed", ",", "kd", ",", "nh", ",", "attn_ratio", "=", "ar", ",", "act_layer", "=", "attn_act_layer", ",", "\n", "resolution", "=", "resolution", ",", "use_conv", "=", "use_conv", ")", ",", "\n", "drop_path_rate", ")", ")", "\n", "if", "mr", ">", "0", ":", "\n", "                    ", "h", "=", "int", "(", "ed", "*", "mr", ")", "\n", "self", ".", "blocks", ".", "append", "(", "\n", "Residual", "(", "nn", ".", "Sequential", "(", "\n", "ln_layer", "(", "ed", ",", "h", ",", "resolution", "=", "resolution", ")", ",", "\n", "act_layer", "(", ")", ",", "\n", "ln_layer", "(", "h", ",", "ed", ",", "bn_weight_init", "=", "0", ",", "resolution", "=", "resolution", ")", ",", "\n", ")", ",", "drop_path_rate", ")", ")", "\n", "", "", "if", "do", "[", "0", "]", "==", "'Subsample'", ":", "\n", "# ('Subsample',key_dim, num_heads, attn_ratio, mlp_ratio, stride)", "\n", "                ", "resolution_", "=", "(", "resolution", "-", "1", ")", "//", "do", "[", "5", "]", "+", "1", "\n", "self", ".", "blocks", ".", "append", "(", "\n", "AttentionSubsample", "(", "\n", "*", "embed_dim", "[", "i", ":", "i", "+", "2", "]", ",", "key_dim", "=", "do", "[", "1", "]", ",", "num_heads", "=", "do", "[", "2", "]", ",", "\n", "attn_ratio", "=", "do", "[", "3", "]", ",", "act_layer", "=", "attn_act_layer", ",", "stride", "=", "do", "[", "5", "]", ",", "\n", "resolution", "=", "resolution", ",", "resolution_", "=", "resolution_", ",", "use_conv", "=", "use_conv", ")", ")", "\n", "resolution", "=", "resolution_", "\n", "if", "do", "[", "4", "]", ">", "0", ":", "# mlp_ratio", "\n", "                    ", "h", "=", "int", "(", "embed_dim", "[", "i", "+", "1", "]", "*", "do", "[", "4", "]", ")", "\n", "self", ".", "blocks", ".", "append", "(", "\n", "Residual", "(", "nn", ".", "Sequential", "(", "\n", "ln_layer", "(", "embed_dim", "[", "i", "+", "1", "]", ",", "h", ",", "resolution", "=", "resolution", ")", ",", "\n", "act_layer", "(", ")", ",", "\n", "ln_layer", "(", "h", ",", "embed_dim", "[", "i", "+", "1", "]", ",", "bn_weight_init", "=", "0", ",", "resolution", "=", "resolution", ")", ",", "\n", ")", ",", "drop_path_rate", ")", ")", "\n", "", "", "", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "blocks", ")", "\n", "\n", "# Classifier head", "\n", "self", ".", "head", "=", "NormLinear", "(", "embed_dim", "[", "-", "1", "]", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "head_dist", "=", "None", "\n", "if", "distillation", ":", "\n", "            ", "self", ".", "head_dist", "=", "NormLinear", "(", "embed_dim", "[", "-", "1", "]", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.Levit.no_weight_decay": [[497, 500], ["levit.Levit.state_dict().keys", "levit.Levit.state_dict"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "{", "x", "for", "x", "in", "self", ".", "state_dict", "(", ")", ".", "keys", "(", ")", "if", "'attention_biases'", "in", "x", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.Levit.get_classifier": [[501, 506], ["None"], "methods", ["None"], ["", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "head_dist", "is", "None", ":", "\n", "            ", "return", "self", ".", "head", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "head", ",", "self", ".", "head_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.Levit.reset_classifier": [[507, 516], ["levit.NormLinear", "torch.Identity", "torch.Identity", "levit.NormLinear", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "''", ",", "distillation", "=", "None", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "head", "=", "NormLinear", "(", "self", ".", "embed_dim", "[", "-", "1", "]", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "if", "distillation", "is", "not", "None", ":", "\n", "            ", "self", ".", "distillation", "=", "distillation", "\n", "", "if", "self", ".", "distillation", ":", "\n", "            ", "self", ".", "head_dist", "=", "NormLinear", "(", "self", ".", "embed_dim", "[", "-", "1", "]", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "head_dist", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.Levit.forward_features": [[517, 524], ["levit.Levit.patch_embed", "levit.Levit.blocks", "x.flatten().transpose.flatten().transpose.flatten().transpose", "x.flatten().transpose.flatten().transpose.mean", "x.flatten().transpose.flatten().transpose.mean", "x.flatten().transpose.flatten().transpose.flatten"], "methods", ["None"], ["", "", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "if", "not", "self", ".", "use_conv", ":", "\n", "            ", "x", "=", "x", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "", "x", "=", "self", ".", "blocks", "(", "x", ")", "\n", "x", "=", "x", ".", "mean", "(", "(", "-", "2", ",", "-", "1", ")", ")", "if", "self", ".", "use_conv", "else", "x", ".", "mean", "(", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.Levit.forward": [[525, 537], ["levit.Levit.forward_features", "levit.Levit.head", "levit.Levit.head", "levit.Levit.head_dist", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "if", "self", ".", "head_dist", "is", "not", "None", ":", "\n", "            ", "x", ",", "x_dist", "=", "self", ".", "head", "(", "x", ")", ",", "self", ".", "head_dist", "(", "x", ")", "\n", "if", "self", ".", "training", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "                ", "return", "x", ",", "x_dist", "\n", "", "else", ":", "\n", "# during inference, return the average of both classifier predictions", "\n", "                ", "return", "(", "x", "+", "x_dist", ")", "/", "2", "\n", "", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "head", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit._cfg": [[41, 49], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", ".9", ",", "'interpolation'", ":", "'bicubic'", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'patch_embed.0.c'", ",", "'classifier'", ":", "(", "'head.l'", ",", "'head_dist.l'", ")", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.levit_128s": [[86, 90], ["levit.create_levit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.create_levit"], ["@", "register_model", "\n", "def", "levit_128s", "(", "pretrained", "=", "False", ",", "use_conv", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "create_levit", "(", "\n", "'levit_128s'", ",", "pretrained", "=", "pretrained", ",", "use_conv", "=", "use_conv", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.levit_128": [[92, 96], ["levit.create_levit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.create_levit"], ["", "@", "register_model", "\n", "def", "levit_128", "(", "pretrained", "=", "False", ",", "use_conv", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "create_levit", "(", "\n", "'levit_128'", ",", "pretrained", "=", "pretrained", ",", "use_conv", "=", "use_conv", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.levit_192": [[98, 102], ["levit.create_levit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.create_levit"], ["", "@", "register_model", "\n", "def", "levit_192", "(", "pretrained", "=", "False", ",", "use_conv", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "create_levit", "(", "\n", "'levit_192'", ",", "pretrained", "=", "pretrained", ",", "use_conv", "=", "use_conv", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.levit_256": [[104, 108], ["levit.create_levit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.create_levit"], ["", "@", "register_model", "\n", "def", "levit_256", "(", "pretrained", "=", "False", ",", "use_conv", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "create_levit", "(", "\n", "'levit_256'", ",", "pretrained", "=", "pretrained", ",", "use_conv", "=", "use_conv", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.levit_384": [[110, 114], ["levit.create_levit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.create_levit"], ["", "@", "register_model", "\n", "def", "levit_384", "(", "pretrained", "=", "False", ",", "use_conv", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "create_levit", "(", "\n", "'levit_384'", ",", "pretrained", "=", "pretrained", ",", "use_conv", "=", "use_conv", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.stem_b16": [[191, 200], ["torch.Sequential", "levit.ConvNorm", "activation", "levit.ConvNorm", "activation", "levit.ConvNorm", "activation", "levit.ConvNorm"], "function", ["None"], ["", "", "def", "stem_b16", "(", "in_chs", ",", "out_chs", ",", "activation", ",", "resolution", "=", "224", ")", ":", "\n", "    ", "return", "nn", ".", "Sequential", "(", "\n", "ConvNorm", "(", "in_chs", ",", "out_chs", "//", "8", ",", "3", ",", "2", ",", "1", ",", "resolution", "=", "resolution", ")", ",", "\n", "activation", "(", ")", ",", "\n", "ConvNorm", "(", "out_chs", "//", "8", ",", "out_chs", "//", "4", ",", "3", ",", "2", ",", "1", ",", "resolution", "=", "resolution", "//", "2", ")", ",", "\n", "activation", "(", ")", ",", "\n", "ConvNorm", "(", "out_chs", "//", "4", ",", "out_chs", "//", "2", ",", "3", ",", "2", ",", "1", ",", "resolution", "=", "resolution", "//", "4", ")", ",", "\n", "activation", "(", ")", ",", "\n", "ConvNorm", "(", "out_chs", "//", "2", ",", "out_chs", ",", "3", ",", "2", ",", "1", ",", "resolution", "=", "resolution", "//", "8", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.checkpoint_filter_fn": [[539, 548], ["model.state_dict", "state_dict.keys"], "function", ["None"], ["", "", "def", "checkpoint_filter_fn", "(", "state_dict", ",", "model", ")", ":", "\n", "    ", "if", "'model'", "in", "state_dict", ":", "\n", "# For deit models", "\n", "        ", "state_dict", "=", "state_dict", "[", "'model'", "]", "\n", "", "D", "=", "model", ".", "state_dict", "(", ")", "\n", "for", "k", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "        ", "if", "k", "in", "D", "and", "D", "[", "k", "]", ".", "ndim", "==", "4", "and", "state_dict", "[", "k", "]", ".", "ndim", "==", "2", ":", "\n", "            ", "state_dict", "[", "k", "]", "=", "state_dict", "[", "k", "]", "[", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.levit.create_levit": [[550, 562], ["kwargs.get", "dict", "helpers.build_model_with_cfg", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "def", "create_levit", "(", "variant", ",", "pretrained", "=", "False", ",", "default_cfg", "=", "None", ",", "fuse", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", ".", "get", "(", "'features_only'", ",", "None", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'features_only not implemented for Vision Transformer models.'", ")", "\n", "\n", "", "model_cfg", "=", "dict", "(", "**", "model_cfgs", "[", "variant", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "build_model_with_cfg", "(", "\n", "Levit", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_filter_fn", "=", "checkpoint_filter_fn", ",", "\n", "**", "model_cfg", ")", "\n", "#if fuse:", "\n", "#    utils.replace_batchnorm(model)", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilevit.MobileViTBlock.__init__": [[148, 200], ["torch.nn.Module.__init__", "byobnet.num_groups", "layers.conv_norm_act", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Sequential", "torch.nn.Sequential", "transformer_norm_layer", "layers.conv_norm_act", "layers.to_2tuple", "byobnet.LayerFn", "layers.make_divisible", "layers.conv_norm_act", "vision_transformer.Block", "range"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.num_groups", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_chs", ":", "int", ",", "\n", "out_chs", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "kernel_size", ":", "int", "=", "3", ",", "\n", "stride", ":", "int", "=", "1", ",", "\n", "bottle_ratio", ":", "float", "=", "1.0", ",", "\n", "group_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "dilation", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "1", ",", "1", ")", ",", "\n", "mlp_ratio", ":", "float", "=", "2.0", ",", "\n", "transformer_dim", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "transformer_depth", ":", "int", "=", "2", ",", "\n", "patch_size", ":", "int", "=", "8", ",", "\n", "num_heads", ":", "int", "=", "4", ",", "\n", "attn_drop", ":", "float", "=", "0.", ",", "\n", "drop", ":", "int", "=", "0.", ",", "\n", "no_fusion", ":", "bool", "=", "False", ",", "\n", "drop_path_rate", ":", "float", "=", "0.", ",", "\n", "layers", ":", "LayerFn", "=", "None", ",", "\n", "transformer_norm_layer", ":", "Callable", "=", "nn", ".", "LayerNorm", ",", "\n", "downsample", ":", "str", "=", "''", "\n", ")", ":", "\n", "        ", "super", "(", "MobileViTBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "layers", "=", "layers", "or", "LayerFn", "(", ")", "\n", "groups", "=", "num_groups", "(", "group_size", ",", "in_chs", ")", "\n", "out_chs", "=", "out_chs", "or", "in_chs", "\n", "transformer_dim", "=", "transformer_dim", "or", "make_divisible", "(", "bottle_ratio", "*", "in_chs", ")", "\n", "\n", "self", ".", "conv_kxk", "=", "layers", ".", "conv_norm_act", "(", "\n", "in_chs", ",", "in_chs", ",", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "groups", "=", "groups", ",", "dilation", "=", "dilation", "[", "0", "]", ")", "\n", "self", ".", "conv_1x1", "=", "nn", ".", "Conv2d", "(", "in_chs", ",", "transformer_dim", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "transformer", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "TransformerBlock", "(", "\n", "transformer_dim", ",", "mlp_ratio", "=", "mlp_ratio", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "True", ",", "\n", "attn_drop", "=", "attn_drop", ",", "drop", "=", "drop", ",", "drop_path", "=", "drop_path_rate", ",", "\n", "act_layer", "=", "layers", ".", "act", ",", "norm_layer", "=", "transformer_norm_layer", ")", "\n", "for", "_", "in", "range", "(", "transformer_depth", ")", "\n", "]", ")", "\n", "self", ".", "norm", "=", "transformer_norm_layer", "(", "transformer_dim", ")", "\n", "\n", "self", ".", "conv_proj", "=", "layers", ".", "conv_norm_act", "(", "transformer_dim", ",", "out_chs", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "\n", "if", "no_fusion", ":", "\n", "            ", "self", ".", "conv_fusion", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv_fusion", "=", "layers", ".", "conv_norm_act", "(", "in_chs", "+", "out_chs", ",", "out_chs", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "1", ")", "\n", "\n", "", "self", ".", "patch_size", "=", "to_2tuple", "(", "patch_size", ")", "\n", "self", ".", "patch_area", "=", "self", ".", "patch_size", "[", "0", "]", "*", "self", ".", "patch_size", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilevit.MobileViTBlock.forward": [[201, 242], ["mobilevit.MobileViTBlock.conv_kxk", "mobilevit.MobileViTBlock.conv_1x1", "mobilevit.MobileViTBlock.reshape().transpose", "mobilevit.MobileViTBlock.reshape().transpose().reshape", "mobilevit.MobileViTBlock.transformer", "mobilevit.MobileViTBlock.norm", "mobilevit.MobileViTBlock.contiguous().view", "mobilevit.MobileViTBlock.transpose().reshape", "mobilevit.MobileViTBlock.transpose().reshape", "mobilevit.MobileViTBlock.conv_proj", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "mobilevit.MobileViTBlock.conv_fusion", "math.ceil", "math.ceil", "mobilevit.MobileViTBlock.reshape", "mobilevit.MobileViTBlock.reshape().transpose", "mobilevit.MobileViTBlock.contiguous", "mobilevit.MobileViTBlock.transpose", "mobilevit.MobileViTBlock.transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mobilevit.MobileViTBlock.reshape"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "shortcut", "=", "x", "\n", "\n", "# Local representation", "\n", "x", "=", "self", ".", "conv_kxk", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_1x1", "(", "x", ")", "\n", "\n", "# Unfold (feature map -> patches)", "\n", "patch_h", ",", "patch_w", "=", "self", ".", "patch_size", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "new_h", ",", "new_w", "=", "math", ".", "ceil", "(", "H", "/", "patch_h", ")", "*", "patch_h", ",", "math", ".", "ceil", "(", "W", "/", "patch_w", ")", "*", "patch_w", "\n", "num_patch_h", ",", "num_patch_w", "=", "new_h", "//", "patch_h", ",", "new_w", "//", "patch_w", "# n_h, n_w", "\n", "num_patches", "=", "num_patch_h", "*", "num_patch_w", "# N", "\n", "interpolate", "=", "False", "\n", "if", "new_h", "!=", "H", "or", "new_w", "!=", "W", ":", "\n", "# Note: Padding can be done, but then it needs to be handled in attention function.", "\n", "            ", "x", "=", "F", ".", "interpolate", "(", "x", ",", "size", "=", "(", "new_h", ",", "new_w", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", "interpolate", "=", "True", "\n", "\n", "# [B, C, H, W] --> [B * C * n_h, n_w, p_h, p_w]", "\n", "", "x", "=", "x", ".", "reshape", "(", "B", "*", "C", "*", "num_patch_h", ",", "patch_h", ",", "num_patch_w", ",", "patch_w", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# [B * C * n_h, n_w, p_h, p_w] --> [BP, N, C] where P = p_h * p_w and N = n_h * n_w", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "C", ",", "num_patches", ",", "self", ".", "patch_area", ")", ".", "transpose", "(", "1", ",", "3", ")", ".", "reshape", "(", "B", "*", "self", ".", "patch_area", ",", "num_patches", ",", "-", "1", ")", "\n", "\n", "# Global representations", "\n", "x", "=", "self", ".", "transformer", "(", "x", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "\n", "# Fold (patch -> feature map)", "\n", "# [B, P, N, C] --> [B*C*n_h, n_w, p_h, p_w]", "\n", "x", "=", "x", ".", "contiguous", "(", ")", ".", "view", "(", "B", ",", "self", ".", "patch_area", ",", "num_patches", ",", "-", "1", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "3", ")", ".", "reshape", "(", "B", "*", "C", "*", "num_patch_h", ",", "num_patch_w", ",", "patch_h", ",", "patch_w", ")", "\n", "# [B*C*n_h, n_w, p_h, p_w] --> [B*C*n_h, p_h, n_w, p_w] --> [B, C, H, W]", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "C", ",", "num_patch_h", "*", "patch_h", ",", "num_patch_w", "*", "patch_w", ")", "\n", "if", "interpolate", ":", "\n", "            ", "x", "=", "F", ".", "interpolate", "(", "x", ",", "size", "=", "(", "H", ",", "W", ")", ",", "mode", "=", "\"bilinear\"", ",", "align_corners", "=", "False", ")", "\n", "\n", "", "x", "=", "self", ".", "conv_proj", "(", "x", ")", "\n", "if", "self", ".", "conv_fusion", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "conv_fusion", "(", "torch", ".", "cat", "(", "(", "shortcut", ",", "x", ")", ",", "dim", "=", "1", ")", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilevit._cfg": [[32, 40], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "256", ",", "256", ")", ",", "'pool_size'", ":", "(", "8", ",", "8", ")", ",", "\n", "'crop_pct'", ":", "0.9", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "(", "0", ",", "0", ",", "0", ")", ",", "'std'", ":", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "'first_conv'", ":", "'stem.conv'", ",", "'classifier'", ":", "'head.fc'", ",", "\n", "'fixed_input_size'", ":", "False", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilevit._inverted_residual_block": [[54, 59], ["byobnet.ByoBlockCfg", "dict"], "function", ["None"], ["def", "_inverted_residual_block", "(", "d", ",", "c", ",", "s", ",", "br", "=", "4.0", ")", ":", "\n", "# inverted residual is a bottleneck block with bottle_ratio > 1 applied to in_chs, linear output, gs=1 (depthwise)", "\n", "    ", "return", "ByoBlockCfg", "(", "\n", "type", "=", "'bottle'", ",", "d", "=", "d", ",", "c", "=", "c", ",", "s", "=", "s", ",", "gs", "=", "1", ",", "br", "=", "br", ",", "\n", "block_kwargs", "=", "dict", "(", "bottle_in", "=", "True", ",", "linear_out", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilevit._mobilevit_block": [[61, 71], ["mobilevit._inverted_residual_block", "byobnet.ByoBlockCfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilevit._inverted_residual_block"], ["", "def", "_mobilevit_block", "(", "d", ",", "c", ",", "s", ",", "transformer_dim", ",", "transformer_depth", ",", "patch_size", "=", "4", ",", "br", "=", "4.0", ")", ":", "\n", "# inverted residual + mobilevit blocks as per MobileViT network", "\n", "    ", "return", "(", "\n", "_inverted_residual_block", "(", "d", "=", "d", ",", "c", "=", "c", ",", "s", "=", "s", ",", "br", "=", "br", ")", ",", "\n", "ByoBlockCfg", "(", "\n", "type", "=", "'mobilevit'", ",", "d", "=", "1", ",", "c", "=", "c", ",", "s", "=", "1", ",", "\n", "block_kwargs", "=", "dict", "(", "\n", "transformer_dim", "=", "transformer_dim", ",", "\n", "transformer_depth", "=", "transformer_depth", ",", "\n", "patch_size", "=", "patch_size", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilevit._create_mobilevit": [[247, 253], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["def", "_create_mobilevit", "(", "variant", ",", "cfg_variant", "=", "None", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "\n", "ByobNet", ",", "variant", ",", "pretrained", ",", "\n", "model_cfg", "=", "model_cfgs", "[", "variant", "]", "if", "not", "cfg_variant", "else", "model_cfgs", "[", "cfg_variant", "]", ",", "\n", "feature_cfg", "=", "dict", "(", "flatten_sequential", "=", "True", ")", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilevit.mobilevit_xxs": [[255, 258], ["mobilevit._create_mobilevit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilevit._create_mobilevit"], ["", "@", "register_model", "\n", "def", "mobilevit_xxs", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_mobilevit", "(", "'mobilevit_xxs'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilevit.mobilevit_xs": [[260, 263], ["mobilevit._create_mobilevit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilevit._create_mobilevit"], ["", "@", "register_model", "\n", "def", "mobilevit_xs", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_mobilevit", "(", "'mobilevit_xs'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilevit.mobilevit_s": [[265, 268], ["mobilevit._create_mobilevit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilevit._create_mobilevit"], ["", "@", "register_model", "\n", "def", "mobilevit_s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_mobilevit", "(", "'mobilevit_s'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilevit.semobilevit_s": [[270, 273], ["mobilevit._create_mobilevit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.mobilevit._create_mobilevit"], ["", "@", "register_model", "\n", "def", "semobilevit_s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_mobilevit", "(", "'semobilevit_s'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Attention.__init__": [[98, 133], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Parameter", "torch.Parameter", "torch.Parameter", "beit.Attention.register_buffer", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "beit.Attention.register_buffer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "beit.gen_relative_position_index"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.gen_relative_position_index"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "qkv_bias", "=", "False", ",", "attn_drop", "=", "0.", ",", "\n", "proj_drop", "=", "0.", ",", "window_size", "=", "None", ",", "attn_head_dim", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "if", "attn_head_dim", "is", "not", "None", ":", "\n", "            ", "head_dim", "=", "attn_head_dim", "\n", "", "all_head_dim", "=", "head_dim", "*", "self", ".", "num_heads", "\n", "self", ".", "scale", "=", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "all_head_dim", "*", "3", ",", "bias", "=", "False", ")", "\n", "if", "qkv_bias", ":", "\n", "            ", "self", ".", "q_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "all_head_dim", ")", ")", "\n", "self", ".", "register_buffer", "(", "'k_bias'", ",", "torch", ".", "zeros", "(", "all_head_dim", ")", ",", "persistent", "=", "False", ")", "\n", "self", ".", "v_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "all_head_dim", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "q_bias", "=", "None", "\n", "self", ".", "k_bias", "=", "None", "\n", "self", ".", "v_bias", "=", "None", "\n", "\n", "", "if", "window_size", ":", "\n", "            ", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "num_relative_distance", "=", "(", "2", "*", "window_size", "[", "0", "]", "-", "1", ")", "*", "(", "2", "*", "window_size", "[", "1", "]", "-", "1", ")", "+", "3", "\n", "self", ".", "relative_position_bias_table", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "self", ".", "num_relative_distance", ",", "num_heads", ")", ")", "# 2*Wh-1 * 2*Ww-1, nH", "\n", "self", ".", "register_buffer", "(", "\"relative_position_index\"", ",", "gen_relative_position_index", "(", "window_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "window_size", "=", "None", "\n", "self", ".", "relative_position_bias_table", "=", "None", "\n", "self", ".", "relative_position_index", "=", "None", "\n", "\n", "", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "all_head_dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Attention._get_rel_pos_bias": [[134, 141], ["beit.Attention.relative_position_bias_table[].view", "relative_position_bias.permute().contiguous.permute().contiguous.permute().contiguous", "relative_position_bias.permute().contiguous.permute().contiguous.unsqueeze", "relative_position_bias.permute().contiguous.permute().contiguous.permute", "beit.Attention.relative_position_index.view"], "methods", ["None"], ["", "def", "_get_rel_pos_bias", "(", "self", ")", ":", "\n", "        ", "relative_position_bias", "=", "self", ".", "relative_position_bias_table", "[", "\n", "self", ".", "relative_position_index", ".", "view", "(", "-", "1", ")", "]", ".", "view", "(", "\n", "self", ".", "window_size", "[", "0", "]", "*", "self", ".", "window_size", "[", "1", "]", "+", "1", ",", "\n", "self", ".", "window_size", "[", "0", "]", "*", "self", ".", "window_size", "[", "1", "]", "+", "1", ",", "-", "1", ")", "# Wh*Ww,Wh*Ww,nH", "\n", "relative_position_bias", "=", "relative_position_bias", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "# nH, Wh*Ww, Wh*Ww", "\n", "return", "relative_position_bias", ".", "unsqueeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Attention.forward": [[142, 165], ["torch.linear", "torch.linear", "torch.linear", "qkv.reshape().permute.reshape().permute.reshape().permute", "qkv.reshape().permute.reshape().permute.unbind", "beit.Attention.softmax", "beit.Attention.attn_drop", "beit.Attention.proj", "beit.Attention.proj_drop", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "k.transpose", "qkv.reshape().permute.reshape().permute.reshape", "beit.Attention._get_rel_pos_bias"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.WindowAttention._get_rel_pos_bias"], ["", "def", "forward", "(", "self", ",", "x", ",", "shared_rel_pos_bias", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "\n", "qkv_bias", "=", "torch", ".", "cat", "(", "(", "self", ".", "q_bias", ",", "self", ".", "k_bias", ",", "self", ".", "v_bias", ")", ")", "if", "self", ".", "q_bias", "is", "not", "None", "else", "None", "\n", "qkv", "=", "F", ".", "linear", "(", "input", "=", "x", ",", "weight", "=", "self", ".", "qkv", ".", "weight", ",", "bias", "=", "qkv_bias", ")", "\n", "qkv", "=", "qkv", ".", "reshape", "(", "B", ",", "N", ",", "3", ",", "self", ".", "num_heads", ",", "-", "1", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", ".", "unbind", "(", "0", ")", "# make torchscript happy (cannot use tensor as tuple)", "\n", "\n", "q", "=", "q", "*", "self", ".", "scale", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "if", "self", ".", "relative_position_bias_table", "is", "not", "None", ":", "\n", "            ", "attn", "=", "attn", "+", "self", ".", "_get_rel_pos_bias", "(", ")", "\n", "", "if", "shared_rel_pos_bias", "is", "not", "None", ":", "\n", "            ", "attn", "=", "attn", "+", "shared_rel_pos_bias", "\n", "\n", "", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "N", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Block.__init__": [[169, 189], ["torch.Module.__init__", "norm_layer", "beit.Attention", "norm_layer", "int", "layers.Mlp", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dim", ",", "num_heads", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "\n", "drop_path", "=", "0.", ",", "init_values", "=", "None", ",", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "\n", "window_size", "=", "None", ",", "attn_head_dim", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "\n", "dim", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ",", "\n", "window_size", "=", "window_size", ",", "attn_head_dim", "=", "attn_head_dim", ")", "\n", "# NOTE: drop path for stochastic depth, we shall see if this is better than dropout here", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "mlp_hidden_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "in_features", "=", "dim", ",", "hidden_features", "=", "mlp_hidden_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "\n", "if", "init_values", ":", "\n", "            ", "self", ".", "gamma_1", "=", "nn", ".", "Parameter", "(", "init_values", "*", "torch", ".", "ones", "(", "dim", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "gamma_2", "=", "nn", ".", "Parameter", "(", "init_values", "*", "torch", ".", "ones", "(", "dim", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "gamma_1", ",", "self", ".", "gamma_2", "=", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Block.forward": [[190, 198], ["beit.Block.drop_path", "beit.Block.drop_path", "beit.Block.drop_path", "beit.Block.drop_path", "beit.Block.attn", "beit.Block.mlp", "beit.Block.norm1", "beit.Block.norm2", "beit.Block.attn", "beit.Block.mlp", "beit.Block.norm1", "beit.Block.norm2"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "shared_rel_pos_bias", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "gamma_1", "is", "None", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "attn", "(", "self", ".", "norm1", "(", "x", ")", ",", "shared_rel_pos_bias", "=", "shared_rel_pos_bias", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "gamma_1", "*", "self", ".", "attn", "(", "self", ".", "norm1", "(", "x", ")", ",", "shared_rel_pos_bias", "=", "shared_rel_pos_bias", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "gamma_2", "*", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.RelativePositionBias.__init__": [[202, 210], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "beit.RelativePositionBias.register_buffer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "beit.gen_relative_position_index"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.gen_relative_position_index"], ["    ", "def", "__init__", "(", "self", ",", "window_size", ",", "num_heads", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "window_area", "=", "window_size", "[", "0", "]", "*", "window_size", "[", "1", "]", "\n", "num_relative_distance", "=", "(", "2", "*", "window_size", "[", "0", "]", "-", "1", ")", "*", "(", "2", "*", "window_size", "[", "1", "]", "-", "1", ")", "+", "3", "\n", "self", ".", "relative_position_bias_table", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_relative_distance", ",", "num_heads", ")", ")", "\n", "# trunc_normal_(self.relative_position_bias_table, std=.02)", "\n", "self", ".", "register_buffer", "(", "\"relative_position_index\"", ",", "gen_relative_position_index", "(", "window_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.RelativePositionBias.forward": [[211, 215], ["beit.RelativePositionBias.relative_position_bias_table[].view", "beit.RelativePositionBias.permute().contiguous", "beit.RelativePositionBias.permute", "beit.RelativePositionBias.relative_position_index.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "relative_position_bias", "=", "self", ".", "relative_position_bias_table", "[", "self", ".", "relative_position_index", ".", "view", "(", "-", "1", ")", "]", ".", "view", "(", "\n", "self", ".", "window_area", "+", "1", ",", "self", ".", "window_area", "+", "1", ",", "-", "1", ")", "# Wh*Ww,Wh*Ww,nH", "\n", "return", "relative_position_bias", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "# nH, Wh*Ww, Wh*Ww", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Beit.__init__": [[221, 269], ["functools.partial", "torch.Module.__init__", "layers.PatchEmbed", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "beit.Beit.apply", "layers.trunc_normal_", "beit.Beit.fix_init_weight", "isinstance", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Parameter", "torch.Parameter", "torch.Parameter", "beit.RelativePositionBias", "x.item", "torch.Identity", "torch.Identity", "torch.Identity", "norm_layer", "norm_layer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "layers.trunc_normal_", "layers.trunc_normal_", "beit.Beit.head.weight.data.mul_", "beit.Beit.head.bias.data.mul_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "beit.Block", "range"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Beit.fix_init_weight", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["def", "__init__", "(", "\n", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "global_pool", "=", "'avg'", ",", "\n", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "True", ",", "drop_rate", "=", "0.", ",", "\n", "attn_drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "\n", "init_values", "=", "None", ",", "use_abs_pos_emb", "=", "True", ",", "use_rel_pos_bias", "=", "False", ",", "use_shared_rel_pos_bias", "=", "False", ",", "\n", "head_init_scale", "=", "0.001", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "self", ".", "num_features", "=", "self", ".", "embed_dim", "=", "embed_dim", "# num_features for consistency with other models", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "self", ".", "patch_embed", "=", "PatchEmbed", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "embed_dim", "=", "embed_dim", ")", "\n", "num_patches", "=", "self", ".", "patch_embed", ".", "num_patches", "\n", "\n", "self", ".", "cls_token", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "# self.mask_token = nn.Parameter(torch.zeros(1, 1, embed_dim))", "\n", "self", ".", "pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "num_patches", "+", "1", ",", "embed_dim", ")", ")", "if", "use_abs_pos_emb", "else", "None", "\n", "self", ".", "pos_drop", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", "\n", "\n", "if", "use_shared_rel_pos_bias", ":", "\n", "            ", "self", ".", "rel_pos_bias", "=", "RelativePositionBias", "(", "window_size", "=", "self", ".", "patch_embed", ".", "grid_size", ",", "num_heads", "=", "num_heads", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "rel_pos_bias", "=", "None", "\n", "\n", "", "dpr", "=", "[", "x", ".", "item", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "depth", ")", "]", "# stochastic depth decay rule", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "[", "\n", "Block", "(", "\n", "dim", "=", "embed_dim", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", "[", "i", "]", ",", "norm_layer", "=", "norm_layer", ",", "\n", "init_values", "=", "init_values", ",", "window_size", "=", "self", ".", "patch_embed", ".", "grid_size", "if", "use_rel_pos_bias", "else", "None", ")", "\n", "for", "i", "in", "range", "(", "depth", ")", "]", ")", "\n", "use_fc_norm", "=", "self", ".", "global_pool", "==", "'avg'", "\n", "self", ".", "norm", "=", "nn", ".", "Identity", "(", ")", "if", "use_fc_norm", "else", "norm_layer", "(", "embed_dim", ")", "\n", "self", ".", "fc_norm", "=", "norm_layer", "(", "embed_dim", ")", "if", "use_fc_norm", "else", "None", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "if", "self", ".", "pos_embed", "is", "not", "None", ":", "\n", "            ", "trunc_normal_", "(", "self", ".", "pos_embed", ",", "std", "=", ".02", ")", "\n", "", "trunc_normal_", "(", "self", ".", "cls_token", ",", "std", "=", ".02", ")", "\n", "# trunc_normal_(self.mask_token, std=.02)", "\n", "self", ".", "fix_init_weight", "(", ")", "\n", "if", "isinstance", "(", "self", ".", "head", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "trunc_normal_", "(", "self", ".", "head", ".", "weight", ",", "std", "=", ".02", ")", "\n", "self", ".", "head", ".", "weight", ".", "data", ".", "mul_", "(", "head_init_scale", ")", "\n", "self", ".", "head", ".", "bias", ".", "data", ".", "mul_", "(", "head_init_scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Beit.fix_init_weight": [[270, 277], ["enumerate", "param.div_", "beit.Beit.fix_init_weight.rescale"], "methods", ["None"], ["", "", "def", "fix_init_weight", "(", "self", ")", ":", "\n", "        ", "def", "rescale", "(", "param", ",", "layer_id", ")", ":", "\n", "            ", "param", ".", "div_", "(", "math", ".", "sqrt", "(", "2.0", "*", "layer_id", ")", ")", "\n", "\n", "", "for", "layer_id", ",", "layer", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "            ", "rescale", "(", "layer", ".", "attn", ".", "proj", ".", "weight", ".", "data", ",", "layer_id", "+", "1", ")", "\n", "rescale", "(", "layer", ".", "mlp", ".", "fc2", ".", "weight", ".", "data", ",", "layer_id", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Beit._init_weights": [[278, 286], ["isinstance", "layers.trunc_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", ".02", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Beit.no_weight_decay": [[287, 294], ["beit.Beit.named_parameters", "nwd.add"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "nwd", "=", "{", "'pos_embed'", ",", "'cls_token'", "}", "\n", "for", "n", ",", "_", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "'relative_position_bias_table'", "in", "n", ":", "\n", "                ", "nwd", ".", "add", "(", "n", ")", "\n", "", "", "return", "nwd", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Beit.set_grad_checkpointing": [[295, 298], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Beit.group_matcher": [[299, 306], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem", "=", "r'^cls_token|pos_embed|patch_embed|rel_pos_bias'", ",", "# stem and embed", "\n", "blocks", "=", "[", "(", "r'^blocks\\.(\\d+)'", ",", "None", ")", ",", "(", "r'^norm'", ",", "(", "99999", ",", ")", ")", "]", ",", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Beit.get_classifier": [[307, 310], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Beit.reset_classifier": [[311, 316], ["torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "None", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "if", "global_pool", "is", "not", "None", ":", "\n", "            ", "self", ".", "global_pool", "=", "global_pool", "\n", "", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Beit.forward_features": [[317, 332], ["beit.Beit.patch_embed", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "beit.Beit.pos_drop", "beit.Beit.norm", "beit.Beit.rel_pos_bias", "beit.Beit.cls_token.expand", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "blk", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "self", ".", "cls_token", ".", "expand", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "-", "1", ")", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "if", "self", ".", "pos_embed", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "pos_embed", "\n", "", "x", "=", "self", ".", "pos_drop", "(", "x", ")", "\n", "\n", "rel_pos_bias", "=", "self", ".", "rel_pos_bias", "(", ")", "if", "self", ".", "rel_pos_bias", "is", "not", "None", "else", "None", "\n", "for", "blk", "in", "self", ".", "blocks", ":", "\n", "            ", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "                ", "x", "=", "checkpoint", "(", "blk", ",", "x", ",", "shared_rel_pos_bias", "=", "rel_pos_bias", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "blk", "(", "x", ",", "shared_rel_pos_bias", "=", "rel_pos_bias", ")", "\n", "", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Beit.forward_head": [[333, 340], ["x[].mean", "beit.Beit.fc_norm", "beit.Beit.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "fc_norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", "1", ":", "]", ".", "mean", "(", "dim", "=", "1", ")", "\n", "x", "=", "self", ".", "fc_norm", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", "0", "]", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.Beit.forward": [[341, 345], ["beit.Beit.forward_features", "beit.Beit.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit._cfg": [[36, 44], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", ".9", ",", "'interpolation'", ":", "'bicubic'", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'mean'", ":", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "'std'", ":", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "\n", "'first_conv'", ":", "'patch_embed.proj'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.gen_relative_position_index": [[75, 95], ["torch.stack", "torch.stack", "torch.stack", "torch.flatten", "torch.flatten", "torch.flatten", "relative_coords.permute().contiguous.permute().contiguous", "torch.zeros", "torch.zeros", "torch.zeros", "relative_coords.permute().contiguous.sum", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "relative_coords.permute().contiguous.permute", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "function", ["None"], ["def", "gen_relative_position_index", "(", "window_size", ":", "Tuple", "[", "int", ",", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "num_relative_distance", "=", "(", "2", "*", "window_size", "[", "0", "]", "-", "1", ")", "*", "(", "2", "*", "window_size", "[", "1", "]", "-", "1", ")", "+", "3", "\n", "# cls to token & token 2 cls & cls to cls", "\n", "# get pair-wise relative position index for each token inside the window", "\n", "window_area", "=", "window_size", "[", "0", "]", "*", "window_size", "[", "1", "]", "\n", "coords", "=", "torch", ".", "stack", "(", "torch", ".", "meshgrid", "(", "\n", "[", "torch", ".", "arange", "(", "window_size", "[", "0", "]", ")", ",", "\n", "torch", ".", "arange", "(", "window_size", "[", "1", "]", ")", "]", ")", ")", "# 2, Wh, Ww", "\n", "coords_flatten", "=", "torch", ".", "flatten", "(", "coords", ",", "1", ")", "# 2, Wh*Ww", "\n", "relative_coords", "=", "coords_flatten", "[", ":", ",", ":", ",", "None", "]", "-", "coords_flatten", "[", ":", ",", "None", ",", ":", "]", "# 2, Wh*Ww, Wh*Ww", "\n", "relative_coords", "=", "relative_coords", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "# Wh*Ww, Wh*Ww, 2", "\n", "relative_coords", "[", ":", ",", ":", ",", "0", "]", "+=", "window_size", "[", "0", "]", "-", "1", "# shift to start from 0", "\n", "relative_coords", "[", ":", ",", ":", ",", "1", "]", "+=", "window_size", "[", "1", "]", "-", "1", "\n", "relative_coords", "[", ":", ",", ":", ",", "0", "]", "*=", "2", "*", "window_size", "[", "1", "]", "-", "1", "\n", "relative_position_index", "=", "torch", ".", "zeros", "(", "size", "=", "(", "window_area", "+", "1", ",", ")", "*", "2", ",", "dtype", "=", "relative_coords", ".", "dtype", ")", "\n", "relative_position_index", "[", "1", ":", ",", "1", ":", "]", "=", "relative_coords", ".", "sum", "(", "-", "1", ")", "# Wh*Ww, Wh*Ww", "\n", "relative_position_index", "[", "0", ",", "0", ":", "]", "=", "num_relative_distance", "-", "3", "\n", "relative_position_index", "[", "0", ":", ",", "0", "]", "=", "num_relative_distance", "-", "2", "\n", "relative_position_index", "[", "0", ",", "0", "]", "=", "num_relative_distance", "-", "1", "\n", "return", "relative_position_index", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit._create_beit": [[347, 357], ["kwargs.get", "helpers.build_model_with_cfg", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_beit", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", ".", "get", "(", "'features_only'", ",", "None", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'features_only not implemented for Beit models.'", ")", "\n", "\n", "", "model", "=", "build_model_with_cfg", "(", "\n", "Beit", ",", "variant", ",", "pretrained", ",", "\n", "# FIXME an updated filter fn needed to interpolate rel pos emb if fine tuning to diff model sizes", "\n", "pretrained_filter_fn", "=", "checkpoint_filter_fn", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.beit_base_patch16_224": [[359, 366], ["dict", "beit._create_beit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit._create_beit"], ["", "@", "register_model", "\n", "def", "beit_base_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "mlp_ratio", "=", "4", ",", "\n", "use_abs_pos_emb", "=", "False", ",", "use_rel_pos_bias", "=", "True", ",", "init_values", "=", "0.1", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_beit", "(", "'beit_base_patch16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.beit_base_patch16_384": [[368, 375], ["dict", "beit._create_beit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit._create_beit"], ["", "@", "register_model", "\n", "def", "beit_base_patch16_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "img_size", "=", "384", ",", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "mlp_ratio", "=", "4", ",", "\n", "use_abs_pos_emb", "=", "False", ",", "use_rel_pos_bias", "=", "True", ",", "init_values", "=", "0.1", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_beit", "(", "'beit_base_patch16_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.beit_base_patch16_224_in22k": [[377, 384], ["dict", "beit._create_beit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit._create_beit"], ["", "@", "register_model", "\n", "def", "beit_base_patch16_224_in22k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "mlp_ratio", "=", "4", ",", "\n", "use_abs_pos_emb", "=", "False", ",", "use_rel_pos_bias", "=", "True", ",", "init_values", "=", "0.1", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_beit", "(", "'beit_base_patch16_224_in22k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.beit_large_patch16_224": [[386, 393], ["dict", "beit._create_beit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit._create_beit"], ["", "@", "register_model", "\n", "def", "beit_large_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "mlp_ratio", "=", "4", ",", "qkv_bias", "=", "True", ",", "\n", "use_abs_pos_emb", "=", "False", ",", "use_rel_pos_bias", "=", "True", ",", "init_values", "=", "1e-5", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_beit", "(", "'beit_large_patch16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.beit_large_patch16_384": [[395, 402], ["dict", "beit._create_beit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit._create_beit"], ["", "@", "register_model", "\n", "def", "beit_large_patch16_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "img_size", "=", "384", ",", "patch_size", "=", "16", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "mlp_ratio", "=", "4", ",", "qkv_bias", "=", "True", ",", "\n", "use_abs_pos_emb", "=", "False", ",", "use_rel_pos_bias", "=", "True", ",", "init_values", "=", "1e-5", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_beit", "(", "'beit_large_patch16_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.beit_large_patch16_512": [[404, 411], ["dict", "beit._create_beit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit._create_beit"], ["", "@", "register_model", "\n", "def", "beit_large_patch16_512", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "img_size", "=", "512", ",", "patch_size", "=", "16", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "mlp_ratio", "=", "4", ",", "qkv_bias", "=", "True", ",", "\n", "use_abs_pos_emb", "=", "False", ",", "use_rel_pos_bias", "=", "True", ",", "init_values", "=", "1e-5", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_beit", "(", "'beit_large_patch16_512'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit.beit_large_patch16_224_in22k": [[413, 420], ["dict", "beit._create_beit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.beit._create_beit"], ["", "@", "register_model", "\n", "def", "beit_large_patch16_224_in22k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "mlp_ratio", "=", "4", ",", "qkv_bias", "=", "True", ",", "\n", "use_abs_pos_emb", "=", "False", ",", "use_rel_pos_bias", "=", "True", ",", "init_values", "=", "1e-5", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_beit", "(", "'beit_large_patch16_224_in22k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.WindowAttention.__init__": [[161, 186], ["torch.Module.__init__", "layers.to_2tuple", "torch.Parameter", "torch.Parameter", "swin_transformer.WindowAttention.register_buffer", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "layers.trunc_normal_", "torch.Softmax", "torch.Softmax", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "swin_transformer.get_relative_position_index"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.get_relative_position_index"], ["def", "__init__", "(", "self", ",", "dim", ",", "num_heads", ",", "head_dim", "=", "None", ",", "window_size", "=", "7", ",", "qkv_bias", "=", "True", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "window_size", "=", "to_2tuple", "(", "window_size", ")", "# Wh, Ww", "\n", "win_h", ",", "win_w", "=", "self", ".", "window_size", "\n", "self", ".", "window_area", "=", "win_h", "*", "win_w", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "head_dim", "or", "dim", "//", "num_heads", "\n", "attn_dim", "=", "head_dim", "*", "num_heads", "\n", "self", ".", "scale", "=", "head_dim", "**", "-", "0.5", "\n", "\n", "# define a parameter table of relative position bias, shape: 2*Wh-1 * 2*Ww-1, nH", "\n", "self", ".", "relative_position_bias_table", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "(", "2", "*", "win_h", "-", "1", ")", "*", "(", "2", "*", "win_w", "-", "1", ")", ",", "num_heads", ")", ")", "\n", "\n", "# get pair-wise relative position index for each token inside the window", "\n", "self", ".", "register_buffer", "(", "\"relative_position_index\"", ",", "get_relative_position_index", "(", "win_h", ",", "win_w", ")", ")", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "attn_dim", "*", "3", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "attn_dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n", "trunc_normal_", "(", "self", ".", "relative_position_bias_table", ",", "std", "=", ".02", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.WindowAttention._get_rel_pos_bias": [[187, 192], ["swin_transformer.WindowAttention.relative_position_bias_table[].view", "relative_position_bias.permute().contiguous.permute().contiguous.permute().contiguous", "relative_position_bias.permute().contiguous.permute().contiguous.unsqueeze", "relative_position_bias.permute().contiguous.permute().contiguous.permute", "swin_transformer.WindowAttention.relative_position_index.view"], "methods", ["None"], ["", "def", "_get_rel_pos_bias", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "relative_position_bias", "=", "self", ".", "relative_position_bias_table", "[", "\n", "self", ".", "relative_position_index", ".", "view", "(", "-", "1", ")", "]", ".", "view", "(", "self", ".", "window_area", ",", "self", ".", "window_area", ",", "-", "1", ")", "# Wh*Ww,Wh*Ww,nH", "\n", "relative_position_bias", "=", "relative_position_bias", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "# nH, Wh*Ww, Wh*Ww", "\n", "return", "relative_position_bias", ".", "unsqueeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.WindowAttention.forward": [[193, 221], ["swin_transformer.WindowAttention.qkv().reshape().permute", "swin_transformer.WindowAttention.unbind", "swin_transformer.WindowAttention.attn_drop", "swin_transformer.WindowAttention.proj", "swin_transformer.WindowAttention.proj_drop", "k.transpose", "swin_transformer.WindowAttention._get_rel_pos_bias", "swin_transformer.WindowAttention.view", "swin_transformer.WindowAttention.softmax", "swin_transformer.WindowAttention.softmax", "swin_transformer.WindowAttention.qkv().reshape", "swin_transformer.WindowAttention.view", "mask.unsqueeze().unsqueeze", "swin_transformer.WindowAttention.qkv", "mask.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.WindowAttention._get_rel_pos_bias"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x: input features with shape of (num_windows*B, N, C)\n            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n        \"\"\"", "\n", "B_", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "B_", ",", "N", ",", "3", ",", "self", ".", "num_heads", ",", "-", "1", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", ".", "unbind", "(", "0", ")", "# make torchscript happy (cannot use tensor as tuple)", "\n", "\n", "q", "=", "q", "*", "self", ".", "scale", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "attn", "=", "attn", "+", "self", ".", "_get_rel_pos_bias", "(", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "num_win", "=", "mask", ".", "shape", "[", "0", "]", "\n", "attn", "=", "attn", ".", "view", "(", "B_", "//", "num_win", ",", "num_win", ",", "self", ".", "num_heads", ",", "N", ",", "N", ")", "+", "mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "0", ")", "\n", "attn", "=", "attn", ".", "view", "(", "-", "1", ",", "self", ".", "num_heads", ",", "N", ",", "N", ")", "\n", "attn", "=", "self", ".", "softmax", "(", "attn", ")", "\n", "", "else", ":", "\n", "            ", "attn", "=", "self", ".", "softmax", "(", "attn", ")", "\n", "\n", "", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B_", ",", "N", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.SwinTransformerBlock.__init__": [[242, 290], ["torch.Module.__init__", "norm_layer", "swin_transformer.WindowAttention", "norm_layer", "layers.Mlp", "swin_transformer.SwinTransformerBlock.register_buffer", "min", "min", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "swin_transformer.window_partition", "mask_windows.view.view.view", "attn_mask.masked_fill().masked_fill.masked_fill().masked_fill.masked_fill().masked_fill", "layers.to_2tuple", "int", "slice", "slice", "slice", "mask_windows.view.view.unsqueeze", "mask_windows.view.view.unsqueeze", "float", "slice", "slice", "slice", "attn_mask.masked_fill().masked_fill.masked_fill().masked_fill.masked_fill", "float"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.window_partition"], ["def", "__init__", "(", "\n", "self", ",", "dim", ",", "input_resolution", ",", "num_heads", "=", "4", ",", "head_dim", "=", "None", ",", "window_size", "=", "7", ",", "shift_size", "=", "0", ",", "\n", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "True", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "drop_path", "=", "0.", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "input_resolution", "=", "input_resolution", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "shift_size", "=", "shift_size", "\n", "self", ".", "mlp_ratio", "=", "mlp_ratio", "\n", "if", "min", "(", "self", ".", "input_resolution", ")", "<=", "self", ".", "window_size", ":", "\n", "# if window size is larger than input resolution, we don't partition windows", "\n", "            ", "self", ".", "shift_size", "=", "0", "\n", "self", ".", "window_size", "=", "min", "(", "self", ".", "input_resolution", ")", "\n", "", "assert", "0", "<=", "self", ".", "shift_size", "<", "self", ".", "window_size", ",", "\"shift_size must in 0-window_size\"", "\n", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn", "=", "WindowAttention", "(", "\n", "dim", ",", "num_heads", "=", "num_heads", ",", "head_dim", "=", "head_dim", ",", "window_size", "=", "to_2tuple", "(", "self", ".", "window_size", ")", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ")", "\n", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "in_features", "=", "dim", ",", "hidden_features", "=", "int", "(", "dim", "*", "mlp_ratio", ")", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "\n", "if", "self", ".", "shift_size", ">", "0", ":", "\n", "# calculate attention mask for SW-MSA", "\n", "            ", "H", ",", "W", "=", "self", ".", "input_resolution", "\n", "img_mask", "=", "torch", ".", "zeros", "(", "(", "1", ",", "H", ",", "W", ",", "1", ")", ")", "# 1 H W 1", "\n", "cnt", "=", "0", "\n", "for", "h", "in", "(", "\n", "slice", "(", "0", ",", "-", "self", ".", "window_size", ")", ",", "\n", "slice", "(", "-", "self", ".", "window_size", ",", "-", "self", ".", "shift_size", ")", ",", "\n", "slice", "(", "-", "self", ".", "shift_size", ",", "None", ")", ")", ":", "\n", "                ", "for", "w", "in", "(", "\n", "slice", "(", "0", ",", "-", "self", ".", "window_size", ")", ",", "\n", "slice", "(", "-", "self", ".", "window_size", ",", "-", "self", ".", "shift_size", ")", ",", "\n", "slice", "(", "-", "self", ".", "shift_size", ",", "None", ")", ")", ":", "\n", "                    ", "img_mask", "[", ":", ",", "h", ",", "w", ",", ":", "]", "=", "cnt", "\n", "cnt", "+=", "1", "\n", "", "", "mask_windows", "=", "window_partition", "(", "img_mask", ",", "self", ".", "window_size", ")", "# num_win, window_size, window_size, 1", "\n", "mask_windows", "=", "mask_windows", ".", "view", "(", "-", "1", ",", "self", ".", "window_size", "*", "self", ".", "window_size", ")", "\n", "attn_mask", "=", "mask_windows", ".", "unsqueeze", "(", "1", ")", "-", "mask_windows", ".", "unsqueeze", "(", "2", ")", "\n", "attn_mask", "=", "attn_mask", ".", "masked_fill", "(", "attn_mask", "!=", "0", ",", "float", "(", "-", "100.0", ")", ")", ".", "masked_fill", "(", "attn_mask", "==", "0", ",", "float", "(", "0.0", ")", ")", "\n", "", "else", ":", "\n", "            ", "attn_mask", "=", "None", "\n", "\n", "", "self", ".", "register_buffer", "(", "\"attn_mask\"", ",", "attn_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.SwinTransformerBlock.forward": [[291, 329], ["layers._assert", "swin_transformer.SwinTransformerBlock.norm1", "torch.roll.view", "torch.roll.view", "swin_transformer.window_partition", "x_windows.view.view.view", "swin_transformer.SwinTransformerBlock.attn", "attn_windows.view.view.view", "swin_transformer.window_reverse", "torch.roll.view", "torch.roll.view", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "swin_transformer.SwinTransformerBlock.drop_path", "swin_transformer.SwinTransformerBlock.drop_path", "swin_transformer.SwinTransformerBlock.mlp", "swin_transformer.SwinTransformerBlock.norm2"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.window_partition", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.window_reverse", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "H", ",", "W", "=", "self", ".", "input_resolution", "\n", "B", ",", "L", ",", "C", "=", "x", ".", "shape", "\n", "_assert", "(", "L", "==", "H", "*", "W", ",", "\"input feature has wrong size\"", ")", "\n", "\n", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "norm1", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "H", ",", "W", ",", "C", ")", "\n", "\n", "# cyclic shift", "\n", "if", "self", ".", "shift_size", ">", "0", ":", "\n", "            ", "shifted_x", "=", "torch", ".", "roll", "(", "x", ",", "shifts", "=", "(", "-", "self", ".", "shift_size", ",", "-", "self", ".", "shift_size", ")", ",", "dims", "=", "(", "1", ",", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "shifted_x", "=", "x", "\n", "\n", "# partition windows", "\n", "", "x_windows", "=", "window_partition", "(", "shifted_x", ",", "self", ".", "window_size", ")", "# num_win*B, window_size, window_size, C", "\n", "x_windows", "=", "x_windows", ".", "view", "(", "-", "1", ",", "self", ".", "window_size", "*", "self", ".", "window_size", ",", "C", ")", "# num_win*B, window_size*window_size, C", "\n", "\n", "# W-MSA/SW-MSA", "\n", "attn_windows", "=", "self", ".", "attn", "(", "x_windows", ",", "mask", "=", "self", ".", "attn_mask", ")", "# num_win*B, window_size*window_size, C", "\n", "\n", "# merge windows", "\n", "attn_windows", "=", "attn_windows", ".", "view", "(", "-", "1", ",", "self", ".", "window_size", ",", "self", ".", "window_size", ",", "C", ")", "\n", "shifted_x", "=", "window_reverse", "(", "attn_windows", ",", "self", ".", "window_size", ",", "H", ",", "W", ")", "# B H' W' C", "\n", "\n", "# reverse cyclic shift", "\n", "if", "self", ".", "shift_size", ">", "0", ":", "\n", "            ", "x", "=", "torch", ".", "roll", "(", "shifted_x", ",", "shifts", "=", "(", "self", ".", "shift_size", ",", "self", ".", "shift_size", ")", ",", "dims", "=", "(", "1", ",", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "shifted_x", "\n", "", "x", "=", "x", ".", "view", "(", "B", ",", "H", "*", "W", ",", "C", ")", "\n", "\n", "# FFN", "\n", "x", "=", "shortcut", "+", "self", ".", "drop_path", "(", "x", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.PatchMerging.__init__": [[340, 347], ["torch.Module.__init__", "norm_layer", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "input_resolution", ",", "dim", ",", "out_dim", "=", "None", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_resolution", "=", "input_resolution", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "out_dim", "=", "out_dim", "or", "2", "*", "dim", "\n", "self", ".", "norm", "=", "norm_layer", "(", "4", "*", "dim", ")", "\n", "self", ".", "reduction", "=", "nn", ".", "Linear", "(", "4", "*", "dim", ",", "self", ".", "out_dim", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.PatchMerging.forward": [[348, 370], ["layers._assert", "layers._assert", "swin_transformer.PatchMerging.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "swin_transformer.PatchMerging.view", "swin_transformer.PatchMerging.norm", "swin_transformer.PatchMerging.reduction"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.reduction"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        x: B, H*W, C\n        \"\"\"", "\n", "H", ",", "W", "=", "self", ".", "input_resolution", "\n", "B", ",", "L", ",", "C", "=", "x", ".", "shape", "\n", "_assert", "(", "L", "==", "H", "*", "W", ",", "\"input feature has wrong size\"", ")", "\n", "_assert", "(", "H", "%", "2", "==", "0", "and", "W", "%", "2", "==", "0", ",", "f\"x size ({H}*{W}) are not even.\"", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "H", ",", "W", ",", "C", ")", "\n", "\n", "x0", "=", "x", "[", ":", ",", "0", ":", ":", "2", ",", "0", ":", ":", "2", ",", ":", "]", "# B H/2 W/2 C", "\n", "x1", "=", "x", "[", ":", ",", "1", ":", ":", "2", ",", "0", ":", ":", "2", ",", ":", "]", "# B H/2 W/2 C", "\n", "x2", "=", "x", "[", ":", ",", "0", ":", ":", "2", ",", "1", ":", ":", "2", ",", ":", "]", "# B H/2 W/2 C", "\n", "x3", "=", "x", "[", ":", ",", "1", ":", ":", "2", ",", "1", ":", ":", "2", ",", ":", "]", "# B H/2 W/2 C", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x0", ",", "x1", ",", "x2", ",", "x3", "]", ",", "-", "1", ")", "# B H/2 W/2 4*C", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "-", "1", ",", "4", "*", "C", ")", "# B H/2*W/2 4*C", "\n", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "x", "=", "self", ".", "reduction", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.BasicLayer.__init__": [[391, 416], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "downsample", "swin_transformer.SwinTransformerBlock", "range", "isinstance"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["def", "__init__", "(", "\n", "self", ",", "dim", ",", "out_dim", ",", "input_resolution", ",", "depth", ",", "num_heads", "=", "4", ",", "head_dim", "=", "None", ",", "\n", "window_size", "=", "7", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "True", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "\n", "drop_path", "=", "0.", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "downsample", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "input_resolution", "=", "input_resolution", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "# build blocks", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "SwinTransformerBlock", "(", "\n", "dim", "=", "dim", ",", "input_resolution", "=", "input_resolution", ",", "num_heads", "=", "num_heads", ",", "head_dim", "=", "head_dim", ",", "\n", "window_size", "=", "window_size", ",", "shift_size", "=", "0", "if", "(", "i", "%", "2", "==", "0", ")", "else", "window_size", "//", "2", ",", "\n", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "drop", "=", "drop", ",", "attn_drop", "=", "attn_drop", ",", "\n", "drop_path", "=", "drop_path", "[", "i", "]", "if", "isinstance", "(", "drop_path", ",", "list", ")", "else", "drop_path", ",", "norm_layer", "=", "norm_layer", ")", "\n", "for", "i", "in", "range", "(", "depth", ")", "]", ")", "\n", "\n", "# patch merging layer", "\n", "if", "downsample", "is", "not", "None", ":", "\n", "            ", "self", ".", "downsample", "=", "downsample", "(", "input_resolution", ",", "dim", "=", "dim", ",", "out_dim", "=", "out_dim", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "downsample", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.BasicLayer.forward": [[417, 425], ["helpers.checkpoint_seq", "swin_transformer.BasicLayer.blocks", "swin_transformer.BasicLayer.downsample", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "blocks", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "blocks", "(", "x", ")", "\n", "", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "downsample", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.SwinTransformer.__init__": [[452, 510], ["torch.Module.__init__", "len", "int", "layers.PatchEmbed", "torch.Dropout", "torch.Dropout", "range", "torch.Sequential", "torch.Sequential", "norm_layer", "torch.Parameter", "torch.Parameter", "isinstance", "layers.to_ntuple", "layers.to_ntuple", "layers.to_ntuple", "x.item", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "swin_transformer.SwinTransformer.init_weights", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "int", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "swin_transformer.BasicLayer", "range", "sum", "sum", "sum"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.GluMlp.init_weights"], ["def", "__init__", "(", "\n", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "4", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "global_pool", "=", "'avg'", ",", "\n", "embed_dim", "=", "96", ",", "depths", "=", "(", "2", ",", "2", ",", "6", ",", "2", ")", ",", "num_heads", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "head_dim", "=", "None", ",", "\n", "window_size", "=", "7", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "True", ",", "\n", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.1", ",", "\n", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "ape", "=", "False", ",", "patch_norm", "=", "True", ",", "weight_init", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "global_pool", "in", "(", "''", ",", "'avg'", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "self", ".", "num_layers", "=", "len", "(", "depths", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_features", "=", "int", "(", "embed_dim", "*", "2", "**", "(", "self", ".", "num_layers", "-", "1", ")", ")", "\n", "\n", "# split image into non-overlapping patches", "\n", "self", ".", "patch_embed", "=", "PatchEmbed", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "embed_dim", "=", "embed_dim", ",", "\n", "norm_layer", "=", "norm_layer", "if", "patch_norm", "else", "None", ")", "\n", "num_patches", "=", "self", ".", "patch_embed", ".", "num_patches", "\n", "self", ".", "patch_grid", "=", "self", ".", "patch_embed", ".", "grid_size", "\n", "\n", "# absolute position embedding", "\n", "self", ".", "absolute_pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "num_patches", ",", "embed_dim", ")", ")", "if", "ape", "else", "None", "\n", "self", ".", "pos_drop", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", "\n", "\n", "# build layers", "\n", "if", "not", "isinstance", "(", "embed_dim", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "embed_dim", "=", "[", "int", "(", "embed_dim", "*", "2", "**", "i", ")", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", "]", "\n", "", "embed_out_dim", "=", "embed_dim", "[", "1", ":", "]", "+", "[", "None", "]", "\n", "head_dim", "=", "to_ntuple", "(", "self", ".", "num_layers", ")", "(", "head_dim", ")", "\n", "window_size", "=", "to_ntuple", "(", "self", ".", "num_layers", ")", "(", "window_size", ")", "\n", "mlp_ratio", "=", "to_ntuple", "(", "self", ".", "num_layers", ")", "(", "mlp_ratio", ")", "\n", "dpr", "=", "[", "x", ".", "item", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "sum", "(", "depths", ")", ")", "]", "# stochastic depth decay rule", "\n", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "layers", "+=", "[", "BasicLayer", "(", "\n", "dim", "=", "embed_dim", "[", "i", "]", ",", "\n", "out_dim", "=", "embed_out_dim", "[", "i", "]", ",", "\n", "input_resolution", "=", "(", "self", ".", "patch_grid", "[", "0", "]", "//", "(", "2", "**", "i", ")", ",", "self", ".", "patch_grid", "[", "1", "]", "//", "(", "2", "**", "i", ")", ")", ",", "\n", "depth", "=", "depths", "[", "i", "]", ",", "\n", "num_heads", "=", "num_heads", "[", "i", "]", ",", "\n", "head_dim", "=", "head_dim", "[", "i", "]", ",", "\n", "window_size", "=", "window_size", "[", "i", "]", ",", "\n", "mlp_ratio", "=", "mlp_ratio", "[", "i", "]", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "\n", "drop", "=", "drop_rate", ",", "\n", "attn_drop", "=", "attn_drop_rate", ",", "\n", "drop_path", "=", "dpr", "[", "sum", "(", "depths", "[", ":", "i", "]", ")", ":", "sum", "(", "depths", "[", ":", "i", "+", "1", "]", ")", "]", ",", "\n", "norm_layer", "=", "norm_layer", ",", "\n", "downsample", "=", "PatchMerging", "if", "(", "i", "<", "self", ".", "num_layers", "-", "1", ")", "else", "None", "\n", ")", "]", "\n", "", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n", "self", ".", "norm", "=", "norm_layer", "(", "self", ".", "num_features", ")", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "if", "weight_init", "!=", "'skip'", ":", "\n", "            ", "self", ".", "init_weights", "(", "weight_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.SwinTransformer.init_weights": [[511, 518], ["helpers.named_apply", "layers.trunc_normal_", "vision_transformer.get_init_weights_vit", "math.log"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_apply", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.get_init_weights_vit"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "init_weights", "(", "self", ",", "mode", "=", "''", ")", ":", "\n", "        ", "assert", "mode", "in", "(", "'jax'", ",", "'jax_nlhb'", ",", "'moco'", ",", "''", ")", "\n", "if", "self", ".", "absolute_pos_embed", "is", "not", "None", ":", "\n", "            ", "trunc_normal_", "(", "self", ".", "absolute_pos_embed", ",", "std", "=", ".02", ")", "\n", "", "head_bias", "=", "-", "math", ".", "log", "(", "self", ".", "num_classes", ")", "if", "'nlhb'", "in", "mode", "else", "0.", "\n", "named_apply", "(", "get_init_weights_vit", "(", "mode", ",", "head_bias", "=", "head_bias", ")", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.SwinTransformer.no_weight_decay": [[519, 526], ["swin_transformer.SwinTransformer.named_parameters", "nwd.add"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "nwd", "=", "{", "'absolute_pos_embed'", "}", "\n", "for", "n", ",", "_", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "'relative_position_bias_table'", "in", "n", ":", "\n", "                ", "nwd", ".", "add", "(", "n", ")", "\n", "", "", "return", "nwd", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.SwinTransformer.group_matcher": [[527, 535], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^absolute_pos_embed|patch_embed'", ",", "# stem and embed", "\n", "blocks", "=", "r'^layers\\.(\\d+)'", "if", "coarse", "else", "[", "\n", "(", "r'^layers\\.(\\d+).downsample'", ",", "(", "0", ",", ")", ")", ",", "\n", "(", "r'^layers\\.(\\d+)\\.\\w+\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^norm'", ",", "(", "99999", ",", ")", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.SwinTransformer.set_grad_checkpointing": [[538, 542], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "for", "l", "in", "self", ".", "layers", ":", "\n", "            ", "l", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.SwinTransformer.get_classifier": [[543, 546], ["None"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.SwinTransformer.reset_classifier": [[547, 553], ["torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "None", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "if", "global_pool", "is", "not", "None", ":", "\n", "            ", "assert", "global_pool", "in", "(", "''", ",", "'avg'", ")", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.SwinTransformer.forward_features": [[554, 562], ["swin_transformer.SwinTransformer.patch_embed", "swin_transformer.SwinTransformer.pos_drop", "swin_transformer.SwinTransformer.layers", "swin_transformer.SwinTransformer.norm"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "if", "self", ".", "absolute_pos_embed", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "absolute_pos_embed", "\n", "", "x", "=", "self", ".", "pos_drop", "(", "x", ")", "\n", "x", "=", "self", ".", "layers", "(", "x", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "# B L C", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.SwinTransformer.forward_head": [[563, 567], ["x.mean.mean.mean", "swin_transformer.SwinTransformer.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "global_pool", "==", "'avg'", ":", "\n", "            ", "x", "=", "x", ".", "mean", "(", "dim", "=", "1", ")", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.SwinTransformer.forward": [[568, 572], ["swin_transformer.SwinTransformer.forward_features", "swin_transformer.SwinTransformer.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer._cfg": [[37, 45], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", ".9", ",", "'interpolation'", ":", "'bicubic'", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'patch_embed.proj'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.window_partition": [[102, 115], ["x.view.view", "x.view.permute().contiguous().view", "x.view.permute().contiguous", "x.view.permute"], "function", ["None"], ["def", "window_partition", "(", "x", ",", "window_size", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        x: (B, H, W, C)\n        window_size (int): window size\n\n    Returns:\n        windows: (num_windows*B, window_size, window_size, C)\n    \"\"\"", "\n", "B", ",", "H", ",", "W", ",", "C", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "H", "//", "window_size", ",", "window_size", ",", "W", "//", "window_size", ",", "window_size", ",", "C", ")", "\n", "windows", "=", "x", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ",", "5", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "window_size", ",", "window_size", ",", "C", ")", "\n", "return", "windows", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.window_reverse": [[117, 133], ["int", "windows.view", "x.permute().contiguous().view.permute().contiguous().view", "x.permute().contiguous().view.permute().contiguous", "x.permute().contiguous().view.permute"], "function", ["None"], ["", "@", "register_notrace_function", "# reason: int argument is a Proxy", "\n", "def", "window_reverse", "(", "windows", ",", "window_size", ":", "int", ",", "H", ":", "int", ",", "W", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        windows: (num_windows*B, window_size, window_size, C)\n        window_size (int): Window size\n        H (int): Height of image\n        W (int): Width of image\n\n    Returns:\n        x: (B, H, W, C)\n    \"\"\"", "\n", "B", "=", "int", "(", "windows", ".", "shape", "[", "0", "]", "/", "(", "H", "*", "W", "/", "window_size", "/", "window_size", ")", ")", "\n", "x", "=", "windows", ".", "view", "(", "B", ",", "H", "//", "window_size", ",", "W", "//", "window_size", ",", "window_size", ",", "window_size", ",", "-", "1", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ",", "5", ")", ".", "contiguous", "(", ")", ".", "view", "(", "B", ",", "H", ",", "W", ",", "-", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.get_relative_position_index": [[135, 145], ["torch.stack", "torch.stack", "torch.flatten", "torch.flatten", "relative_coords.permute().contiguous.permute().contiguous", "relative_coords.permute().contiguous.sum", "torch.meshgrid", "torch.meshgrid", "relative_coords.permute().contiguous.permute", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "function", ["None"], ["", "def", "get_relative_position_index", "(", "win_h", ",", "win_w", ")", ":", "\n", "# get pair-wise relative position index for each token inside the window", "\n", "    ", "coords", "=", "torch", ".", "stack", "(", "torch", ".", "meshgrid", "(", "[", "torch", ".", "arange", "(", "win_h", ")", ",", "torch", ".", "arange", "(", "win_w", ")", "]", ")", ")", "# 2, Wh, Ww", "\n", "coords_flatten", "=", "torch", ".", "flatten", "(", "coords", ",", "1", ")", "# 2, Wh*Ww", "\n", "relative_coords", "=", "coords_flatten", "[", ":", ",", ":", ",", "None", "]", "-", "coords_flatten", "[", ":", ",", "None", ",", ":", "]", "# 2, Wh*Ww, Wh*Ww", "\n", "relative_coords", "=", "relative_coords", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "# Wh*Ww, Wh*Ww, 2", "\n", "relative_coords", "[", ":", ",", ":", ",", "0", "]", "+=", "win_h", "-", "1", "# shift to start from 0", "\n", "relative_coords", "[", ":", ",", ":", ",", "1", "]", "+=", "win_w", "-", "1", "\n", "relative_coords", "[", ":", ",", ":", ",", "0", "]", "*=", "2", "*", "win_w", "-", "1", "\n", "return", "relative_coords", ".", "sum", "(", "-", "1", ")", "# Wh*Ww, Wh*Ww", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer._create_swin_transformer": [[574, 581], ["helpers.build_model_with_cfg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_swin_transformer", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "build_model_with_cfg", "(", "\n", "SwinTransformer", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_filter_fn", "=", "checkpoint_filter_fn", ",", "\n", "**", "kwargs", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.swin_base_patch4_window12_384": [[583, 590], ["dict", "swin_transformer._create_swin_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer._create_swin_transformer"], ["", "@", "register_model", "\n", "def", "swin_base_patch4_window12_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Swin-B @ 384x384, pretrained ImageNet-22k, fine tune 1k\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "window_size", "=", "12", ",", "embed_dim", "=", "128", ",", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "num_heads", "=", "(", "4", ",", "8", ",", "16", ",", "32", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_swin_transformer", "(", "'swin_base_patch4_window12_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.swin_base_patch4_window7_224": [[592, 599], ["dict", "swin_transformer._create_swin_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer._create_swin_transformer"], ["", "@", "register_model", "\n", "def", "swin_base_patch4_window7_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Swin-B @ 224x224, pretrained ImageNet-22k, fine tune 1k\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "window_size", "=", "7", ",", "embed_dim", "=", "128", ",", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "num_heads", "=", "(", "4", ",", "8", ",", "16", ",", "32", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_swin_transformer", "(", "'swin_base_patch4_window7_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.swin_large_patch4_window12_384": [[601, 608], ["dict", "swin_transformer._create_swin_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer._create_swin_transformer"], ["", "@", "register_model", "\n", "def", "swin_large_patch4_window12_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Swin-L @ 384x384, pretrained ImageNet-22k, fine tune 1k\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "window_size", "=", "12", ",", "embed_dim", "=", "192", ",", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "num_heads", "=", "(", "6", ",", "12", ",", "24", ",", "48", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_swin_transformer", "(", "'swin_large_patch4_window12_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.swin_large_patch4_window7_224": [[610, 617], ["dict", "swin_transformer._create_swin_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer._create_swin_transformer"], ["", "@", "register_model", "\n", "def", "swin_large_patch4_window7_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Swin-L @ 224x224, pretrained ImageNet-22k, fine tune 1k\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "window_size", "=", "7", ",", "embed_dim", "=", "192", ",", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "num_heads", "=", "(", "6", ",", "12", ",", "24", ",", "48", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_swin_transformer", "(", "'swin_large_patch4_window7_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.swin_small_patch4_window7_224": [[619, 626], ["dict", "swin_transformer._create_swin_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer._create_swin_transformer"], ["", "@", "register_model", "\n", "def", "swin_small_patch4_window7_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Swin-S @ 224x224, trained ImageNet-1k\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "window_size", "=", "7", ",", "embed_dim", "=", "96", ",", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "num_heads", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_swin_transformer", "(", "'swin_small_patch4_window7_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.swin_tiny_patch4_window7_224": [[628, 635], ["dict", "swin_transformer._create_swin_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer._create_swin_transformer"], ["", "@", "register_model", "\n", "def", "swin_tiny_patch4_window7_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Swin-T @ 224x224, trained ImageNet-1k\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "window_size", "=", "7", ",", "embed_dim", "=", "96", ",", "depths", "=", "(", "2", ",", "2", ",", "6", ",", "2", ")", ",", "num_heads", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_swin_transformer", "(", "'swin_tiny_patch4_window7_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.swin_base_patch4_window12_384_in22k": [[637, 644], ["dict", "swin_transformer._create_swin_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer._create_swin_transformer"], ["", "@", "register_model", "\n", "def", "swin_base_patch4_window12_384_in22k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Swin-B @ 384x384, trained ImageNet-22k\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "window_size", "=", "12", ",", "embed_dim", "=", "128", ",", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "num_heads", "=", "(", "4", ",", "8", ",", "16", ",", "32", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_swin_transformer", "(", "'swin_base_patch4_window12_384_in22k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.swin_base_patch4_window7_224_in22k": [[646, 653], ["dict", "swin_transformer._create_swin_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer._create_swin_transformer"], ["", "@", "register_model", "\n", "def", "swin_base_patch4_window7_224_in22k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Swin-B @ 224x224, trained ImageNet-22k\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "window_size", "=", "7", ",", "embed_dim", "=", "128", ",", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "num_heads", "=", "(", "4", ",", "8", ",", "16", ",", "32", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_swin_transformer", "(", "'swin_base_patch4_window7_224_in22k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.swin_large_patch4_window12_384_in22k": [[655, 662], ["dict", "swin_transformer._create_swin_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer._create_swin_transformer"], ["", "@", "register_model", "\n", "def", "swin_large_patch4_window12_384_in22k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Swin-L @ 384x384, trained ImageNet-22k\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "window_size", "=", "12", ",", "embed_dim", "=", "192", ",", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "num_heads", "=", "(", "6", ",", "12", ",", "24", ",", "48", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_swin_transformer", "(", "'swin_large_patch4_window12_384_in22k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.swin_large_patch4_window7_224_in22k": [[664, 671], ["dict", "swin_transformer._create_swin_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer._create_swin_transformer"], ["", "@", "register_model", "\n", "def", "swin_large_patch4_window7_224_in22k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Swin-L @ 224x224, trained ImageNet-22k\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "window_size", "=", "7", ",", "embed_dim", "=", "192", ",", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "num_heads", "=", "(", "6", ",", "12", ",", "24", ",", "48", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_swin_transformer", "(", "'swin_large_patch4_window7_224_in22k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.swin_s3_tiny_224": [[673, 681], ["dict", "swin_transformer._create_swin_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer._create_swin_transformer"], ["", "@", "register_model", "\n", "def", "swin_s3_tiny_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Swin-S3-T @ 224x224, ImageNet-1k. https://arxiv.org/abs/2111.14725\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "window_size", "=", "(", "7", ",", "7", ",", "14", ",", "7", ")", ",", "embed_dim", "=", "96", ",", "depths", "=", "(", "2", ",", "2", ",", "6", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_swin_transformer", "(", "'swin_s3_tiny_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.swin_s3_small_224": [[683, 691], ["dict", "swin_transformer._create_swin_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer._create_swin_transformer"], ["", "@", "register_model", "\n", "def", "swin_s3_small_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Swin-S3-S @ 224x224, trained ImageNet-1k. https://arxiv.org/abs/2111.14725\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "window_size", "=", "(", "14", ",", "14", ",", "14", ",", "7", ")", ",", "embed_dim", "=", "96", ",", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_swin_transformer", "(", "'swin_s3_small_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer.swin_s3_base_224": [[693, 701], ["dict", "swin_transformer._create_swin_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.swin_transformer._create_swin_transformer"], ["", "@", "register_model", "\n", "def", "swin_s3_base_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Swin-S3-B @ 224x224, trained ImageNet-1k. https://arxiv.org/abs/2111.14725\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "window_size", "=", "(", "7", ",", "7", ",", "14", ",", "7", ")", ",", "embed_dim", "=", "96", ",", "depths", "=", "(", "2", ",", "2", ",", "30", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_swin_transformer", "(", "'swin_s3_base_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.register_model": [[21, 52], ["fn.__module__.split", "hasattr", "_module_to_models[].add", "len", "mod.__all__.append", "hasattr", "_model_has_pretrained.add"], "function", ["None"], ["def", "register_model", "(", "fn", ")", ":", "\n", "# lookup containing module", "\n", "    ", "mod", "=", "sys", ".", "modules", "[", "fn", ".", "__module__", "]", "\n", "module_name_split", "=", "fn", ".", "__module__", ".", "split", "(", "'.'", ")", "\n", "module_name", "=", "module_name_split", "[", "-", "1", "]", "if", "len", "(", "module_name_split", ")", "else", "''", "\n", "\n", "# add model to __all__ in module", "\n", "model_name", "=", "fn", ".", "__name__", "\n", "if", "hasattr", "(", "mod", ",", "'__all__'", ")", ":", "\n", "        ", "mod", ".", "__all__", ".", "append", "(", "model_name", ")", "\n", "", "else", ":", "\n", "        ", "mod", ".", "__all__", "=", "[", "model_name", "]", "\n", "\n", "# add entries to registry dict/sets", "\n", "", "_model_entrypoints", "[", "model_name", "]", "=", "fn", "\n", "_model_to_module", "[", "model_name", "]", "=", "module_name", "\n", "_module_to_models", "[", "module_name", "]", ".", "add", "(", "model_name", ")", "\n", "has_valid_pretrained", "=", "False", "# check if model has a pretrained url to allow filtering on this", "\n", "if", "hasattr", "(", "mod", ",", "'default_cfgs'", ")", "and", "model_name", "in", "mod", ".", "default_cfgs", ":", "\n", "# this will catch all models that have entrypoint matching cfg key, but miss any aliasing", "\n", "# entrypoints or non-matching combos", "\n", "        ", "cfg", "=", "mod", ".", "default_cfgs", "[", "model_name", "]", "\n", "has_valid_pretrained", "=", "(", "\n", "(", "'url'", "in", "cfg", "and", "'http'", "in", "cfg", "[", "'url'", "]", ")", "or", "\n", "(", "'file'", "in", "cfg", "and", "cfg", "[", "'file'", "]", ")", "or", "\n", "(", "'hf_hub_id'", "in", "cfg", "and", "cfg", "[", "'hf_hub_id'", "]", ")", "\n", ")", "\n", "_model_pretrained_cfgs", "[", "model_name", "]", "=", "mod", ".", "default_cfgs", "[", "model_name", "]", "\n", "", "if", "has_valid_pretrained", ":", "\n", "        ", "_model_has_pretrained", ".", "add", "(", "model_name", ")", "\n", "", "return", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry._natural_key": [[54, 56], ["s.isdigit", "int", "re.split", "string_.lower"], "function", ["None"], ["", "def", "_natural_key", "(", "string_", ")", ":", "\n", "    ", "return", "[", "int", "(", "s", ")", "if", "s", ".", "isdigit", "(", ")", "else", "s", "for", "s", "in", "re", ".", "split", "(", "r'(\\d+)'", ",", "string_", ".", "lower", "(", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.list_models": [[58, 97], ["list", "list", "_model_entrypoints.keys", "_model_has_pretrained.intersection", "set().intersection", "sorted", "isinstance", "fnmatch.filter", "len", "isinstance", "fnmatch.filter", "len", "set().union", "set().difference", "set", "set", "set"], "function", ["None"], ["", "def", "list_models", "(", "filter", "=", "''", ",", "module", "=", "''", ",", "pretrained", "=", "False", ",", "exclude_filters", "=", "''", ",", "name_matches_cfg", "=", "False", ")", ":", "\n", "    ", "\"\"\" Return list of available model names, sorted alphabetically\n\n    Args:\n        filter (str) - Wildcard filter string that works with fnmatch\n        module (str) - Limit model selection to a specific sub-module (ie 'gen_efficientnet')\n        pretrained (bool) - Include only models with pretrained weights if True\n        exclude_filters (str or list[str]) - Wildcard filters to exclude models after including them with filter\n        name_matches_cfg (bool) - Include only models w/ model_name matching default_cfg name (excludes some aliases)\n\n    Example:\n        model_list('gluon_resnet*') -- returns all models starting with 'gluon_resnet'\n        model_list('*resnext*, 'resnet') -- returns all models with 'resnext' in 'resnet' module\n    \"\"\"", "\n", "if", "module", ":", "\n", "        ", "all_models", "=", "list", "(", "_module_to_models", "[", "module", "]", ")", "\n", "", "else", ":", "\n", "        ", "all_models", "=", "_model_entrypoints", ".", "keys", "(", ")", "\n", "", "if", "filter", ":", "\n", "        ", "models", "=", "[", "]", "\n", "include_filters", "=", "filter", "if", "isinstance", "(", "filter", ",", "(", "tuple", ",", "list", ")", ")", "else", "[", "filter", "]", "\n", "for", "f", "in", "include_filters", ":", "\n", "            ", "include_models", "=", "fnmatch", ".", "filter", "(", "all_models", ",", "f", ")", "# include these models", "\n", "if", "len", "(", "include_models", ")", ":", "\n", "                ", "models", "=", "set", "(", "models", ")", ".", "union", "(", "include_models", ")", "\n", "", "", "", "else", ":", "\n", "        ", "models", "=", "all_models", "\n", "", "if", "exclude_filters", ":", "\n", "        ", "if", "not", "isinstance", "(", "exclude_filters", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "exclude_filters", "=", "[", "exclude_filters", "]", "\n", "", "for", "xf", "in", "exclude_filters", ":", "\n", "            ", "exclude_models", "=", "fnmatch", ".", "filter", "(", "models", ",", "xf", ")", "# exclude these models", "\n", "if", "len", "(", "exclude_models", ")", ":", "\n", "                ", "models", "=", "set", "(", "models", ")", ".", "difference", "(", "exclude_models", ")", "\n", "", "", "", "if", "pretrained", ":", "\n", "        ", "models", "=", "_model_has_pretrained", ".", "intersection", "(", "models", ")", "\n", "", "if", "name_matches_cfg", ":", "\n", "        ", "models", "=", "set", "(", "_model_pretrained_cfgs", ")", ".", "intersection", "(", "models", ")", "\n", "", "return", "list", "(", "sorted", "(", "models", ",", "key", "=", "_natural_key", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.is_model": [[99, 103], ["None"], "function", ["None"], ["", "def", "is_model", "(", "model_name", ")", ":", "\n", "    ", "\"\"\" Check if a model name exists\n    \"\"\"", "\n", "return", "model_name", "in", "_model_entrypoints", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.model_entrypoint": [[105, 109], ["None"], "function", ["None"], ["", "def", "model_entrypoint", "(", "model_name", ")", ":", "\n", "    ", "\"\"\"Fetch a model entrypoint for specified model name\n    \"\"\"", "\n", "return", "_model_entrypoints", "[", "model_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.list_modules": [[111, 116], ["_module_to_models.keys", "list", "sorted"], "function", ["None"], ["", "def", "list_modules", "(", ")", ":", "\n", "    ", "\"\"\" Return list of module names that contain models / model entrypoints\n    \"\"\"", "\n", "modules", "=", "_module_to_models", ".", "keys", "(", ")", "\n", "return", "list", "(", "sorted", "(", "modules", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.is_model_in_modules": [[118, 126], ["isinstance", "any"], "function", ["None"], ["", "def", "is_model_in_modules", "(", "model_name", ",", "module_names", ")", ":", "\n", "    ", "\"\"\"Check if a model exists within a subset of modules\n    Args:\n        model_name (str) - name of model to check\n        module_names (tuple, list, set) - names of modules to search in\n    \"\"\"", "\n", "assert", "isinstance", "(", "module_names", ",", "(", "tuple", ",", "list", ",", "set", ")", ")", "\n", "return", "any", "(", "model_name", "in", "_module_to_models", "[", "n", "]", "for", "n", "in", "module_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.is_model_pretrained": [[128, 130], ["None"], "function", ["None"], ["", "def", "is_model_pretrained", "(", "model_name", ")", ":", "\n", "    ", "return", "model_name", "in", "_model_has_pretrained", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.get_pretrained_cfg": [[132, 136], ["copy.deepcopy"], "function", ["None"], ["", "def", "get_pretrained_cfg", "(", "model_name", ")", ":", "\n", "    ", "if", "model_name", "in", "_model_pretrained_cfgs", ":", "\n", "        ", "return", "deepcopy", "(", "_model_pretrained_cfgs", "[", "model_name", "]", ")", "\n", "", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.has_pretrained_cfg_key": [[138, 144], ["None"], "function", ["None"], ["", "def", "has_pretrained_cfg_key", "(", "model_name", ",", "cfg_key", ")", ":", "\n", "    ", "\"\"\" Query model default_cfgs for existence of a specific key.\n    \"\"\"", "\n", "if", "model_name", "in", "_model_pretrained_cfgs", "and", "cfg_key", "in", "_model_pretrained_cfgs", "[", "model_name", "]", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.is_pretrained_cfg_key": [[146, 152], ["_model_pretrained_cfgs[].get"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["", "def", "is_pretrained_cfg_key", "(", "model_name", ",", "cfg_key", ")", ":", "\n", "    ", "\"\"\" Return truthy value for specified model default_cfg key, False if does not exist.\n    \"\"\"", "\n", "if", "model_name", "in", "_model_pretrained_cfgs", "and", "_model_pretrained_cfgs", "[", "model_name", "]", ".", "get", "(", "cfg_key", ",", "False", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.get_pretrained_cfg_value": [[154, 160], ["_model_pretrained_cfgs[].get"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["", "def", "get_pretrained_cfg_value", "(", "model_name", ",", "cfg_key", ")", ":", "\n", "    ", "\"\"\" Get a specific model default_cfg value by key. None if it doesn't exist.\n    \"\"\"", "\n", "if", "model_name", "in", "_model_pretrained_cfgs", ":", "\n", "        ", "return", "_model_pretrained_cfgs", "[", "model_name", "]", ".", "get", "(", "cfg_key", ",", "None", ")", "\n", "", "return", "None", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet.GhostModule.__init__": [[47, 63], ["torch.Module.__init__", "math.ceil", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Sequential", "torch.Sequential", "torch.Sequential"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inp", ",", "oup", ",", "kernel_size", "=", "1", ",", "ratio", "=", "2", ",", "dw_size", "=", "3", ",", "stride", "=", "1", ",", "relu", "=", "True", ")", ":", "\n", "        ", "super", "(", "GhostModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "oup", "=", "oup", "\n", "init_channels", "=", "math", ".", "ceil", "(", "oup", "/", "ratio", ")", "\n", "new_channels", "=", "init_channels", "*", "(", "ratio", "-", "1", ")", "\n", "\n", "self", ".", "primary_conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "inp", ",", "init_channels", ",", "kernel_size", ",", "stride", ",", "kernel_size", "//", "2", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "init_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "if", "relu", "else", "nn", ".", "Sequential", "(", ")", ",", "\n", ")", "\n", "\n", "self", ".", "cheap_operation", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "init_channels", ",", "new_channels", ",", "dw_size", ",", "1", ",", "dw_size", "//", "2", ",", "groups", "=", "init_channels", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "new_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "if", "relu", "else", "nn", ".", "Sequential", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet.GhostModule.forward": [[65, 70], ["ghostnet.GhostModule.primary_conv", "ghostnet.GhostModule.cheap_operation", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x1", "=", "self", ".", "primary_conv", "(", "x", ")", "\n", "x2", "=", "self", ".", "cheap_operation", "(", "x1", ")", "\n", "out", "=", "torch", ".", "cat", "(", "[", "x1", ",", "x2", "]", ",", "dim", "=", "1", ")", "\n", "return", "out", "[", ":", ",", ":", "self", ".", "oup", ",", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet.GhostBottleneck.__init__": [[75, 111], ["torch.Module.__init__", "ghostnet.GhostModule", "ghostnet.GhostModule", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "_SE_LAYER", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "in_chs", ",", "mid_chs", ",", "out_chs", ",", "dw_kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "se_ratio", "=", "0.", ")", ":", "\n", "        ", "super", "(", "GhostBottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "has_se", "=", "se_ratio", "is", "not", "None", "and", "se_ratio", ">", "0.", "\n", "self", ".", "stride", "=", "stride", "\n", "\n", "# Point-wise expansion", "\n", "self", ".", "ghost1", "=", "GhostModule", "(", "in_chs", ",", "mid_chs", ",", "relu", "=", "True", ")", "\n", "\n", "# Depth-wise convolution", "\n", "if", "self", ".", "stride", ">", "1", ":", "\n", "            ", "self", ".", "conv_dw", "=", "nn", ".", "Conv2d", "(", "\n", "mid_chs", ",", "mid_chs", ",", "dw_kernel_size", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "(", "dw_kernel_size", "-", "1", ")", "//", "2", ",", "groups", "=", "mid_chs", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn_dw", "=", "nn", ".", "BatchNorm2d", "(", "mid_chs", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv_dw", "=", "None", "\n", "self", ".", "bn_dw", "=", "None", "\n", "\n", "# Squeeze-and-excitation", "\n", "", "self", ".", "se", "=", "_SE_LAYER", "(", "mid_chs", ",", "rd_ratio", "=", "se_ratio", ")", "if", "has_se", "else", "None", "\n", "\n", "# Point-wise linear projection", "\n", "self", ".", "ghost2", "=", "GhostModule", "(", "mid_chs", ",", "out_chs", ",", "relu", "=", "False", ")", "\n", "\n", "# shortcut", "\n", "if", "in_chs", "==", "out_chs", "and", "self", ".", "stride", "==", "1", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_chs", ",", "in_chs", ",", "dw_kernel_size", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "(", "dw_kernel_size", "-", "1", ")", "//", "2", ",", "groups", "=", "in_chs", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "in_chs", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_chs", ",", "out_chs", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_chs", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet.GhostBottleneck.forward": [[113, 133], ["ghostnet.GhostBottleneck.ghost1", "ghostnet.GhostBottleneck.ghost2", "ghostnet.GhostBottleneck.shortcut", "ghostnet.GhostBottleneck.conv_dw", "ghostnet.GhostBottleneck.bn_dw", "ghostnet.GhostBottleneck.se"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "\n", "# 1st ghost bottleneck", "\n", "x", "=", "self", ".", "ghost1", "(", "x", ")", "\n", "\n", "# Depth-wise convolution", "\n", "if", "self", ".", "conv_dw", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "conv_dw", "(", "x", ")", "\n", "x", "=", "self", ".", "bn_dw", "(", "x", ")", "\n", "\n", "# Squeeze-and-excitation", "\n", "", "if", "self", ".", "se", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "se", "(", "x", ")", "\n", "\n", "# 2nd ghost bottleneck", "\n", "", "x", "=", "self", ".", "ghost2", "(", "x", ")", "\n", "\n", "x", "+=", "self", ".", "shortcut", "(", "shortcut", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet.GhostNet.__init__": [[136, 188], ["torch.Module.__init__", "layers.make_divisible", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "ghostnet.GhostNet.feature_info.append", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "layers.make_divisible", "torch.ModuleList.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.SelectAdaptivePool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "dict", "torch.ModuleList.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Flatten", "torch.Flatten", "torch.Flatten", "torch.Identity", "torch.Identity", "torch.Identity", "layers.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "layers.make_divisible", "layers.make_divisible", "layers.append", "ghostnet.GhostNet.feature_info.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "efficientnet_blocks.ConvBnAct", "block", "dict"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["    ", "def", "__init__", "(", "\n", "self", ",", "cfgs", ",", "num_classes", "=", "1000", ",", "width", "=", "1.0", ",", "in_chans", "=", "3", ",", "output_stride", "=", "32", ",", "global_pool", "=", "'avg'", ",", "drop_rate", "=", "0.2", ")", ":", "\n", "        ", "super", "(", "GhostNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# setting of inverted residual blocks", "\n", "assert", "output_stride", "==", "32", ",", "'only output_stride==32 is valid, dilation not supported'", "\n", "self", ".", "cfgs", "=", "cfgs", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "self", ".", "feature_info", "=", "[", "]", "\n", "\n", "# building first layer", "\n", "stem_chs", "=", "make_divisible", "(", "16", "*", "width", ",", "4", ")", "\n", "self", ".", "conv_stem", "=", "nn", ".", "Conv2d", "(", "in_chans", ",", "stem_chs", ",", "3", ",", "2", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "feature_info", ".", "append", "(", "dict", "(", "num_chs", "=", "stem_chs", ",", "reduction", "=", "2", ",", "module", "=", "f'conv_stem'", ")", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "stem_chs", ")", "\n", "self", ".", "act1", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "prev_chs", "=", "stem_chs", "\n", "\n", "# building inverted residual blocks", "\n", "stages", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "block", "=", "GhostBottleneck", "\n", "stage_idx", "=", "0", "\n", "net_stride", "=", "2", "\n", "for", "cfg", "in", "self", ".", "cfgs", ":", "\n", "            ", "layers", "=", "[", "]", "\n", "s", "=", "1", "\n", "for", "k", ",", "exp_size", ",", "c", ",", "se_ratio", ",", "s", "in", "cfg", ":", "\n", "                ", "out_chs", "=", "make_divisible", "(", "c", "*", "width", ",", "4", ")", "\n", "mid_chs", "=", "make_divisible", "(", "exp_size", "*", "width", ",", "4", ")", "\n", "layers", ".", "append", "(", "block", "(", "prev_chs", ",", "mid_chs", ",", "out_chs", ",", "k", ",", "s", ",", "se_ratio", "=", "se_ratio", ")", ")", "\n", "prev_chs", "=", "out_chs", "\n", "", "if", "s", ">", "1", ":", "\n", "                ", "net_stride", "*=", "2", "\n", "self", ".", "feature_info", ".", "append", "(", "dict", "(", "\n", "num_chs", "=", "prev_chs", ",", "reduction", "=", "net_stride", ",", "module", "=", "f'blocks.{stage_idx}'", ")", ")", "\n", "", "stages", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "layers", ")", ")", "\n", "stage_idx", "+=", "1", "\n", "\n", "", "out_chs", "=", "make_divisible", "(", "exp_size", "*", "width", ",", "4", ")", "\n", "stages", ".", "append", "(", "nn", ".", "Sequential", "(", "ConvBnAct", "(", "prev_chs", ",", "out_chs", ",", "1", ")", ")", ")", "\n", "self", ".", "pool_dim", "=", "prev_chs", "=", "out_chs", "\n", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "*", "stages", ")", "\n", "\n", "# building last several layers", "\n", "self", ".", "num_features", "=", "out_chs", "=", "1280", "\n", "self", ".", "global_pool", "=", "SelectAdaptivePool2d", "(", "pool_type", "=", "global_pool", ")", "\n", "self", ".", "conv_head", "=", "nn", ".", "Conv2d", "(", "prev_chs", ",", "out_chs", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "True", ")", "\n", "self", ".", "act2", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "flatten", "=", "nn", ".", "Flatten", "(", "1", ")", "if", "global_pool", "else", "nn", ".", "Identity", "(", ")", "# don't flatten if pooling disabled", "\n", "self", ".", "classifier", "=", "Linear", "(", "out_chs", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet.GhostNet.group_matcher": [[191, 201], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem", "=", "r'^conv_stem|bn1'", ",", "\n", "blocks", "=", "[", "\n", "(", "r'^blocks\\.(\\d+)'", "if", "coarse", "else", "r'^blocks\\.(\\d+)\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'conv_head'", ",", "(", "99999", ",", ")", ")", "\n", "]", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet.GhostNet.set_grad_checkpointing": [[202, 205], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet.GhostNet.get_classifier": [[206, 209], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet.GhostNet.reset_classifier": [[210, 216], ["layers.SelectAdaptivePool2d", "torch.Flatten", "torch.Flatten", "torch.Flatten", "torch.Identity", "torch.Identity", "torch.Identity", "layers.Linear", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "# cannot meaningfully change pooling of efficient head after creation", "\n", "self", ".", "global_pool", "=", "SelectAdaptivePool2d", "(", "pool_type", "=", "global_pool", ")", "\n", "self", ".", "flatten", "=", "nn", ".", "Flatten", "(", "1", ")", "if", "global_pool", "else", "nn", ".", "Identity", "(", ")", "# don't flatten if pooling disabled", "\n", "self", ".", "classifier", "=", "Linear", "(", "self", ".", "pool_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet.GhostNet.forward_features": [[217, 226], ["ghostnet.GhostNet.conv_stem", "ghostnet.GhostNet.bn1", "ghostnet.GhostNet.act1", "helpers.checkpoint_seq", "ghostnet.GhostNet.blocks", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv_stem", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "act1", "(", "x", ")", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "blocks", ",", "x", ",", "flatten", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "blocks", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet.GhostNet.forward_head": [[227, 236], ["ghostnet.GhostNet.global_pool", "ghostnet.GhostNet.conv_head", "ghostnet.GhostNet.act2", "ghostnet.GhostNet.flatten", "ghostnet.GhostNet.classifier", "torch.dropout", "torch.dropout", "torch.dropout"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_head", "(", "x", ")", "\n", "x", "=", "self", ".", "act2", "(", "x", ")", "\n", "x", "=", "self", ".", "flatten", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ">", "0.", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet.GhostNet.forward": [[237, 241], ["ghostnet.GhostNet.forward_features", "ghostnet.GhostNet.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet._cfg": [[25, 32], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bilinear'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'conv_stem'", ",", "'classifier'", ":", "'classifier'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet._create_ghostnet": [[243, 282], ["dict", "helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_ghostnet", "(", "variant", ",", "width", "=", "1.0", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Constructs a GhostNet model\n    \"\"\"", "\n", "cfgs", "=", "[", "\n", "# k, t, c, SE, s ", "\n", "# stage1", "\n", "[", "[", "3", ",", "16", ",", "16", ",", "0", ",", "1", "]", "]", ",", "\n", "# stage2", "\n", "[", "[", "3", ",", "48", ",", "24", ",", "0", ",", "2", "]", "]", ",", "\n", "[", "[", "3", ",", "72", ",", "24", ",", "0", ",", "1", "]", "]", ",", "\n", "# stage3", "\n", "[", "[", "5", ",", "72", ",", "40", ",", "0.25", ",", "2", "]", "]", ",", "\n", "[", "[", "5", ",", "120", ",", "40", ",", "0.25", ",", "1", "]", "]", ",", "\n", "# stage4", "\n", "[", "[", "3", ",", "240", ",", "80", ",", "0", ",", "2", "]", "]", ",", "\n", "[", "[", "3", ",", "200", ",", "80", ",", "0", ",", "1", "]", ",", "\n", "[", "3", ",", "184", ",", "80", ",", "0", ",", "1", "]", ",", "\n", "[", "3", ",", "184", ",", "80", ",", "0", ",", "1", "]", ",", "\n", "[", "3", ",", "480", ",", "112", ",", "0.25", ",", "1", "]", ",", "\n", "[", "3", ",", "672", ",", "112", ",", "0.25", ",", "1", "]", "\n", "]", ",", "\n", "# stage5", "\n", "[", "[", "5", ",", "672", ",", "160", ",", "0.25", ",", "2", "]", "]", ",", "\n", "[", "[", "5", ",", "960", ",", "160", ",", "0", ",", "1", "]", ",", "\n", "[", "5", ",", "960", ",", "160", ",", "0.25", ",", "1", "]", ",", "\n", "[", "5", ",", "960", ",", "160", ",", "0", ",", "1", "]", ",", "\n", "[", "5", ",", "960", ",", "160", ",", "0.25", ",", "1", "]", "\n", "]", "\n", "]", "\n", "model_kwargs", "=", "dict", "(", "\n", "cfgs", "=", "cfgs", ",", "\n", "width", "=", "width", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "build_model_with_cfg", "(", "\n", "GhostNet", ",", "variant", ",", "pretrained", ",", "\n", "feature_cfg", "=", "dict", "(", "flatten_sequential", "=", "True", ")", ",", "\n", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet.ghostnet_050": [[284, 289], ["ghostnet._create_ghostnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet._create_ghostnet"], ["", "@", "register_model", "\n", "def", "ghostnet_050", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" GhostNet-0.5x \"\"\"", "\n", "model", "=", "_create_ghostnet", "(", "'ghostnet_050'", ",", "width", "=", "0.5", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet.ghostnet_100": [[291, 296], ["ghostnet._create_ghostnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet._create_ghostnet"], ["", "@", "register_model", "\n", "def", "ghostnet_100", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" GhostNet-1.0x \"\"\"", "\n", "model", "=", "_create_ghostnet", "(", "'ghostnet_100'", ",", "width", "=", "1.0", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet.ghostnet_130": [[298, 303], ["ghostnet._create_ghostnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.ghostnet._create_ghostnet"], ["", "@", "register_model", "\n", "def", "ghostnet_130", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" GhostNet-1.3x \"\"\"", "\n", "model", "=", "_create_ghostnet", "(", "'ghostnet_130'", ",", "width", "=", "1.3", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.ActConvBn.__init__": [[36, 42], ["torch.Module.__init__", "torch.ReLU", "torch.ReLU", "torch.ReLU", "layers.create_conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "''", ")", ":", "\n", "        ", "super", "(", "ActConvBn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "act", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "conv", "=", "create_conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm2d", "(", "out_channels", ",", "eps", "=", "0.001", ",", "momentum", "=", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.ActConvBn.forward": [[43, 48], ["nasnet.ActConvBn.act", "nasnet.ActConvBn.conv", "nasnet.ActConvBn.bn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.SeparableConv2d.__init__": [[52, 59], ["torch.Module.__init__", "layers.create_conv2d", "layers.create_conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "padding", "=", "''", ")", ":", "\n", "        ", "super", "(", "SeparableConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "depthwise_conv2d", "=", "create_conv2d", "(", "\n", "in_channels", ",", "in_channels", ",", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "groups", "=", "in_channels", ")", "\n", "self", ".", "pointwise_conv2d", "=", "create_conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.SeparableConv2d.forward": [[60, 64], ["nasnet.SeparableConv2d.depthwise_conv2d", "nasnet.SeparableConv2d.pointwise_conv2d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "depthwise_conv2d", "(", "x", ")", "\n", "x", "=", "self", ".", "pointwise_conv2d", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.BranchSeparables.__init__": [[68, 79], ["torch.Module.__init__", "torch.ReLU", "torch.ReLU", "torch.ReLU", "nasnet.SeparableConv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "nasnet.SeparableConv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "pad_type", "=", "''", ",", "stem_cell", "=", "False", ")", ":", "\n", "        ", "super", "(", "BranchSeparables", ",", "self", ")", ".", "__init__", "(", ")", "\n", "middle_channels", "=", "out_channels", "if", "stem_cell", "else", "in_channels", "\n", "self", ".", "act_1", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "separable_1", "=", "SeparableConv2d", "(", "\n", "in_channels", ",", "middle_channels", ",", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "bn_sep_1", "=", "nn", ".", "BatchNorm2d", "(", "middle_channels", ",", "eps", "=", "0.001", ",", "momentum", "=", "0.1", ")", "\n", "self", ".", "act_2", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "separable_2", "=", "SeparableConv2d", "(", "\n", "middle_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "bn_sep_2", "=", "nn", ".", "BatchNorm2d", "(", "out_channels", ",", "eps", "=", "0.001", ",", "momentum", "=", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.BranchSeparables.forward": [[80, 88], ["nasnet.BranchSeparables.act_1", "nasnet.BranchSeparables.separable_1", "nasnet.BranchSeparables.bn_sep_1", "nasnet.BranchSeparables.act_2", "nasnet.BranchSeparables.separable_2", "nasnet.BranchSeparables.bn_sep_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "act_1", "(", "x", ")", "\n", "x", "=", "self", ".", "separable_1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn_sep_1", "(", "x", ")", "\n", "x", "=", "self", ".", "act_2", "(", "x", ")", "\n", "x", "=", "self", ".", "separable_2", "(", "x", ")", "\n", "x", "=", "self", ".", "bn_sep_2", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.CellStem0.__init__": [[91, 110], ["torch.Module.__init__", "nasnet.ActConvBn", "nasnet.BranchSeparables", "nasnet.BranchSeparables", "layers.create_pool2d", "nasnet.BranchSeparables", "layers.create_pool2d", "nasnet.BranchSeparables", "layers.create_pool2d", "nasnet.BranchSeparables", "layers.create_pool2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d"], ["    ", "def", "__init__", "(", "self", ",", "stem_size", ",", "num_channels", "=", "42", ",", "pad_type", "=", "''", ")", ":", "\n", "        ", "super", "(", "CellStem0", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_channels", "=", "num_channels", "\n", "self", ".", "stem_size", "=", "stem_size", "\n", "self", ".", "conv_1x1", "=", "ActConvBn", "(", "self", ".", "stem_size", ",", "self", ".", "num_channels", ",", "1", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "comb_iter_0_left", "=", "BranchSeparables", "(", "self", ".", "num_channels", ",", "self", ".", "num_channels", ",", "5", ",", "2", ",", "pad_type", ")", "\n", "self", ".", "comb_iter_0_right", "=", "BranchSeparables", "(", "self", ".", "stem_size", ",", "self", ".", "num_channels", ",", "7", ",", "2", ",", "pad_type", ",", "stem_cell", "=", "True", ")", "\n", "\n", "self", ".", "comb_iter_1_left", "=", "create_pool2d", "(", "'max'", ",", "3", ",", "2", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_1_right", "=", "BranchSeparables", "(", "self", ".", "stem_size", ",", "self", ".", "num_channels", ",", "7", ",", "2", ",", "pad_type", ",", "stem_cell", "=", "True", ")", "\n", "\n", "self", ".", "comb_iter_2_left", "=", "create_pool2d", "(", "'avg'", ",", "3", ",", "2", ",", "count_include_pad", "=", "False", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_2_right", "=", "BranchSeparables", "(", "self", ".", "stem_size", ",", "self", ".", "num_channels", ",", "5", ",", "2", ",", "pad_type", ",", "stem_cell", "=", "True", ")", "\n", "\n", "self", ".", "comb_iter_3_right", "=", "create_pool2d", "(", "'avg'", ",", "3", ",", "1", ",", "count_include_pad", "=", "False", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_4_left", "=", "BranchSeparables", "(", "self", ".", "num_channels", ",", "self", ".", "num_channels", ",", "3", ",", "1", ",", "pad_type", ")", "\n", "self", ".", "comb_iter_4_right", "=", "create_pool2d", "(", "'max'", ",", "3", ",", "2", ",", "padding", "=", "pad_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.CellStem0.forward": [[111, 135], ["nasnet.CellStem0.conv_1x1", "nasnet.CellStem0.comb_iter_0_left", "nasnet.CellStem0.comb_iter_0_right", "nasnet.CellStem0.comb_iter_1_left", "nasnet.CellStem0.comb_iter_1_right", "nasnet.CellStem0.comb_iter_2_left", "nasnet.CellStem0.comb_iter_2_right", "nasnet.CellStem0.comb_iter_3_right", "nasnet.CellStem0.comb_iter_4_left", "nasnet.CellStem0.comb_iter_4_right", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x1", "=", "self", ".", "conv_1x1", "(", "x", ")", "\n", "\n", "x_comb_iter_0_left", "=", "self", ".", "comb_iter_0_left", "(", "x1", ")", "\n", "x_comb_iter_0_right", "=", "self", ".", "comb_iter_0_right", "(", "x", ")", "\n", "x_comb_iter_0", "=", "x_comb_iter_0_left", "+", "x_comb_iter_0_right", "\n", "\n", "x_comb_iter_1_left", "=", "self", ".", "comb_iter_1_left", "(", "x1", ")", "\n", "x_comb_iter_1_right", "=", "self", ".", "comb_iter_1_right", "(", "x", ")", "\n", "x_comb_iter_1", "=", "x_comb_iter_1_left", "+", "x_comb_iter_1_right", "\n", "\n", "x_comb_iter_2_left", "=", "self", ".", "comb_iter_2_left", "(", "x1", ")", "\n", "x_comb_iter_2_right", "=", "self", ".", "comb_iter_2_right", "(", "x", ")", "\n", "x_comb_iter_2", "=", "x_comb_iter_2_left", "+", "x_comb_iter_2_right", "\n", "\n", "x_comb_iter_3_right", "=", "self", ".", "comb_iter_3_right", "(", "x_comb_iter_0", ")", "\n", "x_comb_iter_3", "=", "x_comb_iter_3_right", "+", "x_comb_iter_1", "\n", "\n", "x_comb_iter_4_left", "=", "self", ".", "comb_iter_4_left", "(", "x_comb_iter_0", ")", "\n", "x_comb_iter_4_right", "=", "self", ".", "comb_iter_4_right", "(", "x1", ")", "\n", "x_comb_iter_4", "=", "x_comb_iter_4_left", "+", "x_comb_iter_4_right", "\n", "\n", "x_out", "=", "torch", ".", "cat", "(", "[", "x_comb_iter_1", ",", "x_comb_iter_2", ",", "x_comb_iter_3", ",", "x_comb_iter_4", "]", ",", "1", ")", "\n", "return", "x_out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.CellStem1.__init__": [[139, 170], ["torch.Module.__init__", "nasnet.ActConvBn", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Sequential", "torch.Sequential", "torch.Sequential", "nasnet.CellStem1.path_1.add_module", "nasnet.CellStem1.path_1.add_module", "torch.Sequential", "torch.Sequential", "torch.Sequential", "nasnet.CellStem1.path_2.add_module", "nasnet.CellStem1.path_2.add_module", "nasnet.CellStem1.path_2.add_module", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "nasnet.BranchSeparables", "nasnet.BranchSeparables", "layers.create_pool2d", "nasnet.BranchSeparables", "layers.create_pool2d", "nasnet.BranchSeparables", "layers.create_pool2d", "nasnet.BranchSeparables", "layers.create_pool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d"], ["    ", "def", "__init__", "(", "self", ",", "stem_size", ",", "num_channels", ",", "pad_type", "=", "''", ")", ":", "\n", "        ", "super", "(", "CellStem1", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_channels", "=", "num_channels", "\n", "self", ".", "stem_size", "=", "stem_size", "\n", "self", ".", "conv_1x1", "=", "ActConvBn", "(", "2", "*", "self", ".", "num_channels", ",", "self", ".", "num_channels", ",", "1", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "act", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "path_1", "=", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "path_1", ".", "add_module", "(", "'avgpool'", ",", "nn", ".", "AvgPool2d", "(", "1", ",", "stride", "=", "2", ",", "count_include_pad", "=", "False", ")", ")", "\n", "self", ".", "path_1", ".", "add_module", "(", "'conv'", ",", "nn", ".", "Conv2d", "(", "self", ".", "stem_size", ",", "self", ".", "num_channels", "//", "2", ",", "1", ",", "stride", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "\n", "self", ".", "path_2", "=", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "path_2", ".", "add_module", "(", "'pad'", ",", "nn", ".", "ZeroPad2d", "(", "(", "-", "1", ",", "1", ",", "-", "1", ",", "1", ")", ")", ")", "\n", "self", ".", "path_2", ".", "add_module", "(", "'avgpool'", ",", "nn", ".", "AvgPool2d", "(", "1", ",", "stride", "=", "2", ",", "count_include_pad", "=", "False", ")", ")", "\n", "self", ".", "path_2", ".", "add_module", "(", "'conv'", ",", "nn", ".", "Conv2d", "(", "self", ".", "stem_size", ",", "self", ".", "num_channels", "//", "2", ",", "1", ",", "stride", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "\n", "self", ".", "final_path_bn", "=", "nn", ".", "BatchNorm2d", "(", "self", ".", "num_channels", ",", "eps", "=", "0.001", ",", "momentum", "=", "0.1", ")", "\n", "\n", "self", ".", "comb_iter_0_left", "=", "BranchSeparables", "(", "self", ".", "num_channels", ",", "self", ".", "num_channels", ",", "5", ",", "2", ",", "pad_type", ")", "\n", "self", ".", "comb_iter_0_right", "=", "BranchSeparables", "(", "self", ".", "num_channels", ",", "self", ".", "num_channels", ",", "7", ",", "2", ",", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_1_left", "=", "create_pool2d", "(", "'max'", ",", "3", ",", "2", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_1_right", "=", "BranchSeparables", "(", "self", ".", "num_channels", ",", "self", ".", "num_channels", ",", "7", ",", "2", ",", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_2_left", "=", "create_pool2d", "(", "'avg'", ",", "3", ",", "2", ",", "count_include_pad", "=", "False", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_2_right", "=", "BranchSeparables", "(", "self", ".", "num_channels", ",", "self", ".", "num_channels", ",", "5", ",", "2", ",", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_3_right", "=", "create_pool2d", "(", "'avg'", ",", "3", ",", "1", ",", "count_include_pad", "=", "False", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_4_left", "=", "BranchSeparables", "(", "self", ".", "num_channels", ",", "self", ".", "num_channels", ",", "3", ",", "1", ",", "pad_type", ")", "\n", "self", ".", "comb_iter_4_right", "=", "create_pool2d", "(", "'max'", ",", "3", ",", "2", ",", "padding", "=", "pad_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.CellStem1.forward": [[171, 203], ["nasnet.CellStem1.conv_1x1", "nasnet.CellStem1.act", "nasnet.CellStem1.path_1", "nasnet.CellStem1.path_2", "nasnet.CellStem1.final_path_bn", "nasnet.CellStem1.comb_iter_0_left", "nasnet.CellStem1.comb_iter_0_right", "nasnet.CellStem1.comb_iter_1_left", "nasnet.CellStem1.comb_iter_1_right", "nasnet.CellStem1.comb_iter_2_left", "nasnet.CellStem1.comb_iter_2_right", "nasnet.CellStem1.comb_iter_3_right", "nasnet.CellStem1.comb_iter_4_left", "nasnet.CellStem1.comb_iter_4_right", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_conv0", ",", "x_stem_0", ")", ":", "\n", "        ", "x_left", "=", "self", ".", "conv_1x1", "(", "x_stem_0", ")", "\n", "\n", "x_relu", "=", "self", ".", "act", "(", "x_conv0", ")", "\n", "# path 1", "\n", "x_path1", "=", "self", ".", "path_1", "(", "x_relu", ")", "\n", "# path 2", "\n", "x_path2", "=", "self", ".", "path_2", "(", "x_relu", ")", "\n", "# final path", "\n", "x_right", "=", "self", ".", "final_path_bn", "(", "torch", ".", "cat", "(", "[", "x_path1", ",", "x_path2", "]", ",", "1", ")", ")", "\n", "\n", "x_comb_iter_0_left", "=", "self", ".", "comb_iter_0_left", "(", "x_left", ")", "\n", "x_comb_iter_0_right", "=", "self", ".", "comb_iter_0_right", "(", "x_right", ")", "\n", "x_comb_iter_0", "=", "x_comb_iter_0_left", "+", "x_comb_iter_0_right", "\n", "\n", "x_comb_iter_1_left", "=", "self", ".", "comb_iter_1_left", "(", "x_left", ")", "\n", "x_comb_iter_1_right", "=", "self", ".", "comb_iter_1_right", "(", "x_right", ")", "\n", "x_comb_iter_1", "=", "x_comb_iter_1_left", "+", "x_comb_iter_1_right", "\n", "\n", "x_comb_iter_2_left", "=", "self", ".", "comb_iter_2_left", "(", "x_left", ")", "\n", "x_comb_iter_2_right", "=", "self", ".", "comb_iter_2_right", "(", "x_right", ")", "\n", "x_comb_iter_2", "=", "x_comb_iter_2_left", "+", "x_comb_iter_2_right", "\n", "\n", "x_comb_iter_3_right", "=", "self", ".", "comb_iter_3_right", "(", "x_comb_iter_0", ")", "\n", "x_comb_iter_3", "=", "x_comb_iter_3_right", "+", "x_comb_iter_1", "\n", "\n", "x_comb_iter_4_left", "=", "self", ".", "comb_iter_4_left", "(", "x_comb_iter_0", ")", "\n", "x_comb_iter_4_right", "=", "self", ".", "comb_iter_4_right", "(", "x_left", ")", "\n", "x_comb_iter_4", "=", "x_comb_iter_4_left", "+", "x_comb_iter_4_right", "\n", "\n", "x_out", "=", "torch", ".", "cat", "(", "[", "x_comb_iter_1", ",", "x_comb_iter_2", ",", "x_comb_iter_3", ",", "x_comb_iter_4", "]", ",", "1", ")", "\n", "return", "x_out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.FirstCell.__init__": [[207, 235], ["torch.Module.__init__", "nasnet.ActConvBn", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Sequential", "torch.Sequential", "torch.Sequential", "nasnet.FirstCell.path_1.add_module", "nasnet.FirstCell.path_1.add_module", "torch.Sequential", "torch.Sequential", "torch.Sequential", "nasnet.FirstCell.path_2.add_module", "nasnet.FirstCell.path_2.add_module", "nasnet.FirstCell.path_2.add_module", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "nasnet.BranchSeparables", "nasnet.BranchSeparables", "nasnet.BranchSeparables", "nasnet.BranchSeparables", "layers.create_pool2d", "layers.create_pool2d", "layers.create_pool2d", "nasnet.BranchSeparables", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d"], ["    ", "def", "__init__", "(", "self", ",", "in_chs_left", ",", "out_chs_left", ",", "in_chs_right", ",", "out_chs_right", ",", "pad_type", "=", "''", ")", ":", "\n", "        ", "super", "(", "FirstCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_1x1", "=", "ActConvBn", "(", "in_chs_right", ",", "out_chs_right", ",", "1", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "act", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "path_1", "=", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "path_1", ".", "add_module", "(", "'avgpool'", ",", "nn", ".", "AvgPool2d", "(", "1", ",", "stride", "=", "2", ",", "count_include_pad", "=", "False", ")", ")", "\n", "self", ".", "path_1", ".", "add_module", "(", "'conv'", ",", "nn", ".", "Conv2d", "(", "in_chs_left", ",", "out_chs_left", ",", "1", ",", "stride", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "\n", "self", ".", "path_2", "=", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "path_2", ".", "add_module", "(", "'pad'", ",", "nn", ".", "ZeroPad2d", "(", "(", "-", "1", ",", "1", ",", "-", "1", ",", "1", ")", ")", ")", "\n", "self", ".", "path_2", ".", "add_module", "(", "'avgpool'", ",", "nn", ".", "AvgPool2d", "(", "1", ",", "stride", "=", "2", ",", "count_include_pad", "=", "False", ")", ")", "\n", "self", ".", "path_2", ".", "add_module", "(", "'conv'", ",", "nn", ".", "Conv2d", "(", "in_chs_left", ",", "out_chs_left", ",", "1", ",", "stride", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "\n", "self", ".", "final_path_bn", "=", "nn", ".", "BatchNorm2d", "(", "out_chs_left", "*", "2", ",", "eps", "=", "0.001", ",", "momentum", "=", "0.1", ")", "\n", "\n", "self", ".", "comb_iter_0_left", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "5", ",", "1", ",", "pad_type", ")", "\n", "self", ".", "comb_iter_0_right", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "3", ",", "1", ",", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_1_left", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "5", ",", "1", ",", "pad_type", ")", "\n", "self", ".", "comb_iter_1_right", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "3", ",", "1", ",", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_2_left", "=", "create_pool2d", "(", "'avg'", ",", "3", ",", "1", ",", "count_include_pad", "=", "False", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_3_left", "=", "create_pool2d", "(", "'avg'", ",", "3", ",", "1", ",", "count_include_pad", "=", "False", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_3_right", "=", "create_pool2d", "(", "'avg'", ",", "3", ",", "1", ",", "count_include_pad", "=", "False", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_4_left", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "3", ",", "1", ",", "pad_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.FirstCell.forward": [[236, 263], ["nasnet.FirstCell.act", "nasnet.FirstCell.path_1", "nasnet.FirstCell.path_2", "nasnet.FirstCell.final_path_bn", "nasnet.FirstCell.conv_1x1", "nasnet.FirstCell.comb_iter_0_left", "nasnet.FirstCell.comb_iter_0_right", "nasnet.FirstCell.comb_iter_1_left", "nasnet.FirstCell.comb_iter_1_right", "nasnet.FirstCell.comb_iter_2_left", "nasnet.FirstCell.comb_iter_3_left", "nasnet.FirstCell.comb_iter_3_right", "nasnet.FirstCell.comb_iter_4_left", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_prev", ")", ":", "\n", "        ", "x_relu", "=", "self", ".", "act", "(", "x_prev", ")", "\n", "x_path1", "=", "self", ".", "path_1", "(", "x_relu", ")", "\n", "x_path2", "=", "self", ".", "path_2", "(", "x_relu", ")", "\n", "x_left", "=", "self", ".", "final_path_bn", "(", "torch", ".", "cat", "(", "[", "x_path1", ",", "x_path2", "]", ",", "1", ")", ")", "\n", "x_right", "=", "self", ".", "conv_1x1", "(", "x", ")", "\n", "\n", "x_comb_iter_0_left", "=", "self", ".", "comb_iter_0_left", "(", "x_right", ")", "\n", "x_comb_iter_0_right", "=", "self", ".", "comb_iter_0_right", "(", "x_left", ")", "\n", "x_comb_iter_0", "=", "x_comb_iter_0_left", "+", "x_comb_iter_0_right", "\n", "\n", "x_comb_iter_1_left", "=", "self", ".", "comb_iter_1_left", "(", "x_left", ")", "\n", "x_comb_iter_1_right", "=", "self", ".", "comb_iter_1_right", "(", "x_left", ")", "\n", "x_comb_iter_1", "=", "x_comb_iter_1_left", "+", "x_comb_iter_1_right", "\n", "\n", "x_comb_iter_2_left", "=", "self", ".", "comb_iter_2_left", "(", "x_right", ")", "\n", "x_comb_iter_2", "=", "x_comb_iter_2_left", "+", "x_left", "\n", "\n", "x_comb_iter_3_left", "=", "self", ".", "comb_iter_3_left", "(", "x_left", ")", "\n", "x_comb_iter_3_right", "=", "self", ".", "comb_iter_3_right", "(", "x_left", ")", "\n", "x_comb_iter_3", "=", "x_comb_iter_3_left", "+", "x_comb_iter_3_right", "\n", "\n", "x_comb_iter_4_left", "=", "self", ".", "comb_iter_4_left", "(", "x_right", ")", "\n", "x_comb_iter_4", "=", "x_comb_iter_4_left", "+", "x_right", "\n", "\n", "x_out", "=", "torch", ".", "cat", "(", "[", "x_left", ",", "x_comb_iter_0", ",", "x_comb_iter_1", ",", "x_comb_iter_2", ",", "x_comb_iter_3", ",", "x_comb_iter_4", "]", ",", "1", ")", "\n", "return", "x_out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.NormalCell.__init__": [[267, 284], ["torch.Module.__init__", "nasnet.ActConvBn", "nasnet.ActConvBn", "nasnet.BranchSeparables", "nasnet.BranchSeparables", "nasnet.BranchSeparables", "nasnet.BranchSeparables", "layers.create_pool2d", "layers.create_pool2d", "layers.create_pool2d", "nasnet.BranchSeparables"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d"], ["    ", "def", "__init__", "(", "self", ",", "in_chs_left", ",", "out_chs_left", ",", "in_chs_right", ",", "out_chs_right", ",", "pad_type", "=", "''", ")", ":", "\n", "        ", "super", "(", "NormalCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_prev_1x1", "=", "ActConvBn", "(", "in_chs_left", ",", "out_chs_left", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "conv_1x1", "=", "ActConvBn", "(", "in_chs_right", ",", "out_chs_right", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_0_left", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "5", ",", "1", ",", "pad_type", ")", "\n", "self", ".", "comb_iter_0_right", "=", "BranchSeparables", "(", "out_chs_left", ",", "out_chs_left", ",", "3", ",", "1", ",", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_1_left", "=", "BranchSeparables", "(", "out_chs_left", ",", "out_chs_left", ",", "5", ",", "1", ",", "pad_type", ")", "\n", "self", ".", "comb_iter_1_right", "=", "BranchSeparables", "(", "out_chs_left", ",", "out_chs_left", ",", "3", ",", "1", ",", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_2_left", "=", "create_pool2d", "(", "'avg'", ",", "3", ",", "1", ",", "count_include_pad", "=", "False", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_3_left", "=", "create_pool2d", "(", "'avg'", ",", "3", ",", "1", ",", "count_include_pad", "=", "False", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_3_right", "=", "create_pool2d", "(", "'avg'", ",", "3", ",", "1", ",", "count_include_pad", "=", "False", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_4_left", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "3", ",", "1", ",", "pad_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.NormalCell.forward": [[285, 309], ["nasnet.NormalCell.conv_prev_1x1", "nasnet.NormalCell.conv_1x1", "nasnet.NormalCell.comb_iter_0_left", "nasnet.NormalCell.comb_iter_0_right", "nasnet.NormalCell.comb_iter_1_left", "nasnet.NormalCell.comb_iter_1_right", "nasnet.NormalCell.comb_iter_2_left", "nasnet.NormalCell.comb_iter_3_left", "nasnet.NormalCell.comb_iter_3_right", "nasnet.NormalCell.comb_iter_4_left", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_prev", ")", ":", "\n", "        ", "x_left", "=", "self", ".", "conv_prev_1x1", "(", "x_prev", ")", "\n", "x_right", "=", "self", ".", "conv_1x1", "(", "x", ")", "\n", "\n", "x_comb_iter_0_left", "=", "self", ".", "comb_iter_0_left", "(", "x_right", ")", "\n", "x_comb_iter_0_right", "=", "self", ".", "comb_iter_0_right", "(", "x_left", ")", "\n", "x_comb_iter_0", "=", "x_comb_iter_0_left", "+", "x_comb_iter_0_right", "\n", "\n", "x_comb_iter_1_left", "=", "self", ".", "comb_iter_1_left", "(", "x_left", ")", "\n", "x_comb_iter_1_right", "=", "self", ".", "comb_iter_1_right", "(", "x_left", ")", "\n", "x_comb_iter_1", "=", "x_comb_iter_1_left", "+", "x_comb_iter_1_right", "\n", "\n", "x_comb_iter_2_left", "=", "self", ".", "comb_iter_2_left", "(", "x_right", ")", "\n", "x_comb_iter_2", "=", "x_comb_iter_2_left", "+", "x_left", "\n", "\n", "x_comb_iter_3_left", "=", "self", ".", "comb_iter_3_left", "(", "x_left", ")", "\n", "x_comb_iter_3_right", "=", "self", ".", "comb_iter_3_right", "(", "x_left", ")", "\n", "x_comb_iter_3", "=", "x_comb_iter_3_left", "+", "x_comb_iter_3_right", "\n", "\n", "x_comb_iter_4_left", "=", "self", ".", "comb_iter_4_left", "(", "x_right", ")", "\n", "x_comb_iter_4", "=", "x_comb_iter_4_left", "+", "x_right", "\n", "\n", "x_out", "=", "torch", ".", "cat", "(", "[", "x_left", ",", "x_comb_iter_0", ",", "x_comb_iter_1", ",", "x_comb_iter_2", ",", "x_comb_iter_3", ",", "x_comb_iter_4", "]", ",", "1", ")", "\n", "return", "x_out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.ReductionCell0.__init__": [[313, 331], ["torch.Module.__init__", "nasnet.ActConvBn", "nasnet.ActConvBn", "nasnet.BranchSeparables", "nasnet.BranchSeparables", "layers.create_pool2d", "nasnet.BranchSeparables", "layers.create_pool2d", "nasnet.BranchSeparables", "layers.create_pool2d", "nasnet.BranchSeparables", "layers.create_pool2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d"], ["    ", "def", "__init__", "(", "self", ",", "in_chs_left", ",", "out_chs_left", ",", "in_chs_right", ",", "out_chs_right", ",", "pad_type", "=", "''", ")", ":", "\n", "        ", "super", "(", "ReductionCell0", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_prev_1x1", "=", "ActConvBn", "(", "in_chs_left", ",", "out_chs_left", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "conv_1x1", "=", "ActConvBn", "(", "in_chs_right", ",", "out_chs_right", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_0_left", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "5", ",", "2", ",", "pad_type", ")", "\n", "self", ".", "comb_iter_0_right", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "7", ",", "2", ",", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_1_left", "=", "create_pool2d", "(", "'max'", ",", "3", ",", "2", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_1_right", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "7", ",", "2", ",", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_2_left", "=", "create_pool2d", "(", "'avg'", ",", "3", ",", "2", ",", "count_include_pad", "=", "False", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_2_right", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "5", ",", "2", ",", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_3_right", "=", "create_pool2d", "(", "'avg'", ",", "3", ",", "1", ",", "count_include_pad", "=", "False", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_4_left", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "3", ",", "1", ",", "pad_type", ")", "\n", "self", ".", "comb_iter_4_right", "=", "create_pool2d", "(", "'max'", ",", "3", ",", "2", ",", "padding", "=", "pad_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.ReductionCell0.forward": [[332, 357], ["nasnet.ReductionCell0.conv_prev_1x1", "nasnet.ReductionCell0.conv_1x1", "nasnet.ReductionCell0.comb_iter_0_left", "nasnet.ReductionCell0.comb_iter_0_right", "nasnet.ReductionCell0.comb_iter_1_left", "nasnet.ReductionCell0.comb_iter_1_right", "nasnet.ReductionCell0.comb_iter_2_left", "nasnet.ReductionCell0.comb_iter_2_right", "nasnet.ReductionCell0.comb_iter_3_right", "nasnet.ReductionCell0.comb_iter_4_left", "nasnet.ReductionCell0.comb_iter_4_right", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_prev", ")", ":", "\n", "        ", "x_left", "=", "self", ".", "conv_prev_1x1", "(", "x_prev", ")", "\n", "x_right", "=", "self", ".", "conv_1x1", "(", "x", ")", "\n", "\n", "x_comb_iter_0_left", "=", "self", ".", "comb_iter_0_left", "(", "x_right", ")", "\n", "x_comb_iter_0_right", "=", "self", ".", "comb_iter_0_right", "(", "x_left", ")", "\n", "x_comb_iter_0", "=", "x_comb_iter_0_left", "+", "x_comb_iter_0_right", "\n", "\n", "x_comb_iter_1_left", "=", "self", ".", "comb_iter_1_left", "(", "x_right", ")", "\n", "x_comb_iter_1_right", "=", "self", ".", "comb_iter_1_right", "(", "x_left", ")", "\n", "x_comb_iter_1", "=", "x_comb_iter_1_left", "+", "x_comb_iter_1_right", "\n", "\n", "x_comb_iter_2_left", "=", "self", ".", "comb_iter_2_left", "(", "x_right", ")", "\n", "x_comb_iter_2_right", "=", "self", ".", "comb_iter_2_right", "(", "x_left", ")", "\n", "x_comb_iter_2", "=", "x_comb_iter_2_left", "+", "x_comb_iter_2_right", "\n", "\n", "x_comb_iter_3_right", "=", "self", ".", "comb_iter_3_right", "(", "x_comb_iter_0", ")", "\n", "x_comb_iter_3", "=", "x_comb_iter_3_right", "+", "x_comb_iter_1", "\n", "\n", "x_comb_iter_4_left", "=", "self", ".", "comb_iter_4_left", "(", "x_comb_iter_0", ")", "\n", "x_comb_iter_4_right", "=", "self", ".", "comb_iter_4_right", "(", "x_right", ")", "\n", "x_comb_iter_4", "=", "x_comb_iter_4_left", "+", "x_comb_iter_4_right", "\n", "\n", "x_out", "=", "torch", ".", "cat", "(", "[", "x_comb_iter_1", ",", "x_comb_iter_2", ",", "x_comb_iter_3", ",", "x_comb_iter_4", "]", ",", "1", ")", "\n", "return", "x_out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.ReductionCell1.__init__": [[361, 379], ["torch.Module.__init__", "nasnet.ActConvBn", "nasnet.ActConvBn", "nasnet.BranchSeparables", "nasnet.BranchSeparables", "layers.create_pool2d", "nasnet.BranchSeparables", "layers.create_pool2d", "nasnet.BranchSeparables", "layers.create_pool2d", "nasnet.BranchSeparables", "layers.create_pool2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d"], ["    ", "def", "__init__", "(", "self", ",", "in_chs_left", ",", "out_chs_left", ",", "in_chs_right", ",", "out_chs_right", ",", "pad_type", "=", "''", ")", ":", "\n", "        ", "super", "(", "ReductionCell1", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_prev_1x1", "=", "ActConvBn", "(", "in_chs_left", ",", "out_chs_left", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "conv_1x1", "=", "ActConvBn", "(", "in_chs_right", ",", "out_chs_right", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_0_left", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "5", ",", "2", ",", "pad_type", ")", "\n", "self", ".", "comb_iter_0_right", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "7", ",", "2", ",", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_1_left", "=", "create_pool2d", "(", "'max'", ",", "3", ",", "2", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_1_right", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "7", ",", "2", ",", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_2_left", "=", "create_pool2d", "(", "'avg'", ",", "3", ",", "2", ",", "count_include_pad", "=", "False", ",", "padding", "=", "pad_type", ")", "\n", "self", ".", "comb_iter_2_right", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "5", ",", "2", ",", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_3_right", "=", "create_pool2d", "(", "'avg'", ",", "3", ",", "1", ",", "count_include_pad", "=", "False", ",", "padding", "=", "pad_type", ")", "\n", "\n", "self", ".", "comb_iter_4_left", "=", "BranchSeparables", "(", "out_chs_right", ",", "out_chs_right", ",", "3", ",", "1", ",", "pad_type", ")", "\n", "self", ".", "comb_iter_4_right", "=", "create_pool2d", "(", "'max'", ",", "3", ",", "2", ",", "padding", "=", "pad_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.ReductionCell1.forward": [[380, 405], ["nasnet.ReductionCell1.conv_prev_1x1", "nasnet.ReductionCell1.conv_1x1", "nasnet.ReductionCell1.comb_iter_0_left", "nasnet.ReductionCell1.comb_iter_0_right", "nasnet.ReductionCell1.comb_iter_1_left", "nasnet.ReductionCell1.comb_iter_1_right", "nasnet.ReductionCell1.comb_iter_2_left", "nasnet.ReductionCell1.comb_iter_2_right", "nasnet.ReductionCell1.comb_iter_3_right", "nasnet.ReductionCell1.comb_iter_4_left", "nasnet.ReductionCell1.comb_iter_4_right", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_prev", ")", ":", "\n", "        ", "x_left", "=", "self", ".", "conv_prev_1x1", "(", "x_prev", ")", "\n", "x_right", "=", "self", ".", "conv_1x1", "(", "x", ")", "\n", "\n", "x_comb_iter_0_left", "=", "self", ".", "comb_iter_0_left", "(", "x_right", ")", "\n", "x_comb_iter_0_right", "=", "self", ".", "comb_iter_0_right", "(", "x_left", ")", "\n", "x_comb_iter_0", "=", "x_comb_iter_0_left", "+", "x_comb_iter_0_right", "\n", "\n", "x_comb_iter_1_left", "=", "self", ".", "comb_iter_1_left", "(", "x_right", ")", "\n", "x_comb_iter_1_right", "=", "self", ".", "comb_iter_1_right", "(", "x_left", ")", "\n", "x_comb_iter_1", "=", "x_comb_iter_1_left", "+", "x_comb_iter_1_right", "\n", "\n", "x_comb_iter_2_left", "=", "self", ".", "comb_iter_2_left", "(", "x_right", ")", "\n", "x_comb_iter_2_right", "=", "self", ".", "comb_iter_2_right", "(", "x_left", ")", "\n", "x_comb_iter_2", "=", "x_comb_iter_2_left", "+", "x_comb_iter_2_right", "\n", "\n", "x_comb_iter_3_right", "=", "self", ".", "comb_iter_3_right", "(", "x_comb_iter_0", ")", "\n", "x_comb_iter_3", "=", "x_comb_iter_3_right", "+", "x_comb_iter_1", "\n", "\n", "x_comb_iter_4_left", "=", "self", ".", "comb_iter_4_left", "(", "x_comb_iter_0", ")", "\n", "x_comb_iter_4_right", "=", "self", ".", "comb_iter_4_right", "(", "x_right", ")", "\n", "x_comb_iter_4", "=", "x_comb_iter_4_left", "+", "x_comb_iter_4_right", "\n", "\n", "x_out", "=", "torch", ".", "cat", "(", "[", "x_comb_iter_1", ",", "x_comb_iter_2", ",", "x_comb_iter_3", ",", "x_comb_iter_4", "]", ",", "1", ")", "\n", "return", "x_out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.NASNetALarge.__init__": [[410, 506], ["torch.Module.__init__", "layers.ConvNormAct", "nasnet.CellStem0", "nasnet.CellStem1", "nasnet.FirstCell", "nasnet.NormalCell", "nasnet.NormalCell", "nasnet.NormalCell", "nasnet.NormalCell", "nasnet.NormalCell", "nasnet.ReductionCell0", "nasnet.FirstCell", "nasnet.NormalCell", "nasnet.NormalCell", "nasnet.NormalCell", "nasnet.NormalCell", "nasnet.NormalCell", "nasnet.ReductionCell1", "nasnet.FirstCell", "nasnet.NormalCell", "nasnet.NormalCell", "nasnet.NormalCell", "nasnet.NormalCell", "nasnet.NormalCell", "torch.ReLU", "torch.ReLU", "torch.ReLU", "layers.create_classifier", "dict", "dict", "dict", "dict", "dict", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["def", "__init__", "(", "\n", "self", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "stem_size", "=", "96", ",", "channel_multiplier", "=", "2", ",", "\n", "num_features", "=", "4032", ",", "output_stride", "=", "32", ",", "drop_rate", "=", "0.", ",", "global_pool", "=", "'avg'", ",", "pad_type", "=", "'same'", ")", ":", "\n", "        ", "super", "(", "NASNetALarge", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "stem_size", "=", "stem_size", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "channel_multiplier", "=", "channel_multiplier", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "assert", "output_stride", "==", "32", "\n", "\n", "channels", "=", "self", ".", "num_features", "//", "24", "\n", "# 24 is default value for the architecture", "\n", "\n", "self", ".", "conv0", "=", "ConvNormAct", "(", "\n", "in_channels", "=", "in_chans", ",", "out_channels", "=", "self", ".", "stem_size", ",", "kernel_size", "=", "3", ",", "padding", "=", "0", ",", "stride", "=", "2", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "BatchNorm2d", ",", "eps", "=", "0.001", ",", "momentum", "=", "0.1", ")", ",", "apply_act", "=", "False", ")", "\n", "\n", "self", ".", "cell_stem_0", "=", "CellStem0", "(", "\n", "self", ".", "stem_size", ",", "num_channels", "=", "channels", "//", "(", "channel_multiplier", "**", "2", ")", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_stem_1", "=", "CellStem1", "(", "\n", "self", ".", "stem_size", ",", "num_channels", "=", "channels", "//", "channel_multiplier", ",", "pad_type", "=", "pad_type", ")", "\n", "\n", "self", ".", "cell_0", "=", "FirstCell", "(", "\n", "in_chs_left", "=", "channels", ",", "out_chs_left", "=", "channels", "//", "2", ",", "\n", "in_chs_right", "=", "2", "*", "channels", ",", "out_chs_right", "=", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_1", "=", "NormalCell", "(", "\n", "in_chs_left", "=", "2", "*", "channels", ",", "out_chs_left", "=", "channels", ",", "\n", "in_chs_right", "=", "6", "*", "channels", ",", "out_chs_right", "=", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_2", "=", "NormalCell", "(", "\n", "in_chs_left", "=", "6", "*", "channels", ",", "out_chs_left", "=", "channels", ",", "\n", "in_chs_right", "=", "6", "*", "channels", ",", "out_chs_right", "=", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_3", "=", "NormalCell", "(", "\n", "in_chs_left", "=", "6", "*", "channels", ",", "out_chs_left", "=", "channels", ",", "\n", "in_chs_right", "=", "6", "*", "channels", ",", "out_chs_right", "=", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_4", "=", "NormalCell", "(", "\n", "in_chs_left", "=", "6", "*", "channels", ",", "out_chs_left", "=", "channels", ",", "\n", "in_chs_right", "=", "6", "*", "channels", ",", "out_chs_right", "=", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_5", "=", "NormalCell", "(", "\n", "in_chs_left", "=", "6", "*", "channels", ",", "out_chs_left", "=", "channels", ",", "\n", "in_chs_right", "=", "6", "*", "channels", ",", "out_chs_right", "=", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "\n", "self", ".", "reduction_cell_0", "=", "ReductionCell0", "(", "\n", "in_chs_left", "=", "6", "*", "channels", ",", "out_chs_left", "=", "2", "*", "channels", ",", "\n", "in_chs_right", "=", "6", "*", "channels", ",", "out_chs_right", "=", "2", "*", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_6", "=", "FirstCell", "(", "\n", "in_chs_left", "=", "6", "*", "channels", ",", "out_chs_left", "=", "channels", ",", "\n", "in_chs_right", "=", "8", "*", "channels", ",", "out_chs_right", "=", "2", "*", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_7", "=", "NormalCell", "(", "\n", "in_chs_left", "=", "8", "*", "channels", ",", "out_chs_left", "=", "2", "*", "channels", ",", "\n", "in_chs_right", "=", "12", "*", "channels", ",", "out_chs_right", "=", "2", "*", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_8", "=", "NormalCell", "(", "\n", "in_chs_left", "=", "12", "*", "channels", ",", "out_chs_left", "=", "2", "*", "channels", ",", "\n", "in_chs_right", "=", "12", "*", "channels", ",", "out_chs_right", "=", "2", "*", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_9", "=", "NormalCell", "(", "\n", "in_chs_left", "=", "12", "*", "channels", ",", "out_chs_left", "=", "2", "*", "channels", ",", "\n", "in_chs_right", "=", "12", "*", "channels", ",", "out_chs_right", "=", "2", "*", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_10", "=", "NormalCell", "(", "\n", "in_chs_left", "=", "12", "*", "channels", ",", "out_chs_left", "=", "2", "*", "channels", ",", "\n", "in_chs_right", "=", "12", "*", "channels", ",", "out_chs_right", "=", "2", "*", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_11", "=", "NormalCell", "(", "\n", "in_chs_left", "=", "12", "*", "channels", ",", "out_chs_left", "=", "2", "*", "channels", ",", "\n", "in_chs_right", "=", "12", "*", "channels", ",", "out_chs_right", "=", "2", "*", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "\n", "self", ".", "reduction_cell_1", "=", "ReductionCell1", "(", "\n", "in_chs_left", "=", "12", "*", "channels", ",", "out_chs_left", "=", "4", "*", "channels", ",", "\n", "in_chs_right", "=", "12", "*", "channels", ",", "out_chs_right", "=", "4", "*", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_12", "=", "FirstCell", "(", "\n", "in_chs_left", "=", "12", "*", "channels", ",", "out_chs_left", "=", "2", "*", "channels", ",", "\n", "in_chs_right", "=", "16", "*", "channels", ",", "out_chs_right", "=", "4", "*", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_13", "=", "NormalCell", "(", "\n", "in_chs_left", "=", "16", "*", "channels", ",", "out_chs_left", "=", "4", "*", "channels", ",", "\n", "in_chs_right", "=", "24", "*", "channels", ",", "out_chs_right", "=", "4", "*", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_14", "=", "NormalCell", "(", "\n", "in_chs_left", "=", "24", "*", "channels", ",", "out_chs_left", "=", "4", "*", "channels", ",", "\n", "in_chs_right", "=", "24", "*", "channels", ",", "out_chs_right", "=", "4", "*", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_15", "=", "NormalCell", "(", "\n", "in_chs_left", "=", "24", "*", "channels", ",", "out_chs_left", "=", "4", "*", "channels", ",", "\n", "in_chs_right", "=", "24", "*", "channels", ",", "out_chs_right", "=", "4", "*", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_16", "=", "NormalCell", "(", "\n", "in_chs_left", "=", "24", "*", "channels", ",", "out_chs_left", "=", "4", "*", "channels", ",", "\n", "in_chs_right", "=", "24", "*", "channels", ",", "out_chs_right", "=", "4", "*", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "cell_17", "=", "NormalCell", "(", "\n", "in_chs_left", "=", "24", "*", "channels", ",", "out_chs_left", "=", "4", "*", "channels", ",", "\n", "in_chs_right", "=", "24", "*", "channels", ",", "out_chs_right", "=", "4", "*", "channels", ",", "pad_type", "=", "pad_type", ")", "\n", "self", ".", "act", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "feature_info", "=", "[", "\n", "dict", "(", "num_chs", "=", "96", ",", "reduction", "=", "2", ",", "module", "=", "'conv0'", ")", ",", "\n", "dict", "(", "num_chs", "=", "168", ",", "reduction", "=", "4", ",", "module", "=", "'cell_stem_1.conv_1x1.act'", ")", ",", "\n", "dict", "(", "num_chs", "=", "1008", ",", "reduction", "=", "8", ",", "module", "=", "'reduction_cell_0.conv_1x1.act'", ")", ",", "\n", "dict", "(", "num_chs", "=", "2016", ",", "reduction", "=", "16", ",", "module", "=", "'reduction_cell_1.conv_1x1.act'", ")", ",", "\n", "dict", "(", "num_chs", "=", "4032", ",", "reduction", "=", "32", ",", "module", "=", "'act'", ")", ",", "\n", "]", "\n", "\n", "self", ".", "global_pool", ",", "self", ".", "last_linear", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.NASNetALarge.group_matcher": [[507, 518], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem", "=", "r'^conv0|cell_stem_[01]'", ",", "\n", "blocks", "=", "[", "\n", "(", "r'^cell_(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^reduction_cell_0'", ",", "(", "6", ",", ")", ")", ",", "\n", "(", "r'^reduction_cell_1'", ",", "(", "12", ",", ")", ")", ",", "\n", "]", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.NASNetALarge.set_grad_checkpointing": [[519, 522], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "'gradient checkpointing not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.NASNetALarge.get_classifier": [[523, 526], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "last_linear", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.NASNetALarge.reset_classifier": [[527, 531], ["layers.create_classifier"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "last_linear", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.NASNetALarge.forward_features": [[532, 562], ["nasnet.NASNetALarge.conv0", "nasnet.NASNetALarge.cell_stem_0", "nasnet.NASNetALarge.cell_stem_1", "nasnet.NASNetALarge.cell_0", "nasnet.NASNetALarge.cell_1", "nasnet.NASNetALarge.cell_2", "nasnet.NASNetALarge.cell_3", "nasnet.NASNetALarge.cell_4", "nasnet.NASNetALarge.cell_5", "nasnet.NASNetALarge.reduction_cell_0", "nasnet.NASNetALarge.cell_6", "nasnet.NASNetALarge.cell_7", "nasnet.NASNetALarge.cell_8", "nasnet.NASNetALarge.cell_9", "nasnet.NASNetALarge.cell_10", "nasnet.NASNetALarge.cell_11", "nasnet.NASNetALarge.reduction_cell_1", "nasnet.NASNetALarge.cell_12", "nasnet.NASNetALarge.cell_13", "nasnet.NASNetALarge.cell_14", "nasnet.NASNetALarge.cell_15", "nasnet.NASNetALarge.cell_16", "nasnet.NASNetALarge.cell_17", "nasnet.NASNetALarge.act"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_conv0", "=", "self", ".", "conv0", "(", "x", ")", "\n", "\n", "x_stem_0", "=", "self", ".", "cell_stem_0", "(", "x_conv0", ")", "\n", "x_stem_1", "=", "self", ".", "cell_stem_1", "(", "x_conv0", ",", "x_stem_0", ")", "\n", "\n", "x_cell_0", "=", "self", ".", "cell_0", "(", "x_stem_1", ",", "x_stem_0", ")", "\n", "x_cell_1", "=", "self", ".", "cell_1", "(", "x_cell_0", ",", "x_stem_1", ")", "\n", "x_cell_2", "=", "self", ".", "cell_2", "(", "x_cell_1", ",", "x_cell_0", ")", "\n", "x_cell_3", "=", "self", ".", "cell_3", "(", "x_cell_2", ",", "x_cell_1", ")", "\n", "x_cell_4", "=", "self", ".", "cell_4", "(", "x_cell_3", ",", "x_cell_2", ")", "\n", "x_cell_5", "=", "self", ".", "cell_5", "(", "x_cell_4", ",", "x_cell_3", ")", "\n", "\n", "x_reduction_cell_0", "=", "self", ".", "reduction_cell_0", "(", "x_cell_5", ",", "x_cell_4", ")", "\n", "x_cell_6", "=", "self", ".", "cell_6", "(", "x_reduction_cell_0", ",", "x_cell_4", ")", "\n", "x_cell_7", "=", "self", ".", "cell_7", "(", "x_cell_6", ",", "x_reduction_cell_0", ")", "\n", "x_cell_8", "=", "self", ".", "cell_8", "(", "x_cell_7", ",", "x_cell_6", ")", "\n", "x_cell_9", "=", "self", ".", "cell_9", "(", "x_cell_8", ",", "x_cell_7", ")", "\n", "x_cell_10", "=", "self", ".", "cell_10", "(", "x_cell_9", ",", "x_cell_8", ")", "\n", "x_cell_11", "=", "self", ".", "cell_11", "(", "x_cell_10", ",", "x_cell_9", ")", "\n", "\n", "x_reduction_cell_1", "=", "self", ".", "reduction_cell_1", "(", "x_cell_11", ",", "x_cell_10", ")", "\n", "x_cell_12", "=", "self", ".", "cell_12", "(", "x_reduction_cell_1", ",", "x_cell_10", ")", "\n", "x_cell_13", "=", "self", ".", "cell_13", "(", "x_cell_12", ",", "x_reduction_cell_1", ")", "\n", "x_cell_14", "=", "self", ".", "cell_14", "(", "x_cell_13", ",", "x_cell_12", ")", "\n", "x_cell_15", "=", "self", ".", "cell_15", "(", "x_cell_14", ",", "x_cell_13", ")", "\n", "x_cell_16", "=", "self", ".", "cell_16", "(", "x_cell_15", ",", "x_cell_14", ")", "\n", "x_cell_17", "=", "self", ".", "cell_17", "(", "x_cell_16", ",", "x_cell_15", ")", "\n", "x", "=", "self", ".", "act", "(", "x_cell_17", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.NASNetALarge.forward_head": [[563, 569], ["nasnet.NASNetALarge.global_pool", "nasnet.NASNetALarge.last_linear", "torch.dropout", "torch.dropout", "torch.dropout"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ">", "0", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "x", ",", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "x", "=", "self", ".", "last_linear", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.NASNetALarge.forward": [[570, 574], ["nasnet.NASNetALarge.forward_features", "nasnet.NASNetALarge.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet._create_nasnet": [[576, 581], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_nasnet", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "\n", "NASNetALarge", ",", "variant", ",", "pretrained", ",", "\n", "feature_cfg", "=", "dict", "(", "feature_cls", "=", "'hook'", ",", "no_rewrite", "=", "True", ")", ",", "# not possible to re-write this model", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet.nasnetalarge": [[583, 589], ["dict", "nasnet._create_nasnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nasnet._create_nasnet"], ["", "@", "register_model", "\n", "def", "nasnetalarge", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"NASNet-A large model architecture.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "pad_type", "=", "'same'", ",", "**", "kwargs", ")", "\n", "return", "_create_nasnet", "(", "'nasnetalarge'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.BasicBlock.__init__": [[318, 350], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "act_layer", "resnet.create_aa", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "layers.create_attn", "act_layer", "drop_block", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.create_aa", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.create_attn"], ["def", "__init__", "(", "\n", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "cardinality", "=", "1", ",", "base_width", "=", "64", ",", "\n", "reduce_first", "=", "1", ",", "dilation", "=", "1", ",", "first_dilation", "=", "None", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "\n", "attn_layer", "=", "None", ",", "aa_layer", "=", "None", ",", "drop_block", "=", "None", ",", "drop_path", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "cardinality", "==", "1", ",", "'BasicBlock only supports cardinality of 1'", "\n", "assert", "base_width", "==", "64", ",", "'BasicBlock does not support changing base width'", "\n", "first_planes", "=", "planes", "//", "reduce_first", "\n", "outplanes", "=", "planes", "*", "self", ".", "expansion", "\n", "first_dilation", "=", "first_dilation", "or", "dilation", "\n", "use_aa", "=", "aa_layer", "is", "not", "None", "and", "(", "stride", "==", "2", "or", "first_dilation", "!=", "dilation", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "inplanes", ",", "first_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", "if", "use_aa", "else", "stride", ",", "padding", "=", "first_dilation", ",", "\n", "dilation", "=", "first_dilation", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "first_planes", ")", "\n", "self", ".", "drop_block", "=", "drop_block", "(", ")", "if", "drop_block", "is", "not", "None", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "act1", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "aa", "=", "create_aa", "(", "aa_layer", ",", "channels", "=", "first_planes", ",", "stride", "=", "stride", ",", "enable", "=", "use_aa", ")", "\n", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "\n", "first_planes", ",", "outplanes", ",", "kernel_size", "=", "3", ",", "padding", "=", "dilation", ",", "dilation", "=", "dilation", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "outplanes", ")", "\n", "\n", "self", ".", "se", "=", "create_attn", "(", "attn_layer", ",", "outplanes", ")", "\n", "\n", "self", ".", "act2", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "drop_path", "=", "drop_path", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.BasicBlock.zero_init_last": [[351, 353], ["torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["None"], ["", "def", "zero_init_last", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "bn2", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.BasicBlock.forward": [[354, 378], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.bn1", "resnet.BasicBlock.drop_block", "resnet.BasicBlock.act1", "resnet.BasicBlock.aa", "resnet.BasicBlock.conv2", "resnet.BasicBlock.bn2", "resnet.BasicBlock.act2", "resnet.BasicBlock.se", "resnet.BasicBlock.drop_path", "resnet.BasicBlock.downsample"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_block", "(", "x", ")", "\n", "x", "=", "self", ".", "act1", "(", "x", ")", "\n", "x", "=", "self", ".", "aa", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "bn2", "(", "x", ")", "\n", "\n", "if", "self", ".", "se", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "se", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "drop_path", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "drop_path", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "downsample", "(", "shortcut", ")", "\n", "", "x", "+=", "shortcut", "\n", "x", "=", "self", ".", "act2", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.Bottleneck.__init__": [[383, 417], ["torch.Module.__init__", "int", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "act_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "act_layer", "resnet.create_aa", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "layers.create_attn", "act_layer", "drop_block", "torch.Identity", "torch.Identity", "torch.Identity", "math.floor"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.create_aa", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.create_attn"], ["def", "__init__", "(", "\n", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "cardinality", "=", "1", ",", "base_width", "=", "64", ",", "\n", "reduce_first", "=", "1", ",", "dilation", "=", "1", ",", "first_dilation", "=", "None", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "\n", "attn_layer", "=", "None", ",", "aa_layer", "=", "None", ",", "drop_block", "=", "None", ",", "drop_path", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "width", "=", "int", "(", "math", ".", "floor", "(", "planes", "*", "(", "base_width", "/", "64", ")", ")", "*", "cardinality", ")", "\n", "first_planes", "=", "width", "//", "reduce_first", "\n", "outplanes", "=", "planes", "*", "self", ".", "expansion", "\n", "first_dilation", "=", "first_dilation", "or", "dilation", "\n", "use_aa", "=", "aa_layer", "is", "not", "None", "and", "(", "stride", "==", "2", "or", "first_dilation", "!=", "dilation", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "first_planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "first_planes", ")", "\n", "self", ".", "act1", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "\n", "first_planes", ",", "width", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", "if", "use_aa", "else", "stride", ",", "\n", "padding", "=", "first_dilation", ",", "dilation", "=", "first_dilation", ",", "groups", "=", "cardinality", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "width", ")", "\n", "self", ".", "drop_block", "=", "drop_block", "(", ")", "if", "drop_block", "is", "not", "None", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "act2", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "aa", "=", "create_aa", "(", "aa_layer", ",", "channels", "=", "width", ",", "stride", "=", "stride", ",", "enable", "=", "use_aa", ")", "\n", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "width", ",", "outplanes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "norm_layer", "(", "outplanes", ")", "\n", "\n", "self", ".", "se", "=", "create_attn", "(", "attn_layer", ",", "outplanes", ")", "\n", "\n", "self", ".", "act3", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "drop_path", "=", "drop_path", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.Bottleneck.zero_init_last": [[418, 420], ["torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["None"], ["", "def", "zero_init_last", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "bn3", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.Bottleneck.forward": [[421, 449], ["resnet.Bottleneck.conv1", "resnet.Bottleneck.bn1", "resnet.Bottleneck.act1", "resnet.Bottleneck.conv2", "resnet.Bottleneck.bn2", "resnet.Bottleneck.drop_block", "resnet.Bottleneck.act2", "resnet.Bottleneck.aa", "resnet.Bottleneck.conv3", "resnet.Bottleneck.bn3", "resnet.Bottleneck.act3", "resnet.Bottleneck.se", "resnet.Bottleneck.drop_path", "resnet.Bottleneck.downsample"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "act1", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "bn2", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_block", "(", "x", ")", "\n", "x", "=", "self", ".", "act2", "(", "x", ")", "\n", "x", "=", "self", ".", "aa", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv3", "(", "x", ")", "\n", "x", "=", "self", ".", "bn3", "(", "x", ")", "\n", "\n", "if", "self", ".", "se", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "se", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "drop_path", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "drop_path", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "downsample", "(", "shortcut", ")", "\n", "", "x", "+=", "shortcut", "\n", "x", "=", "self", ".", "act3", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ResNet.__init__": [[590, 658], ["torch.Module.__init__", "norm_layer", "act_layer", "resnet.make_blocks", "resnet.ResNet.feature_info.extend", "layers.create_classifier", "resnet.ResNet.init_weights", "dict", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "dict", "torch.Sequential", "torch.Sequential", "torch.Sequential", "resnet.ResNet.add_module", "issubclass", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "filter", "aa_layer", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "act_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "act_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "act_layer", "resnet.create_aa", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "aa_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.make_blocks", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.GluMlp.init_weights", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.create_aa"], ["def", "__init__", "(", "\n", "self", ",", "block", ",", "layers", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "output_stride", "=", "32", ",", "global_pool", "=", "'avg'", ",", "\n", "cardinality", "=", "1", ",", "base_width", "=", "64", ",", "stem_width", "=", "64", ",", "stem_type", "=", "''", ",", "replace_stem_pool", "=", "False", ",", "block_reduce_first", "=", "1", ",", "\n", "down_kernel_size", "=", "1", ",", "avg_down", "=", "False", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "aa_layer", "=", "None", ",", "\n", "drop_rate", "=", "0.0", ",", "drop_path_rate", "=", "0.", ",", "drop_block_rate", "=", "0.", ",", "zero_init_last", "=", "True", ",", "block_args", "=", "None", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "block_args", "=", "block_args", "or", "dict", "(", ")", "\n", "assert", "output_stride", "in", "(", "8", ",", "16", ",", "32", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "# Stem", "\n", "deep_stem", "=", "'deep'", "in", "stem_type", "\n", "inplanes", "=", "stem_width", "*", "2", "if", "deep_stem", "else", "64", "\n", "if", "deep_stem", ":", "\n", "            ", "stem_chs", "=", "(", "stem_width", ",", "stem_width", ")", "\n", "if", "'tiered'", "in", "stem_type", ":", "\n", "                ", "stem_chs", "=", "(", "3", "*", "(", "stem_width", "//", "4", ")", ",", "stem_width", ")", "\n", "", "self", ".", "conv1", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "nn", ".", "Conv2d", "(", "in_chans", ",", "stem_chs", "[", "0", "]", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "norm_layer", "(", "stem_chs", "[", "0", "]", ")", ",", "\n", "act_layer", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "stem_chs", "[", "0", "]", ",", "stem_chs", "[", "1", "]", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "norm_layer", "(", "stem_chs", "[", "1", "]", ")", ",", "\n", "act_layer", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "stem_chs", "[", "1", "]", ",", "inplanes", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_chans", ",", "inplanes", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "bias", "=", "False", ")", "\n", "", "self", ".", "bn1", "=", "norm_layer", "(", "inplanes", ")", "\n", "self", ".", "act1", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "feature_info", "=", "[", "dict", "(", "num_chs", "=", "inplanes", ",", "reduction", "=", "2", ",", "module", "=", "'act1'", ")", "]", "\n", "\n", "# Stem pooling. The name 'maxpool' remains for weight compatibility.", "\n", "if", "replace_stem_pool", ":", "\n", "            ", "self", ".", "maxpool", "=", "nn", ".", "Sequential", "(", "*", "filter", "(", "None", ",", "[", "\n", "nn", ".", "Conv2d", "(", "inplanes", ",", "inplanes", ",", "3", ",", "stride", "=", "1", "if", "aa_layer", "else", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "create_aa", "(", "aa_layer", ",", "channels", "=", "inplanes", ",", "stride", "=", "2", ")", "if", "aa_layer", "is", "not", "None", "else", "None", ",", "\n", "norm_layer", "(", "inplanes", ")", ",", "\n", "act_layer", "(", "inplace", "=", "True", ")", "\n", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "aa_layer", "is", "not", "None", ":", "\n", "                ", "if", "issubclass", "(", "aa_layer", ",", "nn", ".", "AvgPool2d", ")", ":", "\n", "                    ", "self", ".", "maxpool", "=", "aa_layer", "(", "2", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "maxpool", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "aa_layer", "(", "channels", "=", "inplanes", ",", "stride", "=", "2", ")", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "\n", "# Feature Blocks", "\n", "", "", "channels", "=", "[", "64", ",", "128", ",", "256", ",", "512", "]", "\n", "stage_modules", ",", "stage_feature_info", "=", "make_blocks", "(", "\n", "block", ",", "channels", ",", "layers", ",", "inplanes", ",", "cardinality", "=", "cardinality", ",", "base_width", "=", "base_width", ",", "\n", "output_stride", "=", "output_stride", ",", "reduce_first", "=", "block_reduce_first", ",", "avg_down", "=", "avg_down", ",", "\n", "down_kernel_size", "=", "down_kernel_size", ",", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ",", "aa_layer", "=", "aa_layer", ",", "\n", "drop_block_rate", "=", "drop_block_rate", ",", "drop_path_rate", "=", "drop_path_rate", ",", "**", "block_args", ")", "\n", "for", "stage", "in", "stage_modules", ":", "\n", "            ", "self", ".", "add_module", "(", "*", "stage", ")", "# layer1, layer2, etc", "\n", "", "self", ".", "feature_info", ".", "extend", "(", "stage_feature_info", ")", "\n", "\n", "# Head (Pooling and Classifier)", "\n", "self", ".", "num_features", "=", "512", "*", "block", ".", "expansion", "\n", "self", ".", "global_pool", ",", "self", ".", "fc", "=", "create_classifier", "(", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n", "self", ".", "init_weights", "(", "zero_init_last", "=", "zero_init_last", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ResNet.init_weights": [[659, 671], ["resnet.ResNet.named_modules", "isinstance", "resnet.ResNet.modules", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "hasattr", "torch.init.ones_", "torch.init.ones_", "torch.init.ones_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_", "m.zero_init_last"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet.SelectiveKernelBottleneck.zero_init_last"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "init_weights", "(", "self", ",", "zero_init_last", "=", "True", ")", ":", "\n", "        ", "for", "n", ",", "m", "in", "self", ".", "named_modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "ones_", "(", "m", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "", "", "if", "zero_init_last", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "hasattr", "(", "m", ",", "'zero_init_last'", ")", ":", "\n", "                    ", "m", ".", "zero_init_last", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ResNet.group_matcher": [[672, 676], ["dict"], "methods", ["None"], ["", "", "", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "stem", "=", "r'^conv1|bn1|maxpool'", ",", "blocks", "=", "r'^layer(\\d+)'", "if", "coarse", "else", "r'^layer(\\d+)\\.(\\d+)'", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ResNet.set_grad_checkpointing": [[677, 680], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ResNet.get_classifier": [[681, 684], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ",", "name_only", "=", "False", ")", ":", "\n", "        ", "return", "'fc'", "if", "name_only", "else", "self", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ResNet.reset_classifier": [[685, 688], ["layers.create_classifier"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "fc", "=", "create_classifier", "(", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ResNet.forward_features": [[689, 703], ["resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.act1", "resnet.ResNet.maxpool", "helpers.checkpoint_seq", "resnet.ResNet.layer1", "resnet.ResNet.layer2", "resnet.ResNet.layer3", "resnet.ResNet.layer4", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "act1", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "[", "self", ".", "layer1", ",", "self", ".", "layer2", ",", "self", ".", "layer3", ",", "self", ".", "layer4", "]", ",", "x", ",", "flatten", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ResNet.forward_head": [[704, 709], ["resnet.ResNet.global_pool", "torch.dropout", "torch.dropout", "torch.dropout", "resnet.ResNet.fc", "float"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "float", "(", "self", ".", "drop_rate", ")", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "fc", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ResNet.forward": [[710, 714], ["resnet.ResNet.forward_features", "resnet.ResNet.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet._cfg": [[25, 33], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bilinear'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'conv1'", ",", "'classifier'", ":", "'fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.get_padding": [[304, 307], ["None"], "function", ["None"], ["def", "get_padding", "(", "kernel_size", ",", "stride", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "padding", "=", "(", "(", "stride", "-", "1", ")", "+", "dilation", "*", "(", "kernel_size", "-", "1", ")", ")", "//", "2", "\n", "return", "padding", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.create_aa": [[309, 313], ["torch.Identity", "issubclass", "aa_layer", "aa_layer"], "function", ["None"], ["", "def", "create_aa", "(", "aa_layer", ",", "channels", ",", "stride", "=", "2", ",", "enable", "=", "True", ")", ":", "\n", "    ", "if", "not", "aa_layer", "or", "not", "enable", ":", "\n", "        ", "return", "nn", ".", "Identity", "(", ")", "\n", "", "return", "aa_layer", "(", "stride", ")", "if", "issubclass", "(", "aa_layer", ",", "nn", ".", "AvgPool2d", ")", "else", "aa_layer", "(", "channels", "=", "channels", ",", "stride", "=", "stride", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.downsample_conv": [[451, 462], ["resnet.get_padding", "torch.Sequential", "torch.Conv2d", "norm_layer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_padding"], ["", "", "def", "downsample_conv", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "first_dilation", "=", "None", ",", "norm_layer", "=", "None", ")", ":", "\n", "    ", "norm_layer", "=", "norm_layer", "or", "nn", ".", "BatchNorm2d", "\n", "kernel_size", "=", "1", "if", "stride", "==", "1", "and", "dilation", "==", "1", "else", "kernel_size", "\n", "first_dilation", "=", "(", "first_dilation", "or", "dilation", ")", "if", "kernel_size", ">", "1", "else", "1", "\n", "p", "=", "get_padding", "(", "kernel_size", ",", "stride", ",", "first_dilation", ")", "\n", "\n", "return", "nn", ".", "Sequential", "(", "*", "[", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "p", ",", "dilation", "=", "first_dilation", ",", "bias", "=", "False", ")", ",", "\n", "norm_layer", "(", "out_channels", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.downsample_avg": [[465, 479], ["torch.Sequential", "torch.Identity", "avg_pool_fn", "torch.Conv2d", "norm_layer"], "function", ["None"], ["", "def", "downsample_avg", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "first_dilation", "=", "None", ",", "norm_layer", "=", "None", ")", ":", "\n", "    ", "norm_layer", "=", "norm_layer", "or", "nn", ".", "BatchNorm2d", "\n", "avg_stride", "=", "stride", "if", "dilation", "==", "1", "else", "1", "\n", "if", "stride", "==", "1", "and", "dilation", "==", "1", ":", "\n", "        ", "pool", "=", "nn", ".", "Identity", "(", ")", "\n", "", "else", ":", "\n", "        ", "avg_pool_fn", "=", "AvgPool2dSame", "if", "avg_stride", "==", "1", "and", "dilation", ">", "1", "else", "nn", ".", "AvgPool2d", "\n", "pool", "=", "avg_pool_fn", "(", "2", ",", "avg_stride", ",", "ceil_mode", "=", "True", ",", "count_include_pad", "=", "False", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "[", "\n", "pool", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ",", "\n", "norm_layer", "(", "out_channels", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.drop_blocks": [[482, 487], ["functools.partial", "functools.partial"], "function", ["None"], ["", "def", "drop_blocks", "(", "drop_prob", "=", "0.", ")", ":", "\n", "    ", "return", "[", "\n", "None", ",", "None", ",", "\n", "partial", "(", "DropBlock2d", ",", "drop_prob", "=", "drop_prob", ",", "block_size", "=", "5", ",", "gamma_scale", "=", "0.25", ")", "if", "drop_prob", "else", "None", ",", "\n", "partial", "(", "DropBlock2d", ",", "drop_prob", "=", "drop_prob", ",", "block_size", "=", "3", ",", "gamma_scale", "=", "1.00", ")", "if", "drop_prob", "else", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.make_blocks": [[489, 531], ["sum", "enumerate", "zip", "dict", "range", "stages.append", "feature_info.append", "resnet.drop_blocks", "dict", "blocks.append", "dict", "resnet.downsample_avg", "resnet.downsample_conv", "block_fn", "torch.Sequential", "kwargs.get", "layers.DropPath"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.drop_blocks", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.downsample_avg", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.downsample_conv", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["", "def", "make_blocks", "(", "\n", "block_fn", ",", "channels", ",", "block_repeats", ",", "inplanes", ",", "reduce_first", "=", "1", ",", "output_stride", "=", "32", ",", "\n", "down_kernel_size", "=", "1", ",", "avg_down", "=", "False", ",", "drop_block_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "**", "kwargs", ")", ":", "\n", "    ", "stages", "=", "[", "]", "\n", "feature_info", "=", "[", "]", "\n", "net_num_blocks", "=", "sum", "(", "block_repeats", ")", "\n", "net_block_idx", "=", "0", "\n", "net_stride", "=", "4", "\n", "dilation", "=", "prev_dilation", "=", "1", "\n", "for", "stage_idx", ",", "(", "planes", ",", "num_blocks", ",", "db", ")", "in", "enumerate", "(", "zip", "(", "channels", ",", "block_repeats", ",", "drop_blocks", "(", "drop_block_rate", ")", ")", ")", ":", "\n", "        ", "stage_name", "=", "f'layer{stage_idx + 1}'", "# never liked this name, but weight compat requires it", "\n", "stride", "=", "1", "if", "stage_idx", "==", "0", "else", "2", "\n", "if", "net_stride", ">=", "output_stride", ":", "\n", "            ", "dilation", "*=", "stride", "\n", "stride", "=", "1", "\n", "", "else", ":", "\n", "            ", "net_stride", "*=", "stride", "\n", "\n", "", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "inplanes", "!=", "planes", "*", "block_fn", ".", "expansion", ":", "\n", "            ", "down_kwargs", "=", "dict", "(", "\n", "in_channels", "=", "inplanes", ",", "out_channels", "=", "planes", "*", "block_fn", ".", "expansion", ",", "kernel_size", "=", "down_kernel_size", ",", "\n", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "first_dilation", "=", "prev_dilation", ",", "norm_layer", "=", "kwargs", ".", "get", "(", "'norm_layer'", ")", ")", "\n", "downsample", "=", "downsample_avg", "(", "**", "down_kwargs", ")", "if", "avg_down", "else", "downsample_conv", "(", "**", "down_kwargs", ")", "\n", "\n", "", "block_kwargs", "=", "dict", "(", "reduce_first", "=", "reduce_first", ",", "dilation", "=", "dilation", ",", "drop_block", "=", "db", ",", "**", "kwargs", ")", "\n", "blocks", "=", "[", "]", "\n", "for", "block_idx", "in", "range", "(", "num_blocks", ")", ":", "\n", "            ", "downsample", "=", "downsample", "if", "block_idx", "==", "0", "else", "None", "\n", "stride", "=", "stride", "if", "block_idx", "==", "0", "else", "1", "\n", "block_dpr", "=", "drop_path_rate", "*", "net_block_idx", "/", "(", "net_num_blocks", "-", "1", ")", "# stochastic depth linear decay rule", "\n", "blocks", ".", "append", "(", "block_fn", "(", "\n", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ",", "first_dilation", "=", "prev_dilation", ",", "\n", "drop_path", "=", "DropPath", "(", "block_dpr", ")", "if", "block_dpr", ">", "0.", "else", "None", ",", "**", "block_kwargs", ")", ")", "\n", "prev_dilation", "=", "dilation", "\n", "inplanes", "=", "planes", "*", "block_fn", ".", "expansion", "\n", "net_block_idx", "+=", "1", "\n", "\n", "", "stages", ".", "append", "(", "(", "stage_name", ",", "nn", ".", "Sequential", "(", "*", "blocks", ")", ")", ")", "\n", "feature_info", ".", "append", "(", "dict", "(", "num_chs", "=", "inplanes", ",", "reduction", "=", "net_stride", ",", "module", "=", "stage_name", ")", ")", "\n", "\n", "", "return", "stages", ",", "feature_info", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet._create_resnet": [[716, 718], ["helpers.build_model_with_cfg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_resnet", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "ResNet", ",", "variant", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet18": [[720, 726], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet18", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "BasicBlock", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet18'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet18d": [[728, 735], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet18d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18-D model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "BasicBlock", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet18d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet34": [[737, 743], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet34", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-34 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "BasicBlock", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet34'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet34d": [[745, 752], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet34d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-34-D model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "BasicBlock", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet34d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet26": [[754, 760], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet26", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-26 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet26'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet26t": [[762, 769], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet26t", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-26-T model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep_tiered'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet26t'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet26d": [[771, 777], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet26d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-26-D model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet26d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet50": [[779, 785], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet50'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet50d": [[787, 794], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet50d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50-D model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet50d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet50t": [[796, 803], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet50t", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50-T model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep_tiered'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet50t'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet101": [[805, 811], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet101", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet101'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet101d": [[813, 819], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet101d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101-D model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet101d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet152": [[821, 827], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet152", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-152 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet152'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet152d": [[829, 836], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet152d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-152-D model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet152d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet200": [[838, 844], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet200", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-200 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "24", ",", "36", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet200'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet200d": [[846, 853], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet200d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-200-D model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "24", ",", "36", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet200d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.tv_resnet34": [[855, 861], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "tv_resnet34", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-34 model with original Torchvision weights.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "BasicBlock", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'tv_resnet34'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.tv_resnet50": [[863, 869], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "tv_resnet50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model with original Torchvision weights.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'tv_resnet50'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.tv_resnet101": [[871, 877], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "tv_resnet101", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model w/ Torchvision pretrained weights.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'tv_resnet101'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.tv_resnet152": [[879, 885], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "tv_resnet152", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-152 model w/ Torchvision pretrained weights.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'tv_resnet152'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.wide_resnet50_2": [[887, 897], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "wide_resnet50_2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a Wide ResNet-50-2 model.\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1\n    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "base_width", "=", "128", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'wide_resnet50_2'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.wide_resnet101_2": [[899, 908], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "wide_resnet101_2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a Wide ResNet-101-2 model.\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1\n    convolutions is the same.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "base_width", "=", "128", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'wide_resnet101_2'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnet50_gn": [[910, 916], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnet50_gn", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model w/ GroupNorm\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnet50_gn'", ",", "pretrained", ",", "norm_layer", "=", "GroupNorm", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnext50_32x4d": [[918, 924], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnext50_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt50-32x4d model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnext50_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnext50d_32x4d": [[926, 934], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnext50d_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt50d-32x4d model. ResNext50 w/ deep stem & avg pool downsample\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "\n", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnext50d_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnext101_32x4d": [[936, 942], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnext101_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt-101 32x4d model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnext101_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnext101_32x8d": [[944, 950], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnext101_32x8d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt-101 32x8d model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "8", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnext101_32x8d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnext101_64x4d": [[952, 958], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnext101_64x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt101-64x4d model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "64", ",", "base_width", "=", "4", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnext101_64x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.tv_resnext50_32x4d": [[960, 966], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "tv_resnext50_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt50-32x4d model with original Torchvision weights.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'tv_resnext50_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ig_resnext101_32x8d": [[968, 977], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ig_resnext101_32x8d", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt-101 32x8 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Weights from https://pytorch.org/hub/facebookresearch_WSL-Images_resnext/\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "8", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ig_resnext101_32x8d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ig_resnext101_32x16d": [[979, 988], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ig_resnext101_32x16d", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt-101 32x16 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Weights from https://pytorch.org/hub/facebookresearch_WSL-Images_resnext/\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "16", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ig_resnext101_32x16d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ig_resnext101_32x32d": [[990, 999], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ig_resnext101_32x32d", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt-101 32x32 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Weights from https://pytorch.org/hub/facebookresearch_WSL-Images_resnext/\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "32", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ig_resnext101_32x32d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ig_resnext101_32x48d": [[1001, 1010], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ig_resnext101_32x48d", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt-101 32x48 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Weights from https://pytorch.org/hub/facebookresearch_WSL-Images_resnext/\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "48", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ig_resnext101_32x48d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ssl_resnet18": [[1012, 1020], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ssl_resnet18", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a semi-supervised ResNet-18 model pre-trained on YFCC100M dataset and finetuned on ImageNet\n    `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n    Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "BasicBlock", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ssl_resnet18'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ssl_resnet50": [[1022, 1030], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ssl_resnet50", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a semi-supervised ResNet-50 model pre-trained on YFCC100M dataset and finetuned on ImageNet\n    `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n    Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ssl_resnet50'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ssl_resnext50_32x4d": [[1032, 1040], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ssl_resnext50_32x4d", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a semi-supervised ResNeXt-50 32x4 model pre-trained on YFCC100M dataset and finetuned on ImageNet\n    `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n    Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ssl_resnext50_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ssl_resnext101_32x4d": [[1042, 1050], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ssl_resnext101_32x4d", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a semi-supervised ResNeXt-101 32x4 model pre-trained on YFCC100M dataset and finetuned on ImageNet\n    `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n    Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ssl_resnext101_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ssl_resnext101_32x8d": [[1052, 1060], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ssl_resnext101_32x8d", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a semi-supervised ResNeXt-101 32x8 model pre-trained on YFCC100M dataset and finetuned on ImageNet\n    `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n    Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "8", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ssl_resnext101_32x8d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ssl_resnext101_32x16d": [[1062, 1070], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ssl_resnext101_32x16d", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a semi-supervised ResNeXt-101 32x16 model pre-trained on YFCC100M dataset and finetuned on ImageNet\n    `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n    Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "16", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ssl_resnext101_32x16d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.swsl_resnet18": [[1072, 1081], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "swsl_resnet18", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a semi-weakly supervised Resnet-18 model pre-trained on 1B weakly supervised\n       image dataset and finetuned on ImageNet.\n       `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n       Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "BasicBlock", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'swsl_resnet18'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.swsl_resnet50": [[1083, 1092], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "swsl_resnet50", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a semi-weakly supervised ResNet-50 model pre-trained on 1B weakly supervised\n       image dataset and finetuned on ImageNet.\n       `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n       Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'swsl_resnet50'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.swsl_resnext50_32x4d": [[1094, 1103], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "swsl_resnext50_32x4d", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a semi-weakly supervised ResNeXt-50 32x4 model pre-trained on 1B weakly supervised\n       image dataset and finetuned on ImageNet.\n       `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n       Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'swsl_resnext50_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.swsl_resnext101_32x4d": [[1105, 1114], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "swsl_resnext101_32x4d", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a semi-weakly supervised ResNeXt-101 32x4 model pre-trained on 1B weakly supervised\n       image dataset and finetuned on ImageNet.\n       `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n       Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'swsl_resnext101_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.swsl_resnext101_32x8d": [[1116, 1125], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "swsl_resnext101_32x8d", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a semi-weakly supervised ResNeXt-101 32x8 model pre-trained on 1B weakly supervised\n       image dataset and finetuned on ImageNet.\n       `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n       Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "8", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'swsl_resnext101_32x8d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.swsl_resnext101_32x16d": [[1127, 1136], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "swsl_resnext101_32x16d", "(", "pretrained", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a semi-weakly supervised ResNeXt-101 32x16 model pre-trained on 1B weakly supervised\n       image dataset and finetuned on ImageNet.\n       `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n       Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "16", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'swsl_resnext101_32x16d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ecaresnet26t": [[1138, 1148], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ecaresnet26t", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs an ECA-ResNeXt-26-T model.\n    This is technically a 28 layer ResNet, like a 'D' bag-of-tricks model but with tiered 24, 32, 64 channels\n    in the deep stem and ECA attn.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "stem_width", "=", "32", ",", "\n", "stem_type", "=", "'deep_tiered'", ",", "avg_down", "=", "True", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "'eca'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ecaresnet26t'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ecaresnet50d": [[1150, 1158], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ecaresnet50d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50-D model with eca.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "'eca'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ecaresnet50d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnetrs50": [[1160, 1171], ["functools.partial", "dict", "resnet._create_resnet", "layers.get_attn", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.get_attn"], ["", "@", "register_model", "\n", "def", "resnetrs50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-RS-50 model.\n    Paper: Revisiting ResNets - https://arxiv.org/abs/2103.07579\n    Pretrained weights from https://github.com/tensorflow/tpu/tree/bee9c4f6/models/official/resnet/resnet_rs\n    \"\"\"", "\n", "attn_layer", "=", "partial", "(", "get_attn", "(", "'se'", ")", ",", "rd_ratio", "=", "0.25", ")", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "replace_stem_pool", "=", "True", ",", "\n", "avg_down", "=", "True", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "attn_layer", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnetrs50'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnetrs101": [[1173, 1184], ["functools.partial", "dict", "resnet._create_resnet", "layers.get_attn", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.get_attn"], ["", "@", "register_model", "\n", "def", "resnetrs101", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-RS-101 model.\n    Paper: Revisiting ResNets - https://arxiv.org/abs/2103.07579\n    Pretrained weights from https://github.com/tensorflow/tpu/tree/bee9c4f6/models/official/resnet/resnet_rs\n    \"\"\"", "\n", "attn_layer", "=", "partial", "(", "get_attn", "(", "'se'", ")", ",", "rd_ratio", "=", "0.25", ")", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "replace_stem_pool", "=", "True", ",", "\n", "avg_down", "=", "True", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "attn_layer", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnetrs101'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnetrs152": [[1186, 1197], ["functools.partial", "dict", "resnet._create_resnet", "layers.get_attn", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.get_attn"], ["", "@", "register_model", "\n", "def", "resnetrs152", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-RS-152 model.\n    Paper: Revisiting ResNets - https://arxiv.org/abs/2103.07579\n    Pretrained weights from https://github.com/tensorflow/tpu/tree/bee9c4f6/models/official/resnet/resnet_rs\n    \"\"\"", "\n", "attn_layer", "=", "partial", "(", "get_attn", "(", "'se'", ")", ",", "rd_ratio", "=", "0.25", ")", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "replace_stem_pool", "=", "True", ",", "\n", "avg_down", "=", "True", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "attn_layer", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnetrs152'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnetrs200": [[1199, 1210], ["functools.partial", "dict", "resnet._create_resnet", "layers.get_attn", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.get_attn"], ["", "@", "register_model", "\n", "def", "resnetrs200", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-RS-200 model.\n    Paper: Revisiting ResNets - https://arxiv.org/abs/2103.07579\n    Pretrained weights from https://github.com/tensorflow/tpu/tree/bee9c4f6/models/official/resnet/resnet_rs\n    \"\"\"", "\n", "attn_layer", "=", "partial", "(", "get_attn", "(", "'se'", ")", ",", "rd_ratio", "=", "0.25", ")", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "24", ",", "36", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "replace_stem_pool", "=", "True", ",", "\n", "avg_down", "=", "True", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "attn_layer", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnetrs200'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnetrs270": [[1212, 1223], ["functools.partial", "dict", "resnet._create_resnet", "layers.get_attn", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.get_attn"], ["", "@", "register_model", "\n", "def", "resnetrs270", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-RS-270 model.\n    Paper: Revisiting ResNets - https://arxiv.org/abs/2103.07579\n    Pretrained weights from https://github.com/tensorflow/tpu/tree/bee9c4f6/models/official/resnet/resnet_rs\n    \"\"\"", "\n", "attn_layer", "=", "partial", "(", "get_attn", "(", "'se'", ")", ",", "rd_ratio", "=", "0.25", ")", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "4", ",", "29", ",", "53", ",", "4", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "replace_stem_pool", "=", "True", ",", "\n", "avg_down", "=", "True", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "attn_layer", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnetrs270'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnetrs350": [[1226, 1237], ["functools.partial", "dict", "resnet._create_resnet", "layers.get_attn", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.get_attn"], ["", "@", "register_model", "\n", "def", "resnetrs350", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-RS-350 model.\n    Paper: Revisiting ResNets - https://arxiv.org/abs/2103.07579\n    Pretrained weights from https://github.com/tensorflow/tpu/tree/bee9c4f6/models/official/resnet/resnet_rs\n    \"\"\"", "\n", "attn_layer", "=", "partial", "(", "get_attn", "(", "'se'", ")", ",", "rd_ratio", "=", "0.25", ")", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "4", ",", "36", ",", "72", ",", "4", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "replace_stem_pool", "=", "True", ",", "\n", "avg_down", "=", "True", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "attn_layer", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnetrs350'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnetrs420": [[1239, 1250], ["functools.partial", "dict", "resnet._create_resnet", "layers.get_attn", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.get_attn"], ["", "@", "register_model", "\n", "def", "resnetrs420", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-RS-420 model\n    Paper: Revisiting ResNets - https://arxiv.org/abs/2103.07579\n    Pretrained weights from https://github.com/tensorflow/tpu/tree/bee9c4f6/models/official/resnet/resnet_rs\n    \"\"\"", "\n", "attn_layer", "=", "partial", "(", "get_attn", "(", "'se'", ")", ",", "rd_ratio", "=", "0.25", ")", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "4", ",", "44", ",", "87", ",", "4", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "replace_stem_pool", "=", "True", ",", "\n", "avg_down", "=", "True", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "attn_layer", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnetrs420'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ecaresnet50d_pruned": [[1252, 1261], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ecaresnet50d_pruned", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50-D model pruned with eca.\n        The pruning has been obtained using https://arxiv.org/pdf/2002.08258.pdf\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "'eca'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ecaresnet50d_pruned'", ",", "pretrained", ",", "pruned", "=", "True", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ecaresnet50t": [[1263, 1272], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ecaresnet50t", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs an ECA-ResNet-50-T model.\n    Like a 'D' bag-of-tricks model but with tiered 24, 32, 64 channels in the deep stem and ECA attn.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "stem_width", "=", "32", ",", "\n", "stem_type", "=", "'deep_tiered'", ",", "avg_down", "=", "True", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "'eca'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ecaresnet50t'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ecaresnetlight": [[1274, 1282], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ecaresnetlight", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50-D light model with eca.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "1", ",", "1", ",", "11", ",", "3", "]", ",", "stem_width", "=", "32", ",", "avg_down", "=", "True", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "'eca'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ecaresnetlight'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ecaresnet101d": [[1284, 1292], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ecaresnet101d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101-D model with eca.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "'eca'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ecaresnet101d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ecaresnet101d_pruned": [[1294, 1303], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ecaresnet101d_pruned", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101-D model pruned with eca.\n       The pruning has been obtained using https://arxiv.org/pdf/2002.08258.pdf\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "'eca'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ecaresnet101d_pruned'", ",", "pretrained", ",", "pruned", "=", "True", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ecaresnet200d": [[1305, 1313], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ecaresnet200d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-200-D model with ECA.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "24", ",", "36", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "'eca'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ecaresnet200d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ecaresnet269d": [[1315, 1323], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ecaresnet269d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-269-D model with ECA.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "30", ",", "48", ",", "8", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "'eca'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ecaresnet269d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ecaresnext26t_32x4d": [[1325, 1335], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ecaresnext26t_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs an ECA-ResNeXt-26-T model.\n    This is technically a 28 layer ResNet, like a 'D' bag-of-tricks model but with tiered 24, 32, 64 channels\n    in the deep stem. This model replaces SE module with the ECA module\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "stem_width", "=", "32", ",", "\n", "stem_type", "=", "'deep_tiered'", ",", "avg_down", "=", "True", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "'eca'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ecaresnext26t_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.ecaresnext50t_32x4d": [[1337, 1347], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "ecaresnext50t_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs an ECA-ResNeXt-50-T model.\n    This is technically a 28 layer ResNet, like a 'D' bag-of-tricks model but with tiered 24, 32, 64 channels\n    in the deep stem. This model replaces SE module with the ECA module\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "stem_width", "=", "32", ",", "\n", "stem_type", "=", "'deep_tiered'", ",", "avg_down", "=", "True", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "'eca'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'ecaresnext50t_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnetblur18": [[1349, 1355], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnetblur18", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model with blur anti-aliasing\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "BasicBlock", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "aa_layer", "=", "BlurPool2d", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnetblur18'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnetblur50": [[1357, 1363], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnetblur50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model with blur anti-aliasing\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "aa_layer", "=", "BlurPool2d", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnetblur50'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnetblur50d": [[1365, 1373], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnetblur50d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50-D model with blur anti-aliasing\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "aa_layer", "=", "BlurPool2d", ",", "\n", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnetblur50d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnetblur101d": [[1375, 1383], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnetblur101d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101-D model with blur anti-aliasing\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "aa_layer", "=", "BlurPool2d", ",", "\n", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnetblur101d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnetaa50d": [[1385, 1393], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnetaa50d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50-D model with avgpool anti-aliasing\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "aa_layer", "=", "nn", ".", "AvgPool2d", ",", "\n", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnetaa50d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.resnetaa101d": [[1395, 1403], ["dict", "resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "resnetaa101d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101-D model with avgpool anti-aliasing\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "aa_layer", "=", "nn", ".", "AvgPool2d", ",", "\n", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'resnetaa101d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnetaa50d": [[1405, 1413], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "seresnetaa50d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a SE=ResNet-50-D model with avgpool anti-aliasing\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "aa_layer", "=", "nn", ".", "AvgPool2d", ",", "\n", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "'se'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'seresnetaa50d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnet18": [[1415, 1419], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "seresnet18", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "block", "=", "BasicBlock", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "'se'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'seresnet18'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnet34": [[1421, 1425], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "seresnet34", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "block", "=", "BasicBlock", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "'se'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'seresnet34'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnet50": [[1427, 1431], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "seresnet50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "'se'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'seresnet50'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnet50t": [[1433, 1439], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "seresnet50t", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep_tiered'", ",", "avg_down", "=", "True", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "'se'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'seresnet50t'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnet101": [[1441, 1445], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "seresnet101", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "'se'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'seresnet101'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnet152": [[1447, 1451], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "seresnet152", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "'se'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'seresnet152'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnet152d": [[1453, 1459], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "seresnet152d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "'se'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'seresnet152d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnet200d": [[1461, 1469], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "seresnet200d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-200-D model with SE attn.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "24", ",", "36", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "'se'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'seresnet200d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnet269d": [[1471, 1479], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "seresnet269d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-269-D model with SE attn.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "30", ",", "48", ",", "8", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "'se'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'seresnet269d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnext26d_32x4d": [[1481, 1491], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "seresnext26d_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a SE-ResNeXt-26-D model.`\n    This is technically a 28 layer ResNet, using the 'D' modifier from Gluon / bag-of-tricks for\n    combination of deep stem and avg_pool in downsample.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "stem_width", "=", "32", ",", "\n", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "'se'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'seresnext26d_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnext26t_32x4d": [[1493, 1503], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "seresnext26t_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a SE-ResNet-26-T model.\n    This is technically a 28 layer ResNet, like a 'D' bag-of-tricks model but with tiered 24, 32, 64 channels\n    in the deep stem.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "stem_width", "=", "32", ",", "\n", "stem_type", "=", "'deep_tiered'", ",", "avg_down", "=", "True", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "'se'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'seresnext26t_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnext26tn_32x4d": [[1505, 1512], ["resnet.seresnext26t_32x4d"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnext26t_32x4d"], ["", "@", "register_model", "\n", "def", "seresnext26tn_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a SE-ResNeXt-26-T model.\n    NOTE I deprecated previous 't' model defs and replaced 't' with 'tn', this was the only tn model of note\n    so keeping this def for backwards compat with any uses out there. Old 't' model is lost.\n    \"\"\"", "\n", "return", "seresnext26t_32x4d", "(", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnext50_32x4d": [[1514, 1520], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "seresnext50_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "'se'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'seresnext50_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnext101_32x4d": [[1522, 1528], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "seresnext101_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "'se'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'seresnext101_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.seresnext101_32x8d": [[1530, 1536], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "seresnext101_32x8d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "8", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "'se'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'seresnext101_32x8d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnet.senet154": [[1538, 1544], ["dict", "resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "senet154", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "cardinality", "=", "64", ",", "base_width", "=", "4", ",", "stem_type", "=", "'deep'", ",", "\n", "down_kernel_size", "=", "3", ",", "block_reduce_first", "=", "2", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "'se'", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'senet154'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.SEModule.__init__": [[73, 79], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channels", ",", "reduction", ")", ":", "\n", "        ", "super", "(", "SEModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Conv2d", "(", "channels", ",", "channels", "//", "reduction", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Conv2d", "(", "channels", "//", "reduction", ",", "channels", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.SEModule.forward": [[80, 88], ["senet.SEModule.mean", "senet.SEModule.fc1", "senet.SEModule.relu", "senet.SEModule.fc2", "senet.SEModule.sigmoid"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "module_input", "=", "x", "\n", "x", "=", "x", ".", "mean", "(", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "sigmoid", "(", "x", ")", "\n", "return", "module_input", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.Bottleneck.forward": [[95, 116], ["senet.Bottleneck.conv1", "senet.Bottleneck.bn1", "senet.Bottleneck.relu", "senet.Bottleneck.conv2", "senet.Bottleneck.bn2", "senet.Bottleneck.relu", "senet.Bottleneck.conv3", "senet.Bottleneck.bn3", "senet.Bottleneck.relu", "senet.Bottleneck.downsample", "senet.Bottleneck.se_module"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "=", "self", ".", "se_module", "(", "out", ")", "+", "shortcut", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.SEBottleneck.__init__": [[124, 138], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "senet.SEModule"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "groups", ",", "reduction", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "SEBottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", "*", "2", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "2", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "\n", "planes", "*", "2", ",", "planes", "*", "4", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "groups", "=", "groups", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "4", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", "*", "4", ",", "planes", "*", "4", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "4", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "se_module", "=", "SEModule", "(", "planes", "*", "4", ",", "reduction", "=", "reduction", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.SEResNetBottleneck.__init__": [[148, 160], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "senet.SEModule"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "groups", ",", "reduction", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "SEResNetBottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ",", "stride", "=", "stride", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "groups", "=", "groups", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", "*", "4", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "4", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "se_module", "=", "SEModule", "(", "planes", "*", "4", ",", "reduction", "=", "reduction", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.SEResNeXtBottleneck.__init__": [[168, 181], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "senet.SEModule", "math.floor"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "groups", ",", "reduction", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "base_width", "=", "4", ")", ":", "\n", "        ", "super", "(", "SEResNeXtBottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "width", "=", "math", ".", "floor", "(", "planes", "*", "(", "base_width", "/", "64", ")", ")", "*", "groups", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "width", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ",", "stride", "=", "1", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "width", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "width", ",", "width", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "groups", "=", "groups", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "width", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "width", ",", "planes", "*", "4", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "4", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "se_module", "=", "SEModule", "(", "planes", "*", "4", ",", "reduction", "=", "reduction", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.SEResNetBlock.__init__": [[186, 196], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "senet.SEModule"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "groups", ",", "reduction", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "SEResNetBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "groups", "=", "groups", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "se_module", "=", "SEModule", "(", "planes", ",", "reduction", "=", "reduction", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.SEResNetBlock.forward": [[197, 215], ["senet.SEResNetBlock.conv1", "senet.SEResNetBlock.bn1", "senet.SEResNetBlock.relu", "senet.SEResNetBlock.conv2", "senet.SEResNetBlock.bn2", "senet.SEResNetBlock.relu", "senet.SEResNetBlock.relu", "senet.SEResNetBlock.downsample", "senet.SEResNetBlock.se_module"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "=", "self", ".", "se_module", "(", "out", ")", "+", "shortcut", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.SENet.__init__": [[219, 342], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "senet.SENet._make_layer", "senet.SENet._make_layer", "senet.SENet._make_layer", "senet.SENet._make_layer", "layers.create_classifier", "senet.SENet.modules", "collections.OrderedDict", "dict", "dict", "dict", "dict", "dict", "senet._weight_init", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet._make_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet._make_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet._make_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet._make_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet._weight_init"], ["    ", "def", "__init__", "(", "\n", "self", ",", "block", ",", "layers", ",", "groups", ",", "reduction", ",", "drop_rate", "=", "0.2", ",", "\n", "in_chans", "=", "3", ",", "inplanes", "=", "64", ",", "input_3x3", "=", "False", ",", "downsample_kernel_size", "=", "1", ",", "\n", "downsample_padding", "=", "0", ",", "num_classes", "=", "1000", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        block (nn.Module): Bottleneck class.\n            - For SENet154: SEBottleneck\n            - For SE-ResNet models: SEResNetBottleneck\n            - For SE-ResNeXt models:  SEResNeXtBottleneck\n        layers (list of ints): Number of residual blocks for 4 layers of the\n            network (layer1...layer4).\n        groups (int): Number of groups for the 3x3 convolution in each\n            bottleneck block.\n            - For SENet154: 64\n            - For SE-ResNet models: 1\n            - For SE-ResNeXt models:  32\n        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n            - For all models: 16\n        dropout_p (float or None): Drop probability for the Dropout layer.\n            If `None` the Dropout layer is not used.\n            - For SENet154: 0.2\n            - For SE-ResNet models: None\n            - For SE-ResNeXt models: None\n        inplanes (int):  Number of input channels for layer1.\n            - For SENet154: 128\n            - For SE-ResNet models: 64\n            - For SE-ResNeXt models: 64\n        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n            a single 7x7 convolution in layer0.\n            - For SENet154: True\n            - For SE-ResNet models: False\n            - For SE-ResNeXt models: False\n        downsample_kernel_size (int): Kernel size for downsampling convolutions\n            in layer2, layer3 and layer4.\n            - For SENet154: 3\n            - For SE-ResNet models: 1\n            - For SE-ResNeXt models: 1\n        downsample_padding (int): Padding for downsampling convolutions in\n            layer2, layer3 and layer4.\n            - For SENet154: 1\n            - For SE-ResNet models: 0\n            - For SE-ResNeXt models: 0\n        num_classes (int): Number of outputs in `last_linear` layer.\n            - For all models: 1000\n        \"\"\"", "\n", "super", "(", "SENet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inplanes", "=", "inplanes", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "if", "input_3x3", ":", "\n", "            ", "layer0_modules", "=", "[", "\n", "(", "'conv1'", ",", "nn", ".", "Conv2d", "(", "in_chans", ",", "64", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ")", ",", "\n", "(", "'bn1'", ",", "nn", ".", "BatchNorm2d", "(", "64", ")", ")", ",", "\n", "(", "'relu1'", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", ",", "\n", "(", "'conv2'", ",", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ")", ",", "\n", "(", "'bn2'", ",", "nn", ".", "BatchNorm2d", "(", "64", ")", ")", ",", "\n", "(", "'relu2'", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", ",", "\n", "(", "'conv3'", ",", "nn", ".", "Conv2d", "(", "64", ",", "inplanes", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ")", ",", "\n", "(", "'bn3'", ",", "nn", ".", "BatchNorm2d", "(", "inplanes", ")", ")", ",", "\n", "(", "'relu3'", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", ",", "\n", "]", "\n", "", "else", ":", "\n", "            ", "layer0_modules", "=", "[", "\n", "(", "'conv1'", ",", "nn", ".", "Conv2d", "(", "\n", "in_chans", ",", "inplanes", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "bias", "=", "False", ")", ")", ",", "\n", "(", "'bn1'", ",", "nn", ".", "BatchNorm2d", "(", "inplanes", ")", ")", ",", "\n", "(", "'relu1'", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", ",", "\n", "]", "\n", "", "self", ".", "layer0", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "layer0_modules", ")", ")", "\n", "# To preserve compatibility with Caffe weights `ceil_mode=True` is used instead of `padding=1`.", "\n", "self", ".", "pool0", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "stride", "=", "2", ",", "ceil_mode", "=", "True", ")", "\n", "self", ".", "feature_info", "=", "[", "dict", "(", "num_chs", "=", "inplanes", ",", "reduction", "=", "2", ",", "module", "=", "'layer0'", ")", "]", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "\n", "planes", "=", "64", ",", "\n", "blocks", "=", "layers", "[", "0", "]", ",", "\n", "groups", "=", "groups", ",", "\n", "reduction", "=", "reduction", ",", "\n", "downsample_kernel_size", "=", "1", ",", "\n", "downsample_padding", "=", "0", "\n", ")", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "64", "*", "block", ".", "expansion", ",", "reduction", "=", "4", ",", "module", "=", "'layer1'", ")", "]", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "\n", "planes", "=", "128", ",", "\n", "blocks", "=", "layers", "[", "1", "]", ",", "\n", "stride", "=", "2", ",", "\n", "groups", "=", "groups", ",", "\n", "reduction", "=", "reduction", ",", "\n", "downsample_kernel_size", "=", "downsample_kernel_size", ",", "\n", "downsample_padding", "=", "downsample_padding", "\n", ")", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "128", "*", "block", ".", "expansion", ",", "reduction", "=", "8", ",", "module", "=", "'layer2'", ")", "]", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "\n", "planes", "=", "256", ",", "\n", "blocks", "=", "layers", "[", "2", "]", ",", "\n", "stride", "=", "2", ",", "\n", "groups", "=", "groups", ",", "\n", "reduction", "=", "reduction", ",", "\n", "downsample_kernel_size", "=", "downsample_kernel_size", ",", "\n", "downsample_padding", "=", "downsample_padding", "\n", ")", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "256", "*", "block", ".", "expansion", ",", "reduction", "=", "16", ",", "module", "=", "'layer3'", ")", "]", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "\n", "planes", "=", "512", ",", "\n", "blocks", "=", "layers", "[", "3", "]", ",", "\n", "stride", "=", "2", ",", "\n", "groups", "=", "groups", ",", "\n", "reduction", "=", "reduction", ",", "\n", "downsample_kernel_size", "=", "downsample_kernel_size", ",", "\n", "downsample_padding", "=", "downsample_padding", "\n", ")", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "512", "*", "block", ".", "expansion", ",", "reduction", "=", "32", ",", "module", "=", "'layer4'", ")", "]", "\n", "self", ".", "num_features", "=", "512", "*", "block", ".", "expansion", "\n", "self", ".", "global_pool", ",", "self", ".", "last_linear", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "_weight_init", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.SENet._make_layer": [[343, 360], ["range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "groups", ",", "reduction", ",", "stride", "=", "1", ",", "\n", "downsample_kernel_size", "=", "1", ",", "downsample_padding", "=", "0", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "kernel_size", "=", "downsample_kernel_size", ",", "\n", "stride", "=", "stride", ",", "padding", "=", "downsample_padding", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "groups", ",", "reduction", ",", "stride", ",", "downsample", ")", "]", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "groups", ",", "reduction", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.SENet.group_matcher": [[361, 365], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "stem", "=", "r'^layer0'", ",", "blocks", "=", "r'^layer(\\d+)'", "if", "coarse", "else", "r'^layer(\\d+)\\.(\\d+)'", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.SENet.set_grad_checkpointing": [[366, 369], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "'gradient checkpointing not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.SENet.get_classifier": [[370, 373], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "last_linear", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.SENet.reset_classifier": [[374, 378], ["layers.create_classifier"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "last_linear", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.SENet.forward_features": [[379, 387], ["senet.SENet.layer0", "senet.SENet.pool0", "senet.SENet.layer1", "senet.SENet.layer2", "senet.SENet.layer3", "senet.SENet.layer4"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "layer0", "(", "x", ")", "\n", "x", "=", "self", ".", "pool0", "(", "x", ")", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.SENet.forward_head": [[388, 393], ["senet.SENet.global_pool", "torch.dropout", "torch.dropout", "torch.dropout", "senet.SENet.last_linear"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ">", "0.", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "last_linear", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.SENet.forward": [[394, 398], ["senet.SENet.forward_features", "senet.SENet.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet._cfg": [[29, 36], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bilinear'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'layer0.conv1'", ",", "'classifier'", ":", "'last_linear'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet._weight_init": [[63, 69], ["isinstance", "torch.init.kaiming_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_"], "function", ["None"], ["def", "_weight_init", "(", "m", ")", ":", "\n", "    ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "        ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet._create_senet": [[400, 402], ["helpers.build_model_with_cfg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_senet", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "SENet", ",", "variant", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.legacy_seresnet18": [[404, 409], ["dict", "senet._create_senet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet._create_senet"], ["", "@", "register_model", "\n", "def", "legacy_seresnet18", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "block", "=", "SEResNetBlock", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "groups", "=", "1", ",", "reduction", "=", "16", ",", "**", "kwargs", ")", "\n", "return", "_create_senet", "(", "'legacy_seresnet18'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.legacy_seresnet34": [[411, 416], ["dict", "senet._create_senet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet._create_senet"], ["", "@", "register_model", "\n", "def", "legacy_seresnet34", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "block", "=", "SEResNetBlock", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "groups", "=", "1", ",", "reduction", "=", "16", ",", "**", "kwargs", ")", "\n", "return", "_create_senet", "(", "'legacy_seresnet34'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.legacy_seresnet50": [[418, 423], ["dict", "senet._create_senet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet._create_senet"], ["", "@", "register_model", "\n", "def", "legacy_seresnet50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "block", "=", "SEResNetBottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "groups", "=", "1", ",", "reduction", "=", "16", ",", "**", "kwargs", ")", "\n", "return", "_create_senet", "(", "'legacy_seresnet50'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.legacy_seresnet101": [[425, 430], ["dict", "senet._create_senet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet._create_senet"], ["", "@", "register_model", "\n", "def", "legacy_seresnet101", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "block", "=", "SEResNetBottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "groups", "=", "1", ",", "reduction", "=", "16", ",", "**", "kwargs", ")", "\n", "return", "_create_senet", "(", "'legacy_seresnet101'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.legacy_seresnet152": [[432, 437], ["dict", "senet._create_senet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet._create_senet"], ["", "@", "register_model", "\n", "def", "legacy_seresnet152", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "block", "=", "SEResNetBottleneck", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "groups", "=", "1", ",", "reduction", "=", "16", ",", "**", "kwargs", ")", "\n", "return", "_create_senet", "(", "'legacy_seresnet152'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.legacy_senet154": [[439, 445], ["dict", "senet._create_senet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet._create_senet"], ["", "@", "register_model", "\n", "def", "legacy_senet154", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "block", "=", "SEBottleneck", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "groups", "=", "64", ",", "reduction", "=", "16", ",", "\n", "downsample_kernel_size", "=", "3", ",", "downsample_padding", "=", "1", ",", "inplanes", "=", "128", ",", "input_3x3", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_senet", "(", "'legacy_senet154'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.legacy_seresnext26_32x4d": [[447, 452], ["dict", "senet._create_senet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet._create_senet"], ["", "@", "register_model", "\n", "def", "legacy_seresnext26_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "block", "=", "SEResNeXtBottleneck", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "groups", "=", "32", ",", "reduction", "=", "16", ",", "**", "kwargs", ")", "\n", "return", "_create_senet", "(", "'legacy_seresnext26_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.legacy_seresnext50_32x4d": [[454, 459], ["dict", "senet._create_senet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet._create_senet"], ["", "@", "register_model", "\n", "def", "legacy_seresnext50_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "block", "=", "SEResNeXtBottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "groups", "=", "32", ",", "reduction", "=", "16", ",", "**", "kwargs", ")", "\n", "return", "_create_senet", "(", "'legacy_seresnext50_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet.legacy_seresnext101_32x4d": [[461, 466], ["dict", "senet._create_senet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.senet._create_senet"], ["", "@", "register_model", "\n", "def", "legacy_seresnext101_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "block", "=", "SEResNeXtBottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "groups", "=", "32", ",", "reduction", "=", "16", ",", "**", "kwargs", ")", "\n", "return", "_create_senet", "(", "'legacy_seresnext101_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.DownsampleAvg.__init__": [[931, 942], ["torch.Module.__init__", "layers.conv_norm_act", "byobnet.LayerFn", "avg_pool_fn", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_chs", ",", "out_chs", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "apply_act", "=", "False", ",", "layers", ":", "LayerFn", "=", "None", ")", ":", "\n", "        ", "\"\"\" AvgPool Downsampling as in 'D' ResNet variants.\"\"\"", "\n", "super", "(", "DownsampleAvg", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layers", "=", "layers", "or", "LayerFn", "(", ")", "\n", "avg_stride", "=", "stride", "if", "dilation", "==", "1", "else", "1", "\n", "if", "stride", ">", "1", "or", "dilation", ">", "1", ":", "\n", "            ", "avg_pool_fn", "=", "AvgPool2dSame", "if", "avg_stride", "==", "1", "and", "dilation", ">", "1", "else", "nn", ".", "AvgPool2d", "\n", "self", ".", "pool", "=", "avg_pool_fn", "(", "2", ",", "avg_stride", ",", "ceil_mode", "=", "True", ",", "count_include_pad", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "pool", "=", "nn", ".", "Identity", "(", ")", "\n", "", "self", ".", "conv", "=", "layers", ".", "conv_norm_act", "(", "in_chs", ",", "out_chs", ",", "1", ",", "apply_act", "=", "apply_act", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.DownsampleAvg.forward": [[943, 945], ["byobnet.DownsampleAvg.conv", "byobnet.DownsampleAvg.pool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "conv", "(", "self", ".", "pool", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.BasicBlock.__init__": [[964, 984], ["torch.Module.__init__", "layers.make_divisible", "byobnet.num_groups", "byobnet.create_shortcut", "layers.conv_norm_act", "layers.conv_norm_act", "byobnet.LayerFn", "torch.Identity", "torch.Identity", "layers.attn", "torch.Identity", "torch.Identity", "layers.attn", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "layers.act"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.num_groups", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.create_shortcut"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "dilation", "=", "(", "1", ",", "1", ")", ",", "group_size", "=", "None", ",", "bottle_ratio", "=", "1.0", ",", "\n", "downsample", "=", "'avg'", ",", "attn_last", "=", "True", ",", "linear_out", "=", "False", ",", "layers", ":", "LayerFn", "=", "None", ",", "drop_block", "=", "None", ",", "\n", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layers", "=", "layers", "or", "LayerFn", "(", ")", "\n", "mid_chs", "=", "make_divisible", "(", "out_chs", "*", "bottle_ratio", ")", "\n", "groups", "=", "num_groups", "(", "group_size", ",", "mid_chs", ")", "\n", "\n", "self", ".", "shortcut", "=", "create_shortcut", "(", "\n", "downsample", ",", "in_chs", "=", "in_chs", ",", "out_chs", "=", "out_chs", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "\n", "apply_act", "=", "False", ",", "layers", "=", "layers", ")", "\n", "\n", "self", ".", "conv1_kxk", "=", "layers", ".", "conv_norm_act", "(", "in_chs", ",", "mid_chs", ",", "kernel_size", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", "[", "0", "]", ")", "\n", "self", ".", "attn", "=", "nn", ".", "Identity", "(", ")", "if", "attn_last", "or", "layers", ".", "attn", "is", "None", "else", "layers", ".", "attn", "(", "mid_chs", ")", "\n", "self", ".", "conv2_kxk", "=", "layers", ".", "conv_norm_act", "(", "\n", "mid_chs", ",", "out_chs", ",", "kernel_size", ",", "dilation", "=", "dilation", "[", "1", "]", ",", "groups", "=", "groups", ",", "drop_layer", "=", "drop_block", ",", "apply_act", "=", "False", ")", "\n", "self", ".", "attn_last", "=", "nn", ".", "Identity", "(", ")", "if", "not", "attn_last", "or", "layers", ".", "attn", "is", "None", "else", "layers", ".", "attn", "(", "out_chs", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path_rate", ")", "if", "drop_path_rate", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "act", "=", "nn", ".", "Identity", "(", ")", "if", "linear_out", "else", "layers", ".", "act", "(", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.BasicBlock.init_weights": [[985, 991], ["torch.init.zeros_", "torch.init.zeros_", "hasattr", "attn.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters"], ["", "def", "init_weights", "(", "self", ",", "zero_init_last", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "zero_init_last", "and", "self", ".", "shortcut", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "conv2_kxk", ".", "bn", ".", "weight", ")", "\n", "", "for", "attn", "in", "(", "self", ".", "attn", ",", "self", ".", "attn_last", ")", ":", "\n", "            ", "if", "hasattr", "(", "attn", ",", "'reset_parameters'", ")", ":", "\n", "                ", "attn", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.BasicBlock.forward": [[992, 1001], ["byobnet.BasicBlock.conv1_kxk", "byobnet.BasicBlock.conv2_kxk", "byobnet.BasicBlock.attn", "byobnet.BasicBlock.drop_path", "byobnet.BasicBlock.act", "byobnet.BasicBlock.shortcut"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "conv1_kxk", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2_kxk", "(", "x", ")", "\n", "x", "=", "self", ".", "attn", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_path", "(", "x", ")", "\n", "if", "self", ".", "shortcut", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "shortcut", "(", "shortcut", ")", "\n", "", "return", "self", ".", "act", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.BottleneckBlock.__init__": [[1007, 1032], ["torch.Module.__init__", "layers.make_divisible", "byobnet.num_groups", "byobnet.create_shortcut", "layers.conv_norm_act", "layers.conv_norm_act", "layers.conv_norm_act", "byobnet.LayerFn", "layers.conv_norm_act", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "layers.attn", "torch.Identity", "torch.Identity", "layers.attn", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "layers.act"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.num_groups", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.create_shortcut"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "dilation", "=", "(", "1", ",", "1", ")", ",", "bottle_ratio", "=", "1.", ",", "group_size", "=", "None", ",", "\n", "downsample", "=", "'avg'", ",", "attn_last", "=", "False", ",", "linear_out", "=", "False", ",", "extra_conv", "=", "False", ",", "bottle_in", "=", "False", ",", "\n", "layers", ":", "LayerFn", "=", "None", ",", "drop_block", "=", "None", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", "BottleneckBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layers", "=", "layers", "or", "LayerFn", "(", ")", "\n", "mid_chs", "=", "make_divisible", "(", "(", "in_chs", "if", "bottle_in", "else", "out_chs", ")", "*", "bottle_ratio", ")", "\n", "groups", "=", "num_groups", "(", "group_size", ",", "mid_chs", ")", "\n", "\n", "self", ".", "shortcut", "=", "create_shortcut", "(", "\n", "downsample", ",", "in_chs", "=", "in_chs", ",", "out_chs", "=", "out_chs", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "\n", "apply_act", "=", "False", ",", "layers", "=", "layers", ")", "\n", "\n", "self", ".", "conv1_1x1", "=", "layers", ".", "conv_norm_act", "(", "in_chs", ",", "mid_chs", ",", "1", ")", "\n", "self", ".", "conv2_kxk", "=", "layers", ".", "conv_norm_act", "(", "\n", "mid_chs", ",", "mid_chs", ",", "kernel_size", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", "[", "0", "]", ",", "groups", "=", "groups", ",", "drop_layer", "=", "drop_block", ")", "\n", "if", "extra_conv", ":", "\n", "            ", "self", ".", "conv2b_kxk", "=", "layers", ".", "conv_norm_act", "(", "mid_chs", ",", "mid_chs", ",", "kernel_size", ",", "dilation", "=", "dilation", "[", "1", "]", ",", "groups", "=", "groups", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv2b_kxk", "=", "nn", ".", "Identity", "(", ")", "\n", "", "self", ".", "attn", "=", "nn", ".", "Identity", "(", ")", "if", "attn_last", "or", "layers", ".", "attn", "is", "None", "else", "layers", ".", "attn", "(", "mid_chs", ")", "\n", "self", ".", "conv3_1x1", "=", "layers", ".", "conv_norm_act", "(", "mid_chs", ",", "out_chs", ",", "1", ",", "apply_act", "=", "False", ")", "\n", "self", ".", "attn_last", "=", "nn", ".", "Identity", "(", ")", "if", "not", "attn_last", "or", "layers", ".", "attn", "is", "None", "else", "layers", ".", "attn", "(", "out_chs", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path_rate", ")", "if", "drop_path_rate", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "act", "=", "nn", ".", "Identity", "(", ")", "if", "linear_out", "else", "layers", ".", "act", "(", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.BottleneckBlock.init_weights": [[1033, 1039], ["torch.init.zeros_", "torch.init.zeros_", "hasattr", "attn.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters"], ["", "def", "init_weights", "(", "self", ",", "zero_init_last", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "zero_init_last", "and", "self", ".", "shortcut", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "conv3_1x1", ".", "bn", ".", "weight", ")", "\n", "", "for", "attn", "in", "(", "self", ".", "attn", ",", "self", ".", "attn_last", ")", ":", "\n", "            ", "if", "hasattr", "(", "attn", ",", "'reset_parameters'", ")", ":", "\n", "                ", "attn", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.BottleneckBlock.forward": [[1040, 1052], ["byobnet.BottleneckBlock.conv1_1x1", "byobnet.BottleneckBlock.conv2_kxk", "byobnet.BottleneckBlock.conv2b_kxk", "byobnet.BottleneckBlock.attn", "byobnet.BottleneckBlock.conv3_1x1", "byobnet.BottleneckBlock.attn_last", "byobnet.BottleneckBlock.drop_path", "byobnet.BottleneckBlock.act", "byobnet.BottleneckBlock.shortcut"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "conv1_1x1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2_kxk", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2b_kxk", "(", "x", ")", "\n", "x", "=", "self", ".", "attn", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3_1x1", "(", "x", ")", "\n", "x", "=", "self", ".", "attn_last", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_path", "(", "x", ")", "\n", "if", "self", ".", "shortcut", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "shortcut", "(", "shortcut", ")", "\n", "", "return", "self", ".", "act", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.DarkBlock.__init__": [[1065, 1086], ["torch.Module.__init__", "layers.make_divisible", "byobnet.num_groups", "byobnet.create_shortcut", "layers.conv_norm_act", "layers.conv_norm_act", "byobnet.LayerFn", "torch.Identity", "torch.Identity", "layers.attn", "torch.Identity", "torch.Identity", "layers.attn", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "layers.act"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.num_groups", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.create_shortcut"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "dilation", "=", "(", "1", ",", "1", ")", ",", "bottle_ratio", "=", "1.0", ",", "group_size", "=", "None", ",", "\n", "downsample", "=", "'avg'", ",", "attn_last", "=", "True", ",", "linear_out", "=", "False", ",", "layers", ":", "LayerFn", "=", "None", ",", "drop_block", "=", "None", ",", "\n", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", "DarkBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layers", "=", "layers", "or", "LayerFn", "(", ")", "\n", "mid_chs", "=", "make_divisible", "(", "out_chs", "*", "bottle_ratio", ")", "\n", "groups", "=", "num_groups", "(", "group_size", ",", "mid_chs", ")", "\n", "\n", "self", ".", "shortcut", "=", "create_shortcut", "(", "\n", "downsample", ",", "in_chs", "=", "in_chs", ",", "out_chs", "=", "out_chs", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "\n", "apply_act", "=", "False", ",", "layers", "=", "layers", ")", "\n", "\n", "self", ".", "conv1_1x1", "=", "layers", ".", "conv_norm_act", "(", "in_chs", ",", "mid_chs", ",", "1", ")", "\n", "self", ".", "attn", "=", "nn", ".", "Identity", "(", ")", "if", "attn_last", "or", "layers", ".", "attn", "is", "None", "else", "layers", ".", "attn", "(", "mid_chs", ")", "\n", "self", ".", "conv2_kxk", "=", "layers", ".", "conv_norm_act", "(", "\n", "mid_chs", ",", "out_chs", ",", "kernel_size", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", "[", "0", "]", ",", "\n", "groups", "=", "groups", ",", "drop_layer", "=", "drop_block", ",", "apply_act", "=", "False", ")", "\n", "self", ".", "attn_last", "=", "nn", ".", "Identity", "(", ")", "if", "not", "attn_last", "or", "layers", ".", "attn", "is", "None", "else", "layers", ".", "attn", "(", "out_chs", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path_rate", ")", "if", "drop_path_rate", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "act", "=", "nn", ".", "Identity", "(", ")", "if", "linear_out", "else", "layers", ".", "act", "(", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.DarkBlock.init_weights": [[1087, 1093], ["torch.init.zeros_", "torch.init.zeros_", "hasattr", "attn.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters"], ["", "def", "init_weights", "(", "self", ",", "zero_init_last", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "zero_init_last", "and", "self", ".", "shortcut", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "conv2_kxk", ".", "bn", ".", "weight", ")", "\n", "", "for", "attn", "in", "(", "self", ".", "attn", ",", "self", ".", "attn_last", ")", ":", "\n", "            ", "if", "hasattr", "(", "attn", ",", "'reset_parameters'", ")", ":", "\n", "                ", "attn", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.DarkBlock.forward": [[1094, 1104], ["byobnet.DarkBlock.conv1_1x1", "byobnet.DarkBlock.attn", "byobnet.DarkBlock.conv2_kxk", "byobnet.DarkBlock.attn_last", "byobnet.DarkBlock.drop_path", "byobnet.DarkBlock.act", "byobnet.DarkBlock.shortcut"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "conv1_1x1", "(", "x", ")", "\n", "x", "=", "self", ".", "attn", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2_kxk", "(", "x", ")", "\n", "x", "=", "self", ".", "attn_last", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_path", "(", "x", ")", "\n", "if", "self", ".", "shortcut", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "shortcut", "(", "shortcut", ")", "\n", "", "return", "self", ".", "act", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.EdgeBlock.__init__": [[1116, 1136], ["torch.Module.__init__", "layers.make_divisible", "byobnet.num_groups", "byobnet.create_shortcut", "layers.conv_norm_act", "layers.conv_norm_act", "byobnet.LayerFn", "torch.Identity", "torch.Identity", "layers.attn", "torch.Identity", "torch.Identity", "layers.attn", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "layers.act"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.num_groups", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.create_shortcut"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "dilation", "=", "(", "1", ",", "1", ")", ",", "bottle_ratio", "=", "1.0", ",", "group_size", "=", "None", ",", "\n", "downsample", "=", "'avg'", ",", "attn_last", "=", "False", ",", "linear_out", "=", "False", ",", "layers", ":", "LayerFn", "=", "None", ",", "\n", "drop_block", "=", "None", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", "EdgeBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layers", "=", "layers", "or", "LayerFn", "(", ")", "\n", "mid_chs", "=", "make_divisible", "(", "out_chs", "*", "bottle_ratio", ")", "\n", "groups", "=", "num_groups", "(", "group_size", ",", "mid_chs", ")", "\n", "\n", "self", ".", "shortcut", "=", "create_shortcut", "(", "\n", "downsample", ",", "in_chs", "=", "in_chs", ",", "out_chs", "=", "out_chs", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "\n", "apply_act", "=", "False", ",", "layers", "=", "layers", ")", "\n", "\n", "self", ".", "conv1_kxk", "=", "layers", ".", "conv_norm_act", "(", "\n", "in_chs", ",", "mid_chs", ",", "kernel_size", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", "[", "0", "]", ",", "groups", "=", "groups", ",", "drop_layer", "=", "drop_block", ")", "\n", "self", ".", "attn", "=", "nn", ".", "Identity", "(", ")", "if", "attn_last", "or", "layers", ".", "attn", "is", "None", "else", "layers", ".", "attn", "(", "mid_chs", ")", "\n", "self", ".", "conv2_1x1", "=", "layers", ".", "conv_norm_act", "(", "mid_chs", ",", "out_chs", ",", "1", ",", "apply_act", "=", "False", ")", "\n", "self", ".", "attn_last", "=", "nn", ".", "Identity", "(", ")", "if", "not", "attn_last", "or", "layers", ".", "attn", "is", "None", "else", "layers", ".", "attn", "(", "out_chs", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path_rate", ")", "if", "drop_path_rate", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "act", "=", "nn", ".", "Identity", "(", ")", "if", "linear_out", "else", "layers", ".", "act", "(", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.EdgeBlock.init_weights": [[1137, 1143], ["torch.init.zeros_", "torch.init.zeros_", "hasattr", "attn.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters"], ["", "def", "init_weights", "(", "self", ",", "zero_init_last", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "zero_init_last", "and", "self", ".", "shortcut", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "conv2_1x1", ".", "bn", ".", "weight", ")", "\n", "", "for", "attn", "in", "(", "self", ".", "attn", ",", "self", ".", "attn_last", ")", ":", "\n", "            ", "if", "hasattr", "(", "attn", ",", "'reset_parameters'", ")", ":", "\n", "                ", "attn", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.EdgeBlock.forward": [[1144, 1154], ["byobnet.EdgeBlock.conv1_kxk", "byobnet.EdgeBlock.attn", "byobnet.EdgeBlock.conv2_1x1", "byobnet.EdgeBlock.attn_last", "byobnet.EdgeBlock.drop_path", "byobnet.EdgeBlock.act", "byobnet.EdgeBlock.shortcut"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "conv1_kxk", "(", "x", ")", "\n", "x", "=", "self", ".", "attn", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2_1x1", "(", "x", ")", "\n", "x", "=", "self", ".", "attn_last", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_path", "(", "x", ")", "\n", "if", "self", ".", "shortcut", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "shortcut", "(", "shortcut", ")", "\n", "", "return", "self", ".", "act", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.RepVggBlock.__init__": [[1164, 1180], ["torch.Module.__init__", "byobnet.num_groups", "layers.conv_norm_act", "layers.conv_norm_act", "layers.act", "byobnet.LayerFn", "layers.norm_act", "torch.Identity", "torch.Identity", "layers.attn", "layers.DropPath", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.num_groups"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "dilation", "=", "(", "1", ",", "1", ")", ",", "bottle_ratio", "=", "1.0", ",", "group_size", "=", "None", ",", "\n", "downsample", "=", "''", ",", "layers", ":", "LayerFn", "=", "None", ",", "drop_block", "=", "None", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", "RepVggBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layers", "=", "layers", "or", "LayerFn", "(", ")", "\n", "groups", "=", "num_groups", "(", "group_size", ",", "in_chs", ")", "\n", "\n", "use_ident", "=", "in_chs", "==", "out_chs", "and", "stride", "==", "1", "and", "dilation", "[", "0", "]", "==", "dilation", "[", "1", "]", "\n", "self", ".", "identity", "=", "layers", ".", "norm_act", "(", "out_chs", ",", "apply_act", "=", "False", ")", "if", "use_ident", "else", "None", "\n", "self", ".", "conv_kxk", "=", "layers", ".", "conv_norm_act", "(", "\n", "in_chs", ",", "out_chs", ",", "kernel_size", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", "[", "0", "]", ",", "\n", "groups", "=", "groups", ",", "drop_layer", "=", "drop_block", ",", "apply_act", "=", "False", ")", "\n", "self", ".", "conv_1x1", "=", "layers", ".", "conv_norm_act", "(", "in_chs", ",", "out_chs", ",", "1", ",", "stride", "=", "stride", ",", "groups", "=", "groups", ",", "apply_act", "=", "False", ")", "\n", "self", ".", "attn", "=", "nn", ".", "Identity", "(", ")", "if", "layers", ".", "attn", "is", "None", "else", "layers", ".", "attn", "(", "out_chs", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path_rate", ")", "if", "drop_path_rate", ">", "0.", "and", "use_ident", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "act", "=", "layers", ".", "act", "(", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.RepVggBlock.init_weights": [[1181, 1189], ["byobnet.RepVggBlock.modules", "hasattr", "isinstance", "byobnet.RepVggBlock.attn.reset_parameters", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters"], ["", "def", "init_weights", "(", "self", ",", "zero_init_last", ":", "bool", "=", "False", ")", ":", "\n", "# NOTE this init overrides that base model init with specific changes for the block type", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", ".1", ",", ".1", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "bias", ",", "0", ",", ".1", ")", "\n", "", "", "if", "hasattr", "(", "self", ".", "attn", ",", "'reset_parameters'", ")", ":", "\n", "            ", "self", ".", "attn", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.RepVggBlock.forward": [[1190, 1200], ["byobnet.RepVggBlock.attn", "byobnet.RepVggBlock.act", "byobnet.RepVggBlock.identity", "byobnet.RepVggBlock.drop_path", "byobnet.RepVggBlock.conv_1x1", "byobnet.RepVggBlock.conv_kxk", "byobnet.RepVggBlock.conv_1x1", "byobnet.RepVggBlock.conv_kxk"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "identity", "is", "None", ":", "\n", "            ", "x", "=", "self", ".", "conv_1x1", "(", "x", ")", "+", "self", ".", "conv_kxk", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "identity", "=", "self", ".", "identity", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_1x1", "(", "x", ")", "+", "self", ".", "conv_kxk", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_path", "(", "x", ")", "# not in the paper / official impl, experimental", "\n", "x", "=", "x", "+", "identity", "\n", "", "x", "=", "self", ".", "attn", "(", "x", ")", "# no attn in the paper / official impl, experimental", "\n", "return", "self", ".", "act", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.SelfAttnBlock.__init__": [[1206, 1234], ["torch.Module.__init__", "layers.make_divisible", "byobnet.num_groups", "byobnet.create_shortcut", "layers.conv_norm_act", "layers.self_attn", "layers.conv_norm_act", "layers.conv_norm_act", "torch.Identity", "torch.Identity", "dict", "layers.norm_act", "torch.Identity", "torch.Identity", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "layers.act"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.num_groups", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.create_shortcut"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "dilation", "=", "(", "1", ",", "1", ")", ",", "bottle_ratio", "=", "1.", ",", "group_size", "=", "None", ",", "\n", "downsample", "=", "'avg'", ",", "extra_conv", "=", "False", ",", "linear_out", "=", "False", ",", "bottle_in", "=", "False", ",", "post_attn_na", "=", "True", ",", "\n", "feat_size", "=", "None", ",", "layers", ":", "LayerFn", "=", "None", ",", "drop_block", "=", "None", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", "SelfAttnBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "layers", "is", "not", "None", "\n", "mid_chs", "=", "make_divisible", "(", "(", "in_chs", "if", "bottle_in", "else", "out_chs", ")", "*", "bottle_ratio", ")", "\n", "groups", "=", "num_groups", "(", "group_size", ",", "mid_chs", ")", "\n", "\n", "self", ".", "shortcut", "=", "create_shortcut", "(", "\n", "downsample", ",", "in_chs", "=", "in_chs", ",", "out_chs", "=", "out_chs", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "\n", "apply_act", "=", "False", ",", "layers", "=", "layers", ")", "\n", "\n", "self", ".", "conv1_1x1", "=", "layers", ".", "conv_norm_act", "(", "in_chs", ",", "mid_chs", ",", "1", ")", "\n", "if", "extra_conv", ":", "\n", "            ", "self", ".", "conv2_kxk", "=", "layers", ".", "conv_norm_act", "(", "\n", "mid_chs", ",", "mid_chs", ",", "kernel_size", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", "[", "0", "]", ",", "\n", "groups", "=", "groups", ",", "drop_layer", "=", "drop_block", ")", "\n", "stride", "=", "1", "# striding done via conv if enabled", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv2_kxk", "=", "nn", ".", "Identity", "(", ")", "\n", "", "opt_kwargs", "=", "{", "}", "if", "feat_size", "is", "None", "else", "dict", "(", "feat_size", "=", "feat_size", ")", "\n", "# FIXME need to dilate self attn to have dilated network support, moop moop", "\n", "self", ".", "self_attn", "=", "layers", ".", "self_attn", "(", "mid_chs", ",", "stride", "=", "stride", ",", "**", "opt_kwargs", ")", "\n", "self", ".", "post_attn", "=", "layers", ".", "norm_act", "(", "mid_chs", ")", "if", "post_attn_na", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "conv3_1x1", "=", "layers", ".", "conv_norm_act", "(", "mid_chs", ",", "out_chs", ",", "1", ",", "apply_act", "=", "False", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path_rate", ")", "if", "drop_path_rate", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "act", "=", "nn", ".", "Identity", "(", ")", "if", "linear_out", "else", "layers", ".", "act", "(", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.SelfAttnBlock.init_weights": [[1235, 1240], ["hasattr", "torch.init.zeros_", "torch.init.zeros_", "byobnet.SelfAttnBlock.self_attn.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters"], ["", "def", "init_weights", "(", "self", ",", "zero_init_last", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "zero_init_last", "and", "self", ".", "shortcut", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "conv3_1x1", ".", "bn", ".", "weight", ")", "\n", "", "if", "hasattr", "(", "self", ".", "self_attn", ",", "'reset_parameters'", ")", ":", "\n", "            ", "self", ".", "self_attn", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.SelfAttnBlock.forward": [[1241, 1252], ["byobnet.SelfAttnBlock.conv1_1x1", "byobnet.SelfAttnBlock.conv2_kxk", "byobnet.SelfAttnBlock.self_attn", "byobnet.SelfAttnBlock.post_attn", "byobnet.SelfAttnBlock.conv3_1x1", "byobnet.SelfAttnBlock.drop_path", "byobnet.SelfAttnBlock.act", "byobnet.SelfAttnBlock.shortcut"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "conv1_1x1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2_kxk", "(", "x", ")", "\n", "x", "=", "self", ".", "self_attn", "(", "x", ")", "\n", "x", "=", "self", ".", "post_attn", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3_1x1", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_path", "(", "x", ")", "\n", "if", "self", ".", "shortcut", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "shortcut", "(", "shortcut", ")", "\n", "", "return", "self", ".", "act", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.Stem.__init__": [[1276, 1320], ["torch.Sequential.__init__", "isinstance", "enumerate", "byobnet.Stem.feature_info.append", "byobnet.LayerFn", "len", "zip", "byobnet.Stem.add_module", "byobnet.Stem.feature_info.append", "byobnet.Stem.add_module", "dict", "byobnet.Stem.feature_info.append", "layer_fn", "pool.lower", "dict", "torch.MaxPool2d", "torch.MaxPool2d", "round", "dict", "range"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "3", ",", "stride", "=", "4", ",", "pool", "=", "'maxpool'", ",", "\n", "num_rep", "=", "3", ",", "num_act", "=", "None", ",", "chs_decay", "=", "0.5", ",", "layers", ":", "LayerFn", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "stride", "in", "(", "2", ",", "4", ")", "\n", "layers", "=", "layers", "or", "LayerFn", "(", ")", "\n", "\n", "if", "isinstance", "(", "out_chs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "num_rep", "=", "len", "(", "out_chs", ")", "\n", "stem_chs", "=", "out_chs", "\n", "", "else", ":", "\n", "            ", "stem_chs", "=", "[", "round", "(", "out_chs", "*", "chs_decay", "**", "i", ")", "for", "i", "in", "range", "(", "num_rep", ")", "]", "[", ":", ":", "-", "1", "]", "\n", "\n", "", "self", ".", "stride", "=", "stride", "\n", "self", ".", "feature_info", "=", "[", "]", "# track intermediate features", "\n", "prev_feat", "=", "''", "\n", "stem_strides", "=", "[", "2", "]", "+", "[", "1", "]", "*", "(", "num_rep", "-", "1", ")", "\n", "if", "stride", "==", "4", "and", "not", "pool", ":", "\n", "# set last conv in stack to be strided if stride == 4 and no pooling layer", "\n", "            ", "stem_strides", "[", "-", "1", "]", "=", "2", "\n", "\n", "", "num_act", "=", "num_rep", "if", "num_act", "is", "None", "else", "num_act", "\n", "# if num_act < num_rep, first convs in stack won't have bn + act", "\n", "stem_norm_acts", "=", "[", "False", "]", "*", "(", "num_rep", "-", "num_act", ")", "+", "[", "True", "]", "*", "num_act", "\n", "prev_chs", "=", "in_chs", "\n", "curr_stride", "=", "1", "\n", "for", "i", ",", "(", "ch", ",", "s", ",", "na", ")", "in", "enumerate", "(", "zip", "(", "stem_chs", ",", "stem_strides", ",", "stem_norm_acts", ")", ")", ":", "\n", "            ", "layer_fn", "=", "layers", ".", "conv_norm_act", "if", "na", "else", "create_conv2d", "\n", "conv_name", "=", "f'conv{i + 1}'", "\n", "if", "i", ">", "0", "and", "s", ">", "1", ":", "\n", "                ", "self", ".", "feature_info", ".", "append", "(", "dict", "(", "num_chs", "=", "prev_chs", ",", "reduction", "=", "curr_stride", ",", "module", "=", "prev_feat", ")", ")", "\n", "", "self", ".", "add_module", "(", "conv_name", ",", "layer_fn", "(", "prev_chs", ",", "ch", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "s", ")", ")", "\n", "prev_chs", "=", "ch", "\n", "curr_stride", "*=", "s", "\n", "prev_feat", "=", "conv_name", "\n", "\n", "", "if", "pool", "and", "'max'", "in", "pool", ".", "lower", "(", ")", ":", "\n", "            ", "self", ".", "feature_info", ".", "append", "(", "dict", "(", "num_chs", "=", "prev_chs", ",", "reduction", "=", "curr_stride", ",", "module", "=", "prev_feat", ")", ")", "\n", "self", ".", "add_module", "(", "'pool'", ",", "nn", ".", "MaxPool2d", "(", "3", ",", "2", ",", "1", ")", ")", "\n", "curr_stride", "*=", "2", "\n", "prev_feat", "=", "'pool'", "\n", "\n", "", "self", ".", "feature_info", ".", "append", "(", "dict", "(", "num_chs", "=", "prev_chs", ",", "reduction", "=", "curr_stride", ",", "module", "=", "prev_feat", ")", ")", "\n", "assert", "curr_stride", "==", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.ByobNet.__init__": [[1487, 1523], ["torch.Module.__init__", "byobnet.get_layer_fns", "int", "byobnet.create_byob_stem", "byobnet.ByobNet.feature_info.extend", "byobnet.reduce_feat_size", "byobnet.create_byob_stages", "byobnet.ByobNet.feature_info.extend", "get_layer_fns.ClassifierHead", "helpers.named_apply", "get_layer_fns.to_2tuple", "round", "int", "get_layer_fns.conv_norm_act", "torch.Identity", "torch.Identity", "dict", "functools.partial", "round"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.get_layer_fns", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.create_byob_stem", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.reduce_feat_size", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.create_byob_stages", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_apply"], ["def", "__init__", "(", "\n", "self", ",", "cfg", ":", "ByoModelCfg", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "global_pool", "=", "'avg'", ",", "output_stride", "=", "32", ",", "\n", "zero_init_last", "=", "True", ",", "img_size", "=", "None", ",", "drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "layers", "=", "get_layer_fns", "(", "cfg", ")", "\n", "if", "cfg", ".", "fixed_input_size", ":", "\n", "            ", "assert", "img_size", "is", "not", "None", ",", "'img_size argument is required for fixed input size model'", "\n", "", "feat_size", "=", "to_2tuple", "(", "img_size", ")", "if", "img_size", "is", "not", "None", "else", "None", "\n", "\n", "self", ".", "feature_info", "=", "[", "]", "\n", "stem_chs", "=", "int", "(", "round", "(", "(", "cfg", ".", "stem_chs", "or", "cfg", ".", "blocks", "[", "0", "]", ".", "c", ")", "*", "cfg", ".", "width_factor", ")", ")", "\n", "self", ".", "stem", ",", "stem_feat", "=", "create_byob_stem", "(", "in_chans", ",", "stem_chs", ",", "cfg", ".", "stem_type", ",", "cfg", ".", "stem_pool", ",", "layers", "=", "layers", ")", "\n", "self", ".", "feature_info", ".", "extend", "(", "stem_feat", "[", ":", "-", "1", "]", ")", "\n", "feat_size", "=", "reduce_feat_size", "(", "feat_size", ",", "stride", "=", "stem_feat", "[", "-", "1", "]", "[", "'reduction'", "]", ")", "\n", "\n", "self", ".", "stages", ",", "stage_feat", "=", "create_byob_stages", "(", "\n", "cfg", ",", "drop_path_rate", ",", "output_stride", ",", "stem_feat", "[", "-", "1", "]", ",", "layers", "=", "layers", ",", "feat_size", "=", "feat_size", ")", "\n", "self", ".", "feature_info", ".", "extend", "(", "stage_feat", "[", ":", "-", "1", "]", ")", "\n", "\n", "prev_chs", "=", "stage_feat", "[", "-", "1", "]", "[", "'num_chs'", "]", "\n", "if", "cfg", ".", "num_features", ":", "\n", "            ", "self", ".", "num_features", "=", "int", "(", "round", "(", "cfg", ".", "width_factor", "*", "cfg", ".", "num_features", ")", ")", "\n", "self", ".", "final_conv", "=", "layers", ".", "conv_norm_act", "(", "prev_chs", ",", "self", ".", "num_features", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_features", "=", "prev_chs", "\n", "self", ".", "final_conv", "=", "nn", ".", "Identity", "(", ")", "\n", "", "self", ".", "feature_info", "+=", "[", "\n", "dict", "(", "num_chs", "=", "self", ".", "num_features", ",", "reduction", "=", "stage_feat", "[", "-", "1", "]", "[", "'reduction'", "]", ",", "module", "=", "'final_conv'", ")", "]", "\n", "\n", "self", ".", "head", "=", "ClassifierHead", "(", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "self", ".", "drop_rate", ")", "\n", "\n", "# init weights", "\n", "named_apply", "(", "partial", "(", "_init_weights", ",", "zero_init_last", "=", "zero_init_last", ")", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.ByobNet.group_matcher": [[1524, 1534], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem", "=", "r'^stem'", ",", "\n", "blocks", "=", "[", "\n", "(", "r'^stages\\.(\\d+)'", "if", "coarse", "else", "r'^stages\\.(\\d+)\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^final_conv'", ",", "(", "99999", ",", ")", ")", "\n", "]", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.ByobNet.set_grad_checkpointing": [[1535, 1538], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.ByobNet.get_classifier": [[1539, 1542], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.ByobNet.reset_classifier": [[1543, 1545], ["layers.ClassifierHead"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "head", "=", "ClassifierHead", "(", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "self", ".", "drop_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.ByobNet.forward_features": [[1546, 1554], ["byobnet.ByobNet.stem", "byobnet.ByobNet.final_conv", "helpers.checkpoint_seq", "byobnet.ByobNet.stages", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.stages"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "stages", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "stages", "(", "x", ")", "\n", "", "x", "=", "self", ".", "final_conv", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.ByobNet.forward_head": [[1555, 1557], ["byobnet.ByobNet.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "head", "(", "x", ",", "pre_logits", "=", "pre_logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.ByobNet.forward": [[1558, 1562], ["byobnet.ByobNet.forward_features", "byobnet.ByobNet.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._cfg": [[45, 52], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bilinear'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'stem.conv'", ",", "'classifier'", ":", "'head.fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._cfgr": [[55, 62], ["None"], "function", ["None"], ["", "def", "_cfgr", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "256", ",", "256", ")", ",", "'pool_size'", ":", "(", "8", ",", "8", ")", ",", "\n", "'crop_pct'", ":", "0.9", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'stem.conv1.conv'", ",", "'classifier'", ":", "'head.fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._rep_vgg_bcfg": [[211, 218], ["tuple", "byobnet.ByoBlockCfg", "zip"], "function", ["None"], ["", "def", "_rep_vgg_bcfg", "(", "d", "=", "(", "4", ",", "6", ",", "16", ",", "1", ")", ",", "wf", "=", "(", "1.", ",", "1.", ",", "1.", ",", "1.", ")", ",", "groups", "=", "0", ")", ":", "\n", "    ", "c", "=", "(", "64", ",", "128", ",", "256", ",", "512", ")", "\n", "group_size", "=", "0", "\n", "if", "groups", ">", "0", ":", "\n", "        ", "group_size", "=", "lambda", "chs", ",", "idx", ":", "chs", "//", "groups", "if", "(", "idx", "+", "1", ")", "%", "2", "==", "0", "else", "0", "\n", "", "bcfg", "=", "tuple", "(", "[", "ByoBlockCfg", "(", "type", "=", "'rep'", ",", "d", "=", "d", ",", "c", "=", "c", "*", "wf", ",", "gs", "=", "group_size", ")", "for", "d", ",", "c", ",", "wf", "in", "zip", "(", "d", ",", "c", ",", "wf", ")", "]", ")", "\n", "return", "bcfg", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.interleave_blocks": [[220, 236], ["isinstance", "set", "range", "tuple", "len", "list", "range", "byobnet.ByoBlockCfg"], "function", ["None"], ["", "def", "interleave_blocks", "(", "\n", "types", ":", "Tuple", "[", "str", ",", "str", "]", ",", "d", ",", "every", ":", "Union", "[", "int", ",", "List", "[", "int", "]", "]", "=", "1", ",", "first", ":", "bool", "=", "False", ",", "**", "kwargs", "\n", ")", "->", "Tuple", "[", "ByoBlockCfg", "]", ":", "\n", "    ", "\"\"\" interleave 2 block types in stack\n    \"\"\"", "\n", "assert", "len", "(", "types", ")", "==", "2", "\n", "if", "isinstance", "(", "every", ",", "int", ")", ":", "\n", "        ", "every", "=", "list", "(", "range", "(", "0", "if", "first", "else", "every", ",", "d", ",", "every", "+", "1", ")", ")", "\n", "if", "not", "every", ":", "\n", "            ", "every", "=", "[", "d", "-", "1", "]", "\n", "", "", "set", "(", "every", ")", "\n", "blocks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "d", ")", ":", "\n", "        ", "block_type", "=", "types", "[", "1", "]", "if", "i", "in", "every", "else", "types", "[", "0", "]", "\n", "blocks", "+=", "[", "ByoBlockCfg", "(", "type", "=", "block_type", ",", "d", "=", "1", ",", "**", "kwargs", ")", "]", "\n", "", "return", "tuple", "(", "blocks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.gernet_l": [[661, 667], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["@", "register_model", "\n", "def", "gernet_l", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" GEResNet-Large (GENet-Large from official impl)\n    `Neural Architecture Design for GPU-Efficient Networks` - https://arxiv.org/abs/2006.14090\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'gernet_l'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.gernet_m": [[669, 675], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "gernet_m", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" GEResNet-Medium (GENet-Normal from official impl)\n    `Neural Architecture Design for GPU-Efficient Networks` - https://arxiv.org/abs/2006.14090\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'gernet_m'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.gernet_s": [[677, 683], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "gernet_s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" EResNet-Small (GENet-Small from official impl)\n    `Neural Architecture Design for GPU-Efficient Networks` - https://arxiv.org/abs/2006.14090\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'gernet_s'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.repvgg_a2": [[685, 691], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "repvgg_a2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" RepVGG-A2\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'repvgg_a2'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.repvgg_b0": [[693, 699], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "repvgg_b0", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" RepVGG-B0\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'repvgg_b0'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.repvgg_b1": [[701, 707], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "repvgg_b1", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" RepVGG-B1\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'repvgg_b1'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.repvgg_b1g4": [[709, 715], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "repvgg_b1g4", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" RepVGG-B1g4\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'repvgg_b1g4'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.repvgg_b2": [[717, 723], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "repvgg_b2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" RepVGG-B2\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'repvgg_b2'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.repvgg_b2g4": [[725, 731], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "repvgg_b2g4", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" RepVGG-B2g4\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'repvgg_b2g4'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.repvgg_b3": [[733, 739], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "repvgg_b3", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" RepVGG-B3\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'repvgg_b3'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.repvgg_b3g4": [[741, 747], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "repvgg_b3g4", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" RepVGG-B3g4\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'repvgg_b3g4'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.resnet51q": [[749, 754], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "resnet51q", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'resnet51q'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.resnet61q": [[756, 761], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "resnet61q", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'resnet61q'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.resnext26ts": [[763, 768], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "resnext26ts", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'resnext26ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.gcresnext26ts": [[770, 775], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "gcresnext26ts", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'gcresnext26ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.seresnext26ts": [[777, 782], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "seresnext26ts", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'seresnext26ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.eca_resnext26ts": [[784, 789], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "eca_resnext26ts", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'eca_resnext26ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.bat_resnext26ts": [[791, 796], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "bat_resnext26ts", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'bat_resnext26ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.resnet32ts": [[798, 803], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "resnet32ts", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'resnet32ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.resnet33ts": [[805, 810], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "resnet33ts", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'resnet33ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.gcresnet33ts": [[812, 817], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "gcresnet33ts", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'gcresnet33ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.seresnet33ts": [[819, 824], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "seresnet33ts", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'seresnet33ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.eca_resnet33ts": [[826, 831], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "eca_resnet33ts", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'eca_resnet33ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.gcresnet50t": [[833, 838], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "gcresnet50t", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'gcresnet50t'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.gcresnext50ts": [[840, 845], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "gcresnext50ts", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'gcresnext50ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.regnetz_b16": [[847, 852], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "regnetz_b16", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'regnetz_b16'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.regnetz_c16": [[854, 859], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "regnetz_c16", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'regnetz_c16'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.regnetz_d32": [[861, 866], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "regnetz_d32", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'regnetz_d32'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.regnetz_d8": [[868, 873], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "regnetz_d8", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'regnetz_d8'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.regnetz_e8": [[875, 880], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "regnetz_e8", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'regnetz_e8'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.regnetz_b16_evos": [[882, 887], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "regnetz_b16_evos", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'regnetz_b16_evos'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.regnetz_c16_evos": [[889, 894], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "regnetz_c16_evos", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'regnetz_c16_evos'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.regnetz_d8_evos": [[896, 901], ["byobnet._create_byobnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet"], ["", "@", "register_model", "\n", "def", "regnetz_d8_evos", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "return", "_create_byobnet", "(", "'regnetz_d8_evos'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.expand_blocks_cfg": [[903, 910], ["enumerate", "isinstance", "dataclasses.replace", "range"], "function", ["None"], ["", "def", "expand_blocks_cfg", "(", "stage_blocks_cfg", ":", "Union", "[", "ByoBlockCfg", ",", "Sequence", "[", "ByoBlockCfg", "]", "]", ")", "->", "List", "[", "ByoBlockCfg", "]", ":", "\n", "    ", "if", "not", "isinstance", "(", "stage_blocks_cfg", ",", "Sequence", ")", ":", "\n", "        ", "stage_blocks_cfg", "=", "(", "stage_blocks_cfg", ",", ")", "\n", "", "block_cfgs", "=", "[", "]", "\n", "for", "i", ",", "cfg", "in", "enumerate", "(", "stage_blocks_cfg", ")", ":", "\n", "        ", "block_cfgs", "+=", "[", "replace", "(", "cfg", ",", "d", "=", "1", ")", "for", "_", "in", "range", "(", "cfg", ".", "d", ")", "]", "\n", "", "return", "block_cfgs", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.num_groups": [[912, 919], ["None"], "function", ["None"], ["", "def", "num_groups", "(", "group_size", ",", "channels", ")", ":", "\n", "    ", "if", "not", "group_size", ":", "# 0 or None", "\n", "        ", "return", "1", "# normal conv with 1 group", "\n", "", "else", ":", "\n", "# NOTE group_size == 1 -> depthwise conv", "\n", "        ", "assert", "channels", "%", "group_size", "==", "0", "\n", "return", "channels", "//", "group_size", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.create_shortcut": [[947, 958], ["torch.Identity", "byobnet.DownsampleAvg", "layers.conv_norm_act"], "function", ["None"], ["", "", "def", "create_shortcut", "(", "downsample_type", ",", "layers", ":", "LayerFn", ",", "in_chs", ",", "out_chs", ",", "stride", ",", "dilation", ",", "**", "kwargs", ")", ":", "\n", "    ", "assert", "downsample_type", "in", "(", "'avg'", ",", "'conv1x1'", ",", "''", ")", "\n", "if", "in_chs", "!=", "out_chs", "or", "stride", "!=", "1", "or", "dilation", "[", "0", "]", "!=", "dilation", "[", "1", "]", ":", "\n", "        ", "if", "not", "downsample_type", ":", "\n", "            ", "return", "None", "# no shortcut", "\n", "", "elif", "downsample_type", "==", "'avg'", ":", "\n", "            ", "return", "DownsampleAvg", "(", "in_chs", ",", "out_chs", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", "[", "0", "]", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "layers", ".", "conv_norm_act", "(", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", "[", "0", "]", ",", "**", "kwargs", ")", "\n", "", "", "else", ":", "\n", "        ", "return", "nn", ".", "Identity", "(", ")", "# identity shortcut", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.register_block": [[1263, 1265], ["None"], "function", ["None"], ["def", "register_block", "(", "block_type", ":", "str", ",", "block_fn", ":", "nn", ".", "Module", ")", ":", "\n", "    ", "_block_registry", "[", "block_type", "]", "=", "block_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.create_block": [[1267, 1272], ["isinstance", "block"], "function", ["None"], ["", "def", "create_block", "(", "block", ":", "Union", "[", "str", ",", "nn", ".", "Module", "]", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "isinstance", "(", "block", ",", "(", "nn", ".", "Module", ",", "partial", ")", ")", ":", "\n", "        ", "return", "block", "(", "**", "kwargs", ")", "\n", "", "assert", "block", "in", "_block_registry", ",", "f'Unknown block type ({block}'", "\n", "return", "_block_registry", "[", "block", "]", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.create_byob_stem": [[1322, 1355], ["isinstance", "byobnet.LayerFn", "byobnet.Stem", "byobnet.Stem", "dict", "dict", "byobnet.Stem", "byobnet.RepVggBlock", "byobnet.Stem", "layers.conv_norm_act", "byobnet.Stem", "layers.conv_norm_act"], "function", ["None"], ["", "", "def", "create_byob_stem", "(", "in_chs", ",", "out_chs", ",", "stem_type", "=", "''", ",", "pool_type", "=", "''", ",", "feat_prefix", "=", "'stem'", ",", "layers", ":", "LayerFn", "=", "None", ")", ":", "\n", "    ", "layers", "=", "layers", "or", "LayerFn", "(", ")", "\n", "assert", "stem_type", "in", "(", "''", ",", "'quad'", ",", "'quad2'", ",", "'tiered'", ",", "'deep'", ",", "'rep'", ",", "'7x7'", ",", "'3x3'", ")", "\n", "if", "'quad'", "in", "stem_type", ":", "\n", "# based on NFNet stem, stack of 4 3x3 convs", "\n", "        ", "num_act", "=", "2", "if", "'quad2'", "in", "stem_type", "else", "None", "\n", "stem", "=", "Stem", "(", "in_chs", ",", "out_chs", ",", "num_rep", "=", "4", ",", "num_act", "=", "num_act", ",", "pool", "=", "pool_type", ",", "layers", "=", "layers", ")", "\n", "", "elif", "'tiered'", "in", "stem_type", ":", "\n", "# 3x3 stack of 3 convs as in my ResNet-T", "\n", "        ", "stem", "=", "Stem", "(", "in_chs", ",", "(", "3", "*", "out_chs", "//", "8", ",", "out_chs", "//", "2", ",", "out_chs", ")", ",", "pool", "=", "pool_type", ",", "layers", "=", "layers", ")", "\n", "", "elif", "'deep'", "in", "stem_type", ":", "\n", "# 3x3 stack of 3 convs as in ResNet-D", "\n", "        ", "stem", "=", "Stem", "(", "in_chs", ",", "out_chs", ",", "num_rep", "=", "3", ",", "chs_decay", "=", "1.0", ",", "pool", "=", "pool_type", ",", "layers", "=", "layers", ")", "\n", "", "elif", "'rep'", "in", "stem_type", ":", "\n", "        ", "stem", "=", "RepVggBlock", "(", "in_chs", ",", "out_chs", ",", "stride", "=", "2", ",", "layers", "=", "layers", ")", "\n", "", "elif", "'7x7'", "in", "stem_type", ":", "\n", "# 7x7 stem conv as in ResNet", "\n", "        ", "if", "pool_type", ":", "\n", "            ", "stem", "=", "Stem", "(", "in_chs", ",", "out_chs", ",", "7", ",", "num_rep", "=", "1", ",", "pool", "=", "pool_type", ",", "layers", "=", "layers", ")", "\n", "", "else", ":", "\n", "            ", "stem", "=", "layers", ".", "conv_norm_act", "(", "in_chs", ",", "out_chs", ",", "7", ",", "stride", "=", "2", ")", "\n", "", "", "else", ":", "\n", "# 3x3 stem conv as in RegNet is the default", "\n", "        ", "if", "pool_type", ":", "\n", "            ", "stem", "=", "Stem", "(", "in_chs", ",", "out_chs", ",", "3", ",", "num_rep", "=", "1", ",", "pool", "=", "pool_type", ",", "layers", "=", "layers", ")", "\n", "", "else", ":", "\n", "            ", "stem", "=", "layers", ".", "conv_norm_act", "(", "in_chs", ",", "out_chs", ",", "3", ",", "stride", "=", "2", ")", "\n", "\n", "", "", "if", "isinstance", "(", "stem", ",", "Stem", ")", ":", "\n", "        ", "feature_info", "=", "[", "dict", "(", "f", ",", "module", "=", "'.'", ".", "join", "(", "[", "feat_prefix", ",", "f", "[", "'module'", "]", "]", ")", ")", "for", "f", "in", "stem", ".", "feature_info", "]", "\n", "", "else", ":", "\n", "        ", "feature_info", "=", "[", "dict", "(", "num_chs", "=", "out_chs", ",", "reduction", "=", "2", ",", "module", "=", "feat_prefix", ")", "]", "\n", "", "return", "stem", ",", "feature_info", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.reduce_feat_size": [[1357, 1359], ["tuple"], "function", ["None"], ["", "def", "reduce_feat_size", "(", "feat_size", ",", "stride", "=", "2", ")", ":", "\n", "    ", "return", "None", "if", "feat_size", "is", "None", "else", "tuple", "(", "[", "s", "//", "stride", "for", "s", "in", "feat_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.override_kwargs": [[1361, 1371], ["None"], "function", ["None"], ["", "def", "override_kwargs", "(", "block_kwargs", ",", "model_kwargs", ")", ":", "\n", "    ", "\"\"\" Override model level attn/self-attn/block kwargs w/ block level\n\n    NOTE: kwargs are NOT merged across levels, block_kwargs will fully replace model_kwargs\n    for the block if set to anything that isn't None.\n\n    i.e. an empty block_kwargs dict will remove kwargs set at model level for that block\n    \"\"\"", "\n", "out_kwargs", "=", "block_kwargs", "if", "block_kwargs", "is", "not", "None", "else", "model_kwargs", "\n", "return", "out_kwargs", "or", "{", "}", "# make sure None isn't returned", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.update_block_kwargs": [[1373, 1407], ["block_kwargs.update", "dataclasses.replace", "dataclasses.replace", "byobnet.override_kwargs", "byobnet.override_kwargs", "byobnet.override_kwargs", "functools.partial", "functools.partial", "layers.get_attn", "layers.get_attn"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.override_kwargs", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.override_kwargs", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.override_kwargs", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.get_attn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.get_attn"], ["", "def", "update_block_kwargs", "(", "block_kwargs", ":", "Dict", "[", "str", ",", "Any", "]", ",", "block_cfg", ":", "ByoBlockCfg", ",", "model_cfg", ":", "ByoModelCfg", ",", ")", ":", "\n", "    ", "layer_fns", "=", "block_kwargs", "[", "'layers'", "]", "\n", "\n", "# override attn layer / args with block local config", "\n", "attn_set", "=", "block_cfg", ".", "attn_layer", "is", "not", "None", "\n", "if", "attn_set", "or", "block_cfg", ".", "attn_kwargs", "is", "not", "None", ":", "\n", "# override attn layer config", "\n", "        ", "if", "attn_set", "and", "not", "block_cfg", ".", "attn_layer", ":", "\n", "# empty string for attn_layer type will disable attn for this block", "\n", "            ", "attn_layer", "=", "None", "\n", "", "else", ":", "\n", "            ", "attn_kwargs", "=", "override_kwargs", "(", "block_cfg", ".", "attn_kwargs", ",", "model_cfg", ".", "attn_kwargs", ")", "\n", "attn_layer", "=", "block_cfg", ".", "attn_layer", "or", "model_cfg", ".", "attn_layer", "\n", "attn_layer", "=", "partial", "(", "get_attn", "(", "attn_layer", ")", ",", "**", "attn_kwargs", ")", "if", "attn_layer", "is", "not", "None", "else", "None", "\n", "", "layer_fns", "=", "replace", "(", "layer_fns", ",", "attn", "=", "attn_layer", ")", "\n", "\n", "# override self-attn layer / args with block local cfg", "\n", "", "self_attn_set", "=", "block_cfg", ".", "self_attn_layer", "is", "not", "None", "\n", "if", "self_attn_set", "or", "block_cfg", ".", "self_attn_kwargs", "is", "not", "None", ":", "\n", "# override attn layer config", "\n", "        ", "if", "self_attn_set", "and", "not", "block_cfg", ".", "self_attn_layer", ":", "# attn_layer == ''", "\n", "# empty string for self_attn_layer type will disable attn for this block", "\n", "            ", "self_attn_layer", "=", "None", "\n", "", "else", ":", "\n", "            ", "self_attn_kwargs", "=", "override_kwargs", "(", "block_cfg", ".", "self_attn_kwargs", ",", "model_cfg", ".", "self_attn_kwargs", ")", "\n", "self_attn_layer", "=", "block_cfg", ".", "self_attn_layer", "or", "model_cfg", ".", "self_attn_layer", "\n", "self_attn_layer", "=", "partial", "(", "get_attn", "(", "self_attn_layer", ")", ",", "**", "self_attn_kwargs", ")", "if", "self_attn_layer", "is", "not", "None", "else", "None", "\n", "", "layer_fns", "=", "replace", "(", "layer_fns", ",", "self_attn", "=", "self_attn_layer", ")", "\n", "\n", "", "block_kwargs", "[", "'layers'", "]", "=", "layer_fns", "\n", "\n", "# add additional block_kwargs specified in block_cfg or model_cfg, precedence to block if set", "\n", "block_kwargs", ".", "update", "(", "override_kwargs", "(", "block_cfg", ".", "block_kwargs", ",", "model_cfg", ".", "block_kwargs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.create_byob_stages": [[1409, 1467], ["enumerate", "feature_info.append", "byobnet.LayerFn", "byobnet.expand_blocks_cfg", "sum", "x.tolist", "enumerate", "dict", "torch.Sequential", "torch.linspace().split", "torch.linspace().split", "feature_info.append", "layers.make_divisible", "isinstance", "dict", "block_kwargs_fn", "torch.Sequential", "group_size.", "byobnet.create_block", "byobnet.reduce_feat_size", "torch.linspace", "torch.linspace", "sum"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.expand_blocks_cfg", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.create_block", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.reduce_feat_size"], ["", "def", "create_byob_stages", "(", "\n", "cfg", ":", "ByoModelCfg", ",", "drop_path_rate", ":", "float", ",", "output_stride", ":", "int", ",", "stem_feat", ":", "Dict", "[", "str", ",", "Any", "]", ",", "\n", "feat_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "layers", ":", "Optional", "[", "LayerFn", "]", "=", "None", ",", "\n", "block_kwargs_fn", ":", "Optional", "[", "Callable", "]", "=", "update_block_kwargs", ")", ":", "\n", "\n", "    ", "layers", "=", "layers", "or", "LayerFn", "(", ")", "\n", "feature_info", "=", "[", "]", "\n", "block_cfgs", "=", "[", "expand_blocks_cfg", "(", "s", ")", "for", "s", "in", "cfg", ".", "blocks", "]", "\n", "depths", "=", "[", "sum", "(", "[", "bc", ".", "d", "for", "bc", "in", "stage_bcs", "]", ")", "for", "stage_bcs", "in", "block_cfgs", "]", "\n", "dpr", "=", "[", "x", ".", "tolist", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "sum", "(", "depths", ")", ")", ".", "split", "(", "depths", ")", "]", "\n", "dilation", "=", "1", "\n", "net_stride", "=", "stem_feat", "[", "'reduction'", "]", "\n", "prev_chs", "=", "stem_feat", "[", "'num_chs'", "]", "\n", "prev_feat", "=", "stem_feat", "\n", "stages", "=", "[", "]", "\n", "for", "stage_idx", ",", "stage_block_cfgs", "in", "enumerate", "(", "block_cfgs", ")", ":", "\n", "        ", "stride", "=", "stage_block_cfgs", "[", "0", "]", ".", "s", "\n", "if", "stride", "!=", "1", "and", "prev_feat", ":", "\n", "            ", "feature_info", ".", "append", "(", "prev_feat", ")", "\n", "", "if", "net_stride", ">=", "output_stride", "and", "stride", ">", "1", ":", "\n", "            ", "dilation", "*=", "stride", "\n", "stride", "=", "1", "\n", "", "net_stride", "*=", "stride", "\n", "first_dilation", "=", "1", "if", "dilation", "in", "(", "1", ",", "2", ")", "else", "2", "\n", "\n", "blocks", "=", "[", "]", "\n", "for", "block_idx", ",", "block_cfg", "in", "enumerate", "(", "stage_block_cfgs", ")", ":", "\n", "            ", "out_chs", "=", "make_divisible", "(", "block_cfg", ".", "c", "*", "cfg", ".", "width_factor", ")", "\n", "group_size", "=", "block_cfg", ".", "gs", "\n", "if", "isinstance", "(", "group_size", ",", "Callable", ")", ":", "\n", "                ", "group_size", "=", "group_size", "(", "out_chs", ",", "block_idx", ")", "\n", "", "block_kwargs", "=", "dict", "(", "# Blocks used in this model must accept these arguments", "\n", "in_chs", "=", "prev_chs", ",", "\n", "out_chs", "=", "out_chs", ",", "\n", "stride", "=", "stride", "if", "block_idx", "==", "0", "else", "1", ",", "\n", "dilation", "=", "(", "first_dilation", ",", "dilation", ")", ",", "\n", "group_size", "=", "group_size", ",", "\n", "bottle_ratio", "=", "block_cfg", ".", "br", ",", "\n", "downsample", "=", "cfg", ".", "downsample", ",", "\n", "drop_path_rate", "=", "dpr", "[", "stage_idx", "]", "[", "block_idx", "]", ",", "\n", "layers", "=", "layers", ",", "\n", ")", "\n", "if", "block_cfg", ".", "type", "in", "(", "'self_attn'", ",", ")", ":", "\n", "# add feat_size arg for blocks that support/need it", "\n", "                ", "block_kwargs", "[", "'feat_size'", "]", "=", "feat_size", "\n", "", "block_kwargs_fn", "(", "block_kwargs", ",", "block_cfg", "=", "block_cfg", ",", "model_cfg", "=", "cfg", ")", "\n", "blocks", "+=", "[", "create_block", "(", "block_cfg", ".", "type", ",", "**", "block_kwargs", ")", "]", "\n", "first_dilation", "=", "dilation", "\n", "prev_chs", "=", "out_chs", "\n", "if", "stride", ">", "1", "and", "block_idx", "==", "0", ":", "\n", "                ", "feat_size", "=", "reduce_feat_size", "(", "feat_size", ",", "stride", ")", "\n", "\n", "", "", "stages", "+=", "[", "nn", ".", "Sequential", "(", "*", "blocks", ")", "]", "\n", "prev_feat", "=", "dict", "(", "num_chs", "=", "prev_chs", ",", "reduction", "=", "net_stride", ",", "module", "=", "f'stages.{stage_idx}'", ")", "\n", "\n", "", "feature_info", ".", "append", "(", "prev_feat", ")", "\n", "return", "nn", ".", "Sequential", "(", "*", "stages", ")", ",", "feature_info", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet.get_layer_fns": [[1469, 1477], ["layers.get_act_layer", "layers.get_norm_act_layer", "functools.partial", "byobnet.LayerFn", "functools.partial", "functools.partial", "layers.get_attn", "layers.get_attn"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.get_attn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.get_attn"], ["", "def", "get_layer_fns", "(", "cfg", ":", "ByoModelCfg", ")", ":", "\n", "    ", "act", "=", "get_act_layer", "(", "cfg", ".", "act_layer", ")", "\n", "norm_act", "=", "get_norm_act_layer", "(", "norm_layer", "=", "cfg", ".", "norm_layer", ",", "act_layer", "=", "act", ")", "\n", "conv_norm_act", "=", "partial", "(", "ConvNormAct", ",", "norm_layer", "=", "cfg", ".", "norm_layer", ",", "act_layer", "=", "act", ")", "\n", "attn", "=", "partial", "(", "get_attn", "(", "cfg", ".", "attn_layer", ")", ",", "**", "cfg", ".", "attn_kwargs", ")", "if", "cfg", ".", "attn_layer", "else", "None", "\n", "self_attn", "=", "partial", "(", "get_attn", "(", "cfg", ".", "self_attn_layer", ")", ",", "**", "cfg", ".", "self_attn_kwargs", ")", "if", "cfg", ".", "self_attn_layer", "else", "None", "\n", "layer_fn", "=", "LayerFn", "(", "conv_norm_act", "=", "conv_norm_act", ",", "norm_act", "=", "norm_act", ",", "act", "=", "act", ",", "attn", "=", "attn", ",", "self_attn", "=", "self_attn", ")", "\n", "return", "layer_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._init_weights": [[1564, 1580], ["isinstance", "module.weight.data.normal_", "isinstance", "math.sqrt", "module.bias.data.zero_", "torch.init.normal_", "isinstance", "torch.init.zeros_", "torch.init.ones_", "torch.init.zeros_", "hasattr", "module.init_weights"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.GluMlp.init_weights"], ["", "", "def", "_init_weights", "(", "module", ",", "name", "=", "''", ",", "zero_init_last", "=", "False", ")", ":", "\n", "    ", "if", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", ":", "\n", "        ", "fan_out", "=", "module", ".", "kernel_size", "[", "0", "]", "*", "module", ".", "kernel_size", "[", "1", "]", "*", "module", ".", "out_channels", "\n", "fan_out", "//=", "module", ".", "groups", "\n", "module", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.0", "/", "fan_out", ")", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "module", ".", "weight", ",", "mean", "=", "0.0", ",", "std", "=", "0.01", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "nn", ".", "init", ".", "ones_", "(", "module", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "", "elif", "hasattr", "(", "module", ",", "'init_weights'", ")", ":", "\n", "        ", "module", ".", "init_weights", "(", "zero_init_last", "=", "zero_init_last", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byobnet._create_byobnet": [[1582, 1588], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_byobnet", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "\n", "ByobNet", ",", "variant", ",", "pretrained", ",", "\n", "model_cfg", "=", "model_cfgs", "[", "variant", "]", ",", "\n", "feature_cfg", "=", "dict", "(", "flatten_sequential", "=", "True", ")", ",", "\n", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.BasicConv2d.__init__": [[39, 45], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_planes", ",", "out_planes", ",", "kernel_size", ",", "stride", ",", "padding", "=", "0", ")", ":", "\n", "        ", "super", "(", "BasicConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "\n", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm2d", "(", "out_planes", ",", "eps", "=", ".001", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.BasicConv2d.forward": [[46, 51], ["inception_resnet_v2.BasicConv2d.conv", "inception_resnet_v2.BasicConv2d.bn", "inception_resnet_v2.BasicConv2d.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.Mixed_5b.__init__": [[54, 73], ["torch.Module.__init__", "inception_resnet_v2.BasicConv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "inception_resnet_v2.BasicConv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Mixed_5b", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "branch0", "=", "BasicConv2d", "(", "192", ",", "96", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "branch1", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "192", ",", "48", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "48", ",", "64", ",", "kernel_size", "=", "5", ",", "stride", "=", "1", ",", "padding", "=", "2", ")", "\n", ")", "\n", "\n", "self", ".", "branch2", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "192", ",", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "64", ",", "96", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "96", ",", "96", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", ")", "\n", "\n", "self", ".", "branch3", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "AvgPool2d", "(", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "count_include_pad", "=", "False", ")", ",", "\n", "BasicConv2d", "(", "192", ",", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.Mixed_5b.forward": [[75, 82], ["inception_resnet_v2.Mixed_5b.branch0", "inception_resnet_v2.Mixed_5b.branch1", "inception_resnet_v2.Mixed_5b.branch2", "inception_resnet_v2.Mixed_5b.branch3", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "x1", "=", "self", ".", "branch1", "(", "x", ")", "\n", "x2", "=", "self", ".", "branch2", "(", "x", ")", "\n", "x3", "=", "self", ".", "branch3", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ",", "x2", ",", "x3", ")", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.Block35.__init__": [[85, 105], ["torch.Module.__init__", "inception_resnet_v2.BasicConv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "scale", "=", "1.0", ")", ":", "\n", "        ", "super", "(", "Block35", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "branch0", "=", "BasicConv2d", "(", "320", ",", "32", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "branch1", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "320", ",", "32", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "32", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", ")", "\n", "\n", "self", ".", "branch2", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "320", ",", "32", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "32", ",", "48", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "48", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", ")", "\n", "\n", "self", ".", "conv2d", "=", "nn", ".", "Conv2d", "(", "128", ",", "320", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.Block35.forward": [[106, 115], ["inception_resnet_v2.Block35.branch0", "inception_resnet_v2.Block35.branch1", "inception_resnet_v2.Block35.branch2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception_resnet_v2.Block35.conv2d", "inception_resnet_v2.Block35.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "x1", "=", "self", ".", "branch1", "(", "x", ")", "\n", "x2", "=", "self", ".", "branch2", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ",", "x2", ")", ",", "1", ")", "\n", "out", "=", "self", ".", "conv2d", "(", "out", ")", "\n", "out", "=", "out", "*", "self", ".", "scale", "+", "x", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.Mixed_6a.__init__": [[118, 130], ["torch.Module.__init__", "inception_resnet_v2.BasicConv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Mixed_6a", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "branch0", "=", "BasicConv2d", "(", "320", ",", "384", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "\n", "self", ".", "branch1", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "320", ",", "256", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "256", ",", "384", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", ")", "\n", "\n", "self", ".", "branch2", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "stride", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.Mixed_6a.forward": [[131, 137], ["inception_resnet_v2.Mixed_6a.branch0", "inception_resnet_v2.Mixed_6a.branch1", "inception_resnet_v2.Mixed_6a.branch2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "x1", "=", "self", ".", "branch1", "(", "x", ")", "\n", "x2", "=", "self", ".", "branch2", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ",", "x2", ")", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.Block17.__init__": [[140, 155], ["torch.Module.__init__", "inception_resnet_v2.BasicConv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "scale", "=", "1.0", ")", ":", "\n", "        ", "super", "(", "Block17", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "branch0", "=", "BasicConv2d", "(", "1088", ",", "192", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "branch1", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "1088", ",", "128", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "128", ",", "160", ",", "kernel_size", "=", "(", "1", ",", "7", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "0", ",", "3", ")", ")", ",", "\n", "BasicConv2d", "(", "160", ",", "192", ",", "kernel_size", "=", "(", "7", ",", "1", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "3", ",", "0", ")", ")", "\n", ")", "\n", "\n", "self", ".", "conv2d", "=", "nn", ".", "Conv2d", "(", "384", ",", "1088", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.Block17.forward": [[156, 164], ["inception_resnet_v2.Block17.branch0", "inception_resnet_v2.Block17.branch1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception_resnet_v2.Block17.conv2d", "inception_resnet_v2.Block17.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "x1", "=", "self", ".", "branch1", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ")", ",", "1", ")", "\n", "out", "=", "self", ".", "conv2d", "(", "out", ")", "\n", "out", "=", "out", "*", "self", ".", "scale", "+", "x", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.Mixed_7a.__init__": [[167, 187], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Mixed_7a", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "branch0", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "1088", ",", "256", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "256", ",", "384", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", ")", "\n", "\n", "self", ".", "branch1", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "1088", ",", "256", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "256", ",", "288", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", ")", "\n", "\n", "self", ".", "branch2", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "1088", ",", "256", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "256", ",", "288", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "288", ",", "320", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", ")", "\n", "\n", "self", ".", "branch3", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "stride", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.Mixed_7a.forward": [[188, 195], ["inception_resnet_v2.Mixed_7a.branch0", "inception_resnet_v2.Mixed_7a.branch1", "inception_resnet_v2.Mixed_7a.branch2", "inception_resnet_v2.Mixed_7a.branch3", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "x1", "=", "self", ".", "branch1", "(", "x", ")", "\n", "x2", "=", "self", ".", "branch2", "(", "x", ")", "\n", "x3", "=", "self", ".", "branch3", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ",", "x2", ",", "x3", ")", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.Block8.__init__": [[199, 214], ["torch.Module.__init__", "inception_resnet_v2.BasicConv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "scale", "=", "1.0", ",", "no_relu", "=", "False", ")", ":", "\n", "        ", "super", "(", "Block8", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "branch0", "=", "BasicConv2d", "(", "2080", ",", "192", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "branch1", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "2080", ",", "192", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "192", ",", "224", ",", "kernel_size", "=", "(", "1", ",", "3", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "0", ",", "1", ")", ")", ",", "\n", "BasicConv2d", "(", "224", ",", "256", ",", "kernel_size", "=", "(", "3", ",", "1", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "1", ",", "0", ")", ")", "\n", ")", "\n", "\n", "self", ".", "conv2d", "=", "nn", ".", "Conv2d", "(", "448", ",", "2080", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "relu", "=", "None", "if", "no_relu", "else", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.Block8.forward": [[215, 224], ["inception_resnet_v2.Block8.branch0", "inception_resnet_v2.Block8.branch1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception_resnet_v2.Block8.conv2d", "inception_resnet_v2.Block8.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "x1", "=", "self", ".", "branch1", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ")", ",", "1", ")", "\n", "out", "=", "self", ".", "conv2d", "(", "out", ")", "\n", "out", "=", "out", "*", "self", ".", "scale", "+", "x", "\n", "if", "self", ".", "relu", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.InceptionResnetV2.__init__": [[227, 302], ["torch.Module.__init__", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "inception_resnet_v2.BasicConv2d", "inception_resnet_v2.BasicConv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "inception_resnet_v2.Mixed_5b", "torch.Sequential", "torch.Sequential", "torch.Sequential", "inception_resnet_v2.Mixed_6a", "torch.Sequential", "torch.Sequential", "torch.Sequential", "inception_resnet_v2.Mixed_7a", "torch.Sequential", "torch.Sequential", "torch.Sequential", "inception_resnet_v2.Block8", "inception_resnet_v2.BasicConv2d", "layers.create_classifier", "dict", "dict", "inception_resnet_v2.Block35", "inception_resnet_v2.Block35", "inception_resnet_v2.Block35", "inception_resnet_v2.Block35", "inception_resnet_v2.Block35", "inception_resnet_v2.Block35", "inception_resnet_v2.Block35", "inception_resnet_v2.Block35", "inception_resnet_v2.Block35", "inception_resnet_v2.Block35", "dict", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "inception_resnet_v2.Block17", "dict", "inception_resnet_v2.Block8", "inception_resnet_v2.Block8", "inception_resnet_v2.Block8", "inception_resnet_v2.Block8", "inception_resnet_v2.Block8", "inception_resnet_v2.Block8", "inception_resnet_v2.Block8", "inception_resnet_v2.Block8", "inception_resnet_v2.Block8", "dict"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["    ", "def", "__init__", "(", "self", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "drop_rate", "=", "0.", ",", "output_stride", "=", "32", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "super", "(", "InceptionResnetV2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_features", "=", "1536", "\n", "assert", "output_stride", "==", "32", "\n", "\n", "self", ".", "conv2d_1a", "=", "BasicConv2d", "(", "in_chans", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "self", ".", "conv2d_2a", "=", "BasicConv2d", "(", "32", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "self", ".", "conv2d_2b", "=", "BasicConv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "feature_info", "=", "[", "dict", "(", "num_chs", "=", "64", ",", "reduction", "=", "2", ",", "module", "=", "'conv2d_2b'", ")", "]", "\n", "\n", "self", ".", "maxpool_3a", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "stride", "=", "2", ")", "\n", "self", ".", "conv2d_3b", "=", "BasicConv2d", "(", "64", ",", "80", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "conv2d_4a", "=", "BasicConv2d", "(", "80", ",", "192", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "192", ",", "reduction", "=", "4", ",", "module", "=", "'conv2d_4a'", ")", "]", "\n", "\n", "self", ".", "maxpool_5a", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "stride", "=", "2", ")", "\n", "self", ".", "mixed_5b", "=", "Mixed_5b", "(", ")", "\n", "self", ".", "repeat", "=", "nn", ".", "Sequential", "(", "\n", "Block35", "(", "scale", "=", "0.17", ")", ",", "\n", "Block35", "(", "scale", "=", "0.17", ")", ",", "\n", "Block35", "(", "scale", "=", "0.17", ")", ",", "\n", "Block35", "(", "scale", "=", "0.17", ")", ",", "\n", "Block35", "(", "scale", "=", "0.17", ")", ",", "\n", "Block35", "(", "scale", "=", "0.17", ")", ",", "\n", "Block35", "(", "scale", "=", "0.17", ")", ",", "\n", "Block35", "(", "scale", "=", "0.17", ")", ",", "\n", "Block35", "(", "scale", "=", "0.17", ")", ",", "\n", "Block35", "(", "scale", "=", "0.17", ")", "\n", ")", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "320", ",", "reduction", "=", "8", ",", "module", "=", "'repeat'", ")", "]", "\n", "\n", "self", ".", "mixed_6a", "=", "Mixed_6a", "(", ")", "\n", "self", ".", "repeat_1", "=", "nn", ".", "Sequential", "(", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", "\n", ")", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "1088", ",", "reduction", "=", "16", ",", "module", "=", "'repeat_1'", ")", "]", "\n", "\n", "self", ".", "mixed_7a", "=", "Mixed_7a", "(", ")", "\n", "self", ".", "repeat_2", "=", "nn", ".", "Sequential", "(", "\n", "Block8", "(", "scale", "=", "0.20", ")", ",", "\n", "Block8", "(", "scale", "=", "0.20", ")", ",", "\n", "Block8", "(", "scale", "=", "0.20", ")", ",", "\n", "Block8", "(", "scale", "=", "0.20", ")", ",", "\n", "Block8", "(", "scale", "=", "0.20", ")", ",", "\n", "Block8", "(", "scale", "=", "0.20", ")", ",", "\n", "Block8", "(", "scale", "=", "0.20", ")", ",", "\n", "Block8", "(", "scale", "=", "0.20", ")", ",", "\n", "Block8", "(", "scale", "=", "0.20", ")", "\n", ")", "\n", "self", ".", "block8", "=", "Block8", "(", "no_relu", "=", "True", ")", "\n", "self", ".", "conv2d_7b", "=", "BasicConv2d", "(", "2080", ",", "self", ".", "num_features", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "self", ".", "num_features", ",", "reduction", "=", "32", ",", "module", "=", "'conv2d_7b'", ")", "]", "\n", "\n", "self", ".", "global_pool", ",", "self", ".", "classif", "=", "create_classifier", "(", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.InceptionResnetV2.group_matcher": [[303, 321], ["module_map.pop", "any", "enumerate", "any", "helpers.flatten_modules", "name.startswith", "any", "inception_resnet_v2.InceptionResnetV2.named_children", "name.startswith", "module_map.keys", "float", "name.startswith", "len", "tuple", "name.split", "len"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.flatten_modules"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "module_map", "=", "{", "k", ":", "i", "for", "i", ",", "(", "k", ",", "_", ")", "in", "enumerate", "(", "flatten_modules", "(", "self", ".", "named_children", "(", ")", ",", "prefix", "=", "(", ")", ")", ")", "}", "\n", "module_map", ".", "pop", "(", "(", "'classif'", ",", ")", ")", "\n", "\n", "def", "_matcher", "(", "name", ")", ":", "\n", "            ", "if", "any", "(", "[", "name", ".", "startswith", "(", "n", ")", "for", "n", "in", "(", "'conv2d_1'", ",", "'conv2d_2'", ")", "]", ")", ":", "\n", "                ", "return", "0", "\n", "", "elif", "any", "(", "[", "name", ".", "startswith", "(", "n", ")", "for", "n", "in", "(", "'conv2d_3'", ",", "'conv2d_4'", ")", "]", ")", ":", "\n", "                ", "return", "1", "\n", "", "elif", "any", "(", "[", "name", ".", "startswith", "(", "n", ")", "for", "n", "in", "(", "'block8'", ",", "'conv2d_7'", ")", "]", ")", ":", "\n", "                ", "return", "len", "(", "module_map", ")", "+", "1", "\n", "", "else", ":", "\n", "                ", "for", "k", "in", "module_map", ".", "keys", "(", ")", ":", "\n", "                    ", "if", "k", "==", "tuple", "(", "name", ".", "split", "(", "'.'", ")", "[", ":", "len", "(", "k", ")", "]", ")", ":", "\n", "                        ", "return", "module_map", "[", "k", "]", "\n", "", "", "return", "float", "(", "'inf'", ")", "\n", "", "", "return", "_matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.InceptionResnetV2.set_grad_checkpointing": [[322, 325], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "\"checkpointing not supported\"", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.InceptionResnetV2.get_classifier": [[326, 329], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "classif", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.InceptionResnetV2.reset_classifier": [[330, 333], ["layers.create_classifier"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "classif", "=", "create_classifier", "(", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.InceptionResnetV2.forward_features": [[334, 351], ["inception_resnet_v2.InceptionResnetV2.conv2d_1a", "inception_resnet_v2.InceptionResnetV2.conv2d_2a", "inception_resnet_v2.InceptionResnetV2.conv2d_2b", "inception_resnet_v2.InceptionResnetV2.maxpool_3a", "inception_resnet_v2.InceptionResnetV2.conv2d_3b", "inception_resnet_v2.InceptionResnetV2.conv2d_4a", "inception_resnet_v2.InceptionResnetV2.maxpool_5a", "inception_resnet_v2.InceptionResnetV2.mixed_5b", "inception_resnet_v2.InceptionResnetV2.repeat", "inception_resnet_v2.InceptionResnetV2.mixed_6a", "inception_resnet_v2.InceptionResnetV2.repeat_1", "inception_resnet_v2.InceptionResnetV2.mixed_7a", "inception_resnet_v2.InceptionResnetV2.repeat_2", "inception_resnet_v2.InceptionResnetV2.block8", "inception_resnet_v2.InceptionResnetV2.conv2d_7b"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv2d_1a", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2d_2a", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2d_2b", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool_3a", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2d_3b", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2d_4a", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool_5a", "(", "x", ")", "\n", "x", "=", "self", ".", "mixed_5b", "(", "x", ")", "\n", "x", "=", "self", ".", "repeat", "(", "x", ")", "\n", "x", "=", "self", ".", "mixed_6a", "(", "x", ")", "\n", "x", "=", "self", ".", "repeat_1", "(", "x", ")", "\n", "x", "=", "self", ".", "mixed_7a", "(", "x", ")", "\n", "x", "=", "self", ".", "repeat_2", "(", "x", ")", "\n", "x", "=", "self", ".", "block8", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2d_7b", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.InceptionResnetV2.forward_head": [[352, 357], ["inception_resnet_v2.InceptionResnetV2.global_pool", "torch.dropout", "torch.dropout", "torch.dropout", "inception_resnet_v2.InceptionResnetV2.classif"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ">", "0", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "classif", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.InceptionResnetV2.forward": [[358, 362], ["inception_resnet_v2.InceptionResnetV2.forward_features", "inception_resnet_v2.InceptionResnetV2.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2._create_inception_resnet_v2": [[364, 366], ["helpers.build_model_with_cfg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_inception_resnet_v2", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "InceptionResnetV2", ",", "variant", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.inception_resnet_v2": [[368, 374], ["inception_resnet_v2._create_inception_resnet_v2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2._create_inception_resnet_v2"], ["", "@", "register_model", "\n", "def", "inception_resnet_v2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"InceptionResnetV2 model architecture from the\n    `\"InceptionV4, Inception-ResNet...\" <https://arxiv.org/abs/1602.07261>` paper.\n    \"\"\"", "\n", "return", "_create_inception_resnet_v2", "(", "'inception_resnet_v2'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2.ens_adv_inception_resnet_v2": [[376, 383], ["inception_resnet_v2._create_inception_resnet_v2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.inception_resnet_v2._create_inception_resnet_v2"], ["", "@", "register_model", "\n", "def", "ens_adv_inception_resnet_v2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\" Ensemble Adversarially trained InceptionResnetV2 model architecture\n    As per https://arxiv.org/abs/1705.07204 and\n    https://github.com/tensorflow/models/tree/master/research/adv_imagenet_models.\n    \"\"\"", "\n", "return", "_create_inception_resnet_v2", "(", "'ens_adv_inception_resnet_v2'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.fx_features.FeatureGraphNet.__init__": [[69, 79], ["torch.nn.Module.__init__", "features._get_feature_info", "fx_features.create_feature_extractor", "len", "len", "enumerate"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features._get_feature_info", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.fx_features.create_feature_extractor"], ["def", "__init__", "(", "self", ",", "model", ",", "out_indices", ",", "out_map", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "has_fx_feature_extraction", ",", "'Please update to PyTorch 1.10+, torchvision 0.11+ for FX feature extraction'", "\n", "self", ".", "feature_info", "=", "_get_feature_info", "(", "model", ",", "out_indices", ")", "\n", "if", "out_map", "is", "not", "None", ":", "\n", "            ", "assert", "len", "(", "out_map", ")", "==", "len", "(", "out_indices", ")", "\n", "", "return_nodes", "=", "{", "\n", "info", "[", "'module'", "]", ":", "out_map", "[", "i", "]", "if", "out_map", "is", "not", "None", "else", "info", "[", "'module'", "]", "\n", "for", "i", ",", "info", "in", "enumerate", "(", "self", ".", "feature_info", ")", "if", "i", "in", "out_indices", "}", "\n", "self", ".", "graph_module", "=", "create_feature_extractor", "(", "model", ",", "return_nodes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.fx_features.FeatureGraphNet.forward": [[80, 82], ["list", "fx_features.FeatureGraphNet.graph_module().values", "fx_features.FeatureGraphNet.graph_module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "list", "(", "self", ".", "graph_module", "(", "x", ")", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.fx_features.GraphExtractNet.__init__": [[97, 101], ["torch.nn.Module.__init__", "fx_features.create_feature_extractor"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.fx_features.create_feature_extractor"], ["def", "__init__", "(", "self", ",", "model", ",", "return_nodes", ":", "Union", "[", "Dict", "[", "str", ",", "str", "]", ",", "List", "[", "str", "]", "]", ",", "squeeze_out", ":", "bool", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "squeeze_out", "=", "squeeze_out", "\n", "self", ".", "graph_module", "=", "create_feature_extractor", "(", "model", ",", "return_nodes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.fx_features.GraphExtractNet.forward": [[102, 107], ["list", "fx_features.GraphExtractNet.graph_module().values", "len", "fx_features.GraphExtractNet.graph_module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "Union", "[", "List", "[", "torch", ".", "Tensor", "]", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "out", "=", "list", "(", "self", ".", "graph_module", "(", "x", ")", ".", "values", "(", ")", ")", "\n", "if", "self", ".", "squeeze_out", "and", "len", "(", "out", ")", "==", "1", ":", "\n", "            ", "return", "out", "[", "0", "]", "\n", "", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.fx_features.register_notrace_module": [[38, 44], ["_leaf_modules.add"], "function", ["None"], ["", "def", "register_notrace_module", "(", "module", ":", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Any module not under timm.models.layers should get this decorator if we don't want to trace through it.\n    \"\"\"", "\n", "_leaf_modules", ".", "add", "(", "module", ")", "\n", "return", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.fx_features.register_notrace_function": [[50, 56], ["_autowrap_functions.add"], "function", ["None"], ["def", "register_notrace_function", "(", "func", ":", "Callable", ")", ":", "\n", "    ", "\"\"\"\n    Decorator for functions which ought not to be traced through\n    \"\"\"", "\n", "_autowrap_functions", ".", "add", "(", "func", ")", "\n", "return", "func", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.fx_features.create_feature_extractor": [[58, 63], ["_create_feature_extractor", "list", "list"], "function", ["None"], ["", "def", "create_feature_extractor", "(", "model", ":", "nn", ".", "Module", ",", "return_nodes", ":", "Union", "[", "Dict", "[", "str", ",", "str", "]", ",", "List", "[", "str", "]", "]", ")", ":", "\n", "    ", "assert", "has_fx_feature_extraction", ",", "'Please update to PyTorch 1.10+, torchvision 0.11+ for FX feature extraction'", "\n", "return", "_create_feature_extractor", "(", "\n", "model", ",", "return_nodes", ",", "\n", "tracer_kwargs", "=", "{", "'leaf_modules'", ":", "list", "(", "_leaf_modules", ")", ",", "'autowrap_functions'", ":", "list", "(", "_autowrap_functions", ")", "}", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.factory.parse_model_name": [[10, 20], ["model_name.replace.replace", "urllib.parse.urlsplit", "os.path.split"], "function", ["None"], ["def", "parse_model_name", "(", "model_name", ")", ":", "\n", "    ", "model_name", "=", "model_name", ".", "replace", "(", "'hf_hub'", ",", "'hf-hub'", ")", "# NOTE for backwards compat, to deprecate hf_hub use", "\n", "parsed", "=", "urlsplit", "(", "model_name", ")", "\n", "assert", "parsed", ".", "scheme", "in", "(", "''", ",", "'timm'", ",", "'hf-hub'", ")", "\n", "if", "parsed", ".", "scheme", "==", "'hf-hub'", ":", "\n", "# FIXME may use fragment as revision, currently `@` in URI path", "\n", "        ", "return", "parsed", ".", "scheme", ",", "parsed", ".", "path", "\n", "", "else", ":", "\n", "        ", "model_name", "=", "os", ".", "path", ".", "split", "(", "parsed", ".", "path", ")", "[", "-", "1", "]", "\n", "return", "'timm'", ",", "model_name", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.factory.safe_model_name": [[22, 28], ["factory.safe_model_name.make_safe"], "function", ["None"], ["", "", "def", "safe_model_name", "(", "model_name", ",", "remove_source", "=", "True", ")", ":", "\n", "    ", "def", "make_safe", "(", "name", ")", ":", "\n", "        ", "return", "''", ".", "join", "(", "c", "if", "c", ".", "isalnum", "(", ")", "else", "'_'", "for", "c", "in", "name", ")", ".", "rstrip", "(", "'_'", ")", "\n", "", "if", "remove_source", ":", "\n", "        ", "model_name", "=", "parse_model_name", "(", "model_name", ")", "[", "-", "1", "]", "\n", "", "return", "make_safe", "(", "model_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.factory.create_model": [[30, 77], ["factory.parse_model_name", "registry.model_entrypoint", "hub.load_model_config_from_hf", "registry.is_model", "RuntimeError", "layers.set_layer_config", "registry.model_entrypoint.", "helpers.load_checkpoint", "kwargs.items"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.factory.parse_model_name", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.model_entrypoint", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.load_model_config_from_hf", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.is_model", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.load_checkpoint"], ["", "def", "create_model", "(", "\n", "model_name", ",", "\n", "pretrained", "=", "False", ",", "\n", "pretrained_cfg", "=", "None", ",", "\n", "checkpoint_path", "=", "''", ",", "\n", "scriptable", "=", "None", ",", "\n", "exportable", "=", "None", ",", "\n", "no_jit", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Create a model\n\n    Args:\n        model_name (str): name of model to instantiate\n        pretrained (bool): load pretrained ImageNet-1k weights if true\n        checkpoint_path (str): path of checkpoint to load after model is initialized\n        scriptable (bool): set layer config so that model is jit scriptable (not working for all models yet)\n        exportable (bool): set layer config so that model is traceable / ONNX exportable (not fully impl/obeyed yet)\n        no_jit (bool): set layer config so that model doesn't utilize jit scripted layers (so far activations only)\n\n    Keyword Args:\n        drop_rate (float): dropout rate for training (default: 0.0)\n        global_pool (str): global pool type (default: 'avg')\n        **: other kwargs are model specific\n    \"\"\"", "\n", "# Parameters that aren't supported by all models or are intended to only override model defaults if set", "\n", "# should default to None in command line args/cfg. Remove them if they are present and not set so that", "\n", "# non-supporting models don't break and default args remain in effect.", "\n", "kwargs", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "if", "v", "is", "not", "None", "}", "\n", "\n", "model_source", ",", "model_name", "=", "parse_model_name", "(", "model_name", ")", "\n", "if", "model_source", "==", "'hf-hub'", ":", "\n", "# FIXME hf-hub source overrides any passed in pretrained_cfg, warn?", "\n", "# For model names specified in the form `hf-hub:path/architecture_name@revision`,", "\n", "# load model weights + pretrained_cfg from Hugging Face hub.", "\n", "        ", "pretrained_cfg", ",", "model_name", "=", "load_model_config_from_hf", "(", "model_name", ")", "\n", "\n", "", "if", "not", "is_model", "(", "model_name", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'Unknown model (%s)'", "%", "model_name", ")", "\n", "\n", "", "create_fn", "=", "model_entrypoint", "(", "model_name", ")", "\n", "with", "set_layer_config", "(", "scriptable", "=", "scriptable", ",", "exportable", "=", "exportable", ",", "no_jit", "=", "no_jit", ")", ":", "\n", "        ", "model", "=", "create_fn", "(", "pretrained", "=", "pretrained", ",", "pretrained_cfg", "=", "pretrained_cfg", ",", "**", "kwargs", ")", "\n", "\n", "", "if", "checkpoint_path", ":", "\n", "        ", "load_checkpoint", "(", "model", ",", "checkpoint_path", ")", "\n", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseLayer.__init__": [[48, 60], ["torch.Module.__init__", "float", "densenet.DenseLayer.add_module", "densenet.DenseLayer.add_module", "densenet.DenseLayer.add_module", "densenet.DenseLayer.add_module", "norm_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "num_input_features", ",", "growth_rate", ",", "bn_size", ",", "norm_layer", "=", "BatchNormAct2d", ",", "\n", "drop_rate", "=", "0.", ",", "memory_efficient", "=", "False", ")", ":", "\n", "        ", "super", "(", "DenseLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "add_module", "(", "'norm1'", ",", "norm_layer", "(", "num_input_features", ")", ")", ",", "\n", "self", ".", "add_module", "(", "'conv1'", ",", "nn", ".", "Conv2d", "(", "\n", "num_input_features", ",", "bn_size", "*", "growth_rate", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "bias", "=", "False", ")", ")", ",", "\n", "self", ".", "add_module", "(", "'norm2'", ",", "norm_layer", "(", "bn_size", "*", "growth_rate", ")", ")", ",", "\n", "self", ".", "add_module", "(", "'conv2'", ",", "nn", ".", "Conv2d", "(", "\n", "bn_size", "*", "growth_rate", ",", "growth_rate", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ")", ",", "\n", "self", ".", "drop_rate", "=", "float", "(", "drop_rate", ")", "\n", "self", ".", "memory_efficient", "=", "memory_efficient", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseLayer.bottleneck_fn": [[61, 66], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "densenet.DenseLayer.conv1", "densenet.DenseLayer.norm1"], "methods", ["None"], ["", "def", "bottleneck_fn", "(", "self", ",", "xs", ")", ":", "\n", "# type: (List[torch.Tensor]) -> torch.Tensor", "\n", "        ", "concated_features", "=", "torch", ".", "cat", "(", "xs", ",", "1", ")", "\n", "bottleneck_output", "=", "self", ".", "conv1", "(", "self", ".", "norm1", "(", "concated_features", ")", ")", "# noqa: T484", "\n", "return", "bottleneck_output", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseLayer.any_requires_grad": [[68, 74], ["None"], "methods", ["None"], ["", "def", "any_requires_grad", "(", "self", ",", "x", ")", ":", "\n", "# type: (List[torch.Tensor]) -> bool", "\n", "        ", "for", "tensor", "in", "x", ":", "\n", "            ", "if", "tensor", ".", "requires_grad", ":", "\n", "                ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseLayer.call_checkpoint_bottleneck": [[75, 82], ["torch.checkpoint", "torch.checkpoint", "torch.checkpoint", "torch.checkpoint", "densenet.DenseLayer.bottleneck_fn"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseLayer.bottleneck_fn"], ["", "@", "torch", ".", "jit", ".", "unused", "# noqa: T484", "\n", "def", "call_checkpoint_bottleneck", "(", "self", ",", "x", ")", ":", "\n", "# type: (List[torch.Tensor]) -> torch.Tensor", "\n", "        ", "def", "closure", "(", "*", "xs", ")", ":", "\n", "            ", "return", "self", ".", "bottleneck_fn", "(", "xs", ")", "\n", "\n", "", "return", "cp", ".", "checkpoint", "(", "closure", ",", "*", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseLayer.forward": [[95, 112], ["isinstance", "densenet.DenseLayer.conv2", "densenet.DenseLayer.any_requires_grad", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "densenet.DenseLayer.call_checkpoint_bottleneck", "densenet.DenseLayer.bottleneck_fn", "densenet.DenseLayer.norm2", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "Exception"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseLayer.any_requires_grad", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseLayer.call_checkpoint_bottleneck", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseLayer.bottleneck_fn"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "# noqa: F811", "\n", "        ", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "prev_features", "=", "[", "x", "]", "\n", "", "else", ":", "\n", "            ", "prev_features", "=", "x", "\n", "\n", "", "if", "self", ".", "memory_efficient", "and", "self", ".", "any_requires_grad", "(", "prev_features", ")", ":", "\n", "            ", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "                ", "raise", "Exception", "(", "\"Memory Efficient not supported in JIT\"", ")", "\n", "", "bottleneck_output", "=", "self", ".", "call_checkpoint_bottleneck", "(", "prev_features", ")", "\n", "", "else", ":", "\n", "            ", "bottleneck_output", "=", "self", ".", "bottleneck_fn", "(", "prev_features", ")", "\n", "\n", "", "new_features", "=", "self", ".", "conv2", "(", "self", ".", "norm2", "(", "bottleneck_output", ")", ")", "\n", "if", "self", ".", "drop_rate", ">", "0", ":", "\n", "            ", "new_features", "=", "F", ".", "dropout", "(", "new_features", ",", "p", "=", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "new_features", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseBlock.__init__": [[117, 131], ["torch.ModuleDict.__init__", "range", "densenet.DenseLayer", "densenet.DenseBlock.add_module"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "num_layers", ",", "num_input_features", ",", "bn_size", ",", "growth_rate", ",", "norm_layer", "=", "nn", ".", "ReLU", ",", "\n", "drop_rate", "=", "0.", ",", "memory_efficient", "=", "False", ")", ":", "\n", "        ", "super", "(", "DenseBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "layer", "=", "DenseLayer", "(", "\n", "num_input_features", "+", "i", "*", "growth_rate", ",", "\n", "growth_rate", "=", "growth_rate", ",", "\n", "bn_size", "=", "bn_size", ",", "\n", "norm_layer", "=", "norm_layer", ",", "\n", "drop_rate", "=", "drop_rate", ",", "\n", "memory_efficient", "=", "memory_efficient", ",", "\n", ")", "\n", "self", ".", "add_module", "(", "'denselayer%d'", "%", "(", "i", "+", "1", ")", ",", "layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseBlock.forward": [[132, 138], ["densenet.DenseBlock.items", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layer", "features.append"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "init_features", ")", ":", "\n", "        ", "features", "=", "[", "init_features", "]", "\n", "for", "name", ",", "layer", "in", "self", ".", "items", "(", ")", ":", "\n", "            ", "new_features", "=", "layer", "(", "features", ")", "\n", "features", ".", "append", "(", "new_features", ")", "\n", "", "return", "torch", ".", "cat", "(", "features", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseTransition.__init__": [[141, 150], ["torch.Sequential.__init__", "densenet.DenseTransition.add_module", "densenet.DenseTransition.add_module", "norm_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "densenet.DenseTransition.add_module", "densenet.DenseTransition.add_module", "aa_layer", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_input_features", ",", "num_output_features", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "aa_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "DenseTransition", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "add_module", "(", "'norm'", ",", "norm_layer", "(", "num_input_features", ")", ")", "\n", "self", ".", "add_module", "(", "'conv'", ",", "nn", ".", "Conv2d", "(", "\n", "num_input_features", ",", "num_output_features", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "if", "aa_layer", "is", "not", "None", ":", "\n", "            ", "self", ".", "add_module", "(", "'pool'", ",", "aa_layer", "(", "num_output_features", ",", "stride", "=", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "add_module", "(", "'pool'", ",", "nn", ".", "AvgPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseNet.__init__": [[167, 253], ["torch.Module.__init__", "enumerate", "densenet.DenseNet.features.add_module", "layers.create_classifier", "densenet.DenseNet.modules", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "dict", "densenet.DenseBlock", "densenet.DenseNet.features.add_module", "norm_layer", "dict", "isinstance", "collections.OrderedDict", "collections.OrderedDict", "densenet.DenseTransition", "densenet.DenseNet.features.add_module", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "len", "dict", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "isinstance", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "aa_layer", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["def", "__init__", "(", "\n", "self", ",", "growth_rate", "=", "32", ",", "block_config", "=", "(", "6", ",", "12", ",", "24", ",", "16", ")", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "global_pool", "=", "'avg'", ",", "\n", "bn_size", "=", "4", ",", "stem_type", "=", "''", ",", "norm_layer", "=", "BatchNormAct2d", ",", "aa_layer", "=", "None", ",", "drop_rate", "=", "0", ",", "\n", "memory_efficient", "=", "False", ",", "aa_stem_only", "=", "True", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "super", "(", "DenseNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Stem", "\n", "deep_stem", "=", "'deep'", "in", "stem_type", "# 3x3 deep stem", "\n", "num_init_features", "=", "growth_rate", "*", "2", "\n", "if", "aa_layer", "is", "None", ":", "\n", "            ", "stem_pool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "stem_pool", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "aa_layer", "(", "channels", "=", "num_init_features", ",", "stride", "=", "2", ")", "]", ")", "\n", "", "if", "deep_stem", ":", "\n", "            ", "stem_chs_1", "=", "stem_chs_2", "=", "growth_rate", "\n", "if", "'tiered'", "in", "stem_type", ":", "\n", "                ", "stem_chs_1", "=", "3", "*", "(", "growth_rate", "//", "4", ")", "\n", "stem_chs_2", "=", "num_init_features", "if", "'narrow'", "in", "stem_type", "else", "6", "*", "(", "growth_rate", "//", "4", ")", "\n", "", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'conv0'", ",", "nn", ".", "Conv2d", "(", "in_chans", ",", "stem_chs_1", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ")", ",", "\n", "(", "'norm0'", ",", "norm_layer", "(", "stem_chs_1", ")", ")", ",", "\n", "(", "'conv1'", ",", "nn", ".", "Conv2d", "(", "stem_chs_1", ",", "stem_chs_2", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ")", ",", "\n", "(", "'norm1'", ",", "norm_layer", "(", "stem_chs_2", ")", ")", ",", "\n", "(", "'conv2'", ",", "nn", ".", "Conv2d", "(", "stem_chs_2", ",", "num_init_features", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ")", ",", "\n", "(", "'norm2'", ",", "norm_layer", "(", "num_init_features", ")", ")", ",", "\n", "(", "'pool0'", ",", "stem_pool", ")", ",", "\n", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'conv0'", ",", "nn", ".", "Conv2d", "(", "in_chans", ",", "num_init_features", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "bias", "=", "False", ")", ")", ",", "\n", "(", "'norm0'", ",", "norm_layer", "(", "num_init_features", ")", ")", ",", "\n", "(", "'pool0'", ",", "stem_pool", ")", ",", "\n", "]", ")", ")", "\n", "", "self", ".", "feature_info", "=", "[", "\n", "dict", "(", "num_chs", "=", "num_init_features", ",", "reduction", "=", "2", ",", "module", "=", "f'features.norm{2 if deep_stem else 0}'", ")", "]", "\n", "current_stride", "=", "4", "\n", "\n", "# DenseBlocks", "\n", "num_features", "=", "num_init_features", "\n", "for", "i", ",", "num_layers", "in", "enumerate", "(", "block_config", ")", ":", "\n", "            ", "block", "=", "DenseBlock", "(", "\n", "num_layers", "=", "num_layers", ",", "\n", "num_input_features", "=", "num_features", ",", "\n", "bn_size", "=", "bn_size", ",", "\n", "growth_rate", "=", "growth_rate", ",", "\n", "norm_layer", "=", "norm_layer", ",", "\n", "drop_rate", "=", "drop_rate", ",", "\n", "memory_efficient", "=", "memory_efficient", "\n", ")", "\n", "module_name", "=", "f'denseblock{(i + 1)}'", "\n", "self", ".", "features", ".", "add_module", "(", "module_name", ",", "block", ")", "\n", "num_features", "=", "num_features", "+", "num_layers", "*", "growth_rate", "\n", "transition_aa_layer", "=", "None", "if", "aa_stem_only", "else", "aa_layer", "\n", "if", "i", "!=", "len", "(", "block_config", ")", "-", "1", ":", "\n", "                ", "self", ".", "feature_info", "+=", "[", "\n", "dict", "(", "num_chs", "=", "num_features", ",", "reduction", "=", "current_stride", ",", "module", "=", "'features.'", "+", "module_name", ")", "]", "\n", "current_stride", "*=", "2", "\n", "trans", "=", "DenseTransition", "(", "\n", "num_input_features", "=", "num_features", ",", "num_output_features", "=", "num_features", "//", "2", ",", "\n", "norm_layer", "=", "norm_layer", ",", "aa_layer", "=", "transition_aa_layer", ")", "\n", "self", ".", "features", ".", "add_module", "(", "f'transition{i + 1}'", ",", "trans", ")", "\n", "num_features", "=", "num_features", "//", "2", "\n", "\n", "# Final batch norm", "\n", "", "", "self", ".", "features", ".", "add_module", "(", "'norm5'", ",", "norm_layer", "(", "num_features", ")", ")", "\n", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "num_features", ",", "reduction", "=", "current_stride", ",", "module", "=", "'features.norm5'", ")", "]", "\n", "self", ".", "num_features", "=", "num_features", "\n", "\n", "# Linear layer", "\n", "self", ".", "global_pool", ",", "self", ".", "classifier", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n", "# Official init from torch repo.", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseNet.group_matcher": [[254, 264], ["dict"], "methods", ["None"], ["", "", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem", "=", "r'^features\\.conv[012]|features\\.norm[012]|features\\.pool[012]'", ",", "\n", "blocks", "=", "r'^features\\.(?:denseblock|transition)(\\d+)'", "if", "coarse", "else", "[", "\n", "(", "r'^features\\.denseblock(\\d+)\\.denselayer(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^features\\.transition(\\d+)'", ",", "MATCH_PREV_GROUP", ")", "# FIXME combine with previous denselayer", "\n", "]", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseNet.get_classifier": [[265, 268], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseNet.reset_classifier": [[269, 273], ["layers.create_classifier"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "classifier", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseNet.forward_features": [[274, 276], ["densenet.DenseNet.features"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "features", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.DenseNet.forward": [[277, 285], ["densenet.DenseNet.forward_features", "densenet.DenseNet.global_pool", "densenet.DenseNet.classifier"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "# both classifier and block drop?", "\n", "# if self.drop_rate > 0.:", "\n", "#     x = F.dropout(x, p=self.drop_rate, training=self.training)", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet._cfg": [[23, 29], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'features.conv0'", ",", "'classifier'", ":", "'classifier'", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet._filter_torchvision_pretrained": [[287, 298], ["re.compile", "list", "state_dict.keys", "re.compile.match", "pattern.match.group", "pattern.match.group"], "function", ["None"], ["", "", "def", "_filter_torchvision_pretrained", "(", "state_dict", ")", ":", "\n", "    ", "pattern", "=", "re", ".", "compile", "(", "\n", "r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$'", ")", "\n", "\n", "for", "key", "in", "list", "(", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "        ", "res", "=", "pattern", ".", "match", "(", "key", ")", "\n", "if", "res", ":", "\n", "            ", "new_key", "=", "res", ".", "group", "(", "1", ")", "+", "res", ".", "group", "(", "2", ")", "\n", "state_dict", "[", "new_key", "]", "=", "state_dict", "[", "key", "]", "\n", "del", "state_dict", "[", "key", "]", "\n", "", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet._create_densenet": [[300, 307], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "def", "_create_densenet", "(", "variant", ",", "growth_rate", ",", "block_config", ",", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "kwargs", "[", "'growth_rate'", "]", "=", "growth_rate", "\n", "kwargs", "[", "'block_config'", "]", "=", "block_config", "\n", "return", "build_model_with_cfg", "(", "\n", "DenseNet", ",", "variant", ",", "pretrained", ",", "\n", "feature_cfg", "=", "dict", "(", "flatten_sequential", "=", "True", ")", ",", "pretrained_filter_fn", "=", "_filter_torchvision_pretrained", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.densenet121": [[309, 317], ["densenet._create_densenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet._create_densenet"], ["", "@", "register_model", "\n", "def", "densenet121", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Densenet-121 model from\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n    \"\"\"", "\n", "model", "=", "_create_densenet", "(", "\n", "'densenet121'", ",", "growth_rate", "=", "32", ",", "block_config", "=", "(", "6", ",", "12", ",", "24", ",", "16", ")", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.densenetblur121d": [[319, 328], ["densenet._create_densenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet._create_densenet"], ["", "@", "register_model", "\n", "def", "densenetblur121d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Densenet-121 model from\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n    \"\"\"", "\n", "model", "=", "_create_densenet", "(", "\n", "'densenetblur121d'", ",", "growth_rate", "=", "32", ",", "block_config", "=", "(", "6", ",", "12", ",", "24", ",", "16", ")", ",", "pretrained", "=", "pretrained", ",", "stem_type", "=", "'deep'", ",", "\n", "aa_layer", "=", "BlurPool2d", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.densenet121d": [[330, 339], ["densenet._create_densenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet._create_densenet"], ["", "@", "register_model", "\n", "def", "densenet121d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Densenet-121 model from\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n    \"\"\"", "\n", "model", "=", "_create_densenet", "(", "\n", "'densenet121d'", ",", "growth_rate", "=", "32", ",", "block_config", "=", "(", "6", ",", "12", ",", "24", ",", "16", ")", ",", "stem_type", "=", "'deep'", ",", "\n", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.densenet169": [[341, 349], ["densenet._create_densenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet._create_densenet"], ["", "@", "register_model", "\n", "def", "densenet169", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Densenet-169 model from\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n    \"\"\"", "\n", "model", "=", "_create_densenet", "(", "\n", "'densenet169'", ",", "growth_rate", "=", "32", ",", "block_config", "=", "(", "6", ",", "12", ",", "32", ",", "32", ")", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.densenet201": [[351, 359], ["densenet._create_densenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet._create_densenet"], ["", "@", "register_model", "\n", "def", "densenet201", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Densenet-201 model from\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n    \"\"\"", "\n", "model", "=", "_create_densenet", "(", "\n", "'densenet201'", ",", "growth_rate", "=", "32", ",", "block_config", "=", "(", "6", ",", "12", ",", "48", ",", "32", ")", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.densenet161": [[361, 369], ["densenet._create_densenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet._create_densenet"], ["", "@", "register_model", "\n", "def", "densenet161", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Densenet-161 model from\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n    \"\"\"", "\n", "model", "=", "_create_densenet", "(", "\n", "'densenet161'", ",", "growth_rate", "=", "48", ",", "block_config", "=", "(", "6", ",", "12", ",", "36", ",", "24", ")", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.densenet264": [[371, 379], ["densenet._create_densenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet._create_densenet"], ["", "@", "register_model", "\n", "def", "densenet264", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Densenet-264 model from\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n    \"\"\"", "\n", "model", "=", "_create_densenet", "(", "\n", "'densenet264'", ",", "growth_rate", "=", "48", ",", "block_config", "=", "(", "6", ",", "12", ",", "64", ",", "48", ")", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.densenet264d_iabn": [[381, 391], ["densenet._create_densenet", "layers.create_norm_act_layer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet._create_densenet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.create_norm_act_layer"], ["", "@", "register_model", "\n", "def", "densenet264d_iabn", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Densenet-264 model with deep stem and Inplace-ABN\n    \"\"\"", "\n", "def", "norm_act_fn", "(", "num_features", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "create_norm_act_layer", "(", "'iabn'", ",", "num_features", ",", "act_layer", "=", "'leaky_relu'", ",", "**", "kwargs", ")", "\n", "", "model", "=", "_create_densenet", "(", "\n", "'densenet264d_iabn'", ",", "growth_rate", "=", "48", ",", "block_config", "=", "(", "6", ",", "12", ",", "64", ",", "48", ")", ",", "stem_type", "=", "'deep'", ",", "\n", "norm_layer", "=", "norm_act_fn", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet.tv_densenet121": [[393, 401], ["densenet._create_densenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.densenet._create_densenet"], ["", "@", "register_model", "\n", "def", "tv_densenet121", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Densenet-121 model with original Torchvision weights, from\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n    \"\"\"", "\n", "model", "=", "_create_densenet", "(", "\n", "'tv_densenet121'", ",", "growth_rate", "=", "32", ",", "block_config", "=", "(", "6", ",", "12", ",", "24", ",", "16", ")", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit.VisionTransformerDistilled.__init__": [[66, 78], ["kwargs.pop", "models.vision_transformer.VisionTransformer.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "deit.VisionTransformerDistilled.init_weights", "torch.zeros", "torch.zeros", "torch.nn.Linear", "torch.nn.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.GluMlp.init_weights"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "weight_init", "=", "kwargs", ".", "pop", "(", "'weight_init'", ",", "''", ")", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "weight_init", "=", "'skip'", ")", "\n", "assert", "self", ".", "global_pool", "in", "(", "'token'", ",", ")", "\n", "\n", "self", ".", "num_tokens", "=", "2", "\n", "self", ".", "dist_token", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "self", ".", "embed_dim", ")", ")", "\n", "self", ".", "pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "self", ".", "patch_embed", ".", "num_patches", "+", "self", ".", "num_tokens", ",", "self", ".", "embed_dim", ")", ")", "\n", "self", ".", "head_dist", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "num_classes", ")", "if", "self", ".", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "distilled_training", "=", "False", "# must set this True to train w/ distillation token", "\n", "\n", "self", ".", "init_weights", "(", "weight_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit.VisionTransformerDistilled.init_weights": [[79, 82], ["models.vision_transformer.trunc_normal_", "super().init_weights"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.GluMlp.init_weights"], ["", "def", "init_weights", "(", "self", ",", "mode", "=", "''", ")", ":", "\n", "        ", "trunc_normal_", "(", "self", ".", "dist_token", ",", "std", "=", ".02", ")", "\n", "super", "(", ")", ".", "init_weights", "(", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit.VisionTransformerDistilled.group_matcher": [[83, 90], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^cls_token|pos_embed|patch_embed|dist_token'", ",", "\n", "blocks", "=", "[", "\n", "(", "r'^blocks\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^norm'", ",", "(", "99999", ",", ")", ")", "]", "# final norm w/ last block", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit.VisionTransformerDistilled.get_classifier": [[92, 95], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", ",", "self", ".", "head_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit.VisionTransformerDistilled.reset_classifier": [[96, 100], ["torch.nn.Linear", "torch.nn.Identity", "torch.nn.Linear", "torch.nn.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "None", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "head_dist", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit.VisionTransformerDistilled.set_distilled_training": [[101, 104], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_distilled_training", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "distilled_training", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit.VisionTransformerDistilled.forward_features": [[105, 117], ["deit.VisionTransformerDistilled.patch_embed", "torch.cat", "deit.VisionTransformerDistilled.pos_drop", "deit.VisionTransformerDistilled.norm", "helpers.checkpoint_seq", "deit.VisionTransformerDistilled.blocks", "deit.VisionTransformerDistilled.cls_token.expand", "deit.VisionTransformerDistilled.dist_token.expand", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq"], ["", "def", "forward_features", "(", "self", ",", "x", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "\n", "self", ".", "cls_token", ".", "expand", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "-", "1", ")", ",", "\n", "self", ".", "dist_token", ".", "expand", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "-", "1", ")", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "x", "=", "self", ".", "pos_drop", "(", "x", "+", "self", ".", "pos_embed", ")", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "blocks", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "blocks", "(", "x", ")", "\n", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit.VisionTransformerDistilled.forward_head": [[118, 128], ["deit.VisionTransformerDistilled.head", "deit.VisionTransformerDistilled.head_dist", "torch.jit.is_scripting"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "pre_logits", ":", "\n", "            ", "return", "(", "x", "[", ":", ",", "0", "]", "+", "x", "[", ":", ",", "1", "]", ")", "/", "2", "\n", "", "x", ",", "x_dist", "=", "self", ".", "head", "(", "x", "[", ":", ",", "0", "]", ")", ",", "self", ".", "head_dist", "(", "x", "[", ":", ",", "1", "]", ")", "\n", "if", "self", ".", "distilled_training", "and", "self", ".", "training", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "# only return separate classification predictions when training in distilled mode", "\n", "            ", "return", "x", ",", "x_dist", "\n", "", "else", ":", "\n", "# during standard train / finetune, inference average the classifier predictions", "\n", "            ", "return", "(", "x", "+", "x_dist", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit._cfg": [[20, 28], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", ".9", ",", "'interpolation'", ":", "'bicubic'", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'patch_embed.proj'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit._create_deit": [[130, 139], ["kwargs.get", "helpers.build_model_with_cfg", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "", "def", "_create_deit", "(", "variant", ",", "pretrained", "=", "False", ",", "distilled", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", ".", "get", "(", "'features_only'", ",", "None", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'features_only not implemented for Vision Transformer models.'", ")", "\n", "", "model_cls", "=", "VisionTransformerDistilled", "if", "distilled", "else", "VisionTransformer", "\n", "model", "=", "build_model_with_cfg", "(", "\n", "model_cls", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_filter_fn", "=", "checkpoint_filter_fn", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit.deit_tiny_patch16_224": [[141, 149], ["dict", "deit._create_deit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit._create_deit"], ["", "@", "register_model", "\n", "def", "deit_tiny_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" DeiT-tiny model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "3", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_deit", "(", "'deit_tiny_patch16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit.deit_small_patch16_224": [[151, 159], ["dict", "deit._create_deit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit._create_deit"], ["", "@", "register_model", "\n", "def", "deit_small_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" DeiT-small model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_deit", "(", "'deit_small_patch16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit.deit_base_patch16_224": [[161, 169], ["dict", "deit._create_deit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit._create_deit"], ["", "@", "register_model", "\n", "def", "deit_base_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" DeiT base model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_deit", "(", "'deit_base_patch16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit.deit_base_patch16_384": [[171, 179], ["dict", "deit._create_deit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit._create_deit"], ["", "@", "register_model", "\n", "def", "deit_base_patch16_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" DeiT base model @ 384x384 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_deit", "(", "'deit_base_patch16_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit.deit_tiny_distilled_patch16_224": [[181, 190], ["dict", "deit._create_deit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit._create_deit"], ["", "@", "register_model", "\n", "def", "deit_tiny_distilled_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" DeiT-tiny distilled model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "3", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_deit", "(", "\n", "'deit_tiny_distilled_patch16_224'", ",", "pretrained", "=", "pretrained", ",", "distilled", "=", "True", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit.deit_small_distilled_patch16_224": [[192, 201], ["dict", "deit._create_deit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit._create_deit"], ["", "@", "register_model", "\n", "def", "deit_small_distilled_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" DeiT-small distilled model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_deit", "(", "\n", "'deit_small_distilled_patch16_224'", ",", "pretrained", "=", "pretrained", ",", "distilled", "=", "True", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit.deit_base_distilled_patch16_224": [[203, 212], ["dict", "deit._create_deit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit._create_deit"], ["", "@", "register_model", "\n", "def", "deit_base_distilled_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" DeiT-base distilled model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_deit", "(", "\n", "'deit_base_distilled_patch16_224'", ",", "pretrained", "=", "pretrained", ",", "distilled", "=", "True", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit.deit_base_distilled_patch16_384": [[214, 223], ["dict", "deit._create_deit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.deit._create_deit"], ["", "@", "register_model", "\n", "def", "deit_base_distilled_patch16_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" DeiT-base distilled model @ 384x384 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_deit", "(", "\n", "'deit_base_distilled_patch16_384'", ",", "pretrained", "=", "pretrained", ",", "distilled", "=", "True", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DlaBasic.__init__": [[55, 65], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "**", "_", ")", ":", "\n", "        ", "super", "(", "DlaBasic", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "inplanes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "dilation", ",", "bias", "=", "False", ",", "dilation", "=", "dilation", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "\n", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "dilation", ",", "bias", "=", "False", ",", "dilation", "=", "dilation", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DlaBasic.forward": [[66, 81], ["dla.DlaBasic.conv1", "dla.DlaBasic.bn1", "dla.DlaBasic.relu", "dla.DlaBasic.conv2", "dla.DlaBasic.bn2", "dla.DlaBasic.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "shortcut", "=", "None", ",", "children", ":", "Optional", "[", "List", "[", "torch", ".", "Tensor", "]", "]", "=", "None", ")", ":", "\n", "        ", "if", "shortcut", "is", "None", ":", "\n", "            ", "shortcut", "=", "x", "\n", "\n", "", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "out", "+=", "shortcut", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DlaBottleneck.__init__": [[87, 102], ["torch.Module.__init__", "int", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "math.floor"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "outplanes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "cardinality", "=", "1", ",", "base_width", "=", "64", ")", ":", "\n", "        ", "super", "(", "DlaBottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "mid_planes", "=", "int", "(", "math", ".", "floor", "(", "outplanes", "*", "(", "base_width", "/", "64", ")", ")", "*", "cardinality", ")", "\n", "mid_planes", "=", "mid_planes", "//", "self", ".", "expansion", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "mid_planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "mid_planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "\n", "mid_planes", ",", "mid_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "dilation", ",", "\n", "bias", "=", "False", ",", "dilation", "=", "dilation", ",", "groups", "=", "cardinality", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "mid_planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "mid_planes", ",", "outplanes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "outplanes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DlaBottleneck.forward": [[103, 122], ["dla.DlaBottleneck.conv1", "dla.DlaBottleneck.bn1", "dla.DlaBottleneck.relu", "dla.DlaBottleneck.conv2", "dla.DlaBottleneck.bn2", "dla.DlaBottleneck.relu", "dla.DlaBottleneck.conv3", "dla.DlaBottleneck.bn3", "dla.DlaBottleneck.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "shortcut", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "children", ":", "Optional", "[", "List", "[", "torch", ".", "Tensor", "]", "]", "=", "None", ")", ":", "\n", "        ", "if", "shortcut", "is", "None", ":", "\n", "            ", "shortcut", "=", "x", "\n", "\n", "", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "out", "+=", "shortcut", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DlaBottle2neck.__init__": [[130, 156], ["torch.Module.__init__", "int", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "max", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "convs.append", "bns.append", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "math.floor", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "outplanes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "scale", "=", "4", ",", "cardinality", "=", "8", ",", "base_width", "=", "4", ")", ":", "\n", "        ", "super", "(", "DlaBottle2neck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_first", "=", "stride", ">", "1", "\n", "self", ".", "scale", "=", "scale", "\n", "mid_planes", "=", "int", "(", "math", ".", "floor", "(", "outplanes", "*", "(", "base_width", "/", "64", ")", ")", "*", "cardinality", ")", "\n", "mid_planes", "=", "mid_planes", "//", "self", ".", "expansion", "\n", "self", ".", "width", "=", "mid_planes", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "mid_planes", "*", "scale", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "mid_planes", "*", "scale", ")", "\n", "\n", "num_scale_convs", "=", "max", "(", "1", ",", "scale", "-", "1", ")", "\n", "convs", "=", "[", "]", "\n", "bns", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_scale_convs", ")", ":", "\n", "            ", "convs", ".", "append", "(", "nn", ".", "Conv2d", "(", "\n", "mid_planes", ",", "mid_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "dilation", ",", "dilation", "=", "dilation", ",", "groups", "=", "cardinality", ",", "bias", "=", "False", ")", ")", "\n", "bns", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "mid_planes", ")", ")", "\n", "", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", "convs", ")", "\n", "self", ".", "bns", "=", "nn", ".", "ModuleList", "(", "bns", ")", "\n", "self", ".", "pool", "=", "nn", ".", "AvgPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ")", "if", "self", ".", "is_first", "else", "None", "\n", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "mid_planes", "*", "scale", ",", "outplanes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "outplanes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DlaBottle2neck.forward": [[157, 191], ["dla.DlaBottle2neck.conv1", "dla.DlaBottle2neck.bn1", "dla.DlaBottle2neck.relu", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dla.DlaBottle2neck.conv3", "dla.DlaBottle2neck.bn3", "dla.DlaBottle2neck.relu", "zip", "conv", "bn", "dla.DlaBottle2neck.relu", "spo.append", "spo.append", "spo.append", "dla.DlaBottle2neck.pool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "shortcut", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "children", ":", "Optional", "[", "List", "[", "torch", ".", "Tensor", "]", "]", "=", "None", ")", ":", "\n", "        ", "if", "shortcut", "is", "None", ":", "\n", "            ", "shortcut", "=", "x", "\n", "\n", "", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "spx", "=", "torch", ".", "split", "(", "out", ",", "self", ".", "width", ",", "1", ")", "\n", "spo", "=", "[", "]", "\n", "sp", "=", "spx", "[", "0", "]", "# redundant, for torchscript", "\n", "for", "i", ",", "(", "conv", ",", "bn", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "convs", ",", "self", ".", "bns", ")", ")", ":", "\n", "            ", "if", "i", "==", "0", "or", "self", ".", "is_first", ":", "\n", "                ", "sp", "=", "spx", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "sp", "=", "sp", "+", "spx", "[", "i", "]", "\n", "", "sp", "=", "conv", "(", "sp", ")", "\n", "sp", "=", "bn", "(", "sp", ")", "\n", "sp", "=", "self", ".", "relu", "(", "sp", ")", "\n", "spo", ".", "append", "(", "sp", ")", "\n", "", "if", "self", ".", "scale", ">", "1", ":", "\n", "            ", "if", "self", ".", "pool", "is", "not", "None", ":", "# self.is_first == True, None check for torchscript", "\n", "                ", "spo", ".", "append", "(", "self", ".", "pool", "(", "spx", "[", "-", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "spo", ".", "append", "(", "spx", "[", "-", "1", "]", ")", "\n", "", "", "out", "=", "torch", ".", "cat", "(", "spo", ",", "1", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "out", "+=", "shortcut", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DlaRoot.__init__": [[194, 201], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "shortcut", ")", ":", "\n", "        ", "super", "(", "DlaRoot", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "1", ",", "stride", "=", "1", ",", "bias", "=", "False", ",", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "shortcut", "=", "shortcut", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DlaRoot.forward": [[202, 210], ["dla.DlaRoot.conv", "dla.DlaRoot.bn", "dla.DlaRoot.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_children", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "torch", ".", "cat", "(", "x_children", ",", "1", ")", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "if", "self", ".", "shortcut", ":", "\n", "            ", "x", "+=", "x_children", "[", "0", "]", "\n", "", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DlaTree.__init__": [[213, 245], ["torch.Module.__init__", "torch.Identity", "torch.Identity", "torch.Identity", "dict", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Identity", "torch.Identity", "torch.Identity", "block", "block", "dla.DlaRoot", "dict.update", "dla.DlaTree", "dla.DlaTree", "torch.Sequential", "torch.Sequential", "torch.Sequential", "dict", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "levels", ",", "block", ",", "in_channels", ",", "out_channels", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "cardinality", "=", "1", ",", "\n", "base_width", "=", "64", ",", "level_root", "=", "False", ",", "root_dim", "=", "0", ",", "root_kernel_size", "=", "1", ",", "root_shortcut", "=", "False", ")", ":", "\n", "        ", "super", "(", "DlaTree", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "root_dim", "==", "0", ":", "\n", "            ", "root_dim", "=", "2", "*", "out_channels", "\n", "", "if", "level_root", ":", "\n", "            ", "root_dim", "+=", "in_channels", "\n", "", "self", ".", "downsample", "=", "nn", ".", "MaxPool2d", "(", "stride", ",", "stride", "=", "stride", ")", "if", "stride", ">", "1", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "project", "=", "nn", ".", "Identity", "(", ")", "\n", "cargs", "=", "dict", "(", "dilation", "=", "dilation", ",", "cardinality", "=", "cardinality", ",", "base_width", "=", "base_width", ")", "\n", "if", "levels", "==", "1", ":", "\n", "            ", "self", ".", "tree1", "=", "block", "(", "in_channels", ",", "out_channels", ",", "stride", ",", "**", "cargs", ")", "\n", "self", ".", "tree2", "=", "block", "(", "out_channels", ",", "out_channels", ",", "1", ",", "**", "cargs", ")", "\n", "if", "in_channels", "!=", "out_channels", ":", "\n", "# NOTE the official impl/weights have  project layers in levels > 1 case that are never", "\n", "# used, I've moved the project layer here to avoid wasted params but old checkpoints will", "\n", "# need strict=False while loading.", "\n", "                ", "self", ".", "project", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", ")", "\n", "", "self", ".", "root", "=", "DlaRoot", "(", "root_dim", ",", "out_channels", ",", "root_kernel_size", ",", "root_shortcut", ")", "\n", "", "else", ":", "\n", "            ", "cargs", ".", "update", "(", "dict", "(", "root_kernel_size", "=", "root_kernel_size", ",", "root_shortcut", "=", "root_shortcut", ")", ")", "\n", "self", ".", "tree1", "=", "DlaTree", "(", "\n", "levels", "-", "1", ",", "block", ",", "in_channels", ",", "out_channels", ",", "stride", ",", "root_dim", "=", "0", ",", "**", "cargs", ")", "\n", "self", ".", "tree2", "=", "DlaTree", "(", "\n", "levels", "-", "1", ",", "block", ",", "out_channels", ",", "out_channels", ",", "root_dim", "=", "root_dim", "+", "out_channels", ",", "**", "cargs", ")", "\n", "self", ".", "root", "=", "None", "\n", "", "self", ".", "level_root", "=", "level_root", "\n", "self", ".", "root_dim", "=", "root_dim", "\n", "self", ".", "levels", "=", "levels", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DlaTree.forward": [[246, 261], ["dla.DlaTree.downsample", "dla.DlaTree.project", "dla.DlaTree.tree1", "children.append", "dla.DlaTree.tree2", "dla.DlaTree.root", "children.append", "dla.DlaTree.tree2"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ",", "shortcut", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "children", ":", "Optional", "[", "List", "[", "torch", ".", "Tensor", "]", "]", "=", "None", ")", ":", "\n", "        ", "if", "children", "is", "None", ":", "\n", "            ", "children", "=", "[", "]", "\n", "", "bottom", "=", "self", ".", "downsample", "(", "x", ")", "\n", "shortcut", "=", "self", ".", "project", "(", "bottom", ")", "\n", "if", "self", ".", "level_root", ":", "\n", "            ", "children", ".", "append", "(", "bottom", ")", "\n", "", "x1", "=", "self", ".", "tree1", "(", "x", ",", "shortcut", ")", "\n", "if", "self", ".", "root", "is", "not", "None", ":", "# levels == 1", "\n", "            ", "x2", "=", "self", ".", "tree2", "(", "x1", ")", "\n", "x", "=", "self", ".", "root", "(", "[", "x2", ",", "x1", "]", "+", "children", ")", "\n", "", "else", ":", "\n", "            ", "children", ".", "append", "(", "x1", ")", "\n", "x", "=", "self", ".", "tree2", "(", "x1", ",", "None", ",", "children", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DLA.__init__": [[264, 307], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "dla.DLA._make_conv_level", "dla.DLA._make_conv_level", "dict", "dla.DlaTree", "dla.DlaTree", "dla.DlaTree", "dla.DlaTree", "layers.create_classifier", "dla.DLA.modules", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "dict", "dict", "dict", "dict", "dict", "dict", "torch.Flatten", "torch.Flatten", "torch.Flatten", "torch.Identity", "torch.Identity", "torch.Identity", "isinstance", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DLA._make_conv_level", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DLA._make_conv_level", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["    ", "def", "__init__", "(", "\n", "self", ",", "levels", ",", "channels", ",", "output_stride", "=", "32", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "global_pool", "=", "'avg'", ",", "\n", "cardinality", "=", "1", ",", "base_width", "=", "64", ",", "block", "=", "DlaBottle2neck", ",", "shortcut_root", "=", "False", ",", "drop_rate", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "DLA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "channels", "=", "channels", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "cardinality", "=", "cardinality", "\n", "self", ".", "base_width", "=", "base_width", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "assert", "output_stride", "==", "32", "# FIXME support dilation", "\n", "\n", "self", ".", "base_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_chans", ",", "channels", "[", "0", "]", ",", "kernel_size", "=", "7", ",", "stride", "=", "1", ",", "padding", "=", "3", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "channels", "[", "0", "]", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "self", ".", "level0", "=", "self", ".", "_make_conv_level", "(", "channels", "[", "0", "]", ",", "channels", "[", "0", "]", ",", "levels", "[", "0", "]", ")", "\n", "self", ".", "level1", "=", "self", ".", "_make_conv_level", "(", "channels", "[", "0", "]", ",", "channels", "[", "1", "]", ",", "levels", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "cargs", "=", "dict", "(", "cardinality", "=", "cardinality", ",", "base_width", "=", "base_width", ",", "root_shortcut", "=", "shortcut_root", ")", "\n", "self", ".", "level2", "=", "DlaTree", "(", "levels", "[", "2", "]", ",", "block", ",", "channels", "[", "1", "]", ",", "channels", "[", "2", "]", ",", "2", ",", "level_root", "=", "False", ",", "**", "cargs", ")", "\n", "self", ".", "level3", "=", "DlaTree", "(", "levels", "[", "3", "]", ",", "block", ",", "channels", "[", "2", "]", ",", "channels", "[", "3", "]", ",", "2", ",", "level_root", "=", "True", ",", "**", "cargs", ")", "\n", "self", ".", "level4", "=", "DlaTree", "(", "levels", "[", "4", "]", ",", "block", ",", "channels", "[", "3", "]", ",", "channels", "[", "4", "]", ",", "2", ",", "level_root", "=", "True", ",", "**", "cargs", ")", "\n", "self", ".", "level5", "=", "DlaTree", "(", "levels", "[", "5", "]", ",", "block", ",", "channels", "[", "4", "]", ",", "channels", "[", "5", "]", ",", "2", ",", "level_root", "=", "True", ",", "**", "cargs", ")", "\n", "self", ".", "feature_info", "=", "[", "\n", "dict", "(", "num_chs", "=", "channels", "[", "0", "]", ",", "reduction", "=", "1", ",", "module", "=", "'level0'", ")", ",", "# rare to have a meaningful stride 1 level", "\n", "dict", "(", "num_chs", "=", "channels", "[", "1", "]", ",", "reduction", "=", "2", ",", "module", "=", "'level1'", ")", ",", "\n", "dict", "(", "num_chs", "=", "channels", "[", "2", "]", ",", "reduction", "=", "4", ",", "module", "=", "'level2'", ")", ",", "\n", "dict", "(", "num_chs", "=", "channels", "[", "3", "]", ",", "reduction", "=", "8", ",", "module", "=", "'level3'", ")", ",", "\n", "dict", "(", "num_chs", "=", "channels", "[", "4", "]", ",", "reduction", "=", "16", ",", "module", "=", "'level4'", ")", ",", "\n", "dict", "(", "num_chs", "=", "channels", "[", "5", "]", ",", "reduction", "=", "32", ",", "module", "=", "'level5'", ")", ",", "\n", "]", "\n", "\n", "self", ".", "num_features", "=", "channels", "[", "-", "1", "]", "\n", "self", ".", "global_pool", ",", "self", ".", "fc", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ",", "use_conv", "=", "True", ")", "\n", "self", ".", "flatten", "=", "nn", ".", "Flatten", "(", "1", ")", "if", "global_pool", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DLA._make_conv_level": [[308, 319], ["range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "modules.extend", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["None"], ["", "", "", "def", "_make_conv_level", "(", "self", ",", "inplanes", ",", "planes", ",", "convs", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "        ", "modules", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "convs", ")", ":", "\n", "            ", "modules", ".", "extend", "(", "[", "\n", "nn", ".", "Conv2d", "(", "\n", "inplanes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", "if", "i", "==", "0", "else", "1", ",", "\n", "padding", "=", "dilation", ",", "bias", "=", "False", ",", "dilation", "=", "dilation", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", ")", "\n", "inplanes", "=", "planes", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DLA.group_matcher": [[320, 332], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem", "=", "r'^base_layer'", ",", "\n", "blocks", "=", "r'^level(\\d+)'", "if", "coarse", "else", "[", "\n", "# an unusual arch, this achieves somewhat more granularity without getting super messy", "\n", "(", "r'^level(\\d+)\\.tree(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^level(\\d+)\\.root'", ",", "(", "2", ",", ")", ")", ",", "\n", "(", "r'^level(\\d+)'", ",", "(", "1", ",", ")", ")", "\n", "]", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DLA.set_grad_checkpointing": [[333, 336], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "'gradient checkpointing not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DLA.get_classifier": [[337, 340], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DLA.reset_classifier": [[341, 346], ["layers.create_classifier", "torch.Flatten", "torch.Flatten", "torch.Flatten", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "fc", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ",", "use_conv", "=", "True", ")", "\n", "self", ".", "flatten", "=", "nn", ".", "Flatten", "(", "1", ")", "if", "global_pool", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DLA.forward_features": [[347, 356], ["dla.DLA.base_layer", "dla.DLA.level0", "dla.DLA.level1", "dla.DLA.level2", "dla.DLA.level3", "dla.DLA.level4", "dla.DLA.level5"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "base_layer", "(", "x", ")", "\n", "x", "=", "self", ".", "level0", "(", "x", ")", "\n", "x", "=", "self", ".", "level1", "(", "x", ")", "\n", "x", "=", "self", ".", "level2", "(", "x", ")", "\n", "x", "=", "self", ".", "level3", "(", "x", ")", "\n", "x", "=", "self", ".", "level4", "(", "x", ")", "\n", "x", "=", "self", ".", "level5", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DLA.forward_head": [[357, 366], ["dla.DLA.global_pool", "torch.dropout", "torch.dropout", "torch.dropout", "dla.DLA.flatten", "dla.DLA.fc", "dla.DLA.flatten"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ">", "0.", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "if", "pre_logits", ":", "\n", "            ", "return", "x", ".", "flatten", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "self", ".", "flatten", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.DLA.forward": [[367, 371], ["dla.DLA.forward_features", "dla.DLA.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla._cfg": [[23, 31], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bilinear'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'base_layer.0'", ",", "'classifier'", ":", "'fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla._create_dla": [[373, 379], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_dla", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "\n", "DLA", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_strict", "=", "False", ",", "\n", "feature_cfg", "=", "dict", "(", "out_indices", "=", "(", "1", ",", "2", ",", "3", ",", "4", ",", "5", ")", ")", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.dla60_res2net": [[381, 387], ["dict", "dla._create_dla"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla._create_dla"], ["", "@", "register_model", "\n", "def", "dla60_res2net", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "levels", "=", "(", "1", ",", "1", ",", "1", ",", "2", ",", "3", ",", "1", ")", ",", "channels", "=", "(", "16", ",", "32", ",", "128", ",", "256", ",", "512", ",", "1024", ")", ",", "\n", "block", "=", "DlaBottle2neck", ",", "cardinality", "=", "1", ",", "base_width", "=", "28", ",", "**", "kwargs", ")", "\n", "return", "_create_dla", "(", "'dla60_res2net'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.dla60_res2next": [[389, 395], ["dict", "dla._create_dla"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla._create_dla"], ["", "@", "register_model", "\n", "def", "dla60_res2next", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "levels", "=", "(", "1", ",", "1", ",", "1", ",", "2", ",", "3", ",", "1", ")", ",", "channels", "=", "(", "16", ",", "32", ",", "128", ",", "256", ",", "512", ",", "1024", ")", ",", "\n", "block", "=", "DlaBottle2neck", ",", "cardinality", "=", "8", ",", "base_width", "=", "4", ",", "**", "kwargs", ")", "\n", "return", "_create_dla", "(", "'dla60_res2next'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.dla34": [[397, 403], ["dict", "dla._create_dla"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla._create_dla"], ["", "@", "register_model", "\n", "def", "dla34", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "# DLA-34", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "levels", "=", "[", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "1", "]", ",", "channels", "=", "[", "16", ",", "32", ",", "64", ",", "128", ",", "256", ",", "512", "]", ",", "\n", "block", "=", "DlaBasic", ",", "**", "kwargs", ")", "\n", "return", "_create_dla", "(", "'dla34'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.dla46_c": [[405, 411], ["dict", "dla._create_dla"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla._create_dla"], ["", "@", "register_model", "\n", "def", "dla46_c", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "# DLA-46-C", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "levels", "=", "[", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "1", "]", ",", "channels", "=", "[", "16", ",", "32", ",", "64", ",", "64", ",", "128", ",", "256", "]", ",", "\n", "block", "=", "DlaBottleneck", ",", "**", "kwargs", ")", "\n", "return", "_create_dla", "(", "'dla46_c'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.dla46x_c": [[413, 419], ["dict", "dla._create_dla"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla._create_dla"], ["", "@", "register_model", "\n", "def", "dla46x_c", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "# DLA-X-46-C", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "levels", "=", "[", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "1", "]", ",", "channels", "=", "[", "16", ",", "32", ",", "64", ",", "64", ",", "128", ",", "256", "]", ",", "\n", "block", "=", "DlaBottleneck", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "**", "kwargs", ")", "\n", "return", "_create_dla", "(", "'dla46x_c'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.dla60x_c": [[421, 427], ["dict", "dla._create_dla"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla._create_dla"], ["", "@", "register_model", "\n", "def", "dla60x_c", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "# DLA-X-60-C", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "levels", "=", "[", "1", ",", "1", ",", "1", ",", "2", ",", "3", ",", "1", "]", ",", "channels", "=", "[", "16", ",", "32", ",", "64", ",", "64", ",", "128", ",", "256", "]", ",", "\n", "block", "=", "DlaBottleneck", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "**", "kwargs", ")", "\n", "return", "_create_dla", "(", "'dla60x_c'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.dla60": [[429, 435], ["dict", "dla._create_dla"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla._create_dla"], ["", "@", "register_model", "\n", "def", "dla60", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "# DLA-60", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "levels", "=", "[", "1", ",", "1", ",", "1", ",", "2", ",", "3", ",", "1", "]", ",", "channels", "=", "[", "16", ",", "32", ",", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "\n", "block", "=", "DlaBottleneck", ",", "**", "kwargs", ")", "\n", "return", "_create_dla", "(", "'dla60'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.dla60x": [[437, 443], ["dict", "dla._create_dla"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla._create_dla"], ["", "@", "register_model", "\n", "def", "dla60x", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "# DLA-X-60", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "levels", "=", "[", "1", ",", "1", ",", "1", ",", "2", ",", "3", ",", "1", "]", ",", "channels", "=", "[", "16", ",", "32", ",", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "\n", "block", "=", "DlaBottleneck", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "**", "kwargs", ")", "\n", "return", "_create_dla", "(", "'dla60x'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.dla102": [[445, 451], ["dict", "dla._create_dla"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla._create_dla"], ["", "@", "register_model", "\n", "def", "dla102", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "# DLA-102", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "levels", "=", "[", "1", ",", "1", ",", "1", ",", "3", ",", "4", ",", "1", "]", ",", "channels", "=", "[", "16", ",", "32", ",", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "\n", "block", "=", "DlaBottleneck", ",", "shortcut_root", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_dla", "(", "'dla102'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.dla102x": [[453, 459], ["dict", "dla._create_dla"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla._create_dla"], ["", "@", "register_model", "\n", "def", "dla102x", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "# DLA-X-102", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "levels", "=", "[", "1", ",", "1", ",", "1", ",", "3", ",", "4", ",", "1", "]", ",", "channels", "=", "[", "16", ",", "32", ",", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "\n", "block", "=", "DlaBottleneck", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "shortcut_root", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_dla", "(", "'dla102x'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.dla102x2": [[461, 467], ["dict", "dla._create_dla"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla._create_dla"], ["", "@", "register_model", "\n", "def", "dla102x2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "# DLA-X-102 64", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "levels", "=", "[", "1", ",", "1", ",", "1", ",", "3", ",", "4", ",", "1", "]", ",", "channels", "=", "[", "16", ",", "32", ",", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "\n", "block", "=", "DlaBottleneck", ",", "cardinality", "=", "64", ",", "base_width", "=", "4", ",", "shortcut_root", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_dla", "(", "'dla102x2'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla.dla169": [[469, 475], ["dict", "dla._create_dla"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.dla._create_dla"], ["", "@", "register_model", "\n", "def", "dla169", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "# DLA-169", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "levels", "=", "[", "1", ",", "1", ",", "2", ",", "3", ",", "5", ",", "1", "]", ",", "channels", "=", "[", "16", ",", "32", ",", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "\n", "block", "=", "DlaBottleneck", ",", "shortcut_root", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_dla", "(", "'dla169'", ",", "pretrained", ",", "**", "model_kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.clean_state_dict": [[36, 43], ["collections.OrderedDict", "state_dict.items", "k.startswith"], "function", ["None"], ["module", "=", "model", "\n", "if", "hasattr", "(", "model", ",", "'module'", ")", "and", "layer", "[", "0", "]", "!=", "'module'", ":", "\n", "        ", "module", "=", "model", ".", "module", "\n", "", "lst_index", "=", "0", "\n", "module2", "=", "module", "\n", "for", "l", "in", "layer", ":", "\n", "        ", "if", "hasattr", "(", "module2", ",", "l", ")", ":", "\n", "            ", "if", "not", "l", ".", "isdigit", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.load_state_dict": [[45, 64], ["os.path.isfile", "torch.load", "torch.load", "isinstance", "helpers.clean_state_dict", "_logger.info", "_logger.error", "FileNotFoundError", "torch.load.get", "torch.load.get"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.clean_state_dict", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["", "else", ":", "\n", "                ", "module2", "=", "module2", "[", "int", "(", "l", ")", "]", "\n", "", "lst_index", "+=", "1", "\n", "", "", "lst_index", "-=", "1", "\n", "for", "l", "in", "layer", "[", ":", "lst_index", "]", ":", "\n", "        ", "if", "not", "l", ".", "isdigit", "(", ")", ":", "\n", "            ", "module", "=", "getattr", "(", "module", ",", "l", ")", "\n", "", "else", ":", "\n", "            ", "module", "=", "module", "[", "int", "(", "l", ")", "]", "\n", "", "", "l", "=", "layer", "[", "lst_index", "]", "\n", "setattr", "(", "module", ",", "l", ",", "val", ")", "\n", "\n", "\n", "\n", "", "def", "fuse_bn_to_conv", "(", "bn_layer", ",", "conv_layer", ")", ":", "\n", "    ", "bn_st_dict", "=", "bn_layer", ".", "state_dict", "(", ")", "\n", "conv_st_dict", "=", "conv_layer", ".", "state_dict", "(", ")", "\n", "\n", "# BatchNorm params", "\n", "eps", "=", "bn_layer", ".", "eps", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.load_checkpoint": [[66, 77], ["helpers.load_state_dict", "model.load_state_dict", "[].lower", "hasattr", "model.load_pretrained", "NotImplementedError", "os.path.splitext"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.load_state_dict", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.load_state_dict", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer.load_pretrained"], ["var", "=", "bn_st_dict", "[", "'running_var'", "]", "\n", "gamma", "=", "bn_st_dict", "[", "'weight'", "]", "\n", "\n", "if", "'bias'", "in", "bn_st_dict", ":", "\n", "        ", "beta", "=", "bn_st_dict", "[", "'bias'", "]", "\n", "", "else", ":", "\n", "        ", "beta", "=", "torch", ".", "zeros", "(", "gamma", ".", "size", "(", "0", ")", ")", ".", "float", "(", ")", ".", "to", "(", "gamma", ".", "device", ")", "\n", "\n", "# Conv params", "\n", "", "W", "=", "conv_st_dict", "[", "'weight'", "]", "\n", "if", "'bias'", "in", "conv_st_dict", ":", "\n", "        ", "bias", "=", "conv_st_dict", "[", "'bias'", "]", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.resume_checkpoint": [[79, 114], ["os.path.isfile", "torch.load", "torch.load", "_logger.error", "FileNotFoundError", "isinstance", "helpers.clean_state_dict", "model.load_state_dict", "model.load_state_dict", "_logger.info", "optimizer.load_state_dict", "loss_scaler.load_state_dict", "_logger.info", "_logger.info", "_logger.info", "_logger.info"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.clean_state_dict", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.load_state_dict", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.load_state_dict", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.load_state_dict", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.load_state_dict"], ["        ", "bias", "=", "torch", ".", "zeros", "(", "W", ".", "size", "(", "0", ")", ")", ".", "float", "(", ")", ".", "to", "(", "gamma", ".", "device", ")", "\n", "\n", "", "denom", "=", "torch", ".", "sqrt", "(", "var", "+", "eps", ")", "\n", "b", "=", "beta", "-", "gamma", ".", "mul", "(", "mu", ")", ".", "div", "(", "denom", ")", "\n", "A", "=", "gamma", ".", "div", "(", "denom", ")", "\n", "bias", "*=", "A", "\n", "A", "=", "A", ".", "expand_as", "(", "W", ".", "transpose", "(", "0", ",", "-", "1", ")", ")", ".", "transpose", "(", "0", ",", "-", "1", ")", "\n", "\n", "W", ".", "mul_", "(", "A", ")", "\n", "bias", ".", "add_", "(", "b", ")", "\n", "\n", "conv_layer", ".", "weight", ".", "data", ".", "copy_", "(", "W", ")", "\n", "if", "conv_layer", ".", "bias", "is", "None", ":", "\n", "        ", "conv_layer", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "bias", ")", "\n", "", "else", ":", "\n", "        ", "conv_layer", ".", "bias", ".", "data", ".", "copy_", "(", "bias", ")", "\n", "\n", "\n", "", "", "def", "fuse_bn_to_linear", "(", "bn_layer", ",", "linear_layer", ")", ":", "\n", "# print('bn fuse')", "\n", "    ", "bn_st_dict", "=", "bn_layer", ".", "state_dict", "(", ")", "\n", "conv_st_dict", "=", "linear_layer", ".", "state_dict", "(", ")", "\n", "\n", "# BatchNorm params", "\n", "eps", "=", "bn_layer", ".", "eps", "\n", "mu", "=", "bn_st_dict", "[", "'running_mean'", "]", "\n", "var", "=", "bn_st_dict", "[", "'running_var'", "]", "\n", "gamma", "=", "bn_st_dict", "[", "'weight'", "]", "\n", "\n", "if", "'bias'", "in", "bn_st_dict", ":", "\n", "        ", "beta", "=", "bn_st_dict", "[", "'bias'", "]", "\n", "", "else", ":", "\n", "        ", "beta", "=", "torch", ".", "zeros", "(", "gamma", ".", "size", "(", "0", ")", ")", ".", "float", "(", ")", ".", "to", "(", "gamma", ".", "device", ")", "\n", "\n", "# Conv params", "\n", "", "W", "=", "conv_st_dict", "[", "'weight'", "]", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers._resolve_pretrained_source": [[116, 142], ["pretrained_cfg.get", "pretrained_cfg.get", "pretrained_cfg.get", "pretrained_cfg.get", "hub.has_hf_hub", "hub.has_hf_hub"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.has_hf_hub", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.has_hf_hub"], ["        ", "bias", "=", "conv_st_dict", "[", "'bias'", "]", "\n", "", "else", ":", "\n", "        ", "bias", "=", "torch", ".", "zeros", "(", "W", ".", "size", "(", "0", ")", ")", ".", "float", "(", ")", ".", "to", "(", "gamma", ".", "device", ")", "\n", "\n", "", "denom", "=", "torch", ".", "sqrt", "(", "var", "+", "eps", ")", "\n", "b", "=", "beta", "-", "gamma", ".", "mul", "(", "mu", ")", ".", "div", "(", "denom", ")", "\n", "A", "=", "gamma", ".", "div", "(", "denom", ")", "\n", "bias", "*=", "A", "\n", "A", "=", "A", ".", "expand_as", "(", "W", ".", "transpose", "(", "0", ",", "-", "1", ")", ")", ".", "transpose", "(", "0", ",", "-", "1", ")", "\n", "\n", "W", ".", "mul_", "(", "A", ")", "\n", "bias", ".", "add_", "(", "b", ")", "\n", "\n", "linear_layer", ".", "weight", ".", "data", ".", "copy_", "(", "W", ")", "\n", "if", "linear_layer", ".", "bias", "is", "None", ":", "\n", "        ", "linear_layer", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "bias", ")", "\n", "", "else", ":", "\n", "        ", "linear_layer", ".", "bias", ".", "data", ".", "copy_", "(", "bias", ")", "\n", "\n", "\n", "", "", "def", "extract_layers", "(", "model", ")", ":", "\n", "    ", "list_layers", "=", "[", "]", "\n", "for", "n", ",", "p", "in", "model", ".", "named_modules", "(", ")", ":", "\n", "        ", "list_layers", ".", "append", "(", "n", ")", "\n", "", "return", "list_layers", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.set_pretrained_download_progress": [[144, 148], ["None"], "function", ["None"], ["    ", "list_layer", "=", "extract_layers", "(", "resnet", ")", "\n", "assert", "layer_name", "in", "list_layer", "\n", "if", "layer_name", "==", "list_layer", "[", "-", "1", "]", ":", "\n", "        ", "return", "None", "\n", "", "next_bn", "=", "list_layer", "[", "list_layer", ".", "index", "(", "layer_name", ")", "+", "1", "]", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.set_pretrained_check_hash": [[150, 154], ["None"], "function", ["None"], ["        ", "return", "next_bn", "\n", "", "return", "None", "\n", "\n", "\n", "", "def", "compute_next_abn", "(", "layer_name", ",", "resnet", ")", ":", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.load_custom_pretrained": [[156, 197], ["helpers._resolve_pretrained_source", "getattr", "_logger.warning", "_logger.warning", "load_fn", "hasattr", "hub.download_cached_file", "model.load_pretrained", "_logger.warning"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers._resolve_pretrained_source", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.download_cached_file", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer.load_pretrained"], ["assert", "layer_name", "in", "list_layer", "\n", "if", "layer_name", "==", "list_layer", "[", "-", "1", "]", ":", "\n", "        ", "return", "None", "\n", "", "next_bn", "=", "list_layer", "[", "list_layer", ".", "index", "(", "layer_name", ")", "+", "1", "]", "\n", "if", "extract_layer", "(", "resnet", ",", "next_bn", ")", ".", "__class__", ".", "__name__", "==", "'ABN'", ":", "\n", "        ", "return", "next_bn", "\n", "", "return", "None", "\n", "\n", "\n", "", "def", "compute_next_bn_1d", "(", "layer_name", ",", "resnet", ")", ":", "\n", "    ", "list_layer", "=", "extract_layers", "(", "resnet", ")", "\n", "assert", "layer_name", "in", "list_layer", "\n", "if", "layer_name", "==", "list_layer", "[", "-", "1", "]", ":", "\n", "        ", "return", "None", "\n", "", "next_bn", "=", "list_layer", "[", "list_layer", ".", "index", "(", "layer_name", ")", "+", "1", "]", "\n", "if", "extract_layer", "(", "resnet", ",", "next_bn", ")", ".", "__class__", ".", "__name__", "==", "'BatchNorm1d'", ":", "\n", "        ", "return", "next_bn", "\n", "", "return", "None", "\n", "\n", "\n", "", "def", "fuse_bn2d_bn1d_abn", "(", "model", ")", ":", "\n", "    ", "for", "n", ",", "m", "in", "model", ".", "named_modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "next_bn", "=", "compute_next_bn", "(", "n", ",", "model", ")", "\n", "if", "next_bn", "is", "not", "None", ":", "\n", "                ", "next_bn_", "=", "extract_layer", "(", "model", ",", "next_bn", ")", "\n", "fuse_bn_to_conv", "(", "next_bn_", ",", "m", ")", "\n", "set_layer", "(", "model", ",", "next_bn", ",", "nn", ".", "Identity", "(", ")", ")", "\n", "\n", "", "next_abn", "=", "compute_next_abn", "(", "n", ",", "model", ")", "\n", "if", "next_abn", "is", "not", "None", ":", "\n", "                ", "next_bn_", "=", "extract_layer", "(", "model", ",", "next_abn", ")", "\n", "activation", "=", "calc_abn_activation", "(", "next_bn_", ")", "\n", "fuse_bn_to_conv", "(", "next_bn_", ",", "m", ")", "\n", "set_layer", "(", "model", ",", "next_abn", ",", "activation", ")", "\n", "", "", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "Linear", ")", ":", "\n", "            ", "next_bn1d", "=", "compute_next_bn_1d", "(", "n", ",", "model", ")", "\n", "if", "next_bn1d", "is", "not", "None", ":", "\n", "                ", "next_bn1d_", "=", "extract_layer", "(", "model", ",", "next_bn1d", ")", "\n", "fuse_bn_to_linear", "(", "next_bn1d_", ",", "m", ")", "\n", "set_layer", "(", "model", ",", "next_bn1d", ",", "nn", ".", "Identity", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.adapt_input_conv": [[199, 222], ["conv_weight.sum.float", "conv_weight.sum.to", "conv_weight.sum.reshape", "conv_weight.sum.sum", "conv_weight.sum.sum", "NotImplementedError", "int", "math.ceil", "conv_weight.sum.repeat", "float"], "function", ["None"], ["\n", "", "def", "calc_abn_activation", "(", "ABN_layer", ")", ":", "\n", "    ", "from", "inplace_abn", "import", "ABN", "\n", "activation", "=", "nn", ".", "Identity", "(", ")", "\n", "if", "isinstance", "(", "ABN_layer", ",", "ABN", ")", ":", "\n", "        ", "if", "ABN_layer", ".", "activation", "==", "\"relu\"", ":", "\n", "            ", "activation", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "", "elif", "ABN_layer", ".", "activation", "==", "\"leaky_relu\"", ":", "\n", "            ", "activation", "=", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "ABN_layer", ".", "activation_param", ",", "inplace", "=", "True", ")", "\n", "", "elif", "ABN_layer", ".", "activation", "==", "\"elu\"", ":", "\n", "            ", "activation", "=", "nn", ".", "ELU", "(", "alpha", "=", "ABN_layer", ".", "activation_param", ",", "inplace", "=", "True", ")", "\n", "", "", "return", "activation", "\n", "\n", "", "def", "InplacABN_to_ABN", "(", "module", ":", "nn", ".", "Module", ")", "->", "nn", ".", "Module", ":", "\n", "    ", "from", "models", ".", "layers", "import", "InplaceAbn", "\n", "from", "inplace_abn", "import", "ABN", "\n", "# convert all InplaceABN layer to bit-accurate ABN layers.", "\n", "if", "isinstance", "(", "module", ",", "InplaceAbn", ")", ":", "\n", "        ", "module_new", "=", "ABN", "(", "module", ".", "num_features", ",", "activation", "=", "module", ".", "act_name", ",", "\n", "activation_param", "=", "module", ".", "act_param", ")", "\n", "for", "key", "in", "module", ".", "state_dict", "(", ")", ":", "\n", "            ", "module_new", ".", "state_dict", "(", ")", "[", "key", "]", ".", "copy_", "(", "module", ".", "state_dict", "(", ")", "[", "key", "]", ")", "\n", "", "module_new", ".", "training", "=", "module", ".", "training", "\n", "module_new", ".", "weight", ".", "data", "=", "module_new", ".", "weight", ".", "abs", "(", ")", "+", "module_new", ".", "eps", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.load_pretrained": [[224, 302], ["helpers._resolve_pretrained_source", "pretrained_cfg.get", "pretrained_cfg.get", "pretrained_cfg.get", "model.load_state_dict", "getattr", "_logger.info", "helpers.load_state_dict", "isinstance", "isinstance", "_logger.info", "torch.hub.load_state_dict_from_url", "filter_fn", "_logger.info", "hub.load_state_dict_from_hf", "_logger.warning", "filter_fn", "helpers.adapt_input_conv", "_logger.info", "filter_fn.pop", "filter_fn.pop", "_logger.warning"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers._resolve_pretrained_source", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.load_state_dict", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.load_state_dict", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hub.load_state_dict_from_hf", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.adapt_input_conv"], ["", "for", "name", ",", "child", "in", "reversed", "(", "module", ".", "_modules", ".", "items", "(", ")", ")", ":", "\n", "        ", "new_child", "=", "InplacABN_to_ABN", "(", "child", ")", "\n", "if", "new_child", "!=", "child", ":", "\n", "            ", "module", ".", "_modules", "[", "name", "]", "=", "new_child", "\n", "", "", "return", "module", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.extract_layer": [[304, 320], ["layer.split.split", "hasattr", "hasattr", "hasattr", "l.isdigit", "getattr", "int"], "function", ["None"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.set_layer": [[322, 344], ["layer.split.split", "setattr", "hasattr", "hasattr", "l.isdigit", "getattr", "l.isdigit", "getattr", "int", "int"], "function", ["None"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.adapt_model_from_string": [[346, 401], ["model_string.split", "copy.deepcopy", "parent_module.named_modules", "copy.deepcopy.eval", "parent_module.eval", "k.split.split", "[].split", "helpers.extract_layer", "isinstance", "isinstance", "isinstance", "conv", "helpers.set_layer", "isinstance", "int", "layers.BatchNormAct2d", "helpers.set_layer", "isinstance", "torch.BatchNorm2d", "helpers.set_layer", "isinstance", "layers.Linear", "helpers.set_layer", "hasattr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.extract_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.set_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.set_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.set_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.set_layer"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.adapt_model_from_file": [[403, 407], ["os.path.join", "os.path.dirname", "open", "helpers.adapt_model_from_string", "f.read().strip", "f.read"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.adapt_model_from_string"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.pretrained_cfg_for_features": [[409, 416], ["copy.deepcopy", "copy.deepcopy.pop"], "function", ["None"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.set_default_kwargs": [[418, 436], ["pretrained_cfg.get", "kwargs.setdefault", "pretrained_cfg.get", "pretrained_cfg.get", "len", "kwargs.setdefault", "kwargs.setdefault", "len"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.filter_kwargs": [[438, 443], ["kwargs.pop"], "function", ["None"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.update_pretrained_cfg_and_kwargs": [[445, 461], ["pretrained_cfg.get", "helpers.set_default_kwargs", "helpers.filter_kwargs"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.set_default_kwargs", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.filter_kwargs"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.resolve_pretrained_cfg": [[463, 476], ["registry.get_pretrained_cfg", "isinstance", "copy.deepcopy", "kwargs.pop", "copy.deepcopy"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.registry.get_pretrained_cfg"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg": [[478, 568], ["kwargs.pop", "helpers.resolve_pretrained_cfg", "helpers.update_pretrained_cfg_and_kwargs", "resolve_pretrained_cfg.setdefault", "kwargs.pop", "feature_cfg.setdefault", "model_cls", "model_cls", "helpers.adapt_model_from_file", "getattr", "feature_cls.lower.", "helpers.pretrained_cfg_for_features", "kwargs.pop", "kwargs.get", "helpers.load_custom_pretrained", "helpers.load_pretrained", "feature_cfg.pop", "isinstance", "feature_cls.lower.lower", "kwargs.get"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.resolve_pretrained_cfg", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.update_pretrained_cfg_and_kwargs", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.adapt_model_from_file", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.pretrained_cfg_for_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.load_custom_pretrained", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer.load_pretrained", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.model_parameters": [[570, 576], ["model.parameters", "model.parameters"], "function", ["None"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_apply": [[578, 587], ["module.named_children", "fn", "helpers.named_apply", "fn"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_apply"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules": [[589, 598], ["module.named_children", "helpers.named_modules"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules_with_params": [[600, 609], ["module.named_children", "helpers.named_modules_with_params"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules_with_params"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.group_with_matcher": [[614, 673], ["isinstance", "collections.defaultdict", "collections.defaultdict", "sorted", "enumerate", "isinstance", "grouping[].append", "filter", "layer_id_to_param[].extend", "collections.defaultdict.items", "group_matcher.items", "isinstance", "group_matcher", "tuple", "collections.defaultdict.keys", "match_fn.match", "float", "isinstance", "tuple", "re.compile", "match_fn.match.groups", "map", "helpers.group_with_matcher._get_grouping"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.group_matcher"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.group_parameters": [[675, 683], ["helpers.group_with_matcher", "module.named_parameters"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.group_with_matcher"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.group_modules": [[685, 693], ["helpers.group_with_matcher", "helpers.named_modules_with_params"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.group_with_matcher", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules_with_params"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq": [[695, 763], ["isinstance", "len", "range", "tuple.children", "itertools.chain.from_iterable", "isinstance", "tuple", "min", "torch.utils.checkpoint.checkpoint", "range", "helpers.checkpoint_seq.run_function"], "function", ["None"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.flatten_modules": [[765, 788], ["isinstance", "isinstance", "isinstance", "helpers.flatten_modules", "module.named_children"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.flatten_modules"], []], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._cfg": [[14, 22], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'conv1'", ",", "'classifier'", ":", "'fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet": [[60, 62], ["helpers.build_model_with_cfg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["def", "_create_resnet", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "ResNet", ",", "variant", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnet18_v1b": [[64, 70], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnet18_v1b", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "BasicBlock", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnet18_v1b'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnet34_v1b": [[72, 78], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnet34_v1b", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-34 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "BasicBlock", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnet34_v1b'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnet50_v1b": [[80, 86], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnet50_v1b", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnet50_v1b'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnet101_v1b": [[88, 94], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnet101_v1b", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnet101_v1b'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnet152_v1b": [[96, 102], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnet152_v1b", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-152 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnet152_v1b'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnet50_v1c": [[104, 110], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnet50_v1c", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnet50_v1c'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnet101_v1c": [[112, 118], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnet101_v1c", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnet101_v1c'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnet152_v1c": [[120, 126], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnet152_v1c", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-152 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnet152_v1c'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnet50_v1d": [[128, 135], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnet50_v1d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnet50_v1d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnet101_v1d": [[137, 144], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnet101_v1d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnet101_v1d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnet152_v1d": [[146, 153], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnet152_v1d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-152 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnet152_v1d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnet50_v1s": [[155, 162], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnet50_v1s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "stem_width", "=", "64", ",", "stem_type", "=", "'deep'", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnet50_v1s'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnet101_v1s": [[165, 172], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnet101_v1s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "stem_width", "=", "64", ",", "stem_type", "=", "'deep'", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnet101_v1s'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnet152_v1s": [[174, 181], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnet152_v1s", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-152 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "stem_width", "=", "64", ",", "stem_type", "=", "'deep'", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnet152_v1s'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnext50_32x4d": [[184, 190], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnext50_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt50-32x4d model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnext50_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnext101_32x4d": [[192, 198], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnext101_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt-101 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnext101_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_resnext101_64x4d": [[200, 206], ["dict", "gluon_resnet._create_resnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_resnext101_64x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt-101 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "64", ",", "base_width", "=", "4", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_resnext101_64x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_seresnext50_32x4d": [[208, 216], ["dict", "gluon_resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_seresnext50_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a SEResNeXt50-32x4d model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "SEModule", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_seresnext50_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_seresnext101_32x4d": [[218, 226], ["dict", "gluon_resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_seresnext101_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a SEResNeXt-101-32x4d model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "SEModule", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_seresnext101_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_seresnext101_64x4d": [[228, 236], ["dict", "gluon_resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_seresnext101_64x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a SEResNeXt-101-64x4d model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "cardinality", "=", "64", ",", "base_width", "=", "4", ",", "\n", "block_args", "=", "dict", "(", "attn_layer", "=", "SEModule", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_seresnext101_64x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet.gluon_senet154": [[238, 246], ["dict", "gluon_resnet._create_resnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.gluon_resnet._create_resnet"], ["", "@", "register_model", "\n", "def", "gluon_senet154", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs an SENet-154 model.\n    \"\"\"", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "Bottleneck", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "cardinality", "=", "64", ",", "base_width", "=", "4", ",", "stem_type", "=", "'deep'", ",", "\n", "down_kernel_size", "=", "3", ",", "block_reduce_first", "=", "2", ",", "block_args", "=", "dict", "(", "attn_layer", "=", "SEModule", ")", ",", "**", "kwargs", ")", "\n", "return", "_create_resnet", "(", "'gluon_senet154'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.PatchEmbed.__init__": [[92, 119], ["torch.Module.__init__", "layers.to_2tuple", "layers.to_2tuple", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "embed_dim", "=", "768", ",", "multi_conv", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "patch_size", "=", "to_2tuple", "(", "patch_size", ")", "\n", "num_patches", "=", "(", "img_size", "[", "1", "]", "//", "patch_size", "[", "1", "]", ")", "*", "(", "img_size", "[", "0", "]", "//", "patch_size", "[", "0", "]", ")", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "self", ".", "num_patches", "=", "num_patches", "\n", "if", "multi_conv", ":", "\n", "            ", "if", "patch_size", "[", "0", "]", "==", "12", ":", "\n", "                ", "self", ".", "proj", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_chans", ",", "embed_dim", "//", "4", ",", "kernel_size", "=", "7", ",", "stride", "=", "4", ",", "padding", "=", "3", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "embed_dim", "//", "4", ",", "embed_dim", "//", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "3", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "embed_dim", "//", "2", ",", "embed_dim", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", ")", "\n", "", "elif", "patch_size", "[", "0", "]", "==", "16", ":", "\n", "                ", "self", ".", "proj", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_chans", ",", "embed_dim", "//", "4", ",", "kernel_size", "=", "7", ",", "stride", "=", "4", ",", "padding", "=", "3", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "embed_dim", "//", "4", ",", "embed_dim", "//", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "embed_dim", "//", "2", ",", "embed_dim", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "proj", "=", "nn", ".", "Conv2d", "(", "in_chans", ",", "embed_dim", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "patch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.PatchEmbed.forward": [[120, 129], ["layers._assert", "layers._assert", "crossvit.PatchEmbed.proj().flatten().transpose", "crossvit.PatchEmbed.proj().flatten", "crossvit.PatchEmbed.proj"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "# FIXME look at relaxing size constraints", "\n", "_assert", "(", "H", "==", "self", ".", "img_size", "[", "0", "]", ",", "\n", "f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"", ")", "\n", "_assert", "(", "W", "==", "self", ".", "img_size", "[", "1", "]", ",", "\n", "f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.CrossAttention.__init__": [[132, 145], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "# NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights", "\n", "self", ".", "scale", "=", "qk_scale", "or", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "wq", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "wk", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "wv", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.CrossAttention.forward": [[146, 163], ["crossvit.CrossAttention.wq().reshape().permute", "crossvit.CrossAttention.wk().reshape().permute", "crossvit.CrossAttention.wv().reshape().permute", "crossvit.CrossAttention.softmax", "crossvit.CrossAttention.attn_drop", "crossvit.CrossAttention.proj", "crossvit.CrossAttention.proj_drop", "crossvit.CrossAttention.wq().reshape", "crossvit.CrossAttention.wk().reshape", "crossvit.CrossAttention.wv().reshape", "crossvit.CrossAttention.transpose", "crossvit.CrossAttention.wq", "crossvit.CrossAttention.wk", "crossvit.CrossAttention.wv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "# B1C -> B1H(C/H) -> BH1(C/H)", "\n", "q", "=", "self", ".", "wq", "(", "x", "[", ":", ",", "0", ":", "1", ",", "...", "]", ")", ".", "reshape", "(", "B", ",", "1", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "# BNC -> BNH(C/H) -> BHN(C/H)", "\n", "k", "=", "self", ".", "wk", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "# BNC -> BNH(C/H) -> BHN(C/H)", "\n", "v", "=", "self", ".", "wv", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "*", "self", ".", "scale", "# BH1(C/H) @ BH(C/H)N -> BH1N", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "1", ",", "C", ")", "# (BH1N @ BHN(C/H)) -> BH1(C/H) -> B1H(C/H) -> B1C", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.CrossAttentionBlock.__init__": [[167, 176], ["torch.Module.__init__", "norm_layer", "crossvit.CrossAttention", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dim", ",", "num_heads", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "\n", "drop_path", "=", "0.", ",", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn", "=", "CrossAttention", "(", "\n", "dim", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "qk_scale", "=", "qk_scale", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ")", "\n", "# NOTE: drop path for stochastic depth, we shall see if this is better than dropout here", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.CrossAttentionBlock.forward": [[177, 180], ["crossvit.CrossAttentionBlock.drop_path", "crossvit.CrossAttentionBlock.attn", "crossvit.CrossAttentionBlock.norm1"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "[", ":", ",", "0", ":", "1", ",", "...", "]", "+", "self", ".", "drop_path", "(", "self", ".", "attn", "(", "self", ".", "norm1", "(", "x", ")", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.MultiScaleBlock.__init__": [[184, 237], ["torch.Module.__init__", "len", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "range", "len", "crossvit.MultiScaleBlock.projs.append", "crossvit.MultiScaleBlock.revert_projs.append", "tmp.append", "len", "crossvit.MultiScaleBlock.blocks.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "crossvit.MultiScaleBlock.fusion.append", "range", "crossvit.MultiScaleBlock.fusion.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "vision_transformer.Block", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "norm_layer", "act_layer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "crossvit.CrossAttentionBlock", "tmp.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "norm_layer", "act_layer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "crossvit.CrossAttentionBlock"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "patches", ",", "depth", ",", "num_heads", ",", "mlp_ratio", ",", "qkv_bias", "=", "False", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "\n", "drop_path", "=", "0.", ",", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "num_branches", "=", "len", "(", "dim", ")", "\n", "self", ".", "num_branches", "=", "num_branches", "\n", "# different branch could have different embedding size, the first one is the base", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "d", "in", "range", "(", "num_branches", ")", ":", "\n", "            ", "tmp", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "depth", "[", "d", "]", ")", ":", "\n", "                ", "tmp", ".", "append", "(", "Block", "(", "\n", "dim", "=", "dim", "[", "d", "]", ",", "num_heads", "=", "num_heads", "[", "d", "]", ",", "mlp_ratio", "=", "mlp_ratio", "[", "d", "]", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "drop", "=", "drop", ",", "attn_drop", "=", "attn_drop", ",", "drop_path", "=", "drop_path", "[", "i", "]", ",", "norm_layer", "=", "norm_layer", ")", ")", "\n", "", "if", "len", "(", "tmp", ")", "!=", "0", ":", "\n", "                ", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "tmp", ")", ")", "\n", "\n", "", "", "if", "len", "(", "self", ".", "blocks", ")", "==", "0", ":", "\n", "            ", "self", ".", "blocks", "=", "None", "\n", "\n", "", "self", ".", "projs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "d", "in", "range", "(", "num_branches", ")", ":", "\n", "            ", "if", "dim", "[", "d", "]", "==", "dim", "[", "(", "d", "+", "1", ")", "%", "num_branches", "]", "and", "False", ":", "\n", "                ", "tmp", "=", "[", "nn", ".", "Identity", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "tmp", "=", "[", "norm_layer", "(", "dim", "[", "d", "]", ")", ",", "act_layer", "(", ")", ",", "nn", ".", "Linear", "(", "dim", "[", "d", "]", ",", "dim", "[", "(", "d", "+", "1", ")", "%", "num_branches", "]", ")", "]", "\n", "", "self", ".", "projs", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "tmp", ")", ")", "\n", "\n", "", "self", ".", "fusion", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "d", "in", "range", "(", "num_branches", ")", ":", "\n", "            ", "d_", "=", "(", "d", "+", "1", ")", "%", "num_branches", "\n", "nh", "=", "num_heads", "[", "d_", "]", "\n", "if", "depth", "[", "-", "1", "]", "==", "0", ":", "# backward capability:", "\n", "                ", "self", ".", "fusion", ".", "append", "(", "\n", "CrossAttentionBlock", "(", "\n", "dim", "=", "dim", "[", "d_", "]", ",", "num_heads", "=", "nh", ",", "mlp_ratio", "=", "mlp_ratio", "[", "d", "]", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "drop", "=", "drop", ",", "attn_drop", "=", "attn_drop", ",", "drop_path", "=", "drop_path", "[", "-", "1", "]", ",", "norm_layer", "=", "norm_layer", ")", ")", "\n", "", "else", ":", "\n", "                ", "tmp", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "depth", "[", "-", "1", "]", ")", ":", "\n", "                    ", "tmp", ".", "append", "(", "CrossAttentionBlock", "(", "\n", "dim", "=", "dim", "[", "d_", "]", ",", "num_heads", "=", "nh", ",", "mlp_ratio", "=", "mlp_ratio", "[", "d", "]", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "drop", "=", "drop", ",", "attn_drop", "=", "attn_drop", ",", "drop_path", "=", "drop_path", "[", "-", "1", "]", ",", "norm_layer", "=", "norm_layer", ")", ")", "\n", "", "self", ".", "fusion", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "tmp", ")", ")", "\n", "\n", "", "", "self", ".", "revert_projs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "d", "in", "range", "(", "num_branches", ")", ":", "\n", "            ", "if", "dim", "[", "(", "d", "+", "1", ")", "%", "num_branches", "]", "==", "dim", "[", "d", "]", "and", "False", ":", "\n", "                ", "tmp", "=", "[", "nn", ".", "Identity", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "tmp", "=", "[", "norm_layer", "(", "dim", "[", "(", "d", "+", "1", ")", "%", "num_branches", "]", ")", ",", "act_layer", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "dim", "[", "(", "d", "+", "1", ")", "%", "num_branches", "]", ",", "dim", "[", "d", "]", ")", "]", "\n", "", "self", ".", "revert_projs", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "tmp", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.MultiScaleBlock.forward": [[238, 258], ["enumerate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "enumerate", "enumerate", "outs_b.append", "torch.jit.annotate.append", "torch.jit.annotate.append", "torch.jit.annotate.append", "torch.jit.annotate.append", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fusion", "revert_proj", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "outs.append", "block", "proj"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ":", "List", "[", "torch", ".", "Tensor", "]", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "outs_b", "=", "[", "]", "\n", "for", "i", ",", "block", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "            ", "outs_b", ".", "append", "(", "block", "(", "x", "[", "i", "]", ")", ")", "\n", "\n", "# only take the cls token out", "\n", "", "proj_cls_token", "=", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "torch", ".", "Tensor", "]", ",", "[", "]", ")", "\n", "for", "i", ",", "proj", "in", "enumerate", "(", "self", ".", "projs", ")", ":", "\n", "            ", "proj_cls_token", ".", "append", "(", "proj", "(", "outs_b", "[", "i", "]", "[", ":", ",", "0", ":", "1", ",", "...", "]", ")", ")", "\n", "\n", "# cross attention", "\n", "", "outs", "=", "[", "]", "\n", "for", "i", ",", "(", "fusion", ",", "revert_proj", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "fusion", ",", "self", ".", "revert_projs", ")", ")", ":", "\n", "            ", "tmp", "=", "torch", ".", "cat", "(", "(", "proj_cls_token", "[", "i", "]", ",", "outs_b", "[", "(", "i", "+", "1", ")", "%", "self", ".", "num_branches", "]", "[", ":", ",", "1", ":", ",", "...", "]", ")", ",", "dim", "=", "1", ")", "\n", "tmp", "=", "fusion", "(", "tmp", ")", "\n", "reverted_proj_cls_token", "=", "revert_proj", "(", "tmp", "[", ":", ",", "0", ":", "1", ",", "...", "]", ")", "\n", "tmp", "=", "torch", ".", "cat", "(", "(", "reverted_proj_cls_token", ",", "outs_b", "[", "i", "]", "[", ":", ",", "1", ":", ",", "...", "]", ")", ",", "dim", "=", "1", ")", "\n", "outs", ".", "append", "(", "tmp", ")", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.CrossViT.__init__": [[289, 344], ["functools.partial", "torch.Module.__init__", "layers.to_2tuple", "layers.to_2tuple", "crossvit._compute_num_patches", "len", "sum", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "zip", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "sum", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "enumerate", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "crossvit.CrossViT.apply", "tuple", "setattr", "setattr", "crossvit.CrossViT.patch_embed.append", "x.item", "crossvit.MultiScaleBlock", "crossvit.CrossViT.blocks.append", "layers.trunc_normal_", "layers.trunc_normal_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "crossvit.PatchEmbed", "sum", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "max", "norm_layer", "getattr", "getattr", "int", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "range"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit._compute_num_patches", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["def", "__init__", "(", "\n", "self", ",", "img_size", "=", "224", ",", "img_scale", "=", "(", "1.0", ",", "1.0", ")", ",", "patch_size", "=", "(", "8", ",", "16", ")", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "\n", "embed_dim", "=", "(", "192", ",", "384", ")", ",", "depth", "=", "(", "(", "1", ",", "3", ",", "1", ")", ",", "(", "1", ",", "3", ",", "1", ")", ",", "(", "1", ",", "3", ",", "1", ")", ")", ",", "num_heads", "=", "(", "6", ",", "12", ")", ",", "mlp_ratio", "=", "(", "2.", ",", "2.", ",", "4.", ")", ",", "\n", "multi_conv", "=", "False", ",", "crop_scale", "=", "False", ",", "qkv_bias", "=", "True", ",", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "global_pool", "=", "'token'", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "global_pool", "in", "(", "'token'", ",", "'avg'", ")", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "self", ".", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "img_scale", "=", "to_2tuple", "(", "img_scale", ")", "\n", "self", ".", "img_size_scaled", "=", "[", "tuple", "(", "[", "int", "(", "sj", "*", "si", ")", "for", "sj", "in", "self", ".", "img_size", "]", ")", "for", "si", "in", "img_scale", "]", "\n", "self", ".", "crop_scale", "=", "crop_scale", "# crop instead of interpolate for scale", "\n", "num_patches", "=", "_compute_num_patches", "(", "self", ".", "img_size_scaled", ",", "patch_size", ")", "\n", "self", ".", "num_branches", "=", "len", "(", "patch_size", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_features", "=", "sum", "(", "embed_dim", ")", "\n", "self", ".", "patch_embed", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "# hard-coded for torch jit script", "\n", "for", "i", "in", "range", "(", "self", ".", "num_branches", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "f'pos_embed_{i}'", ",", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", "+", "num_patches", "[", "i", "]", ",", "embed_dim", "[", "i", "]", ")", ")", ")", "\n", "setattr", "(", "self", ",", "f'cls_token_{i}'", ",", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "embed_dim", "[", "i", "]", ")", ")", ")", "\n", "\n", "", "for", "im_s", ",", "p", ",", "d", "in", "zip", "(", "self", ".", "img_size_scaled", ",", "patch_size", ",", "embed_dim", ")", ":", "\n", "            ", "self", ".", "patch_embed", ".", "append", "(", "\n", "PatchEmbed", "(", "img_size", "=", "im_s", ",", "patch_size", "=", "p", ",", "in_chans", "=", "in_chans", ",", "embed_dim", "=", "d", ",", "multi_conv", "=", "multi_conv", ")", ")", "\n", "\n", "", "self", ".", "pos_drop", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", "\n", "\n", "total_depth", "=", "sum", "(", "[", "sum", "(", "x", "[", "-", "2", ":", "]", ")", "for", "x", "in", "depth", "]", ")", "\n", "dpr", "=", "[", "x", ".", "item", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "total_depth", ")", "]", "# stochastic depth decay rule", "\n", "dpr_ptr", "=", "0", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "idx", ",", "block_cfg", "in", "enumerate", "(", "depth", ")", ":", "\n", "            ", "curr_depth", "=", "max", "(", "block_cfg", "[", ":", "-", "1", "]", ")", "+", "block_cfg", "[", "-", "1", "]", "\n", "dpr_", "=", "dpr", "[", "dpr_ptr", ":", "dpr_ptr", "+", "curr_depth", "]", "\n", "blk", "=", "MultiScaleBlock", "(", "\n", "embed_dim", ",", "num_patches", ",", "block_cfg", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr_", ",", "norm_layer", "=", "norm_layer", ")", "\n", "dpr_ptr", "+=", "curr_depth", "\n", "self", ".", "blocks", ".", "append", "(", "blk", ")", "\n", "\n", "", "self", ".", "norm", "=", "nn", ".", "ModuleList", "(", "[", "norm_layer", "(", "embed_dim", "[", "i", "]", ")", "for", "i", "in", "range", "(", "self", ".", "num_branches", ")", "]", ")", "\n", "self", ".", "head", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "Linear", "(", "embed_dim", "[", "i", "]", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_branches", ")", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_branches", ")", ":", "\n", "            ", "trunc_normal_", "(", "getattr", "(", "self", ",", "f'pos_embed_{i}'", ")", ",", "std", "=", ".02", ")", "\n", "trunc_normal_", "(", "getattr", "(", "self", ",", "f'cls_token_{i}'", ")", ",", "std", "=", ".02", ")", "\n", "\n", "", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.CrossViT._init_weights": [[345, 353], ["isinstance", "layers.trunc_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", ".02", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.CrossViT.no_weight_decay": [[354, 363], ["set", "range", "set.add", "getattr", "set.add"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "out", "=", "set", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_branches", ")", ":", "\n", "            ", "out", ".", "add", "(", "f'cls_token_{i}'", ")", "\n", "pe", "=", "getattr", "(", "self", ",", "f'pos_embed_{i}'", ",", "None", ")", "\n", "if", "pe", "is", "not", "None", "and", "pe", ".", "requires_grad", ":", "\n", "                ", "out", ".", "add", "(", "f'pos_embed_{i}'", ")", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.CrossViT.group_matcher": [[364, 369], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^cls_token|pos_embed|patch_embed'", ",", "# stem and embed", "\n", "blocks", "=", "[", "(", "r'^blocks\\.(\\d+)'", ",", "None", ")", ",", "(", "r'^norm'", ",", "(", "99999", ",", ")", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.CrossViT.set_grad_checkpointing": [[371, 374], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "'gradient checkpointing not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.CrossViT.get_classifier": [[375, 378], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.CrossViT.reset_classifier": [[379, 387], ["torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "range"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "None", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "if", "global_pool", "is", "not", "None", ":", "\n", "            ", "assert", "global_pool", "in", "(", "'token'", ",", "'avg'", ")", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "", "self", ".", "head", "=", "nn", ".", "ModuleList", "(", "\n", "[", "nn", ".", "Linear", "(", "self", ".", "embed_dim", "[", "i", "]", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "for", "i", "in", "\n", "range", "(", "self", ".", "num_branches", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.CrossViT.forward_features": [[388, 410], ["enumerate", "enumerate", "crossvit.scale_image", "patch_embed", "cls_tokens.expand.expand.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "crossvit.CrossViT.pos_drop", "blk.append", "blk", "norm", "enumerate"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.scale_image"], ["", "def", "forward_features", "(", "self", ",", "x", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "        ", "B", "=", "x", ".", "shape", "[", "0", "]", "\n", "xs", "=", "[", "]", "\n", "for", "i", ",", "patch_embed", "in", "enumerate", "(", "self", ".", "patch_embed", ")", ":", "\n", "            ", "x_", "=", "x", "\n", "ss", "=", "self", ".", "img_size_scaled", "[", "i", "]", "\n", "x_", "=", "scale_image", "(", "x_", ",", "ss", ",", "self", ".", "crop_scale", ")", "\n", "x_", "=", "patch_embed", "(", "x_", ")", "\n", "cls_tokens", "=", "self", ".", "cls_token_0", "if", "i", "==", "0", "else", "self", ".", "cls_token_1", "# hard-coded for torch jit script", "\n", "cls_tokens", "=", "cls_tokens", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", "\n", "x_", "=", "torch", ".", "cat", "(", "(", "cls_tokens", ",", "x_", ")", ",", "dim", "=", "1", ")", "\n", "pos_embed", "=", "self", ".", "pos_embed_0", "if", "i", "==", "0", "else", "self", ".", "pos_embed_1", "# hard-coded for torch jit script", "\n", "x_", "=", "x_", "+", "pos_embed", "\n", "x_", "=", "self", ".", "pos_drop", "(", "x_", ")", "\n", "xs", ".", "append", "(", "x_", ")", "\n", "\n", "", "for", "i", ",", "blk", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "            ", "xs", "=", "blk", "(", "xs", ")", "\n", "\n", "# NOTE: was before branch token section, move to here to assure all branch token are before layer norm", "\n", "", "xs", "=", "[", "norm", "(", "xs", "[", "i", "]", ")", "for", "i", ",", "norm", "in", "enumerate", "(", "self", ".", "norm", ")", "]", "\n", "return", "xs", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.CrossViT.forward_head": [[411, 416], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "isinstance", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x[].mean", "head", "enumerate"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "xs", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "pre_logits", ":", "bool", "=", "False", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "xs", "=", "[", "x", "[", ":", ",", "1", ":", "]", ".", "mean", "(", "dim", "=", "1", ")", "for", "x", "in", "xs", "]", "if", "self", ".", "global_pool", "==", "'avg'", "else", "[", "x", "[", ":", ",", "0", "]", "for", "x", "in", "xs", "]", "\n", "if", "pre_logits", "or", "isinstance", "(", "self", ".", "head", "[", "0", "]", ",", "nn", ".", "Identity", ")", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "x", "for", "x", "in", "xs", "]", ",", "dim", "=", "1", ")", "\n", "", "return", "torch", ".", "mean", "(", "torch", ".", "stack", "(", "[", "head", "(", "xs", "[", "i", "]", ")", "for", "i", ",", "head", "in", "enumerate", "(", "self", ".", "head", ")", "]", ",", "dim", "=", "0", ")", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.CrossViT.forward": [[417, 421], ["crossvit.CrossViT.forward_features", "crossvit.CrossViT.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "xs", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "xs", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit._cfg": [[44, 52], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "240", ",", "240", ")", ",", "'pool_size'", ":", "None", ",", "'crop_pct'", ":", "0.875", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'first_conv'", ":", "(", "'patch_embed.0.proj'", ",", "'patch_embed.1.proj'", ")", ",", "\n", "'classifier'", ":", "(", "'head.0'", ",", "'head.1'", ")", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit._compute_num_patches": [[260, 262], ["zip"], "function", ["None"], ["", "", "def", "_compute_num_patches", "(", "img_size", ",", "patches", ")", ":", "\n", "    ", "return", "[", "i", "[", "0", "]", "//", "p", "*", "i", "[", "1", "]", "//", "p", "for", "i", ",", "p", "in", "zip", "(", "img_size", ",", "patches", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.scale_image": [[264, 283], ["torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "int", "int", "round", "round"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate"], ["", "@", "register_notrace_function", "\n", "def", "scale_image", "(", "x", ",", "ss", ":", "Tuple", "[", "int", ",", "int", "]", ",", "crop_scale", ":", "bool", "=", "False", ")", ":", "# annotations for torchscript", "\n", "    ", "\"\"\"\n    Pulled out of CrossViT.forward_features to bury conditional logic in a leaf node for FX tracing.\n    Args:\n        x (Tensor): input image\n        ss (tuple[int, int]): height and width to scale to\n        crop_scale (bool): whether to crop instead of interpolate to achieve the desired scale. Defaults to False\n    Returns:\n        Tensor: the \"scaled\" image batch tensor\n    \"\"\"", "\n", "H", ",", "W", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "\n", "if", "H", "!=", "ss", "[", "0", "]", "or", "W", "!=", "ss", "[", "1", "]", ":", "\n", "        ", "if", "crop_scale", "and", "ss", "[", "0", "]", "<=", "H", "and", "ss", "[", "1", "]", "<=", "W", ":", "\n", "            ", "cu", ",", "cl", "=", "int", "(", "round", "(", "(", "H", "-", "ss", "[", "0", "]", ")", "/", "2.", ")", ")", ",", "int", "(", "round", "(", "(", "W", "-", "ss", "[", "1", "]", ")", "/", "2.", ")", ")", "\n", "x", "=", "x", "[", ":", ",", ":", ",", "cu", ":", "cu", "+", "ss", "[", "0", "]", ",", "cl", ":", "cl", "+", "ss", "[", "1", "]", "]", "\n", "", "else", ":", "\n", "            ", "x", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "x", ",", "size", "=", "ss", ",", "mode", "=", "'bicubic'", ",", "align_corners", "=", "False", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit._create_crossvit": [[423, 441], ["kwargs.get", "helpers.build_model_with_cfg", "RuntimeError", "state_dict.keys", "key.replace"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_crossvit", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", ".", "get", "(", "'features_only'", ",", "None", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'features_only not implemented for Vision Transformer models.'", ")", "\n", "\n", "", "def", "pretrained_filter_fn", "(", "state_dict", ")", ":", "\n", "        ", "new_state_dict", "=", "{", "}", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "'pos_embed'", "in", "key", "or", "'cls_token'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "\".\"", ",", "\"_\"", ")", "\n", "", "else", ":", "\n", "                ", "new_key", "=", "key", "\n", "", "new_state_dict", "[", "new_key", "]", "=", "state_dict", "[", "key", "]", "\n", "", "return", "new_state_dict", "\n", "\n", "", "return", "build_model_with_cfg", "(", "\n", "CrossViT", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_filter_fn", "=", "pretrained_filter_fn", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.crossvit_tiny_240": [[443, 450], ["dict", "crossvit._create_crossvit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit._create_crossvit"], ["", "@", "register_model", "\n", "def", "crossvit_tiny_240", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "img_scale", "=", "(", "1.0", ",", "224", "/", "240", ")", ",", "patch_size", "=", "[", "12", ",", "16", "]", ",", "embed_dim", "=", "[", "96", ",", "192", "]", ",", "depth", "=", "[", "[", "1", ",", "4", ",", "0", "]", ",", "[", "1", ",", "4", ",", "0", "]", ",", "[", "1", ",", "4", ",", "0", "]", "]", ",", "\n", "num_heads", "=", "[", "3", ",", "3", "]", ",", "mlp_ratio", "=", "[", "4", ",", "4", ",", "1", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_crossvit", "(", "variant", "=", "'crossvit_tiny_240'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.crossvit_small_240": [[452, 459], ["dict", "crossvit._create_crossvit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit._create_crossvit"], ["", "@", "register_model", "\n", "def", "crossvit_small_240", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "img_scale", "=", "(", "1.0", ",", "224", "/", "240", ")", ",", "patch_size", "=", "[", "12", ",", "16", "]", ",", "embed_dim", "=", "[", "192", ",", "384", "]", ",", "depth", "=", "[", "[", "1", ",", "4", ",", "0", "]", ",", "[", "1", ",", "4", ",", "0", "]", ",", "[", "1", ",", "4", ",", "0", "]", "]", ",", "\n", "num_heads", "=", "[", "6", ",", "6", "]", ",", "mlp_ratio", "=", "[", "4", ",", "4", ",", "1", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_crossvit", "(", "variant", "=", "'crossvit_small_240'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.crossvit_base_240": [[461, 468], ["dict", "crossvit._create_crossvit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit._create_crossvit"], ["", "@", "register_model", "\n", "def", "crossvit_base_240", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "img_scale", "=", "(", "1.0", ",", "224", "/", "240", ")", ",", "patch_size", "=", "[", "12", ",", "16", "]", ",", "embed_dim", "=", "[", "384", ",", "768", "]", ",", "depth", "=", "[", "[", "1", ",", "4", ",", "0", "]", ",", "[", "1", ",", "4", ",", "0", "]", ",", "[", "1", ",", "4", ",", "0", "]", "]", ",", "\n", "num_heads", "=", "[", "12", ",", "12", "]", ",", "mlp_ratio", "=", "[", "4", ",", "4", ",", "1", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_crossvit", "(", "variant", "=", "'crossvit_base_240'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.crossvit_9_240": [[470, 477], ["dict", "crossvit._create_crossvit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit._create_crossvit"], ["", "@", "register_model", "\n", "def", "crossvit_9_240", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "img_scale", "=", "(", "1.0", ",", "224", "/", "240", ")", ",", "patch_size", "=", "[", "12", ",", "16", "]", ",", "embed_dim", "=", "[", "128", ",", "256", "]", ",", "depth", "=", "[", "[", "1", ",", "3", ",", "0", "]", ",", "[", "1", ",", "3", ",", "0", "]", ",", "[", "1", ",", "3", ",", "0", "]", "]", ",", "\n", "num_heads", "=", "[", "4", ",", "4", "]", ",", "mlp_ratio", "=", "[", "3", ",", "3", ",", "1", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_crossvit", "(", "variant", "=", "'crossvit_9_240'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.crossvit_15_240": [[479, 486], ["dict", "crossvit._create_crossvit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit._create_crossvit"], ["", "@", "register_model", "\n", "def", "crossvit_15_240", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "img_scale", "=", "(", "1.0", ",", "224", "/", "240", ")", ",", "patch_size", "=", "[", "12", ",", "16", "]", ",", "embed_dim", "=", "[", "192", ",", "384", "]", ",", "depth", "=", "[", "[", "1", ",", "5", ",", "0", "]", ",", "[", "1", ",", "5", ",", "0", "]", ",", "[", "1", ",", "5", ",", "0", "]", "]", ",", "\n", "num_heads", "=", "[", "6", ",", "6", "]", ",", "mlp_ratio", "=", "[", "3", ",", "3", ",", "1", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_crossvit", "(", "variant", "=", "'crossvit_15_240'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.crossvit_18_240": [[488, 495], ["dict", "crossvit._create_crossvit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit._create_crossvit"], ["", "@", "register_model", "\n", "def", "crossvit_18_240", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "img_scale", "=", "(", "1.0", ",", "224", "/", "240", ")", ",", "patch_size", "=", "[", "12", ",", "16", "]", ",", "embed_dim", "=", "[", "224", ",", "448", "]", ",", "depth", "=", "[", "[", "1", ",", "6", ",", "0", "]", ",", "[", "1", ",", "6", ",", "0", "]", ",", "[", "1", ",", "6", ",", "0", "]", "]", ",", "\n", "num_heads", "=", "[", "7", ",", "7", "]", ",", "mlp_ratio", "=", "[", "3", ",", "3", ",", "1", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_crossvit", "(", "variant", "=", "'crossvit_18_240'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.crossvit_9_dagger_240": [[497, 504], ["dict", "crossvit._create_crossvit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit._create_crossvit"], ["", "@", "register_model", "\n", "def", "crossvit_9_dagger_240", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "img_scale", "=", "(", "1.0", ",", "224", "/", "240", ")", ",", "patch_size", "=", "[", "12", ",", "16", "]", ",", "embed_dim", "=", "[", "128", ",", "256", "]", ",", "depth", "=", "[", "[", "1", ",", "3", ",", "0", "]", ",", "[", "1", ",", "3", ",", "0", "]", ",", "[", "1", ",", "3", ",", "0", "]", "]", ",", "\n", "num_heads", "=", "[", "4", ",", "4", "]", ",", "mlp_ratio", "=", "[", "3", ",", "3", ",", "1", "]", ",", "multi_conv", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_crossvit", "(", "variant", "=", "'crossvit_9_dagger_240'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.crossvit_15_dagger_240": [[506, 513], ["dict", "crossvit._create_crossvit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit._create_crossvit"], ["", "@", "register_model", "\n", "def", "crossvit_15_dagger_240", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "img_scale", "=", "(", "1.0", ",", "224", "/", "240", ")", ",", "patch_size", "=", "[", "12", ",", "16", "]", ",", "embed_dim", "=", "[", "192", ",", "384", "]", ",", "depth", "=", "[", "[", "1", ",", "5", ",", "0", "]", ",", "[", "1", ",", "5", ",", "0", "]", ",", "[", "1", ",", "5", ",", "0", "]", "]", ",", "\n", "num_heads", "=", "[", "6", ",", "6", "]", ",", "mlp_ratio", "=", "[", "3", ",", "3", ",", "1", "]", ",", "multi_conv", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_crossvit", "(", "variant", "=", "'crossvit_15_dagger_240'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.crossvit_15_dagger_408": [[515, 522], ["dict", "crossvit._create_crossvit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit._create_crossvit"], ["", "@", "register_model", "\n", "def", "crossvit_15_dagger_408", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "img_scale", "=", "(", "1.0", ",", "384", "/", "408", ")", ",", "patch_size", "=", "[", "12", ",", "16", "]", ",", "embed_dim", "=", "[", "192", ",", "384", "]", ",", "depth", "=", "[", "[", "1", ",", "5", ",", "0", "]", ",", "[", "1", ",", "5", ",", "0", "]", ",", "[", "1", ",", "5", ",", "0", "]", "]", ",", "\n", "num_heads", "=", "[", "6", ",", "6", "]", ",", "mlp_ratio", "=", "[", "3", ",", "3", ",", "1", "]", ",", "multi_conv", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_crossvit", "(", "variant", "=", "'crossvit_15_dagger_408'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.crossvit_18_dagger_240": [[524, 531], ["dict", "crossvit._create_crossvit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit._create_crossvit"], ["", "@", "register_model", "\n", "def", "crossvit_18_dagger_240", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "img_scale", "=", "(", "1.0", ",", "224", "/", "240", ")", ",", "patch_size", "=", "[", "12", ",", "16", "]", ",", "embed_dim", "=", "[", "224", ",", "448", "]", ",", "depth", "=", "[", "[", "1", ",", "6", ",", "0", "]", ",", "[", "1", ",", "6", ",", "0", "]", ",", "[", "1", ",", "6", ",", "0", "]", "]", ",", "\n", "num_heads", "=", "[", "7", ",", "7", "]", ",", "mlp_ratio", "=", "[", "3", ",", "3", ",", "1", "]", ",", "multi_conv", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_crossvit", "(", "variant", "=", "'crossvit_18_dagger_240'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit.crossvit_18_dagger_408": [[533, 540], ["dict", "crossvit._create_crossvit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.crossvit._create_crossvit"], ["", "@", "register_model", "\n", "def", "crossvit_18_dagger_408", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "\n", "img_scale", "=", "(", "1.0", ",", "384", "/", "408", ")", ",", "patch_size", "=", "[", "12", ",", "16", "]", ",", "embed_dim", "=", "[", "224", ",", "448", "]", ",", "depth", "=", "[", "[", "1", ",", "6", ",", "0", "]", ",", "[", "1", ",", "6", ",", "0", "]", ",", "[", "1", ",", "6", ",", "0", "]", "]", ",", "\n", "num_heads", "=", "[", "7", ",", "7", "]", ",", "mlp_ratio", "=", "[", "3", ",", "3", ",", "1", "]", ",", "multi_conv", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_crossvit", "(", "variant", "=", "'crossvit_18_dagger_408'", ",", "pretrained", "=", "pretrained", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.LinearBottleneck.__init__": [[57, 81], ["torch.Module.__init__", "layers.ConvNormAct", "layers.create_act_layer", "layers.ConvNormAct", "layers.make_divisible", "layers.ConvNormAct", "SEWithNorm", "round", "layers.make_divisible", "int"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "stride", ",", "exp_ratio", "=", "1.0", ",", "se_ratio", "=", "0.", ",", "ch_div", "=", "1", ",", "\n", "act_layer", "=", "'swish'", ",", "dw_act_layer", "=", "'relu6'", ",", "drop_path", "=", "None", ")", ":", "\n", "        ", "super", "(", "LinearBottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_shortcut", "=", "stride", "==", "1", "and", "in_chs", "<=", "out_chs", "\n", "self", ".", "in_channels", "=", "in_chs", "\n", "self", ".", "out_channels", "=", "out_chs", "\n", "\n", "if", "exp_ratio", "!=", "1.", ":", "\n", "            ", "dw_chs", "=", "make_divisible", "(", "round", "(", "in_chs", "*", "exp_ratio", ")", ",", "divisor", "=", "ch_div", ")", "\n", "self", ".", "conv_exp", "=", "ConvNormAct", "(", "in_chs", ",", "dw_chs", ",", "act_layer", "=", "act_layer", ")", "\n", "", "else", ":", "\n", "            ", "dw_chs", "=", "in_chs", "\n", "self", ".", "conv_exp", "=", "None", "\n", "\n", "", "self", ".", "conv_dw", "=", "ConvNormAct", "(", "dw_chs", ",", "dw_chs", ",", "3", ",", "stride", "=", "stride", ",", "groups", "=", "dw_chs", ",", "apply_act", "=", "False", ")", "\n", "if", "se_ratio", ">", "0", ":", "\n", "            ", "self", ".", "se", "=", "SEWithNorm", "(", "dw_chs", ",", "rd_channels", "=", "make_divisible", "(", "int", "(", "dw_chs", "*", "se_ratio", ")", ",", "ch_div", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "se", "=", "None", "\n", "", "self", ".", "act_dw", "=", "create_act_layer", "(", "dw_act_layer", ")", "\n", "\n", "self", ".", "conv_pwl", "=", "ConvNormAct", "(", "dw_chs", ",", "out_chs", ",", "1", ",", "apply_act", "=", "False", ")", "\n", "self", ".", "drop_path", "=", "drop_path", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.LinearBottleneck.feat_channels": [[82, 84], ["None"], "methods", ["None"], ["", "def", "feat_channels", "(", "self", ",", "exp", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "conv_dw", ".", "out_channels", "if", "exp", "else", "self", ".", "out_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.LinearBottleneck.forward": [[85, 99], ["rexnet.LinearBottleneck.conv_dw", "rexnet.LinearBottleneck.act_dw", "rexnet.LinearBottleneck.conv_pwl", "rexnet.LinearBottleneck.conv_exp", "rexnet.LinearBottleneck.se", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "rexnet.LinearBottleneck.drop_path"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "if", "self", ".", "conv_exp", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "conv_exp", "(", "x", ")", "\n", "", "x", "=", "self", ".", "conv_dw", "(", "x", ")", "\n", "if", "self", ".", "se", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "se", "(", "x", ")", "\n", "", "x", "=", "self", ".", "act_dw", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_pwl", "(", "x", ")", "\n", "if", "self", ".", "use_shortcut", ":", "\n", "            ", "if", "self", ".", "drop_path", "is", "not", "None", ":", "\n", "                ", "x", "=", "self", ".", "drop_path", "(", "x", ")", "\n", "", "x", "=", "torch", ".", "cat", "(", "[", "x", "[", ":", ",", "0", ":", "self", ".", "in_channels", "]", "+", "shortcut", ",", "x", "[", ":", ",", "self", ".", "in_channels", ":", "]", "]", ",", "dim", "=", "1", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.ReXNetV1.__init__": [[147, 171], ["torch.Module.__init__", "layers.make_divisible", "layers.ConvNormAct", "rexnet._block_cfg", "rexnet._build_blocks", "torch.Sequential", "torch.Sequential", "layers.ClassifierHead", "efficientnet_builder.efficientnet_init_weights", "round"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet._block_cfg", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet._build_blocks", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.efficientnet_init_weights"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "global_pool", "=", "'avg'", ",", "output_stride", "=", "32", ",", "\n", "initial_chs", "=", "16", ",", "final_chs", "=", "180", ",", "width_mult", "=", "1.0", ",", "depth_mult", "=", "1.0", ",", "se_ratio", "=", "1", "/", "12.", ",", "\n", "ch_div", "=", "1", ",", "act_layer", "=", "'swish'", ",", "dw_act_layer", "=", "'relu6'", ",", "drop_rate", "=", "0.2", ",", "drop_path_rate", "=", "0.", "\n", ")", ":", "\n", "        ", "super", "(", "ReXNetV1", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "assert", "output_stride", "==", "32", "# FIXME support dilation", "\n", "stem_base_chs", "=", "32", "/", "width_mult", "if", "width_mult", "<", "1.0", "else", "32", "\n", "stem_chs", "=", "make_divisible", "(", "round", "(", "stem_base_chs", "*", "width_mult", ")", ",", "divisor", "=", "ch_div", ")", "\n", "self", ".", "stem", "=", "ConvNormAct", "(", "in_chans", ",", "stem_chs", ",", "3", ",", "stride", "=", "2", ",", "act_layer", "=", "act_layer", ")", "\n", "\n", "block_cfg", "=", "_block_cfg", "(", "width_mult", ",", "depth_mult", ",", "initial_chs", ",", "final_chs", ",", "se_ratio", ",", "ch_div", ")", "\n", "features", ",", "self", ".", "feature_info", "=", "_build_blocks", "(", "\n", "block_cfg", ",", "stem_chs", ",", "width_mult", ",", "ch_div", ",", "act_layer", ",", "dw_act_layer", ",", "drop_path_rate", ")", "\n", "self", ".", "num_features", "=", "features", "[", "-", "1", "]", ".", "out_channels", "\n", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "*", "features", ")", "\n", "\n", "self", ".", "head", "=", "ClassifierHead", "(", "self", ".", "num_features", ",", "num_classes", ",", "global_pool", ",", "drop_rate", ")", "\n", "\n", "efficientnet_init_weights", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.ReXNetV1.group_matcher": [[172, 179], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem", "=", "r'^stem'", ",", "\n", "blocks", "=", "r'^features\\.(\\d+)'", ",", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.ReXNetV1.set_grad_checkpointing": [[180, 183], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.ReXNetV1.get_classifier": [[184, 187], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.ReXNetV1.reset_classifier": [[188, 190], ["layers.ClassifierHead"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "head", "=", "ClassifierHead", "(", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "self", ".", "drop_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.ReXNetV1.forward_features": [[191, 198], ["rexnet.ReXNetV1.stem", "helpers.checkpoint_seq", "rexnet.ReXNetV1.features", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "features", ",", "x", ",", "flatten", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.ReXNetV1.forward_head": [[199, 201], ["rexnet.ReXNetV1.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "head", "(", "x", ",", "pre_logits", "=", "pre_logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.ReXNetV1.forward": [[202, 206], ["rexnet.ReXNetV1.forward_features", "rexnet.ReXNetV1.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet._cfg": [[25, 31], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'stem.conv'", ",", "'classifier'", ":", "'head.fc'", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet._block_cfg": [[101, 119], ["sum", "range", "list", "math.ceil", "sum", "out_chs_list.append", "zip", "sum", "layers.make_divisible", "sum", "enumerate", "round"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["", "", "def", "_block_cfg", "(", "width_mult", "=", "1.0", ",", "depth_mult", "=", "1.0", ",", "initial_chs", "=", "16", ",", "final_chs", "=", "180", ",", "se_ratio", "=", "0.", ",", "ch_div", "=", "1", ")", ":", "\n", "    ", "layers", "=", "[", "1", ",", "2", ",", "2", ",", "3", ",", "3", ",", "5", "]", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "2", ",", "1", ",", "2", "]", "\n", "layers", "=", "[", "ceil", "(", "element", "*", "depth_mult", ")", "for", "element", "in", "layers", "]", "\n", "strides", "=", "sum", "(", "[", "[", "element", "]", "+", "[", "1", "]", "*", "(", "layers", "[", "idx", "]", "-", "1", ")", "for", "idx", ",", "element", "in", "enumerate", "(", "strides", ")", "]", ",", "[", "]", ")", "\n", "exp_ratios", "=", "[", "1", "]", "*", "layers", "[", "0", "]", "+", "[", "6", "]", "*", "sum", "(", "layers", "[", "1", ":", "]", ")", "\n", "depth", "=", "sum", "(", "layers", "[", ":", "]", ")", "*", "3", "\n", "base_chs", "=", "initial_chs", "/", "width_mult", "if", "width_mult", "<", "1.0", "else", "initial_chs", "\n", "\n", "# The following channel configuration is a simple instance to make each layer become an expand layer.", "\n", "out_chs_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "depth", "//", "3", ")", ":", "\n", "        ", "out_chs_list", ".", "append", "(", "make_divisible", "(", "round", "(", "base_chs", "*", "width_mult", ")", ",", "divisor", "=", "ch_div", ")", ")", "\n", "base_chs", "+=", "final_chs", "/", "(", "depth", "//", "3", "*", "1.0", ")", "\n", "\n", "", "se_ratios", "=", "[", "0.", "]", "*", "(", "layers", "[", "0", "]", "+", "layers", "[", "1", "]", ")", "+", "[", "se_ratio", "]", "*", "sum", "(", "layers", "[", "2", ":", "]", ")", "\n", "\n", "return", "list", "(", "zip", "(", "out_chs_list", ",", "exp_ratios", ",", "strides", ",", "se_ratios", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet._build_blocks": [[121, 144], ["len", "enumerate", "layers.make_divisible", "features.append", "features.append", "dict", "layers.ConvNormAct", "layers.DropPath", "rexnet.LinearBottleneck", "features[].feat_channels", "dict", "len"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.LinearBottleneck.feat_channels"], ["", "def", "_build_blocks", "(", "\n", "block_cfg", ",", "prev_chs", ",", "width_mult", ",", "ch_div", "=", "1", ",", "act_layer", "=", "'swish'", ",", "dw_act_layer", "=", "'relu6'", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "    ", "feat_chs", "=", "[", "prev_chs", "]", "\n", "feature_info", "=", "[", "]", "\n", "curr_stride", "=", "2", "\n", "features", "=", "[", "]", "\n", "num_blocks", "=", "len", "(", "block_cfg", ")", "\n", "for", "block_idx", ",", "(", "chs", ",", "exp_ratio", ",", "stride", ",", "se_ratio", ")", "in", "enumerate", "(", "block_cfg", ")", ":", "\n", "        ", "if", "stride", ">", "1", ":", "\n", "            ", "fname", "=", "'stem'", "if", "block_idx", "==", "0", "else", "f'features.{block_idx - 1}'", "\n", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "feat_chs", "[", "-", "1", "]", ",", "reduction", "=", "curr_stride", ",", "module", "=", "fname", ")", "]", "\n", "curr_stride", "*=", "stride", "\n", "", "block_dpr", "=", "drop_path_rate", "*", "block_idx", "/", "(", "num_blocks", "-", "1", ")", "# stochastic depth linear decay rule", "\n", "drop_path", "=", "DropPath", "(", "block_dpr", ")", "if", "block_dpr", ">", "0.", "else", "None", "\n", "features", ".", "append", "(", "LinearBottleneck", "(", "\n", "in_chs", "=", "prev_chs", ",", "out_chs", "=", "chs", ",", "exp_ratio", "=", "exp_ratio", ",", "stride", "=", "stride", ",", "se_ratio", "=", "se_ratio", ",", "\n", "ch_div", "=", "ch_div", ",", "act_layer", "=", "act_layer", ",", "dw_act_layer", "=", "dw_act_layer", ",", "drop_path", "=", "drop_path", ")", ")", "\n", "prev_chs", "=", "chs", "\n", "feat_chs", "+=", "[", "features", "[", "-", "1", "]", ".", "feat_channels", "(", ")", "]", "\n", "", "pen_chs", "=", "make_divisible", "(", "1280", "*", "width_mult", ",", "divisor", "=", "ch_div", ")", "\n", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "feat_chs", "[", "-", "1", "]", ",", "reduction", "=", "curr_stride", ",", "module", "=", "f'features.{len(features) - 1}'", ")", "]", "\n", "features", ".", "append", "(", "ConvNormAct", "(", "prev_chs", ",", "pen_chs", ",", "act_layer", "=", "act_layer", ")", ")", "\n", "return", "features", ",", "feature_info", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet._create_rexnet": [[208, 214], ["dict", "helpers.build_model_with_cfg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_rexnet", "(", "variant", ",", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "feature_cfg", "=", "dict", "(", "flatten_sequential", "=", "True", ")", "\n", "return", "build_model_with_cfg", "(", "\n", "ReXNetV1", ",", "variant", ",", "pretrained", ",", "\n", "feature_cfg", "=", "feature_cfg", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.rexnet_100": [[216, 220], ["rexnet._create_rexnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet._create_rexnet"], ["", "@", "register_model", "\n", "def", "rexnet_100", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"ReXNet V1 1.0x\"\"\"", "\n", "return", "_create_rexnet", "(", "'rexnet_100'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.rexnet_130": [[222, 226], ["rexnet._create_rexnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet._create_rexnet"], ["", "@", "register_model", "\n", "def", "rexnet_130", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"ReXNet V1 1.3x\"\"\"", "\n", "return", "_create_rexnet", "(", "'rexnet_130'", ",", "pretrained", ",", "width_mult", "=", "1.3", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.rexnet_150": [[228, 232], ["rexnet._create_rexnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet._create_rexnet"], ["", "@", "register_model", "\n", "def", "rexnet_150", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"ReXNet V1 1.5x\"\"\"", "\n", "return", "_create_rexnet", "(", "'rexnet_150'", ",", "pretrained", ",", "width_mult", "=", "1.5", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.rexnet_200": [[234, 238], ["rexnet._create_rexnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet._create_rexnet"], ["", "@", "register_model", "\n", "def", "rexnet_200", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"ReXNet V1 2.0x\"\"\"", "\n", "return", "_create_rexnet", "(", "'rexnet_200'", ",", "pretrained", ",", "width_mult", "=", "2.0", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.rexnetr_100": [[240, 244], ["rexnet._create_rexnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet._create_rexnet"], ["", "@", "register_model", "\n", "def", "rexnetr_100", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"ReXNet V1 1.0x w/ rounded (mod 8) channels\"\"\"", "\n", "return", "_create_rexnet", "(", "'rexnetr_100'", ",", "pretrained", ",", "ch_div", "=", "8", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.rexnetr_130": [[246, 250], ["rexnet._create_rexnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet._create_rexnet"], ["", "@", "register_model", "\n", "def", "rexnetr_130", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"ReXNet V1 1.3x w/ rounded (mod 8) channels\"\"\"", "\n", "return", "_create_rexnet", "(", "'rexnetr_130'", ",", "pretrained", ",", "width_mult", "=", "1.3", ",", "ch_div", "=", "8", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.rexnetr_150": [[252, 256], ["rexnet._create_rexnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet._create_rexnet"], ["", "@", "register_model", "\n", "def", "rexnetr_150", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"ReXNet V1 1.5x w/ rounded (mod 8) channels\"\"\"", "\n", "return", "_create_rexnet", "(", "'rexnetr_150'", ",", "pretrained", ",", "width_mult", "=", "1.5", ",", "ch_div", "=", "8", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet.rexnetr_200": [[258, 262], ["rexnet._create_rexnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.rexnet._create_rexnet"], ["", "@", "register_model", "\n", "def", "rexnetr_200", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"ReXNet V1 2.0x w/ rounded (mod 8) channels\"\"\"", "\n", "return", "_create_rexnet", "(", "'rexnetr_200'", ",", "pretrained", ",", "width_mult", "=", "2.0", ",", "ch_div", "=", "8", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.PreActBottleneck.__init__": [[154, 178], ["torch.Module.__init__", "resnetv2.make_div", "norm_layer", "conv_layer", "norm_layer", "conv_layer", "norm_layer", "conv_layer", "functools.partial", "proj_layer", "layers.DropPath", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.make_div"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", "=", "None", ",", "bottle_ratio", "=", "0.25", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "first_dilation", "=", "None", ",", "groups", "=", "1", ",", "\n", "act_layer", "=", "None", ",", "conv_layer", "=", "None", ",", "norm_layer", "=", "None", ",", "proj_layer", "=", "None", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "first_dilation", "=", "first_dilation", "or", "dilation", "\n", "conv_layer", "=", "conv_layer", "or", "StdConv2d", "\n", "norm_layer", "=", "norm_layer", "or", "partial", "(", "GroupNormAct", ",", "num_groups", "=", "32", ")", "\n", "out_chs", "=", "out_chs", "or", "in_chs", "\n", "mid_chs", "=", "make_div", "(", "out_chs", "*", "bottle_ratio", ")", "\n", "\n", "if", "proj_layer", "is", "not", "None", ":", "\n", "            ", "self", ".", "downsample", "=", "proj_layer", "(", "\n", "in_chs", ",", "out_chs", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "first_dilation", "=", "first_dilation", ",", "preact", "=", "True", ",", "\n", "conv_layer", "=", "conv_layer", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "downsample", "=", "None", "\n", "\n", "", "self", ".", "norm1", "=", "norm_layer", "(", "in_chs", ")", "\n", "self", ".", "conv1", "=", "conv_layer", "(", "in_chs", ",", "mid_chs", ",", "1", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "mid_chs", ")", "\n", "self", ".", "conv2", "=", "conv_layer", "(", "mid_chs", ",", "mid_chs", ",", "3", ",", "stride", "=", "stride", ",", "dilation", "=", "first_dilation", ",", "groups", "=", "groups", ")", "\n", "self", ".", "norm3", "=", "norm_layer", "(", "mid_chs", ")", "\n", "self", ".", "conv3", "=", "conv_layer", "(", "mid_chs", ",", "out_chs", ",", "1", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path_rate", ")", "if", "drop_path_rate", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.PreActBottleneck.zero_init_last": [[179, 181], ["torch.init.zeros_", "torch.init.zeros_"], "methods", ["None"], ["", "def", "zero_init_last", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "conv3", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.PreActBottleneck.forward": [[182, 196], ["resnetv2.PreActBottleneck.norm1", "resnetv2.PreActBottleneck.conv1", "resnetv2.PreActBottleneck.conv2", "resnetv2.PreActBottleneck.conv3", "resnetv2.PreActBottleneck.drop_path", "resnetv2.PreActBottleneck.downsample", "resnetv2.PreActBottleneck.norm2", "resnetv2.PreActBottleneck.norm3"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_preact", "=", "self", ".", "norm1", "(", "x", ")", "\n", "\n", "# shortcut branch", "\n", "shortcut", "=", "x", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "downsample", "(", "x_preact", ")", "\n", "\n", "# residual branch", "\n", "", "x", "=", "self", ".", "conv1", "(", "x_preact", ")", "\n", "x", "=", "self", ".", "conv2", "(", "self", ".", "norm2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "conv3", "(", "self", ".", "norm3", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "drop_path", "(", "x", ")", "\n", "return", "x", "+", "shortcut", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.Bottleneck.__init__": [[201, 227], ["torch.Module.__init__", "resnetv2.make_div", "conv_layer", "norm_layer", "conv_layer", "norm_layer", "conv_layer", "norm_layer", "act_layer", "functools.partial", "proj_layer", "layers.DropPath", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.make_div"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", "=", "None", ",", "bottle_ratio", "=", "0.25", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "first_dilation", "=", "None", ",", "groups", "=", "1", ",", "\n", "act_layer", "=", "None", ",", "conv_layer", "=", "None", ",", "norm_layer", "=", "None", ",", "proj_layer", "=", "None", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "first_dilation", "=", "first_dilation", "or", "dilation", "\n", "act_layer", "=", "act_layer", "or", "nn", ".", "ReLU", "\n", "conv_layer", "=", "conv_layer", "or", "StdConv2d", "\n", "norm_layer", "=", "norm_layer", "or", "partial", "(", "GroupNormAct", ",", "num_groups", "=", "32", ")", "\n", "out_chs", "=", "out_chs", "or", "in_chs", "\n", "mid_chs", "=", "make_div", "(", "out_chs", "*", "bottle_ratio", ")", "\n", "\n", "if", "proj_layer", "is", "not", "None", ":", "\n", "            ", "self", ".", "downsample", "=", "proj_layer", "(", "\n", "in_chs", ",", "out_chs", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "preact", "=", "False", ",", "\n", "conv_layer", "=", "conv_layer", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "downsample", "=", "None", "\n", "\n", "", "self", ".", "conv1", "=", "conv_layer", "(", "in_chs", ",", "mid_chs", ",", "1", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "mid_chs", ")", "\n", "self", ".", "conv2", "=", "conv_layer", "(", "mid_chs", ",", "mid_chs", ",", "3", ",", "stride", "=", "stride", ",", "dilation", "=", "first_dilation", ",", "groups", "=", "groups", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "mid_chs", ")", "\n", "self", ".", "conv3", "=", "conv_layer", "(", "mid_chs", ",", "out_chs", ",", "1", ")", "\n", "self", ".", "norm3", "=", "norm_layer", "(", "out_chs", ",", "apply_act", "=", "False", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path_rate", ")", "if", "drop_path_rate", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "act3", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.Bottleneck.zero_init_last": [[228, 230], ["torch.init.zeros_", "torch.init.zeros_"], "methods", ["None"], ["", "def", "zero_init_last", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "norm3", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.Bottleneck.forward": [[231, 247], ["resnetv2.Bottleneck.conv1", "resnetv2.Bottleneck.norm1", "resnetv2.Bottleneck.conv2", "resnetv2.Bottleneck.norm2", "resnetv2.Bottleneck.conv3", "resnetv2.Bottleneck.norm3", "resnetv2.Bottleneck.drop_path", "resnetv2.Bottleneck.act3", "resnetv2.Bottleneck.downsample"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# shortcut branch", "\n", "        ", "shortcut", "=", "x", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "# residual", "\n", "", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "norm1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "norm2", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3", "(", "x", ")", "\n", "x", "=", "self", ".", "norm3", "(", "x", ")", "\n", "x", "=", "self", ".", "drop_path", "(", "x", ")", "\n", "x", "=", "self", ".", "act3", "(", "x", "+", "shortcut", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.DownsampleConv.__init__": [[250, 256], ["torch.Module.__init__", "conv_layer", "torch.Identity", "torch.Identity", "norm_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "first_dilation", "=", "None", ",", "preact", "=", "True", ",", "\n", "conv_layer", "=", "None", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "DownsampleConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "conv_layer", "(", "in_chs", ",", "out_chs", ",", "1", ",", "stride", "=", "stride", ")", "\n", "self", ".", "norm", "=", "nn", ".", "Identity", "(", ")", "if", "preact", "else", "norm_layer", "(", "out_chs", ",", "apply_act", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.DownsampleConv.forward": [[257, 259], ["resnetv2.DownsampleConv.norm", "resnetv2.DownsampleConv.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "norm", "(", "self", ".", "conv", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.DownsampleAvg.__init__": [[262, 275], ["torch.Module.__init__", "conv_layer", "avg_pool_fn", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "norm_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "first_dilation", "=", "None", ",", "\n", "preact", "=", "True", ",", "conv_layer", "=", "None", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "\"\"\" AvgPool Downsampling as in 'D' ResNet variants. This is not in RegNet space but I might experiment.\"\"\"", "\n", "super", "(", "DownsampleAvg", ",", "self", ")", ".", "__init__", "(", ")", "\n", "avg_stride", "=", "stride", "if", "dilation", "==", "1", "else", "1", "\n", "if", "stride", ">", "1", "or", "dilation", ">", "1", ":", "\n", "            ", "avg_pool_fn", "=", "AvgPool2dSame", "if", "avg_stride", "==", "1", "and", "dilation", ">", "1", "else", "nn", ".", "AvgPool2d", "\n", "self", ".", "pool", "=", "avg_pool_fn", "(", "2", ",", "avg_stride", ",", "ceil_mode", "=", "True", ",", "count_include_pad", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "pool", "=", "nn", ".", "Identity", "(", ")", "\n", "", "self", ".", "conv", "=", "conv_layer", "(", "in_chs", ",", "out_chs", ",", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "norm", "=", "nn", ".", "Identity", "(", ")", "if", "preact", "else", "norm_layer", "(", "out_chs", ",", "apply_act", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.DownsampleAvg.forward": [[276, 278], ["resnetv2.DownsampleAvg.norm", "resnetv2.DownsampleAvg.conv", "resnetv2.DownsampleAvg.pool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "norm", "(", "self", ".", "conv", "(", "self", ".", "pool", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.ResNetStage.__init__": [[282, 302], ["torch.Module.__init__", "dict", "torch.Sequential", "torch.Sequential", "range", "resnetv2.ResNetStage.blocks.add_module", "str", "block_fn"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "stride", ",", "dilation", ",", "depth", ",", "bottle_ratio", "=", "0.25", ",", "groups", "=", "1", ",", "\n", "avg_down", "=", "False", ",", "block_dpr", "=", "None", ",", "block_fn", "=", "PreActBottleneck", ",", "\n", "act_layer", "=", "None", ",", "conv_layer", "=", "None", ",", "norm_layer", "=", "None", ",", "**", "block_kwargs", ")", ":", "\n", "        ", "super", "(", "ResNetStage", ",", "self", ")", ".", "__init__", "(", ")", "\n", "first_dilation", "=", "1", "if", "dilation", "in", "(", "1", ",", "2", ")", "else", "2", "\n", "layer_kwargs", "=", "dict", "(", "act_layer", "=", "act_layer", ",", "conv_layer", "=", "conv_layer", ",", "norm_layer", "=", "norm_layer", ")", "\n", "proj_layer", "=", "DownsampleAvg", "if", "avg_down", "else", "DownsampleConv", "\n", "prev_chs", "=", "in_chs", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", ")", "\n", "for", "block_idx", "in", "range", "(", "depth", ")", ":", "\n", "            ", "drop_path_rate", "=", "block_dpr", "[", "block_idx", "]", "if", "block_dpr", "else", "0.", "\n", "stride", "=", "stride", "if", "block_idx", "==", "0", "else", "1", "\n", "self", ".", "blocks", ".", "add_module", "(", "str", "(", "block_idx", ")", ",", "block_fn", "(", "\n", "prev_chs", ",", "out_chs", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "bottle_ratio", "=", "bottle_ratio", ",", "groups", "=", "groups", ",", "\n", "first_dilation", "=", "first_dilation", ",", "proj_layer", "=", "proj_layer", ",", "drop_path_rate", "=", "drop_path_rate", ",", "\n", "**", "layer_kwargs", ",", "**", "block_kwargs", ")", ")", "\n", "prev_chs", "=", "out_chs", "\n", "first_dilation", "=", "dilation", "\n", "proj_layer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.ResNetStage.forward": [[303, 306], ["resnetv2.ResNetStage.blocks"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "blocks", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.ResNetV2.__init__": [[356, 401], ["functools.partial", "torch.Module.__init__", "resnetv2.make_div", "resnetv2.create_resnetv2_stem", "resnetv2.ResNetV2.feature_info.append", "torch.Sequential", "torch.Sequential", "enumerate", "layers.ClassifierHead", "resnetv2.ResNetV2.init_weights", "dict", "x.tolist", "zip", "resnetv2.make_div", "resnetv2.ResNetStage", "resnetv2.ResNetV2.stages.add_module", "norm_layer", "torch.Identity", "torch.Identity", "resnetv2.is_stem_deep", "torch.linspace().split", "torch.linspace().split", "torch.linspace().split", "torch.linspace().split", "dict", "str", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "sum"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.make_div", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.create_resnetv2_stem", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.GluMlp.init_weights", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.make_div", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.is_stem_deep"], ["def", "__init__", "(", "\n", "self", ",", "layers", ",", "channels", "=", "(", "256", ",", "512", ",", "1024", ",", "2048", ")", ",", "\n", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "global_pool", "=", "'avg'", ",", "output_stride", "=", "32", ",", "\n", "width_factor", "=", "1", ",", "stem_chs", "=", "64", ",", "stem_type", "=", "''", ",", "avg_down", "=", "False", ",", "preact", "=", "True", ",", "\n", "act_layer", "=", "nn", ".", "ReLU", ",", "conv_layer", "=", "StdConv2d", ",", "norm_layer", "=", "partial", "(", "GroupNormAct", ",", "num_groups", "=", "32", ")", ",", "\n", "drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "zero_init_last", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "wf", "=", "width_factor", "\n", "\n", "self", ".", "feature_info", "=", "[", "]", "\n", "stem_chs", "=", "make_div", "(", "stem_chs", "*", "wf", ")", "\n", "self", ".", "stem", "=", "create_resnetv2_stem", "(", "\n", "in_chans", ",", "stem_chs", ",", "stem_type", ",", "preact", ",", "conv_layer", "=", "conv_layer", ",", "norm_layer", "=", "norm_layer", ")", "\n", "stem_feat", "=", "(", "'stem.conv3'", "if", "is_stem_deep", "(", "stem_type", ")", "else", "'stem.conv'", ")", "if", "preact", "else", "'stem.norm'", "\n", "self", ".", "feature_info", ".", "append", "(", "dict", "(", "num_chs", "=", "stem_chs", ",", "reduction", "=", "2", ",", "module", "=", "stem_feat", ")", ")", "\n", "\n", "prev_chs", "=", "stem_chs", "\n", "curr_stride", "=", "4", "\n", "dilation", "=", "1", "\n", "block_dprs", "=", "[", "x", ".", "tolist", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "sum", "(", "layers", ")", ")", ".", "split", "(", "layers", ")", "]", "\n", "block_fn", "=", "PreActBottleneck", "if", "preact", "else", "Bottleneck", "\n", "self", ".", "stages", "=", "nn", ".", "Sequential", "(", ")", "\n", "for", "stage_idx", ",", "(", "d", ",", "c", ",", "bdpr", ")", "in", "enumerate", "(", "zip", "(", "layers", ",", "channels", ",", "block_dprs", ")", ")", ":", "\n", "            ", "out_chs", "=", "make_div", "(", "c", "*", "wf", ")", "\n", "stride", "=", "1", "if", "stage_idx", "==", "0", "else", "2", "\n", "if", "curr_stride", ">=", "output_stride", ":", "\n", "                ", "dilation", "*=", "stride", "\n", "stride", "=", "1", "\n", "", "stage", "=", "ResNetStage", "(", "\n", "prev_chs", ",", "out_chs", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "depth", "=", "d", ",", "avg_down", "=", "avg_down", ",", "\n", "act_layer", "=", "act_layer", ",", "conv_layer", "=", "conv_layer", ",", "norm_layer", "=", "norm_layer", ",", "block_dpr", "=", "bdpr", ",", "block_fn", "=", "block_fn", ")", "\n", "prev_chs", "=", "out_chs", "\n", "curr_stride", "*=", "stride", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "prev_chs", ",", "reduction", "=", "curr_stride", ",", "module", "=", "f'stages.{stage_idx}'", ")", "]", "\n", "self", ".", "stages", ".", "add_module", "(", "str", "(", "stage_idx", ")", ",", "stage", ")", "\n", "\n", "", "self", ".", "num_features", "=", "prev_chs", "\n", "self", ".", "norm", "=", "norm_layer", "(", "self", ".", "num_features", ")", "if", "preact", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "head", "=", "ClassifierHead", "(", "\n", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "self", ".", "drop_rate", ",", "use_conv", "=", "True", ")", "\n", "\n", "self", ".", "init_weights", "(", "zero_init_last", "=", "zero_init_last", ")", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.ResNetV2.init_weights": [[402, 405], ["helpers.named_apply", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_apply"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "init_weights", "(", "self", ",", "zero_init_last", "=", "True", ")", ":", "\n", "        ", "named_apply", "(", "partial", "(", "_init_weights", ",", "zero_init_last", "=", "zero_init_last", ")", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.ResNetV2.load_pretrained": [[406, 409], ["torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "resnetv2._load_weights"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._load_weights"], ["", "@", "torch", ".", "jit", ".", "ignore", "(", ")", "\n", "def", "load_pretrained", "(", "self", ",", "checkpoint_path", ",", "prefix", "=", "'resnet/'", ")", ":", "\n", "        ", "_load_weights", "(", "self", ",", "checkpoint_path", ",", "prefix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.ResNetV2.group_matcher": [[410, 420], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem", "=", "r'^stem'", ",", "\n", "blocks", "=", "r'^stages\\.(\\d+)'", "if", "coarse", "else", "[", "\n", "(", "r'^stages\\.(\\d+)\\.blocks\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^norm'", ",", "(", "99999", ",", ")", ")", "\n", "]", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.ResNetV2.set_grad_checkpointing": [[421, 424], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.ResNetV2.get_classifier": [[425, 428], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.ResNetV2.reset_classifier": [[429, 433], ["layers.ClassifierHead"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "head", "=", "ClassifierHead", "(", "\n", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "self", ".", "drop_rate", ",", "use_conv", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.ResNetV2.forward_features": [[434, 442], ["resnetv2.ResNetV2.stem", "resnetv2.ResNetV2.norm", "helpers.checkpoint_seq", "resnetv2.ResNetV2.stages", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.stages"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "stages", ",", "x", ",", "flatten", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "stages", "(", "x", ")", "\n", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.ResNetV2.forward_head": [[443, 445], ["resnetv2.ResNetV2.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "head", "(", "x", ",", "pre_logits", "=", "pre_logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.ResNetV2.forward": [[446, 450], ["resnetv2.ResNetV2.forward_features", "resnetv2.ResNetV2.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._cfg": [[45, 53], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bilinear'", ",", "\n", "'mean'", ":", "IMAGENET_INCEPTION_MEAN", ",", "'std'", ":", "IMAGENET_INCEPTION_STD", ",", "\n", "'first_conv'", ":", "'stem.conv'", ",", "'classifier'", ":", "'head.fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.make_div": [[137, 143], ["max", "int"], "function", ["None"], ["def", "make_div", "(", "v", ",", "divisor", "=", "8", ")", ":", "\n", "    ", "min_value", "=", "divisor", "\n", "new_v", "=", "max", "(", "min_value", ",", "int", "(", "v", "+", "divisor", "/", "2", ")", "//", "divisor", "*", "divisor", ")", "\n", "if", "new_v", "<", "0.9", "*", "v", ":", "\n", "        ", "new_v", "+=", "divisor", "\n", "", "return", "new_v", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.is_stem_deep": [[308, 310], ["any"], "function", ["None"], ["", "", "def", "is_stem_deep", "(", "stem_type", ")", ":", "\n", "    ", "return", "any", "(", "[", "s", "in", "stem_type", "for", "s", "in", "(", "'deep'", ",", "'tiered'", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.create_resnetv2_stem": [[312, 350], ["functools.partial", "collections.OrderedDict", "resnetv2.is_stem_deep", "torch.Sequential", "conv_layer", "norm_layer", "conv_layer", "norm_layer", "conv_layer", "conv_layer", "torch.ConstantPad2d", "torch.MaxPool2d", "norm_layer", "norm_layer", "layers.create_pool2d", "torch.MaxPool2d"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.is_stem_deep", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d"], ["", "def", "create_resnetv2_stem", "(", "\n", "in_chs", ",", "out_chs", "=", "64", ",", "stem_type", "=", "''", ",", "preact", "=", "True", ",", "\n", "conv_layer", "=", "StdConv2d", ",", "norm_layer", "=", "partial", "(", "GroupNormAct", ",", "num_groups", "=", "32", ")", ")", ":", "\n", "    ", "stem", "=", "OrderedDict", "(", ")", "\n", "assert", "stem_type", "in", "(", "''", ",", "'fixed'", ",", "'same'", ",", "'deep'", ",", "'deep_fixed'", ",", "'deep_same'", ",", "'tiered'", ")", "\n", "\n", "# NOTE conv padding mode can be changed by overriding the conv_layer def", "\n", "if", "is_stem_deep", "(", "stem_type", ")", ":", "\n", "# A 3 deep 3x3  conv stack as in ResNet V1D models", "\n", "        ", "if", "'tiered'", "in", "stem_type", ":", "\n", "            ", "stem_chs", "=", "(", "3", "*", "out_chs", "//", "8", ",", "out_chs", "//", "2", ")", "# 'T' resnets in resnet.py", "\n", "", "else", ":", "\n", "            ", "stem_chs", "=", "(", "out_chs", "//", "2", ",", "out_chs", "//", "2", ")", "# 'D' ResNets", "\n", "", "stem", "[", "'conv1'", "]", "=", "conv_layer", "(", "in_chs", ",", "stem_chs", "[", "0", "]", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "stem", "[", "'norm1'", "]", "=", "norm_layer", "(", "stem_chs", "[", "0", "]", ")", "\n", "stem", "[", "'conv2'", "]", "=", "conv_layer", "(", "stem_chs", "[", "0", "]", ",", "stem_chs", "[", "1", "]", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "stem", "[", "'norm2'", "]", "=", "norm_layer", "(", "stem_chs", "[", "1", "]", ")", "\n", "stem", "[", "'conv3'", "]", "=", "conv_layer", "(", "stem_chs", "[", "1", "]", ",", "out_chs", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "if", "not", "preact", ":", "\n", "            ", "stem", "[", "'norm3'", "]", "=", "norm_layer", "(", "out_chs", ")", "\n", "", "", "else", ":", "\n", "# The usual 7x7 stem conv", "\n", "        ", "stem", "[", "'conv'", "]", "=", "conv_layer", "(", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ")", "\n", "if", "not", "preact", ":", "\n", "            ", "stem", "[", "'norm'", "]", "=", "norm_layer", "(", "out_chs", ")", "\n", "\n", "", "", "if", "'fixed'", "in", "stem_type", ":", "\n", "# 'fixed' SAME padding approximation that is used in BiT models", "\n", "        ", "stem", "[", "'pad'", "]", "=", "nn", ".", "ConstantPad2d", "(", "1", ",", "0.", ")", "\n", "stem", "[", "'pool'", "]", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "", "elif", "'same'", "in", "stem_type", ":", "\n", "# full, input size based 'SAME' padding, used in ViT Hybrid model", "\n", "        ", "stem", "[", "'pool'", "]", "=", "create_pool2d", "(", "'max'", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "'same'", ")", "\n", "", "else", ":", "\n", "# the usual PyTorch symmetric padding", "\n", "        ", "stem", "[", "'pool'", "]", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "stem", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._init_weights": [[452, 465], ["isinstance", "torch.init.normal_", "torch.init.zeros_", "isinstance", "isinstance", "torch.init.kaiming_normal_", "isinstance", "torch.init.zeros_", "torch.init.ones_", "torch.init.zeros_", "hasattr", "module.zero_init_last"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet.SelectiveKernelBottleneck.zero_init_last"], ["", "", "def", "_init_weights", "(", "module", ":", "nn", ".", "Module", ",", "name", ":", "str", "=", "''", ",", "zero_init_last", "=", "True", ")", ":", "\n", "    ", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "or", "(", "'head.fc'", "in", "name", "and", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "module", ".", "weight", ",", "mean", "=", "0.0", ",", "std", "=", "0.01", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", ":", "\n", "        ", "nn", ".", "init", ".", "kaiming_normal_", "(", "module", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "(", "nn", ".", "BatchNorm2d", ",", "nn", ".", "LayerNorm", ",", "nn", ".", "GroupNorm", ")", ")", ":", "\n", "        ", "nn", ".", "init", ".", "ones_", "(", "module", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "", "elif", "zero_init_last", "and", "hasattr", "(", "module", ",", "'zero_init_last'", ")", ":", "\n", "        ", "module", ".", "zero_init_last", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._load_weights": [[467, 503], ["torch.no_grad", "torch.no_grad", "np.load", "helpers.adapt_input_conv", "model.stem.conv.weight.copy_", "model.norm.weight.copy_", "model.norm.bias.copy_", "enumerate", "torch.from_numpy", "torch.from_numpy", "resnetv2._load_weights.t2p"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.adapt_input_conv"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_load_weights", "(", "model", ":", "nn", ".", "Module", ",", "checkpoint_path", ":", "str", ",", "prefix", ":", "str", "=", "'resnet/'", ")", ":", "\n", "    ", "import", "numpy", "as", "np", "\n", "\n", "def", "t2p", "(", "conv_weights", ")", ":", "\n", "        ", "\"\"\"Possibly convert HWIO to OIHW.\"\"\"", "\n", "if", "conv_weights", ".", "ndim", "==", "4", ":", "\n", "            ", "conv_weights", "=", "conv_weights", ".", "transpose", "(", "[", "3", ",", "2", ",", "0", ",", "1", "]", ")", "\n", "", "return", "torch", ".", "from_numpy", "(", "conv_weights", ")", "\n", "\n", "", "weights", "=", "np", ".", "load", "(", "checkpoint_path", ")", "\n", "stem_conv_w", "=", "adapt_input_conv", "(", "\n", "model", ".", "stem", ".", "conv", ".", "weight", ".", "shape", "[", "1", "]", ",", "t2p", "(", "weights", "[", "f'{prefix}root_block/standardized_conv2d/kernel'", "]", ")", ")", "\n", "model", ".", "stem", ".", "conv", ".", "weight", ".", "copy_", "(", "stem_conv_w", ")", "\n", "model", ".", "norm", ".", "weight", ".", "copy_", "(", "t2p", "(", "weights", "[", "f'{prefix}group_norm/gamma'", "]", ")", ")", "\n", "model", ".", "norm", ".", "bias", ".", "copy_", "(", "t2p", "(", "weights", "[", "f'{prefix}group_norm/beta'", "]", ")", ")", "\n", "if", "isinstance", "(", "getattr", "(", "model", ".", "head", ",", "'fc'", ",", "None", ")", ",", "nn", ".", "Conv2d", ")", "and", "model", ".", "head", ".", "fc", ".", "weight", ".", "shape", "[", "0", "]", "==", "weights", "[", "f'{prefix}head/conv2d/kernel'", "]", ".", "shape", "[", "-", "1", "]", ":", "\n", "        ", "model", ".", "head", ".", "fc", ".", "weight", ".", "copy_", "(", "t2p", "(", "weights", "[", "f'{prefix}head/conv2d/kernel'", "]", ")", ")", "\n", "model", ".", "head", ".", "fc", ".", "bias", ".", "copy_", "(", "t2p", "(", "weights", "[", "f'{prefix}head/conv2d/bias'", "]", ")", ")", "\n", "", "for", "i", ",", "(", "sname", ",", "stage", ")", "in", "enumerate", "(", "model", ".", "stages", ".", "named_children", "(", ")", ")", ":", "\n", "        ", "for", "j", ",", "(", "bname", ",", "block", ")", "in", "enumerate", "(", "stage", ".", "blocks", ".", "named_children", "(", ")", ")", ":", "\n", "            ", "cname", "=", "'standardized_conv2d'", "\n", "block_prefix", "=", "f'{prefix}block{i + 1}/unit{j + 1:02d}/'", "\n", "block", ".", "conv1", ".", "weight", ".", "copy_", "(", "t2p", "(", "weights", "[", "f'{block_prefix}a/{cname}/kernel'", "]", ")", ")", "\n", "block", ".", "conv2", ".", "weight", ".", "copy_", "(", "t2p", "(", "weights", "[", "f'{block_prefix}b/{cname}/kernel'", "]", ")", ")", "\n", "block", ".", "conv3", ".", "weight", ".", "copy_", "(", "t2p", "(", "weights", "[", "f'{block_prefix}c/{cname}/kernel'", "]", ")", ")", "\n", "block", ".", "norm1", ".", "weight", ".", "copy_", "(", "t2p", "(", "weights", "[", "f'{block_prefix}a/group_norm/gamma'", "]", ")", ")", "\n", "block", ".", "norm2", ".", "weight", ".", "copy_", "(", "t2p", "(", "weights", "[", "f'{block_prefix}b/group_norm/gamma'", "]", ")", ")", "\n", "block", ".", "norm3", ".", "weight", ".", "copy_", "(", "t2p", "(", "weights", "[", "f'{block_prefix}c/group_norm/gamma'", "]", ")", ")", "\n", "block", ".", "norm1", ".", "bias", ".", "copy_", "(", "t2p", "(", "weights", "[", "f'{block_prefix}a/group_norm/beta'", "]", ")", ")", "\n", "block", ".", "norm2", ".", "bias", ".", "copy_", "(", "t2p", "(", "weights", "[", "f'{block_prefix}b/group_norm/beta'", "]", ")", ")", "\n", "block", ".", "norm3", ".", "bias", ".", "copy_", "(", "t2p", "(", "weights", "[", "f'{block_prefix}c/group_norm/beta'", "]", ")", ")", "\n", "if", "block", ".", "downsample", "is", "not", "None", ":", "\n", "                ", "w", "=", "weights", "[", "f'{block_prefix}a/proj/{cname}/kernel'", "]", "\n", "block", ".", "downsample", ".", "conv", ".", "weight", ".", "copy_", "(", "t2p", "(", "w", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2": [[505, 512], ["dict", "helpers.build_model_with_cfg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "", "", "def", "_create_resnetv2", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "feature_cfg", "=", "dict", "(", "flatten_sequential", "=", "True", ")", "\n", "return", "build_model_with_cfg", "(", "\n", "ResNetV2", ",", "variant", ",", "pretrained", ",", "\n", "feature_cfg", "=", "feature_cfg", ",", "\n", "pretrained_custom_load", "=", "'_bit'", "in", "variant", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2_bit": [[514, 517], ["resnetv2._create_resnetv2", "functools.partial"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2"], ["", "def", "_create_resnetv2_bit", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2", "(", "\n", "variant", ",", "pretrained", "=", "pretrained", ",", "stem_type", "=", "'fixed'", ",", "conv_layer", "=", "partial", "(", "StdConv2d", ",", "eps", "=", "1e-8", ")", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_50x1_bitm": [[519, 523], ["resnetv2._create_resnetv2_bit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2_bit"], ["", "@", "register_model", "\n", "def", "resnetv2_50x1_bitm", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2_bit", "(", "\n", "'resnetv2_50x1_bitm'", ",", "pretrained", "=", "pretrained", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "width_factor", "=", "1", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_50x3_bitm": [[525, 529], ["resnetv2._create_resnetv2_bit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2_bit"], ["", "@", "register_model", "\n", "def", "resnetv2_50x3_bitm", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2_bit", "(", "\n", "'resnetv2_50x3_bitm'", ",", "pretrained", "=", "pretrained", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "width_factor", "=", "3", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_101x1_bitm": [[531, 535], ["resnetv2._create_resnetv2_bit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2_bit"], ["", "@", "register_model", "\n", "def", "resnetv2_101x1_bitm", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2_bit", "(", "\n", "'resnetv2_101x1_bitm'", ",", "pretrained", "=", "pretrained", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "width_factor", "=", "1", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_101x3_bitm": [[537, 541], ["resnetv2._create_resnetv2_bit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2_bit"], ["", "@", "register_model", "\n", "def", "resnetv2_101x3_bitm", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2_bit", "(", "\n", "'resnetv2_101x3_bitm'", ",", "pretrained", "=", "pretrained", ",", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "width_factor", "=", "3", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_152x2_bitm": [[543, 547], ["resnetv2._create_resnetv2_bit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2_bit"], ["", "@", "register_model", "\n", "def", "resnetv2_152x2_bitm", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2_bit", "(", "\n", "'resnetv2_152x2_bitm'", ",", "pretrained", "=", "pretrained", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "width_factor", "=", "2", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_152x4_bitm": [[549, 553], ["resnetv2._create_resnetv2_bit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2_bit"], ["", "@", "register_model", "\n", "def", "resnetv2_152x4_bitm", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2_bit", "(", "\n", "'resnetv2_152x4_bitm'", ",", "pretrained", "=", "pretrained", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "width_factor", "=", "4", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_50x1_bitm_in21k": [[555, 560], ["resnetv2._create_resnetv2_bit", "kwargs.pop"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2_bit"], ["", "@", "register_model", "\n", "def", "resnetv2_50x1_bitm_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2_bit", "(", "\n", "'resnetv2_50x1_bitm_in21k'", ",", "pretrained", "=", "pretrained", ",", "num_classes", "=", "kwargs", ".", "pop", "(", "'num_classes'", ",", "21843", ")", ",", "\n", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "width_factor", "=", "1", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_50x3_bitm_in21k": [[562, 567], ["resnetv2._create_resnetv2_bit", "kwargs.pop"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2_bit"], ["", "@", "register_model", "\n", "def", "resnetv2_50x3_bitm_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2_bit", "(", "\n", "'resnetv2_50x3_bitm_in21k'", ",", "pretrained", "=", "pretrained", ",", "num_classes", "=", "kwargs", ".", "pop", "(", "'num_classes'", ",", "21843", ")", ",", "\n", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "width_factor", "=", "3", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_101x1_bitm_in21k": [[569, 574], ["resnetv2._create_resnetv2", "kwargs.pop"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2"], ["", "@", "register_model", "\n", "def", "resnetv2_101x1_bitm_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2", "(", "\n", "'resnetv2_101x1_bitm_in21k'", ",", "pretrained", "=", "pretrained", ",", "num_classes", "=", "kwargs", ".", "pop", "(", "'num_classes'", ",", "21843", ")", ",", "\n", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "width_factor", "=", "1", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_101x3_bitm_in21k": [[576, 581], ["resnetv2._create_resnetv2_bit", "kwargs.pop"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2_bit"], ["", "@", "register_model", "\n", "def", "resnetv2_101x3_bitm_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2_bit", "(", "\n", "'resnetv2_101x3_bitm_in21k'", ",", "pretrained", "=", "pretrained", ",", "num_classes", "=", "kwargs", ".", "pop", "(", "'num_classes'", ",", "21843", ")", ",", "\n", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "width_factor", "=", "3", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_152x2_bitm_in21k": [[583, 588], ["resnetv2._create_resnetv2_bit", "kwargs.pop"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2_bit"], ["", "@", "register_model", "\n", "def", "resnetv2_152x2_bitm_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2_bit", "(", "\n", "'resnetv2_152x2_bitm_in21k'", ",", "pretrained", "=", "pretrained", ",", "num_classes", "=", "kwargs", ".", "pop", "(", "'num_classes'", ",", "21843", ")", ",", "\n", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "width_factor", "=", "2", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_152x4_bitm_in21k": [[590, 595], ["resnetv2._create_resnetv2_bit", "kwargs.pop"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2_bit"], ["", "@", "register_model", "\n", "def", "resnetv2_152x4_bitm_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2_bit", "(", "\n", "'resnetv2_152x4_bitm_in21k'", ",", "pretrained", "=", "pretrained", ",", "num_classes", "=", "kwargs", ".", "pop", "(", "'num_classes'", ",", "21843", ")", ",", "\n", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "width_factor", "=", "4", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_50x1_bit_distilled": [[597, 604], ["resnetv2._create_resnetv2_bit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2_bit"], ["", "@", "register_model", "\n", "def", "resnetv2_50x1_bit_distilled", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResNetV2-50x1-BiT Distilled\n    Paper: Knowledge distillation: A good teacher is patient and consistent - https://arxiv.org/abs/2106.05237\n    \"\"\"", "\n", "return", "_create_resnetv2_bit", "(", "\n", "'resnetv2_50x1_bit_distilled'", ",", "pretrained", "=", "pretrained", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "width_factor", "=", "1", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_152x2_bit_teacher": [[606, 613], ["resnetv2._create_resnetv2_bit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2_bit"], ["", "@", "register_model", "\n", "def", "resnetv2_152x2_bit_teacher", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResNetV2-152x2-BiT Teacher\n    Paper: Knowledge distillation: A good teacher is patient and consistent - https://arxiv.org/abs/2106.05237\n    \"\"\"", "\n", "return", "_create_resnetv2_bit", "(", "\n", "'resnetv2_152x2_bit_teacher'", ",", "pretrained", "=", "pretrained", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "width_factor", "=", "2", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_152x2_bit_teacher_384": [[615, 622], ["resnetv2._create_resnetv2_bit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2_bit"], ["", "@", "register_model", "\n", "def", "resnetv2_152x2_bit_teacher_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ResNetV2-152xx-BiT Teacher @ 384x384\n    Paper: Knowledge distillation: A good teacher is patient and consistent - https://arxiv.org/abs/2106.05237\n    \"\"\"", "\n", "return", "_create_resnetv2_bit", "(", "\n", "'resnetv2_152x2_bit_teacher_384'", ",", "pretrained", "=", "pretrained", ",", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "width_factor", "=", "2", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_50": [[624, 629], ["resnetv2._create_resnetv2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2"], ["", "@", "register_model", "\n", "def", "resnetv2_50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2", "(", "\n", "'resnetv2_50'", ",", "pretrained", "=", "pretrained", ",", "\n", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "conv_layer", "=", "create_conv2d", ",", "norm_layer", "=", "BatchNormAct2d", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_50d": [[631, 637], ["resnetv2._create_resnetv2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2"], ["", "@", "register_model", "\n", "def", "resnetv2_50d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2", "(", "\n", "'resnetv2_50d'", ",", "pretrained", "=", "pretrained", ",", "\n", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "conv_layer", "=", "create_conv2d", ",", "norm_layer", "=", "BatchNormAct2d", ",", "\n", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_50t": [[639, 645], ["resnetv2._create_resnetv2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2"], ["", "@", "register_model", "\n", "def", "resnetv2_50t", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2", "(", "\n", "'resnetv2_50t'", ",", "pretrained", "=", "pretrained", ",", "\n", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "conv_layer", "=", "create_conv2d", ",", "norm_layer", "=", "BatchNormAct2d", ",", "\n", "stem_type", "=", "'tiered'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_101": [[647, 652], ["resnetv2._create_resnetv2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2"], ["", "@", "register_model", "\n", "def", "resnetv2_101", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2", "(", "\n", "'resnetv2_101'", ",", "pretrained", "=", "pretrained", ",", "\n", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "conv_layer", "=", "create_conv2d", ",", "norm_layer", "=", "BatchNormAct2d", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_101d": [[654, 660], ["resnetv2._create_resnetv2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2"], ["", "@", "register_model", "\n", "def", "resnetv2_101d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2", "(", "\n", "'resnetv2_101d'", ",", "pretrained", "=", "pretrained", ",", "\n", "layers", "=", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "conv_layer", "=", "create_conv2d", ",", "norm_layer", "=", "BatchNormAct2d", ",", "\n", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_152": [[662, 667], ["resnetv2._create_resnetv2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2"], ["", "@", "register_model", "\n", "def", "resnetv2_152", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2", "(", "\n", "'resnetv2_152'", ",", "pretrained", "=", "pretrained", ",", "\n", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "conv_layer", "=", "create_conv2d", ",", "norm_layer", "=", "BatchNormAct2d", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_152d": [[669, 675], ["resnetv2._create_resnetv2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2"], ["", "@", "register_model", "\n", "def", "resnetv2_152d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2", "(", "\n", "'resnetv2_152d'", ",", "pretrained", "=", "pretrained", ",", "\n", "layers", "=", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "conv_layer", "=", "create_conv2d", ",", "norm_layer", "=", "BatchNormAct2d", ",", "\n", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_50d_gn": [[679, 685], ["resnetv2._create_resnetv2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2"], ["", "@", "register_model", "\n", "def", "resnetv2_50d_gn", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2", "(", "\n", "'resnetv2_50d_gn'", ",", "pretrained", "=", "pretrained", ",", "\n", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "conv_layer", "=", "create_conv2d", ",", "norm_layer", "=", "GroupNormAct", ",", "\n", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_50d_evob": [[687, 693], ["resnetv2._create_resnetv2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2"], ["", "@", "register_model", "\n", "def", "resnetv2_50d_evob", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2", "(", "\n", "'resnetv2_50d_evob'", ",", "pretrained", "=", "pretrained", ",", "\n", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "conv_layer", "=", "create_conv2d", ",", "norm_layer", "=", "EvoNorm2dB0", ",", "\n", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "zero_init_last", "=", "True", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_50d_evos": [[695, 701], ["resnetv2._create_resnetv2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2"], ["", "@", "register_model", "\n", "def", "resnetv2_50d_evos", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2", "(", "\n", "'resnetv2_50d_evos'", ",", "pretrained", "=", "pretrained", ",", "\n", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "conv_layer", "=", "create_conv2d", ",", "norm_layer", "=", "EvoNorm2dS0", ",", "\n", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2.resnetv2_50d_frn": [[703, 709], ["resnetv2._create_resnetv2"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.resnetv2._create_resnetv2"], ["", "@", "register_model", "\n", "def", "resnetv2_50d_frn", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_resnetv2", "(", "\n", "'resnetv2_50d_frn'", ",", "pretrained", "=", "pretrained", ",", "\n", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "conv_layer", "=", "create_conv2d", ",", "norm_layer", "=", "FilterResponseNormTlu2d", ",", "\n", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception.SeparableConv2d.__init__": [[52, 58], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "dilation", "=", "1", ")", ":", "\n", "        ", "super", "(", "SeparableConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "in_channels", ",", "kernel_size", ",", "stride", ",", "padding", ",", "dilation", ",", "groups", "=", "in_channels", ",", "bias", "=", "False", ")", "\n", "self", ".", "pointwise", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "1", ",", "0", ",", "1", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception.SeparableConv2d.forward": [[59, 63], ["xception.SeparableConv2d.conv1", "xception.SeparableConv2d.pointwise"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "pointwise", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception.Block.__init__": [[66, 95], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "rep.append", "rep.append", "rep.append", "torch.ReLU", "torch.ReLU", "torch.ReLU", "rep.append", "torch.ReLU", "torch.ReLU", "torch.ReLU", "xception.SeparableConv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "reps", ",", "strides", "=", "1", ",", "start_with_relu", "=", "True", ",", "grow_first", "=", "True", ")", ":", "\n", "        ", "super", "(", "Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "out_channels", "!=", "in_channels", "or", "strides", "!=", "1", ":", "\n", "            ", "self", ".", "skip", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "stride", "=", "strides", ",", "bias", "=", "False", ")", "\n", "self", ".", "skipbn", "=", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "skip", "=", "None", "\n", "\n", "", "rep", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "reps", ")", ":", "\n", "            ", "if", "grow_first", ":", "\n", "                ", "inc", "=", "in_channels", "if", "i", "==", "0", "else", "out_channels", "\n", "outc", "=", "out_channels", "\n", "", "else", ":", "\n", "                ", "inc", "=", "in_channels", "\n", "outc", "=", "in_channels", "if", "i", "<", "(", "reps", "-", "1", ")", "else", "out_channels", "\n", "", "rep", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "rep", ".", "append", "(", "SeparableConv2d", "(", "inc", ",", "outc", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ")", "\n", "rep", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "outc", ")", ")", "\n", "\n", "", "if", "not", "start_with_relu", ":", "\n", "            ", "rep", "=", "rep", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "            ", "rep", "[", "0", "]", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", "\n", "\n", "", "if", "strides", "!=", "1", ":", "\n", "            ", "rep", ".", "append", "(", "nn", ".", "MaxPool2d", "(", "3", ",", "strides", ",", "1", ")", ")", "\n", "", "self", ".", "rep", "=", "nn", ".", "Sequential", "(", "*", "rep", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception.Block.forward": [[96, 107], ["xception.Block.rep", "xception.Block.skip", "xception.Block.skipbn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "x", "=", "self", ".", "rep", "(", "inp", ")", "\n", "\n", "if", "self", ".", "skip", "is", "not", "None", ":", "\n", "            ", "skip", "=", "self", ".", "skip", "(", "inp", ")", "\n", "skip", "=", "self", ".", "skipbn", "(", "skip", ")", "\n", "", "else", ":", "\n", "            ", "skip", "=", "inp", "\n", "\n", "", "x", "+=", "skip", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception.Xception.__init__": [[115, 174], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "xception.Block", "xception.Block", "xception.Block", "xception.Block", "xception.Block", "xception.Block", "xception.Block", "xception.Block", "xception.Block", "xception.Block", "xception.Block", "xception.Block", "xception.SeparableConv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "xception.SeparableConv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "layers.create_classifier", "xception.Xception.modules", "dict", "dict", "dict", "dict", "dict", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["def", "__init__", "(", "self", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "drop_rate", "=", "0.", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "\"\"\" Constructor\n        Args:\n            num_classes: number of classes\n        \"\"\"", "\n", "super", "(", "Xception", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_features", "=", "2048", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_chans", ",", "32", ",", "3", ",", "2", ",", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "32", ")", "\n", "self", ".", "act1", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "3", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "act2", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "block1", "=", "Block", "(", "64", ",", "128", ",", "2", ",", "2", ",", "start_with_relu", "=", "False", ")", "\n", "self", ".", "block2", "=", "Block", "(", "128", ",", "256", ",", "2", ",", "2", ")", "\n", "self", ".", "block3", "=", "Block", "(", "256", ",", "728", ",", "2", ",", "2", ")", "\n", "\n", "self", ".", "block4", "=", "Block", "(", "728", ",", "728", ",", "3", ",", "1", ")", "\n", "self", ".", "block5", "=", "Block", "(", "728", ",", "728", ",", "3", ",", "1", ")", "\n", "self", ".", "block6", "=", "Block", "(", "728", ",", "728", ",", "3", ",", "1", ")", "\n", "self", ".", "block7", "=", "Block", "(", "728", ",", "728", ",", "3", ",", "1", ")", "\n", "\n", "self", ".", "block8", "=", "Block", "(", "728", ",", "728", ",", "3", ",", "1", ")", "\n", "self", ".", "block9", "=", "Block", "(", "728", ",", "728", ",", "3", ",", "1", ")", "\n", "self", ".", "block10", "=", "Block", "(", "728", ",", "728", ",", "3", ",", "1", ")", "\n", "self", ".", "block11", "=", "Block", "(", "728", ",", "728", ",", "3", ",", "1", ")", "\n", "\n", "self", ".", "block12", "=", "Block", "(", "728", ",", "1024", ",", "2", ",", "2", ",", "grow_first", "=", "False", ")", "\n", "\n", "self", ".", "conv3", "=", "SeparableConv2d", "(", "1024", ",", "1536", ",", "3", ",", "1", ",", "1", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "1536", ")", "\n", "self", ".", "act3", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "conv4", "=", "SeparableConv2d", "(", "1536", ",", "self", ".", "num_features", ",", "3", ",", "1", ",", "1", ")", "\n", "self", ".", "bn4", "=", "nn", ".", "BatchNorm2d", "(", "self", ".", "num_features", ")", "\n", "self", ".", "act4", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "feature_info", "=", "[", "\n", "dict", "(", "num_chs", "=", "64", ",", "reduction", "=", "2", ",", "module", "=", "'act2'", ")", ",", "\n", "dict", "(", "num_chs", "=", "128", ",", "reduction", "=", "4", ",", "module", "=", "'block2.rep.0'", ")", ",", "\n", "dict", "(", "num_chs", "=", "256", ",", "reduction", "=", "8", ",", "module", "=", "'block3.rep.0'", ")", ",", "\n", "dict", "(", "num_chs", "=", "728", ",", "reduction", "=", "16", ",", "module", "=", "'block12.rep.0'", ")", ",", "\n", "dict", "(", "num_chs", "=", "2048", ",", "reduction", "=", "32", ",", "module", "=", "'act4'", ")", ",", "\n", "]", "\n", "\n", "self", ".", "global_pool", ",", "self", ".", "fc", "=", "create_classifier", "(", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n", "# #------- init weights --------", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception.Xception.group_matcher": [[175, 182], ["dict"], "methods", ["None"], ["", "", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^conv[12]|bn[12]'", ",", "\n", "blocks", "=", "[", "\n", "(", "r'^block(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^conv[34]|bn[34]'", ",", "(", "99", ",", ")", ")", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception.Xception.set_grad_checkpointing": [[185, 188], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "\"gradient checkpointing not supported\"", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception.Xception.get_classifier": [[189, 192], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception.Xception.reset_classifier": [[193, 196], ["layers.create_classifier"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "fc", "=", "create_classifier", "(", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception.Xception.forward_features": [[197, 227], ["xception.Xception.conv1", "xception.Xception.bn1", "xception.Xception.act1", "xception.Xception.conv2", "xception.Xception.bn2", "xception.Xception.act2", "xception.Xception.block1", "xception.Xception.block2", "xception.Xception.block3", "xception.Xception.block4", "xception.Xception.block5", "xception.Xception.block6", "xception.Xception.block7", "xception.Xception.block8", "xception.Xception.block9", "xception.Xception.block10", "xception.Xception.block11", "xception.Xception.block12", "xception.Xception.conv3", "xception.Xception.bn3", "xception.Xception.act3", "xception.Xception.conv4", "xception.Xception.bn4", "xception.Xception.act4"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "act1", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "bn2", "(", "x", ")", "\n", "x", "=", "self", ".", "act2", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "block1", "(", "x", ")", "\n", "x", "=", "self", ".", "block2", "(", "x", ")", "\n", "x", "=", "self", ".", "block3", "(", "x", ")", "\n", "x", "=", "self", ".", "block4", "(", "x", ")", "\n", "x", "=", "self", ".", "block5", "(", "x", ")", "\n", "x", "=", "self", ".", "block6", "(", "x", ")", "\n", "x", "=", "self", ".", "block7", "(", "x", ")", "\n", "x", "=", "self", ".", "block8", "(", "x", ")", "\n", "x", "=", "self", ".", "block9", "(", "x", ")", "\n", "x", "=", "self", ".", "block10", "(", "x", ")", "\n", "x", "=", "self", ".", "block11", "(", "x", ")", "\n", "x", "=", "self", ".", "block12", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv3", "(", "x", ")", "\n", "x", "=", "self", ".", "bn3", "(", "x", ")", "\n", "x", "=", "self", ".", "act3", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv4", "(", "x", ")", "\n", "x", "=", "self", ".", "bn4", "(", "x", ")", "\n", "x", "=", "self", ".", "act4", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception.Xception.forward_head": [[228, 233], ["xception.Xception.global_pool", "torch.dropout", "torch.dropout", "torch.dropout", "xception.Xception.fc"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ":", "\n", "            ", "F", ".", "dropout", "(", "x", ",", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "fc", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception.Xception.forward": [[234, 238], ["xception.Xception.forward_features", "xception.Xception.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception._xception": [[240, 245], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_xception", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "\n", "Xception", ",", "variant", ",", "pretrained", ",", "\n", "feature_cfg", "=", "dict", "(", "feature_cls", "=", "'hook'", ")", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception.xception": [[247, 250], ["xception._xception"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xception._xception"], ["", "@", "register_model", "\n", "def", "xception", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_xception", "(", "'xception'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.SequentialList.__init__": [[58, 60], ["torch.Sequential.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "super", "(", "SequentialList", ",", "self", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.SequentialList.forward": [[71, 75], ["module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "        ", "for", "module", "in", "self", ":", "\n", "            ", "x", "=", "module", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.SelectSeq.__init__": [[78, 82], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "mode", "=", "'index'", ",", "index", "=", "0", ")", ":", "\n", "        ", "super", "(", "SelectSeq", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "index", "=", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.SelectSeq.forward": [[93, 98], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'index'", ":", "\n", "            ", "return", "x", "[", "self", ".", "index", "]", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "x", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.SelecSLSBlock.__init__": [[111, 124], ["torch.Module.__init__", "selecsls.conv_bn", "selecsls.conv_bn", "selecsls.conv_bn", "selecsls.conv_bn", "selecsls.conv_bn", "selecsls.conv_bn"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.conv_bn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.conv_bn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.conv_bn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.conv_bn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.conv_bn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.conv_bn"], ["    ", "def", "__init__", "(", "self", ",", "in_chs", ",", "skip_chs", ",", "mid_chs", ",", "out_chs", ",", "is_first", ",", "stride", ",", "dilation", "=", "1", ")", ":", "\n", "        ", "super", "(", "SelecSLSBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "is_first", "=", "is_first", "\n", "assert", "stride", "in", "[", "1", ",", "2", "]", "\n", "\n", "# Process input with 4 conv blocks with the same number of input and output channels", "\n", "self", ".", "conv1", "=", "conv_bn", "(", "in_chs", ",", "mid_chs", ",", "3", ",", "stride", ",", "dilation", "=", "dilation", ")", "\n", "self", ".", "conv2", "=", "conv_bn", "(", "mid_chs", ",", "mid_chs", ",", "1", ")", "\n", "self", ".", "conv3", "=", "conv_bn", "(", "mid_chs", ",", "mid_chs", "//", "2", ",", "3", ")", "\n", "self", ".", "conv4", "=", "conv_bn", "(", "mid_chs", "//", "2", ",", "mid_chs", ",", "1", ")", "\n", "self", ".", "conv5", "=", "conv_bn", "(", "mid_chs", ",", "mid_chs", "//", "2", ",", "3", ")", "\n", "self", ".", "conv6", "=", "conv_bn", "(", "2", "*", "mid_chs", "+", "(", "0", "if", "is_first", "else", "skip_chs", ")", ",", "out_chs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.SelecSLSBlock.forward": [[125, 138], ["selecsls.SelecSLSBlock.conv1", "selecsls.SelecSLSBlock.conv3", "selecsls.SelecSLSBlock.conv5", "isinstance", "len", "selecsls.SelecSLSBlock.conv2", "selecsls.SelecSLSBlock.conv4", "selecsls.SelecSLSBlock.conv6", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "selecsls.SelecSLSBlock.conv6", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "List", "[", "torch", ".", "Tensor", "]", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "        ", "if", "not", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "            ", "x", "=", "[", "x", "]", "\n", "", "assert", "len", "(", "x", ")", "in", "[", "1", ",", "2", "]", "\n", "\n", "d1", "=", "self", ".", "conv1", "(", "x", "[", "0", "]", ")", "\n", "d2", "=", "self", ".", "conv3", "(", "self", ".", "conv2", "(", "d1", ")", ")", "\n", "d3", "=", "self", ".", "conv5", "(", "self", ".", "conv4", "(", "d2", ")", ")", "\n", "if", "self", ".", "is_first", ":", "\n", "            ", "out", "=", "self", ".", "conv6", "(", "torch", ".", "cat", "(", "[", "d1", ",", "d2", ",", "d3", "]", ",", "1", ")", ")", "\n", "return", "[", "out", ",", "out", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "self", ".", "conv6", "(", "torch", ".", "cat", "(", "[", "d1", ",", "d2", ",", "d3", ",", "x", "[", "1", "]", "]", ",", "1", ")", ")", ",", "x", "[", "1", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.SelecSLS.__init__": [[156, 176], ["torch.Module.__init__", "selecsls.conv_bn", "selecsls.SequentialList", "selecsls.SelectSeq", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.create_classifier", "selecsls.SelecSLS.named_modules", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "selecsls.conv_bn", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.conv_bn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.conv_bn"], ["def", "__init__", "(", "self", ",", "cfg", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "drop_rate", "=", "0.0", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "super", "(", "SelecSLS", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "stem", "=", "conv_bn", "(", "in_chans", ",", "32", ",", "stride", "=", "2", ")", "\n", "self", ".", "features", "=", "SequentialList", "(", "*", "[", "cfg", "[", "'block'", "]", "(", "*", "block_args", ")", "for", "block_args", "in", "cfg", "[", "'features'", "]", "]", ")", "\n", "self", ".", "from_seq", "=", "SelectSeq", "(", ")", "# from List[tensor] -> Tensor in module compatible way", "\n", "self", ".", "head", "=", "nn", ".", "Sequential", "(", "*", "[", "conv_bn", "(", "*", "conv_args", ")", "for", "conv_args", "in", "cfg", "[", "'head'", "]", "]", ")", "\n", "self", ".", "num_features", "=", "cfg", "[", "'num_features'", "]", "\n", "self", ".", "feature_info", "=", "cfg", "[", "'feature_info'", "]", "\n", "\n", "self", ".", "global_pool", ",", "self", ".", "fc", "=", "create_classifier", "(", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n", "for", "n", ",", "m", "in", "self", ".", "named_modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.SelecSLS.group_matcher": [[177, 183], ["dict"], "methods", ["None"], ["", "", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^stem'", ",", "\n", "blocks", "=", "r'^features\\.(\\d+)'", ",", "\n", "blocks_head", "=", "r'^head'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.SelecSLS.set_grad_checkpointing": [[185, 188], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "'gradient checkpointing not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.SelecSLS.get_classifier": [[189, 192], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.SelecSLS.reset_classifier": [[193, 196], ["layers.create_classifier"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "fc", "=", "create_classifier", "(", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.SelecSLS.forward_features": [[197, 202], ["selecsls.SelecSLS.stem", "selecsls.SelecSLS.features", "selecsls.SelecSLS.head", "selecsls.SelecSLS.from_seq"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "x", "=", "self", ".", "head", "(", "self", ".", "from_seq", "(", "x", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.SelecSLS.forward_head": [[203, 208], ["selecsls.SelecSLS.global_pool", "torch.dropout", "torch.dropout", "torch.dropout", "selecsls.SelecSLS.fc"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ">", "0.", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "fc", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.SelecSLS.forward": [[209, 213], ["selecsls.SelecSLS.forward_features", "selecsls.SelecSLS.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls._cfg": [[26, 34], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "4", ",", "4", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bilinear'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'stem.0'", ",", "'classifier'", ":", "'fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.conv_bn": [[100, 107], ["torch.Sequential", "torch.Conv2d", "torch.BatchNorm2d", "torch.ReLU"], "function", ["None"], ["", "", "", "def", "conv_bn", "(", "in_chs", ",", "out_chs", ",", "k", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "None", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "if", "padding", "is", "None", ":", "\n", "        ", "padding", "=", "(", "(", "stride", "-", "1", ")", "+", "dilation", "*", "(", "k", "-", "1", ")", ")", "//", "2", "\n", "", "return", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_chs", ",", "out_chs", ",", "k", ",", "stride", ",", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_chs", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls._create_selecsls": [[215, 343], ["variant.startswith", "helpers.build_model_with_cfg", "dict", "feature_info.extend", "feature_info.append", "variant.startswith", "dict", "feature_info.append", "feature_info.append", "feature_info.extend", "feature_info.append", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "feature_info.append", "feature_info.append", "feature_info.extend", "feature_info.extend", "ValueError", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_selecsls", "(", "variant", ",", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "cfg", "=", "{", "}", "\n", "feature_info", "=", "[", "dict", "(", "num_chs", "=", "32", ",", "reduction", "=", "2", ",", "module", "=", "'stem.2'", ")", "]", "\n", "if", "variant", ".", "startswith", "(", "'selecsls42'", ")", ":", "\n", "        ", "cfg", "[", "'block'", "]", "=", "SelecSLSBlock", "\n", "# Define configuration of the network after the initial neck", "\n", "cfg", "[", "'features'", "]", "=", "[", "\n", "# in_chs, skip_chs, mid_chs, out_chs, is_first, stride", "\n", "(", "32", ",", "0", ",", "64", ",", "64", ",", "True", ",", "2", ")", ",", "\n", "(", "64", ",", "64", ",", "64", ",", "128", ",", "False", ",", "1", ")", ",", "\n", "(", "128", ",", "0", ",", "144", ",", "144", ",", "True", ",", "2", ")", ",", "\n", "(", "144", ",", "144", ",", "144", ",", "288", ",", "False", ",", "1", ")", ",", "\n", "(", "288", ",", "0", ",", "304", ",", "304", ",", "True", ",", "2", ")", ",", "\n", "(", "304", ",", "304", ",", "304", ",", "480", ",", "False", ",", "1", ")", ",", "\n", "]", "\n", "feature_info", ".", "extend", "(", "[", "\n", "dict", "(", "num_chs", "=", "128", ",", "reduction", "=", "4", ",", "module", "=", "'features.1'", ")", ",", "\n", "dict", "(", "num_chs", "=", "288", ",", "reduction", "=", "8", ",", "module", "=", "'features.3'", ")", ",", "\n", "dict", "(", "num_chs", "=", "480", ",", "reduction", "=", "16", ",", "module", "=", "'features.5'", ")", ",", "\n", "]", ")", "\n", "# Head can be replaced with alternative configurations depending on the problem", "\n", "feature_info", ".", "append", "(", "dict", "(", "num_chs", "=", "1024", ",", "reduction", "=", "32", ",", "module", "=", "'head.1'", ")", ")", "\n", "if", "variant", "==", "'selecsls42b'", ":", "\n", "            ", "cfg", "[", "'head'", "]", "=", "[", "\n", "(", "480", ",", "960", ",", "3", ",", "2", ")", ",", "\n", "(", "960", ",", "1024", ",", "3", ",", "1", ")", ",", "\n", "(", "1024", ",", "1280", ",", "3", ",", "2", ")", ",", "\n", "(", "1280", ",", "1024", ",", "1", ",", "1", ")", ",", "\n", "]", "\n", "feature_info", ".", "append", "(", "dict", "(", "num_chs", "=", "1024", ",", "reduction", "=", "64", ",", "module", "=", "'head.3'", ")", ")", "\n", "cfg", "[", "'num_features'", "]", "=", "1024", "\n", "", "else", ":", "\n", "            ", "cfg", "[", "'head'", "]", "=", "[", "\n", "(", "480", ",", "960", ",", "3", ",", "2", ")", ",", "\n", "(", "960", ",", "1024", ",", "3", ",", "1", ")", ",", "\n", "(", "1024", ",", "1024", ",", "3", ",", "2", ")", ",", "\n", "(", "1024", ",", "1280", ",", "1", ",", "1", ")", ",", "\n", "]", "\n", "feature_info", ".", "append", "(", "dict", "(", "num_chs", "=", "1280", ",", "reduction", "=", "64", ",", "module", "=", "'head.3'", ")", ")", "\n", "cfg", "[", "'num_features'", "]", "=", "1280", "\n", "\n", "", "", "elif", "variant", ".", "startswith", "(", "'selecsls60'", ")", ":", "\n", "        ", "cfg", "[", "'block'", "]", "=", "SelecSLSBlock", "\n", "# Define configuration of the network after the initial neck", "\n", "cfg", "[", "'features'", "]", "=", "[", "\n", "# in_chs, skip_chs, mid_chs, out_chs, is_first, stride", "\n", "(", "32", ",", "0", ",", "64", ",", "64", ",", "True", ",", "2", ")", ",", "\n", "(", "64", ",", "64", ",", "64", ",", "128", ",", "False", ",", "1", ")", ",", "\n", "(", "128", ",", "0", ",", "128", ",", "128", ",", "True", ",", "2", ")", ",", "\n", "(", "128", ",", "128", ",", "128", ",", "128", ",", "False", ",", "1", ")", ",", "\n", "(", "128", ",", "128", ",", "128", ",", "288", ",", "False", ",", "1", ")", ",", "\n", "(", "288", ",", "0", ",", "288", ",", "288", ",", "True", ",", "2", ")", ",", "\n", "(", "288", ",", "288", ",", "288", ",", "288", ",", "False", ",", "1", ")", ",", "\n", "(", "288", ",", "288", ",", "288", ",", "288", ",", "False", ",", "1", ")", ",", "\n", "(", "288", ",", "288", ",", "288", ",", "416", ",", "False", ",", "1", ")", ",", "\n", "]", "\n", "feature_info", ".", "extend", "(", "[", "\n", "dict", "(", "num_chs", "=", "128", ",", "reduction", "=", "4", ",", "module", "=", "'features.1'", ")", ",", "\n", "dict", "(", "num_chs", "=", "288", ",", "reduction", "=", "8", ",", "module", "=", "'features.4'", ")", ",", "\n", "dict", "(", "num_chs", "=", "416", ",", "reduction", "=", "16", ",", "module", "=", "'features.8'", ")", ",", "\n", "]", ")", "\n", "# Head can be replaced with alternative configurations depending on the problem", "\n", "feature_info", ".", "append", "(", "dict", "(", "num_chs", "=", "1024", ",", "reduction", "=", "32", ",", "module", "=", "'head.1'", ")", ")", "\n", "if", "variant", "==", "'selecsls60b'", ":", "\n", "            ", "cfg", "[", "'head'", "]", "=", "[", "\n", "(", "416", ",", "756", ",", "3", ",", "2", ")", ",", "\n", "(", "756", ",", "1024", ",", "3", ",", "1", ")", ",", "\n", "(", "1024", ",", "1280", ",", "3", ",", "2", ")", ",", "\n", "(", "1280", ",", "1024", ",", "1", ",", "1", ")", ",", "\n", "]", "\n", "feature_info", ".", "append", "(", "dict", "(", "num_chs", "=", "1024", ",", "reduction", "=", "64", ",", "module", "=", "'head.3'", ")", ")", "\n", "cfg", "[", "'num_features'", "]", "=", "1024", "\n", "", "else", ":", "\n", "            ", "cfg", "[", "'head'", "]", "=", "[", "\n", "(", "416", ",", "756", ",", "3", ",", "2", ")", ",", "\n", "(", "756", ",", "1024", ",", "3", ",", "1", ")", ",", "\n", "(", "1024", ",", "1024", ",", "3", ",", "2", ")", ",", "\n", "(", "1024", ",", "1280", ",", "1", ",", "1", ")", ",", "\n", "]", "\n", "feature_info", ".", "append", "(", "dict", "(", "num_chs", "=", "1280", ",", "reduction", "=", "64", ",", "module", "=", "'head.3'", ")", ")", "\n", "cfg", "[", "'num_features'", "]", "=", "1280", "\n", "\n", "", "", "elif", "variant", "==", "'selecsls84'", ":", "\n", "        ", "cfg", "[", "'block'", "]", "=", "SelecSLSBlock", "\n", "# Define configuration of the network after the initial neck", "\n", "cfg", "[", "'features'", "]", "=", "[", "\n", "# in_chs, skip_chs, mid_chs, out_chs, is_first, stride", "\n", "(", "32", ",", "0", ",", "64", ",", "64", ",", "True", ",", "2", ")", ",", "\n", "(", "64", ",", "64", ",", "64", ",", "144", ",", "False", ",", "1", ")", ",", "\n", "(", "144", ",", "0", ",", "144", ",", "144", ",", "True", ",", "2", ")", ",", "\n", "(", "144", ",", "144", ",", "144", ",", "144", ",", "False", ",", "1", ")", ",", "\n", "(", "144", ",", "144", ",", "144", ",", "144", ",", "False", ",", "1", ")", ",", "\n", "(", "144", ",", "144", ",", "144", ",", "144", ",", "False", ",", "1", ")", ",", "\n", "(", "144", ",", "144", ",", "144", ",", "304", ",", "False", ",", "1", ")", ",", "\n", "(", "304", ",", "0", ",", "304", ",", "304", ",", "True", ",", "2", ")", ",", "\n", "(", "304", ",", "304", ",", "304", ",", "304", ",", "False", ",", "1", ")", ",", "\n", "(", "304", ",", "304", ",", "304", ",", "304", ",", "False", ",", "1", ")", ",", "\n", "(", "304", ",", "304", ",", "304", ",", "304", ",", "False", ",", "1", ")", ",", "\n", "(", "304", ",", "304", ",", "304", ",", "304", ",", "False", ",", "1", ")", ",", "\n", "(", "304", ",", "304", ",", "304", ",", "512", ",", "False", ",", "1", ")", ",", "\n", "]", "\n", "feature_info", ".", "extend", "(", "[", "\n", "dict", "(", "num_chs", "=", "144", ",", "reduction", "=", "4", ",", "module", "=", "'features.1'", ")", ",", "\n", "dict", "(", "num_chs", "=", "304", ",", "reduction", "=", "8", ",", "module", "=", "'features.6'", ")", ",", "\n", "dict", "(", "num_chs", "=", "512", ",", "reduction", "=", "16", ",", "module", "=", "'features.12'", ")", ",", "\n", "]", ")", "\n", "# Head can be replaced with alternative configurations depending on the problem", "\n", "cfg", "[", "'head'", "]", "=", "[", "\n", "(", "512", ",", "960", ",", "3", ",", "2", ")", ",", "\n", "(", "960", ",", "1024", ",", "3", ",", "1", ")", ",", "\n", "(", "1024", ",", "1024", ",", "3", ",", "2", ")", ",", "\n", "(", "1024", ",", "1280", ",", "3", ",", "1", ")", ",", "\n", "]", "\n", "cfg", "[", "'num_features'", "]", "=", "1280", "\n", "feature_info", ".", "extend", "(", "[", "\n", "dict", "(", "num_chs", "=", "1024", ",", "reduction", "=", "32", ",", "module", "=", "'head.1'", ")", ",", "\n", "dict", "(", "num_chs", "=", "1280", ",", "reduction", "=", "64", ",", "module", "=", "'head.3'", ")", "\n", "]", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid net configuration '", "+", "variant", "+", "' !!!'", ")", "\n", "", "cfg", "[", "'feature_info'", "]", "=", "feature_info", "\n", "\n", "# this model can do 6 feature levels by default, unlike most others, leave as 0-4 to avoid surprises?", "\n", "return", "build_model_with_cfg", "(", "\n", "SelecSLS", ",", "variant", ",", "pretrained", ",", "\n", "model_cfg", "=", "cfg", ",", "\n", "feature_cfg", "=", "dict", "(", "out_indices", "=", "(", "0", ",", "1", ",", "2", ",", "3", ",", "4", ")", ",", "flatten_sequential", "=", "True", ")", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.selecsls42": [[345, 350], ["selecsls._create_selecsls"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls._create_selecsls"], ["", "@", "register_model", "\n", "def", "selecsls42", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a SelecSLS42 model.\n    \"\"\"", "\n", "return", "_create_selecsls", "(", "'selecsls42'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.selecsls42b": [[352, 357], ["selecsls._create_selecsls"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls._create_selecsls"], ["", "@", "register_model", "\n", "def", "selecsls42b", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a SelecSLS42_B model.\n    \"\"\"", "\n", "return", "_create_selecsls", "(", "'selecsls42b'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.selecsls60": [[359, 364], ["selecsls._create_selecsls"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls._create_selecsls"], ["", "@", "register_model", "\n", "def", "selecsls60", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a SelecSLS60 model.\n    \"\"\"", "\n", "return", "_create_selecsls", "(", "'selecsls60'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.selecsls60b": [[366, 371], ["selecsls._create_selecsls"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls._create_selecsls"], ["", "@", "register_model", "\n", "def", "selecsls60b", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a SelecSLS60_B model.\n    \"\"\"", "\n", "return", "_create_selecsls", "(", "'selecsls60b'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls.selecsls84": [[373, 378], ["selecsls._create_selecsls"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.selecsls._create_selecsls"], ["", "@", "register_model", "\n", "def", "selecsls84", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a SelecSLS84 model.\n    \"\"\"", "\n", "return", "_create_selecsls", "(", "'selecsls84'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer.Residual.__init__": [[32, 35], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "fn", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fn", "=", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer.Residual.forward": [[36, 38], ["convmixer.Residual.fn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "fn", "(", "x", ")", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer.ConvMixer.__init__": [[41, 68], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.SelectAdaptivePool2d", "torch.Conv2d", "torch.Conv2d", "act_layer", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Sequential", "torch.Sequential", "convmixer.Residual", "torch.Conv2d", "torch.Conv2d", "act_layer", "torch.BatchNorm2d", "torch.BatchNorm2d", "range", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "act_layer", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dim", ",", "depth", ",", "kernel_size", "=", "9", ",", "patch_size", "=", "7", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "global_pool", "=", "'avg'", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_features", "=", "dim", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "self", ".", "stem", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_chans", ",", "dim", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "patch_size", ")", ",", "\n", "act_layer", "(", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "dim", ")", "\n", ")", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "nn", ".", "Sequential", "(", "\n", "Residual", "(", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", ",", "groups", "=", "dim", ",", "padding", "=", "\"same\"", ")", ",", "\n", "act_layer", "(", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "dim", ")", "\n", ")", ")", ",", "\n", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "1", ")", ",", "\n", "act_layer", "(", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "dim", ")", "\n", ")", "for", "i", "in", "range", "(", "depth", ")", "]", "\n", ")", "\n", "self", ".", "pooling", "=", "SelectAdaptivePool2d", "(", "pool_type", "=", "global_pool", ",", "flatten", "=", "True", ")", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer.ConvMixer.group_matcher": [[69, 73], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "stem", "=", "r'^stem'", ",", "blocks", "=", "r'^blocks\\.(\\d+)'", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer.ConvMixer.set_grad_checkpointing": [[74, 77], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer.ConvMixer.get_classifier": [[78, 81], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer.ConvMixer.reset_classifier": [[82, 87], ["layers.SelectAdaptivePool2d", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "None", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "if", "global_pool", "is", "not", "None", ":", "\n", "            ", "self", ".", "pooling", "=", "SelectAdaptivePool2d", "(", "pool_type", "=", "global_pool", ",", "flatten", "=", "True", ")", "\n", "", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer.ConvMixer.forward_features": [[88, 95], ["convmixer.ConvMixer.stem", "helpers.checkpoint_seq", "convmixer.ConvMixer.blocks", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "blocks", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "blocks", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer.ConvMixer.forward_head": [[96, 99], ["convmixer.ConvMixer.pooling", "convmixer.ConvMixer.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "pooling", "(", "x", ")", "\n", "return", "x", "if", "pre_logits", "else", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer.ConvMixer.forward": [[100, 104], ["convmixer.ConvMixer.forward_features", "convmixer.ConvMixer.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer._cfg": [[13, 21], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", ".96", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "'classifier'", ":", "'head'", ",", "\n", "'first_conv'", ":", "'stem.0'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer._create_convmixer": [[106, 108], ["helpers.build_model_with_cfg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_convmixer", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "ConvMixer", ",", "variant", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer.convmixer_1536_20": [[110, 114], ["dict", "convmixer._create_convmixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer._create_convmixer"], ["", "@", "register_model", "\n", "def", "convmixer_1536_20", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "dim", "=", "1536", ",", "depth", "=", "20", ",", "kernel_size", "=", "9", ",", "patch_size", "=", "7", ",", "**", "kwargs", ")", "\n", "return", "_create_convmixer", "(", "'convmixer_1536_20'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer.convmixer_768_32": [[116, 120], ["dict", "convmixer._create_convmixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer._create_convmixer"], ["", "@", "register_model", "\n", "def", "convmixer_768_32", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "dim", "=", "768", ",", "depth", "=", "32", ",", "kernel_size", "=", "7", ",", "patch_size", "=", "7", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "**", "kwargs", ")", "\n", "return", "_create_convmixer", "(", "'convmixer_768_32'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer.convmixer_1024_20_ks9_p14": [[122, 126], ["dict", "convmixer._create_convmixer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.convmixer._create_convmixer"], ["", "@", "register_model", "\n", "def", "convmixer_1024_20_ks9_p14", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "dim", "=", "1024", ",", "depth", "=", "20", ",", "kernel_size", "=", "9", ",", "patch_size", "=", "14", ",", "**", "kwargs", ")", "\n", "return", "_create_convmixer", "(", "'convmixer_1024_20_ks9_p14'", ",", "pretrained", ",", "**", "model_args", ")", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.ResBottleneck.__init__": [[160, 177], ["torch.Module.__init__", "int", "dict", "layers.ConvNormAct", "layers.ConvNormActAa", "layers.ConvNormAct", "act_layer", "round", "layers.create_attn", "layers.create_attn"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.create_attn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.create_attn"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "dilation", "=", "1", ",", "bottle_ratio", "=", "0.25", ",", "groups", "=", "1", ",", "\n", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "attn_last", "=", "False", ",", "\n", "attn_layer", "=", "None", ",", "aa_layer", "=", "None", ",", "drop_block", "=", "None", ",", "drop_path", "=", "None", ")", ":", "\n", "        ", "super", "(", "ResBottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "mid_chs", "=", "int", "(", "round", "(", "out_chs", "*", "bottle_ratio", ")", ")", "\n", "ckwargs", "=", "dict", "(", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ")", "\n", "\n", "self", ".", "conv1", "=", "ConvNormAct", "(", "in_chs", ",", "mid_chs", ",", "kernel_size", "=", "1", ",", "**", "ckwargs", ")", "\n", "self", ".", "conv2", "=", "ConvNormActAa", "(", "\n", "mid_chs", ",", "mid_chs", ",", "kernel_size", "=", "3", ",", "dilation", "=", "dilation", ",", "groups", "=", "groups", ",", "\n", "aa_layer", "=", "aa_layer", ",", "drop_layer", "=", "drop_block", ",", "**", "ckwargs", ")", "\n", "self", ".", "attn2", "=", "create_attn", "(", "attn_layer", ",", "channels", "=", "mid_chs", ")", "if", "not", "attn_last", "else", "None", "\n", "self", ".", "conv3", "=", "ConvNormAct", "(", "mid_chs", ",", "out_chs", ",", "kernel_size", "=", "1", ",", "apply_act", "=", "False", ",", "**", "ckwargs", ")", "\n", "self", ".", "attn3", "=", "create_attn", "(", "attn_layer", ",", "channels", "=", "out_chs", ")", "if", "attn_last", "else", "None", "\n", "self", ".", "drop_path", "=", "drop_path", "\n", "self", ".", "act3", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.ResBottleneck.zero_init_last": [[178, 180], ["torch.init.zeros_", "torch.init.zeros_"], "methods", ["None"], ["", "def", "zero_init_last", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "conv3", ".", "bn", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.ResBottleneck.forward": [[181, 197], ["cspnet.ResBottleneck.conv1", "cspnet.ResBottleneck.conv2", "cspnet.ResBottleneck.conv3", "cspnet.ResBottleneck.act3", "cspnet.ResBottleneck.attn2", "cspnet.ResBottleneck.attn3", "cspnet.ResBottleneck.drop_path"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "if", "self", ".", "attn2", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "attn2", "(", "x", ")", "\n", "", "x", "=", "self", ".", "conv3", "(", "x", ")", "\n", "if", "self", ".", "attn3", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "attn3", "(", "x", ")", "\n", "", "if", "self", ".", "drop_path", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "drop_path", "(", "x", ")", "\n", "", "x", "=", "x", "+", "shortcut", "\n", "# FIXME partial shortcut needed if first block handled as per original, not used for my current impl", "\n", "#x[:, :shortcut.size(1)] += shortcut", "\n", "x", "=", "self", ".", "act3", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.DarkBlock.__init__": [[203, 216], ["torch.Module.__init__", "int", "dict", "layers.ConvNormAct", "layers.ConvNormActAa", "layers.create_attn", "round"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.create_attn"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "dilation", "=", "1", ",", "bottle_ratio", "=", "0.5", ",", "groups", "=", "1", ",", "\n", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "attn_layer", "=", "None", ",", "aa_layer", "=", "None", ",", "\n", "drop_block", "=", "None", ",", "drop_path", "=", "None", ")", ":", "\n", "        ", "super", "(", "DarkBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "mid_chs", "=", "int", "(", "round", "(", "out_chs", "*", "bottle_ratio", ")", ")", "\n", "ckwargs", "=", "dict", "(", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "conv1", "=", "ConvNormAct", "(", "in_chs", ",", "mid_chs", ",", "kernel_size", "=", "1", ",", "**", "ckwargs", ")", "\n", "self", ".", "conv2", "=", "ConvNormActAa", "(", "\n", "mid_chs", ",", "out_chs", ",", "kernel_size", "=", "3", ",", "dilation", "=", "dilation", ",", "groups", "=", "groups", ",", "\n", "aa_layer", "=", "aa_layer", ",", "drop_layer", "=", "drop_block", ",", "**", "ckwargs", ")", "\n", "self", ".", "attn", "=", "create_attn", "(", "attn_layer", ",", "channels", "=", "out_chs", ")", "\n", "self", ".", "drop_path", "=", "drop_path", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.DarkBlock.zero_init_last": [[217, 219], ["torch.init.zeros_", "torch.init.zeros_"], "methods", ["None"], ["", "def", "zero_init_last", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "conv2", ".", "bn", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.DarkBlock.forward": [[220, 230], ["cspnet.DarkBlock.conv1", "cspnet.DarkBlock.conv2", "cspnet.DarkBlock.attn", "cspnet.DarkBlock.drop_path"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "if", "self", ".", "attn", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "attn", "(", "x", ")", "\n", "", "if", "self", ".", "drop_path", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "drop_path", "(", "x", ")", "\n", "", "x", "=", "x", "+", "shortcut", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.CrossStage.__init__": [[234, 270], ["torch.Module.__init__", "int", "int", "dict", "layers.ConvNormAct", "torch.Sequential", "torch.Sequential", "range", "layers.ConvNormAct", "layers.ConvNormAct", "round", "round", "layers.ConvNormActAa", "cspnet.CrossStage.blocks.add_module", "block_kwargs.get", "block_kwargs.get", "layers.DropPath", "str", "block_fn", "block_kwargs.get"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "stride", ",", "dilation", ",", "depth", ",", "block_ratio", "=", "1.", ",", "bottle_ratio", "=", "1.", ",", "exp_ratio", "=", "1.", ",", "\n", "groups", "=", "1", ",", "first_dilation", "=", "None", ",", "down_growth", "=", "False", ",", "cross_linear", "=", "False", ",", "block_dpr", "=", "None", ",", "\n", "block_fn", "=", "ResBottleneck", ",", "**", "block_kwargs", ")", ":", "\n", "        ", "super", "(", "CrossStage", ",", "self", ")", ".", "__init__", "(", ")", "\n", "first_dilation", "=", "first_dilation", "or", "dilation", "\n", "down_chs", "=", "out_chs", "if", "down_growth", "else", "in_chs", "# grow downsample channels to output channels", "\n", "exp_chs", "=", "int", "(", "round", "(", "out_chs", "*", "exp_ratio", ")", ")", "\n", "block_out_chs", "=", "int", "(", "round", "(", "out_chs", "*", "block_ratio", ")", ")", "\n", "conv_kwargs", "=", "dict", "(", "act_layer", "=", "block_kwargs", ".", "get", "(", "'act_layer'", ")", ",", "norm_layer", "=", "block_kwargs", ".", "get", "(", "'norm_layer'", ")", ")", "\n", "\n", "if", "stride", "!=", "1", "or", "first_dilation", "!=", "dilation", ":", "\n", "            ", "self", ".", "conv_down", "=", "ConvNormActAa", "(", "\n", "in_chs", ",", "down_chs", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "dilation", "=", "first_dilation", ",", "groups", "=", "groups", ",", "\n", "aa_layer", "=", "block_kwargs", ".", "get", "(", "'aa_layer'", ",", "None", ")", ",", "**", "conv_kwargs", ")", "\n", "prev_chs", "=", "down_chs", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv_down", "=", "None", "\n", "prev_chs", "=", "in_chs", "\n", "\n", "# FIXME this 1x1 expansion is pushed down into the cross and block paths in the darknet cfgs. Also,", "\n", "# there is also special case for the first stage for some of the model that results in uneven split", "\n", "# across the two paths. I did it this way for simplicity for now.", "\n", "", "self", ".", "conv_exp", "=", "ConvNormAct", "(", "prev_chs", ",", "exp_chs", ",", "kernel_size", "=", "1", ",", "apply_act", "=", "not", "cross_linear", ",", "**", "conv_kwargs", ")", "\n", "prev_chs", "=", "exp_chs", "//", "2", "# output of conv_exp is always split in two", "\n", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", ")", "\n", "for", "i", "in", "range", "(", "depth", ")", ":", "\n", "            ", "drop_path", "=", "DropPath", "(", "block_dpr", "[", "i", "]", ")", "if", "block_dpr", "and", "block_dpr", "[", "i", "]", "else", "None", "\n", "self", ".", "blocks", ".", "add_module", "(", "str", "(", "i", ")", ",", "block_fn", "(", "\n", "prev_chs", ",", "block_out_chs", ",", "dilation", ",", "bottle_ratio", ",", "groups", ",", "drop_path", "=", "drop_path", ",", "**", "block_kwargs", ")", ")", "\n", "prev_chs", "=", "block_out_chs", "\n", "\n", "# transition convs", "\n", "", "self", ".", "conv_transition_b", "=", "ConvNormAct", "(", "prev_chs", ",", "exp_chs", "//", "2", ",", "kernel_size", "=", "1", ",", "**", "conv_kwargs", ")", "\n", "self", ".", "conv_transition", "=", "ConvNormAct", "(", "exp_chs", ",", "out_chs", ",", "kernel_size", "=", "1", ",", "**", "conv_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.CrossStage.forward": [[271, 281], ["cspnet.CrossStage.conv_exp", "cspnet.CrossStage.blocks", "cspnet.CrossStage.conv_transition_b().contiguous", "cspnet.CrossStage.conv_transition", "cspnet.CrossStage.conv_down", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "cspnet.CrossStage.conv_transition_b"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "conv_down", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "conv_down", "(", "x", ")", "\n", "", "x", "=", "self", ".", "conv_exp", "(", "x", ")", "\n", "split", "=", "x", ".", "shape", "[", "1", "]", "//", "2", "\n", "xs", ",", "xb", "=", "x", "[", ":", ",", ":", "split", "]", ",", "x", "[", ":", ",", "split", ":", "]", "\n", "xb", "=", "self", ".", "blocks", "(", "xb", ")", "\n", "xb", "=", "self", ".", "conv_transition_b", "(", "xb", ")", ".", "contiguous", "(", ")", "\n", "out", "=", "self", ".", "conv_transition", "(", "torch", ".", "cat", "(", "[", "xs", ",", "xb", "]", ",", "dim", "=", "1", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.DarkStage.__init__": [[286, 305], ["torch.Module.__init__", "layers.ConvNormActAa", "int", "torch.Sequential", "torch.Sequential", "range", "round", "cspnet.DarkStage.blocks.add_module", "block_kwargs.get", "block_kwargs.get", "block_kwargs.get", "layers.DropPath", "str", "block_fn"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "stride", ",", "dilation", ",", "depth", ",", "block_ratio", "=", "1.", ",", "bottle_ratio", "=", "1.", ",", "groups", "=", "1", ",", "\n", "first_dilation", "=", "None", ",", "block_fn", "=", "ResBottleneck", ",", "block_dpr", "=", "None", ",", "**", "block_kwargs", ")", ":", "\n", "        ", "super", "(", "DarkStage", ",", "self", ")", ".", "__init__", "(", ")", "\n", "first_dilation", "=", "first_dilation", "or", "dilation", "\n", "\n", "self", ".", "conv_down", "=", "ConvNormActAa", "(", "\n", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "dilation", "=", "first_dilation", ",", "groups", "=", "groups", ",", "\n", "act_layer", "=", "block_kwargs", ".", "get", "(", "'act_layer'", ")", ",", "norm_layer", "=", "block_kwargs", ".", "get", "(", "'norm_layer'", ")", ",", "\n", "aa_layer", "=", "block_kwargs", ".", "get", "(", "'aa_layer'", ",", "None", ")", ")", "\n", "\n", "prev_chs", "=", "out_chs", "\n", "block_out_chs", "=", "int", "(", "round", "(", "out_chs", "*", "block_ratio", ")", ")", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", ")", "\n", "for", "i", "in", "range", "(", "depth", ")", ":", "\n", "            ", "drop_path", "=", "DropPath", "(", "block_dpr", "[", "i", "]", ")", "if", "block_dpr", "and", "block_dpr", "[", "i", "]", "else", "None", "\n", "self", ".", "blocks", ".", "add_module", "(", "str", "(", "i", ")", ",", "block_fn", "(", "\n", "prev_chs", ",", "block_out_chs", ",", "dilation", ",", "bottle_ratio", ",", "groups", ",", "drop_path", "=", "drop_path", ",", "**", "block_kwargs", ")", ")", "\n", "prev_chs", "=", "block_out_chs", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.DarkStage.forward": [[306, 310], ["cspnet.DarkStage.conv_down", "cspnet.DarkStage.blocks"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv_down", "(", "x", ")", "\n", "x", "=", "self", ".", "blocks", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.CspNet.__init__": [[354, 389], ["torch.Module.__init__", "dict", "cspnet.create_stem", "cspnet._cfg_to_stage_args", "torch.Sequential", "torch.Sequential", "enumerate", "layers.ClassifierHead", "helpers.named_apply", "cspnet.CspNet.stages.add_module", "functools.partial", "str", "stage_fn", "dict"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.create_stem", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet._cfg_to_stage_args", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_apply"], ["def", "__init__", "(", "\n", "self", ",", "cfg", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "output_stride", "=", "32", ",", "global_pool", "=", "'avg'", ",", "drop_rate", "=", "0.", ",", "\n", "act_layer", "=", "nn", ".", "LeakyReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "aa_layer", "=", "None", ",", "drop_path_rate", "=", "0.", ",", "\n", "zero_init_last", "=", "True", ",", "stage_fn", "=", "CrossStage", ",", "block_fn", "=", "ResBottleneck", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "assert", "output_stride", "in", "(", "8", ",", "16", ",", "32", ")", "\n", "layer_args", "=", "dict", "(", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ",", "aa_layer", "=", "aa_layer", ")", "\n", "\n", "# Construct the stem", "\n", "self", ".", "stem", ",", "stem_feat_info", "=", "create_stem", "(", "in_chans", ",", "**", "cfg", "[", "'stem'", "]", ",", "**", "layer_args", ")", "\n", "self", ".", "feature_info", "=", "[", "stem_feat_info", "]", "\n", "prev_chs", "=", "stem_feat_info", "[", "'num_chs'", "]", "\n", "curr_stride", "=", "stem_feat_info", "[", "'reduction'", "]", "# reduction does not include pool", "\n", "if", "cfg", "[", "'stem'", "]", "[", "'pool'", "]", ":", "\n", "            ", "curr_stride", "*=", "2", "\n", "\n", "# Construct the stages", "\n", "", "per_stage_args", "=", "_cfg_to_stage_args", "(", "\n", "cfg", "[", "'stage'", "]", ",", "curr_stride", "=", "curr_stride", ",", "output_stride", "=", "output_stride", ",", "drop_path_rate", "=", "drop_path_rate", ")", "\n", "self", ".", "stages", "=", "nn", ".", "Sequential", "(", ")", "\n", "for", "i", ",", "sa", "in", "enumerate", "(", "per_stage_args", ")", ":", "\n", "            ", "self", ".", "stages", ".", "add_module", "(", "\n", "str", "(", "i", ")", ",", "stage_fn", "(", "prev_chs", ",", "**", "sa", ",", "**", "layer_args", ",", "block_fn", "=", "block_fn", ")", ")", "\n", "prev_chs", "=", "sa", "[", "'out_chs'", "]", "\n", "curr_stride", "*=", "sa", "[", "'stride'", "]", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "prev_chs", ",", "reduction", "=", "curr_stride", ",", "module", "=", "f'stages.{i}'", ")", "]", "\n", "\n", "# Construct the head", "\n", "", "self", ".", "num_features", "=", "prev_chs", "\n", "self", ".", "head", "=", "ClassifierHead", "(", "\n", "in_chs", "=", "prev_chs", ",", "num_classes", "=", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "drop_rate", ")", "\n", "\n", "named_apply", "(", "partial", "(", "_init_weights", ",", "zero_init_last", "=", "zero_init_last", ")", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.CspNet.group_matcher": [[390, 401], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem", "=", "r'^stem'", ",", "\n", "blocks", "=", "r'^stages\\.(\\d+)'", "if", "coarse", "else", "[", "\n", "(", "r'^stages\\.(\\d+)\\.blocks\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^stages\\.(\\d+)\\..*transition'", ",", "MATCH_PREV_GROUP", ")", ",", "# map to last block in stage", "\n", "(", "r'^stages\\.(\\d+)'", ",", "(", "0", ",", ")", ")", ",", "\n", "]", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.CspNet.set_grad_checkpointing": [[402, 405], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "'gradient checkpointing not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.CspNet.get_classifier": [[406, 409], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.CspNet.reset_classifier": [[410, 412], ["layers.ClassifierHead"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "head", "=", "ClassifierHead", "(", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "self", ".", "drop_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.CspNet.forward_features": [[413, 417], ["cspnet.CspNet.stem", "cspnet.CspNet.stages"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.stages"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "x", "=", "self", ".", "stages", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.CspNet.forward_head": [[418, 420], ["cspnet.CspNet.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "head", "(", "x", ",", "pre_logits", "=", "pre_logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.CspNet.forward": [[421, 425], ["cspnet.CspNet.forward_features", "cspnet.CspNet.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet._cfg": [[29, 37], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "256", ",", "256", ")", ",", "'pool_size'", ":", "(", "8", ",", "8", ")", ",", "\n", "'crop_pct'", ":", "0.887", ",", "'interpolation'", ":", "'bilinear'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'stem.conv1.conv'", ",", "'classifier'", ":", "'head.fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.create_stem": [[132, 154], ["torch.Sequential", "len", "enumerate", "isinstance", "nn.Sequential.add_module", "dict", "layers.ConvNormAct", "nn.Sequential.add_module", "nn.Sequential.add_module", "nn.Sequential.add_module", "torch.MaxPool2d", "aa_layer", "torch.MaxPool2d"], "function", ["None"], ["def", "create_stem", "(", "\n", "in_chans", "=", "3", ",", "out_chs", "=", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "pool", "=", "''", ",", "\n", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "aa_layer", "=", "None", ")", ":", "\n", "    ", "stem", "=", "nn", ".", "Sequential", "(", ")", "\n", "if", "not", "isinstance", "(", "out_chs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "        ", "out_chs", "=", "[", "out_chs", "]", "\n", "", "assert", "len", "(", "out_chs", ")", "\n", "in_c", "=", "in_chans", "\n", "for", "i", ",", "out_c", "in", "enumerate", "(", "out_chs", ")", ":", "\n", "        ", "conv_name", "=", "f'conv{i + 1}'", "\n", "stem", ".", "add_module", "(", "conv_name", ",", "ConvNormAct", "(", "\n", "in_c", ",", "out_c", ",", "kernel_size", ",", "stride", "=", "stride", "if", "i", "==", "0", "else", "1", ",", "\n", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ")", ")", "\n", "in_c", "=", "out_c", "\n", "last_conv", "=", "conv_name", "\n", "", "if", "pool", ":", "\n", "        ", "if", "aa_layer", "is", "not", "None", ":", "\n", "            ", "stem", ".", "add_module", "(", "'pool'", ",", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ")", "\n", "stem", ".", "add_module", "(", "'aa'", ",", "aa_layer", "(", "channels", "=", "in_c", ",", "stride", "=", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "stem", ".", "add_module", "(", "'pool'", ",", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ")", "\n", "", "", "return", "stem", ",", "dict", "(", "num_chs", "=", "in_c", ",", "reduction", "=", "stride", ",", "module", "=", "'.'", ".", "join", "(", "[", "'stem'", ",", "last_conv", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet._cfg_to_stage_args": [[312, 342], ["len", "stage_first_dilations.append", "stage_strides.append", "stage_dilations.append", "dict", "isinstance", "isinstance", "x.tolist", "zip", "zip", "torch.linspace().split", "torch.linspace().split", "cfg.keys", "cfg.values", "torch.linspace", "torch.linspace", "sum"], "function", ["None"], ["", "", "def", "_cfg_to_stage_args", "(", "cfg", ",", "curr_stride", "=", "2", ",", "output_stride", "=", "32", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "# get per stage args for stage and containing blocks, calculate strides to meet target output_stride", "\n", "    ", "num_stages", "=", "len", "(", "cfg", "[", "'depth'", "]", ")", "\n", "if", "'groups'", "not", "in", "cfg", ":", "\n", "        ", "cfg", "[", "'groups'", "]", "=", "(", "1", ",", ")", "*", "num_stages", "\n", "", "if", "'down_growth'", "in", "cfg", "and", "not", "isinstance", "(", "cfg", "[", "'down_growth'", "]", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "cfg", "[", "'down_growth'", "]", "=", "(", "cfg", "[", "'down_growth'", "]", ",", ")", "*", "num_stages", "\n", "", "if", "'cross_linear'", "in", "cfg", "and", "not", "isinstance", "(", "cfg", "[", "'cross_linear'", "]", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "cfg", "[", "'cross_linear'", "]", "=", "(", "cfg", "[", "'cross_linear'", "]", ",", ")", "*", "num_stages", "\n", "", "cfg", "[", "'block_dpr'", "]", "=", "[", "None", "]", "*", "num_stages", "if", "not", "drop_path_rate", "else", "[", "x", ".", "tolist", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "sum", "(", "cfg", "[", "'depth'", "]", ")", ")", ".", "split", "(", "cfg", "[", "'depth'", "]", ")", "]", "\n", "stage_strides", "=", "[", "]", "\n", "stage_dilations", "=", "[", "]", "\n", "stage_first_dilations", "=", "[", "]", "\n", "dilation", "=", "1", "\n", "for", "cfg_stride", "in", "cfg", "[", "'stride'", "]", ":", "\n", "        ", "stage_first_dilations", ".", "append", "(", "dilation", ")", "\n", "if", "curr_stride", ">=", "output_stride", ":", "\n", "            ", "dilation", "*=", "cfg_stride", "\n", "stride", "=", "1", "\n", "", "else", ":", "\n", "            ", "stride", "=", "cfg_stride", "\n", "curr_stride", "*=", "stride", "\n", "", "stage_strides", ".", "append", "(", "stride", ")", "\n", "stage_dilations", ".", "append", "(", "dilation", ")", "\n", "", "cfg", "[", "'stride'", "]", "=", "stage_strides", "\n", "cfg", "[", "'dilation'", "]", "=", "stage_dilations", "\n", "cfg", "[", "'first_dilation'", "]", "=", "stage_first_dilations", "\n", "stage_args", "=", "[", "dict", "(", "zip", "(", "cfg", ".", "keys", "(", ")", ",", "values", ")", ")", "for", "values", "in", "zip", "(", "*", "cfg", ".", "values", "(", ")", ")", "]", "\n", "return", "stage_args", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet._init_weights": [[427, 438], ["isinstance", "torch.init.kaiming_normal_", "isinstance", "torch.init.ones_", "torch.init.zeros_", "isinstance", "torch.init.normal_", "torch.init.zeros_", "hasattr", "module.zero_init_last"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet.SelectiveKernelBottleneck.zero_init_last"], ["", "", "def", "_init_weights", "(", "module", ",", "name", ",", "zero_init_last", "=", "False", ")", ":", "\n", "    ", "if", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", ":", "\n", "        ", "nn", ".", "init", ".", "kaiming_normal_", "(", "module", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "nn", ".", "init", ".", "ones_", "(", "module", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "module", ".", "weight", ",", "mean", "=", "0.0", ",", "std", "=", "0.01", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "", "elif", "zero_init_last", "and", "hasattr", "(", "module", ",", "'zero_init_last'", ")", ":", "\n", "        ", "module", ".", "zero_init_last", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet._create_cspnet": [[440, 449], ["kwargs.pop", "helpers.build_model_with_cfg", "variant.split", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_cspnet", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "cfg_variant", "=", "variant", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "# NOTE: DarkNet is one of few models with stride==1 features w/ 6 out_indices [0..5]", "\n", "out_indices", "=", "kwargs", ".", "pop", "(", "'out_indices'", ",", "(", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", ")", "if", "'darknet'", "in", "variant", "else", "(", "0", ",", "1", ",", "2", ",", "3", ",", "4", ")", ")", "\n", "return", "build_model_with_cfg", "(", "\n", "CspNet", ",", "variant", ",", "pretrained", ",", "\n", "model_cfg", "=", "model_cfgs", "[", "cfg_variant", "]", ",", "\n", "feature_cfg", "=", "dict", "(", "flatten_sequential", "=", "True", ",", "out_indices", "=", "out_indices", ")", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.cspresnet50": [[451, 454], ["cspnet._create_cspnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet._create_cspnet"], ["", "@", "register_model", "\n", "def", "cspresnet50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_cspnet", "(", "'cspresnet50'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.cspresnet50d": [[456, 459], ["cspnet._create_cspnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet._create_cspnet"], ["", "@", "register_model", "\n", "def", "cspresnet50d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_cspnet", "(", "'cspresnet50d'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.cspresnet50w": [[461, 464], ["cspnet._create_cspnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet._create_cspnet"], ["", "@", "register_model", "\n", "def", "cspresnet50w", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_cspnet", "(", "'cspresnet50w'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.cspresnext50": [[466, 469], ["cspnet._create_cspnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet._create_cspnet"], ["", "@", "register_model", "\n", "def", "cspresnext50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_cspnet", "(", "'cspresnext50'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.cspresnext50_iabn": [[471, 475], ["layers.get_norm_act_layer", "cspnet._create_cspnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet._create_cspnet"], ["", "@", "register_model", "\n", "def", "cspresnext50_iabn", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "norm_layer", "=", "get_norm_act_layer", "(", "'iabn'", ",", "act_layer", "=", "'leaky_relu'", ")", "\n", "return", "_create_cspnet", "(", "'cspresnext50_iabn'", ",", "pretrained", "=", "pretrained", ",", "norm_layer", "=", "norm_layer", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.cspdarknet53": [[477, 480], ["cspnet._create_cspnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet._create_cspnet"], ["", "@", "register_model", "\n", "def", "cspdarknet53", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_cspnet", "(", "'cspdarknet53'", ",", "pretrained", "=", "pretrained", ",", "block_fn", "=", "DarkBlock", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.cspdarknet53_iabn": [[482, 486], ["layers.get_norm_act_layer", "cspnet._create_cspnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet._create_cspnet"], ["", "@", "register_model", "\n", "def", "cspdarknet53_iabn", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "norm_layer", "=", "get_norm_act_layer", "(", "'iabn'", ",", "act_layer", "=", "'leaky_relu'", ")", "\n", "return", "_create_cspnet", "(", "'cspdarknet53_iabn'", ",", "pretrained", "=", "pretrained", ",", "block_fn", "=", "DarkBlock", ",", "norm_layer", "=", "norm_layer", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet.darknet53": [[488, 491], ["cspnet._create_cspnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.cspnet._create_cspnet"], ["", "@", "register_model", "\n", "def", "darknet53", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_cspnet", "(", "'darknet53'", ",", "pretrained", "=", "pretrained", ",", "block_fn", "=", "DarkBlock", ",", "stage_fn", "=", "DarkStage", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.SequentialAppendList.__init__": [[166, 168], ["torch.Sequential.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "super", "(", "SequentialAppendList", ",", "self", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.SequentialAppendList.forward": [[169, 177], ["enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "concat_list.append", "concat_list.append", "module", "module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "concat_list", ":", "List", "[", "torch", ".", "Tensor", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "for", "i", ",", "module", "in", "enumerate", "(", "self", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "concat_list", ".", "append", "(", "module", "(", "x", ")", ")", "\n", "", "else", ":", "\n", "                ", "concat_list", ".", "append", "(", "module", "(", "concat_list", "[", "-", "1", "]", ")", ")", "\n", "", "", "x", "=", "torch", ".", "cat", "(", "concat_list", ",", "dim", "=", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.OsaBlock.__init__": [[181, 214], ["torch.Module.__init__", "dict", "range", "vovnet.SequentialAppendList", "layers.ConvNormAct", "layers.ConvNormAct", "mid_convs.append", "layers.create_attn", "layers.SeparableConvNormAct", "layers.ConvNormAct"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.create_attn"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "mid_chs", ",", "out_chs", ",", "layer_per_block", ",", "residual", "=", "False", ",", "\n", "depthwise", "=", "False", ",", "attn", "=", "''", ",", "norm_layer", "=", "BatchNormAct2d", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "drop_path", "=", "None", ")", ":", "\n", "        ", "super", "(", "OsaBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "residual", "=", "residual", "\n", "self", ".", "depthwise", "=", "depthwise", "\n", "conv_kwargs", "=", "dict", "(", "norm_layer", "=", "norm_layer", ",", "act_layer", "=", "act_layer", ")", "\n", "\n", "next_in_chs", "=", "in_chs", "\n", "if", "self", ".", "depthwise", "and", "next_in_chs", "!=", "mid_chs", ":", "\n", "            ", "assert", "not", "residual", "\n", "self", ".", "conv_reduction", "=", "ConvNormAct", "(", "next_in_chs", ",", "mid_chs", ",", "1", ",", "**", "conv_kwargs", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv_reduction", "=", "None", "\n", "\n", "", "mid_convs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "layer_per_block", ")", ":", "\n", "            ", "if", "self", ".", "depthwise", ":", "\n", "                ", "conv", "=", "SeparableConvNormAct", "(", "mid_chs", ",", "mid_chs", ",", "**", "conv_kwargs", ")", "\n", "", "else", ":", "\n", "                ", "conv", "=", "ConvNormAct", "(", "next_in_chs", ",", "mid_chs", ",", "3", ",", "**", "conv_kwargs", ")", "\n", "", "next_in_chs", "=", "mid_chs", "\n", "mid_convs", ".", "append", "(", "conv", ")", "\n", "", "self", ".", "conv_mid", "=", "SequentialAppendList", "(", "*", "mid_convs", ")", "\n", "\n", "# feature aggregation", "\n", "next_in_chs", "=", "in_chs", "+", "layer_per_block", "*", "mid_chs", "\n", "self", ".", "conv_concat", "=", "ConvNormAct", "(", "next_in_chs", ",", "out_chs", ",", "**", "conv_kwargs", ")", "\n", "\n", "self", ".", "attn", "=", "create_attn", "(", "attn", ",", "out_chs", ")", "if", "attn", "else", "None", "\n", "\n", "self", ".", "drop_path", "=", "drop_path", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.OsaBlock.forward": [[215, 228], ["vovnet.OsaBlock.conv_mid", "vovnet.OsaBlock.conv_concat", "vovnet.OsaBlock.conv_reduction", "vovnet.OsaBlock.attn", "vovnet.OsaBlock.drop_path"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output", "=", "[", "x", "]", "\n", "if", "self", ".", "conv_reduction", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "conv_reduction", "(", "x", ")", "\n", "", "x", "=", "self", ".", "conv_mid", "(", "x", ",", "output", ")", "\n", "x", "=", "self", ".", "conv_concat", "(", "x", ")", "\n", "if", "self", ".", "attn", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "attn", "(", "x", ")", "\n", "", "if", "self", ".", "drop_path", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "drop_path", "(", "x", ")", "\n", "", "if", "self", ".", "residual", ":", "\n", "            ", "x", "=", "x", "+", "output", "[", "0", "]", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.OsaStage.__init__": [[232, 257], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "layers.DropPath", "vovnet.OsaBlock"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "mid_chs", ",", "out_chs", ",", "block_per_stage", ",", "layer_per_block", ",", "downsample", "=", "True", ",", "\n", "residual", "=", "True", ",", "depthwise", "=", "False", ",", "attn", "=", "'ese'", ",", "norm_layer", "=", "BatchNormAct2d", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "\n", "drop_path_rates", "=", "None", ")", ":", "\n", "        ", "super", "(", "OsaStage", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "if", "downsample", ":", "\n", "            ", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "ceil_mode", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "pool", "=", "None", "\n", "\n", "", "blocks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "block_per_stage", ")", ":", "\n", "            ", "last_block", "=", "i", "==", "block_per_stage", "-", "1", "\n", "if", "drop_path_rates", "is", "not", "None", "and", "drop_path_rates", "[", "i", "]", ">", "0.", ":", "\n", "                ", "drop_path", "=", "DropPath", "(", "drop_path_rates", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "drop_path", "=", "None", "\n", "", "blocks", "+=", "[", "OsaBlock", "(", "\n", "in_chs", ",", "mid_chs", ",", "out_chs", ",", "layer_per_block", ",", "residual", "=", "residual", "and", "i", ">", "0", ",", "depthwise", "=", "depthwise", ",", "\n", "attn", "=", "attn", "if", "last_block", "else", "''", ",", "norm_layer", "=", "norm_layer", ",", "act_layer", "=", "act_layer", ",", "drop_path", "=", "drop_path", ")", "\n", "]", "\n", "in_chs", "=", "out_chs", "\n", "", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "*", "blocks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.OsaStage.forward": [[258, 266], ["vovnet.OsaStage.pool", "helpers.checkpoint_seq", "vovnet.OsaStage.blocks", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "pool", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "blocks", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "blocks", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.VovNet.__init__": [[270, 324], ["torch.Module.__init__", "dict", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "dict", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.ClassifierHead", "vovnet.VovNet.named_modules", "dict", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "isinstance", "sum", "vovnet.OsaStage", "dict", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "layers.ConvNormAct", "conv_type", "conv_type", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules"], ["    ", "def", "__init__", "(", "\n", "self", ",", "cfg", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "global_pool", "=", "'avg'", ",", "drop_rate", "=", "0.", ",", "stem_stride", "=", "4", ",", "\n", "output_stride", "=", "32", ",", "norm_layer", "=", "BatchNormAct2d", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "\"\"\" VovNet (v2)\n        \"\"\"", "\n", "super", "(", "VovNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "assert", "stem_stride", "in", "(", "4", ",", "2", ")", "\n", "assert", "output_stride", "==", "32", "# FIXME support dilation", "\n", "\n", "stem_chs", "=", "cfg", "[", "\"stem_chs\"", "]", "\n", "stage_conv_chs", "=", "cfg", "[", "\"stage_conv_chs\"", "]", "\n", "stage_out_chs", "=", "cfg", "[", "\"stage_out_chs\"", "]", "\n", "block_per_stage", "=", "cfg", "[", "\"block_per_stage\"", "]", "\n", "layer_per_block", "=", "cfg", "[", "\"layer_per_block\"", "]", "\n", "conv_kwargs", "=", "dict", "(", "norm_layer", "=", "norm_layer", ",", "act_layer", "=", "act_layer", ")", "\n", "\n", "# Stem module", "\n", "last_stem_stride", "=", "stem_stride", "//", "2", "\n", "conv_type", "=", "SeparableConvNormAct", "if", "cfg", "[", "\"depthwise\"", "]", "else", "ConvNormAct", "\n", "self", ".", "stem", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "ConvNormAct", "(", "in_chans", ",", "stem_chs", "[", "0", "]", ",", "3", ",", "stride", "=", "2", ",", "**", "conv_kwargs", ")", ",", "\n", "conv_type", "(", "stem_chs", "[", "0", "]", ",", "stem_chs", "[", "1", "]", ",", "3", ",", "stride", "=", "1", ",", "**", "conv_kwargs", ")", ",", "\n", "conv_type", "(", "stem_chs", "[", "1", "]", ",", "stem_chs", "[", "2", "]", ",", "3", ",", "stride", "=", "last_stem_stride", ",", "**", "conv_kwargs", ")", ",", "\n", "]", ")", "\n", "self", ".", "feature_info", "=", "[", "dict", "(", "\n", "num_chs", "=", "stem_chs", "[", "1", "]", ",", "reduction", "=", "2", ",", "module", "=", "f'stem.{1 if stem_stride == 4 else 2}'", ")", "]", "\n", "current_stride", "=", "stem_stride", "\n", "\n", "# OSA stages", "\n", "stage_dpr", "=", "torch", ".", "split", "(", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "sum", "(", "block_per_stage", ")", ")", ",", "block_per_stage", ")", "\n", "in_ch_list", "=", "stem_chs", "[", "-", "1", ":", "]", "+", "stage_out_chs", "[", ":", "-", "1", "]", "\n", "stage_args", "=", "dict", "(", "residual", "=", "cfg", "[", "\"residual\"", "]", ",", "depthwise", "=", "cfg", "[", "\"depthwise\"", "]", ",", "attn", "=", "cfg", "[", "\"attn\"", "]", ",", "**", "conv_kwargs", ")", "\n", "stages", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "# num_stages", "\n", "            ", "downsample", "=", "stem_stride", "==", "2", "or", "i", ">", "0", "# first stage has no stride/downsample if stem_stride is 4", "\n", "stages", "+=", "[", "OsaStage", "(", "\n", "in_ch_list", "[", "i", "]", ",", "stage_conv_chs", "[", "i", "]", ",", "stage_out_chs", "[", "i", "]", ",", "block_per_stage", "[", "i", "]", ",", "layer_per_block", ",", "\n", "downsample", "=", "downsample", ",", "drop_path_rates", "=", "stage_dpr", "[", "i", "]", ",", "**", "stage_args", ")", "\n", "]", "\n", "self", ".", "num_features", "=", "stage_out_chs", "[", "i", "]", "\n", "current_stride", "*=", "2", "if", "downsample", "else", "1", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "self", ".", "num_features", ",", "reduction", "=", "current_stride", ",", "module", "=", "f'stages.{i}'", ")", "]", "\n", "\n", "", "self", ".", "stages", "=", "nn", ".", "Sequential", "(", "*", "stages", ")", "\n", "\n", "self", ".", "head", "=", "ClassifierHead", "(", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "drop_rate", ")", "\n", "\n", "for", "n", ",", "m", "in", "self", ".", "named_modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.VovNet.group_matcher": [[326, 331], ["dict"], "methods", ["None"], ["", "", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^stem'", ",", "\n", "blocks", "=", "r'^stages\\.(\\d+)'", "if", "coarse", "else", "r'^stages\\.(\\d+).blocks\\.(\\d+)'", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.VovNet.set_grad_checkpointing": [[333, 337], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "for", "s", "in", "self", ".", "stages", ":", "\n", "            ", "s", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.VovNet.get_classifier": [[338, 341], ["None"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.VovNet.reset_classifier": [[342, 344], ["layers.ClassifierHead"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "head", "=", "ClassifierHead", "(", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "self", ".", "drop_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.VovNet.forward_features": [[345, 348], ["vovnet.VovNet.stem", "vovnet.VovNet.stages"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.stages"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "return", "self", ".", "stages", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.VovNet.forward_head": [[349, 351], ["vovnet.VovNet.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "head", "(", "x", ",", "pre_logits", "=", "pre_logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.VovNet.forward": [[352, 356], ["vovnet.VovNet.forward_features", "vovnet.VovNet.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet._cfg": [[139, 145], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'stem.0.conv'", ",", "'classifier'", ":", "'head.fc'", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet._create_vovnet": [[358, 364], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_vovnet", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "\n", "VovNet", ",", "variant", ",", "pretrained", ",", "\n", "model_cfg", "=", "model_cfgs", "[", "variant", "]", ",", "\n", "feature_cfg", "=", "dict", "(", "flatten_sequential", "=", "True", ")", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.vovnet39a": [[366, 369], ["vovnet._create_vovnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet._create_vovnet"], ["", "@", "register_model", "\n", "def", "vovnet39a", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_vovnet", "(", "'vovnet39a'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.vovnet57a": [[371, 374], ["vovnet._create_vovnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet._create_vovnet"], ["", "@", "register_model", "\n", "def", "vovnet57a", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_vovnet", "(", "'vovnet57a'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.ese_vovnet19b_slim_dw": [[376, 379], ["vovnet._create_vovnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet._create_vovnet"], ["", "@", "register_model", "\n", "def", "ese_vovnet19b_slim_dw", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_vovnet", "(", "'ese_vovnet19b_slim_dw'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.ese_vovnet19b_dw": [[381, 384], ["vovnet._create_vovnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet._create_vovnet"], ["", "@", "register_model", "\n", "def", "ese_vovnet19b_dw", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_vovnet", "(", "'ese_vovnet19b_dw'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.ese_vovnet19b_slim": [[386, 389], ["vovnet._create_vovnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet._create_vovnet"], ["", "@", "register_model", "\n", "def", "ese_vovnet19b_slim", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_vovnet", "(", "'ese_vovnet19b_slim'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.ese_vovnet39b": [[391, 394], ["vovnet._create_vovnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet._create_vovnet"], ["", "@", "register_model", "\n", "def", "ese_vovnet39b", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_vovnet", "(", "'ese_vovnet39b'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.ese_vovnet57b": [[396, 399], ["vovnet._create_vovnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet._create_vovnet"], ["", "@", "register_model", "\n", "def", "ese_vovnet57b", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_vovnet", "(", "'ese_vovnet57b'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.ese_vovnet99b": [[401, 404], ["vovnet._create_vovnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet._create_vovnet"], ["", "@", "register_model", "\n", "def", "ese_vovnet99b", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_vovnet", "(", "'ese_vovnet99b'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.eca_vovnet39b": [[406, 409], ["vovnet._create_vovnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet._create_vovnet"], ["", "@", "register_model", "\n", "def", "eca_vovnet39b", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_create_vovnet", "(", "'eca_vovnet39b'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.ese_vovnet39b_evos": [[413, 418], ["vovnet._create_vovnet", "layers.create_norm_act_layer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet._create_vovnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.create_norm_act_layer"], ["", "@", "register_model", "\n", "def", "ese_vovnet39b_evos", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "def", "norm_act_fn", "(", "num_features", ",", "**", "nkwargs", ")", ":", "\n", "        ", "return", "create_norm_act_layer", "(", "'evonorms0'", ",", "num_features", ",", "jit", "=", "False", ",", "**", "nkwargs", ")", "\n", "", "return", "_create_vovnet", "(", "'ese_vovnet39b_evos'", ",", "pretrained", "=", "pretrained", ",", "norm_layer", "=", "norm_act_fn", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet.ese_vovnet99b_iabn": [[420, 425], ["layers.get_norm_act_layer", "vovnet._create_vovnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vovnet._create_vovnet"], ["", "@", "register_model", "\n", "def", "ese_vovnet99b_iabn", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "norm_layer", "=", "get_norm_act_layer", "(", "'iabn'", ",", "act_layer", "=", "'leaky_relu'", ")", "\n", "return", "_create_vovnet", "(", "\n", "'ese_vovnet99b_iabn'", ",", "pretrained", "=", "pretrained", ",", "norm_layer", "=", "norm_layer", ",", "act_layer", "=", "nn", ".", "LeakyReLU", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.Attention.__init__": [[48, 61], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "hidden_dim", ",", "num_heads", "=", "8", ",", "qkv_bias", "=", "False", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "hidden_dim", "//", "num_heads", "\n", "self", ".", "head_dim", "=", "head_dim", "\n", "self", ".", "scale", "=", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "qk", "=", "nn", ".", "Linear", "(", "dim", ",", "hidden_dim", "*", "2", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ",", "inplace", "=", "True", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ",", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.Attention.forward": [[62, 76], ["tnt.Attention.qk().reshape().permute", "tnt.Attention.unbind", "tnt.Attention.v().reshape().permute", "tnt.Attention.softmax", "tnt.Attention.attn_drop", "tnt.Attention.proj", "tnt.Attention.proj_drop", "tnt.Attention.qk().reshape", "tnt.Attention.v().reshape", "k.transpose", "tnt.Attention.qk", "tnt.Attention.v"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "qk", "=", "self", ".", "qk", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "2", ",", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", "=", "qk", ".", "unbind", "(", "0", ")", "# make torchscript happy (cannot use tensor as tuple)", "\n", "v", "=", "self", ".", "v", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "self", ".", "num_heads", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "*", "self", ".", "scale", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "N", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.Block.__init__": [[81, 107], ["torch.Module.__init__", "norm_layer", "tnt.Attention", "norm_layer", "models.layers.Mlp", "norm_layer", "torch.Linear", "torch.Linear", "norm_layer", "tnt.Attention", "norm_layer", "models.layers.Mlp", "models.layers.DropPath", "torch.Identity", "torch.Identity", "int", "int"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "dim", ",", "in_dim", ",", "num_pixel", ",", "num_heads", "=", "12", ",", "in_num_head", "=", "4", ",", "mlp_ratio", "=", "4.", ",", "\n", "qkv_bias", "=", "False", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "drop_path", "=", "0.", ",", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# Inner transformer", "\n", "self", ".", "norm_in", "=", "norm_layer", "(", "in_dim", ")", "\n", "self", ".", "attn_in", "=", "Attention", "(", "\n", "in_dim", ",", "in_dim", ",", "num_heads", "=", "in_num_head", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ")", "\n", "\n", "self", ".", "norm_mlp_in", "=", "norm_layer", "(", "in_dim", ")", "\n", "self", ".", "mlp_in", "=", "Mlp", "(", "in_features", "=", "in_dim", ",", "hidden_features", "=", "int", "(", "in_dim", "*", "4", ")", ",", "\n", "out_features", "=", "in_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "\n", "self", ".", "norm1_proj", "=", "norm_layer", "(", "in_dim", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "in_dim", "*", "num_pixel", ",", "dim", ",", "bias", "=", "True", ")", "\n", "# Outer transformer", "\n", "self", ".", "norm_out", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn_out", "=", "Attention", "(", "\n", "dim", ",", "dim", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "norm_mlp", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "in_features", "=", "dim", ",", "hidden_features", "=", "int", "(", "dim", "*", "mlp_ratio", ")", ",", "\n", "out_features", "=", "dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.Block.forward": [[108, 120], ["torch.cat.size", "torch.cat.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tnt.Block.drop_path", "tnt.Block.drop_path", "tnt.Block.drop_path", "tnt.Block.drop_path", "tnt.Block.attn_in", "tnt.Block.mlp_in", "tnt.Block.attn_out", "tnt.Block.mlp", "tnt.Block.norm_in", "tnt.Block.norm_mlp_in", "tnt.Block.proj", "tnt.Block.norm_out", "tnt.Block.norm_mlp", "tnt.Block.norm1_proj().reshape", "tnt.Block.norm1_proj"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "pixel_embed", ",", "patch_embed", ")", ":", "\n", "# inner", "\n", "        ", "pixel_embed", "=", "pixel_embed", "+", "self", ".", "drop_path", "(", "self", ".", "attn_in", "(", "self", ".", "norm_in", "(", "pixel_embed", ")", ")", ")", "\n", "pixel_embed", "=", "pixel_embed", "+", "self", ".", "drop_path", "(", "self", ".", "mlp_in", "(", "self", ".", "norm_mlp_in", "(", "pixel_embed", ")", ")", ")", "\n", "# outer", "\n", "B", ",", "N", ",", "C", "=", "patch_embed", ".", "size", "(", ")", "\n", "patch_embed", "=", "torch", ".", "cat", "(", "\n", "[", "patch_embed", "[", ":", ",", "0", ":", "1", "]", ",", "patch_embed", "[", ":", ",", "1", ":", "]", "+", "self", ".", "proj", "(", "self", ".", "norm1_proj", "(", "pixel_embed", ")", ".", "reshape", "(", "B", ",", "N", "-", "1", ",", "-", "1", ")", ")", "]", ",", "\n", "dim", "=", "1", ")", "\n", "patch_embed", "=", "patch_embed", "+", "self", ".", "drop_path", "(", "self", ".", "attn_out", "(", "self", ".", "norm_out", "(", "patch_embed", ")", ")", ")", "\n", "patch_embed", "=", "patch_embed", "+", "self", ".", "drop_path", "(", "self", ".", "mlp", "(", "self", ".", "norm_mlp", "(", "patch_embed", ")", ")", ")", "\n", "return", "pixel_embed", ",", "patch_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.PixelEmbed.__init__": [[125, 140], ["torch.Module.__init__", "models.layers.helpers.to_2tuple", "models.layers.helpers.to_2tuple", "torch.Conv2d", "torch.Conv2d", "torch.Unfold", "torch.Unfold", "math.ceil"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "in_dim", "=", "48", ",", "stride", "=", "4", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "patch_size", "=", "to_2tuple", "(", "patch_size", ")", "\n", "# grid_size property necessary for resizing positional embedding", "\n", "self", ".", "grid_size", "=", "(", "img_size", "[", "0", "]", "//", "patch_size", "[", "0", "]", ",", "img_size", "[", "1", "]", "//", "patch_size", "[", "1", "]", ")", "\n", "num_patches", "=", "(", "self", ".", "grid_size", "[", "0", "]", ")", "*", "(", "self", ".", "grid_size", "[", "1", "]", ")", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "num_patches", "=", "num_patches", "\n", "self", ".", "in_dim", "=", "in_dim", "\n", "new_patch_size", "=", "[", "math", ".", "ceil", "(", "ps", "/", "stride", ")", "for", "ps", "in", "patch_size", "]", "\n", "self", ".", "new_patch_size", "=", "new_patch_size", "\n", "\n", "self", ".", "proj", "=", "nn", ".", "Conv2d", "(", "in_chans", ",", "self", ".", "in_dim", ",", "kernel_size", "=", "7", ",", "padding", "=", "3", ",", "stride", "=", "stride", ")", "\n", "self", ".", "unfold", "=", "nn", ".", "Unfold", "(", "kernel_size", "=", "new_patch_size", ",", "stride", "=", "new_patch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.PixelEmbed.forward": [[141, 153], ["models.layers._assert", "models.layers._assert", "tnt.PixelEmbed.proj", "tnt.PixelEmbed.unfold", "x.reshape().transpose.reshape().transpose.transpose().reshape", "x.reshape().transpose.reshape().transpose.reshape().transpose", "x.reshape().transpose.reshape().transpose.transpose", "x.reshape().transpose.reshape().transpose.reshape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "pixel_pos", ")", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "_assert", "(", "H", "==", "self", ".", "img_size", "[", "0", "]", ",", "\n", "f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"", ")", "\n", "_assert", "(", "W", "==", "self", ".", "img_size", "[", "1", "]", ",", "\n", "f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "unfold", "(", "x", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", "*", "self", ".", "num_patches", ",", "self", ".", "in_dim", ",", "self", ".", "new_patch_size", "[", "0", "]", ",", "self", ".", "new_patch_size", "[", "1", "]", ")", "\n", "x", "=", "x", "+", "pixel_pos", "\n", "x", "=", "x", ".", "reshape", "(", "B", "*", "self", ".", "num_patches", ",", "self", ".", "in_dim", ",", "-", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.TNT.__init__": [[158, 201], ["torch.Module.__init__", "tnt.PixelEmbed", "norm_layer", "torch.Linear", "torch.Linear", "norm_layer", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Dropout", "torch.Dropout", "range", "torch.ModuleList", "torch.ModuleList", "norm_layer", "models.layers.trunc_normal_", "models.layers.trunc_normal_", "models.layers.trunc_normal_", "tnt.TNT.apply", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "x.item", "blocks.append", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "tnt.Block"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["def", "__init__", "(", "\n", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "global_pool", "=", "'token'", ",", "\n", "embed_dim", "=", "768", ",", "in_dim", "=", "48", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "in_num_head", "=", "4", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "\n", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "first_stride", "=", "4", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "global_pool", "in", "(", "''", ",", "'token'", ",", "'avg'", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "self", ".", "num_features", "=", "self", ".", "embed_dim", "=", "embed_dim", "# num_features for consistency with other models", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "self", ".", "pixel_embed", "=", "PixelEmbed", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "in_dim", "=", "in_dim", ",", "stride", "=", "first_stride", ")", "\n", "num_patches", "=", "self", ".", "pixel_embed", ".", "num_patches", "\n", "self", ".", "num_patches", "=", "num_patches", "\n", "new_patch_size", "=", "self", ".", "pixel_embed", ".", "new_patch_size", "\n", "num_pixel", "=", "new_patch_size", "[", "0", "]", "*", "new_patch_size", "[", "1", "]", "\n", "\n", "self", ".", "norm1_proj", "=", "norm_layer", "(", "num_pixel", "*", "in_dim", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "num_pixel", "*", "in_dim", ",", "embed_dim", ")", "\n", "self", ".", "norm2_proj", "=", "norm_layer", "(", "embed_dim", ")", "\n", "\n", "self", ".", "cls_token", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "self", ".", "patch_pos", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "num_patches", "+", "1", ",", "embed_dim", ")", ")", "\n", "self", ".", "pixel_pos", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "in_dim", ",", "new_patch_size", "[", "0", "]", ",", "new_patch_size", "[", "1", "]", ")", ")", "\n", "self", ".", "pos_drop", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", "\n", "\n", "dpr", "=", "[", "x", ".", "item", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "depth", ")", "]", "# stochastic depth decay rule", "\n", "blocks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "depth", ")", ":", "\n", "            ", "blocks", ".", "append", "(", "Block", "(", "\n", "dim", "=", "embed_dim", ",", "in_dim", "=", "in_dim", ",", "num_pixel", "=", "num_pixel", ",", "num_heads", "=", "num_heads", ",", "in_num_head", "=", "in_num_head", ",", "\n", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "\n", "drop_path", "=", "dpr", "[", "i", "]", ",", "norm_layer", "=", "norm_layer", ")", ")", "\n", "", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "blocks", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "\n", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "trunc_normal_", "(", "self", ".", "cls_token", ",", "std", "=", ".02", ")", "\n", "trunc_normal_", "(", "self", ".", "patch_pos", ",", "std", "=", ".02", ")", "\n", "trunc_normal_", "(", "self", ".", "pixel_pos", ",", "std", "=", ".02", ")", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.TNT._init_weights": [[202, 210], ["isinstance", "models.layers.trunc_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", ".02", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.TNT.no_weight_decay": [[211, 214], ["None"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "{", "'patch_pos'", ",", "'pixel_pos'", ",", "'cls_token'", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.TNT.group_matcher": [[215, 225], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem", "=", "r'^cls_token|patch_pos|pixel_pos|pixel_embed|norm[12]_proj|proj'", ",", "# stem and embed / pos", "\n", "blocks", "=", "[", "\n", "(", "r'^blocks\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^norm'", ",", "(", "99999", ",", ")", ")", ",", "\n", "]", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.TNT.set_grad_checkpointing": [[226, 229], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.TNT.get_classifier": [[230, 233], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.TNT.reset_classifier": [[234, 239], ["torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "None", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "if", "global_pool", "is", "not", "None", ":", "\n", "            ", "assert", "global_pool", "in", "(", "''", ",", "'token'", ",", "'avg'", ")", "\n", "", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.TNT.forward_features": [[240, 258], ["tnt.TNT.pixel_embed", "tnt.TNT.norm2_proj", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tnt.TNT.pos_drop", "tnt.TNT.norm", "tnt.TNT.proj", "tnt.TNT.norm1_proj", "tnt.TNT.cls_token.expand", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "blk", "tnt.TNT.reshape"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", "=", "x", ".", "shape", "[", "0", "]", "\n", "pixel_embed", "=", "self", ".", "pixel_embed", "(", "x", ",", "self", ".", "pixel_pos", ")", "\n", "\n", "patch_embed", "=", "self", ".", "norm2_proj", "(", "self", ".", "proj", "(", "self", ".", "norm1_proj", "(", "pixel_embed", ".", "reshape", "(", "B", ",", "self", ".", "num_patches", ",", "-", "1", ")", ")", ")", ")", "\n", "patch_embed", "=", "torch", ".", "cat", "(", "(", "self", ".", "cls_token", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", ",", "patch_embed", ")", ",", "dim", "=", "1", ")", "\n", "patch_embed", "=", "patch_embed", "+", "self", ".", "patch_pos", "\n", "patch_embed", "=", "self", ".", "pos_drop", "(", "patch_embed", ")", "\n", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "for", "blk", "in", "self", ".", "blocks", ":", "\n", "                ", "pixel_embed", ",", "patch_embed", "=", "checkpoint", "(", "blk", ",", "pixel_embed", ",", "patch_embed", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "blk", "in", "self", ".", "blocks", ":", "\n", "                ", "pixel_embed", ",", "patch_embed", "=", "blk", "(", "pixel_embed", ",", "patch_embed", ")", "\n", "\n", "", "", "patch_embed", "=", "self", ".", "norm", "(", "patch_embed", ")", "\n", "return", "patch_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.TNT.forward_head": [[259, 263], ["tnt.TNT.head", "x[].mean"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "global_pool", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", "1", ":", "]", ".", "mean", "(", "dim", "=", "1", ")", "if", "self", ".", "global_pool", "==", "'avg'", "else", "x", "[", ":", ",", "0", "]", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.TNT.forward": [[264, 268], ["tnt.TNT.forward_features", "tnt.TNT.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt._cfg": [[23, 31], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", ".9", ",", "'interpolation'", ":", "'bicubic'", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'pixel_embed.proj'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.checkpoint_filter_fn": [[270, 276], ["models.vision_transformer.resize_pos_embed", "getattr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.resize_pos_embed"], ["", "", "def", "checkpoint_filter_fn", "(", "state_dict", ",", "model", ")", ":", "\n", "    ", "\"\"\" convert patch embedding weight from manual patchify + linear proj to conv\"\"\"", "\n", "if", "state_dict", "[", "'patch_pos'", "]", ".", "shape", "!=", "model", ".", "patch_pos", ".", "shape", ":", "\n", "        ", "state_dict", "[", "'patch_pos'", "]", "=", "resize_pos_embed", "(", "state_dict", "[", "'patch_pos'", "]", ",", "\n", "model", ".", "patch_pos", ",", "getattr", "(", "model", ",", "'num_tokens'", ",", "1", ")", ",", "model", ".", "pixel_embed", ".", "grid_size", ")", "\n", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt._create_tnt": [[278, 287], ["kwargs.get", "models.helpers.build_model_with_cfg", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "def", "_create_tnt", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", ".", "get", "(", "'features_only'", ",", "None", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'features_only not implemented for Vision Transformer models.'", ")", "\n", "\n", "", "model", "=", "build_model_with_cfg", "(", "\n", "TNT", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_filter_fn", "=", "checkpoint_filter_fn", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.tnt_s_patch16_224": [[289, 296], ["dict", "tnt._create_tnt"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt._create_tnt"], ["", "@", "register_model", "\n", "def", "tnt_s_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_cfg", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "in_dim", "=", "24", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "in_num_head", "=", "4", ",", "\n", "qkv_bias", "=", "False", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_tnt", "(", "'tnt_s_patch16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_cfg", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt.tnt_b_patch16_224": [[298, 305], ["dict", "tnt._create_tnt"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tnt._create_tnt"], ["", "@", "register_model", "\n", "def", "tnt_b_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_cfg", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "640", ",", "in_dim", "=", "40", ",", "depth", "=", "12", ",", "num_heads", "=", "10", ",", "in_num_head", "=", "4", ",", "\n", "qkv_bias", "=", "False", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_tnt", "(", "'tnt_b_patch16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_cfg", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.Bottleneck.__init__": [[250, 273], ["torch.Module.__init__", "layers.get_act_layer", "int", "dict", "layers.ConvNormAct", "layers.ConvNormAct", "layers.ConvNormAct", "regnet.create_shortcut", "round", "int", "layers.SEModule", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "layers.get_act_layer.", "layers.DropPath", "torch.Identity", "torch.Identity", "round"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.create_shortcut"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "stride", "=", "1", ",", "dilation", "=", "(", "1", ",", "1", ")", ",", "bottle_ratio", "=", "1", ",", "group_size", "=", "1", ",", "se_ratio", "=", "0.25", ",", "\n", "downsample", "=", "'conv1x1'", ",", "linear_out", "=", "False", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "\n", "drop_block", "=", "None", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "act_layer", "=", "get_act_layer", "(", "act_layer", ")", "\n", "bottleneck_chs", "=", "int", "(", "round", "(", "out_chs", "*", "bottle_ratio", ")", ")", "\n", "groups", "=", "bottleneck_chs", "//", "group_size", "\n", "\n", "cargs", "=", "dict", "(", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "conv1", "=", "ConvNormAct", "(", "in_chs", ",", "bottleneck_chs", ",", "kernel_size", "=", "1", ",", "**", "cargs", ")", "\n", "self", ".", "conv2", "=", "ConvNormAct", "(", "\n", "bottleneck_chs", ",", "bottleneck_chs", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", "[", "0", "]", ",", "\n", "groups", "=", "groups", ",", "drop_layer", "=", "drop_block", ",", "**", "cargs", ")", "\n", "if", "se_ratio", ":", "\n", "            ", "se_channels", "=", "int", "(", "round", "(", "in_chs", "*", "se_ratio", ")", ")", "\n", "self", ".", "se", "=", "SEModule", "(", "bottleneck_chs", ",", "rd_channels", "=", "se_channels", ",", "act_layer", "=", "act_layer", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "se", "=", "nn", ".", "Identity", "(", ")", "\n", "", "self", ".", "conv3", "=", "ConvNormAct", "(", "bottleneck_chs", ",", "out_chs", ",", "kernel_size", "=", "1", ",", "apply_act", "=", "False", ",", "**", "cargs", ")", "\n", "self", ".", "act3", "=", "nn", ".", "Identity", "(", ")", "if", "linear_out", "else", "act_layer", "(", ")", "\n", "self", ".", "downsample", "=", "create_shortcut", "(", "downsample", ",", "in_chs", ",", "out_chs", ",", "1", ",", "stride", ",", "dilation", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path_rate", ")", "if", "drop_path_rate", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.Bottleneck.zero_init_last": [[274, 276], ["torch.init.zeros_", "torch.init.zeros_"], "methods", ["None"], ["", "def", "zero_init_last", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "conv3", ".", "bn", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.Bottleneck.forward": [[277, 289], ["regnet.Bottleneck.conv1", "regnet.Bottleneck.conv2", "regnet.Bottleneck.se", "regnet.Bottleneck.conv3", "regnet.Bottleneck.act3", "regnet.Bottleneck.drop_path", "regnet.Bottleneck.downsample"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "se", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3", "(", "x", ")", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "# NOTE stuck with downsample as the attr name due to weight compatibility", "\n", "# now represents the shortcut, no shortcut if None, and non-downsample shortcut == nn.Identity()", "\n", "            ", "x", "=", "self", ".", "drop_path", "(", "x", ")", "+", "self", ".", "downsample", "(", "shortcut", ")", "\n", "", "x", "=", "self", ".", "act3", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.PreBottleneck.__init__": [[298, 321], ["torch.Module.__init__", "layers.get_norm_act_layer", "int", "layers.get_norm_act_layer.", "layers.create_conv2d", "layers.get_norm_act_layer.", "layers.create_conv2d", "layers.get_norm_act_layer.", "layers.create_conv2d", "regnet.create_shortcut", "round", "int", "layers.SEModule", "torch.Identity", "torch.Identity", "layers.DropPath", "torch.Identity", "torch.Identity", "round"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.create_shortcut"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "stride", "=", "1", ",", "dilation", "=", "(", "1", ",", "1", ")", ",", "bottle_ratio", "=", "1", ",", "group_size", "=", "1", ",", "se_ratio", "=", "0.25", ",", "\n", "downsample", "=", "'conv1x1'", ",", "linear_out", "=", "False", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "\n", "drop_block", "=", "None", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", "PreBottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "norm_act_layer", "=", "get_norm_act_layer", "(", "norm_layer", ",", "act_layer", ")", "\n", "bottleneck_chs", "=", "int", "(", "round", "(", "out_chs", "*", "bottle_ratio", ")", ")", "\n", "groups", "=", "bottleneck_chs", "//", "group_size", "\n", "\n", "self", ".", "norm1", "=", "norm_act_layer", "(", "in_chs", ")", "\n", "self", ".", "conv1", "=", "create_conv2d", "(", "in_chs", ",", "bottleneck_chs", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "norm2", "=", "norm_act_layer", "(", "bottleneck_chs", ")", "\n", "self", ".", "conv2", "=", "create_conv2d", "(", "\n", "bottleneck_chs", ",", "bottleneck_chs", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", "[", "0", "]", ",", "groups", "=", "groups", ")", "\n", "if", "se_ratio", ":", "\n", "            ", "se_channels", "=", "int", "(", "round", "(", "in_chs", "*", "se_ratio", ")", ")", "\n", "self", ".", "se", "=", "SEModule", "(", "bottleneck_chs", ",", "rd_channels", "=", "se_channels", ",", "act_layer", "=", "act_layer", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "se", "=", "nn", ".", "Identity", "(", ")", "\n", "", "self", ".", "norm3", "=", "norm_act_layer", "(", "bottleneck_chs", ")", "\n", "self", ".", "conv3", "=", "create_conv2d", "(", "bottleneck_chs", ",", "out_chs", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "downsample", "=", "create_shortcut", "(", "downsample", ",", "in_chs", ",", "out_chs", ",", "1", ",", "stride", ",", "dilation", ",", "preact", "=", "True", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path_rate", ")", "if", "drop_path_rate", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.PreBottleneck.zero_init_last": [[322, 324], ["None"], "methods", ["None"], ["", "def", "zero_init_last", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.PreBottleneck.forward": [[325, 339], ["regnet.PreBottleneck.norm1", "regnet.PreBottleneck.conv1", "regnet.PreBottleneck.norm2", "regnet.PreBottleneck.conv2", "regnet.PreBottleneck.se", "regnet.PreBottleneck.norm3", "regnet.PreBottleneck.conv3", "regnet.PreBottleneck.drop_path", "regnet.PreBottleneck.downsample"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "norm1", "(", "x", ")", "\n", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "norm2", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "se", "(", "x", ")", "\n", "x", "=", "self", ".", "norm3", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3", "(", "x", ")", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "# NOTE stuck with downsample as the attr name due to weight compatibility", "\n", "# now represents the shortcut, no shortcut if None, and non-downsample shortcut == nn.Identity()", "\n", "            ", "x", "=", "self", ".", "drop_path", "(", "x", ")", "+", "self", ".", "downsample", "(", "shortcut", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.RegStage.__init__": [[344, 363], ["torch.Module.__init__", "range", "regnet.RegStage.add_module", "block_fn"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "depth", ",", "in_chs", ",", "out_chs", ",", "stride", ",", "dilation", ",", "\n", "drop_path_rates", "=", "None", ",", "block_fn", "=", "Bottleneck", ",", "**", "block_kwargs", ")", ":", "\n", "        ", "super", "(", "RegStage", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "first_dilation", "=", "1", "if", "dilation", "in", "(", "1", ",", "2", ")", "else", "2", "\n", "for", "i", "in", "range", "(", "depth", ")", ":", "\n", "            ", "block_stride", "=", "stride", "if", "i", "==", "0", "else", "1", "\n", "block_in_chs", "=", "in_chs", "if", "i", "==", "0", "else", "out_chs", "\n", "block_dilation", "=", "(", "first_dilation", ",", "dilation", ")", "\n", "dpr", "=", "drop_path_rates", "[", "i", "]", "if", "drop_path_rates", "is", "not", "None", "else", "0.", "\n", "name", "=", "\"b{}\"", ".", "format", "(", "i", "+", "1", ")", "\n", "self", ".", "add_module", "(", "\n", "name", ",", "block_fn", "(", "\n", "block_in_chs", ",", "out_chs", ",", "stride", "=", "block_stride", ",", "dilation", "=", "block_dilation", ",", "\n", "drop_path_rate", "=", "dpr", ",", "**", "block_kwargs", ")", "\n", ")", "\n", "first_dilation", "=", "dilation", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.RegStage.forward": [[364, 371], ["helpers.checkpoint_seq", "regnet.RegStage.children", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "regnet.RegStage.children", "block"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "children", "(", ")", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "for", "block", "in", "self", ".", "children", "(", ")", ":", "\n", "                ", "x", "=", "block", "(", "x", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.RegNet.__init__": [[380, 423], ["torch.Module.__init__", "dict", "regnet.RegNet._get_stage_args", "enumerate", "layers.ClassifierHead", "helpers.named_apply", "layers.create_conv2d", "layers.ConvNormAct", "dict", "len", "regnet.RegNet.add_module", "layers.ConvNormAct", "functools.partial", "regnet.RegStage", "dict", "torch.Identity", "torch.Identity", "layers.get_act_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.RegNet._get_stage_args", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_apply", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer"], ["def", "__init__", "(", "\n", "self", ",", "cfg", ":", "RegNetCfg", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "output_stride", "=", "32", ",", "global_pool", "=", "'avg'", ",", "\n", "drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "zero_init_last", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "assert", "output_stride", "in", "(", "8", ",", "16", ",", "32", ")", "\n", "\n", "# Construct the stem", "\n", "stem_width", "=", "cfg", ".", "stem_width", "\n", "na_args", "=", "dict", "(", "act_layer", "=", "cfg", ".", "act_layer", ",", "norm_layer", "=", "cfg", ".", "norm_layer", ")", "\n", "if", "cfg", ".", "preact", ":", "\n", "            ", "self", ".", "stem", "=", "create_conv2d", "(", "in_chans", ",", "stem_width", ",", "3", ",", "stride", "=", "2", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "stem", "=", "ConvNormAct", "(", "in_chans", ",", "stem_width", ",", "3", ",", "stride", "=", "2", ",", "**", "na_args", ")", "\n", "", "self", ".", "feature_info", "=", "[", "dict", "(", "num_chs", "=", "stem_width", ",", "reduction", "=", "2", ",", "module", "=", "'stem'", ")", "]", "\n", "\n", "# Construct the stages", "\n", "prev_width", "=", "stem_width", "\n", "curr_stride", "=", "2", "\n", "per_stage_args", ",", "common_args", "=", "self", ".", "_get_stage_args", "(", "\n", "cfg", ",", "output_stride", "=", "output_stride", ",", "drop_path_rate", "=", "drop_path_rate", ")", "\n", "assert", "len", "(", "per_stage_args", ")", "==", "4", "\n", "block_fn", "=", "PreBottleneck", "if", "cfg", ".", "preact", "else", "Bottleneck", "\n", "for", "i", ",", "stage_args", "in", "enumerate", "(", "per_stage_args", ")", ":", "\n", "            ", "stage_name", "=", "\"s{}\"", ".", "format", "(", "i", "+", "1", ")", "\n", "self", ".", "add_module", "(", "stage_name", ",", "RegStage", "(", "in_chs", "=", "prev_width", ",", "block_fn", "=", "block_fn", ",", "**", "stage_args", ",", "**", "common_args", ")", ")", "\n", "prev_width", "=", "stage_args", "[", "'out_chs'", "]", "\n", "curr_stride", "*=", "stage_args", "[", "'stride'", "]", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "prev_width", ",", "reduction", "=", "curr_stride", ",", "module", "=", "stage_name", ")", "]", "\n", "\n", "# Construct the head", "\n", "", "if", "cfg", ".", "num_features", ":", "\n", "            ", "self", ".", "final_conv", "=", "ConvNormAct", "(", "prev_width", ",", "cfg", ".", "num_features", ",", "kernel_size", "=", "1", ",", "**", "na_args", ")", "\n", "self", ".", "num_features", "=", "cfg", ".", "num_features", "\n", "", "else", ":", "\n", "            ", "final_act", "=", "cfg", ".", "linear_out", "or", "cfg", ".", "preact", "\n", "self", ".", "final_conv", "=", "get_act_layer", "(", "cfg", ".", "act_layer", ")", "(", ")", "if", "final_act", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "num_features", "=", "prev_width", "\n", "", "self", ".", "head", "=", "ClassifierHead", "(", "\n", "in_chs", "=", "self", ".", "num_features", ",", "num_classes", "=", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "drop_rate", ")", "\n", "\n", "named_apply", "(", "partial", "(", "_init_weights", ",", "zero_init_last", "=", "zero_init_last", ")", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.RegNet._get_stage_args": [[424, 456], ["regnet.generate_regnet", "numpy.unique", "range", "numpy.split", "regnet.adjust_widths_groups_comp", "dict", "stage_strides.append", "stage_dilations.append", "numpy.linspace", "numpy.cumsum", "dict", "range", "sum", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.generate_regnet", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.adjust_widths_groups_comp"], ["", "def", "_get_stage_args", "(", "self", ",", "cfg", ":", "RegNetCfg", ",", "default_stride", "=", "2", ",", "output_stride", "=", "32", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "# Generate RegNet ws per block", "\n", "        ", "widths", ",", "num_stages", ",", "stage_gs", "=", "generate_regnet", "(", "cfg", ".", "wa", ",", "cfg", ".", "w0", ",", "cfg", ".", "wm", ",", "cfg", ".", "depth", ",", "cfg", ".", "group_size", ")", "\n", "\n", "# Convert to per stage format", "\n", "stage_widths", ",", "stage_depths", "=", "np", ".", "unique", "(", "widths", ",", "return_counts", "=", "True", ")", "\n", "stage_br", "=", "[", "cfg", ".", "bottle_ratio", "for", "_", "in", "range", "(", "num_stages", ")", "]", "\n", "stage_strides", "=", "[", "]", "\n", "stage_dilations", "=", "[", "]", "\n", "net_stride", "=", "2", "\n", "dilation", "=", "1", "\n", "for", "_", "in", "range", "(", "num_stages", ")", ":", "\n", "            ", "if", "net_stride", ">=", "output_stride", ":", "\n", "                ", "dilation", "*=", "default_stride", "\n", "stride", "=", "1", "\n", "", "else", ":", "\n", "                ", "stride", "=", "default_stride", "\n", "net_stride", "*=", "stride", "\n", "", "stage_strides", ".", "append", "(", "stride", ")", "\n", "stage_dilations", ".", "append", "(", "dilation", ")", "\n", "", "stage_dpr", "=", "np", ".", "split", "(", "np", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "sum", "(", "stage_depths", ")", ")", ",", "np", ".", "cumsum", "(", "stage_depths", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "# Adjust the compatibility of ws and gws", "\n", "stage_widths", ",", "stage_gs", "=", "adjust_widths_groups_comp", "(", "stage_widths", ",", "stage_br", ",", "stage_gs", ")", "\n", "arg_names", "=", "[", "'out_chs'", ",", "'stride'", ",", "'dilation'", ",", "'depth'", ",", "'bottle_ratio'", ",", "'group_size'", ",", "'drop_path_rates'", "]", "\n", "per_stage_args", "=", "[", "\n", "dict", "(", "zip", "(", "arg_names", ",", "params", ")", ")", "for", "params", "in", "\n", "zip", "(", "stage_widths", ",", "stage_strides", ",", "stage_dilations", ",", "stage_depths", ",", "stage_br", ",", "stage_gs", ",", "stage_dpr", ")", "]", "\n", "common_args", "=", "dict", "(", "\n", "downsample", "=", "cfg", ".", "downsample", ",", "se_ratio", "=", "cfg", ".", "se_ratio", ",", "linear_out", "=", "cfg", ".", "linear_out", ",", "\n", "act_layer", "=", "cfg", ".", "act_layer", ",", "norm_layer", "=", "cfg", ".", "norm_layer", ")", "\n", "return", "per_stage_args", ",", "common_args", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.RegNet.group_matcher": [[457, 462], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^stem'", ",", "\n", "blocks", "=", "r'^stages\\.(\\d+)'", "if", "coarse", "else", "r'^stages\\.(\\d+)\\.blocks\\.(\\d+)'", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.RegNet.set_grad_checkpointing": [[464, 468], ["list", "regnet.RegNet.children"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "for", "s", "in", "list", "(", "self", ".", "children", "(", ")", ")", "[", "1", ":", "-", "1", "]", ":", "\n", "            ", "s", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.RegNet.get_classifier": [[469, 472], ["None"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.RegNet.reset_classifier": [[473, 475], ["layers.ClassifierHead"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "head", "=", "ClassifierHead", "(", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "self", ".", "drop_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.RegNet.forward_features": [[476, 484], ["regnet.RegNet.stem", "regnet.RegNet.s1", "regnet.RegNet.s2", "regnet.RegNet.s3", "regnet.RegNet.s4", "regnet.RegNet.final_conv"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "x", "=", "self", ".", "s1", "(", "x", ")", "\n", "x", "=", "self", ".", "s2", "(", "x", ")", "\n", "x", "=", "self", ".", "s3", "(", "x", ")", "\n", "x", "=", "self", ".", "s4", "(", "x", ")", "\n", "x", "=", "self", ".", "final_conv", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.RegNet.forward_head": [[485, 487], ["regnet.RegNet.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "head", "(", "x", ",", "pre_logits", "=", "pre_logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.RegNet.forward": [[488, 492], ["regnet.RegNet.forward_features", "regnet.RegNet.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._cfg": [[108, 115], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'stem.conv'", ",", "'classifier'", ":", "'head.fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.quantize_float": [[173, 176], ["int", "round"], "function", ["None"], ["def", "quantize_float", "(", "f", ",", "q", ")", ":", "\n", "    ", "\"\"\"Converts a float to closest non-zero int divisible by q.\"\"\"", "\n", "return", "int", "(", "round", "(", "f", "/", "q", ")", "*", "q", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.adjust_widths_groups_comp": [[178, 185], ["int", "min", "regnet.quantize_float", "int", "zip", "zip", "zip", "zip"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.quantize_float"], ["", "def", "adjust_widths_groups_comp", "(", "widths", ",", "bottle_ratios", ",", "groups", ")", ":", "\n", "    ", "\"\"\"Adjusts the compatibility of widths and groups.\"\"\"", "\n", "bottleneck_widths", "=", "[", "int", "(", "w", "*", "b", ")", "for", "w", ",", "b", "in", "zip", "(", "widths", ",", "bottle_ratios", ")", "]", "\n", "groups", "=", "[", "min", "(", "g", ",", "w_bot", ")", "for", "g", ",", "w_bot", "in", "zip", "(", "groups", ",", "bottleneck_widths", ")", "]", "\n", "bottleneck_widths", "=", "[", "quantize_float", "(", "w_bot", ",", "g", ")", "for", "w_bot", ",", "g", "in", "zip", "(", "bottleneck_widths", ",", "groups", ")", "]", "\n", "widths", "=", "[", "int", "(", "w_bot", "/", "b", ")", "for", "w_bot", ",", "b", "in", "zip", "(", "bottleneck_widths", ",", "bottle_ratios", ")", "]", "\n", "return", "widths", ",", "groups", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.generate_regnet": [[187, 200], ["numpy.round", "numpy.array", "numpy.power", "numpy.round", "len", "widths.astype().tolist", "np.array.astype().tolist", "numpy.arange", "numpy.log", "numpy.log", "numpy.divide", "numpy.unique", "np.round.max", "range", "widths.astype", "np.array.astype"], "function", ["None"], ["", "def", "generate_regnet", "(", "width_slope", ",", "width_initial", ",", "width_mult", ",", "depth", ",", "group_size", ",", "q", "=", "8", ")", ":", "\n", "    ", "\"\"\"Generates per block widths from RegNet parameters.\"\"\"", "\n", "assert", "width_slope", ">=", "0", "and", "width_initial", ">", "0", "and", "width_mult", ">", "1", "and", "width_initial", "%", "q", "==", "0", "\n", "# TODO dWr scaling?", "\n", "# depth = int(depth * (scale ** 0.1))", "\n", "# width_scale = scale ** 0.4  # dWr scale, exp 0.8 / 2, applied to both group and layer widths", "\n", "widths_cont", "=", "np", ".", "arange", "(", "depth", ")", "*", "width_slope", "+", "width_initial", "\n", "width_exps", "=", "np", ".", "round", "(", "np", ".", "log", "(", "widths_cont", "/", "width_initial", ")", "/", "np", ".", "log", "(", "width_mult", ")", ")", "\n", "widths", "=", "width_initial", "*", "np", ".", "power", "(", "width_mult", ",", "width_exps", ")", "\n", "widths", "=", "np", ".", "round", "(", "np", ".", "divide", "(", "widths", ",", "q", ")", ")", "*", "q", "\n", "num_stages", ",", "max_stage", "=", "len", "(", "np", ".", "unique", "(", "widths", ")", ")", ",", "width_exps", ".", "max", "(", ")", "+", "1", "\n", "groups", "=", "np", ".", "array", "(", "[", "group_size", "for", "_", "in", "range", "(", "num_stages", ")", "]", ")", "\n", "return", "widths", ".", "astype", "(", "int", ")", ".", "tolist", "(", ")", ",", "num_stages", ",", "groups", ".", "astype", "(", "int", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.downsample_conv": [[202, 211], ["layers.create_conv2d", "layers.ConvNormAct"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["", "def", "downsample_conv", "(", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "norm_layer", "=", "None", ",", "preact", "=", "False", ")", ":", "\n", "    ", "norm_layer", "=", "norm_layer", "or", "nn", ".", "BatchNorm2d", "\n", "kernel_size", "=", "1", "if", "stride", "==", "1", "and", "dilation", "==", "1", "else", "kernel_size", "\n", "dilation", "=", "dilation", "if", "kernel_size", ">", "1", "else", "1", "\n", "if", "preact", ":", "\n", "        ", "return", "create_conv2d", "(", "in_chs", ",", "out_chs", ",", "kernel_size", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ")", "\n", "", "else", ":", "\n", "        ", "return", "ConvNormAct", "(", "\n", "in_chs", ",", "out_chs", ",", "kernel_size", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "norm_layer", "=", "norm_layer", ",", "apply_act", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.downsample_avg": [[213, 226], ["torch.Identity", "torch.Sequential", "avg_pool_fn", "layers.create_conv2d", "layers.ConvNormAct"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["", "", "def", "downsample_avg", "(", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "norm_layer", "=", "None", ",", "preact", "=", "False", ")", ":", "\n", "    ", "\"\"\" AvgPool Downsampling as in 'D' ResNet variants. This is not in RegNet space but I might experiment.\"\"\"", "\n", "norm_layer", "=", "norm_layer", "or", "nn", ".", "BatchNorm2d", "\n", "avg_stride", "=", "stride", "if", "dilation", "==", "1", "else", "1", "\n", "pool", "=", "nn", ".", "Identity", "(", ")", "\n", "if", "stride", ">", "1", "or", "dilation", ">", "1", ":", "\n", "        ", "avg_pool_fn", "=", "AvgPool2dSame", "if", "avg_stride", "==", "1", "and", "dilation", ">", "1", "else", "nn", ".", "AvgPool2d", "\n", "pool", "=", "avg_pool_fn", "(", "2", ",", "avg_stride", ",", "ceil_mode", "=", "True", ",", "count_include_pad", "=", "False", ")", "\n", "", "if", "preact", ":", "\n", "        ", "conv", "=", "create_conv2d", "(", "in_chs", ",", "out_chs", ",", "1", ",", "stride", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "conv", "=", "ConvNormAct", "(", "in_chs", ",", "out_chs", ",", "1", ",", "stride", "=", "1", ",", "norm_layer", "=", "norm_layer", ",", "apply_act", "=", "False", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "[", "pool", ",", "conv", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.create_shortcut": [[228, 241], ["dict", "torch.Identity", "regnet.downsample_avg", "regnet.downsample_conv"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.downsample_avg", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.downsample_conv"], ["", "def", "create_shortcut", "(", "\n", "downsample_type", ",", "in_chs", ",", "out_chs", ",", "kernel_size", ",", "stride", ",", "dilation", "=", "(", "1", ",", "1", ")", ",", "norm_layer", "=", "None", ",", "preact", "=", "False", ")", ":", "\n", "    ", "assert", "downsample_type", "in", "(", "'avg'", ",", "'conv1x1'", ",", "''", ",", "None", ")", "\n", "if", "in_chs", "!=", "out_chs", "or", "stride", "!=", "1", "or", "dilation", "[", "0", "]", "!=", "dilation", "[", "1", "]", ":", "\n", "        ", "dargs", "=", "dict", "(", "stride", "=", "stride", ",", "dilation", "=", "dilation", "[", "0", "]", ",", "norm_layer", "=", "norm_layer", ",", "preact", "=", "preact", ")", "\n", "if", "not", "downsample_type", ":", "\n", "            ", "return", "None", "# no shortcut, no downsample", "\n", "", "elif", "downsample_type", "==", "'avg'", ":", "\n", "            ", "return", "downsample_avg", "(", "in_chs", ",", "out_chs", ",", "**", "dargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "downsample_conv", "(", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "kernel_size", ",", "**", "dargs", ")", "\n", "", "", "else", ":", "\n", "        ", "return", "nn", ".", "Identity", "(", ")", "# identity shortcut (no downsample)", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._init_weights": [[494, 507], ["isinstance", "module.weight.data.normal_", "isinstance", "math.sqrt", "module.bias.data.zero_", "torch.init.normal_", "torch.init.zeros_", "hasattr", "module.zero_init_last"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet.SelectiveKernelBottleneck.zero_init_last"], ["", "", "def", "_init_weights", "(", "module", ",", "name", "=", "''", ",", "zero_init_last", "=", "False", ")", ":", "\n", "    ", "if", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", ":", "\n", "        ", "fan_out", "=", "module", ".", "kernel_size", "[", "0", "]", "*", "module", ".", "kernel_size", "[", "1", "]", "*", "module", ".", "out_channels", "\n", "fan_out", "//=", "module", ".", "groups", "\n", "module", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.0", "/", "fan_out", ")", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "module", ".", "weight", ",", "mean", "=", "0.0", ",", "std", "=", "0.01", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "", "", "elif", "zero_init_last", "and", "hasattr", "(", "module", ",", "'zero_init_last'", ")", ":", "\n", "        ", "module", ".", "zero_init_last", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._filter_fn": [[509, 515], ["None"], "function", ["None"], ["", "", "def", "_filter_fn", "(", "state_dict", ")", ":", "\n", "    ", "\"\"\" convert patch embedding weight from manual patchify + linear proj to conv\"\"\"", "\n", "if", "'model'", "in", "state_dict", ":", "\n", "# For DeiT trained regnety_160 pretraiend model", "\n", "        ", "state_dict", "=", "state_dict", "[", "'model'", "]", "\n", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet": [[517, 523], ["helpers.build_model_with_cfg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "def", "_create_regnet", "(", "variant", ",", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "\n", "RegNet", ",", "variant", ",", "pretrained", ",", "\n", "model_cfg", "=", "model_cfgs", "[", "variant", "]", ",", "\n", "pretrained_filter_fn", "=", "_filter_fn", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetx_002": [[525, 529], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetx_002", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetX-200MF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnetx_002'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetx_004": [[531, 535], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetx_004", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetX-400MF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnetx_004'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetx_006": [[537, 541], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetx_006", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetX-600MF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnetx_006'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetx_008": [[543, 547], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetx_008", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetX-800MF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnetx_008'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetx_016": [[549, 553], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetx_016", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetX-1.6GF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnetx_016'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetx_032": [[555, 559], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetx_032", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetX-3.2GF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnetx_032'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetx_040": [[561, 565], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetx_040", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetX-4.0GF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnetx_040'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetx_064": [[567, 571], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetx_064", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetX-6.4GF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnetx_064'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetx_080": [[573, 577], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetx_080", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetX-8.0GF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnetx_080'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetx_120": [[579, 583], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetx_120", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetX-12GF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnetx_120'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetx_160": [[585, 589], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetx_160", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetX-16GF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnetx_160'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetx_320": [[591, 595], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetx_320", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetX-32GF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnetx_320'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnety_002": [[597, 601], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnety_002", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetY-200MF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnety_002'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnety_004": [[603, 607], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnety_004", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetY-400MF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnety_004'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnety_006": [[609, 613], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnety_006", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetY-600MF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnety_006'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnety_008": [[615, 619], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnety_008", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetY-800MF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnety_008'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnety_016": [[621, 625], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnety_016", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetY-1.6GF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnety_016'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnety_032": [[627, 631], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnety_032", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetY-3.2GF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnety_032'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnety_040": [[633, 637], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnety_040", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetY-4.0GF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnety_040'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnety_064": [[639, 643], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnety_064", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetY-6.4GF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnety_064'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnety_080": [[645, 649], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnety_080", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetY-8.0GF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnety_080'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnety_120": [[651, 655], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnety_120", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetY-12GF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnety_120'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnety_160": [[657, 661], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnety_160", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetY-16GF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnety_160'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnety_320": [[663, 667], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnety_320", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetY-32GF\"\"\"", "\n", "return", "_create_regnet", "(", "'regnety_320'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnety_040s_gn": [[669, 673], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnety_040s_gn", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetY-4.0GF w/ GroupNorm \"\"\"", "\n", "return", "_create_regnet", "(", "'regnety_040s_gn'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetv_040": [[675, 679], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetv_040", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\"\"\"", "\n", "return", "_create_regnet", "(", "'regnetv_040'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetv_064": [[681, 685], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetv_064", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\"\"\"", "\n", "return", "_create_regnet", "(", "'regnetv_064'", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetz_005": [[687, 694], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetz_005", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetZ-500MF\n    NOTE: config found in https://github.com/facebookresearch/ClassyVision/blob/main/classy_vision/models/regnet.py\n    but it's not clear it is equivalent to paper model as not detailed in the paper.\n    \"\"\"", "\n", "return", "_create_regnet", "(", "'regnetz_005'", ",", "pretrained", ",", "zero_init_last", "=", "False", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetz_040": [[696, 703], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetz_040", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetZ-4.0GF\n    NOTE: config found in https://github.com/facebookresearch/ClassyVision/blob/main/classy_vision/models/regnet.py\n    but it's not clear it is equivalent to paper model as not detailed in the paper.\n    \"\"\"", "\n", "return", "_create_regnet", "(", "'regnetz_040'", ",", "pretrained", ",", "zero_init_last", "=", "False", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet.regnetz_040h": [[705, 712], ["regnet._create_regnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.regnet._create_regnet"], ["", "@", "register_model", "\n", "def", "regnetz_040h", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"RegNetZ-4.0GF\n    NOTE: config found in https://github.com/facebookresearch/ClassyVision/blob/main/classy_vision/models/regnet.py\n    but it's not clear it is equivalent to paper model as not detailed in the paper.\n    \"\"\"", "\n", "return", "_create_regnet", "(", "'regnetz_040h'", ",", "pretrained", ",", "zero_init_last", "=", "False", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.BasicBlock.__init__": [[71, 89], ["torch.Module.__init__", "tresnet.conv2d_iabn", "torch.ReLU", "torch.ReLU", "max", "tresnet.conv2d_iabn", "layers.SEModule", "tresnet.conv2d_iabn", "torch.Sequential", "torch.Sequential", "tresnet.conv2d_iabn", "aa_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "use_se", "=", "True", ",", "aa_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "stride", "==", "1", ":", "\n", "            ", "self", ".", "conv1", "=", "conv2d_iabn", "(", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "act_param", "=", "1e-3", ")", "\n", "", "else", ":", "\n", "            ", "if", "aa_layer", "is", "None", ":", "\n", "                ", "self", ".", "conv1", "=", "conv2d_iabn", "(", "inplanes", ",", "planes", ",", "stride", "=", "2", ",", "act_param", "=", "1e-3", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "conv1", "=", "nn", ".", "Sequential", "(", "\n", "conv2d_iabn", "(", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "act_param", "=", "1e-3", ")", ",", "\n", "aa_layer", "(", "channels", "=", "planes", ",", "filt_size", "=", "3", ",", "stride", "=", "2", ")", ")", "\n", "\n", "", "", "self", ".", "conv2", "=", "conv2d_iabn", "(", "planes", ",", "planes", ",", "stride", "=", "1", ",", "act_layer", "=", "\"identity\"", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "rd_chs", "=", "max", "(", "planes", "*", "self", ".", "expansion", "//", "4", ",", "64", ")", "\n", "self", ".", "se", "=", "SEModule", "(", "planes", "*", "self", ".", "expansion", ",", "rd_channels", "=", "rd_chs", ")", "if", "use_se", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.BasicBlock.forward": [[90, 105], ["tresnet.BasicBlock.conv1", "tresnet.BasicBlock.conv2", "tresnet.BasicBlock.relu", "tresnet.BasicBlock.downsample", "tresnet.BasicBlock.se"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "downsample", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "shortcut", "=", "x", "\n", "\n", "", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "\n", "if", "self", ".", "se", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "se", "(", "out", ")", "\n", "\n", "", "out", "+=", "shortcut", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.Bottleneck.__init__": [[110, 137], ["torch.Module.__init__", "tresnet.conv2d_iabn", "max", "tresnet.conv2d_iabn", "torch.ReLU", "torch.ReLU", "tresnet.conv2d_iabn", "layers.SEModule", "tresnet.conv2d_iabn", "torch.Sequential", "torch.Sequential", "tresnet.conv2d_iabn", "aa_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn"], ["def", "__init__", "(", "\n", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "use_se", "=", "True", ",", "\n", "act_layer", "=", "\"leaky_relu\"", ",", "aa_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv2d_iabn", "(", "\n", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "act_layer", "=", "act_layer", ",", "act_param", "=", "1e-3", ")", "\n", "if", "stride", "==", "1", ":", "\n", "            ", "self", ".", "conv2", "=", "conv2d_iabn", "(", "\n", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "act_layer", "=", "act_layer", ",", "act_param", "=", "1e-3", ")", "\n", "", "else", ":", "\n", "            ", "if", "aa_layer", "is", "None", ":", "\n", "                ", "self", ".", "conv2", "=", "conv2d_iabn", "(", "\n", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "act_layer", "=", "act_layer", ",", "act_param", "=", "1e-3", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "conv2", "=", "nn", ".", "Sequential", "(", "\n", "conv2d_iabn", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "act_layer", "=", "act_layer", ",", "act_param", "=", "1e-3", ")", ",", "\n", "aa_layer", "(", "channels", "=", "planes", ",", "filt_size", "=", "3", ",", "stride", "=", "2", ")", ")", "\n", "\n", "", "", "reduction_chs", "=", "max", "(", "planes", "*", "self", ".", "expansion", "//", "8", ",", "64", ")", "\n", "self", ".", "se", "=", "SEModule", "(", "planes", ",", "rd_channels", "=", "reduction_chs", ")", "if", "use_se", "else", "None", "\n", "\n", "self", ".", "conv3", "=", "conv2d_iabn", "(", "\n", "planes", ",", "planes", "*", "self", ".", "expansion", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "act_layer", "=", "\"identity\"", ")", "\n", "\n", "self", ".", "act", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.Bottleneck.forward": [[138, 153], ["tresnet.Bottleneck.conv1", "tresnet.Bottleneck.conv2", "tresnet.Bottleneck.conv3", "tresnet.Bottleneck.act", "tresnet.Bottleneck.downsample", "tresnet.Bottleneck.se"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "downsample", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "shortcut", "=", "x", "\n", "\n", "", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "if", "self", ".", "se", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "se", "(", "out", ")", "\n", "", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "out", "+", "shortcut", "# no inplace", "\n", "out", "=", "self", ".", "act", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet.__init__": [[156, 213], ["torch.Module.__init__", "int", "int", "tresnet.conv2d_iabn", "tresnet.TResNet._make_layer", "tresnet.TResNet._make_layer", "tresnet.TResNet._make_layer", "tresnet.TResNet._make_layer", "torch.Sequential", "torch.Sequential", "layers.ClassifierHead", "tresnet.TResNet.modules", "tresnet.TResNet.modules", "collections.OrderedDict", "dict", "dict", "dict", "dict", "dict", "isinstance", "isinstance", "isinstance", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "m.weight.data.normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "layers.SpaceToDepthModule"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet._make_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet._make_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet._make_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "layers", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "width_factor", "=", "1.0", ",", "global_pool", "=", "'fast'", ",", "drop_rate", "=", "0.", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "super", "(", "TResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "aa_layer", "=", "BlurPool2d", "\n", "\n", "# TResnet stages", "\n", "self", ".", "inplanes", "=", "int", "(", "64", "*", "width_factor", ")", "\n", "self", ".", "planes", "=", "int", "(", "64", "*", "width_factor", ")", "\n", "conv1", "=", "conv2d_iabn", "(", "in_chans", "*", "16", ",", "self", ".", "planes", ",", "stride", "=", "1", ",", "kernel_size", "=", "3", ")", "\n", "layer1", "=", "self", ".", "_make_layer", "(", "\n", "BasicBlock", ",", "self", ".", "planes", ",", "layers", "[", "0", "]", ",", "stride", "=", "1", ",", "use_se", "=", "True", ",", "aa_layer", "=", "aa_layer", ")", "# 56x56", "\n", "layer2", "=", "self", ".", "_make_layer", "(", "\n", "BasicBlock", ",", "self", ".", "planes", "*", "2", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ",", "use_se", "=", "True", ",", "aa_layer", "=", "aa_layer", ")", "# 28x28", "\n", "layer3", "=", "self", ".", "_make_layer", "(", "\n", "Bottleneck", ",", "self", ".", "planes", "*", "4", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ",", "use_se", "=", "True", ",", "aa_layer", "=", "aa_layer", ")", "# 14x14", "\n", "layer4", "=", "self", ".", "_make_layer", "(", "\n", "Bottleneck", ",", "self", ".", "planes", "*", "8", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ",", "use_se", "=", "False", ",", "aa_layer", "=", "aa_layer", ")", "# 7x7", "\n", "\n", "# body", "\n", "self", ".", "body", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'SpaceToDepth'", ",", "SpaceToDepthModule", "(", ")", ")", ",", "\n", "(", "'conv1'", ",", "conv1", ")", ",", "\n", "(", "'layer1'", ",", "layer1", ")", ",", "\n", "(", "'layer2'", ",", "layer2", ")", ",", "\n", "(", "'layer3'", ",", "layer3", ")", ",", "\n", "(", "'layer4'", ",", "layer4", ")", "]", ")", ")", "\n", "\n", "self", ".", "feature_info", "=", "[", "\n", "dict", "(", "num_chs", "=", "self", ".", "planes", ",", "reduction", "=", "2", ",", "module", "=", "''", ")", ",", "# Not with S2D?", "\n", "dict", "(", "num_chs", "=", "self", ".", "planes", ",", "reduction", "=", "4", ",", "module", "=", "'body.layer1'", ")", ",", "\n", "dict", "(", "num_chs", "=", "self", ".", "planes", "*", "2", ",", "reduction", "=", "8", ",", "module", "=", "'body.layer2'", ")", ",", "\n", "dict", "(", "num_chs", "=", "self", ".", "planes", "*", "4", "*", "Bottleneck", ".", "expansion", ",", "reduction", "=", "16", ",", "module", "=", "'body.layer3'", ")", ",", "\n", "dict", "(", "num_chs", "=", "self", ".", "planes", "*", "8", "*", "Bottleneck", ".", "expansion", ",", "reduction", "=", "32", ",", "module", "=", "'body.layer4'", ")", ",", "\n", "]", "\n", "\n", "# head", "\n", "self", ".", "num_features", "=", "(", "self", ".", "planes", "*", "8", ")", "*", "Bottleneck", ".", "expansion", "\n", "self", ".", "head", "=", "ClassifierHead", "(", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "drop_rate", ")", "\n", "\n", "# model initialization", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'leaky_relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", "or", "isinstance", "(", "m", ",", "InplaceAbn", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n", "# residual connections special initialization", "\n", "", "", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "BasicBlock", ")", ":", "\n", "                ", "m", ".", "conv2", "[", "1", "]", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros_like", "(", "m", ".", "conv2", "[", "1", "]", ".", "weight", ")", ")", "# BN to zero", "\n", "", "if", "isinstance", "(", "m", ",", "Bottleneck", ")", ":", "\n", "                ", "m", ".", "conv3", "[", "1", "]", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros_like", "(", "m", ".", "conv3", "[", "1", "]", ".", "weight", ")", ")", "# BN to zero", "\n", "", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.01", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet._make_layer": [[214, 233], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "layers.append", "tresnet.conv2d_iabn", "block", "torch.AvgPool2d", "torch.AvgPool2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ",", "use_se", "=", "True", ",", "aa_layer", "=", "None", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "layers", "=", "[", "]", "\n", "if", "stride", "==", "2", ":", "\n", "# avg pooling before 1x1 conv", "\n", "                ", "layers", ".", "append", "(", "nn", ".", "AvgPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "ceil_mode", "=", "True", ",", "count_include_pad", "=", "False", ")", ")", "\n", "", "layers", "+=", "[", "conv2d_iabn", "(", "\n", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "act_layer", "=", "\"identity\"", ")", "]", "\n", "downsample", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "\n", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ",", "use_se", "=", "use_se", ",", "aa_layer", "=", "aa_layer", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "use_se", "=", "use_se", ",", "aa_layer", "=", "aa_layer", ")", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet.group_matcher": [[234, 238], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "stem", "=", "r'^body\\.conv1'", ",", "blocks", "=", "r'^body\\.layer(\\d+)'", "if", "coarse", "else", "r'^body\\.layer(\\d+)\\.(\\d+)'", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet.set_grad_checkpointing": [[239, 242], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "'gradient checkpointing not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet.get_classifier": [[243, 246], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet.reset_classifier": [[247, 250], ["layers.ClassifierHead"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'fast'", ")", ":", "\n", "        ", "self", ".", "head", "=", "ClassifierHead", "(", "\n", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "self", ".", "drop_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet.forward_features": [[251, 253], ["tresnet.TResNet.body"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "body", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet.forward_head": [[254, 256], ["tresnet.TResNet.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "return", "x", "if", "pre_logits", "else", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.TResNet.forward": [[257, 261], ["tresnet.TResNet.forward_features", "tresnet.TResNet.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet._cfg": [[20, 27], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bilinear'", ",", "\n", "'mean'", ":", "(", "0", ",", "0", ",", "0", ")", ",", "'std'", ":", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "'first_conv'", ":", "'body.conv1.0'", ",", "'classifier'", ":", "'head.fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.IABN2Float": [[51, 58], ["isinstance", "module.children", "module.float", "tresnet.IABN2Float"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.IABN2Float"], ["def", "IABN2Float", "(", "module", ":", "nn", ".", "Module", ")", "->", "nn", ".", "Module", ":", "\n", "    ", "\"\"\"If `module` is IABN don't use half precision.\"\"\"", "\n", "if", "isinstance", "(", "module", ",", "InplaceAbn", ")", ":", "\n", "        ", "module", ".", "float", "(", ")", "\n", "", "for", "child", "in", "module", ".", "children", "(", ")", ":", "\n", "        ", "IABN2Float", "(", "child", ")", "\n", "", "return", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.conv2d_iabn": [[60, 65], ["torch.Sequential", "torch.Conv2d", "layers.InplaceAbn"], "function", ["None"], ["", "def", "conv2d_iabn", "(", "ni", ",", "nf", ",", "stride", ",", "kernel_size", "=", "3", ",", "groups", "=", "1", ",", "act_layer", "=", "\"leaky_relu\"", ",", "act_param", "=", "1e-2", ")", ":", "\n", "    ", "return", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "ni", ",", "nf", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "kernel_size", "//", "2", ",", "groups", "=", "groups", ",", "bias", "=", "False", ")", ",", "\n", "InplaceAbn", "(", "nf", ",", "act_layer", "=", "act_layer", ",", "act_param", "=", "act_param", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet._create_tresnet": [[263, 268], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_tresnet", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "\n", "TResNet", ",", "variant", ",", "pretrained", ",", "\n", "feature_cfg", "=", "dict", "(", "out_indices", "=", "(", "1", ",", "2", ",", "3", ",", "4", ")", ",", "flatten_sequential", "=", "True", ")", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.tresnet_m": [[270, 274], ["dict", "tresnet._create_tresnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet._create_tresnet"], ["", "@", "register_model", "\n", "def", "tresnet_m", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "layers", "=", "[", "3", ",", "4", ",", "11", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_tresnet", "(", "'tresnet_m'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.tresnet_m_miil_in21k": [[276, 280], ["dict", "tresnet._create_tresnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet._create_tresnet"], ["", "@", "register_model", "\n", "def", "tresnet_m_miil_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "layers", "=", "[", "3", ",", "4", ",", "11", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_tresnet", "(", "'tresnet_m_miil_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.tresnet_l": [[282, 286], ["dict", "tresnet._create_tresnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet._create_tresnet"], ["", "@", "register_model", "\n", "def", "tresnet_l", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "layers", "=", "[", "4", ",", "5", ",", "18", ",", "3", "]", ",", "width_factor", "=", "1.2", ",", "**", "kwargs", ")", "\n", "return", "_create_tresnet", "(", "'tresnet_l'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.tresnet_xl": [[288, 292], ["dict", "tresnet._create_tresnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet._create_tresnet"], ["", "@", "register_model", "\n", "def", "tresnet_xl", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "layers", "=", "[", "4", ",", "5", ",", "24", ",", "3", "]", ",", "width_factor", "=", "1.3", ",", "**", "kwargs", ")", "\n", "return", "_create_tresnet", "(", "'tresnet_xl'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.tresnet_m_448": [[294, 298], ["dict", "tresnet._create_tresnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet._create_tresnet"], ["", "@", "register_model", "\n", "def", "tresnet_m_448", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "layers", "=", "[", "3", ",", "4", ",", "11", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "_create_tresnet", "(", "'tresnet_m_448'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.tresnet_l_448": [[300, 304], ["dict", "tresnet._create_tresnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet._create_tresnet"], ["", "@", "register_model", "\n", "def", "tresnet_l_448", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "layers", "=", "[", "4", ",", "5", ",", "18", ",", "3", "]", ",", "width_factor", "=", "1.2", ",", "**", "kwargs", ")", "\n", "return", "_create_tresnet", "(", "'tresnet_l_448'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet.tresnet_xl_448": [[306, 310], ["dict", "tresnet._create_tresnet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.tresnet._create_tresnet"], ["", "@", "register_model", "\n", "def", "tresnet_xl_448", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "layers", "=", "[", "4", ",", "5", ",", "24", ",", "3", "]", ",", "width_factor", "=", "1.3", ",", "**", "kwargs", ")", "\n", "return", "_create_tresnet", "(", "'tresnet_xl_448'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.Attention.__init__": [[182, 193], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "qkv_bias", "=", "False", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "dim", "%", "num_heads", "==", "0", ",", "'dim should be divisible by num_heads'", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "self", ".", "scale", "=", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", "*", "3", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.Attention.forward": [[194, 207], ["vision_transformer.Attention.qkv().reshape().permute", "vision_transformer.Attention.unbind", "vision_transformer.Attention.softmax", "vision_transformer.Attention.attn_drop", "vision_transformer.Attention.proj", "vision_transformer.Attention.proj_drop", "vision_transformer.Attention.qkv().reshape", "k.transpose", "vision_transformer.Attention.qkv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "3", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", ".", "unbind", "(", "0", ")", "# make torchscript happy (cannot use tensor as tuple)", "\n", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "*", "self", ".", "scale", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "N", ",", "C", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.LayerScale.__init__": [[210, 214], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "init_values", "=", "1e-5", ",", "inplace", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inplace", "=", "inplace", "\n", "self", ".", "gamma", "=", "nn", ".", "Parameter", "(", "init_values", "*", "torch", ".", "ones", "(", "dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.LayerScale.forward": [[215, 217], ["x.mul_"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", ".", "mul_", "(", "self", ".", "gamma", ")", "if", "self", ".", "inplace", "else", "x", "*", "self", ".", "gamma", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.Block.__init__": [[221, 236], ["torch.Module.__init__", "norm_layer", "vision_transformer.Attention", "norm_layer", "int", "layers.Mlp", "vision_transformer.LayerScale", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "vision_transformer.LayerScale", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dim", ",", "num_heads", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "init_values", "=", "None", ",", "\n", "drop_path", "=", "0.", ",", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "dim", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ")", "\n", "self", ".", "ls1", "=", "LayerScale", "(", "dim", ",", "init_values", "=", "init_values", ")", "if", "init_values", "else", "nn", ".", "Identity", "(", ")", "\n", "# NOTE: drop path for stochastic depth, we shall see if this is better than dropout here", "\n", "self", ".", "drop_path1", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "mlp_hidden_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "in_features", "=", "dim", ",", "hidden_features", "=", "mlp_hidden_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "self", ".", "ls2", "=", "LayerScale", "(", "dim", ",", "init_values", "=", "init_values", ")", "if", "init_values", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "drop_path2", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.Block.forward": [[237, 241], ["vision_transformer.Block.drop_path1", "vision_transformer.Block.drop_path2", "vision_transformer.Block.ls1", "vision_transformer.Block.ls2", "vision_transformer.Block.attn", "vision_transformer.Block.mlp", "vision_transformer.Block.norm1", "vision_transformer.Block.norm2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "drop_path1", "(", "self", ".", "ls1", "(", "self", ".", "attn", "(", "self", ".", "norm1", "(", "x", ")", ")", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path2", "(", "self", ".", "ls2", "(", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.ParallelBlock.__init__": [[245, 264], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "vision_transformer.ParallelBlock.attns.append", "vision_transformer.ParallelBlock.ffns.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "collections.OrderedDict", "collections.OrderedDict", "norm_layer", "vision_transformer.Attention", "norm_layer", "layers.Mlp", "vision_transformer.LayerScale", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "vision_transformer.LayerScale", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "int"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dim", ",", "num_heads", ",", "num_parallel", "=", "2", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "init_values", "=", "None", ",", "\n", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "drop_path", "=", "0.", ",", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_parallel", "=", "num_parallel", "\n", "self", ".", "attns", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "ffns", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "num_parallel", ")", ":", "\n", "            ", "self", ".", "attns", ".", "append", "(", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'norm'", ",", "norm_layer", "(", "dim", ")", ")", ",", "\n", "(", "'attn'", ",", "Attention", "(", "dim", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ")", ")", ",", "\n", "(", "'ls'", ",", "LayerScale", "(", "dim", ",", "init_values", "=", "init_values", ")", "if", "init_values", "else", "nn", ".", "Identity", "(", ")", ")", ",", "\n", "(", "'drop_path'", ",", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", ")", "\n", "]", ")", ")", ")", "\n", "self", ".", "ffns", ".", "append", "(", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'norm'", ",", "norm_layer", "(", "dim", ")", ")", ",", "\n", "(", "'mlp'", ",", "Mlp", "(", "dim", ",", "hidden_features", "=", "int", "(", "dim", "*", "mlp_ratio", ")", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", ")", ",", "\n", "(", "'ls'", ",", "LayerScale", "(", "dim", ",", "init_values", "=", "init_values", ")", "if", "init_values", "else", "nn", ".", "Identity", "(", ")", ")", ",", "\n", "(", "'drop_path'", ",", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", ")", "\n", "]", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.ParallelBlock._forward_jit": [[266, 270], ["torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "attn", "ffn"], "methods", ["None"], ["", "", "def", "_forward_jit", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "torch", ".", "stack", "(", "[", "attn", "(", "x", ")", "for", "attn", "in", "self", ".", "attns", "]", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "x", "=", "x", "+", "torch", ".", "stack", "(", "[", "ffn", "(", "x", ")", "for", "ffn", "in", "self", ".", "ffns", "]", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.ParallelBlock._forward": [[271, 276], ["sum", "sum", "attn", "ffn"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "_forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "sum", "(", "attn", "(", "x", ")", "for", "attn", "in", "self", ".", "attns", ")", "\n", "x", "=", "x", "+", "sum", "(", "ffn", "(", "x", ")", "for", "ffn", "in", "self", ".", "ffns", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.ParallelBlock.forward": [[277, 282], ["torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_tracing", "torch.jit.is_tracing", "torch.jit.is_tracing", "torch.jit.is_tracing", "torch.jit.is_tracing", "torch.jit.is_tracing", "torch.jit.is_tracing", "torch.jit.is_tracing", "torch.jit.is_tracing", "torch.jit.is_tracing", "torch.jit.is_tracing", "torch.jit.is_tracing", "torch.jit.is_tracing", "torch.jit.is_tracing", "torch.jit.is_tracing", "torch.jit.is_tracing", "vision_transformer.ParallelBlock._forward_jit", "vision_transformer.ParallelBlock._forward"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.ParallelBlock._forward_jit", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.ParallelBlock._forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", "or", "torch", ".", "jit", ".", "is_tracing", "(", ")", ":", "\n", "            ", "return", "self", ".", "_forward_jit", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_forward", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer.__init__": [[291, 359], ["torch.Module.__init__", "embed_layer", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "functools.partial", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "x.item", "norm_layer", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "vision_transformer.VisionTransformer._reset_representation", "norm_layer", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "vision_transformer.VisionTransformer.init_weights", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "block_fn", "range"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer._reset_representation", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.GluMlp.init_weights"], ["def", "__init__", "(", "\n", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "global_pool", "=", "'token'", ",", "\n", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "True", ",", "representation_size", "=", "None", ",", "\n", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "weight_init", "=", "''", ",", "init_values", "=", "None", ",", "\n", "embed_layer", "=", "PatchEmbed", ",", "norm_layer", "=", "None", ",", "act_layer", "=", "None", ",", "block_fn", "=", "Block", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img_size (int, tuple): input image size\n            patch_size (int, tuple): patch size\n            in_chans (int): number of input channels\n            num_classes (int): number of classes for classification head\n            global_pool (str): type of global pooling for final sequence (default: 'token')\n            embed_dim (int): embedding dimension\n            depth (int): depth of transformer\n            num_heads (int): number of attention heads\n            mlp_ratio (int): ratio of mlp hidden dim to embedding dim\n            qkv_bias (bool): enable bias for qkv if True\n            representation_size (Optional[int]): enable and set representation layer (pre-logits) to this value if set\n            drop_rate (float): dropout rate\n            attn_drop_rate (float): attention dropout rate\n            drop_path_rate (float): stochastic depth rate\n            weight_init: (str): weight init scheme\n            init_values: (float): layer-scale init values\n            embed_layer (nn.Module): patch embedding layer\n            norm_layer: (nn.Module): normalization layer\n            act_layer: (nn.Module): MLP activation layer\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "global_pool", "in", "(", "''", ",", "'avg'", ",", "'token'", ")", "\n", "norm_layer", "=", "norm_layer", "or", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", "\n", "act_layer", "=", "act_layer", "or", "nn", ".", "GELU", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "self", ".", "num_features", "=", "self", ".", "embed_dim", "=", "embed_dim", "# num_features for consistency with other models", "\n", "self", ".", "num_tokens", "=", "1", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "self", ".", "patch_embed", "=", "embed_layer", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "embed_dim", "=", "embed_dim", ")", "\n", "num_patches", "=", "self", ".", "patch_embed", ".", "num_patches", "\n", "\n", "self", ".", "cls_token", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "self", ".", "pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "num_patches", "+", "self", ".", "num_tokens", ",", "embed_dim", ")", ")", "\n", "self", ".", "pos_drop", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", "\n", "\n", "dpr", "=", "[", "x", ".", "item", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "depth", ")", "]", "# stochastic depth decay rule", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "block_fn", "(", "\n", "dim", "=", "embed_dim", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "init_values", "=", "init_values", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", "[", "i", "]", ",", "norm_layer", "=", "norm_layer", ",", "act_layer", "=", "act_layer", ")", "\n", "for", "i", "in", "range", "(", "depth", ")", "]", ")", "\n", "use_fc_norm", "=", "self", ".", "global_pool", "==", "'avg'", "\n", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "if", "not", "use_fc_norm", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "# Representation layer. Used for original ViT models w/ in21k pretraining.", "\n", "self", ".", "representation_size", "=", "representation_size", "\n", "self", ".", "pre_logits", "=", "nn", ".", "Identity", "(", ")", "\n", "if", "representation_size", ":", "\n", "            ", "self", ".", "_reset_representation", "(", "representation_size", ")", "\n", "\n", "# Classifier Head", "\n", "", "self", ".", "fc_norm", "=", "norm_layer", "(", "embed_dim", ")", "if", "use_fc_norm", "else", "nn", ".", "Identity", "(", ")", "\n", "final_chs", "=", "self", ".", "representation_size", "if", "self", ".", "representation_size", "else", "self", ".", "embed_dim", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "final_chs", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "if", "weight_init", "!=", "'skip'", ":", "\n", "            ", "self", ".", "init_weights", "(", "weight_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer._reset_representation": [[360, 369], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "collections.OrderedDict", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["None"], ["", "", "def", "_reset_representation", "(", "self", ",", "representation_size", ")", ":", "\n", "        ", "self", ".", "representation_size", "=", "representation_size", "\n", "if", "self", ".", "representation_size", ":", "\n", "            ", "self", ".", "pre_logits", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'fc'", ",", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "representation_size", ")", ")", ",", "\n", "(", "'act'", ",", "nn", ".", "Tanh", "(", ")", ")", "\n", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "pre_logits", "=", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer.init_weights": [[370, 376], ["layers.trunc_normal_", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "helpers.named_apply", "vision_transformer.get_init_weights_vit", "math.log"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_apply", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.get_init_weights_vit"], ["", "", "def", "init_weights", "(", "self", ",", "mode", "=", "''", ")", ":", "\n", "        ", "assert", "mode", "in", "(", "'jax'", ",", "'jax_nlhb'", ",", "'moco'", ",", "''", ")", "\n", "head_bias", "=", "-", "math", ".", "log", "(", "self", ".", "num_classes", ")", "if", "'nlhb'", "in", "mode", "else", "0.", "\n", "trunc_normal_", "(", "self", ".", "pos_embed", ",", "std", "=", ".02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "cls_token", ",", "std", "=", "1e-6", ")", "\n", "named_apply", "(", "get_init_weights_vit", "(", "mode", ",", "head_bias", ")", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer._init_weights": [[377, 380], ["vision_transformer.init_weights_vit_timm"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.init_weights_vit_timm"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "# this fn left here for compat with downstream users", "\n", "        ", "init_weights_vit_timm", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer.load_pretrained": [[381, 384], ["torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "torch.jit.ignore", "vision_transformer._load_weights"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._load_weights"], ["", "@", "torch", ".", "jit", ".", "ignore", "(", ")", "\n", "def", "load_pretrained", "(", "self", ",", "checkpoint_path", ",", "prefix", "=", "''", ")", ":", "\n", "        ", "_load_weights", "(", "self", ",", "checkpoint_path", ",", "prefix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer.no_weight_decay": [[385, 388], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "{", "'pos_embed'", ",", "'cls_token'", ",", "'dist_token'", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer.group_matcher": [[389, 394], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^cls_token|pos_embed|patch_embed'", ",", "# stem and embed", "\n", "blocks", "=", "[", "(", "r'^blocks\\.(\\d+)'", ",", "None", ")", ",", "(", "r'^norm'", ",", "(", "99999", ",", ")", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer.set_grad_checkpointing": [[396, 399], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer.get_classifier": [[400, 403], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer.reset_classifier": [[404, 413], ["vision_transformer.VisionTransformer._reset_representation", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer._reset_representation"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ":", "int", ",", "global_pool", "=", "None", ",", "representation_size", "=", "None", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "if", "global_pool", "is", "not", "None", ":", "\n", "            ", "assert", "global_pool", "in", "(", "''", ",", "'avg'", ",", "'token'", ")", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "", "if", "representation_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "_reset_representation", "(", "representation_size", ")", "\n", "", "final_chs", "=", "self", ".", "representation_size", "if", "self", ".", "representation_size", "else", "self", ".", "embed_dim", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "final_chs", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer.forward_features": [[414, 424], ["vision_transformer.VisionTransformer.patch_embed", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "vision_transformer.VisionTransformer.pos_drop", "vision_transformer.VisionTransformer.norm", "helpers.checkpoint_seq", "vision_transformer.VisionTransformer.blocks", "vision_transformer.VisionTransformer.cls_token.expand", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "self", ".", "cls_token", ".", "expand", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "-", "1", ")", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "x", "=", "self", ".", "pos_drop", "(", "x", "+", "self", ".", "pos_embed", ")", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "blocks", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "blocks", "(", "x", ")", "\n", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer.forward_head": [[425, 431], ["vision_transformer.VisionTransformer.fc_norm", "vision_transformer.VisionTransformer.pre_logits", "vision_transformer.VisionTransformer.head", "x[].mean"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "global_pool", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", "1", ":", "]", ".", "mean", "(", "dim", "=", "1", ")", "if", "self", ".", "global_pool", "==", "'avg'", "else", "x", "[", ":", ",", "0", "]", "\n", "", "x", "=", "self", ".", "fc_norm", "(", "x", ")", "\n", "x", "=", "self", ".", "pre_logits", "(", "x", ")", "\n", "return", "x", "if", "pre_logits", "else", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.VisionTransformer.forward": [[432, 436], ["vision_transformer.VisionTransformer.forward_features", "vision_transformer.VisionTransformer.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._cfg": [[40, 48], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", ".9", ",", "'interpolation'", ":", "'bicubic'", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'mean'", ":", "IMAGENET_INCEPTION_MEAN", ",", "'std'", ":", "IMAGENET_INCEPTION_STD", ",", "\n", "'first_conv'", ":", "'patch_embed.proj'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.init_weights_vit_timm": [[438, 444], ["isinstance", "layers.trunc_normal_", "torch.init.zeros_"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "", "def", "init_weights_vit_timm", "(", "module", ":", "nn", ".", "Module", ",", "name", ":", "str", "=", "''", ")", ":", "\n", "    ", "\"\"\" ViT weight initialization, original timm impl (for reproducibility) \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "trunc_normal_", "(", "module", ".", "weight", ",", "std", "=", ".02", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.init_weights_vit_jax": [[446, 463], ["isinstance", "name.startswith", "isinstance", "torch.init.zeros_", "torch.init.constant_", "name.startswith", "layers.lecun_normal_", "layers.lecun_normal_", "torch.init.zeros_", "torch.init.xavier_uniform_", "torch.init.zeros_", "torch.init.normal_", "torch.init.zeros_"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.lecun_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.lecun_normal_"], ["", "", "", "def", "init_weights_vit_jax", "(", "module", ":", "nn", ".", "Module", ",", "name", ":", "str", "=", "''", ",", "head_bias", ":", "float", "=", "0.", ")", ":", "\n", "    ", "\"\"\" ViT weight initialization, matching JAX (Flax) impl \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "if", "name", ".", "startswith", "(", "'head'", ")", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "weight", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "module", ".", "bias", ",", "head_bias", ")", "\n", "", "elif", "name", ".", "startswith", "(", "'pre_logits'", ")", ":", "\n", "            ", "lecun_normal_", "(", "module", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "", "else", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "module", ".", "weight", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "module", ".", "bias", ",", "std", "=", "1e-6", ")", "if", "'mlp'", "in", "name", "else", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", ":", "\n", "        ", "lecun_normal_", "(", "module", ".", "weight", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.init_weights_vit_moco": [[465, 476], ["isinstance", "math.sqrt", "torch.init.uniform_", "torch.init.xavier_uniform_", "torch.init.zeros_", "float"], "function", ["None"], ["", "", "", "def", "init_weights_vit_moco", "(", "module", ":", "nn", ".", "Module", ",", "name", ":", "str", "=", "''", ")", ":", "\n", "    ", "\"\"\" ViT weight initialization, matching moco-v3 impl minus fixed PatchEmbed \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "if", "'qkv'", "in", "name", ":", "\n", "# treat the weights of Q, K, V separately", "\n", "            ", "val", "=", "math", ".", "sqrt", "(", "6.", "/", "float", "(", "module", ".", "weight", ".", "shape", "[", "0", "]", "//", "3", "+", "module", ".", "weight", ".", "shape", "[", "1", "]", ")", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "module", ".", "weight", ",", "-", "val", ",", "val", ")", "\n", "", "else", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "module", ".", "weight", ")", "\n", "", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.get_init_weights_vit": [[478, 485], ["functools.partial"], "function", ["None"], ["", "", "", "def", "get_init_weights_vit", "(", "mode", "=", "'jax'", ",", "head_bias", ":", "float", "=", "0.", ")", ":", "\n", "    ", "if", "'jax'", "in", "mode", ":", "\n", "        ", "return", "partial", "(", "init_weights_vit_jax", ",", "head_bias", "=", "head_bias", ")", "\n", "", "elif", "'moco'", "in", "mode", ":", "\n", "        ", "return", "init_weights_vit_moco", "\n", "", "else", ":", "\n", "        ", "return", "init_weights_vit_timm", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._load_weights": [[487, 565], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "np.load", "hasattr", "model.patch_embed.proj.weight.copy_", "model.patch_embed.proj.bias.copy_", "model.cls_token.copy_", "vision_transformer._load_weights._n2p"], "function", ["None"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_load_weights", "(", "model", ":", "VisionTransformer", ",", "checkpoint_path", ":", "str", ",", "prefix", ":", "str", "=", "''", ")", ":", "\n", "    ", "\"\"\" Load weights from .npz checkpoints for official Google Brain Flax implementation\n    \"\"\"", "\n", "import", "numpy", "as", "np", "\n", "\n", "def", "_n2p", "(", "w", ",", "t", "=", "True", ")", ":", "\n", "        ", "if", "w", ".", "ndim", "==", "4", "and", "w", ".", "shape", "[", "0", "]", "==", "w", ".", "shape", "[", "1", "]", "==", "w", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "            ", "w", "=", "w", ".", "flatten", "(", ")", "\n", "", "if", "t", ":", "\n", "            ", "if", "w", ".", "ndim", "==", "4", ":", "\n", "                ", "w", "=", "w", ".", "transpose", "(", "[", "3", ",", "2", ",", "0", ",", "1", "]", ")", "\n", "", "elif", "w", ".", "ndim", "==", "3", ":", "\n", "                ", "w", "=", "w", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", "\n", "", "elif", "w", ".", "ndim", "==", "2", ":", "\n", "                ", "w", "=", "w", ".", "transpose", "(", "[", "1", ",", "0", "]", ")", "\n", "", "", "return", "torch", ".", "from_numpy", "(", "w", ")", "\n", "\n", "", "w", "=", "np", ".", "load", "(", "checkpoint_path", ")", "\n", "if", "not", "prefix", "and", "'opt/target/embedding/kernel'", "in", "w", ":", "\n", "        ", "prefix", "=", "'opt/target/'", "\n", "\n", "", "if", "hasattr", "(", "model", ".", "patch_embed", ",", "'backbone'", ")", ":", "\n", "# hybrid", "\n", "        ", "backbone", "=", "model", ".", "patch_embed", ".", "backbone", "\n", "stem_only", "=", "not", "hasattr", "(", "backbone", ",", "'stem'", ")", "\n", "stem", "=", "backbone", "if", "stem_only", "else", "backbone", ".", "stem", "\n", "stem", ".", "conv", ".", "weight", ".", "copy_", "(", "adapt_input_conv", "(", "stem", ".", "conv", ".", "weight", ".", "shape", "[", "1", "]", ",", "_n2p", "(", "w", "[", "f'{prefix}conv_root/kernel'", "]", ")", ")", ")", "\n", "stem", ".", "norm", ".", "weight", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{prefix}gn_root/scale'", "]", ")", ")", "\n", "stem", ".", "norm", ".", "bias", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{prefix}gn_root/bias'", "]", ")", ")", "\n", "if", "not", "stem_only", ":", "\n", "            ", "for", "i", ",", "stage", "in", "enumerate", "(", "backbone", ".", "stages", ")", ":", "\n", "                ", "for", "j", ",", "block", "in", "enumerate", "(", "stage", ".", "blocks", ")", ":", "\n", "                    ", "bp", "=", "f'{prefix}block{i + 1}/unit{j + 1}/'", "\n", "for", "r", "in", "range", "(", "3", ")", ":", "\n", "                        ", "getattr", "(", "block", ",", "f'conv{r + 1}'", ")", ".", "weight", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{bp}conv{r + 1}/kernel'", "]", ")", ")", "\n", "getattr", "(", "block", ",", "f'norm{r + 1}'", ")", ".", "weight", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{bp}gn{r + 1}/scale'", "]", ")", ")", "\n", "getattr", "(", "block", ",", "f'norm{r + 1}'", ")", ".", "bias", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{bp}gn{r + 1}/bias'", "]", ")", ")", "\n", "", "if", "block", ".", "downsample", "is", "not", "None", ":", "\n", "                        ", "block", ".", "downsample", ".", "conv", ".", "weight", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{bp}conv_proj/kernel'", "]", ")", ")", "\n", "block", ".", "downsample", ".", "norm", ".", "weight", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{bp}gn_proj/scale'", "]", ")", ")", "\n", "block", ".", "downsample", ".", "norm", ".", "bias", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{bp}gn_proj/bias'", "]", ")", ")", "\n", "", "", "", "", "embed_conv_w", "=", "_n2p", "(", "w", "[", "f'{prefix}embedding/kernel'", "]", ")", "\n", "", "else", ":", "\n", "        ", "embed_conv_w", "=", "adapt_input_conv", "(", "\n", "model", ".", "patch_embed", ".", "proj", ".", "weight", ".", "shape", "[", "1", "]", ",", "_n2p", "(", "w", "[", "f'{prefix}embedding/kernel'", "]", ")", ")", "\n", "", "model", ".", "patch_embed", ".", "proj", ".", "weight", ".", "copy_", "(", "embed_conv_w", ")", "\n", "model", ".", "patch_embed", ".", "proj", ".", "bias", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{prefix}embedding/bias'", "]", ")", ")", "\n", "model", ".", "cls_token", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{prefix}cls'", "]", ",", "t", "=", "False", ")", ")", "\n", "pos_embed_w", "=", "_n2p", "(", "w", "[", "f'{prefix}Transformer/posembed_input/pos_embedding'", "]", ",", "t", "=", "False", ")", "\n", "if", "pos_embed_w", ".", "shape", "!=", "model", ".", "pos_embed", ".", "shape", ":", "\n", "        ", "pos_embed_w", "=", "resize_pos_embed", "(", "# resize pos embedding when different size from pretrained weights", "\n", "pos_embed_w", ",", "model", ".", "pos_embed", ",", "getattr", "(", "model", ",", "'num_tokens'", ",", "1", ")", ",", "model", ".", "patch_embed", ".", "grid_size", ")", "\n", "", "model", ".", "pos_embed", ".", "copy_", "(", "pos_embed_w", ")", "\n", "model", ".", "norm", ".", "weight", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{prefix}Transformer/encoder_norm/scale'", "]", ")", ")", "\n", "model", ".", "norm", ".", "bias", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{prefix}Transformer/encoder_norm/bias'", "]", ")", ")", "\n", "if", "isinstance", "(", "model", ".", "head", ",", "nn", ".", "Linear", ")", "and", "model", ".", "head", ".", "bias", ".", "shape", "[", "0", "]", "==", "w", "[", "f'{prefix}head/bias'", "]", ".", "shape", "[", "-", "1", "]", ":", "\n", "        ", "model", ".", "head", ".", "weight", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{prefix}head/kernel'", "]", ")", ")", "\n", "model", ".", "head", ".", "bias", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{prefix}head/bias'", "]", ")", ")", "\n", "", "if", "isinstance", "(", "getattr", "(", "model", ".", "pre_logits", ",", "'fc'", ",", "None", ")", ",", "nn", ".", "Linear", ")", "and", "f'{prefix}pre_logits/bias'", "in", "w", ":", "\n", "        ", "model", ".", "pre_logits", ".", "fc", ".", "weight", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{prefix}pre_logits/kernel'", "]", ")", ")", "\n", "model", ".", "pre_logits", ".", "fc", ".", "bias", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{prefix}pre_logits/bias'", "]", ")", ")", "\n", "", "for", "i", ",", "block", "in", "enumerate", "(", "model", ".", "blocks", ".", "children", "(", ")", ")", ":", "\n", "        ", "block_prefix", "=", "f'{prefix}Transformer/encoderblock_{i}/'", "\n", "mha_prefix", "=", "block_prefix", "+", "'MultiHeadDotProductAttention_1/'", "\n", "block", ".", "norm1", ".", "weight", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{block_prefix}LayerNorm_0/scale'", "]", ")", ")", "\n", "block", ".", "norm1", ".", "bias", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{block_prefix}LayerNorm_0/bias'", "]", ")", ")", "\n", "block", ".", "attn", ".", "qkv", ".", "weight", ".", "copy_", "(", "torch", ".", "cat", "(", "[", "\n", "_n2p", "(", "w", "[", "f'{mha_prefix}{n}/kernel'", "]", ",", "t", "=", "False", ")", ".", "flatten", "(", "1", ")", ".", "T", "for", "n", "in", "(", "'query'", ",", "'key'", ",", "'value'", ")", "]", ")", ")", "\n", "block", ".", "attn", ".", "qkv", ".", "bias", ".", "copy_", "(", "torch", ".", "cat", "(", "[", "\n", "_n2p", "(", "w", "[", "f'{mha_prefix}{n}/bias'", "]", ",", "t", "=", "False", ")", ".", "reshape", "(", "-", "1", ")", "for", "n", "in", "(", "'query'", ",", "'key'", ",", "'value'", ")", "]", ")", ")", "\n", "block", ".", "attn", ".", "proj", ".", "weight", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{mha_prefix}out/kernel'", "]", ")", ".", "flatten", "(", "1", ")", ")", "\n", "block", ".", "attn", ".", "proj", ".", "bias", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{mha_prefix}out/bias'", "]", ")", ")", "\n", "for", "r", "in", "range", "(", "2", ")", ":", "\n", "            ", "getattr", "(", "block", ".", "mlp", ",", "f'fc{r + 1}'", ")", ".", "weight", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{block_prefix}MlpBlock_3/Dense_{r}/kernel'", "]", ")", ")", "\n", "getattr", "(", "block", ".", "mlp", ",", "f'fc{r + 1}'", ")", ".", "bias", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{block_prefix}MlpBlock_3/Dense_{r}/bias'", "]", ")", ")", "\n", "", "block", ".", "norm2", ".", "weight", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{block_prefix}LayerNorm_2/scale'", "]", ")", ")", "\n", "block", ".", "norm2", ".", "bias", ".", "copy_", "(", "_n2p", "(", "w", "[", "f'{block_prefix}LayerNorm_2/bias'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.resize_pos_embed": [[567, 587], ["_logger.info", "int", "_logger.info", "posemb_grid.permute().reshape.reshape().permute", "torch.interpolate", "posemb_grid.permute().reshape.permute().reshape", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "math.sqrt", "len", "len", "len", "posemb_grid.permute().reshape.reshape", "posemb_grid.permute().reshape.permute", "int", "math.sqrt"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate"], ["", "", "def", "resize_pos_embed", "(", "posemb", ",", "posemb_new", ",", "num_tokens", "=", "1", ",", "gs_new", "=", "(", ")", ")", ":", "\n", "# Rescale the grid of position embeddings when loading from state_dict. Adapted from", "\n", "# https://github.com/google-research/vision_transformer/blob/00883dd691c63a6830751563748663526e811cee/vit_jax/checkpoint.py#L224", "\n", "    ", "_logger", ".", "info", "(", "'Resized position embedding: %s to %s'", ",", "posemb", ".", "shape", ",", "posemb_new", ".", "shape", ")", "\n", "ntok_new", "=", "posemb_new", ".", "shape", "[", "1", "]", "\n", "if", "num_tokens", ":", "\n", "        ", "posemb_tok", ",", "posemb_grid", "=", "posemb", "[", ":", ",", ":", "num_tokens", "]", ",", "posemb", "[", "0", ",", "num_tokens", ":", "]", "\n", "ntok_new", "-=", "num_tokens", "\n", "", "else", ":", "\n", "        ", "posemb_tok", ",", "posemb_grid", "=", "posemb", "[", ":", ",", ":", "0", "]", ",", "posemb", "[", "0", "]", "\n", "", "gs_old", "=", "int", "(", "math", ".", "sqrt", "(", "len", "(", "posemb_grid", ")", ")", ")", "\n", "if", "not", "len", "(", "gs_new", ")", ":", "# backwards compatibility", "\n", "        ", "gs_new", "=", "[", "int", "(", "math", ".", "sqrt", "(", "ntok_new", ")", ")", "]", "*", "2", "\n", "", "assert", "len", "(", "gs_new", ")", ">=", "2", "\n", "_logger", ".", "info", "(", "'Position embedding grid-size from %s to %s'", ",", "[", "gs_old", ",", "gs_old", "]", ",", "gs_new", ")", "\n", "posemb_grid", "=", "posemb_grid", ".", "reshape", "(", "1", ",", "gs_old", ",", "gs_old", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "posemb_grid", "=", "F", ".", "interpolate", "(", "posemb_grid", ",", "size", "=", "gs_new", ",", "mode", "=", "'bicubic'", ",", "align_corners", "=", "False", ")", "\n", "posemb_grid", "=", "posemb_grid", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "reshape", "(", "1", ",", "gs_new", "[", "0", "]", "*", "gs_new", "[", "1", "]", ",", "-", "1", ")", "\n", "posemb", "=", "torch", ".", "cat", "(", "[", "posemb_tok", ",", "posemb_grid", "]", ",", "dim", "=", "1", ")", "\n", "return", "posemb", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.checkpoint_filter_fn": [[589, 606], ["state_dict.items", "resize_pos_embed.reshape", "len", "vision_transformer.resize_pos_embed", "getattr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.resize_pos_embed"], ["", "def", "checkpoint_filter_fn", "(", "state_dict", ",", "model", ")", ":", "\n", "    ", "\"\"\" convert patch embedding weight from manual patchify + linear proj to conv\"\"\"", "\n", "out_dict", "=", "{", "}", "\n", "if", "'model'", "in", "state_dict", ":", "\n", "# For deit models", "\n", "        ", "state_dict", "=", "state_dict", "[", "'model'", "]", "\n", "", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "'patch_embed.proj.weight'", "in", "k", "and", "len", "(", "v", ".", "shape", ")", "<", "4", ":", "\n", "# For old models that I trained prior to conv based patchification", "\n", "            ", "O", ",", "I", ",", "H", ",", "W", "=", "model", ".", "patch_embed", ".", "proj", ".", "weight", ".", "shape", "\n", "v", "=", "v", ".", "reshape", "(", "O", ",", "-", "1", ",", "H", ",", "W", ")", "\n", "", "elif", "k", "==", "'pos_embed'", "and", "v", ".", "shape", "!=", "model", ".", "pos_embed", ".", "shape", ":", "\n", "# To resize pos embedding when using model at different size from pretrained weights", "\n", "            ", "v", "=", "resize_pos_embed", "(", "\n", "v", ",", "model", ".", "pos_embed", ",", "getattr", "(", "model", ",", "'num_tokens'", ",", "1", ")", ",", "model", ".", "patch_embed", ".", "grid_size", ")", "\n", "", "out_dict", "[", "k", "]", "=", "v", "\n", "", "return", "out_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer": [[608, 631], ["kwargs.get", "helpers.resolve_pretrained_cfg", "kwargs.get", "kwargs.pop", "helpers.build_model_with_cfg", "RuntimeError", "_logger.warning"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.resolve_pretrained_cfg", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "def", "_create_vision_transformer", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", ".", "get", "(", "'features_only'", ",", "None", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'features_only not implemented for Vision Transformer models.'", ")", "\n", "\n", "# NOTE this extra code to support handling of repr size for in21k pretrained models", "\n", "", "pretrained_cfg", "=", "resolve_pretrained_cfg", "(", "variant", ",", "kwargs", "=", "kwargs", ")", "\n", "default_num_classes", "=", "pretrained_cfg", "[", "'num_classes'", "]", "\n", "num_classes", "=", "kwargs", ".", "get", "(", "'num_classes'", ",", "default_num_classes", ")", "\n", "repr_size", "=", "kwargs", ".", "pop", "(", "'representation_size'", ",", "None", ")", "\n", "if", "repr_size", "is", "not", "None", "and", "num_classes", "!=", "default_num_classes", ":", "\n", "# Remove representation layer if fine-tuning. This may not always be the desired action,", "\n", "# but I feel better than doing nothing by default for fine-tuning. Perhaps a better interface?", "\n", "        ", "_logger", ".", "warning", "(", "\"Removing representation layer for fine-tuning.\"", ")", "\n", "repr_size", "=", "None", "\n", "\n", "", "model", "=", "build_model_with_cfg", "(", "\n", "VisionTransformer", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_cfg", "=", "pretrained_cfg", ",", "\n", "representation_size", "=", "repr_size", ",", "\n", "pretrained_filter_fn", "=", "checkpoint_filter_fn", ",", "\n", "pretrained_custom_load", "=", "'npz'", "in", "pretrained_cfg", "[", "'url'", "]", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_tiny_patch16_224": [[633, 640], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_tiny_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Tiny (Vit-Ti/16)\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "3", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_tiny_patch16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_tiny_patch16_384": [[642, 649], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_tiny_patch16_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Tiny (Vit-Ti/16) @ 384x384.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "3", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_tiny_patch16_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_small_patch32_224": [[651, 658], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_small_patch32_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Small (ViT-S/32)\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "32", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_small_patch32_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_small_patch32_384": [[660, 667], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_small_patch32_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Small (ViT-S/32) at 384x384.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "32", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_small_patch32_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_small_patch16_224": [[669, 677], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_small_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Small (ViT-S/16)\n    NOTE I've replaced my previous 'small' model definition and weights with the small variant from the DeiT paper\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_small_patch16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_small_patch16_384": [[679, 687], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_small_patch16_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Small (ViT-S/16)\n    NOTE I've replaced my previous 'small' model definition and weights with the small variant from the DeiT paper\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_small_patch16_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_base_patch32_224": [[689, 697], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_base_patch32_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base (ViT-B/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "32", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_base_patch32_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_base2_patch32_256": [[699, 707], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_base2_patch32_256", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base (ViT-B/32)\n    # FIXME experiment\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "32", ",", "embed_dim", "=", "896", ",", "depth", "=", "12", ",", "num_heads", "=", "14", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_base2_patch32_256'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_base_patch32_384": [[709, 717], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_base_patch32_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base model (ViT-B/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 384x384, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "32", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_base_patch32_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_base_patch16_224": [[719, 727], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_base_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 224x224, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_base_patch16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_base_patch16_384": [[729, 737], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_base_patch16_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base model (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 384x384, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_base_patch16_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_base_patch8_224": [[739, 747], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_base_patch8_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base (ViT-B/8) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 224x224, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "8", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_base_patch8_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_large_patch32_224": [[749, 756], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_large_patch32_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Large model (ViT-L/32) from original paper (https://arxiv.org/abs/2010.11929). No pretrained weights.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "32", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_large_patch32_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_large_patch32_384": [[758, 766], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_large_patch32_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Large model (ViT-L/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 384x384, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "32", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_large_patch32_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_large_patch16_224": [[768, 776], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_large_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Large model (ViT-L/16) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 224x224, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_large_patch16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_large_patch16_384": [[778, 786], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_large_patch16_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Large model (ViT-L/16) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 384x384, source https://github.com/google-research/vision_transformer.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_large_patch16_384'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_large_patch14_224": [[788, 795], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_large_patch14_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Large model (ViT-L/14)\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "14", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_large_patch14_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_huge_patch14_224": [[797, 804], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_huge_patch14_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Huge model (ViT-H/14) from original paper (https://arxiv.org/abs/2010.11929).\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "14", ",", "embed_dim", "=", "1280", ",", "depth", "=", "32", ",", "num_heads", "=", "16", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_huge_patch14_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_giant_patch14_224": [[806, 813], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_giant_patch14_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Giant model (ViT-g/14) from `Scaling Vision Transformers` - https://arxiv.org/abs/2106.04560\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "14", ",", "embed_dim", "=", "1408", ",", "mlp_ratio", "=", "48", "/", "11", ",", "depth", "=", "40", ",", "num_heads", "=", "16", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_giant_patch14_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_gigantic_patch14_224": [[815, 822], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_gigantic_patch14_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Gigantic model (ViT-G/14) from `Scaling Vision Transformers` - https://arxiv.org/abs/2106.04560\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "14", ",", "embed_dim", "=", "1664", ",", "mlp_ratio", "=", "64", "/", "13", ",", "depth", "=", "48", ",", "num_heads", "=", "16", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_gigantic_patch14_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_tiny_patch16_224_in21k": [[824, 833], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_tiny_patch16_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Tiny (Vit-Ti/16).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has valid 21k classifier head and no representation (pre-logits) layer\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "3", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_tiny_patch16_224_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_small_patch32_224_in21k": [[835, 844], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_small_patch32_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Small (ViT-S/16)\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has valid 21k classifier head and no representation (pre-logits) layer\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "32", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_small_patch32_224_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_small_patch16_224_in21k": [[846, 855], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_small_patch16_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Small (ViT-S/16)\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has valid 21k classifier head and no representation (pre-logits) layer\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_small_patch16_224_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_base_patch32_224_in21k": [[857, 867], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_base_patch32_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base model (ViT-B/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has valid 21k classifier head and no representation (pre-logits) layer\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "32", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_base_patch32_224_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_base_patch16_224_in21k": [[869, 879], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_base_patch16_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base model (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has valid 21k classifier head and no representation (pre-logits) layer\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_base_patch16_224_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_base_patch8_224_in21k": [[881, 891], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_base_patch8_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base model (ViT-B/8) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has valid 21k classifier head and no representation (pre-logits) layer\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_base_patch8_224_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_large_patch32_224_in21k": [[893, 903], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_large_patch32_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Large model (ViT-L/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has a representation layer but the 21k classifier head is zero'd out in original weights\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "32", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "representation_size", "=", "1024", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_large_patch32_224_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_large_patch16_224_in21k": [[905, 915], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_large_patch16_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Large model (ViT-L/16) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has valid 21k classifier head and no representation (pre-logits) layer\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_large_patch16_224_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_huge_patch14_224_in21k": [[917, 927], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_huge_patch14_224_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Huge model (ViT-H/14) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has a representation layer but the 21k classifier head is zero'd out in original weights\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "14", ",", "embed_dim", "=", "1280", ",", "depth", "=", "32", ",", "num_heads", "=", "16", ",", "representation_size", "=", "1280", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_huge_patch14_224_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_base_patch16_224_sam": [[929, 937], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_base_patch16_224_sam", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base (ViT-B/16) w/ SAM pretrained weights. Paper: https://arxiv.org/abs/2106.01548\n    \"\"\"", "\n", "# NOTE original SAM weights release worked with representation_size=768", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_base_patch16_224_sam'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_base_patch32_224_sam": [[939, 947], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_base_patch32_224_sam", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base (ViT-B/32) w/ SAM pretrained weights. Paper: https://arxiv.org/abs/2106.01548\n    \"\"\"", "\n", "# NOTE original SAM weights release worked with representation_size=768", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "32", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_base_patch32_224_sam'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_small_patch16_224_dino": [[949, 956], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_small_patch16_224_dino", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Small (ViT-S/16) w/ DINO pretrained weights (no head) - https://arxiv.org/abs/2104.14294\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_small_patch16_224_dino'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_small_patch8_224_dino": [[958, 965], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_small_patch8_224_dino", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Small (ViT-S/8) w/ DINO pretrained weights (no head) - https://arxiv.org/abs/2104.14294\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "8", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_small_patch8_224_dino'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_base_patch16_224_dino": [[967, 974], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_base_patch16_224_dino", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base (ViT-B/16) /w DINO pretrained weights (no head) - https://arxiv.org/abs/2104.14294\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_base_patch16_224_dino'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_base_patch8_224_dino": [[976, 983], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_base_patch8_224_dino", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base (ViT-B/8) w/ DINO pretrained weights (no head) - https://arxiv.org/abs/2104.14294\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "8", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_base_patch8_224_dino'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_base_patch16_224_miil_in21k": [[985, 993], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_base_patch16_224_miil_in21k", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).\n    Weights taken from: https://github.com/Alibaba-MIIL/ImageNet21K\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "qkv_bias", "=", "False", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_base_patch16_224_miil_in21k'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_base_patch16_224_miil": [[995, 1003], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_base_patch16_224_miil", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).\n    Weights taken from: https://github.com/Alibaba-MIIL/ImageNet21K\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "qkv_bias", "=", "False", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_base_patch16_224_miil'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_small_patch16_36x1_224": [[1005, 1014], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_small_patch16_36x1_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base w/ LayerScale + 36 x 1 (36 block serial) config. Experimental, may remove.\n    Based on `Three things everyone should know about Vision Transformers` - https://arxiv.org/abs/2203.09795\n    Paper focuses on 24x2 + 48x1 for 'Small' width but those are extremely slow.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "36", ",", "num_heads", "=", "6", ",", "init_values", "=", "1e-5", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_small_patch16_36x1_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_small_patch16_18x2_224": [[1016, 1026], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_small_patch16_18x2_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Small w/ LayerScale + 18 x 2 (36 block parallel) config. Experimental, may remove.\n    Based on `Three things everyone should know about Vision Transformers` - https://arxiv.org/abs/2203.09795\n    Paper focuses on 24x2 + 48x1 for 'Small' width but those are extremely slow.\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "18", ",", "num_heads", "=", "6", ",", "init_values", "=", "1e-5", ",", "block_fn", "=", "ParallelBlock", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_small_patch16_18x2_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer.vit_base_patch16_18x2_224": [[1028, 1037], ["dict", "vision_transformer._create_vision_transformer"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.vision_transformer._create_vision_transformer"], ["", "@", "register_model", "\n", "def", "vit_base_patch16_18x2_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ViT-Base w/ LayerScale + 18 x 2 (36 block parallel) config. Experimental, may remove.\n    Based on `Three things everyone should know about Vision Transformers` - https://arxiv.org/abs/2203.09795\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "18", ",", "num_heads", "=", "12", ",", "init_values", "=", "1e-5", ",", "block_fn", "=", "ParallelBlock", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_vision_transformer", "(", "'vit_base_patch16_18x2_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.Attention.__init__": [[68, 78], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "qkv_bias", "=", "False", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "self", ".", "scale", "=", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "3", "*", "dim", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.Attention.forward": [[79, 97], ["nest.Attention.qkv().reshape().permute", "nest.Attention.unbind", "nest.Attention.softmax", "nest.Attention.attn_drop", "nest.Attention.proj", "nest.Attention.proj_drop", "nest.Attention.qkv().reshape", "k.transpose", "nest.Attention.qkv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        x is shape: B (batch_size), T (image blocks), N (seq length per image block), C (embed dim)\n        \"\"\"", "\n", "B", ",", "T", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "# result of next line is (qkv, B, num (H)eads, T, N, (C')hannels per head)", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "B", ",", "T", ",", "N", ",", "3", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "3", ",", "0", ",", "4", ",", "1", ",", "2", ",", "5", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", ".", "unbind", "(", "0", ")", "# make torchscript happy (cannot use tensor as tuple)", "\n", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "*", "self", ".", "scale", "# (B, H, T, N, N)", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "# (B, H, T, N, C'), permute -> (B, T, N, C', H)", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "4", ",", "1", ")", ".", "reshape", "(", "B", ",", "T", ",", "N", ",", "C", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "# (B, T, N, C)", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.TransformerLayer.__init__": [[105, 114], ["torch.nn.Module.__init__", "norm_layer", "nest.Attention", "norm_layer", "int", "layers.Mlp", "layers.DropPath", "torch.nn.Identity", "torch.nn.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "num_heads", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "drop_path", "=", "0.", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "dim", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "mlp_hidden_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "in_features", "=", "dim", ",", "hidden_features", "=", "mlp_hidden_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.TransformerLayer.forward": [[115, 120], ["nest.TransformerLayer.norm1", "nest.TransformerLayer.drop_path", "nest.TransformerLayer.drop_path", "nest.TransformerLayer.attn", "nest.TransformerLayer.mlp", "nest.TransformerLayer.norm2"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "y", "=", "self", ".", "norm1", "(", "x", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "attn", "(", "y", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.ConvPool.__init__": [[123, 128], ["torch.nn.Module.__init__", "layers.create_conv2d", "norm_layer", "layers.create_pool2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "norm_layer", ",", "pad_type", "=", "''", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "create_conv2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "pad_type", ",", "bias", "=", "True", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "out_channels", ")", "\n", "self", ".", "pool", "=", "create_pool2d", "(", "'max'", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "pad_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.ConvPool.forward": [[129, 140], ["layers._assert", "layers._assert", "nest.ConvPool.conv", "nest.ConvPool.norm().permute", "nest.ConvPool.pool", "nest.ConvPool.norm", "nest.ConvPool.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        x is expected to have shape (B, C, H, W)\n        \"\"\"", "\n", "_assert", "(", "x", ".", "shape", "[", "-", "2", "]", "%", "2", "==", "0", ",", "'BlockAggregation requires even input spatial dims'", ")", "\n", "_assert", "(", "x", ".", "shape", "[", "-", "1", "]", "%", "2", "==", "0", ",", "'BlockAggregation requires even input spatial dims'", ")", "\n", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "# Layer norm done over channel dim only", "\n", "x", "=", "self", ".", "norm", "(", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "return", "x", "# (B, C, H//2, W//2)", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.NestLevel.__init__": [[176, 200], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "len", "torch.nn.Sequential", "torch.nn.Sequential", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "nest.ConvPool", "torch.nn.Identity", "torch.nn.Identity", "len", "nest.TransformerLayer", "range"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "num_blocks", ",", "block_size", ",", "seq_length", ",", "num_heads", ",", "depth", ",", "embed_dim", ",", "prev_embed_dim", "=", "None", ",", "\n", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "True", ",", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "drop_path_rates", "=", "[", "]", ",", "\n", "norm_layer", "=", "None", ",", "act_layer", "=", "None", ",", "pad_type", "=", "''", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "block_size", "=", "block_size", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "self", ".", "pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "num_blocks", ",", "seq_length", ",", "embed_dim", ")", ")", "\n", "\n", "if", "prev_embed_dim", "is", "not", "None", ":", "\n", "            ", "self", ".", "pool", "=", "ConvPool", "(", "prev_embed_dim", ",", "embed_dim", ",", "norm_layer", "=", "norm_layer", ",", "pad_type", "=", "pad_type", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "pool", "=", "nn", ".", "Identity", "(", ")", "\n", "\n", "# Transformer encoder", "\n", "", "if", "len", "(", "drop_path_rates", ")", ":", "\n", "            ", "assert", "len", "(", "drop_path_rates", ")", "==", "depth", ",", "'Must provide as many drop path rates as there are transformer layers'", "\n", "", "self", ".", "transformer_encoder", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "TransformerLayer", "(", "\n", "dim", "=", "embed_dim", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "drop_path_rates", "[", "i", "]", ",", "\n", "norm_layer", "=", "norm_layer", ",", "act_layer", "=", "act_layer", ")", "\n", "for", "i", "in", "range", "(", "depth", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.NestLevel.forward": [[201, 216], ["nest.NestLevel.pool", "nest.NestLevel.permute", "nest.blockify", "nest.deblockify", "nest.NestLevel.permute", "helpers.checkpoint_seq", "nest.NestLevel.transformer_encoder", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.blockify", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.deblockify", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        expects x as (B, C, H, W)\n        \"\"\"", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "# (B, H', W', C), switch to channels last for transformer", "\n", "x", "=", "blockify", "(", "x", ",", "self", ".", "block_size", ")", "# (B, T, N, C')", "\n", "x", "=", "x", "+", "self", ".", "pos_embed", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "transformer_encoder", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "transformer_encoder", "(", "x", ")", "# (B, T, N, C')", "\n", "", "x", "=", "deblockify", "(", "x", ",", "self", ".", "block_size", ")", "# (B, H', W', C')", "\n", "# Channel-first for block aggregation, and generally to replicate convnet feature map at each stage", "\n", "return", "x", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "# (B, C, H', W')", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.Nest.__init__": [[225, 319], ["torch.nn.Module.__init__", "isinstance", "int", "layers.PatchEmbed", "range", "torch.nn.Sequential", "torch.nn.Sequential", "norm_layer", "layers.create_classifier", "nest.Nest.init_weights", "isinstance", "layers.to_ntuple", "layers.to_ntuple", "layers.to_ntuple", "functools.partial", "x.tolist", "len", "levels.append", "locals", "math.sqrt", "math.sqrt", "torch.linspace().split", "torch.linspace().split", "torch.linspace().split", "torch.linspace().split", "nest.NestLevel", "dict", "len", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "sum"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.GluMlp.init_weights"], ["def", "__init__", "(", "\n", "self", ",", "img_size", "=", "224", ",", "in_chans", "=", "3", ",", "patch_size", "=", "4", ",", "num_levels", "=", "3", ",", "embed_dims", "=", "(", "128", ",", "256", ",", "512", ")", ",", "\n", "num_heads", "=", "(", "4", ",", "8", ",", "16", ")", ",", "depths", "=", "(", "2", ",", "2", ",", "20", ")", ",", "num_classes", "=", "1000", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "True", ",", "\n", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.5", ",", "norm_layer", "=", "None", ",", "act_layer", "=", "None", ",", "\n", "pad_type", "=", "''", ",", "weight_init", "=", "''", ",", "global_pool", "=", "'avg'", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img_size (int, tuple): input image size\n            in_chans (int): number of input channels\n            patch_size (int): patch size\n            num_levels (int): number of block hierarchies (T_d in the paper)\n            embed_dims (int, tuple): embedding dimensions of each level\n            num_heads (int, tuple): number of attention heads for each level\n            depths (int, tuple): number of transformer layers for each level\n            num_classes (int): number of classes for classification head\n            mlp_ratio (int): ratio of mlp hidden dim to embedding dim for MLP of transformer layers\n            qkv_bias (bool): enable bias for qkv if True\n            drop_rate (float): dropout rate for MLP of transformer layers, MSA final projection layer, and classifier\n            attn_drop_rate (float): attention dropout rate\n            drop_path_rate (float): stochastic depth rate\n            norm_layer: (nn.Module): normalization layer for transformer layers\n            act_layer: (nn.Module): activation layer in MLP of transformer layers\n            pad_type: str: Type of padding to use '' for PyTorch symmetric, 'same' for TF SAME\n            weight_init: (str): weight init scheme\n            global_pool: (str): type of pooling operation to apply to final feature map\n\n        Notes:\n            - Default values follow NesT-B from the original Jax code.\n            - `embed_dims`, `num_heads`, `depths` should be ints or tuples with length `num_levels`.\n            - For those following the paper, Table A1 may have errors!\n                - https://github.com/google-research/nested-transformer/issues/2\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "for", "param_name", "in", "[", "'embed_dims'", ",", "'num_heads'", ",", "'depths'", "]", ":", "\n", "            ", "param_value", "=", "locals", "(", ")", "[", "param_name", "]", "\n", "if", "isinstance", "(", "param_value", ",", "collections", ".", "abc", ".", "Sequence", ")", ":", "\n", "                ", "assert", "len", "(", "param_value", ")", "==", "num_levels", ",", "f'Require `len({param_name}) == num_levels`'", "\n", "\n", "", "", "embed_dims", "=", "to_ntuple", "(", "num_levels", ")", "(", "embed_dims", ")", "\n", "num_heads", "=", "to_ntuple", "(", "num_levels", ")", "(", "num_heads", ")", "\n", "depths", "=", "to_ntuple", "(", "num_levels", ")", "(", "depths", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_features", "=", "embed_dims", "[", "-", "1", "]", "\n", "self", ".", "feature_info", "=", "[", "]", "\n", "norm_layer", "=", "norm_layer", "or", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", "\n", "act_layer", "=", "act_layer", "or", "nn", ".", "GELU", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "num_levels", "=", "num_levels", "\n", "if", "isinstance", "(", "img_size", ",", "collections", ".", "abc", ".", "Sequence", ")", ":", "\n", "            ", "assert", "img_size", "[", "0", "]", "==", "img_size", "[", "1", "]", ",", "'Model only handles square inputs'", "\n", "img_size", "=", "img_size", "[", "0", "]", "\n", "", "assert", "img_size", "%", "patch_size", "==", "0", ",", "'`patch_size` must divide `img_size` evenly'", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "\n", "# Number of blocks at each level", "\n", "self", ".", "num_blocks", "=", "(", "4", "**", "torch", ".", "arange", "(", "num_levels", ")", ")", ".", "flip", "(", "0", ")", ".", "tolist", "(", ")", "\n", "assert", "(", "img_size", "//", "patch_size", ")", "%", "math", ".", "sqrt", "(", "self", ".", "num_blocks", "[", "0", "]", ")", "==", "0", ",", "'First level blocks don\\'t fit evenly. Check `img_size`, `patch_size`, and `num_levels`'", "\n", "\n", "# Block edge size in units of patches", "\n", "# Hint: (img_size // patch_size) gives number of patches along edge of image. sqrt(self.num_blocks[0]) is the", "\n", "#  number of blocks along edge of image", "\n", "self", ".", "block_size", "=", "int", "(", "(", "img_size", "//", "patch_size", ")", "//", "math", ".", "sqrt", "(", "self", ".", "num_blocks", "[", "0", "]", ")", ")", "\n", "\n", "# Patch embedding", "\n", "self", ".", "patch_embed", "=", "PatchEmbed", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "embed_dim", "=", "embed_dims", "[", "0", "]", ",", "flatten", "=", "False", ")", "\n", "self", ".", "num_patches", "=", "self", ".", "patch_embed", ".", "num_patches", "\n", "self", ".", "seq_length", "=", "self", ".", "num_patches", "//", "self", ".", "num_blocks", "[", "0", "]", "\n", "\n", "# Build up each hierarchical level", "\n", "levels", "=", "[", "]", "\n", "dp_rates", "=", "[", "x", ".", "tolist", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "sum", "(", "depths", ")", ")", ".", "split", "(", "depths", ")", "]", "\n", "prev_dim", "=", "None", "\n", "curr_stride", "=", "4", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "num_blocks", ")", ")", ":", "\n", "            ", "dim", "=", "embed_dims", "[", "i", "]", "\n", "levels", ".", "append", "(", "NestLevel", "(", "\n", "self", ".", "num_blocks", "[", "i", "]", ",", "self", ".", "block_size", ",", "self", ".", "seq_length", ",", "num_heads", "[", "i", "]", ",", "depths", "[", "i", "]", ",", "dim", ",", "prev_dim", ",", "\n", "mlp_ratio", ",", "qkv_bias", ",", "drop_rate", ",", "attn_drop_rate", ",", "dp_rates", "[", "i", "]", ",", "norm_layer", ",", "act_layer", ",", "pad_type", "=", "pad_type", ")", ")", "\n", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "dim", ",", "reduction", "=", "curr_stride", ",", "module", "=", "f'levels.{i}'", ")", "]", "\n", "prev_dim", "=", "dim", "\n", "curr_stride", "*=", "2", "\n", "", "self", ".", "levels", "=", "nn", ".", "Sequential", "(", "*", "levels", ")", "\n", "\n", "# Final normalization layer", "\n", "self", ".", "norm", "=", "norm_layer", "(", "embed_dims", "[", "-", "1", "]", ")", "\n", "\n", "# Classifier", "\n", "self", ".", "global_pool", ",", "self", ".", "head", "=", "create_classifier", "(", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n", "self", ".", "init_weights", "(", "weight_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.Nest.init_weights": [[320, 327], ["helpers.named_apply", "layers.trunc_normal_", "functools.partial", "math.log"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_apply", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "init_weights", "(", "self", ",", "mode", "=", "''", ")", ":", "\n", "        ", "assert", "mode", "in", "(", "'nlhb'", ",", "''", ")", "\n", "head_bias", "=", "-", "math", ".", "log", "(", "self", ".", "num_classes", ")", "if", "'nlhb'", "in", "mode", "else", "0.", "\n", "for", "level", "in", "self", ".", "levels", ":", "\n", "            ", "trunc_normal_", "(", "level", ".", "pos_embed", ",", "std", "=", ".02", ",", "a", "=", "-", "2", ",", "b", "=", "2", ")", "\n", "", "named_apply", "(", "partial", "(", "_init_nest_weights", ",", "head_bias", "=", "head_bias", ")", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.Nest.no_weight_decay": [[328, 331], ["range", "len"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "{", "f'level.{i}.pos_embed'", "for", "i", "in", "range", "(", "len", "(", "self", ".", "levels", ")", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.Nest.group_matcher": [[332, 343], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem", "=", "r'^patch_embed'", ",", "# stem and embed", "\n", "blocks", "=", "[", "\n", "(", "r'^levels\\.(\\d+)'", "if", "coarse", "else", "r'^levels\\.(\\d+)\\.transformer_encoder\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^levels\\.(\\d+)\\.(?:pool|pos_embed)'", ",", "(", "0", ",", ")", ")", ",", "\n", "(", "r'^norm'", ",", "(", "99999", ",", ")", ")", "\n", "]", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.Nest.set_grad_checkpointing": [[344, 348], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "for", "l", "in", "self", ".", "levels", ":", "\n", "            ", "l", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.Nest.get_classifier": [[349, 352], ["None"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.Nest.reset_classifier": [[353, 357], ["layers.create_classifier"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", ",", "self", ".", "head", "=", "create_classifier", "(", "\n", "self", ".", "num_features", ",", "self", ".", "num_classes", ",", "pool_type", "=", "global_pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.Nest.forward_features": [[358, 364], ["nest.Nest.patch_embed", "nest.Nest.levels", "nest.Nest.norm().permute", "nest.Nest.norm", "nest.Nest.permute"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "x", "=", "self", ".", "levels", "(", "x", ")", "\n", "# Layer norm done over channel dim only (to NHWC and back)", "\n", "x", "=", "self", ".", "norm", "(", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.Nest.forward_head": [[365, 370], ["nest.Nest.global_pool", "torch.dropout", "torch.dropout", "nest.Nest.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ">", "0.", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.Nest.forward": [[371, 375], ["nest.Nest.forward_features", "nest.Nest.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest._cfg": [[38, 46], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "[", "14", ",", "14", "]", ",", "\n", "'crop_pct'", ":", ".875", ",", "'interpolation'", ":", "'bicubic'", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'patch_embed.proj'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.blockify": [[142, 156], ["layers._assert", "layers._assert", "x.transpose().reshape.reshape", "x.transpose().reshape.transpose().reshape", "x.transpose().reshape.transpose"], "function", ["None"], ["", "", "def", "blockify", "(", "x", ",", "block_size", ":", "int", ")", ":", "\n", "    ", "\"\"\"image to blocks\n    Args:\n        x (Tensor): with shape (B, H, W, C)\n        block_size (int): edge length of a single square block in units of H, W\n    \"\"\"", "\n", "B", ",", "H", ",", "W", ",", "C", "=", "x", ".", "shape", "\n", "_assert", "(", "H", "%", "block_size", "==", "0", ",", "'`block_size` must divide input height evenly'", ")", "\n", "_assert", "(", "W", "%", "block_size", "==", "0", ",", "'`block_size` must divide input width evenly'", ")", "\n", "grid_height", "=", "H", "//", "block_size", "\n", "grid_width", "=", "W", "//", "block_size", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "grid_height", ",", "block_size", ",", "grid_width", ",", "block_size", ",", "C", ")", "\n", "x", "=", "x", ".", "transpose", "(", "2", ",", "3", ")", ".", "reshape", "(", "B", ",", "grid_height", "*", "grid_width", ",", "-", "1", ",", "C", ")", "\n", "return", "x", "# (B, T, N, C)", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.deblockify": [[158, 171], ["int", "x.transpose().reshape.reshape", "x.transpose().reshape.transpose().reshape", "math.sqrt", "x.transpose().reshape.transpose"], "function", ["None"], ["", "@", "register_notrace_function", "# reason: int receives Proxy", "\n", "def", "deblockify", "(", "x", ",", "block_size", ":", "int", ")", ":", "\n", "    ", "\"\"\"blocks to image\n    Args:\n        x (Tensor): with shape (B, T, N, C) where T is number of blocks and N is sequence size per block\n        block_size (int): edge length of a single square block in units of desired H, W\n    \"\"\"", "\n", "B", ",", "T", ",", "_", ",", "C", "=", "x", ".", "shape", "\n", "grid_size", "=", "int", "(", "math", ".", "sqrt", "(", "T", ")", ")", "\n", "height", "=", "width", "=", "grid_size", "*", "block_size", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "grid_size", ",", "grid_size", ",", "block_size", ",", "block_size", ",", "C", ")", "\n", "x", "=", "x", ".", "transpose", "(", "2", ",", "3", ")", ".", "reshape", "(", "B", ",", "height", ",", "width", ",", "C", ")", "\n", "return", "x", "# (B, H, W, C)", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest._init_nest_weights": [[377, 393], ["isinstance", "name.startswith", "isinstance", "layers.trunc_normal_", "torch.nn.init.constant_", "layers.trunc_normal_", "layers.trunc_normal_", "torch.nn.init.zeros_", "torch.nn.init.zeros_"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "", "def", "_init_nest_weights", "(", "module", ":", "nn", ".", "Module", ",", "name", ":", "str", "=", "''", ",", "head_bias", ":", "float", "=", "0.", ")", ":", "\n", "    ", "\"\"\" NesT weight initialization\n    Can replicate Jax implementation. Otherwise follows vision_transformer.py\n    \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "if", "name", ".", "startswith", "(", "'head'", ")", ":", "\n", "            ", "trunc_normal_", "(", "module", ".", "weight", ",", "std", "=", ".02", ",", "a", "=", "-", "2", ",", "b", "=", "2", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "module", ".", "bias", ",", "head_bias", ")", "\n", "", "else", ":", "\n", "            ", "trunc_normal_", "(", "module", ".", "weight", ",", "std", "=", ".02", ",", "a", "=", "-", "2", ",", "b", "=", "2", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", ":", "\n", "        ", "trunc_normal_", "(", "module", ".", "weight", ",", "std", "=", ".02", ",", "a", "=", "-", "2", ",", "b", "=", "2", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "module", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.resize_pos_embed": [[395, 410], ["_logger.info", "int", "deblockify().permute", "torch.interpolate", "nest.blockify", "math.sqrt", "blockify.permute", "int", "nest.deblockify", "math.sqrt", "int", "math.sqrt"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.blockify", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.deblockify"], ["", "", "", "def", "resize_pos_embed", "(", "posemb", ",", "posemb_new", ")", ":", "\n", "    ", "\"\"\"\n    Rescale the grid of position embeddings when loading from state_dict\n    Expected shape of position embeddings is (1, T, N, C), and considers only square images\n    \"\"\"", "\n", "_logger", ".", "info", "(", "'Resized position embedding: %s to %s'", ",", "posemb", ".", "shape", ",", "posemb_new", ".", "shape", ")", "\n", "seq_length_old", "=", "posemb", ".", "shape", "[", "2", "]", "\n", "num_blocks_new", ",", "seq_length_new", "=", "posemb_new", ".", "shape", "[", "1", ":", "3", "]", "\n", "size_new", "=", "int", "(", "math", ".", "sqrt", "(", "num_blocks_new", "*", "seq_length_new", ")", ")", "\n", "# First change to (1, C, H, W)", "\n", "posemb", "=", "deblockify", "(", "posemb", ",", "int", "(", "math", ".", "sqrt", "(", "seq_length_old", ")", ")", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "posemb", "=", "F", ".", "interpolate", "(", "posemb", ",", "size", "=", "[", "size_new", ",", "size_new", "]", ",", "mode", "=", "'bicubic'", ",", "align_corners", "=", "False", ")", "\n", "# Now change to new (1, T, N, C)", "\n", "posemb", "=", "blockify", "(", "posemb", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ",", "int", "(", "math", ".", "sqrt", "(", "seq_length_new", ")", ")", ")", "\n", "return", "posemb", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.checkpoint_filter_fn": [[412, 419], ["state_dict.keys", "k.startswith", "nest.resize_pos_embed", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.resize_pos_embed"], ["", "def", "checkpoint_filter_fn", "(", "state_dict", ",", "model", ")", ":", "\n", "    ", "\"\"\" resize positional embeddings of pretrained weights \"\"\"", "\n", "pos_embed_keys", "=", "[", "k", "for", "k", "in", "state_dict", ".", "keys", "(", ")", "if", "k", ".", "startswith", "(", "'pos_embed_'", ")", "]", "\n", "for", "k", "in", "pos_embed_keys", ":", "\n", "        ", "if", "state_dict", "[", "k", "]", ".", "shape", "!=", "getattr", "(", "model", ",", "k", ")", ".", "shape", ":", "\n", "            ", "state_dict", "[", "k", "]", "=", "resize_pos_embed", "(", "state_dict", "[", "k", "]", ",", "getattr", "(", "model", ",", "k", ")", ")", "\n", "", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest._create_nest": [[421, 429], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "def", "_create_nest", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "build_model_with_cfg", "(", "\n", "Nest", ",", "variant", ",", "pretrained", ",", "\n", "feature_cfg", "=", "dict", "(", "out_indices", "=", "(", "0", ",", "1", ",", "2", ")", ",", "flatten_sequential", "=", "True", ")", ",", "\n", "pretrained_filter_fn", "=", "checkpoint_filter_fn", ",", "\n", "**", "kwargs", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.nest_base": [[431, 439], ["dict", "nest._create_nest"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest._create_nest"], ["", "@", "register_model", "\n", "def", "nest_base", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Nest-B @ 224x224\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "embed_dims", "=", "(", "128", ",", "256", ",", "512", ")", ",", "num_heads", "=", "(", "4", ",", "8", ",", "16", ")", ",", "depths", "=", "(", "2", ",", "2", ",", "20", ")", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_nest", "(", "'nest_base'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.nest_small": [[441, 448], ["dict", "nest._create_nest"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest._create_nest"], ["", "@", "register_model", "\n", "def", "nest_small", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Nest-S @ 224x224\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "embed_dims", "=", "(", "96", ",", "192", ",", "384", ")", ",", "num_heads", "=", "(", "3", ",", "6", ",", "12", ")", ",", "depths", "=", "(", "2", ",", "2", ",", "20", ")", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_nest", "(", "'nest_small'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.nest_tiny": [[450, 457], ["dict", "nest._create_nest"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest._create_nest"], ["", "@", "register_model", "\n", "def", "nest_tiny", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Nest-T @ 224x224\n    \"\"\"", "\n", "model_kwargs", "=", "dict", "(", "embed_dims", "=", "(", "96", ",", "192", ",", "384", ")", ",", "num_heads", "=", "(", "3", ",", "6", ",", "12", ")", ",", "depths", "=", "(", "2", ",", "2", ",", "8", ")", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_nest", "(", "'nest_tiny'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.jx_nest_base": [[459, 467], ["dict", "nest._create_nest"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest._create_nest"], ["", "@", "register_model", "\n", "def", "jx_nest_base", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Nest-B @ 224x224, Pretrained weights converted from official Jax impl.\n    \"\"\"", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model_kwargs", "=", "dict", "(", "embed_dims", "=", "(", "128", ",", "256", ",", "512", ")", ",", "num_heads", "=", "(", "4", ",", "8", ",", "16", ")", ",", "depths", "=", "(", "2", ",", "2", ",", "20", ")", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_nest", "(", "'jx_nest_base'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.jx_nest_small": [[469, 477], ["dict", "nest._create_nest"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest._create_nest"], ["", "@", "register_model", "\n", "def", "jx_nest_small", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Nest-S @ 224x224, Pretrained weights converted from official Jax impl.\n    \"\"\"", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model_kwargs", "=", "dict", "(", "embed_dims", "=", "(", "96", ",", "192", ",", "384", ")", ",", "num_heads", "=", "(", "3", ",", "6", ",", "12", ")", ",", "depths", "=", "(", "2", ",", "2", ",", "20", ")", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_nest", "(", "'jx_nest_small'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest.jx_nest_tiny": [[479, 487], ["dict", "nest._create_nest"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nest._create_nest"], ["", "@", "register_model", "\n", "def", "jx_nest_tiny", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Nest-T @ 224x224, Pretrained weights converted from official Jax impl.\n    \"\"\"", "\n", "kwargs", "[", "'pad_type'", "]", "=", "'same'", "\n", "model_kwargs", "=", "dict", "(", "embed_dims", "=", "(", "96", ",", "192", ",", "384", ")", ",", "num_heads", "=", "(", "3", ",", "6", ",", "12", ")", ",", "depths", "=", "(", "2", ",", "2", ",", "8", ")", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_nest", "(", "'jx_nest_tiny'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.GammaAct.__init__": [[261, 266], ["torch.Module.__init__", "layers.get_act_fn"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_fn"], ["    ", "def", "__init__", "(", "self", ",", "act_type", "=", "'relu'", ",", "gamma", ":", "float", "=", "1.0", ",", "inplace", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "act_fn", "=", "get_act_fn", "(", "act_type", ")", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "inplace", "=", "inplace", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.GammaAct.forward": [[267, 269], ["nfnet.GammaAct.act_fn().mul_", "nfnet.GammaAct.act_fn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "act_fn", "(", "x", ",", "inplace", "=", "self", ".", "inplace", ")", ".", "mul_", "(", "self", ".", "gamma", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.DownsampleAvg.__init__": [[278, 289], ["torch.Module.__init__", "conv_layer", "avg_pool_fn", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "first_dilation", "=", "None", ",", "conv_layer", "=", "ScaledStdConv2d", ")", ":", "\n", "        ", "\"\"\" AvgPool Downsampling as in 'D' ResNet variants. Support for dilation.\"\"\"", "\n", "super", "(", "DownsampleAvg", ",", "self", ")", ".", "__init__", "(", ")", "\n", "avg_stride", "=", "stride", "if", "dilation", "==", "1", "else", "1", "\n", "if", "stride", ">", "1", "or", "dilation", ">", "1", ":", "\n", "            ", "avg_pool_fn", "=", "AvgPool2dSame", "if", "avg_stride", "==", "1", "and", "dilation", ">", "1", "else", "nn", ".", "AvgPool2d", "\n", "self", ".", "pool", "=", "avg_pool_fn", "(", "2", ",", "avg_stride", ",", "ceil_mode", "=", "True", ",", "count_include_pad", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "pool", "=", "nn", ".", "Identity", "(", ")", "\n", "", "self", ".", "conv", "=", "conv_layer", "(", "in_chs", ",", "out_chs", ",", "1", ",", "stride", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.DownsampleAvg.forward": [[290, 292], ["nfnet.DownsampleAvg.conv", "nfnet.DownsampleAvg.pool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "conv", "(", "self", ".", "pool", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.NormFreeBlock.__init__": [[299, 343], ["torch.Module.__init__", "layers.make_divisible", "act_layer", "conv_layer", "act_layer", "conv_layer", "act_layer", "conv_layer", "nfnet.DownsampleAvg", "act_layer", "conv_layer", "attn_layer", "attn_layer", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Parameter", "torch.Parameter", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["def", "__init__", "(", "\n", "self", ",", "in_chs", ",", "out_chs", "=", "None", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "first_dilation", "=", "None", ",", "\n", "alpha", "=", "1.0", ",", "beta", "=", "1.0", ",", "bottle_ratio", "=", "0.25", ",", "group_size", "=", "None", ",", "ch_div", "=", "1", ",", "reg", "=", "True", ",", "extra_conv", "=", "False", ",", "\n", "skipinit", "=", "False", ",", "attn_layer", "=", "None", ",", "attn_gain", "=", "2.0", ",", "act_layer", "=", "None", ",", "conv_layer", "=", "None", ",", "drop_path_rate", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "first_dilation", "=", "first_dilation", "or", "dilation", "\n", "out_chs", "=", "out_chs", "or", "in_chs", "\n", "# RegNet variants scale bottleneck from in_chs, otherwise scale from out_chs like ResNet", "\n", "mid_chs", "=", "make_divisible", "(", "in_chs", "*", "bottle_ratio", "if", "reg", "else", "out_chs", "*", "bottle_ratio", ",", "ch_div", ")", "\n", "groups", "=", "1", "if", "not", "group_size", "else", "mid_chs", "//", "group_size", "\n", "if", "group_size", "and", "group_size", "%", "ch_div", "==", "0", ":", "\n", "            ", "mid_chs", "=", "group_size", "*", "groups", "# correct mid_chs if group_size divisible by ch_div, otherwise error", "\n", "", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "attn_gain", "=", "attn_gain", "\n", "\n", "if", "in_chs", "!=", "out_chs", "or", "stride", "!=", "1", "or", "dilation", "!=", "first_dilation", ":", "\n", "            ", "self", ".", "downsample", "=", "DownsampleAvg", "(", "\n", "in_chs", ",", "out_chs", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "first_dilation", "=", "first_dilation", ",", "conv_layer", "=", "conv_layer", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "downsample", "=", "None", "\n", "\n", "", "self", ".", "act1", "=", "act_layer", "(", ")", "\n", "self", ".", "conv1", "=", "conv_layer", "(", "in_chs", ",", "mid_chs", ",", "1", ")", "\n", "self", ".", "act2", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv_layer", "(", "mid_chs", ",", "mid_chs", ",", "3", ",", "stride", "=", "stride", ",", "dilation", "=", "first_dilation", ",", "groups", "=", "groups", ")", "\n", "if", "extra_conv", ":", "\n", "            ", "self", ".", "act2b", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2b", "=", "conv_layer", "(", "mid_chs", ",", "mid_chs", ",", "3", ",", "stride", "=", "1", ",", "dilation", "=", "dilation", ",", "groups", "=", "groups", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "act2b", "=", "None", "\n", "self", ".", "conv2b", "=", "None", "\n", "", "if", "reg", "and", "attn_layer", "is", "not", "None", ":", "\n", "            ", "self", ".", "attn", "=", "attn_layer", "(", "mid_chs", ")", "# RegNet blocks apply attn btw conv2 & 3", "\n", "", "else", ":", "\n", "            ", "self", ".", "attn", "=", "None", "\n", "", "self", ".", "act3", "=", "act_layer", "(", ")", "\n", "self", ".", "conv3", "=", "conv_layer", "(", "mid_chs", ",", "out_chs", ",", "1", ",", "gain_init", "=", "1.", "if", "skipinit", "else", "0.", ")", "\n", "if", "not", "reg", "and", "attn_layer", "is", "not", "None", ":", "\n", "            ", "self", ".", "attn_last", "=", "attn_layer", "(", "out_chs", ")", "# ResNet blocks apply attn after conv3", "\n", "", "else", ":", "\n", "            ", "self", ".", "attn_last", "=", "None", "\n", "", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path_rate", ")", "if", "drop_path_rate", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "skipinit_gain", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "0.", ")", ")", "if", "skipinit", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.NormFreeBlock.forward": [[344, 368], ["nfnet.NormFreeBlock.conv1", "nfnet.NormFreeBlock.conv2", "nfnet.NormFreeBlock.conv3", "nfnet.NormFreeBlock.drop_path", "nfnet.NormFreeBlock.act1", "nfnet.NormFreeBlock.downsample", "nfnet.NormFreeBlock.act2", "nfnet.NormFreeBlock.conv2b", "nfnet.NormFreeBlock.act3", "nfnet.NormFreeBlock.mul_", "nfnet.NormFreeBlock.act2b", "nfnet.NormFreeBlock.attn", "nfnet.NormFreeBlock.attn_last"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "act1", "(", "x", ")", "*", "self", ".", "beta", "\n", "\n", "# shortcut branch", "\n", "shortcut", "=", "x", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "downsample", "(", "out", ")", "\n", "\n", "# residual branch", "\n", "", "out", "=", "self", ".", "conv1", "(", "out", ")", "\n", "out", "=", "self", ".", "conv2", "(", "self", ".", "act2", "(", "out", ")", ")", "\n", "if", "self", ".", "conv2b", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "conv2b", "(", "self", ".", "act2b", "(", "out", ")", ")", "\n", "", "if", "self", ".", "attn", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "attn_gain", "*", "self", ".", "attn", "(", "out", ")", "\n", "", "out", "=", "self", ".", "conv3", "(", "self", ".", "act3", "(", "out", ")", ")", "\n", "if", "self", ".", "attn_last", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "attn_gain", "*", "self", ".", "attn_last", "(", "out", ")", "\n", "", "out", "=", "self", ".", "drop_path", "(", "out", ")", "\n", "\n", "if", "self", ".", "skipinit_gain", "is", "not", "None", ":", "\n", "            ", "out", ".", "mul_", "(", "self", ".", "skipinit_gain", ")", "# this slows things down more than expected, TBD", "\n", "", "out", "=", "out", "*", "self", ".", "alpha", "+", "shortcut", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.NormFreeNet.__init__": [[452, 546], ["torch.Module.__init__", "layers.make_divisible", "nfnet.create_stem", "enumerate", "torch.Sequential", "torch.Sequential", "layers.get_act_layer.", "layers.ClassifierHead", "nfnet.NormFreeNet.named_modules", "nfnet.act_with_gamma", "functools.partial", "layers.get_act_layer", "functools.partial", "functools.partial", "x.tolist", "range", "layers.make_divisible", "functools.partial.", "dict", "torch.Identity", "torch.Identity", "layers.get_attn", "torch.linspace().split", "torch.linspace().split", "torch.linspace().split", "torch.linspace().split", "layers.make_divisible", "dict", "torch.Sequential", "torch.Sequential", "isinstance", "isinstance", "nfnet.NormFreeBlock", "torch.init.zeros_", "torch.init.zeros_", "torch.init.normal_", "torch.init.normal_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.init.zeros_", "torch.init.zeros_", "sum"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.create_stem", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.act_with_gamma", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.get_attn", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["def", "__init__", "(", "\n", "self", ",", "cfg", ":", "NfCfg", ",", "num_classes", "=", "1000", ",", "in_chans", "=", "3", ",", "global_pool", "=", "'avg'", ",", "output_stride", "=", "32", ",", "\n", "drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "assert", "cfg", ".", "act_layer", "in", "_nonlin_gamma", ",", "f\"Please add non-linearity constants for activation ({cfg.act_layer}).\"", "\n", "conv_layer", "=", "ScaledStdConv2dSame", "if", "cfg", ".", "same_padding", "else", "ScaledStdConv2d", "\n", "if", "cfg", ".", "gamma_in_act", ":", "\n", "            ", "act_layer", "=", "act_with_gamma", "(", "cfg", ".", "act_layer", ",", "gamma", "=", "_nonlin_gamma", "[", "cfg", ".", "act_layer", "]", ")", "\n", "conv_layer", "=", "partial", "(", "conv_layer", ",", "eps", "=", "cfg", ".", "std_conv_eps", ")", "\n", "", "else", ":", "\n", "            ", "act_layer", "=", "get_act_layer", "(", "cfg", ".", "act_layer", ")", "\n", "conv_layer", "=", "partial", "(", "conv_layer", ",", "gamma", "=", "_nonlin_gamma", "[", "cfg", ".", "act_layer", "]", ",", "eps", "=", "cfg", ".", "std_conv_eps", ")", "\n", "", "attn_layer", "=", "partial", "(", "get_attn", "(", "cfg", ".", "attn_layer", ")", ",", "**", "cfg", ".", "attn_kwargs", ")", "if", "cfg", ".", "attn_layer", "else", "None", "\n", "\n", "stem_chs", "=", "make_divisible", "(", "(", "cfg", ".", "stem_chs", "or", "cfg", ".", "channels", "[", "0", "]", ")", "*", "cfg", ".", "width_factor", ",", "cfg", ".", "ch_div", ")", "\n", "self", ".", "stem", ",", "stem_stride", ",", "stem_feat", "=", "create_stem", "(", "\n", "in_chans", ",", "stem_chs", ",", "cfg", ".", "stem_type", ",", "conv_layer", "=", "conv_layer", ",", "act_layer", "=", "act_layer", ")", "\n", "\n", "self", ".", "feature_info", "=", "[", "stem_feat", "]", "\n", "drop_path_rates", "=", "[", "x", ".", "tolist", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "sum", "(", "cfg", ".", "depths", ")", ")", ".", "split", "(", "cfg", ".", "depths", ")", "]", "\n", "prev_chs", "=", "stem_chs", "\n", "net_stride", "=", "stem_stride", "\n", "dilation", "=", "1", "\n", "expected_var", "=", "1.0", "\n", "stages", "=", "[", "]", "\n", "for", "stage_idx", ",", "stage_depth", "in", "enumerate", "(", "cfg", ".", "depths", ")", ":", "\n", "            ", "stride", "=", "1", "if", "stage_idx", "==", "0", "and", "stem_stride", ">", "2", "else", "2", "\n", "if", "net_stride", ">=", "output_stride", "and", "stride", ">", "1", ":", "\n", "                ", "dilation", "*=", "stride", "\n", "stride", "=", "1", "\n", "", "net_stride", "*=", "stride", "\n", "first_dilation", "=", "1", "if", "dilation", "in", "(", "1", ",", "2", ")", "else", "2", "\n", "\n", "blocks", "=", "[", "]", "\n", "for", "block_idx", "in", "range", "(", "cfg", ".", "depths", "[", "stage_idx", "]", ")", ":", "\n", "                ", "first_block", "=", "block_idx", "==", "0", "and", "stage_idx", "==", "0", "\n", "out_chs", "=", "make_divisible", "(", "cfg", ".", "channels", "[", "stage_idx", "]", "*", "cfg", ".", "width_factor", ",", "cfg", ".", "ch_div", ")", "\n", "blocks", "+=", "[", "NormFreeBlock", "(", "\n", "in_chs", "=", "prev_chs", ",", "out_chs", "=", "out_chs", ",", "\n", "alpha", "=", "cfg", ".", "alpha", ",", "\n", "beta", "=", "1.", "/", "expected_var", "**", "0.5", ",", "\n", "stride", "=", "stride", "if", "block_idx", "==", "0", "else", "1", ",", "\n", "dilation", "=", "dilation", ",", "\n", "first_dilation", "=", "first_dilation", ",", "\n", "group_size", "=", "cfg", ".", "group_size", ",", "\n", "bottle_ratio", "=", "1.", "if", "cfg", ".", "reg", "and", "first_block", "else", "cfg", ".", "bottle_ratio", ",", "\n", "ch_div", "=", "cfg", ".", "ch_div", ",", "\n", "reg", "=", "cfg", ".", "reg", ",", "\n", "extra_conv", "=", "cfg", ".", "extra_conv", ",", "\n", "skipinit", "=", "cfg", ".", "skipinit", ",", "\n", "attn_layer", "=", "attn_layer", ",", "\n", "attn_gain", "=", "cfg", ".", "attn_gain", ",", "\n", "act_layer", "=", "act_layer", ",", "\n", "conv_layer", "=", "conv_layer", ",", "\n", "drop_path_rate", "=", "drop_path_rates", "[", "stage_idx", "]", "[", "block_idx", "]", ",", "\n", ")", "]", "\n", "if", "block_idx", "==", "0", ":", "\n", "                    ", "expected_var", "=", "1.", "# expected var is reset after first block of each stage", "\n", "", "expected_var", "+=", "cfg", ".", "alpha", "**", "2", "# Even if reset occurs, increment expected variance", "\n", "first_dilation", "=", "dilation", "\n", "prev_chs", "=", "out_chs", "\n", "", "self", ".", "feature_info", "+=", "[", "dict", "(", "num_chs", "=", "prev_chs", ",", "reduction", "=", "net_stride", ",", "module", "=", "f'stages.{stage_idx}'", ")", "]", "\n", "stages", "+=", "[", "nn", ".", "Sequential", "(", "*", "blocks", ")", "]", "\n", "", "self", ".", "stages", "=", "nn", ".", "Sequential", "(", "*", "stages", ")", "\n", "\n", "if", "cfg", ".", "num_features", ":", "\n", "# The paper NFRegNet models have an EfficientNet-like final head convolution.", "\n", "            ", "self", ".", "num_features", "=", "make_divisible", "(", "cfg", ".", "width_factor", "*", "cfg", ".", "num_features", ",", "cfg", ".", "ch_div", ")", "\n", "self", ".", "final_conv", "=", "conv_layer", "(", "prev_chs", ",", "self", ".", "num_features", ",", "1", ")", "\n", "self", ".", "feature_info", "[", "-", "1", "]", "=", "dict", "(", "num_chs", "=", "self", ".", "num_features", ",", "reduction", "=", "net_stride", ",", "module", "=", "f'final_conv'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_features", "=", "prev_chs", "\n", "self", ".", "final_conv", "=", "nn", ".", "Identity", "(", ")", "\n", "", "self", ".", "final_act", "=", "act_layer", "(", "inplace", "=", "cfg", ".", "num_features", ">", "0", ")", "\n", "\n", "self", ".", "head", "=", "ClassifierHead", "(", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "self", ".", "drop_rate", ")", "\n", "\n", "for", "n", ",", "m", "in", "self", ".", "named_modules", "(", ")", ":", "\n", "            ", "if", "'fc'", "in", "n", "and", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "if", "cfg", ".", "zero_init_fc", ":", "\n", "                    ", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "weight", ")", "\n", "", "else", ":", "\n", "                    ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "0.", ",", ".01", ")", "\n", "", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_in'", ",", "nonlinearity", "=", "'linear'", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.NormFreeNet.group_matcher": [[547, 557], ["dict"], "methods", ["None"], ["", "", "", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem", "=", "r'^stem'", ",", "\n", "blocks", "=", "[", "\n", "(", "r'^stages\\.(\\d+)'", "if", "coarse", "else", "r'^stages\\.(\\d+)\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^final_conv'", ",", "(", "99999", ",", ")", ")", "\n", "]", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.NormFreeNet.set_grad_checkpointing": [[558, 561], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.NormFreeNet.get_classifier": [[562, 565], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", ".", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.NormFreeNet.reset_classifier": [[566, 568], ["layers.ClassifierHead"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "head", "=", "ClassifierHead", "(", "self", ".", "num_features", ",", "num_classes", ",", "pool_type", "=", "global_pool", ",", "drop_rate", "=", "self", ".", "drop_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.NormFreeNet.forward_features": [[569, 578], ["nfnet.NormFreeNet.stem", "nfnet.NormFreeNet.final_conv", "nfnet.NormFreeNet.final_act", "helpers.checkpoint_seq", "nfnet.NormFreeNet.stages", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.checkpoint_seq", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hrnet.HighResolutionNet.stages"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "x", "=", "checkpoint_seq", "(", "self", ".", "stages", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "stages", "(", "x", ")", "\n", "", "x", "=", "self", ".", "final_conv", "(", "x", ")", "\n", "x", "=", "self", ".", "final_act", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.NormFreeNet.forward_head": [[579, 581], ["nfnet.NormFreeNet.head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.NormFreeNet.forward": [[582, 586], ["nfnet.NormFreeNet.forward_features", "nfnet.NormFreeNet.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._dcfg": [[36, 44], ["None"], "function", ["None"], ["def", "_dcfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.9", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'stem.conv1'", ",", "'classifier'", ":", "'head.fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._nfres_cfg": [[159, 166], ["nfnet.NfCfg"], "function", ["None"], ["", "def", "_nfres_cfg", "(", "\n", "depths", ",", "channels", "=", "(", "256", ",", "512", ",", "1024", ",", "2048", ")", ",", "group_size", "=", "None", ",", "act_layer", "=", "'relu'", ",", "attn_layer", "=", "None", ",", "attn_kwargs", "=", "None", ")", ":", "\n", "    ", "attn_kwargs", "=", "attn_kwargs", "or", "{", "}", "\n", "cfg", "=", "NfCfg", "(", "\n", "depths", "=", "depths", ",", "channels", "=", "channels", ",", "stem_type", "=", "'7x7_pool'", ",", "stem_chs", "=", "64", ",", "bottle_ratio", "=", "0.25", ",", "\n", "group_size", "=", "group_size", ",", "act_layer", "=", "act_layer", ",", "attn_layer", "=", "attn_layer", ",", "attn_kwargs", "=", "attn_kwargs", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._nfreg_cfg": [[168, 175], ["dict", "nfnet.NfCfg"], "function", ["None"], ["", "def", "_nfreg_cfg", "(", "depths", ",", "channels", "=", "(", "48", ",", "104", ",", "208", ",", "440", ")", ")", ":", "\n", "    ", "num_features", "=", "1280", "*", "channels", "[", "-", "1", "]", "//", "440", "\n", "attn_kwargs", "=", "dict", "(", "rd_ratio", "=", "0.5", ")", "\n", "cfg", "=", "NfCfg", "(", "\n", "depths", "=", "depths", ",", "channels", "=", "channels", ",", "stem_type", "=", "'3x3'", ",", "group_size", "=", "8", ",", "width_factor", "=", "0.75", ",", "bottle_ratio", "=", "2.25", ",", "\n", "num_features", "=", "num_features", ",", "reg", "=", "True", ",", "attn_layer", "=", "'se'", ",", "attn_kwargs", "=", "attn_kwargs", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._nfnet_cfg": [[177, 187], ["int", "nfnet.NfCfg", "dict"], "function", ["None"], ["", "def", "_nfnet_cfg", "(", "\n", "depths", ",", "channels", "=", "(", "256", ",", "512", ",", "1536", ",", "1536", ")", ",", "group_size", "=", "128", ",", "bottle_ratio", "=", "0.5", ",", "feat_mult", "=", "2.", ",", "\n", "act_layer", "=", "'gelu'", ",", "attn_layer", "=", "'se'", ",", "attn_kwargs", "=", "None", ")", ":", "\n", "    ", "num_features", "=", "int", "(", "channels", "[", "-", "1", "]", "*", "feat_mult", ")", "\n", "attn_kwargs", "=", "attn_kwargs", "if", "attn_kwargs", "is", "not", "None", "else", "dict", "(", "rd_ratio", "=", "0.5", ")", "\n", "cfg", "=", "NfCfg", "(", "\n", "depths", "=", "depths", ",", "channels", "=", "channels", ",", "stem_type", "=", "'deep_quad'", ",", "stem_chs", "=", "128", ",", "group_size", "=", "group_size", ",", "\n", "bottle_ratio", "=", "bottle_ratio", ",", "extra_conv", "=", "True", ",", "num_features", "=", "num_features", ",", "act_layer", "=", "act_layer", ",", "\n", "attn_layer", "=", "attn_layer", ",", "attn_kwargs", "=", "attn_kwargs", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._dm_nfnet_cfg": [[189, 195], ["nfnet.NfCfg", "int", "dict"], "function", ["None"], ["", "def", "_dm_nfnet_cfg", "(", "depths", ",", "channels", "=", "(", "256", ",", "512", ",", "1536", ",", "1536", ")", ",", "act_layer", "=", "'gelu'", ",", "skipinit", "=", "True", ")", ":", "\n", "    ", "cfg", "=", "NfCfg", "(", "\n", "depths", "=", "depths", ",", "channels", "=", "channels", ",", "stem_type", "=", "'deep_quad'", ",", "stem_chs", "=", "128", ",", "group_size", "=", "128", ",", "\n", "bottle_ratio", "=", "0.5", ",", "extra_conv", "=", "True", ",", "gamma_in_act", "=", "True", ",", "same_padding", "=", "True", ",", "skipinit", "=", "skipinit", ",", "\n", "num_features", "=", "int", "(", "channels", "[", "-", "1", "]", "*", "2.0", ")", ",", "act_layer", "=", "act_layer", ",", "attn_layer", "=", "'se'", ",", "attn_kwargs", "=", "dict", "(", "rd_ratio", "=", "0.5", ")", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.act_with_gamma": [[271, 275], ["nfnet.GammaAct"], "function", ["None"], ["", "", "def", "act_with_gamma", "(", "act_type", ",", "gamma", ":", "float", "=", "1.", ")", ":", "\n", "    ", "def", "_create", "(", "inplace", "=", "False", ")", ":", "\n", "        ", "return", "GammaAct", "(", "act_type", ",", "gamma", "=", "gamma", ",", "inplace", "=", "inplace", ")", "\n", "", "return", "_create", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.create_stem": [[370, 408], ["dict", "collections.OrderedDict", "enumerate", "torch.MaxPool2d", "torch.Sequential", "dict", "dict", "len", "zip", "conv_layer", "conv_layer", "conv_layer", "act_layer"], "function", ["None"], ["", "", "def", "create_stem", "(", "in_chs", ",", "out_chs", ",", "stem_type", "=", "''", ",", "conv_layer", "=", "None", ",", "act_layer", "=", "None", ",", "preact_feature", "=", "True", ")", ":", "\n", "    ", "stem_stride", "=", "2", "\n", "stem_feature", "=", "dict", "(", "num_chs", "=", "out_chs", ",", "reduction", "=", "2", ",", "module", "=", "'stem.conv'", ")", "\n", "stem", "=", "OrderedDict", "(", ")", "\n", "assert", "stem_type", "in", "(", "''", ",", "'deep'", ",", "'deep_tiered'", ",", "'deep_quad'", ",", "'3x3'", ",", "'7x7'", ",", "'deep_pool'", ",", "'3x3_pool'", ",", "'7x7_pool'", ")", "\n", "if", "'deep'", "in", "stem_type", ":", "\n", "        ", "if", "'quad'", "in", "stem_type", ":", "\n", "# 4 deep conv stack as in NFNet-F models", "\n", "            ", "assert", "not", "'pool'", "in", "stem_type", "\n", "stem_chs", "=", "(", "out_chs", "//", "8", ",", "out_chs", "//", "4", ",", "out_chs", "//", "2", ",", "out_chs", ")", "\n", "strides", "=", "(", "2", ",", "1", ",", "1", ",", "2", ")", "\n", "stem_stride", "=", "4", "\n", "stem_feature", "=", "dict", "(", "num_chs", "=", "out_chs", "//", "2", ",", "reduction", "=", "2", ",", "module", "=", "'stem.conv3'", ")", "\n", "", "else", ":", "\n", "            ", "if", "'tiered'", "in", "stem_type", ":", "\n", "                ", "stem_chs", "=", "(", "3", "*", "out_chs", "//", "8", ",", "out_chs", "//", "2", ",", "out_chs", ")", "# 'T' resnets in resnet.py", "\n", "", "else", ":", "\n", "                ", "stem_chs", "=", "(", "out_chs", "//", "2", ",", "out_chs", "//", "2", ",", "out_chs", ")", "# 'D' ResNets", "\n", "", "strides", "=", "(", "2", ",", "1", ",", "1", ")", "\n", "stem_feature", "=", "dict", "(", "num_chs", "=", "out_chs", "//", "2", ",", "reduction", "=", "2", ",", "module", "=", "'stem.conv2'", ")", "\n", "", "last_idx", "=", "len", "(", "stem_chs", ")", "-", "1", "\n", "for", "i", ",", "(", "c", ",", "s", ")", "in", "enumerate", "(", "zip", "(", "stem_chs", ",", "strides", ")", ")", ":", "\n", "            ", "stem", "[", "f'conv{i + 1}'", "]", "=", "conv_layer", "(", "in_chs", ",", "c", ",", "kernel_size", "=", "3", ",", "stride", "=", "s", ")", "\n", "if", "i", "!=", "last_idx", ":", "\n", "                ", "stem", "[", "f'act{i + 2}'", "]", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "", "in_chs", "=", "c", "\n", "", "", "elif", "'3x3'", "in", "stem_type", ":", "\n", "# 3x3 stem conv as in RegNet", "\n", "        ", "stem", "[", "'conv'", "]", "=", "conv_layer", "(", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "", "else", ":", "\n", "# 7x7 stem conv as in ResNet", "\n", "        ", "stem", "[", "'conv'", "]", "=", "conv_layer", "(", "in_chs", ",", "out_chs", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ")", "\n", "\n", "", "if", "'pool'", "in", "stem_type", ":", "\n", "        ", "stem", "[", "'pool'", "]", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "stem_stride", "=", "4", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "stem", ")", ",", "stem_stride", ",", "stem_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet": [[588, 596], ["dict", "helpers.build_model_with_cfg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_normfreenet", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_cfg", "=", "model_cfgs", "[", "variant", "]", "\n", "feature_cfg", "=", "dict", "(", "flatten_sequential", "=", "True", ")", "\n", "return", "build_model_with_cfg", "(", "\n", "NormFreeNet", ",", "variant", ",", "pretrained", ",", "\n", "model_cfg", "=", "model_cfg", ",", "\n", "feature_cfg", "=", "feature_cfg", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.dm_nfnet_f0": [[598, 605], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "dm_nfnet_f0", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" NFNet-F0 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'dm_nfnet_f0'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.dm_nfnet_f1": [[607, 614], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "dm_nfnet_f1", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" NFNet-F1 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'dm_nfnet_f1'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.dm_nfnet_f2": [[616, 623], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "dm_nfnet_f2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" NFNet-F2 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'dm_nfnet_f2'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.dm_nfnet_f3": [[625, 632], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "dm_nfnet_f3", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" NFNet-F3 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'dm_nfnet_f3'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.dm_nfnet_f4": [[634, 641], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "dm_nfnet_f4", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" NFNet-F4 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'dm_nfnet_f4'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.dm_nfnet_f5": [[643, 650], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "dm_nfnet_f5", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" NFNet-F5 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'dm_nfnet_f5'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.dm_nfnet_f6": [[652, 659], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "dm_nfnet_f6", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" NFNet-F6 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'dm_nfnet_f6'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nfnet_f0": [[661, 668], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nfnet_f0", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" NFNet-F0\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nfnet_f0'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nfnet_f1": [[670, 677], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nfnet_f1", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" NFNet-F1\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nfnet_f1'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nfnet_f2": [[679, 686], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nfnet_f2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" NFNet-F2\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nfnet_f2'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nfnet_f3": [[688, 695], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nfnet_f3", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" NFNet-F3\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nfnet_f3'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nfnet_f4": [[697, 704], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nfnet_f4", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" NFNet-F4\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nfnet_f4'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nfnet_f5": [[706, 713], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nfnet_f5", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" NFNet-F5\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nfnet_f5'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nfnet_f6": [[715, 722], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nfnet_f6", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" NFNet-F6\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nfnet_f6'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nfnet_f7": [[724, 731], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nfnet_f7", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" NFNet-F7\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nfnet_f7'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nfnet_l0": [[733, 739], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nfnet_l0", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" NFNet-L0b w/ SiLU\n    My experimental 'light' model w/ F0 repeats, 1.5x final_conv mult, 64 group_size, .25 bottleneck & SE ratio\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nfnet_l0'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.eca_nfnet_l0": [[741, 747], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "eca_nfnet_l0", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ECA-NFNet-L0 w/ SiLU\n    My experimental 'light' model w/ F0 repeats, 1.5x final_conv mult, 64 group_size, .25 bottleneck & ECA attn\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'eca_nfnet_l0'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.eca_nfnet_l1": [[749, 755], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "eca_nfnet_l1", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ECA-NFNet-L1 w/ SiLU\n    My experimental 'light' model w/ F1 repeats, 2.0x final_conv mult, 64 group_size, .25 bottleneck & ECA attn\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'eca_nfnet_l1'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.eca_nfnet_l2": [[757, 763], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "eca_nfnet_l2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ECA-NFNet-L2 w/ SiLU\n    My experimental 'light' model w/ F2 repeats, 2.0x final_conv mult, 64 group_size, .25 bottleneck & ECA attn\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'eca_nfnet_l2'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.eca_nfnet_l3": [[765, 771], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "eca_nfnet_l3", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" ECA-NFNet-L3 w/ SiLU\n    My experimental 'light' model w/ F3 repeats, 2.0x final_conv mult, 64 group_size, .25 bottleneck & ECA attn\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'eca_nfnet_l3'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nf_regnet_b0": [[773, 780], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nf_regnet_b0", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Normalization-Free RegNet-B0\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nf_regnet_b0'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nf_regnet_b1": [[782, 789], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nf_regnet_b1", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Normalization-Free RegNet-B1\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nf_regnet_b1'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nf_regnet_b2": [[791, 798], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nf_regnet_b2", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Normalization-Free RegNet-B2\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nf_regnet_b2'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nf_regnet_b3": [[800, 807], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nf_regnet_b3", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Normalization-Free RegNet-B3\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nf_regnet_b3'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nf_regnet_b4": [[809, 816], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nf_regnet_b4", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Normalization-Free RegNet-B4\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nf_regnet_b4'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nf_regnet_b5": [[818, 825], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nf_regnet_b5", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Normalization-Free RegNet-B5\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nf_regnet_b5'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nf_resnet26": [[827, 834], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nf_resnet26", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Normalization-Free ResNet-26\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nf_resnet26'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nf_resnet50": [[836, 843], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nf_resnet50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Normalization-Free ResNet-50\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nf_resnet50'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nf_resnet101": [[845, 852], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nf_resnet101", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Normalization-Free ResNet-101\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nf_resnet101'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nf_seresnet26": [[854, 859], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nf_seresnet26", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Normalization-Free SE-ResNet26\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nf_seresnet26'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nf_seresnet50": [[861, 866], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nf_seresnet50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Normalization-Free SE-ResNet50\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nf_seresnet50'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nf_seresnet101": [[868, 873], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nf_seresnet101", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Normalization-Free SE-ResNet101\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nf_seresnet101'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nf_ecaresnet26": [[875, 880], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nf_ecaresnet26", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Normalization-Free ECA-ResNet26\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nf_ecaresnet26'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nf_ecaresnet50": [[882, 887], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nf_ecaresnet50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Normalization-Free ECA-ResNet50\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nf_ecaresnet50'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet.nf_ecaresnet101": [[889, 894], ["nfnet._create_normfreenet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.nfnet._create_normfreenet"], ["", "@", "register_model", "\n", "def", "nf_ecaresnet101", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Normalization-Free ECA-ResNet101\n    \"\"\"", "\n", "return", "_create_normfreenet", "(", "'nf_ecaresnet101'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hardcorenas._cfg": [[14, 21], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bilinear'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'conv_stem'", ",", "'classifier'", ":", "'classifier'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hardcorenas._gen_hardcorenas": [[34, 68], ["functools.partial", "dict", "dict.pop", "helpers.build_model_with_cfg", "helpers.pretrained_cfg_for_features", "efficientnet_builder.decode_arch_def", "functools.partial", "efficientnet_builder.resolve_act_layer", "efficientnet_builder.resolve_bn_args"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.pretrained_cfg_for_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.decode_arch_def", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.efficientnet_builder.resolve_bn_args"], ["def", "_gen_hardcorenas", "(", "pretrained", ",", "variant", ",", "arch_def", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Creates a hardcorenas model\n\n    Ref impl: https://github.com/Alibaba-MIIL/HardCoReNAS\n    Paper: https://arxiv.org/abs/2102.11646\n\n    \"\"\"", "\n", "num_features", "=", "1280", "\n", "se_layer", "=", "partial", "(", "SqueezeExcite", ",", "gate_layer", "=", "'hard_sigmoid'", ",", "force_act_layer", "=", "nn", ".", "ReLU", ",", "rd_round_fn", "=", "round_channels", ")", "\n", "model_kwargs", "=", "dict", "(", "\n", "block_args", "=", "decode_arch_def", "(", "arch_def", ")", ",", "\n", "num_features", "=", "num_features", ",", "\n", "stem_size", "=", "32", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "BatchNorm2d", ",", "**", "resolve_bn_args", "(", "kwargs", ")", ")", ",", "\n", "act_layer", "=", "resolve_act_layer", "(", "kwargs", ",", "'hard_swish'", ")", ",", "\n", "se_layer", "=", "se_layer", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "\n", "features_only", "=", "False", "\n", "model_cls", "=", "MobileNetV3", "\n", "kwargs_filter", "=", "None", "\n", "if", "model_kwargs", ".", "pop", "(", "'features_only'", ",", "False", ")", ":", "\n", "        ", "features_only", "=", "True", "\n", "kwargs_filter", "=", "(", "'num_classes'", ",", "'num_features'", ",", "'global_pool'", ",", "'head_conv'", ",", "'head_bias'", ",", "'global_pool'", ")", "\n", "model_cls", "=", "MobileNetV3Features", "\n", "", "model", "=", "build_model_with_cfg", "(", "\n", "model_cls", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_strict", "=", "not", "features_only", ",", "\n", "kwargs_filter", "=", "kwargs_filter", ",", "\n", "**", "model_kwargs", ")", "\n", "if", "features_only", ":", "\n", "        ", "model", ".", "default_cfg", "=", "pretrained_cfg_for_features", "(", "model", ".", "default_cfg", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hardcorenas.hardcorenas_a": [[70, 80], ["hardcorenas._gen_hardcorenas"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hardcorenas._gen_hardcorenas"], ["", "@", "register_model", "\n", "def", "hardcorenas_a", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" hardcorenas_A \"\"\"", "\n", "arch_def", "=", "[", "[", "'ds_r1_k3_s1_e1_c16_nre'", "]", ",", "[", "'ir_r1_k5_s2_e3_c24_nre'", ",", "'ir_r1_k5_s1_e3_c24_nre_se0.25'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e3_c40_nre'", ",", "'ir_r1_k5_s1_e6_c40_nre_se0.25'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e6_c80_se0.25'", ",", "'ir_r1_k5_s1_e6_c80_se0.25'", "]", ",", "\n", "[", "'ir_r1_k5_s1_e6_c112_se0.25'", ",", "'ir_r1_k5_s1_e6_c112_se0.25'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e6_c192_se0.25'", ",", "'ir_r1_k5_s1_e6_c192_se0.25'", "]", ",", "[", "'cn_r1_k1_s1_c960'", "]", "]", "\n", "model", "=", "_gen_hardcorenas", "(", "pretrained", "=", "pretrained", ",", "variant", "=", "'hardcorenas_a'", ",", "arch_def", "=", "arch_def", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hardcorenas.hardcorenas_b": [[82, 94], ["hardcorenas._gen_hardcorenas"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hardcorenas._gen_hardcorenas"], ["", "@", "register_model", "\n", "def", "hardcorenas_b", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" hardcorenas_B \"\"\"", "\n", "arch_def", "=", "[", "[", "'ds_r1_k3_s1_e1_c16_nre'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e3_c24_nre'", ",", "'ir_r1_k5_s1_e3_c24_nre_se0.25'", ",", "'ir_r1_k3_s1_e3_c24_nre'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e3_c40_nre'", ",", "'ir_r1_k5_s1_e3_c40_nre'", ",", "'ir_r1_k5_s1_e3_c40_nre'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e3_c80'", ",", "'ir_r1_k5_s1_e3_c80'", ",", "'ir_r1_k3_s1_e3_c80'", ",", "'ir_r1_k3_s1_e3_c80'", "]", ",", "\n", "[", "'ir_r1_k5_s1_e3_c112'", ",", "'ir_r1_k3_s1_e3_c112'", ",", "'ir_r1_k3_s1_e3_c112'", ",", "'ir_r1_k3_s1_e3_c112'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e6_c192_se0.25'", ",", "'ir_r1_k5_s1_e6_c192_se0.25'", ",", "'ir_r1_k3_s1_e3_c192_se0.25'", "]", ",", "\n", "[", "'cn_r1_k1_s1_c960'", "]", "]", "\n", "model", "=", "_gen_hardcorenas", "(", "pretrained", "=", "pretrained", ",", "variant", "=", "'hardcorenas_b'", ",", "arch_def", "=", "arch_def", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hardcorenas.hardcorenas_c": [[96, 108], ["hardcorenas._gen_hardcorenas"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hardcorenas._gen_hardcorenas"], ["", "@", "register_model", "\n", "def", "hardcorenas_c", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" hardcorenas_C \"\"\"", "\n", "arch_def", "=", "[", "[", "'ds_r1_k3_s1_e1_c16_nre'", "]", ",", "[", "'ir_r1_k5_s2_e3_c24_nre'", ",", "'ir_r1_k5_s1_e3_c24_nre_se0.25'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e3_c40_nre'", ",", "'ir_r1_k5_s1_e3_c40_nre'", ",", "'ir_r1_k5_s1_e3_c40_nre'", ",", "\n", "'ir_r1_k5_s1_e3_c40_nre'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e4_c80'", ",", "'ir_r1_k5_s1_e6_c80_se0.25'", ",", "'ir_r1_k3_s1_e3_c80'", ",", "'ir_r1_k3_s1_e3_c80'", "]", ",", "\n", "[", "'ir_r1_k5_s1_e6_c112_se0.25'", ",", "'ir_r1_k3_s1_e3_c112'", ",", "'ir_r1_k3_s1_e3_c112'", ",", "'ir_r1_k3_s1_e3_c112'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e6_c192_se0.25'", ",", "'ir_r1_k5_s1_e6_c192_se0.25'", ",", "'ir_r1_k3_s1_e3_c192_se0.25'", "]", ",", "\n", "[", "'cn_r1_k1_s1_c960'", "]", "]", "\n", "model", "=", "_gen_hardcorenas", "(", "pretrained", "=", "pretrained", ",", "variant", "=", "'hardcorenas_c'", ",", "arch_def", "=", "arch_def", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hardcorenas.hardcorenas_d": [[110, 123], ["hardcorenas._gen_hardcorenas"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hardcorenas._gen_hardcorenas"], ["", "@", "register_model", "\n", "def", "hardcorenas_d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" hardcorenas_D \"\"\"", "\n", "arch_def", "=", "[", "[", "'ds_r1_k3_s1_e1_c16_nre'", "]", ",", "[", "'ir_r1_k5_s2_e3_c24_nre_se0.25'", ",", "'ir_r1_k5_s1_e3_c24_nre_se0.25'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e3_c40_nre_se0.25'", ",", "'ir_r1_k5_s1_e4_c40_nre_se0.25'", ",", "'ir_r1_k3_s1_e3_c40_nre_se0.25'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e4_c80_se0.25'", ",", "'ir_r1_k3_s1_e3_c80_se0.25'", ",", "'ir_r1_k3_s1_e3_c80_se0.25'", ",", "\n", "'ir_r1_k3_s1_e3_c80_se0.25'", "]", ",", "\n", "[", "'ir_r1_k3_s1_e4_c112_se0.25'", ",", "'ir_r1_k5_s1_e4_c112_se0.25'", ",", "'ir_r1_k3_s1_e3_c112_se0.25'", ",", "\n", "'ir_r1_k5_s1_e3_c112_se0.25'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e6_c192_se0.25'", ",", "'ir_r1_k5_s1_e6_c192_se0.25'", ",", "'ir_r1_k5_s1_e6_c192_se0.25'", ",", "\n", "'ir_r1_k3_s1_e6_c192_se0.25'", "]", ",", "[", "'cn_r1_k1_s1_c960'", "]", "]", "\n", "model", "=", "_gen_hardcorenas", "(", "pretrained", "=", "pretrained", ",", "variant", "=", "'hardcorenas_d'", ",", "arch_def", "=", "arch_def", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hardcorenas.hardcorenas_e": [[125, 137], ["hardcorenas._gen_hardcorenas"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hardcorenas._gen_hardcorenas"], ["", "@", "register_model", "\n", "def", "hardcorenas_e", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" hardcorenas_E \"\"\"", "\n", "arch_def", "=", "[", "[", "'ds_r1_k3_s1_e1_c16_nre'", "]", ",", "[", "'ir_r1_k5_s2_e3_c24_nre_se0.25'", ",", "'ir_r1_k5_s1_e3_c24_nre_se0.25'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e6_c40_nre_se0.25'", ",", "'ir_r1_k5_s1_e4_c40_nre_se0.25'", ",", "'ir_r1_k5_s1_e4_c40_nre_se0.25'", ",", "\n", "'ir_r1_k3_s1_e3_c40_nre_se0.25'", "]", ",", "[", "'ir_r1_k5_s2_e4_c80_se0.25'", ",", "'ir_r1_k3_s1_e6_c80_se0.25'", "]", ",", "\n", "[", "'ir_r1_k5_s1_e6_c112_se0.25'", ",", "'ir_r1_k5_s1_e6_c112_se0.25'", ",", "'ir_r1_k5_s1_e6_c112_se0.25'", ",", "\n", "'ir_r1_k5_s1_e3_c112_se0.25'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e6_c192_se0.25'", ",", "'ir_r1_k5_s1_e6_c192_se0.25'", ",", "'ir_r1_k5_s1_e6_c192_se0.25'", ",", "\n", "'ir_r1_k3_s1_e6_c192_se0.25'", "]", ",", "[", "'cn_r1_k1_s1_c960'", "]", "]", "\n", "model", "=", "_gen_hardcorenas", "(", "pretrained", "=", "pretrained", ",", "variant", "=", "'hardcorenas_e'", ",", "arch_def", "=", "arch_def", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hardcorenas.hardcorenas_f": [[139, 152], ["hardcorenas._gen_hardcorenas"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.hardcorenas._gen_hardcorenas"], ["", "@", "register_model", "\n", "def", "hardcorenas_f", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" hardcorenas_F \"\"\"", "\n", "arch_def", "=", "[", "[", "'ds_r1_k3_s1_e1_c16_nre'", "]", ",", "[", "'ir_r1_k5_s2_e3_c24_nre_se0.25'", ",", "'ir_r1_k5_s1_e3_c24_nre_se0.25'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e6_c40_nre_se0.25'", ",", "'ir_r1_k5_s1_e6_c40_nre_se0.25'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e6_c80_se0.25'", ",", "'ir_r1_k5_s1_e6_c80_se0.25'", ",", "'ir_r1_k3_s1_e3_c80_se0.25'", ",", "\n", "'ir_r1_k3_s1_e3_c80_se0.25'", "]", ",", "\n", "[", "'ir_r1_k3_s1_e6_c112_se0.25'", ",", "'ir_r1_k5_s1_e6_c112_se0.25'", ",", "'ir_r1_k5_s1_e6_c112_se0.25'", ",", "\n", "'ir_r1_k3_s1_e3_c112_se0.25'", "]", ",", "\n", "[", "'ir_r1_k5_s2_e6_c192_se0.25'", ",", "'ir_r1_k5_s1_e6_c192_se0.25'", ",", "'ir_r1_k3_s1_e6_c192_se0.25'", ",", "\n", "'ir_r1_k3_s1_e6_c192_se0.25'", "]", ",", "[", "'cn_r1_k1_s1_c960'", "]", "]", "\n", "model", "=", "_gen_hardcorenas", "(", "pretrained", "=", "pretrained", ",", "variant", "=", "'hardcorenas_f'", ",", "arch_def", "=", "arch_def", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.__init__": [[22, 32], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "feature_info", ":", "List", "[", "Dict", "]", ",", "out_indices", ":", "Tuple", "[", "int", "]", ")", ":", "\n", "        ", "prev_reduction", "=", "1", "\n", "for", "fi", "in", "feature_info", ":", "\n", "# sanity check the mandatory fields, there may be additional fields depending on the model", "\n", "            ", "assert", "'num_chs'", "in", "fi", "and", "fi", "[", "'num_chs'", "]", ">", "0", "\n", "assert", "'reduction'", "in", "fi", "and", "fi", "[", "'reduction'", "]", ">=", "prev_reduction", "\n", "prev_reduction", "=", "fi", "[", "'reduction'", "]", "\n", "assert", "'module'", "in", "fi", "\n", "", "self", ".", "out_indices", "=", "out_indices", "\n", "self", ".", "info", "=", "feature_info", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.from_other": [[33, 35], ["features.FeatureInfo", "copy.deepcopy"], "methods", ["None"], ["", "def", "from_other", "(", "self", ",", "out_indices", ":", "Tuple", "[", "int", "]", ")", ":", "\n", "        ", "return", "FeatureInfo", "(", "deepcopy", "(", "self", ".", "info", ")", ",", "out_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get": [[36, 48], ["isinstance"], "methods", ["None"], ["", "def", "get", "(", "self", ",", "key", ",", "idx", "=", "None", ")", ":", "\n", "        ", "\"\"\" Get value by key at specified index (indices)\n        if idx == None, returns value for key at each output index\n        if idx is an integer, return value for that feature module index (ignoring output indices)\n        if idx is a list/tupple, return value for each module index (ignoring output indices)\n        \"\"\"", "\n", "if", "idx", "is", "None", ":", "\n", "            ", "return", "[", "self", ".", "info", "[", "i", "]", "[", "key", "]", "for", "i", "in", "self", ".", "out_indices", "]", "\n", "", "if", "isinstance", "(", "idx", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "return", "[", "self", ".", "info", "[", "i", "]", "[", "key", "]", "for", "i", "in", "idx", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "info", "[", "idx", "]", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get_dicts": [[49, 61], ["isinstance"], "methods", ["None"], ["", "", "def", "get_dicts", "(", "self", ",", "keys", "=", "None", ",", "idx", "=", "None", ")", ":", "\n", "        ", "\"\"\" return info dicts for specified keys (or all if None) at specified indices (or out_indices if None)\n        \"\"\"", "\n", "if", "idx", "is", "None", ":", "\n", "            ", "if", "keys", "is", "None", ":", "\n", "                ", "return", "[", "self", ".", "info", "[", "i", "]", "for", "i", "in", "self", ".", "out_indices", "]", "\n", "", "else", ":", "\n", "                ", "return", "[", "{", "k", ":", "self", ".", "info", "[", "i", "]", "[", "k", "]", "for", "k", "in", "keys", "}", "for", "i", "in", "self", ".", "out_indices", "]", "\n", "", "", "if", "isinstance", "(", "idx", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "return", "[", "self", ".", "info", "[", "i", "]", "if", "keys", "is", "None", "else", "{", "k", ":", "self", ".", "info", "[", "i", "]", "[", "k", "]", "for", "k", "in", "keys", "}", "for", "i", "in", "idx", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "info", "[", "idx", "]", "if", "keys", "is", "None", "else", "{", "k", ":", "self", ".", "info", "[", "idx", "]", "[", "k", "]", "for", "k", "in", "keys", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.channels": [[62, 66], ["features.FeatureInfo.get"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["", "", "def", "channels", "(", "self", ",", "idx", "=", "None", ")", ":", "\n", "        ", "\"\"\" feature channels accessor\n        \"\"\"", "\n", "return", "self", ".", "get", "(", "'num_chs'", ",", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.reduction": [[67, 71], ["features.FeatureInfo.get"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["", "def", "reduction", "(", "self", ",", "idx", "=", "None", ")", ":", "\n", "        ", "\"\"\" feature reduction (output stride) accessor\n        \"\"\"", "\n", "return", "self", ".", "get", "(", "'reduction'", ",", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.module_name": [[72, 76], ["features.FeatureInfo.get"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["", "def", "module_name", "(", "self", ",", "idx", "=", "None", ")", ":", "\n", "        ", "\"\"\" feature module name accessor\n        \"\"\"", "\n", "return", "self", ".", "get", "(", "'module'", ",", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.__getitem__": [[77, 79], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "self", ".", "info", "[", "item", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.__len__": [[80, 82], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureHooks.__init__": [[92, 108], ["enumerate", "collections.defaultdict", "functools.partial", "h.get", "m.register_forward_pre_hook", "m.register_forward_hook"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["def", "__init__", "(", "self", ",", "hooks", ",", "named_modules", ",", "out_map", "=", "None", ",", "default_hook_type", "=", "'forward'", ")", ":", "\n", "# setup feature hooks", "\n", "        ", "modules", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "named_modules", "}", "\n", "for", "i", ",", "h", "in", "enumerate", "(", "hooks", ")", ":", "\n", "            ", "hook_name", "=", "h", "[", "'module'", "]", "\n", "m", "=", "modules", "[", "hook_name", "]", "\n", "hook_id", "=", "out_map", "[", "i", "]", "if", "out_map", "else", "hook_name", "\n", "hook_fn", "=", "partial", "(", "self", ".", "_collect_output_hook", ",", "hook_id", ")", "\n", "hook_type", "=", "h", ".", "get", "(", "'hook_type'", ",", "default_hook_type", ")", "\n", "if", "hook_type", "==", "'forward_pre'", ":", "\n", "                ", "m", ".", "register_forward_pre_hook", "(", "hook_fn", ")", "\n", "", "elif", "hook_type", "==", "'forward'", ":", "\n", "                ", "m", ".", "register_forward_hook", "(", "hook_fn", ")", "\n", "", "else", ":", "\n", "                ", "assert", "False", ",", "\"Unsupported hook type\"", "\n", "", "", "self", ".", "_feature_outputs", "=", "defaultdict", "(", "OrderedDict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureHooks._collect_output_hook": [[109, 114], ["isinstance"], "methods", ["None"], ["", "def", "_collect_output_hook", "(", "self", ",", "hook_id", ",", "*", "args", ")", ":", "\n", "        ", "x", "=", "args", "[", "-", "1", "]", "# tensor we want is last argument, output for fwd, input for fwd_pre", "\n", "if", "isinstance", "(", "x", ",", "tuple", ")", ":", "\n", "            ", "x", "=", "x", "[", "0", "]", "# unwrap input tuple", "\n", "", "self", ".", "_feature_outputs", "[", "x", ".", "device", "]", "[", "hook_id", "]", "=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureHooks.get_output": [[115, 119], ["collections.OrderedDict"], "methods", ["None"], ["", "def", "get_output", "(", "self", ",", "device", ")", "->", "Dict", "[", "str", ",", "torch", ".", "tensor", "]", ":", "\n", "        ", "output", "=", "self", ".", "_feature_outputs", "[", "device", "]", "\n", "self", ".", "_feature_outputs", "[", "device", "]", "=", "OrderedDict", "(", ")", "# clear after reading", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureDictNet.__init__": [[177, 199], ["torch.ModuleDict.__init__", "features._get_feature_info", "features._get_return_layers", "features._module_list", "set", "collections.OrderedDict", "features.FeatureDictNet.update", "_get_return_layers.keys", "str", "set.remove", "len", "len"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features._get_feature_info", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features._get_return_layers", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features._module_list"], ["def", "__init__", "(", "\n", "self", ",", "model", ",", "\n", "out_indices", "=", "(", "0", ",", "1", ",", "2", ",", "3", ",", "4", ")", ",", "out_map", "=", "None", ",", "feature_concat", "=", "False", ",", "flatten_sequential", "=", "False", ")", ":", "\n", "        ", "super", "(", "FeatureDictNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "feature_info", "=", "_get_feature_info", "(", "model", ",", "out_indices", ")", "\n", "self", ".", "concat", "=", "feature_concat", "\n", "self", ".", "return_layers", "=", "{", "}", "\n", "return_layers", "=", "_get_return_layers", "(", "self", ".", "feature_info", ",", "out_map", ")", "\n", "modules", "=", "_module_list", "(", "model", ",", "flatten_sequential", "=", "flatten_sequential", ")", "\n", "remaining", "=", "set", "(", "return_layers", ".", "keys", "(", ")", ")", "\n", "layers", "=", "OrderedDict", "(", ")", "\n", "for", "new_name", ",", "old_name", ",", "module", "in", "modules", ":", "\n", "            ", "layers", "[", "new_name", "]", "=", "module", "\n", "if", "old_name", "in", "remaining", ":", "\n", "# return id has to be consistently str type for torchscript", "\n", "                ", "self", ".", "return_layers", "[", "new_name", "]", "=", "str", "(", "return_layers", "[", "old_name", "]", ")", "\n", "remaining", ".", "remove", "(", "old_name", ")", "\n", "", "if", "not", "remaining", ":", "\n", "                ", "break", "\n", "", "", "assert", "not", "remaining", "and", "len", "(", "self", ".", "return_layers", ")", "==", "len", "(", "return_layers", ")", ",", "f'Return layers ({remaining}) are not present in model'", "\n", "self", ".", "update", "(", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureDictNet._collect": [[200, 213], ["collections.OrderedDict", "features.FeatureDictNet.items", "module", "isinstance", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "_collect", "(", "self", ",", "x", ")", "->", "(", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "out", "=", "OrderedDict", "(", ")", "\n", "for", "name", ",", "module", "in", "self", ".", "items", "(", ")", ":", "\n", "            ", "x", "=", "module", "(", "x", ")", "\n", "if", "name", "in", "self", ".", "return_layers", ":", "\n", "                ", "out_id", "=", "self", ".", "return_layers", "[", "name", "]", "\n", "if", "isinstance", "(", "x", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "# If model tap is a tuple or list, concat or select first element", "\n", "# FIXME this may need to be more generic / flexible for some nets", "\n", "                    ", "out", "[", "out_id", "]", "=", "torch", ".", "cat", "(", "x", ",", "1", ")", "if", "self", ".", "concat", "else", "x", "[", "0", "]", "\n", "", "else", ":", "\n", "                    ", "out", "[", "out_id", "]", "=", "x", "\n", "", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureDictNet.forward": [[214, 216], ["features.FeatureDictNet._collect"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureDictNet._collect"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "return", "self", ".", "_collect", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureListNet.__init__": [[224, 230], ["features.FeatureDictNet.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "model", ",", "\n", "out_indices", "=", "(", "0", ",", "1", ",", "2", ",", "3", ",", "4", ")", ",", "out_map", "=", "None", ",", "feature_concat", "=", "False", ",", "flatten_sequential", "=", "False", ")", ":", "\n", "        ", "super", "(", "FeatureListNet", ",", "self", ")", ".", "__init__", "(", "\n", "model", ",", "out_indices", "=", "out_indices", ",", "out_map", "=", "out_map", ",", "feature_concat", "=", "feature_concat", ",", "\n", "flatten_sequential", "=", "flatten_sequential", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureListNet.forward": [[231, 233], ["list", "features.FeatureListNet._collect().values", "features.FeatureListNet._collect"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureDictNet._collect"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "(", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "return", "list", "(", "self", ".", "_collect", "(", "x", ")", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureHookNet.__init__": [[248, 279], ["torch.ModuleDict.__init__", "features._get_feature_info", "collections.OrderedDict", "features.FeatureHookNet.update", "features.FeatureHooks", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "hasattr", "hooks.extend", "features._module_list", "model.named_modules", "model.reset_classifier", "features.FeatureHookNet.feature_info.get_dicts", "module.named_modules", "features.FeatureHookNet.feature_info.get_dicts", "hooks.append", "dict"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features._get_feature_info", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features._module_list", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.reset_classifier", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get_dicts", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get_dicts"], ["def", "__init__", "(", "\n", "self", ",", "model", ",", "\n", "out_indices", "=", "(", "0", ",", "1", ",", "2", ",", "3", ",", "4", ")", ",", "out_map", "=", "None", ",", "out_as_dict", "=", "False", ",", "no_rewrite", "=", "False", ",", "\n", "feature_concat", "=", "False", ",", "flatten_sequential", "=", "False", ",", "default_hook_type", "=", "'forward'", ")", ":", "\n", "        ", "super", "(", "FeatureHookNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", "\n", "self", ".", "feature_info", "=", "_get_feature_info", "(", "model", ",", "out_indices", ")", "\n", "self", ".", "out_as_dict", "=", "out_as_dict", "\n", "layers", "=", "OrderedDict", "(", ")", "\n", "hooks", "=", "[", "]", "\n", "if", "no_rewrite", ":", "\n", "            ", "assert", "not", "flatten_sequential", "\n", "if", "hasattr", "(", "model", ",", "'reset_classifier'", ")", ":", "# make sure classifier is removed?", "\n", "                ", "model", ".", "reset_classifier", "(", "0", ")", "\n", "", "layers", "[", "'body'", "]", "=", "model", "\n", "hooks", ".", "extend", "(", "self", ".", "feature_info", ".", "get_dicts", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "modules", "=", "_module_list", "(", "model", ",", "flatten_sequential", "=", "flatten_sequential", ")", "\n", "remaining", "=", "{", "f", "[", "'module'", "]", ":", "f", "[", "'hook_type'", "]", "if", "'hook_type'", "in", "f", "else", "default_hook_type", "\n", "for", "f", "in", "self", ".", "feature_info", ".", "get_dicts", "(", ")", "}", "\n", "for", "new_name", ",", "old_name", ",", "module", "in", "modules", ":", "\n", "                ", "layers", "[", "new_name", "]", "=", "module", "\n", "for", "fn", ",", "fm", "in", "module", ".", "named_modules", "(", "prefix", "=", "old_name", ")", ":", "\n", "                    ", "if", "fn", "in", "remaining", ":", "\n", "                        ", "hooks", ".", "append", "(", "dict", "(", "module", "=", "fn", ",", "hook_type", "=", "remaining", "[", "fn", "]", ")", ")", "\n", "del", "remaining", "[", "fn", "]", "\n", "", "", "if", "not", "remaining", ":", "\n", "                    ", "break", "\n", "", "", "assert", "not", "remaining", ",", "f'Return layers ({remaining}) are not present in model'", "\n", "", "self", ".", "update", "(", "layers", ")", "\n", "self", ".", "hooks", "=", "FeatureHooks", "(", "hooks", ",", "model", ".", "named_modules", "(", ")", ",", "out_map", "=", "out_map", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureHookNet.forward": [[280, 285], ["features.FeatureHookNet.items", "features.FeatureHookNet.hooks.get_output", "module", "list", "features.FeatureHookNet.values"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureHooks.get_output"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "name", ",", "module", "in", "self", ".", "items", "(", ")", ":", "\n", "            ", "x", "=", "module", "(", "x", ")", "\n", "", "out", "=", "self", ".", "hooks", ".", "get_output", "(", "x", ".", "device", ")", "\n", "return", "out", "if", "self", ".", "out_as_dict", "else", "list", "(", "out", ".", "values", "(", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features._module_list": [[121, 133], ["module.named_children", "isinstance", "module.named_children", "ml.append", "ml.append"], "function", ["None"], ["", "", "def", "_module_list", "(", "module", ",", "flatten_sequential", "=", "False", ")", ":", "\n", "# a yield/iter would be better for this but wouldn't be compatible with torchscript", "\n", "    ", "ml", "=", "[", "]", "\n", "for", "name", ",", "module", "in", "module", ".", "named_children", "(", ")", ":", "\n", "        ", "if", "flatten_sequential", "and", "isinstance", "(", "module", ",", "nn", ".", "Sequential", ")", ":", "\n", "# first level of Sequential containers is flattened into containing model", "\n", "            ", "for", "child_name", ",", "child_module", "in", "module", ".", "named_children", "(", ")", ":", "\n", "                ", "combined", "=", "[", "name", ",", "child_name", "]", "\n", "ml", ".", "append", "(", "(", "'_'", ".", "join", "(", "combined", ")", ",", "'.'", ".", "join", "(", "combined", ")", ",", "child_module", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "ml", ".", "append", "(", "(", "name", ",", "name", ",", "module", ")", ")", "\n", "", "", "return", "ml", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features._get_feature_info": [[135, 143], ["getattr", "isinstance", "getattr.from_other", "isinstance", "features.FeatureInfo"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.from_other"], ["", "def", "_get_feature_info", "(", "net", ",", "out_indices", ")", ":", "\n", "    ", "feature_info", "=", "getattr", "(", "net", ",", "'feature_info'", ")", "\n", "if", "isinstance", "(", "feature_info", ",", "FeatureInfo", ")", ":", "\n", "        ", "return", "feature_info", ".", "from_other", "(", "out_indices", ")", "\n", "", "elif", "isinstance", "(", "feature_info", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "return", "FeatureInfo", "(", "net", ".", "feature_info", ",", "out_indices", ")", "\n", "", "else", ":", "\n", "        ", "assert", "False", ",", "\"Provided feature_info is not valid\"", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features._get_return_layers": [[145, 151], ["feature_info.module_name", "enumerate"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.module_name"], ["", "", "def", "_get_return_layers", "(", "feature_info", ",", "out_map", ")", ":", "\n", "    ", "module_names", "=", "feature_info", ".", "module_name", "(", ")", "\n", "return_layers", "=", "{", "}", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "module_names", ")", ":", "\n", "        ", "return_layers", "[", "name", "]", "=", "out_map", "[", "i", "]", "if", "out_map", "is", "not", "None", "else", "feature_info", ".", "out_indices", "[", "i", "]", "\n", "", "return", "return_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.PositionalEncodingFourier.__init__": [[112, 120], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "hidden_dim", "=", "32", ",", "dim", "=", "768", ",", "temperature", "=", "10000", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "token_projection", "=", "nn", ".", "Conv2d", "(", "hidden_dim", "*", "2", ",", "dim", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "scale", "=", "2", "*", "math", ".", "pi", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "eps", "=", "1e-6", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.PositionalEncodingFourier.forward": [[121, 136], ["torch.arange().unsqueeze().repeat", "torch.arange().unsqueeze().repeat", "torch.arange().unsqueeze().repeat", "torch.arange().unsqueeze().repeat", "torch.arange().repeat", "torch.arange().repeat", "torch.arange().repeat", "torch.arange().repeat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.stack().flatten", "torch.stack().flatten", "torch.stack().flatten", "torch.stack().flatten", "torch.stack().flatten", "torch.stack().flatten", "torch.stack().flatten", "torch.stack().flatten", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "xcit.PositionalEncodingFourier.token_projection", "xcit.PositionalEncodingFourier.repeat", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.div", "torch.div", "torch.div", "torch.div", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "pos_x[].sin", "pos_x[].cos", "pos_y[].sin", "pos_y[].cos"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "B", ":", "int", ",", "H", ":", "int", ",", "W", ":", "int", ")", ":", "\n", "        ", "device", "=", "self", ".", "token_projection", ".", "weight", ".", "device", "\n", "y_embed", "=", "torch", ".", "arange", "(", "1", ",", "H", "+", "1", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "W", ")", "\n", "x_embed", "=", "torch", ".", "arange", "(", "1", ",", "W", "+", "1", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", ".", "repeat", "(", "1", ",", "H", ",", "1", ")", "\n", "y_embed", "=", "y_embed", "/", "(", "y_embed", "[", ":", ",", "-", "1", ":", ",", ":", "]", "+", "self", ".", "eps", ")", "*", "self", ".", "scale", "\n", "x_embed", "=", "x_embed", "/", "(", "x_embed", "[", ":", ",", ":", ",", "-", "1", ":", "]", "+", "self", ".", "eps", ")", "*", "self", ".", "scale", "\n", "dim_t", "=", "torch", ".", "arange", "(", "self", ".", "hidden_dim", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "dim_t", "=", "self", ".", "temperature", "**", "(", "2", "*", "torch", ".", "div", "(", "dim_t", ",", "2", ",", "rounding_mode", "=", "'floor'", ")", "/", "self", ".", "hidden_dim", ")", "\n", "pos_x", "=", "x_embed", "[", ":", ",", ":", ",", ":", ",", "None", "]", "/", "dim_t", "\n", "pos_y", "=", "y_embed", "[", ":", ",", ":", ",", ":", ",", "None", "]", "/", "dim_t", "\n", "pos_x", "=", "torch", ".", "stack", "(", "[", "pos_x", "[", ":", ",", ":", ",", ":", ",", "0", ":", ":", "2", "]", ".", "sin", "(", ")", ",", "pos_x", "[", ":", ",", ":", ",", ":", ",", "1", ":", ":", "2", "]", ".", "cos", "(", ")", "]", ",", "dim", "=", "4", ")", ".", "flatten", "(", "3", ")", "\n", "pos_y", "=", "torch", ".", "stack", "(", "[", "pos_y", "[", ":", ",", ":", ",", ":", ",", "0", ":", ":", "2", "]", ".", "sin", "(", ")", ",", "pos_y", "[", ":", ",", ":", ",", ":", ",", "1", ":", ":", "2", "]", ".", "cos", "(", ")", "]", ",", "dim", "=", "4", ")", ".", "flatten", "(", "3", ")", "\n", "pos", "=", "torch", ".", "cat", "(", "(", "pos_y", ",", "pos_x", ")", ",", "dim", "=", "3", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "pos", "=", "self", ".", "token_projection", "(", "pos", ")", "\n", "return", "pos", ".", "repeat", "(", "B", ",", "1", ",", "1", ",", "1", ")", "# (B, C, H, W)", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.ConvPatchEmbed.__init__": [[149, 177], ["torch.Module.__init__", "layers.to_2tuple", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "xcit.conv3x3", "act_layer", "xcit.conv3x3", "act_layer", "xcit.conv3x3", "act_layer", "xcit.conv3x3", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "xcit.conv3x3", "act_layer", "xcit.conv3x3", "act_layer", "xcit.conv3x3"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.conv3x3", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.conv3x3", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.conv3x3", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.conv3x3", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.conv3x3", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.conv3x3", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.conv3x3"], ["def", "__init__", "(", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "embed_dim", "=", "768", ",", "act_layer", "=", "nn", ".", "GELU", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "num_patches", "=", "(", "img_size", "[", "1", "]", "//", "patch_size", ")", "*", "(", "img_size", "[", "0", "]", "//", "patch_size", ")", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "self", ".", "num_patches", "=", "num_patches", "\n", "\n", "if", "patch_size", "==", "16", ":", "\n", "            ", "self", ".", "proj", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "conv3x3", "(", "in_chans", ",", "embed_dim", "//", "8", ",", "2", ")", ",", "\n", "act_layer", "(", ")", ",", "\n", "conv3x3", "(", "embed_dim", "//", "8", ",", "embed_dim", "//", "4", ",", "2", ")", ",", "\n", "act_layer", "(", ")", ",", "\n", "conv3x3", "(", "embed_dim", "//", "4", ",", "embed_dim", "//", "2", ",", "2", ")", ",", "\n", "act_layer", "(", ")", ",", "\n", "conv3x3", "(", "embed_dim", "//", "2", ",", "embed_dim", ",", "2", ")", ",", "\n", ")", "\n", "", "elif", "patch_size", "==", "8", ":", "\n", "            ", "self", ".", "proj", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "conv3x3", "(", "in_chans", ",", "embed_dim", "//", "4", ",", "2", ")", ",", "\n", "act_layer", "(", ")", ",", "\n", "conv3x3", "(", "embed_dim", "//", "4", ",", "embed_dim", "//", "2", ",", "2", ")", ",", "\n", "act_layer", "(", ")", ",", "\n", "conv3x3", "(", "embed_dim", "//", "2", ",", "embed_dim", ",", "2", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "(", "'For convolutional projection, patch size has to be in [8, 16]'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.ConvPatchEmbed.forward": [[178, 183], ["xcit.ConvPatchEmbed.proj", "x.flatten().transpose.flatten().transpose.flatten().transpose", "x.flatten().transpose.flatten().transpose.flatten"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "Hp", ",", "Wp", "=", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "3", "]", "\n", "x", "=", "x", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "# (B, N, C)", "\n", "return", "x", ",", "(", "Hp", ",", "Wp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.LPI.__init__": [[192, 204], ["torch.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "act_layer", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", "=", "None", ",", "act_layer", "=", "nn", ".", "GELU", ",", "kernel_size", "=", "3", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "out_features", "=", "out_features", "or", "in_features", "\n", "\n", "padding", "=", "kernel_size", "//", "2", "\n", "\n", "self", ".", "conv1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "\n", "in_features", ",", "in_features", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", ",", "groups", "=", "in_features", ")", "\n", "self", ".", "act", "=", "act_layer", "(", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm2d", "(", "in_features", ")", "\n", "self", ".", "conv2", "=", "torch", ".", "nn", ".", "Conv2d", "(", "\n", "in_features", ",", "out_features", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", ",", "groups", "=", "out_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.LPI.forward": [[205, 214], ["x.reshape().permute.reshape().permute.permute().reshape", "xcit.LPI.conv1", "xcit.LPI.act", "xcit.LPI.bn", "xcit.LPI.conv2", "x.reshape().permute.reshape().permute.reshape().permute", "x.reshape().permute.reshape().permute.permute", "x.reshape().permute.reshape().permute.reshape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "H", ":", "int", ",", "W", ":", "int", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "reshape", "(", "B", ",", "C", ",", "H", ",", "W", ")", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "C", ",", "N", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.ClassAttentionBlock.__init__": [[219, 240], ["torch.Module.__init__", "norm_layer", "cait.ClassAttn", "norm_layer", "vision_transformer.Mlp", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "int", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "dim", ",", "num_heads", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "drop_path", "=", "0.", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "eta", "=", "1.", ",", "tokens_norm", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "\n", "self", ".", "attn", "=", "ClassAttn", "(", "\n", "dim", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ")", "\n", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "in_features", "=", "dim", ",", "hidden_features", "=", "int", "(", "dim", "*", "mlp_ratio", ")", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "\n", "if", "eta", "is", "not", "None", ":", "# LayerScale Initialization (no layerscale when None)", "\n", "            ", "self", ".", "gamma1", "=", "nn", ".", "Parameter", "(", "eta", "*", "torch", ".", "ones", "(", "dim", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "gamma2", "=", "nn", ".", "Parameter", "(", "eta", "*", "torch", ".", "ones", "(", "dim", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "gamma1", ",", "self", ".", "gamma2", "=", "1.0", ",", "1.0", "\n", "\n", "# See https://github.com/rwightman/pytorch-image-models/pull/747#issuecomment-877795721", "\n", "", "self", ".", "tokens_norm", "=", "tokens_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.ClassAttentionBlock.forward": [[241, 255], ["xcit.ClassAttentionBlock.norm1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "xcit.ClassAttentionBlock.drop_path", "xcit.ClassAttentionBlock.norm2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "xcit.ClassAttentionBlock.mlp", "xcit.ClassAttentionBlock.drop_path", "xcit.ClassAttentionBlock.attn", "xcit.ClassAttentionBlock.norm2"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_norm1", "=", "self", ".", "norm1", "(", "x", ")", "\n", "x_attn", "=", "torch", ".", "cat", "(", "[", "self", ".", "attn", "(", "x_norm1", ")", ",", "x_norm1", "[", ":", ",", "1", ":", "]", "]", ",", "dim", "=", "1", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "gamma1", "*", "x_attn", ")", "\n", "if", "self", ".", "tokens_norm", ":", "\n", "            ", "x", "=", "self", ".", "norm2", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "torch", ".", "cat", "(", "[", "self", ".", "norm2", "(", "x", "[", ":", ",", "0", ":", "1", "]", ")", ",", "x", "[", ":", ",", "1", ":", "]", "]", ",", "dim", "=", "1", ")", "\n", "", "x_res", "=", "x", "\n", "cls_token", "=", "x", "[", ":", ",", "0", ":", "1", "]", "\n", "cls_token", "=", "self", ".", "gamma2", "*", "self", ".", "mlp", "(", "cls_token", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "cls_token", ",", "x", "[", ":", ",", "1", ":", "]", "]", ",", "dim", "=", "1", ")", "\n", "x", "=", "x_res", "+", "self", ".", "drop_path", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.XCA.__init__": [[263, 271], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "qkv_bias", "=", "False", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "temperature", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_heads", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", "*", "3", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.XCA.forward": [[272, 290], ["xcit.XCA.qkv().reshape().permute", "xcit.XCA.unbind", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "xcit.XCA.softmax", "xcit.XCA.attn_drop", "xcit.XCA.proj", "xcit.XCA.proj_drop", "xcit.XCA.qkv().reshape", "torch.nn.functional.normalize.transpose", "torch.nn.functional.normalize.transpose", "xcit.XCA.qkv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "# Result of next line is (qkv, B, num (H)eads,  (C')hannels per head, N)", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "3", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "4", ",", "1", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", ".", "unbind", "(", "0", ")", "# make torchscript happy (cannot use tensor as tuple)", "\n", "\n", "# Paper section 3.2 l2-Normalization and temperature scaling", "\n", "q", "=", "torch", ".", "nn", ".", "functional", ".", "normalize", "(", "q", ",", "dim", "=", "-", "1", ")", "\n", "k", "=", "torch", ".", "nn", ".", "functional", ".", "normalize", "(", "k", ",", "dim", "=", "-", "1", ")", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "*", "self", ".", "temperature", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "# (B, H, C', N), permute -> (B, N, H, C')", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "N", ",", "C", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.XCA.no_weight_decay": [[291, 294], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "{", "'temperature'", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.XCABlock.__init__": [[297, 314], ["torch.Module.__init__", "norm_layer", "xcit.XCA", "norm_layer", "xcit.LPI", "norm_layer", "vision_transformer.Mlp", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "layers.DropPath", "torch.Identity", "torch.Identity", "int", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dim", ",", "num_heads", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "\n", "drop_path", "=", "0.", ",", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "eta", "=", "1.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn", "=", "XCA", "(", "dim", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "norm3", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "local_mp", "=", "LPI", "(", "in_features", "=", "dim", ",", "act_layer", "=", "act_layer", ")", "\n", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "in_features", "=", "dim", ",", "hidden_features", "=", "int", "(", "dim", "*", "mlp_ratio", ")", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "\n", "self", ".", "gamma1", "=", "nn", ".", "Parameter", "(", "eta", "*", "torch", ".", "ones", "(", "dim", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "gamma3", "=", "nn", ".", "Parameter", "(", "eta", "*", "torch", ".", "ones", "(", "dim", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "gamma2", "=", "nn", ".", "Parameter", "(", "eta", "*", "torch", ".", "ones", "(", "dim", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.XCABlock.forward": [[315, 322], ["xcit.XCABlock.drop_path", "xcit.XCABlock.drop_path", "xcit.XCABlock.drop_path", "xcit.XCABlock.attn", "xcit.XCABlock.local_mp", "xcit.XCABlock.mlp", "xcit.XCABlock.norm1", "xcit.XCABlock.norm3", "xcit.XCABlock.norm2"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ",", "H", ":", "int", ",", "W", ":", "int", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "gamma1", "*", "self", ".", "attn", "(", "self", ".", "norm1", "(", "x", ")", ")", ")", "\n", "# NOTE official code has 3 then 2, so keeping it the same to be consistent with loaded weights", "\n", "# See https://github.com/rwightman/pytorch-image-models/pull/747#issuecomment-877795721", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "gamma3", "*", "self", ".", "local_mp", "(", "self", ".", "norm3", "(", "x", ")", ",", "H", ",", "W", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "gamma2", "*", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.XCiT.__init__": [[331, 400], ["torch.Module.__init__", "layers.to_2tuple", "xcit.ConvPatchEmbed", "torch.Parameter", "torch.Parameter", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "norm_layer", "layers.trunc_normal_", "xcit.XCiT.apply", "functools.partial", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "xcit.PositionalEncodingFourier", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "xcit.XCABlock", "xcit.ClassAttentionBlock", "range", "range"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["def", "__init__", "(", "\n", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "global_pool", "=", "'token'", ",", "embed_dim", "=", "768", ",", "\n", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "True", ",", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "\n", "act_layer", "=", "None", ",", "norm_layer", "=", "None", ",", "cls_attn_layers", "=", "2", ",", "use_pos_embed", "=", "True", ",", "eta", "=", "1.", ",", "tokens_norm", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img_size (int, tuple): input image size\n            patch_size (int): patch size\n            in_chans (int): number of input channels\n            num_classes (int): number of classes for classification head\n            embed_dim (int): embedding dimension\n            depth (int): depth of transformer\n            num_heads (int): number of attention heads\n            mlp_ratio (int): ratio of mlp hidden dim to embedding dim\n            qkv_bias (bool): enable bias for qkv if True\n            drop_rate (float): dropout rate after positional embedding, and in XCA/CA projection + MLP\n            attn_drop_rate (float): attention dropout rate\n            drop_path_rate (float): stochastic depth rate (constant across all layers)\n            norm_layer: (nn.Module): normalization layer\n            cls_attn_layers: (int) Depth of Class attention layers\n            use_pos_embed: (bool) whether to use positional encoding\n            eta: (float) layerscale initialization value\n            tokens_norm: (bool) Whether to normalize all tokens or just the cls_token in the CA\n\n        Notes:\n            - Although `layer_norm` is user specifiable, there are hard-coded `BatchNorm2d`s in the local patch\n              interaction (class LPI) and the patch embedding (class ConvPatchEmbed)\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "global_pool", "in", "(", "''", ",", "'avg'", ",", "'token'", ")", "\n", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "assert", "(", "img_size", "[", "0", "]", "%", "patch_size", "==", "0", ")", "and", "(", "img_size", "[", "0", "]", "%", "patch_size", "==", "0", ")", ",", "'`patch_size` should divide image dimensions evenly'", "\n", "norm_layer", "=", "norm_layer", "or", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", "\n", "act_layer", "=", "act_layer", "or", "nn", ".", "GELU", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_features", "=", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "self", ".", "patch_embed", "=", "ConvPatchEmbed", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "embed_dim", "=", "embed_dim", ",", "act_layer", "=", "act_layer", ")", "\n", "\n", "self", ".", "cls_token", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "self", ".", "use_pos_embed", "=", "use_pos_embed", "\n", "if", "use_pos_embed", ":", "\n", "            ", "self", ".", "pos_embed", "=", "PositionalEncodingFourier", "(", "dim", "=", "embed_dim", ")", "\n", "", "self", ".", "pos_drop", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", "\n", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "[", "\n", "XCABlock", "(", "\n", "dim", "=", "embed_dim", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "drop", "=", "drop_rate", ",", "\n", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "drop_path_rate", ",", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ",", "eta", "=", "eta", ")", "\n", "for", "_", "in", "range", "(", "depth", ")", "]", ")", "\n", "\n", "self", ".", "cls_attn_blocks", "=", "nn", ".", "ModuleList", "(", "[", "\n", "ClassAttentionBlock", "(", "\n", "dim", "=", "embed_dim", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "drop", "=", "drop_rate", ",", "\n", "attn_drop", "=", "attn_drop_rate", ",", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ",", "eta", "=", "eta", ",", "tokens_norm", "=", "tokens_norm", ")", "\n", "for", "_", "in", "range", "(", "cls_attn_layers", ")", "]", ")", "\n", "\n", "# Classifier head", "\n", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "# Init weights", "\n", "trunc_normal_", "(", "self", ".", "cls_token", ",", "std", "=", ".02", ")", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.XCiT._init_weights": [[401, 406], ["isinstance", "layers.trunc_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", ".02", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.XCiT.no_weight_decay": [[407, 410], ["None"], "methods", ["None"], ["", "", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "{", "'pos_embed'", ",", "'cls_token'", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.XCiT.group_matcher": [[411, 417], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "return", "dict", "(", "\n", "stem", "=", "r'^cls_token|pos_embed|patch_embed'", ",", "# stem and embed", "\n", "blocks", "=", "r'^blocks\\.(\\d+)'", ",", "\n", "cls_attn_blocks", "=", "[", "(", "r'^cls_attn_blocks\\.(\\d+)'", ",", "None", ")", ",", "(", "r'^norm'", ",", "(", "99999", ",", ")", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.XCiT.set_grad_checkpointing": [[419, 422], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.XCiT.get_classifier": [[423, 426], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.XCiT.reset_classifier": [[427, 433], ["torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "''", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "if", "global_pool", "is", "not", "None", ":", "\n", "            ", "assert", "global_pool", "in", "(", "''", ",", "'avg'", ",", "'token'", ")", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.XCiT.forward_features": [[434, 461], ["xcit.XCiT.patch_embed", "xcit.XCiT.pos_drop", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "xcit.XCiT.norm", "xcit.XCiT.pos_embed().reshape().permute", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "blk", "xcit.XCiT.cls_token.expand", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "blk", "xcit.XCiT.pos_embed().reshape", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "xcit.XCiT.pos_embed"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", "=", "x", ".", "shape", "[", "0", "]", "\n", "# x is (B, N, C). (Hp, Hw) is (height in units of patches, width in units of patches)", "\n", "x", ",", "(", "Hp", ",", "Wp", ")", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "\n", "if", "self", ".", "use_pos_embed", ":", "\n", "# `pos_embed` (B, C, Hp, Wp), reshape -> (B, C, N), permute -> (B, N, C)", "\n", "            ", "pos_encoding", "=", "self", ".", "pos_embed", "(", "B", ",", "Hp", ",", "Wp", ")", ".", "reshape", "(", "B", ",", "-", "1", ",", "x", ".", "shape", "[", "1", "]", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "x", "=", "x", "+", "pos_encoding", "\n", "", "x", "=", "self", ".", "pos_drop", "(", "x", ")", "\n", "\n", "for", "blk", "in", "self", ".", "blocks", ":", "\n", "            ", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "                ", "x", "=", "checkpoint", "(", "blk", ",", "x", ",", "Hp", ",", "Wp", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "blk", "(", "x", ",", "Hp", ",", "Wp", ")", "\n", "\n", "", "", "x", "=", "torch", ".", "cat", "(", "(", "self", ".", "cls_token", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "\n", "for", "blk", "in", "self", ".", "cls_attn_blocks", ":", "\n", "            ", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "                ", "x", "=", "checkpoint", "(", "blk", ",", "x", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "blk", "(", "x", ")", "\n", "\n", "", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.XCiT.forward_head": [[462, 466], ["xcit.XCiT.head", "x[].mean"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "global_pool", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", "1", ":", "]", ".", "mean", "(", "dim", "=", "1", ")", "if", "self", ".", "global_pool", "==", "'avg'", "else", "x", "[", ":", ",", "0", "]", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.XCiT.forward": [[467, 471], ["xcit.XCiT.forward_features", "xcit.XCiT.forward_head"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._cfg": [[30, 38], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", "1.0", ",", "'interpolation'", ":", "'bicubic'", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'patch_embed.proj.0.0'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.conv3x3": [[138, 143], ["torch.nn.Sequential", "torch.nn.Sequential", "torch.Conv2d", "torch.BatchNorm2d"], "function", ["None"], ["", "", "def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution + batch norm\"\"\"", "\n", "return", "torch", ".", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_planes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.checkpoint_filter_fn": [[473, 500], ["getattr", "len", "range", "k.startswith", "state_dict.pop", "model.state_dict", "state_dict.pop", "qkv_weight.reshape.reshape", "enumerate", "state_dict.pop", "qkv_bias.reshape.reshape", "enumerate", "k.replace"], "function", ["None"], ["", "", "def", "checkpoint_filter_fn", "(", "state_dict", ",", "model", ")", ":", "\n", "    ", "if", "'model'", "in", "state_dict", ":", "\n", "        ", "state_dict", "=", "state_dict", "[", "'model'", "]", "\n", "# For consistency with timm's transformer models while being compatible with official weights source we rename", "\n", "# pos_embeder to pos_embed. Also account for use_pos_embed == False", "\n", "", "use_pos_embed", "=", "getattr", "(", "model", ",", "'pos_embed'", ",", "None", ")", "is", "not", "None", "\n", "pos_embed_keys", "=", "[", "k", "for", "k", "in", "state_dict", "if", "k", ".", "startswith", "(", "'pos_embed'", ")", "]", "\n", "for", "k", "in", "pos_embed_keys", ":", "\n", "        ", "if", "use_pos_embed", ":", "\n", "            ", "state_dict", "[", "k", ".", "replace", "(", "'pos_embeder.'", ",", "'pos_embed.'", ")", "]", "=", "state_dict", ".", "pop", "(", "k", ")", "\n", "", "else", ":", "\n", "            ", "del", "state_dict", "[", "k", "]", "\n", "# timm's implementation of class attention in CaiT is slightly more efficient as it does not compute query vectors", "\n", "# for all tokens, just the class token. To use official weights source we must split qkv into q, k, v", "\n", "", "", "if", "'cls_attn_blocks.0.attn.qkv.weight'", "in", "state_dict", "and", "'cls_attn_blocks.0.attn.q.weight'", "in", "model", ".", "state_dict", "(", ")", ":", "\n", "        ", "num_ca_blocks", "=", "len", "(", "model", ".", "cls_attn_blocks", ")", "\n", "for", "i", "in", "range", "(", "num_ca_blocks", ")", ":", "\n", "            ", "qkv_weight", "=", "state_dict", ".", "pop", "(", "f'cls_attn_blocks.{i}.attn.qkv.weight'", ")", "\n", "qkv_weight", "=", "qkv_weight", ".", "reshape", "(", "3", ",", "-", "1", ",", "qkv_weight", ".", "shape", "[", "-", "1", "]", ")", "\n", "for", "j", ",", "subscript", "in", "enumerate", "(", "'qkv'", ")", ":", "\n", "                ", "state_dict", "[", "f'cls_attn_blocks.{i}.attn.{subscript}.weight'", "]", "=", "qkv_weight", "[", "j", "]", "\n", "", "qkv_bias", "=", "state_dict", ".", "pop", "(", "f'cls_attn_blocks.{i}.attn.qkv.bias'", ",", "None", ")", "\n", "if", "qkv_bias", "is", "not", "None", ":", "\n", "                ", "qkv_bias", "=", "qkv_bias", ".", "reshape", "(", "3", ",", "-", "1", ")", "\n", "for", "j", ",", "subscript", "in", "enumerate", "(", "'qkv'", ")", ":", "\n", "                    ", "state_dict", "[", "f'cls_attn_blocks.{i}.attn.{subscript}.bias'", "]", "=", "qkv_bias", "[", "j", "]", "\n", "", "", "", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit": [[502, 506], ["helpers.build_model_with_cfg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "def", "_create_xcit", "(", "variant", ",", "pretrained", "=", "False", ",", "default_cfg", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "build_model_with_cfg", "(", "\n", "XCiT", ",", "variant", ",", "pretrained", ",", "pretrained_filter_fn", "=", "checkpoint_filter_fn", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_nano_12_p16_224": [[508, 514], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_nano_12_p16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "128", ",", "depth", "=", "12", ",", "num_heads", "=", "4", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "False", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_nano_12_p16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_nano_12_p16_224_dist": [[516, 522], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_nano_12_p16_224_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "128", ",", "depth", "=", "12", ",", "num_heads", "=", "4", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "False", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_nano_12_p16_224_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_nano_12_p16_384_dist": [[524, 530], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_nano_12_p16_384_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "128", ",", "depth", "=", "12", ",", "num_heads", "=", "4", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "False", ",", "img_size", "=", "384", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_nano_12_p16_384_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_tiny_12_p16_224": [[532, 538], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_tiny_12_p16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "4", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_tiny_12_p16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_tiny_12_p16_224_dist": [[540, 546], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_tiny_12_p16_224_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "4", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_tiny_12_p16_224_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_tiny_12_p16_384_dist": [[548, 554], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_tiny_12_p16_384_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "4", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_tiny_12_p16_384_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_small_12_p16_224": [[556, 562], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_small_12_p16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "8", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_small_12_p16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_small_12_p16_224_dist": [[564, 570], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_small_12_p16_224_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "8", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_small_12_p16_224_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_small_12_p16_384_dist": [[572, 578], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_small_12_p16_384_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "8", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_small_12_p16_384_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_tiny_24_p16_224": [[580, 586], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_tiny_24_p16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "24", ",", "num_heads", "=", "4", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_tiny_24_p16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_tiny_24_p16_224_dist": [[588, 594], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_tiny_24_p16_224_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "24", ",", "num_heads", "=", "4", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_tiny_24_p16_224_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_tiny_24_p16_384_dist": [[596, 602], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_tiny_24_p16_384_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "192", ",", "depth", "=", "24", ",", "num_heads", "=", "4", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_tiny_24_p16_384_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_small_24_p16_224": [[604, 610], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_small_24_p16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "24", ",", "num_heads", "=", "8", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_small_24_p16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_small_24_p16_224_dist": [[612, 618], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_small_24_p16_224_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "24", ",", "num_heads", "=", "8", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_small_24_p16_224_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_small_24_p16_384_dist": [[620, 626], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_small_24_p16_384_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "24", ",", "num_heads", "=", "8", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_small_24_p16_384_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_medium_24_p16_224": [[628, 634], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_medium_24_p16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "512", ",", "depth", "=", "24", ",", "num_heads", "=", "8", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_medium_24_p16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_medium_24_p16_224_dist": [[636, 642], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_medium_24_p16_224_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "512", ",", "depth", "=", "24", ",", "num_heads", "=", "8", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_medium_24_p16_224_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_medium_24_p16_384_dist": [[644, 650], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_medium_24_p16_384_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "512", ",", "depth", "=", "24", ",", "num_heads", "=", "8", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_medium_24_p16_384_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_large_24_p16_224": [[652, 658], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_large_24_p16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_large_24_p16_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_large_24_p16_224_dist": [[660, 666], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_large_24_p16_224_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_large_24_p16_224_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_large_24_p16_384_dist": [[668, 674], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_large_24_p16_384_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_large_24_p16_384_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_nano_12_p8_224": [[677, 683], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_nano_12_p8_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "128", ",", "depth", "=", "12", ",", "num_heads", "=", "4", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "False", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_nano_12_p8_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_nano_12_p8_224_dist": [[685, 691], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_nano_12_p8_224_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "128", ",", "depth", "=", "12", ",", "num_heads", "=", "4", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "False", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_nano_12_p8_224_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_nano_12_p8_384_dist": [[693, 699], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_nano_12_p8_384_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "128", ",", "depth", "=", "12", ",", "num_heads", "=", "4", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "False", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_nano_12_p8_384_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_tiny_12_p8_224": [[701, 707], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_tiny_12_p8_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "4", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_tiny_12_p8_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_tiny_12_p8_224_dist": [[709, 715], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_tiny_12_p8_224_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "4", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_tiny_12_p8_224_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_tiny_12_p8_384_dist": [[717, 723], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_tiny_12_p8_384_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "4", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_tiny_12_p8_384_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_small_12_p8_224": [[725, 731], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_small_12_p8_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "8", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_small_12_p8_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_small_12_p8_224_dist": [[733, 739], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_small_12_p8_224_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "8", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_small_12_p8_224_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_small_12_p8_384_dist": [[741, 747], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_small_12_p8_384_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "8", ",", "eta", "=", "1.0", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_small_12_p8_384_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_tiny_24_p8_224": [[749, 755], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_tiny_24_p8_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "192", ",", "depth", "=", "24", ",", "num_heads", "=", "4", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_tiny_24_p8_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_tiny_24_p8_224_dist": [[757, 763], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_tiny_24_p8_224_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "192", ",", "depth", "=", "24", ",", "num_heads", "=", "4", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_tiny_24_p8_224_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_tiny_24_p8_384_dist": [[765, 771], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_tiny_24_p8_384_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "192", ",", "depth", "=", "24", ",", "num_heads", "=", "4", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_tiny_24_p8_384_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_small_24_p8_224": [[773, 779], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_small_24_p8_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "384", ",", "depth", "=", "24", ",", "num_heads", "=", "8", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_small_24_p8_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_small_24_p8_224_dist": [[781, 787], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_small_24_p8_224_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "384", ",", "depth", "=", "24", ",", "num_heads", "=", "8", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_small_24_p8_224_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_small_24_p8_384_dist": [[789, 795], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_small_24_p8_384_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "384", ",", "depth", "=", "24", ",", "num_heads", "=", "8", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_small_24_p8_384_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_medium_24_p8_224": [[797, 803], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_medium_24_p8_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "512", ",", "depth", "=", "24", ",", "num_heads", "=", "8", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_medium_24_p8_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_medium_24_p8_224_dist": [[805, 811], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_medium_24_p8_224_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "512", ",", "depth", "=", "24", ",", "num_heads", "=", "8", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_medium_24_p8_224_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_medium_24_p8_384_dist": [[813, 819], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_medium_24_p8_384_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "512", ",", "depth", "=", "24", ",", "num_heads", "=", "8", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_medium_24_p8_384_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_large_24_p8_224": [[821, 827], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_large_24_p8_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "768", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_large_24_p8_224'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_large_24_p8_224_dist": [[829, 835], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_large_24_p8_224_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "768", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_large_24_p8_224_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit.xcit_large_24_p8_384_dist": [[837, 843], ["dict", "xcit._create_xcit"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.xcit._create_xcit"], ["", "@", "register_model", "\n", "def", "xcit_large_24_p8_384_dist", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "8", ",", "embed_dim", "=", "768", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "eta", "=", "1e-5", ",", "tokens_norm", "=", "True", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_xcit", "(", "'xcit_large_24_p8_384_dist'", ",", "pretrained", "=", "pretrained", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._cfg": [[23, 31], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.95", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'stem.conv1.conv'", ",", "'classifier'", ":", "'head.fc'", ",", "\n", "'fixed_input_size'", ":", "False", ",", "'min_input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._create_byoanet": [[327, 333], ["helpers.build_model_with_cfg", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["def", "_create_byoanet", "(", "variant", ",", "cfg_variant", "=", "None", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "\n", "ByobNet", ",", "variant", ",", "pretrained", ",", "\n", "model_cfg", "=", "model_cfgs", "[", "variant", "]", "if", "not", "cfg_variant", "else", "model_cfgs", "[", "cfg_variant", "]", ",", "\n", "feature_cfg", "=", "dict", "(", "flatten_sequential", "=", "True", ")", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet.botnet26t_256": [[335, 341], ["kwargs.setdefault", "byoanet._create_byoanet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._create_byoanet"], ["", "@", "register_model", "\n", "def", "botnet26t_256", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Bottleneck Transformer w/ ResNet26-T backbone.\n    \"\"\"", "\n", "kwargs", ".", "setdefault", "(", "'img_size'", ",", "256", ")", "\n", "return", "_create_byoanet", "(", "'botnet26t_256'", ",", "'botnet26t'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet.sebotnet33ts_256": [[343, 348], ["byoanet._create_byoanet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._create_byoanet"], ["", "@", "register_model", "\n", "def", "sebotnet33ts_256", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Bottleneck Transformer w/ a ResNet33-t backbone, SE attn for non Halo blocks, SiLU,\n    \"\"\"", "\n", "return", "_create_byoanet", "(", "'sebotnet33ts_256'", ",", "'sebotnet33ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet.botnet50ts_256": [[350, 356], ["kwargs.setdefault", "byoanet._create_byoanet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._create_byoanet"], ["", "@", "register_model", "\n", "def", "botnet50ts_256", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Bottleneck Transformer w/ ResNet50-T backbone, silu act.\n    \"\"\"", "\n", "kwargs", ".", "setdefault", "(", "'img_size'", ",", "256", ")", "\n", "return", "_create_byoanet", "(", "'botnet50ts_256'", ",", "'botnet50ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet.eca_botnext26ts_256": [[358, 364], ["kwargs.setdefault", "byoanet._create_byoanet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._create_byoanet"], ["", "@", "register_model", "\n", "def", "eca_botnext26ts_256", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Bottleneck Transformer w/ ResNet26-T backbone, silu act.\n    \"\"\"", "\n", "kwargs", ".", "setdefault", "(", "'img_size'", ",", "256", ")", "\n", "return", "_create_byoanet", "(", "'eca_botnext26ts_256'", ",", "'eca_botnext26ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet.halonet_h1": [[366, 372], ["byoanet._create_byoanet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._create_byoanet"], ["", "@", "register_model", "\n", "def", "halonet_h1", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" HaloNet-H1. Halo attention in all stages as per the paper.\n    NOTE: This runs very slowly!\n    \"\"\"", "\n", "return", "_create_byoanet", "(", "'halonet_h1'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet.halonet26t": [[374, 379], ["byoanet._create_byoanet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._create_byoanet"], ["", "@", "register_model", "\n", "def", "halonet26t", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" HaloNet w/ a ResNet26-t backbone. Halo attention in final two stages\n    \"\"\"", "\n", "return", "_create_byoanet", "(", "'halonet26t'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet.sehalonet33ts": [[381, 386], ["byoanet._create_byoanet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._create_byoanet"], ["", "@", "register_model", "\n", "def", "sehalonet33ts", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" HaloNet w/ a ResNet33-t backbone, SE attn for non Halo blocks, SiLU, 1-2 Halo in stage 2,3,4.\n    \"\"\"", "\n", "return", "_create_byoanet", "(", "'sehalonet33ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet.halonet50ts": [[388, 393], ["byoanet._create_byoanet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._create_byoanet"], ["", "@", "register_model", "\n", "def", "halonet50ts", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" HaloNet w/ a ResNet50-t backbone, silu act. Halo attention in final two stages\n    \"\"\"", "\n", "return", "_create_byoanet", "(", "'halonet50ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet.eca_halonext26ts": [[395, 400], ["byoanet._create_byoanet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._create_byoanet"], ["", "@", "register_model", "\n", "def", "eca_halonext26ts", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" HaloNet w/ a ResNet26-t backbone, silu act. Halo attention in final two stages\n    \"\"\"", "\n", "return", "_create_byoanet", "(", "'eca_halonext26ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet.lambda_resnet26t": [[402, 407], ["byoanet._create_byoanet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._create_byoanet"], ["", "@", "register_model", "\n", "def", "lambda_resnet26t", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Lambda-ResNet-26-T. Lambda layers w/ conv pos in last two stages.\n    \"\"\"", "\n", "return", "_create_byoanet", "(", "'lambda_resnet26t'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet.lambda_resnet50ts": [[409, 414], ["byoanet._create_byoanet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._create_byoanet"], ["", "@", "register_model", "\n", "def", "lambda_resnet50ts", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Lambda-ResNet-50-TS. SiLU act. Lambda layers w/ conv pos in last two stages.\n    \"\"\"", "\n", "return", "_create_byoanet", "(", "'lambda_resnet50ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet.lambda_resnet26rpt_256": [[416, 422], ["kwargs.setdefault", "byoanet._create_byoanet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._create_byoanet"], ["", "@", "register_model", "\n", "def", "lambda_resnet26rpt_256", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Lambda-ResNet-26-R-T. Lambda layers w/ rel pos embed in last two stages.\n    \"\"\"", "\n", "kwargs", ".", "setdefault", "(", "'img_size'", ",", "256", ")", "\n", "return", "_create_byoanet", "(", "'lambda_resnet26rpt_256'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet.haloregnetz_b": [[424, 429], ["byoanet._create_byoanet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._create_byoanet"], ["", "@", "register_model", "\n", "def", "haloregnetz_b", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Halo + RegNetZ\n    \"\"\"", "\n", "return", "_create_byoanet", "(", "'haloregnetz_b'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet.lamhalobotnet50ts_256": [[431, 436], ["byoanet._create_byoanet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._create_byoanet"], ["", "@", "register_model", "\n", "def", "lamhalobotnet50ts_256", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Combo Attention (Lambda + Halo + Bot) Network\n    \"\"\"", "\n", "return", "_create_byoanet", "(", "'lamhalobotnet50ts_256'", ",", "'lamhalobotnet50ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet.halo2botnet50ts_256": [[438, 443], ["byoanet._create_byoanet"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.byoanet._create_byoanet"], ["", "@", "register_model", "\n", "def", "halo2botnet50ts_256", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Combo Attention (Halo + Halo + Bot) Network\n    \"\"\"", "\n", "return", "_create_byoanet", "(", "'halo2botnet50ts_256'", ",", "'halo2botnet50ts'", ",", "pretrained", "=", "pretrained", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ConvRelPosEnc.__init__": [[66, 105], ["torch.Module.__init__", "isinstance", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "window.items", "isinstance", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "coat.ConvRelPosEnc.conv_list.append", "coat.ConvRelPosEnc.head_splits.append", "ValueError"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "Ch", ",", "h", ",", "window", ")", ":", "\n", "        ", "\"\"\"\n        Initialization.\n            Ch: Channels per head.\n            h: Number of heads.\n            window: Window size(s) in convolutional relative positional encoding. It can have two forms:\n                1. An integer of window size, which assigns all attention heads with the same window s\n                    size in ConvRelPosEnc.\n                2. A dict mapping window size to #attention head splits (\n                    e.g. {window size 1: #attention head split 1, window size 2: #attention head split 2})\n                    It will apply different window size to the attention head splits.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "isinstance", "(", "window", ",", "int", ")", ":", "\n", "# Set the same window size for all attention heads.", "\n", "            ", "window", "=", "{", "window", ":", "h", "}", "\n", "self", ".", "window", "=", "window", "\n", "", "elif", "isinstance", "(", "window", ",", "dict", ")", ":", "\n", "            ", "self", ".", "window", "=", "window", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", ")", "\n", "\n", "", "self", ".", "conv_list", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "head_splits", "=", "[", "]", "\n", "for", "cur_window", ",", "cur_head_split", "in", "window", ".", "items", "(", ")", ":", "\n", "            ", "dilation", "=", "1", "\n", "# Determine padding size.", "\n", "# Ref: https://discuss.pytorch.org/t/how-to-keep-the-shape-of-input-and-output-same-when-dilation-conv/14338", "\n", "padding_size", "=", "(", "cur_window", "+", "(", "cur_window", "-", "1", ")", "*", "(", "dilation", "-", "1", ")", ")", "//", "2", "\n", "cur_conv", "=", "nn", ".", "Conv2d", "(", "cur_head_split", "*", "Ch", ",", "cur_head_split", "*", "Ch", ",", "\n", "kernel_size", "=", "(", "cur_window", ",", "cur_window", ")", ",", "\n", "padding", "=", "(", "padding_size", ",", "padding_size", ")", ",", "\n", "dilation", "=", "(", "dilation", ",", "dilation", ")", ",", "\n", "groups", "=", "cur_head_split", "*", "Ch", ",", "\n", ")", "\n", "self", ".", "conv_list", ".", "append", "(", "cur_conv", ")", "\n", "self", ".", "head_splits", ".", "append", "(", "cur_head_split", ")", "\n", "", "self", ".", "channel_splits", "=", "[", "x", "*", "Ch", "for", "x", "in", "self", ".", "head_splits", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ConvRelPosEnc.forward": [[106, 126], ["layers._assert", "v_img.transpose().reshape.transpose().reshape.transpose().reshape", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "conv_v_img.reshape().transpose.reshape().transpose.reshape().transpose", "torch.pad", "torch.pad", "torch.pad", "conv_v_img_list.append", "v_img.transpose().reshape.transpose().reshape.transpose", "conv", "conv_v_img.reshape().transpose.reshape().transpose.reshape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "v", ",", "size", ":", "Tuple", "[", "int", ",", "int", "]", ")", ":", "\n", "        ", "B", ",", "h", ",", "N", ",", "Ch", "=", "q", ".", "shape", "\n", "H", ",", "W", "=", "size", "\n", "_assert", "(", "N", "==", "1", "+", "H", "*", "W", ",", "''", ")", "\n", "\n", "# Convolutional relative position encoding.", "\n", "q_img", "=", "q", "[", ":", ",", ":", ",", "1", ":", ",", ":", "]", "# [B, h, H*W, Ch]", "\n", "v_img", "=", "v", "[", ":", ",", ":", ",", "1", ":", ",", ":", "]", "# [B, h, H*W, Ch]", "\n", "\n", "v_img", "=", "v_img", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ".", "reshape", "(", "B", ",", "h", "*", "Ch", ",", "H", ",", "W", ")", "\n", "v_img_list", "=", "torch", ".", "split", "(", "v_img", ",", "self", ".", "channel_splits", ",", "dim", "=", "1", ")", "# Split according to channels", "\n", "conv_v_img_list", "=", "[", "]", "\n", "for", "i", ",", "conv", "in", "enumerate", "(", "self", ".", "conv_list", ")", ":", "\n", "            ", "conv_v_img_list", ".", "append", "(", "conv", "(", "v_img_list", "[", "i", "]", ")", ")", "\n", "", "conv_v_img", "=", "torch", ".", "cat", "(", "conv_v_img_list", ",", "dim", "=", "1", ")", "\n", "conv_v_img", "=", "conv_v_img", ".", "reshape", "(", "B", ",", "h", ",", "Ch", ",", "H", "*", "W", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "\n", "EV_hat", "=", "q_img", "*", "conv_v_img", "\n", "EV_hat", "=", "F", ".", "pad", "(", "EV_hat", ",", "(", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ")", ")", "# [B, h, N, Ch].", "\n", "return", "EV_hat", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.FactorAttnConvRelPosEnc.__init__": [[130, 143], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "qkv_bias", "=", "False", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ",", "shared_crpe", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "self", ".", "scale", "=", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", "*", "3", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "# Note: attn_drop is actually not used.", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n", "# Shared convolutional relative position encoding.", "\n", "self", ".", "crpe", "=", "shared_crpe", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.FactorAttnConvRelPosEnc.forward": [[144, 168], ["coat.FactorAttnConvRelPosEnc.qkv().reshape().permute", "k.softmax", "coat.FactorAttnConvRelPosEnc.crpe", "coat.FactorAttnConvRelPosEnc.transpose().reshape", "coat.FactorAttnConvRelPosEnc.proj", "coat.FactorAttnConvRelPosEnc.proj_drop", "k.softmax.transpose", "coat.FactorAttnConvRelPosEnc.qkv().reshape", "coat.FactorAttnConvRelPosEnc.transpose", "coat.FactorAttnConvRelPosEnc.qkv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "size", ":", "Tuple", "[", "int", ",", "int", "]", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "\n", "# Generate Q, K, V.", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "3", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", "[", "0", "]", ",", "qkv", "[", "1", "]", ",", "qkv", "[", "2", "]", "# [B, h, N, Ch]", "\n", "\n", "# Factorized attention.", "\n", "k_softmax", "=", "k", ".", "softmax", "(", "dim", "=", "2", ")", "\n", "factor_att", "=", "k_softmax", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "@", "v", "\n", "factor_att", "=", "q", "@", "factor_att", "\n", "\n", "# Convolutional relative position encoding.", "\n", "crpe", "=", "self", ".", "crpe", "(", "q", ",", "v", ",", "size", "=", "size", ")", "# [B, h, N, Ch]", "\n", "\n", "# Merge and reshape.", "\n", "x", "=", "self", ".", "scale", "*", "factor_att", "+", "crpe", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "N", ",", "C", ")", "# [B, h, N, Ch] -> [B, N, h, Ch] -> [B, N, C]", "\n", "\n", "# Output projection.", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ConvPosEnc.__init__": [[174, 177], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "k", "=", "3", ")", ":", "\n", "        ", "super", "(", "ConvPosEnc", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "k", ",", "1", ",", "k", "//", "2", ",", "groups", "=", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ConvPosEnc.forward": [[178, 195], ["layers._assert", "img_tokens.transpose().view", "torch.cat.flatten().transpose", "torch.cat.flatten().transpose", "torch.cat.flatten().transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "coat.ConvPosEnc.proj", "img_tokens.transpose", "torch.cat.flatten", "torch.cat.flatten", "torch.cat.flatten"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "size", ":", "Tuple", "[", "int", ",", "int", "]", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "H", ",", "W", "=", "size", "\n", "_assert", "(", "N", "==", "1", "+", "H", "*", "W", ",", "''", ")", "\n", "\n", "# Extract CLS token and image tokens.", "\n", "cls_token", ",", "img_tokens", "=", "x", "[", ":", ",", ":", "1", "]", ",", "x", "[", ":", ",", "1", ":", "]", "# [B, 1, C], [B, H*W, C]", "\n", "\n", "# Depthwise convolution.", "\n", "feat", "=", "img_tokens", ".", "transpose", "(", "1", ",", "2", ")", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", "\n", "x", "=", "self", ".", "proj", "(", "feat", ")", "+", "feat", "\n", "x", "=", "x", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "# Combine with CLS token.", "\n", "x", "=", "torch", ".", "cat", "(", "(", "cls_token", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.SerialBlock.__init__": [[200, 216], ["torch.Module.__init__", "norm_layer", "coat.FactorAttnConvRelPosEnc", "norm_layer", "int", "layers.Mlp", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "num_heads", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "\n", "drop_path", "=", "0.", ",", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "shared_cpe", "=", "None", ",", "shared_crpe", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# Conv-Attention.", "\n", "self", ".", "cpe", "=", "shared_cpe", "\n", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "factoratt_crpe", "=", "FactorAttnConvRelPosEnc", "(", "\n", "dim", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ",", "shared_crpe", "=", "shared_crpe", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "# MLP.", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "mlp_hidden_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "in_features", "=", "dim", ",", "hidden_features", "=", "mlp_hidden_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.SerialBlock.forward": [[217, 230], ["coat.SerialBlock.cpe", "coat.SerialBlock.norm1", "coat.SerialBlock.factoratt_crpe", "coat.SerialBlock.norm2", "coat.SerialBlock.mlp", "coat.SerialBlock.drop_path", "coat.SerialBlock.drop_path"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ",", "size", ":", "Tuple", "[", "int", ",", "int", "]", ")", ":", "\n", "# Conv-Attention.", "\n", "        ", "x", "=", "self", ".", "cpe", "(", "x", ",", "size", ")", "\n", "cur", "=", "self", ".", "norm1", "(", "x", ")", "\n", "cur", "=", "self", ".", "factoratt_crpe", "(", "cur", ",", "size", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "cur", ")", "\n", "\n", "# MLP. ", "\n", "cur", "=", "self", ".", "norm2", "(", "x", ")", "\n", "cur", "=", "self", ".", "mlp", "(", "cur", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "cur", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.__init__": [[234, 266], ["torch.Module.__init__", "norm_layer", "norm_layer", "norm_layer", "coat.FactorAttnConvRelPosEnc", "coat.FactorAttnConvRelPosEnc", "coat.FactorAttnConvRelPosEnc", "norm_layer", "norm_layer", "norm_layer", "int", "layers.Mlp", "layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "dims", ",", "num_heads", ",", "mlp_ratios", "=", "[", "]", ",", "qkv_bias", "=", "False", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "\n", "drop_path", "=", "0.", ",", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "shared_crpes", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# Conv-Attention.", "\n", "self", ".", "norm12", "=", "norm_layer", "(", "dims", "[", "1", "]", ")", "\n", "self", ".", "norm13", "=", "norm_layer", "(", "dims", "[", "2", "]", ")", "\n", "self", ".", "norm14", "=", "norm_layer", "(", "dims", "[", "3", "]", ")", "\n", "self", ".", "factoratt_crpe2", "=", "FactorAttnConvRelPosEnc", "(", "\n", "dims", "[", "1", "]", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ",", "\n", "shared_crpe", "=", "shared_crpes", "[", "1", "]", "\n", ")", "\n", "self", ".", "factoratt_crpe3", "=", "FactorAttnConvRelPosEnc", "(", "\n", "dims", "[", "2", "]", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ",", "\n", "shared_crpe", "=", "shared_crpes", "[", "2", "]", "\n", ")", "\n", "self", ".", "factoratt_crpe4", "=", "FactorAttnConvRelPosEnc", "(", "\n", "dims", "[", "3", "]", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ",", "\n", "shared_crpe", "=", "shared_crpes", "[", "3", "]", "\n", ")", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "# MLP.", "\n", "self", ".", "norm22", "=", "norm_layer", "(", "dims", "[", "1", "]", ")", "\n", "self", ".", "norm23", "=", "norm_layer", "(", "dims", "[", "2", "]", ")", "\n", "self", ".", "norm24", "=", "norm_layer", "(", "dims", "[", "3", "]", ")", "\n", "# In parallel block, we assume dimensions are the same and share the linear transformation.", "\n", "assert", "dims", "[", "1", "]", "==", "dims", "[", "2", "]", "==", "dims", "[", "3", "]", "\n", "assert", "mlp_ratios", "[", "1", "]", "==", "mlp_ratios", "[", "2", "]", "==", "mlp_ratios", "[", "3", "]", "\n", "mlp_hidden_dim", "=", "int", "(", "dims", "[", "1", "]", "*", "mlp_ratios", "[", "1", "]", ")", "\n", "self", ".", "mlp2", "=", "self", ".", "mlp3", "=", "self", ".", "mlp4", "=", "Mlp", "(", "\n", "in_features", "=", "dims", "[", "1", "]", ",", "hidden_features", "=", "mlp_hidden_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.upsample": [[267, 270], ["coat.ParallelBlock.interpolate"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate"], ["", "def", "upsample", "(", "self", ",", "x", ",", "factor", ":", "float", ",", "size", ":", "Tuple", "[", "int", ",", "int", "]", ")", ":", "\n", "        ", "\"\"\" Feature map up-sampling. \"\"\"", "\n", "return", "self", ".", "interpolate", "(", "x", ",", "scale_factor", "=", "factor", ",", "size", "=", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample": [[271, 274], ["coat.ParallelBlock.interpolate"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate"], ["", "def", "downsample", "(", "self", ",", "x", ",", "factor", ":", "float", ",", "size", ":", "Tuple", "[", "int", ",", "int", "]", ")", ":", "\n", "        ", "\"\"\" Feature map down-sampling. \"\"\"", "\n", "return", "self", ".", "interpolate", "(", "x", ",", "scale_factor", "=", "1.0", "/", "factor", ",", "size", "=", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate": [[275, 292], ["layers._assert", "img_tokens.reshape().transpose.reshape().transpose.transpose().reshape", "torch.interpolate", "torch.interpolate", "torch.interpolate", "img_tokens.reshape().transpose.reshape().transpose.reshape().transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "img_tokens.reshape().transpose.reshape().transpose.transpose", "img_tokens.reshape().transpose.reshape().transpose.reshape"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate"], ["", "def", "interpolate", "(", "self", ",", "x", ",", "scale_factor", ":", "float", ",", "size", ":", "Tuple", "[", "int", ",", "int", "]", ")", ":", "\n", "        ", "\"\"\" Feature map interpolation. \"\"\"", "\n", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "H", ",", "W", "=", "size", "\n", "_assert", "(", "N", "==", "1", "+", "H", "*", "W", ",", "''", ")", "\n", "\n", "cls_token", "=", "x", "[", ":", ",", ":", "1", ",", ":", "]", "\n", "img_tokens", "=", "x", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "\n", "img_tokens", "=", "img_tokens", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "C", ",", "H", ",", "W", ")", "\n", "img_tokens", "=", "F", ".", "interpolate", "(", "\n", "img_tokens", ",", "scale_factor", "=", "scale_factor", ",", "recompute_scale_factor", "=", "False", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "False", ")", "\n", "img_tokens", "=", "img_tokens", ".", "reshape", "(", "B", ",", "C", ",", "-", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "out", "=", "torch", ".", "cat", "(", "(", "cls_token", ",", "img_tokens", ")", ",", "dim", "=", "1", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.forward": [[293, 326], ["coat.ParallelBlock.norm12", "coat.ParallelBlock.norm13", "coat.ParallelBlock.norm14", "coat.ParallelBlock.factoratt_crpe2", "coat.ParallelBlock.factoratt_crpe3", "coat.ParallelBlock.factoratt_crpe4", "coat.ParallelBlock.upsample", "coat.ParallelBlock.upsample", "coat.ParallelBlock.upsample", "coat.ParallelBlock.downsample", "coat.ParallelBlock.downsample", "coat.ParallelBlock.downsample", "coat.ParallelBlock.norm22", "coat.ParallelBlock.norm23", "coat.ParallelBlock.norm24", "coat.ParallelBlock.mlp2", "coat.ParallelBlock.mlp3", "coat.ParallelBlock.mlp4", "coat.ParallelBlock.drop_path", "coat.ParallelBlock.drop_path", "coat.ParallelBlock.drop_path", "coat.ParallelBlock.drop_path", "coat.ParallelBlock.drop_path", "coat.ParallelBlock.drop_path"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.upsample", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.upsample", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.upsample", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ",", "x3", ",", "x4", ",", "sizes", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ")", ":", "\n", "        ", "_", ",", "S2", ",", "S3", ",", "S4", "=", "sizes", "\n", "cur2", "=", "self", ".", "norm12", "(", "x2", ")", "\n", "cur3", "=", "self", ".", "norm13", "(", "x3", ")", "\n", "cur4", "=", "self", ".", "norm14", "(", "x4", ")", "\n", "cur2", "=", "self", ".", "factoratt_crpe2", "(", "cur2", ",", "size", "=", "S2", ")", "\n", "cur3", "=", "self", ".", "factoratt_crpe3", "(", "cur3", ",", "size", "=", "S3", ")", "\n", "cur4", "=", "self", ".", "factoratt_crpe4", "(", "cur4", ",", "size", "=", "S4", ")", "\n", "upsample3_2", "=", "self", ".", "upsample", "(", "cur3", ",", "factor", "=", "2.", ",", "size", "=", "S3", ")", "\n", "upsample4_3", "=", "self", ".", "upsample", "(", "cur4", ",", "factor", "=", "2.", ",", "size", "=", "S4", ")", "\n", "upsample4_2", "=", "self", ".", "upsample", "(", "cur4", ",", "factor", "=", "4.", ",", "size", "=", "S4", ")", "\n", "downsample2_3", "=", "self", ".", "downsample", "(", "cur2", ",", "factor", "=", "2.", ",", "size", "=", "S2", ")", "\n", "downsample3_4", "=", "self", ".", "downsample", "(", "cur3", ",", "factor", "=", "2.", ",", "size", "=", "S3", ")", "\n", "downsample2_4", "=", "self", ".", "downsample", "(", "cur2", ",", "factor", "=", "4.", ",", "size", "=", "S2", ")", "\n", "cur2", "=", "cur2", "+", "upsample3_2", "+", "upsample4_2", "\n", "cur3", "=", "cur3", "+", "upsample4_3", "+", "downsample2_3", "\n", "cur4", "=", "cur4", "+", "downsample3_4", "+", "downsample2_4", "\n", "x2", "=", "x2", "+", "self", ".", "drop_path", "(", "cur2", ")", "\n", "x3", "=", "x3", "+", "self", ".", "drop_path", "(", "cur3", ")", "\n", "x4", "=", "x4", "+", "self", ".", "drop_path", "(", "cur4", ")", "\n", "\n", "# MLP. ", "\n", "cur2", "=", "self", ".", "norm22", "(", "x2", ")", "\n", "cur3", "=", "self", ".", "norm23", "(", "x3", ")", "\n", "cur4", "=", "self", ".", "norm24", "(", "x4", ")", "\n", "cur2", "=", "self", ".", "mlp2", "(", "cur2", ")", "\n", "cur3", "=", "self", ".", "mlp3", "(", "cur3", ")", "\n", "cur4", "=", "self", ".", "mlp4", "(", "cur4", ")", "\n", "x2", "=", "x2", "+", "self", ".", "drop_path", "(", "cur2", ")", "\n", "x3", "=", "x3", "+", "self", ".", "drop_path", "(", "cur3", ")", "\n", "x4", "=", "x4", "+", "self", ".", "drop_path", "(", "cur4", ")", "\n", "\n", "return", "x1", ",", "x2", ",", "x3", ",", "x4", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.__init__": [[330, 461], ["functools.partial", "torch.Module.__init__", "layers.to_2tuple", "layers.PatchEmbed", "layers.PatchEmbed", "layers.PatchEmbed", "layers.PatchEmbed", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "coat.ConvPosEnc", "coat.ConvPosEnc", "coat.ConvPosEnc", "coat.ConvPosEnc", "coat.ConvRelPosEnc", "coat.ConvRelPosEnc", "coat.ConvRelPosEnc", "coat.ConvRelPosEnc", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "layers.trunc_normal_", "layers.trunc_normal_", "layers.trunc_normal_", "layers.trunc_normal_", "coat.CoaT.apply", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "norm_layer", "coat.SerialBlock", "coat.SerialBlock", "coat.SerialBlock", "coat.SerialBlock", "norm_layer", "norm_layer", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "range", "range", "range", "range", "coat.ParallelBlock", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "range"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["def", "__init__", "(", "\n", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1000", ",", "embed_dims", "=", "(", "0", ",", "0", ",", "0", ",", "0", ")", ",", "\n", "serial_depths", "=", "(", "0", ",", "0", ",", "0", ",", "0", ")", ",", "parallel_depth", "=", "0", ",", "num_heads", "=", "0", ",", "mlp_ratios", "=", "(", "0", ",", "0", ",", "0", ",", "0", ")", ",", "qkv_bias", "=", "True", ",", "\n", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "drop_path_rate", "=", "0.", ",", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "\n", "return_interm_layers", "=", "False", ",", "out_features", "=", "None", ",", "crpe_window", "=", "None", ",", "global_pool", "=", "'token'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "global_pool", "in", "(", "'token'", ",", "'avg'", ")", "\n", "crpe_window", "=", "crpe_window", "or", "{", "3", ":", "2", ",", "5", ":", "3", ",", "7", ":", "3", "}", "\n", "self", ".", "return_interm_layers", "=", "return_interm_layers", "\n", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "embed_dims", "=", "embed_dims", "\n", "self", ".", "num_features", "=", "embed_dims", "[", "-", "1", "]", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "\n", "# Patch embeddings.", "\n", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "self", ".", "patch_embed1", "=", "PatchEmbed", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "\n", "embed_dim", "=", "embed_dims", "[", "0", "]", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", "\n", "self", ".", "patch_embed2", "=", "PatchEmbed", "(", "\n", "img_size", "=", "[", "x", "//", "4", "for", "x", "in", "img_size", "]", ",", "patch_size", "=", "2", ",", "in_chans", "=", "embed_dims", "[", "0", "]", ",", "\n", "embed_dim", "=", "embed_dims", "[", "1", "]", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", "\n", "self", ".", "patch_embed3", "=", "PatchEmbed", "(", "\n", "img_size", "=", "[", "x", "//", "8", "for", "x", "in", "img_size", "]", ",", "patch_size", "=", "2", ",", "in_chans", "=", "embed_dims", "[", "1", "]", ",", "\n", "embed_dim", "=", "embed_dims", "[", "2", "]", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", "\n", "self", ".", "patch_embed4", "=", "PatchEmbed", "(", "\n", "img_size", "=", "[", "x", "//", "16", "for", "x", "in", "img_size", "]", ",", "patch_size", "=", "2", ",", "in_chans", "=", "embed_dims", "[", "2", "]", ",", "\n", "embed_dim", "=", "embed_dims", "[", "3", "]", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", "\n", "\n", "# Class tokens.", "\n", "self", ".", "cls_token1", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "embed_dims", "[", "0", "]", ")", ")", "\n", "self", ".", "cls_token2", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "embed_dims", "[", "1", "]", ")", ")", "\n", "self", ".", "cls_token3", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "embed_dims", "[", "2", "]", ")", ")", "\n", "self", ".", "cls_token4", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "embed_dims", "[", "3", "]", ")", ")", "\n", "\n", "# Convolutional position encodings.", "\n", "self", ".", "cpe1", "=", "ConvPosEnc", "(", "dim", "=", "embed_dims", "[", "0", "]", ",", "k", "=", "3", ")", "\n", "self", ".", "cpe2", "=", "ConvPosEnc", "(", "dim", "=", "embed_dims", "[", "1", "]", ",", "k", "=", "3", ")", "\n", "self", ".", "cpe3", "=", "ConvPosEnc", "(", "dim", "=", "embed_dims", "[", "2", "]", ",", "k", "=", "3", ")", "\n", "self", ".", "cpe4", "=", "ConvPosEnc", "(", "dim", "=", "embed_dims", "[", "3", "]", ",", "k", "=", "3", ")", "\n", "\n", "# Convolutional relative position encodings.", "\n", "self", ".", "crpe1", "=", "ConvRelPosEnc", "(", "Ch", "=", "embed_dims", "[", "0", "]", "//", "num_heads", ",", "h", "=", "num_heads", ",", "window", "=", "crpe_window", ")", "\n", "self", ".", "crpe2", "=", "ConvRelPosEnc", "(", "Ch", "=", "embed_dims", "[", "1", "]", "//", "num_heads", ",", "h", "=", "num_heads", ",", "window", "=", "crpe_window", ")", "\n", "self", ".", "crpe3", "=", "ConvRelPosEnc", "(", "Ch", "=", "embed_dims", "[", "2", "]", "//", "num_heads", ",", "h", "=", "num_heads", ",", "window", "=", "crpe_window", ")", "\n", "self", ".", "crpe4", "=", "ConvRelPosEnc", "(", "Ch", "=", "embed_dims", "[", "3", "]", "//", "num_heads", ",", "h", "=", "num_heads", ",", "window", "=", "crpe_window", ")", "\n", "\n", "# Disable stochastic depth.", "\n", "dpr", "=", "drop_path_rate", "\n", "assert", "dpr", "==", "0.0", "\n", "\n", "# Serial blocks 1.", "\n", "self", ".", "serial_blocks1", "=", "nn", ".", "ModuleList", "(", "[", "\n", "SerialBlock", "(", "\n", "dim", "=", "embed_dims", "[", "0", "]", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratios", "[", "0", "]", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", ",", "norm_layer", "=", "norm_layer", ",", "\n", "shared_cpe", "=", "self", ".", "cpe1", ",", "shared_crpe", "=", "self", ".", "crpe1", "\n", ")", "\n", "for", "_", "in", "range", "(", "serial_depths", "[", "0", "]", ")", "]", "\n", ")", "\n", "\n", "# Serial blocks 2.", "\n", "self", ".", "serial_blocks2", "=", "nn", ".", "ModuleList", "(", "[", "\n", "SerialBlock", "(", "\n", "dim", "=", "embed_dims", "[", "1", "]", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratios", "[", "1", "]", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", ",", "norm_layer", "=", "norm_layer", ",", "\n", "shared_cpe", "=", "self", ".", "cpe2", ",", "shared_crpe", "=", "self", ".", "crpe2", "\n", ")", "\n", "for", "_", "in", "range", "(", "serial_depths", "[", "1", "]", ")", "]", "\n", ")", "\n", "\n", "# Serial blocks 3.", "\n", "self", ".", "serial_blocks3", "=", "nn", ".", "ModuleList", "(", "[", "\n", "SerialBlock", "(", "\n", "dim", "=", "embed_dims", "[", "2", "]", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratios", "[", "2", "]", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", ",", "norm_layer", "=", "norm_layer", ",", "\n", "shared_cpe", "=", "self", ".", "cpe3", ",", "shared_crpe", "=", "self", ".", "crpe3", "\n", ")", "\n", "for", "_", "in", "range", "(", "serial_depths", "[", "2", "]", ")", "]", "\n", ")", "\n", "\n", "# Serial blocks 4.", "\n", "self", ".", "serial_blocks4", "=", "nn", ".", "ModuleList", "(", "[", "\n", "SerialBlock", "(", "\n", "dim", "=", "embed_dims", "[", "3", "]", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratios", "[", "3", "]", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", ",", "norm_layer", "=", "norm_layer", ",", "\n", "shared_cpe", "=", "self", ".", "cpe4", ",", "shared_crpe", "=", "self", ".", "crpe4", "\n", ")", "\n", "for", "_", "in", "range", "(", "serial_depths", "[", "3", "]", ")", "]", "\n", ")", "\n", "\n", "# Parallel blocks.", "\n", "self", ".", "parallel_depth", "=", "parallel_depth", "\n", "if", "self", ".", "parallel_depth", ">", "0", ":", "\n", "            ", "self", ".", "parallel_blocks", "=", "nn", ".", "ModuleList", "(", "[", "\n", "ParallelBlock", "(", "\n", "dims", "=", "embed_dims", ",", "num_heads", "=", "num_heads", ",", "mlp_ratios", "=", "mlp_ratios", ",", "qkv_bias", "=", "qkv_bias", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", ",", "norm_layer", "=", "norm_layer", ",", "\n", "shared_crpes", "=", "(", "self", ".", "crpe1", ",", "self", ".", "crpe2", ",", "self", ".", "crpe3", ",", "self", ".", "crpe4", ")", "\n", ")", "\n", "for", "_", "in", "range", "(", "parallel_depth", ")", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "parallel_blocks", "=", "None", "\n", "\n", "# Classification head(s).", "\n", "", "if", "not", "self", ".", "return_interm_layers", ":", "\n", "            ", "if", "self", ".", "parallel_blocks", "is", "not", "None", ":", "\n", "                ", "self", ".", "norm2", "=", "norm_layer", "(", "embed_dims", "[", "1", "]", ")", "\n", "self", ".", "norm3", "=", "norm_layer", "(", "embed_dims", "[", "2", "]", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "norm2", "=", "self", ".", "norm3", "=", "None", "\n", "", "self", ".", "norm4", "=", "norm_layer", "(", "embed_dims", "[", "3", "]", ")", "\n", "\n", "if", "self", ".", "parallel_depth", ">", "0", ":", "\n", "# CoaT series: Aggregate features of last three scales for classification.", "\n", "                ", "assert", "embed_dims", "[", "1", "]", "==", "embed_dims", "[", "2", "]", "==", "embed_dims", "[", "3", "]", "\n", "self", ".", "aggregate", "=", "torch", ".", "nn", ".", "Conv1d", "(", "in_channels", "=", "3", ",", "out_channels", "=", "1", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "", "else", ":", "\n", "# CoaT-Lite series: Use feature of last scale for classification.", "\n", "                ", "self", ".", "aggregate", "=", "None", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "# Initialize weights.", "\n", "", "", "trunc_normal_", "(", "self", ".", "cls_token1", ",", "std", "=", ".02", ")", "\n", "trunc_normal_", "(", "self", ".", "cls_token2", ",", "std", "=", ".02", ")", "\n", "trunc_normal_", "(", "self", ".", "cls_token3", ",", "std", "=", ".02", ")", "\n", "trunc_normal_", "(", "self", ".", "cls_token4", ",", "std", "=", ".02", ")", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT._init_weights": [[462, 470], ["isinstance", "layers.trunc_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", ".02", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.no_weight_decay": [[471, 474], ["None"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "{", "'cls_token1'", ",", "'cls_token2'", ",", "'cls_token3'", ",", "'cls_token4'", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.set_grad_checkpointing": [[475, 478], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "assert", "not", "enable", ",", "'gradient checkpointing not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.group_matcher": [[479, 496], ["dict"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "group_matcher", "(", "self", ",", "coarse", "=", "False", ")", ":", "\n", "        ", "matcher", "=", "dict", "(", "\n", "stem1", "=", "r'^cls_token1|patch_embed1|crpe1|cpe1'", ",", "\n", "serial_blocks1", "=", "r'^serial_blocks1\\.(\\d+)'", ",", "\n", "stem2", "=", "r'^cls_token2|patch_embed2|crpe2|cpe2'", ",", "\n", "serial_blocks2", "=", "r'^serial_blocks2\\.(\\d+)'", ",", "\n", "stem3", "=", "r'^cls_token3|patch_embed3|crpe3|cpe3'", ",", "\n", "serial_blocks3", "=", "r'^serial_blocks3\\.(\\d+)'", ",", "\n", "stem4", "=", "r'^cls_token4|patch_embed4|crpe4|cpe4'", ",", "\n", "serial_blocks4", "=", "r'^serial_blocks4\\.(\\d+)'", ",", "\n", "parallel_blocks", "=", "[", "# FIXME (partially?) overlap parallel w/ serial blocks??", "\n", "(", "r'^parallel_blocks\\.(\\d+)'", ",", "None", ")", ",", "\n", "(", "r'^norm|aggregate'", ",", "(", "99999", ",", ")", ")", ",", "\n", "]", "\n", ")", "\n", "return", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.get_classifier": [[497, 500], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.reset_classifier": [[501, 507], ["torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "None", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "if", "global_pool", "is", "not", "None", ":", "\n", "            ", "assert", "global_pool", "in", "(", "'token'", ",", "'avg'", ")", "\n", "self", ".", "global_pool", "=", "global_pool", "\n", "", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features": [[508, 588], ["coat.CoaT.patch_embed1", "coat.insert_cls", "remove_cls().reshape().permute().contiguous", "coat.CoaT.patch_embed2", "coat.insert_cls", "remove_cls().reshape().permute().contiguous", "coat.CoaT.patch_embed3", "coat.insert_cls", "remove_cls().reshape().permute().contiguous", "coat.CoaT.patch_embed4", "coat.insert_cls", "remove_cls().reshape().permute().contiguous", "blk", "blk", "blk", "blk", "blk", "coat.CoaT.norm2", "coat.CoaT.norm3", "coat.CoaT.norm4", "remove_cls().reshape().permute", "remove_cls().reshape().permute", "remove_cls().reshape().permute", "remove_cls().reshape().permute", "coat.CoaT.norm4", "coat.CoaT.cpe2", "coat.CoaT.cpe3", "coat.CoaT.cpe4", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "remove_cls().reshape().permute().contiguous", "remove_cls().reshape().permute().contiguous", "remove_cls().reshape().permute().contiguous", "remove_cls().reshape().permute().contiguous", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "remove_cls().reshape", "remove_cls().reshape", "remove_cls().reshape", "remove_cls().reshape", "remove_cls().reshape().permute", "remove_cls().reshape().permute", "remove_cls().reshape().permute", "remove_cls().reshape().permute", "coat.remove_cls", "coat.remove_cls", "coat.remove_cls", "coat.remove_cls", "remove_cls().reshape", "remove_cls().reshape", "remove_cls().reshape", "remove_cls().reshape", "coat.remove_cls", "coat.remove_cls", "coat.remove_cls", "coat.remove_cls"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.insert_cls", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.insert_cls", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.insert_cls", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.insert_cls", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.remove_cls", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.remove_cls", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.remove_cls", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.remove_cls", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.remove_cls", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.remove_cls", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.remove_cls", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.remove_cls"], ["", "def", "forward_features", "(", "self", ",", "x0", ")", ":", "\n", "        ", "B", "=", "x0", ".", "shape", "[", "0", "]", "\n", "\n", "# Serial blocks 1.", "\n", "x1", "=", "self", ".", "patch_embed1", "(", "x0", ")", "\n", "H1", ",", "W1", "=", "self", ".", "patch_embed1", ".", "grid_size", "\n", "x1", "=", "insert_cls", "(", "x1", ",", "self", ".", "cls_token1", ")", "\n", "for", "blk", "in", "self", ".", "serial_blocks1", ":", "\n", "            ", "x1", "=", "blk", "(", "x1", ",", "size", "=", "(", "H1", ",", "W1", ")", ")", "\n", "", "x1_nocls", "=", "remove_cls", "(", "x1", ")", ".", "reshape", "(", "B", ",", "H1", ",", "W1", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Serial blocks 2.", "\n", "x2", "=", "self", ".", "patch_embed2", "(", "x1_nocls", ")", "\n", "H2", ",", "W2", "=", "self", ".", "patch_embed2", ".", "grid_size", "\n", "x2", "=", "insert_cls", "(", "x2", ",", "self", ".", "cls_token2", ")", "\n", "for", "blk", "in", "self", ".", "serial_blocks2", ":", "\n", "            ", "x2", "=", "blk", "(", "x2", ",", "size", "=", "(", "H2", ",", "W2", ")", ")", "\n", "", "x2_nocls", "=", "remove_cls", "(", "x2", ")", ".", "reshape", "(", "B", ",", "H2", ",", "W2", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Serial blocks 3.", "\n", "x3", "=", "self", ".", "patch_embed3", "(", "x2_nocls", ")", "\n", "H3", ",", "W3", "=", "self", ".", "patch_embed3", ".", "grid_size", "\n", "x3", "=", "insert_cls", "(", "x3", ",", "self", ".", "cls_token3", ")", "\n", "for", "blk", "in", "self", ".", "serial_blocks3", ":", "\n", "            ", "x3", "=", "blk", "(", "x3", ",", "size", "=", "(", "H3", ",", "W3", ")", ")", "\n", "", "x3_nocls", "=", "remove_cls", "(", "x3", ")", ".", "reshape", "(", "B", ",", "H3", ",", "W3", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Serial blocks 4.", "\n", "x4", "=", "self", ".", "patch_embed4", "(", "x3_nocls", ")", "\n", "H4", ",", "W4", "=", "self", ".", "patch_embed4", ".", "grid_size", "\n", "x4", "=", "insert_cls", "(", "x4", ",", "self", ".", "cls_token4", ")", "\n", "for", "blk", "in", "self", ".", "serial_blocks4", ":", "\n", "            ", "x4", "=", "blk", "(", "x4", ",", "size", "=", "(", "H4", ",", "W4", ")", ")", "\n", "", "x4_nocls", "=", "remove_cls", "(", "x4", ")", ".", "reshape", "(", "B", ",", "H4", ",", "W4", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Only serial blocks: Early return.", "\n", "if", "self", ".", "parallel_blocks", "is", "None", ":", "\n", "            ", "if", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", "and", "self", ".", "return_interm_layers", ":", "\n", "# Return intermediate features for down-stream tasks (e.g. Deformable DETR and Detectron2).", "\n", "                ", "feat_out", "=", "{", "}", "\n", "if", "'x1_nocls'", "in", "self", ".", "out_features", ":", "\n", "                    ", "feat_out", "[", "'x1_nocls'", "]", "=", "x1_nocls", "\n", "", "if", "'x2_nocls'", "in", "self", ".", "out_features", ":", "\n", "                    ", "feat_out", "[", "'x2_nocls'", "]", "=", "x2_nocls", "\n", "", "if", "'x3_nocls'", "in", "self", ".", "out_features", ":", "\n", "                    ", "feat_out", "[", "'x3_nocls'", "]", "=", "x3_nocls", "\n", "", "if", "'x4_nocls'", "in", "self", ".", "out_features", ":", "\n", "                    ", "feat_out", "[", "'x4_nocls'", "]", "=", "x4_nocls", "\n", "", "return", "feat_out", "\n", "", "else", ":", "\n", "# Return features for classification.", "\n", "                ", "x4", "=", "self", ".", "norm4", "(", "x4", ")", "\n", "return", "x4", "\n", "\n", "# Parallel blocks.", "\n", "", "", "for", "blk", "in", "self", ".", "parallel_blocks", ":", "\n", "            ", "x2", ",", "x3", ",", "x4", "=", "self", ".", "cpe2", "(", "x2", ",", "(", "H2", ",", "W2", ")", ")", ",", "self", ".", "cpe3", "(", "x3", ",", "(", "H3", ",", "W3", ")", ")", ",", "self", ".", "cpe4", "(", "x4", ",", "(", "H4", ",", "W4", ")", ")", "\n", "x1", ",", "x2", ",", "x3", ",", "x4", "=", "blk", "(", "x1", ",", "x2", ",", "x3", ",", "x4", ",", "sizes", "=", "[", "(", "H1", ",", "W1", ")", ",", "(", "H2", ",", "W2", ")", ",", "(", "H3", ",", "W3", ")", ",", "(", "H4", ",", "W4", ")", "]", ")", "\n", "\n", "", "if", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", "and", "self", ".", "return_interm_layers", ":", "\n", "# Return intermediate features for down-stream tasks (e.g. Deformable DETR and Detectron2).", "\n", "            ", "feat_out", "=", "{", "}", "\n", "if", "'x1_nocls'", "in", "self", ".", "out_features", ":", "\n", "                ", "x1_nocls", "=", "remove_cls", "(", "x1", ")", ".", "reshape", "(", "B", ",", "H1", ",", "W1", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "feat_out", "[", "'x1_nocls'", "]", "=", "x1_nocls", "\n", "", "if", "'x2_nocls'", "in", "self", ".", "out_features", ":", "\n", "                ", "x2_nocls", "=", "remove_cls", "(", "x2", ")", ".", "reshape", "(", "B", ",", "H2", ",", "W2", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "feat_out", "[", "'x2_nocls'", "]", "=", "x2_nocls", "\n", "", "if", "'x3_nocls'", "in", "self", ".", "out_features", ":", "\n", "                ", "x3_nocls", "=", "remove_cls", "(", "x3", ")", ".", "reshape", "(", "B", ",", "H3", ",", "W3", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "feat_out", "[", "'x3_nocls'", "]", "=", "x3_nocls", "\n", "", "if", "'x4_nocls'", "in", "self", ".", "out_features", ":", "\n", "                ", "x4_nocls", "=", "remove_cls", "(", "x4", ")", ".", "reshape", "(", "B", ",", "H4", ",", "W4", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "feat_out", "[", "'x4_nocls'", "]", "=", "x4_nocls", "\n", "", "return", "feat_out", "\n", "", "else", ":", "\n", "            ", "x2", "=", "self", ".", "norm2", "(", "x2", ")", "\n", "x3", "=", "self", ".", "norm3", "(", "x3", ")", "\n", "x4", "=", "self", ".", "norm4", "(", "x4", ")", "\n", "return", "[", "x2", ",", "x3", ",", "x4", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head": [[589, 600], ["isinstance", "coat.CoaT.aggregate().squeeze", "coat.CoaT.head", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x_feat[].mean", "coat.CoaT.aggregate", "xl[].mean"], "methods", ["None"], ["", "", "def", "forward_head", "(", "self", ",", "x_feat", ":", "Union", "[", "torch", ".", "Tensor", ",", "List", "[", "torch", ".", "Tensor", "]", "]", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "x_feat", ",", "list", ")", ":", "\n", "            ", "assert", "self", ".", "aggregate", "is", "not", "None", "\n", "if", "self", ".", "global_pool", "==", "'avg'", ":", "\n", "                ", "x", "=", "torch", ".", "cat", "(", "[", "xl", "[", ":", ",", "1", ":", "]", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "for", "xl", "in", "x_feat", "]", ",", "dim", "=", "1", ")", "# [B, 3, C]", "\n", "", "else", ":", "\n", "                ", "x", "=", "torch", ".", "stack", "(", "[", "xl", "[", ":", ",", "0", "]", "for", "xl", "in", "x_feat", "]", ",", "dim", "=", "1", ")", "# [B, 3, C]", "\n", "", "x", "=", "self", ".", "aggregate", "(", "x", ")", ".", "squeeze", "(", "dim", "=", "1", ")", "# Shape: [B, C]", "\n", "", "else", ":", "\n", "            ", "x", "=", "x_feat", "[", ":", ",", "1", ":", "]", ".", "mean", "(", "dim", "=", "1", ")", "if", "self", ".", "global_pool", "==", "'avg'", "else", "x_feat", "[", ":", ",", "0", "]", "\n", "", "return", "x", "if", "pre_logits", "else", "self", ".", "head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward": [[601, 610], ["coat.CoaT.forward_features", "coat.CoaT.forward_features", "coat.CoaT.forward_head", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_head"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", "and", "self", ".", "return_interm_layers", ":", "\n", "# Return intermediate features (for down-stream tasks).", "\n", "            ", "return", "self", ".", "forward_features", "(", "x", ")", "\n", "", "else", ":", "\n", "# Return features for classification.", "\n", "            ", "x_feat", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_head", "(", "x_feat", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat._cfg_coat": [[34, 42], ["None"], "function", ["None"], ["def", "_cfg_coat", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", ".9", ",", "'interpolation'", ":", "'bicubic'", ",", "'fixed_input_size'", ":", "True", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'patch_embed1.proj'", ",", "'classifier'", ":", "'head'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.insert_cls": [[612, 617], ["cls_token.expand", "torch.cat", "torch.cat", "torch.cat"], "function", ["None"], ["", "", "", "def", "insert_cls", "(", "x", ",", "cls_token", ")", ":", "\n", "    ", "\"\"\" Insert CLS token. \"\"\"", "\n", "cls_tokens", "=", "cls_token", ".", "expand", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "-", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "cls_tokens", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.remove_cls": [[619, 622], ["None"], "function", ["None"], ["", "def", "remove_cls", "(", "x", ")", ":", "\n", "    ", "\"\"\" Remove CLS token. \"\"\"", "\n", "return", "x", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.checkpoint_filter_fn": [[624, 634], ["state_dict.items", "k.startswith", "k.startswith", "k.startswith"], "function", ["None"], ["", "def", "checkpoint_filter_fn", "(", "state_dict", ",", "model", ")", ":", "\n", "    ", "out_dict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "# original model had unused norm layers, removing them requires filtering pretrained checkpoints", "\n", "        ", "if", "k", ".", "startswith", "(", "'norm1'", ")", "or", "(", "model", ".", "norm2", "is", "None", "and", "k", ".", "startswith", "(", "'norm2'", ")", ")", "or", "(", "model", ".", "norm3", "is", "None", "and", "k", ".", "startswith", "(", "'norm3'", ")", ")", ":", "\n", "            ", "continue", "\n", "", "out_dict", "[", "k", "]", "=", "v", "\n", "", "return", "out_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat._create_coat": [[636, 645], ["kwargs.get", "helpers.build_model_with_cfg", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "def", "_create_coat", "(", "variant", ",", "pretrained", "=", "False", ",", "default_cfg", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", ".", "get", "(", "'features_only'", ",", "None", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'features_only not implemented for Vision Transformer models.'", ")", "\n", "\n", "", "model", "=", "build_model_with_cfg", "(", "\n", "CoaT", ",", "variant", ",", "pretrained", ",", "\n", "pretrained_filter_fn", "=", "checkpoint_filter_fn", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.coat_tiny": [[647, 654], ["dict", "coat._create_coat"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat._create_coat"], ["", "@", "register_model", "\n", "def", "coat_tiny", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_cfg", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "embed_dims", "=", "[", "152", ",", "152", ",", "152", ",", "152", "]", ",", "serial_depths", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "parallel_depth", "=", "6", ",", "\n", "num_heads", "=", "8", ",", "mlp_ratios", "=", "[", "4", ",", "4", ",", "4", ",", "4", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_coat", "(", "'coat_tiny'", ",", "pretrained", "=", "pretrained", ",", "**", "model_cfg", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.coat_mini": [[656, 663], ["dict", "coat._create_coat"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat._create_coat"], ["", "@", "register_model", "\n", "def", "coat_mini", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_cfg", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "embed_dims", "=", "[", "152", ",", "216", ",", "216", ",", "216", "]", ",", "serial_depths", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "parallel_depth", "=", "6", ",", "\n", "num_heads", "=", "8", ",", "mlp_ratios", "=", "[", "4", ",", "4", ",", "4", ",", "4", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_coat", "(", "'coat_mini'", ",", "pretrained", "=", "pretrained", ",", "**", "model_cfg", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.coat_lite_tiny": [[665, 672], ["dict", "coat._create_coat"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat._create_coat"], ["", "@", "register_model", "\n", "def", "coat_lite_tiny", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_cfg", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "embed_dims", "=", "[", "64", ",", "128", ",", "256", ",", "320", "]", ",", "serial_depths", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "parallel_depth", "=", "0", ",", "\n", "num_heads", "=", "8", ",", "mlp_ratios", "=", "[", "8", ",", "8", ",", "4", ",", "4", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_coat", "(", "'coat_lite_tiny'", ",", "pretrained", "=", "pretrained", ",", "**", "model_cfg", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.coat_lite_mini": [[674, 681], ["dict", "coat._create_coat"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat._create_coat"], ["", "@", "register_model", "\n", "def", "coat_lite_mini", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_cfg", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "embed_dims", "=", "[", "64", ",", "128", ",", "320", ",", "512", "]", ",", "serial_depths", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "parallel_depth", "=", "0", ",", "\n", "num_heads", "=", "8", ",", "mlp_ratios", "=", "[", "8", ",", "8", ",", "4", ",", "4", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_coat", "(", "'coat_lite_mini'", ",", "pretrained", "=", "pretrained", ",", "**", "model_cfg", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.coat_lite_small": [[683, 690], ["dict", "coat._create_coat"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat._create_coat"], ["", "@", "register_model", "\n", "def", "coat_lite_small", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_cfg", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "embed_dims", "=", "[", "64", ",", "128", ",", "320", ",", "512", "]", ",", "serial_depths", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "parallel_depth", "=", "0", ",", "\n", "num_heads", "=", "8", ",", "mlp_ratios", "=", "[", "8", ",", "8", ",", "4", ",", "4", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_coat", "(", "'coat_lite_small'", ",", "pretrained", "=", "pretrained", ",", "**", "model_cfg", ")", "\n", "return", "model", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet.SelectiveKernelBasic.__init__": [[49, 72], ["torch.nn.Module.__init__", "dict", "layers.SelectiveKernel", "layers.ConvNormAct", "layers.create_attn", "act_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.create_attn"], ["def", "__init__", "(", "\n", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "cardinality", "=", "1", ",", "base_width", "=", "64", ",", "\n", "sk_kwargs", "=", "None", ",", "reduce_first", "=", "1", ",", "dilation", "=", "1", ",", "first_dilation", "=", "None", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "\n", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "attn_layer", "=", "None", ",", "aa_layer", "=", "None", ",", "drop_block", "=", "None", ",", "drop_path", "=", "None", ")", ":", "\n", "        ", "super", "(", "SelectiveKernelBasic", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "sk_kwargs", "=", "sk_kwargs", "or", "{", "}", "\n", "conv_kwargs", "=", "dict", "(", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ")", "\n", "assert", "cardinality", "==", "1", ",", "'BasicBlock only supports cardinality of 1'", "\n", "assert", "base_width", "==", "64", ",", "'BasicBlock doest not support changing base width'", "\n", "first_planes", "=", "planes", "//", "reduce_first", "\n", "outplanes", "=", "planes", "*", "self", ".", "expansion", "\n", "first_dilation", "=", "first_dilation", "or", "dilation", "\n", "\n", "self", ".", "conv1", "=", "SelectiveKernel", "(", "\n", "inplanes", ",", "first_planes", ",", "stride", "=", "stride", ",", "dilation", "=", "first_dilation", ",", "\n", "aa_layer", "=", "aa_layer", ",", "drop_layer", "=", "drop_block", ",", "**", "conv_kwargs", ",", "**", "sk_kwargs", ")", "\n", "self", ".", "conv2", "=", "ConvNormAct", "(", "\n", "first_planes", ",", "outplanes", ",", "kernel_size", "=", "3", ",", "dilation", "=", "dilation", ",", "apply_act", "=", "False", ",", "**", "conv_kwargs", ")", "\n", "self", ".", "se", "=", "create_attn", "(", "attn_layer", ",", "outplanes", ")", "\n", "self", ".", "act", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "drop_path", "=", "drop_path", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet.SelectiveKernelBasic.zero_init_last": [[73, 75], ["torch.nn.init.zeros_"], "methods", ["None"], ["", "def", "zero_init_last", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "conv2", ".", "bn", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet.SelectiveKernelBasic.forward": [[76, 89], ["sknet.SelectiveKernelBasic.conv1", "sknet.SelectiveKernelBasic.conv2", "sknet.SelectiveKernelBasic.act", "sknet.SelectiveKernelBasic.se", "sknet.SelectiveKernelBasic.drop_path", "sknet.SelectiveKernelBasic.downsample"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "if", "self", ".", "se", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "se", "(", "x", ")", "\n", "", "if", "self", ".", "drop_path", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "drop_path", "(", "x", ")", "\n", "", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "downsample", "(", "shortcut", ")", "\n", "", "x", "+=", "shortcut", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet.SelectiveKernelBottleneck.__init__": [[94, 116], ["torch.nn.Module.__init__", "dict", "int", "layers.ConvNormAct", "layers.SelectiveKernel", "layers.ConvNormAct", "layers.create_attn", "act_layer", "math.floor"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.create_attn"], ["def", "__init__", "(", "\n", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "cardinality", "=", "1", ",", "base_width", "=", "64", ",", "sk_kwargs", "=", "None", ",", "\n", "reduce_first", "=", "1", ",", "dilation", "=", "1", ",", "first_dilation", "=", "None", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "\n", "attn_layer", "=", "None", ",", "aa_layer", "=", "None", ",", "drop_block", "=", "None", ",", "drop_path", "=", "None", ")", ":", "\n", "        ", "super", "(", "SelectiveKernelBottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "sk_kwargs", "=", "sk_kwargs", "or", "{", "}", "\n", "conv_kwargs", "=", "dict", "(", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ")", "\n", "width", "=", "int", "(", "math", ".", "floor", "(", "planes", "*", "(", "base_width", "/", "64", ")", ")", "*", "cardinality", ")", "\n", "first_planes", "=", "width", "//", "reduce_first", "\n", "outplanes", "=", "planes", "*", "self", ".", "expansion", "\n", "first_dilation", "=", "first_dilation", "or", "dilation", "\n", "\n", "self", ".", "conv1", "=", "ConvNormAct", "(", "inplanes", ",", "first_planes", ",", "kernel_size", "=", "1", ",", "**", "conv_kwargs", ")", "\n", "self", ".", "conv2", "=", "SelectiveKernel", "(", "\n", "first_planes", ",", "width", ",", "stride", "=", "stride", ",", "dilation", "=", "first_dilation", ",", "groups", "=", "cardinality", ",", "\n", "aa_layer", "=", "aa_layer", ",", "drop_layer", "=", "drop_block", ",", "**", "conv_kwargs", ",", "**", "sk_kwargs", ")", "\n", "self", ".", "conv3", "=", "ConvNormAct", "(", "width", ",", "outplanes", ",", "kernel_size", "=", "1", ",", "apply_act", "=", "False", ",", "**", "conv_kwargs", ")", "\n", "self", ".", "se", "=", "create_attn", "(", "attn_layer", ",", "outplanes", ")", "\n", "self", ".", "act", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "drop_path", "=", "drop_path", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet.SelectiveKernelBottleneck.zero_init_last": [[117, 119], ["torch.nn.init.zeros_"], "methods", ["None"], ["", "def", "zero_init_last", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "conv3", ".", "bn", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet.SelectiveKernelBottleneck.forward": [[120, 134], ["sknet.SelectiveKernelBottleneck.conv1", "sknet.SelectiveKernelBottleneck.conv2", "sknet.SelectiveKernelBottleneck.conv3", "sknet.SelectiveKernelBottleneck.act", "sknet.SelectiveKernelBottleneck.se", "sknet.SelectiveKernelBottleneck.drop_path", "sknet.SelectiveKernelBottleneck.downsample"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3", "(", "x", ")", "\n", "if", "self", ".", "se", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "se", "(", "x", ")", "\n", "", "if", "self", ".", "drop_path", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "drop_path", "(", "x", ")", "\n", "", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "shortcut", "=", "self", ".", "downsample", "(", "shortcut", ")", "\n", "", "x", "+=", "shortcut", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet._cfg": [[22, 30], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "1000", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "(", "7", ",", "7", ")", ",", "\n", "'crop_pct'", ":", "0.875", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "IMAGENET_DEFAULT_MEAN", ",", "'std'", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "'first_conv'", ":", "'conv1'", ",", "'classifier'", ":", "'fc'", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet._create_skresnet": [[136, 138], ["helpers.build_model_with_cfg"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.build_model_with_cfg"], ["", "", "def", "_create_skresnet", "(", "variant", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "build_model_with_cfg", "(", "ResNet", ",", "variant", ",", "pretrained", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet.skresnet18": [[140, 152], ["dict", "dict", "sknet._create_skresnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet._create_skresnet"], ["", "@", "register_model", "\n", "def", "skresnet18", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a Selective Kernel ResNet-18 model.\n\n    Different from configs in Select Kernel paper or \"Compounding the Performance Improvements...\" this\n    variation splits the input channels to the selective convolutions to keep param count down.\n    \"\"\"", "\n", "sk_kwargs", "=", "dict", "(", "rd_ratio", "=", "1", "/", "8", ",", "rd_divisor", "=", "16", ",", "split_input", "=", "True", ")", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "SelectiveKernelBasic", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "block_args", "=", "dict", "(", "sk_kwargs", "=", "sk_kwargs", ")", ",", "\n", "zero_init_last", "=", "False", ",", "**", "kwargs", ")", "\n", "return", "_create_skresnet", "(", "'skresnet18'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet.skresnet34": [[154, 166], ["dict", "dict", "sknet._create_skresnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet._create_skresnet"], ["", "@", "register_model", "\n", "def", "skresnet34", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a Selective Kernel ResNet-34 model.\n\n    Different from configs in Select Kernel paper or \"Compounding the Performance Improvements...\" this\n    variation splits the input channels to the selective convolutions to keep param count down.\n    \"\"\"", "\n", "sk_kwargs", "=", "dict", "(", "rd_ratio", "=", "1", "/", "8", ",", "rd_divisor", "=", "16", ",", "split_input", "=", "True", ")", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "SelectiveKernelBasic", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "block_args", "=", "dict", "(", "sk_kwargs", "=", "sk_kwargs", ")", ",", "\n", "zero_init_last", "=", "False", ",", "**", "kwargs", ")", "\n", "return", "_create_skresnet", "(", "'skresnet34'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet.skresnet50": [[168, 180], ["dict", "dict", "sknet._create_skresnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet._create_skresnet"], ["", "@", "register_model", "\n", "def", "skresnet50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a Select Kernel ResNet-50 model.\n\n    Different from configs in Select Kernel paper or \"Compounding the Performance Improvements...\" this\n    variation splits the input channels to the selective convolutions to keep param count down.\n    \"\"\"", "\n", "sk_kwargs", "=", "dict", "(", "split_input", "=", "True", ")", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "SelectiveKernelBottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "block_args", "=", "dict", "(", "sk_kwargs", "=", "sk_kwargs", ")", ",", "\n", "zero_init_last", "=", "False", ",", "**", "kwargs", ")", "\n", "return", "_create_skresnet", "(", "'skresnet50'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet.skresnet50d": [[182, 194], ["dict", "dict", "sknet._create_skresnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet._create_skresnet"], ["", "@", "register_model", "\n", "def", "skresnet50d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a Select Kernel ResNet-50-D model.\n\n    Different from configs in Select Kernel paper or \"Compounding the Performance Improvements...\" this\n    variation splits the input channels to the selective convolutions to keep param count down.\n    \"\"\"", "\n", "sk_kwargs", "=", "dict", "(", "split_input", "=", "True", ")", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "SelectiveKernelBottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "stem_width", "=", "32", ",", "stem_type", "=", "'deep'", ",", "avg_down", "=", "True", ",", "\n", "block_args", "=", "dict", "(", "sk_kwargs", "=", "sk_kwargs", ")", ",", "zero_init_last", "=", "False", ",", "**", "kwargs", ")", "\n", "return", "_create_skresnet", "(", "'skresnet50d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet.skresnext50_32x4d": [[196, 206], ["dict", "dict", "sknet._create_skresnet", "dict"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.sknet._create_skresnet"], ["", "@", "register_model", "\n", "def", "skresnext50_32x4d", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a Select Kernel ResNeXt50-32x4d model. This should be equivalent to\n    the SKNet-50 model in the Select Kernel Paper\n    \"\"\"", "\n", "sk_kwargs", "=", "dict", "(", "rd_ratio", "=", "1", "/", "16", ",", "rd_divisor", "=", "32", ",", "split_input", "=", "False", ")", "\n", "model_args", "=", "dict", "(", "\n", "block", "=", "SelectiveKernelBottleneck", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "cardinality", "=", "32", ",", "base_width", "=", "4", ",", "\n", "block_args", "=", "dict", "(", "sk_kwargs", "=", "sk_kwargs", ")", ",", "zero_init_last", "=", "False", ",", "**", "kwargs", ")", "\n", "return", "_create_skresnet", "(", "'skresnext50_32x4d'", ",", "pretrained", ",", "**", "model_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.trace_utils._float_to_int": [[8, 14], ["int"], "function", ["None"], ["", "", "def", "_float_to_int", "(", "x", ":", "float", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Symbolic tracing helper to substitute for inbuilt `int`.\n    Hint: Inbuilt `int` can't accept an argument of type `Proxy`\n    \"\"\"", "\n", "return", "int", "(", "x", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.SwishJit.__init__": [[33, 35], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "SwishJit", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.SwishJit.forward": [[36, 38], ["activations_jit.swish_jit"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.swish_jit"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "swish_jit", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.MishJit.__init__": [[41, 43], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "MishJit", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.MishJit.forward": [[44, 46], ["activations_jit.mish_jit"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.mish_jit"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "mish_jit", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.HardSigmoidJit.__init__": [[55, 57], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "HardSigmoidJit", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.HardSigmoidJit.forward": [[58, 60], ["activations_jit.hard_sigmoid_jit"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.hard_sigmoid_jit"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "hard_sigmoid_jit", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.HardSwishJit.__init__": [[69, 71], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "HardSwishJit", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.HardSwishJit.forward": [[72, 74], ["activations_jit.hard_swish_jit"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.hard_swish_jit"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "hard_swish_jit", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.HardMishJit.__init__": [[86, 88], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "HardMishJit", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.HardMishJit.forward": [[89, 91], ["activations_jit.hard_mish_jit"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.hard_mish_jit"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "hard_mish_jit", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.swish_jit": [[18, 23], ["x.mul", "x.sigmoid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid"], ["@", "torch", ".", "jit", ".", "script", "\n", "def", "swish_jit", "(", "x", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Swish - Described in: https://arxiv.org/abs/1710.05941\n    \"\"\"", "\n", "return", "x", ".", "mul", "(", "x", ".", "sigmoid", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.mish_jit": [[25, 30], ["x.mul", "torch.nn.functional.softplus().tanh", "torch.nn.functional.softplus"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.tanh"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "mish_jit", "(", "x", ",", "_inplace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Mish: A Self Regularized Non-Monotonic Neural Activation Function - https://arxiv.org/abs/1908.08681\n    \"\"\"", "\n", "return", "x", ".", "mul", "(", "F", ".", "softplus", "(", "x", ")", ".", "tanh", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.hard_sigmoid_jit": [[48, 52], ["None"], "function", ["None"], ["", "", "@", "torch", ".", "jit", ".", "script", "\n", "def", "hard_sigmoid_jit", "(", "x", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "# return F.relu6(x + 3.) / 6.", "\n", "    ", "return", "(", "x", "+", "3", ")", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "6", ")", ".", "div", "(", "6.", ")", "# clamp seems ever so slightly faster?", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.hard_swish_jit": [[62, 66], ["None"], "function", ["None"], ["", "", "@", "torch", ".", "jit", ".", "script", "\n", "def", "hard_swish_jit", "(", "x", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "# return x * (F.relu6(x + 3.) / 6)", "\n", "    ", "return", "x", "*", "(", "x", "+", "3", ")", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "6", ")", ".", "div", "(", "6.", ")", "# clamp seems ever so slightly faster?", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_jit.hard_mish_jit": [[76, 83], ["None"], "function", ["None"], ["", "", "@", "torch", ".", "jit", ".", "script", "\n", "def", "hard_mish_jit", "(", "x", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\" Hard Mish\n    Experimental, based on notes by Mish author Diganta Misra at\n      https://github.com/digantamisra98/H-Mish/blob/0da20d4bc58e696b6803f2523c58d3c8a82782d0/README.md\n    \"\"\"", "\n", "return", "0.5", "*", "x", "*", "(", "x", "+", "2", ")", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.test_time_pool.TestTimePoolHead.__init__": [[17, 30], ["torch.nn.Module.__init__", "test_time_pool.TestTimePoolHead.base.get_classifier", "isinstance", "test_time_pool.TestTimePoolHead.base.reset_classifier", "torch.nn.Conv2d", "test_time_pool.TestTimePoolHead.fc.weight.data.copy_", "test_time_pool.TestTimePoolHead.fc.bias.data.copy_", "test_time_pool.TestTimePoolHead.weight.data.view", "test_time_pool.TestTimePoolHead.bias.data.view", "test_time_pool.TestTimePoolHead.fc.weight.size", "test_time_pool.TestTimePoolHead.fc.bias.size"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.get_classifier", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.reset_classifier"], ["    ", "def", "__init__", "(", "self", ",", "base", ",", "original_pool", "=", "7", ")", ":", "\n", "        ", "super", "(", "TestTimePoolHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "base", "=", "base", "\n", "self", ".", "original_pool", "=", "original_pool", "\n", "base_fc", "=", "self", ".", "base", ".", "get_classifier", "(", ")", "\n", "if", "isinstance", "(", "base_fc", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "self", ".", "fc", "=", "base_fc", "\n", "", "else", ":", "\n", "            ", "self", ".", "fc", "=", "nn", ".", "Conv2d", "(", "\n", "self", ".", "base", ".", "num_features", ",", "self", ".", "base", ".", "num_classes", ",", "kernel_size", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "fc", ".", "weight", ".", "data", ".", "copy_", "(", "base_fc", ".", "weight", ".", "data", ".", "view", "(", "self", ".", "fc", ".", "weight", ".", "size", "(", ")", ")", ")", "\n", "self", ".", "fc", ".", "bias", ".", "data", ".", "copy_", "(", "base_fc", ".", "bias", ".", "data", ".", "view", "(", "self", ".", "fc", ".", "bias", ".", "size", "(", ")", ")", ")", "\n", "", "self", ".", "base", ".", "reset_classifier", "(", "0", ")", "# delete original fc layer", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.test_time_pool.TestTimePoolHead.forward": [[31, 37], ["test_time_pool.TestTimePoolHead.base.forward_features", "torch.avg_pool2d", "test_time_pool.TestTimePoolHead.fc", "adaptive_avgmax_pool.adaptive_avgmax_pool2d", "adaptive_avgmax_pool.adaptive_avgmax_pool2d.view", "adaptive_avgmax_pool.adaptive_avgmax_pool2d.size"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.CoaT.forward_features", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.adaptive_avgmax_pool2d"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "base", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", "=", "self", ".", "original_pool", ",", "stride", "=", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "x", "=", "adaptive_avgmax_pool2d", "(", "x", ",", "1", ")", "\n", "return", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.test_time_pool.apply_test_time_pool": [[39, 53], ["_logger.info", "test_time_pool.TestTimePoolHead", "hasattr", "str", "str"], "function", ["None"], ["", "", "def", "apply_test_time_pool", "(", "model", ",", "config", ",", "use_test_size", "=", "True", ")", ":", "\n", "    ", "test_time_pool", "=", "False", "\n", "if", "not", "hasattr", "(", "model", ",", "'default_cfg'", ")", "or", "not", "model", ".", "default_cfg", ":", "\n", "        ", "return", "model", ",", "False", "\n", "", "if", "use_test_size", "and", "'test_input_size'", "in", "model", ".", "default_cfg", ":", "\n", "        ", "df_input_size", "=", "model", ".", "default_cfg", "[", "'test_input_size'", "]", "\n", "", "else", ":", "\n", "        ", "df_input_size", "=", "model", ".", "default_cfg", "[", "'input_size'", "]", "\n", "", "if", "config", "[", "'input_size'", "]", "[", "-", "1", "]", ">", "df_input_size", "[", "-", "1", "]", "and", "config", "[", "'input_size'", "]", "[", "-", "2", "]", ">", "df_input_size", "[", "-", "2", "]", ":", "\n", "        ", "_logger", ".", "info", "(", "'Target input size %s > pretrained default %s, using test time pooling'", "%", "\n", "(", "str", "(", "config", "[", "'input_size'", "]", "[", "-", "2", ":", "]", ")", ",", "str", "(", "df_input_size", "[", "-", "2", ":", "]", ")", ")", ")", "\n", "model", "=", "TestTimePoolHead", "(", "model", ",", "original_pool", "=", "model", ".", "default_cfg", "[", "'pool_size'", "]", ")", "\n", "test_time_pool", "=", "True", "\n", "", "return", "model", ",", "test_time_pool", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.conv2d_same.Conv2dSame.__init__": [[24, 28], ["torch.Conv2d.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "Conv2dSame", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "0", ",", "dilation", ",", "groups", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.conv2d_same.Conv2dSame.forward": [[29, 31], ["conv2d_same.conv2d_same"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.conv2d_same.conv2d_same"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "conv2d_same", "(", "x", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.conv2d_same.conv2d_same": [[13, 18], ["padding.pad_same", "torch.conv2d"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.pad_same"], ["def", "conv2d_same", "(", "\n", "x", ",", "weight", ":", "torch", ".", "Tensor", ",", "bias", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "stride", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "1", ",", "1", ")", ",", "\n", "padding", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "0", ",", "0", ")", ",", "dilation", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "1", ",", "1", ")", ",", "groups", ":", "int", "=", "1", ")", ":", "\n", "    ", "x", "=", "pad_same", "(", "x", ",", "weight", ".", "shape", "[", "-", "2", ":", "]", ",", "stride", ",", "dilation", ")", "\n", "return", "F", ".", "conv2d", "(", "x", ",", "weight", ",", "bias", ",", "stride", ",", "(", "0", ",", "0", ")", ",", "dilation", ",", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.conv2d_same.create_conv2d_pad": [[33, 41], ["kwargs.pop", "kwargs.setdefault", "padding.get_padding_value", "conv2d_same.Conv2dSame", "torch.Conv2d"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_padding_value"], ["", "", "def", "create_conv2d_pad", "(", "in_chs", ",", "out_chs", ",", "kernel_size", ",", "**", "kwargs", ")", ":", "\n", "    ", "padding", "=", "kwargs", ".", "pop", "(", "'padding'", ",", "''", ")", "\n", "kwargs", ".", "setdefault", "(", "'bias'", ",", "False", ")", "\n", "padding", ",", "is_dynamic", "=", "get_padding_value", "(", "padding", ",", "kernel_size", ",", "**", "kwargs", ")", "\n", "if", "is_dynamic", ":", "\n", "        ", "return", "Conv2dSame", "(", "in_chs", ",", "out_chs", ",", "kernel_size", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "return", "nn", ".", "Conv2d", "(", "in_chs", ",", "out_chs", ",", "kernel_size", ",", "padding", "=", "padding", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.std_conv.StdConv2d.__init__": [[32, 41], ["torch.Conv2d.__init__", "padding.get_padding.get_padding"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_padding"], ["def", "__init__", "(", "\n", "self", ",", "in_channel", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "None", ",", "\n", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "False", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "if", "padding", "is", "None", ":", "\n", "            ", "padding", "=", "get_padding", "(", "kernel_size", ",", "stride", ",", "dilation", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "in_channel", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "groups", "=", "groups", ",", "bias", "=", "bias", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.std_conv.StdConv2d.forward": [[42, 48], ["torch.batch_norm().reshape_as", "torch.batch_norm().reshape_as", "torch.batch_norm().reshape_as", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm", "std_conv.StdConv2d.weight.reshape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "weight", "=", "F", ".", "batch_norm", "(", "\n", "self", ".", "weight", ".", "reshape", "(", "1", ",", "self", ".", "out_channels", ",", "-", "1", ")", ",", "None", ",", "None", ",", "\n", "training", "=", "True", ",", "momentum", "=", "0.", ",", "eps", "=", "self", ".", "eps", ")", ".", "reshape_as", "(", "self", ".", "weight", ")", "\n", "x", "=", "F", ".", "conv2d", "(", "x", ",", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.std_conv.StdConv2dSame.__init__": [[56, 65], ["padding.get_padding_value", "torch.Conv2d.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_padding_value", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "in_channel", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "'SAME'", ",", "\n", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "False", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "padding", ",", "is_dynamic", "=", "get_padding_value", "(", "padding", ",", "kernel_size", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ")", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "in_channel", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "\n", "groups", "=", "groups", ",", "bias", "=", "bias", ")", "\n", "self", ".", "same_pad", "=", "is_dynamic", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.std_conv.StdConv2dSame.forward": [[66, 74], ["torch.batch_norm().reshape_as", "torch.batch_norm().reshape_as", "torch.batch_norm().reshape_as", "torch.conv2d", "torch.conv2d", "torch.conv2d", "padding.pad_same", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm", "std_conv.StdConv2dSame.weight.reshape"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.pad_same"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "same_pad", ":", "\n", "            ", "x", "=", "pad_same", "(", "x", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", ",", "self", ".", "dilation", ")", "\n", "", "weight", "=", "F", ".", "batch_norm", "(", "\n", "self", ".", "weight", ".", "reshape", "(", "1", ",", "self", ".", "out_channels", ",", "-", "1", ")", ",", "None", ",", "None", ",", "\n", "training", "=", "True", ",", "momentum", "=", "0.", ",", "eps", "=", "self", ".", "eps", ")", ".", "reshape_as", "(", "self", ".", "weight", ")", "\n", "x", "=", "F", ".", "conv2d", "(", "x", ",", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.std_conv.ScaledStdConv2d.__init__": [[85, 96], ["torch.Conv2d.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "padding.get_padding.get_padding", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "std_conv.ScaledStdConv2d.weight[].numel"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_padding"], ["def", "__init__", "(", "\n", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "None", ",", "\n", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "True", ",", "gamma", "=", "1.0", ",", "eps", "=", "1e-6", ",", "gain_init", "=", "1.0", ")", ":", "\n", "        ", "if", "padding", "is", "None", ":", "\n", "            ", "padding", "=", "get_padding", "(", "kernel_size", ",", "stride", ",", "dilation", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "\n", "groups", "=", "groups", ",", "bias", "=", "bias", ")", "\n", "self", ".", "gain", "=", "nn", ".", "Parameter", "(", "torch", ".", "full", "(", "(", "self", ".", "out_channels", ",", "1", ",", "1", ",", "1", ")", ",", "gain_init", ")", ")", "\n", "self", ".", "scale", "=", "gamma", "*", "self", ".", "weight", "[", "0", "]", ".", "numel", "(", ")", "**", "-", "0.5", "# gamma * 1 / sqrt(fan-in)", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.std_conv.ScaledStdConv2d.forward": [[97, 103], ["torch.batch_norm().reshape_as", "torch.batch_norm().reshape_as", "torch.batch_norm().reshape_as", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm", "std_conv.ScaledStdConv2d.weight.reshape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "weight", "=", "F", ".", "batch_norm", "(", "\n", "self", ".", "weight", ".", "reshape", "(", "1", ",", "self", ".", "out_channels", ",", "-", "1", ")", ",", "None", ",", "None", ",", "\n", "weight", "=", "(", "self", ".", "gain", "*", "self", ".", "scale", ")", ".", "view", "(", "-", "1", ")", ",", "\n", "training", "=", "True", ",", "momentum", "=", "0.", ",", "eps", "=", "self", ".", "eps", ")", ".", "reshape_as", "(", "self", ".", "weight", ")", "\n", "return", "F", ".", "conv2d", "(", "x", ",", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.std_conv.ScaledStdConv2dSame.__init__": [[114, 125], ["padding.get_padding_value", "torch.Conv2d.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "std_conv.ScaledStdConv2dSame.weight[].numel"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_padding_value", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "'SAME'", ",", "\n", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "True", ",", "gamma", "=", "1.0", ",", "eps", "=", "1e-6", ",", "gain_init", "=", "1.0", ")", ":", "\n", "        ", "padding", ",", "is_dynamic", "=", "get_padding_value", "(", "padding", ",", "kernel_size", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ")", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "\n", "groups", "=", "groups", ",", "bias", "=", "bias", ")", "\n", "self", ".", "gain", "=", "nn", ".", "Parameter", "(", "torch", ".", "full", "(", "(", "self", ".", "out_channels", ",", "1", ",", "1", ",", "1", ")", ",", "gain_init", ")", ")", "\n", "self", ".", "scale", "=", "gamma", "*", "self", ".", "weight", "[", "0", "]", ".", "numel", "(", ")", "**", "-", "0.5", "\n", "self", ".", "same_pad", "=", "is_dynamic", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.std_conv.ScaledStdConv2dSame.forward": [[126, 134], ["torch.batch_norm().reshape_as", "torch.batch_norm().reshape_as", "torch.batch_norm().reshape_as", "torch.conv2d", "torch.conv2d", "torch.conv2d", "padding.pad_same", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm", "std_conv.ScaledStdConv2dSame.weight.reshape"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.pad_same"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "same_pad", ":", "\n", "            ", "x", "=", "pad_same", "(", "x", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", ",", "self", ".", "dilation", ")", "\n", "", "weight", "=", "F", ".", "batch_norm", "(", "\n", "self", ".", "weight", ".", "reshape", "(", "1", ",", "self", ".", "out_channels", ",", "-", "1", ")", ",", "None", ",", "None", ",", "\n", "weight", "=", "(", "self", ".", "gain", "*", "self", ".", "scale", ")", ".", "view", "(", "-", "1", ")", ",", "\n", "training", "=", "True", ",", "momentum", "=", "0.", ",", "eps", "=", "self", ".", "eps", ")", ".", "reshape_as", "(", "self", ".", "weight", ")", "\n", "return", "F", ".", "conv2d", "(", "x", ",", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d": [[11, 37], ["isinstance", "mixed_conv2d.MixedConv2d", "kwargs.pop", "kwargs.pop", "kwargs.pop", "cond_conv2d.CondConv2d", "conv2d_same.create_conv2d_pad"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.conv2d_same.create_conv2d_pad"], ["def", "create_conv2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Select a 2d convolution implementation based on arguments\n    Creates and returns one of torch.nn.Conv2d, Conv2dSame, MixedConv2d, or CondConv2d.\n\n    Used extensively by EfficientNet, MobileNetv3 and related networks.\n    \"\"\"", "\n", "if", "isinstance", "(", "kernel_size", ",", "list", ")", ":", "\n", "        ", "assert", "'num_experts'", "not", "in", "kwargs", "# MixNet + CondConv combo not supported currently", "\n", "if", "'groups'", "in", "kwargs", ":", "\n", "            ", "groups", "=", "kwargs", ".", "pop", "(", "'groups'", ")", "\n", "if", "groups", "==", "in_channels", ":", "\n", "                ", "kwargs", "[", "'depthwise'", "]", "=", "True", "\n", "", "else", ":", "\n", "                ", "assert", "groups", "==", "1", "\n", "# We're going to use only lists for defining the MixedConv2d kernel groups,", "\n", "# ints, tuples, other iterables will continue to pass to normal conv and specify h, w.", "\n", "", "", "m", "=", "MixedConv2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "depthwise", "=", "kwargs", ".", "pop", "(", "'depthwise'", ",", "False", ")", "\n", "# for DW out_channels must be multiple of in_channels as must have out_channels % groups == 0", "\n", "groups", "=", "in_channels", "if", "depthwise", "else", "kwargs", ".", "pop", "(", "'groups'", ",", "1", ")", "\n", "if", "'num_experts'", "in", "kwargs", "and", "kwargs", "[", "'num_experts'", "]", ">", "0", ":", "\n", "            ", "m", "=", "CondConv2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "groups", "=", "groups", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "m", "=", "create_conv2d_pad", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "groups", "=", "groups", ",", "**", "kwargs", ")", "\n", "", "", "return", "m", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.FourierEmbed.__init__": [[114, 121], ["torch.nn.Module.__init__", "pos_embed.FourierEmbed.register_buffer", "pos_embed.pixel_freq_bands"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.pixel_freq_bands"], ["    ", "def", "__init__", "(", "self", ",", "max_res", ":", "int", "=", "224", ",", "num_bands", ":", "int", "=", "64", ",", "concat_grid", "=", "True", ",", "keep_spatial", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "max_res", "=", "max_res", "\n", "self", ".", "num_bands", "=", "num_bands", "\n", "self", ".", "concat_grid", "=", "concat_grid", "\n", "self", ".", "keep_spatial", "=", "keep_spatial", "\n", "self", ".", "register_buffer", "(", "'bands'", ",", "pixel_freq_bands", "(", "max_res", ",", "num_bands", ")", ",", "persistent", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.FourierEmbed.forward": [[122, 142], ["pos_embed.build_fourier_pos_embed", "emb.transpose().flatten.transpose().flatten.transpose().flatten", "len", "torch.cat", "torch.cat", "x.reshape.reshape.reshape", "emb.transpose().flatten.transpose().flatten.transpose", "feat_shape.numel", "emb.transpose().flatten.transpose().flatten.unsqueeze().expand().permute", "x.reshape.reshape.permute", "emb.transpose().flatten.transpose().flatten.unsqueeze().expand", "emb.transpose().flatten.transpose().flatten.unsqueeze().expand", "emb.transpose().flatten.transpose().flatten.unsqueeze", "emb.transpose().flatten.transpose().flatten.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.build_fourier_pos_embed"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "C", "=", "x", ".", "shape", "[", ":", "2", "]", "\n", "feat_shape", "=", "x", ".", "shape", "[", "2", ":", "]", "\n", "emb", "=", "build_fourier_pos_embed", "(", "\n", "feat_shape", ",", "\n", "self", ".", "bands", ",", "\n", "include_grid", "=", "self", ".", "concat_grid", ",", "\n", "dtype", "=", "x", ".", "dtype", ",", "\n", "device", "=", "x", ".", "device", ")", "\n", "emb", "=", "emb", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ".", "flatten", "(", "len", "(", "feat_shape", ")", ")", "\n", "batch_expand", "=", "(", "B", ",", ")", "+", "(", "-", "1", ",", ")", "*", "(", "x", ".", "ndim", "-", "1", ")", "\n", "\n", "# FIXME support nD", "\n", "if", "self", ".", "keep_spatial", ":", "\n", "            ", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "emb", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_expand", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "torch", ".", "cat", "(", "[", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ",", "emb", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_expand", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "feat_shape", ".", "numel", "(", ")", ",", "-", "1", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.RotaryEmbedding.__init__": [[196, 200], ["torch.nn.Module.__init__", "pos_embed.RotaryEmbedding.register_buffer", "pos_embed.pixel_freq_bands"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.pixel_freq_bands"], ["def", "__init__", "(", "self", ",", "dim", ",", "max_res", "=", "224", ",", "linear_bands", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "register_buffer", "(", "'bands'", ",", "pixel_freq_bands", "(", "dim", "//", "4", ",", "max_res", ",", "linear_bands", "=", "linear_bands", ")", ",", "persistent", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.RotaryEmbedding.get_embed": [[201, 203], ["pos_embed.build_rotary_pos_embed"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.build_rotary_pos_embed"], ["", "def", "get_embed", "(", "self", ",", "shape", ":", "List", "[", "int", "]", ")", ":", "\n", "        ", "return", "build_rotary_pos_embed", "(", "shape", ",", "self", ".", "bands", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.RotaryEmbedding.forward": [[204, 208], ["pos_embed.RotaryEmbedding.get_embed", "pos_embed.apply_rot_embed"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.RotaryEmbedding.get_embed", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.apply_rot_embed"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# assuming channel-first tensor where spatial dim are >= 2", "\n", "        ", "sin_emb", ",", "cos_emb", "=", "self", ".", "get_embed", "(", "x", ".", "shape", "[", "2", ":", "]", ")", "\n", "return", "apply_rot_embed", "(", "x", ",", "sin_emb", ",", "cos_emb", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.pixel_freq_bands": [[8, 20], ["torch.linspace", "torch.linspace", "math.log"], "function", ["None"], ["def", "pixel_freq_bands", "(", "\n", "num_bands", ":", "int", ",", "\n", "max_freq", ":", "float", "=", "224.", ",", "\n", "linear_bands", ":", "bool", "=", "True", ",", "\n", "dtype", ":", "torch", ".", "dtype", "=", "torch", ".", "float32", ",", "\n", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "if", "linear_bands", ":", "\n", "        ", "bands", "=", "torch", ".", "linspace", "(", "1.0", ",", "max_freq", "/", "2", ",", "num_bands", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "        ", "bands", "=", "2", "**", "torch", ".", "linspace", "(", "0", ",", "math", ".", "log", "(", "max_freq", ",", "2", ")", "-", "1", ",", "num_bands", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "", "return", "bands", "*", "torch", ".", "pi", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.inv_freq_bands": [[22, 31], ["torch.arange"], "function", ["None"], ["", "def", "inv_freq_bands", "(", "\n", "num_bands", ":", "int", ",", "\n", "temperature", ":", "float", "=", "100000.", ",", "\n", "step", ":", "int", "=", "2", ",", "\n", "dtype", ":", "torch", ".", "dtype", "=", "torch", ".", "float32", ",", "\n", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "inv_freq", "=", "1.", "/", "(", "temperature", "**", "(", "torch", ".", "arange", "(", "0", ",", "num_bands", ",", "step", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "/", "num_bands", ")", ")", "\n", "return", "inv_freq", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.build_sincos2d_pos_embed": [[33, 70], ["pos_embed.inv_freq_bands", "torch.stack().flatten().transpose", "torch.stack().flatten", "torch.stack().flatten().transpose.unsqueeze", "inv_freq_bands.unsqueeze", "torch.stack().flatten", "torch.stack", "torch.stack", "torch.sin", "torch.cos", "torch.meshgrid", "torch.arange"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.inv_freq_bands"], ["", "def", "build_sincos2d_pos_embed", "(", "\n", "feat_shape", ":", "List", "[", "int", "]", ",", "\n", "dim", ":", "int", "=", "64", ",", "\n", "temperature", ":", "float", "=", "10000.", ",", "\n", "reverse_coord", ":", "bool", "=", "False", ",", "\n", "interleave_sin_cos", ":", "bool", "=", "False", ",", "\n", "dtype", ":", "torch", ".", "dtype", "=", "torch", ".", "float32", ",", "\n", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n\n    Args:\n        feat_shape:\n        dim:\n        temperature:\n        reverse_coord: stack grid order W, H instead of H, W\n        interleave_sin_cos: sin, cos, sin, cos stack instead of sin, sin, cos, cos\n        dtype:\n        device:\n\n    Returns:\n\n    \"\"\"", "\n", "assert", "dim", "%", "4", "==", "0", ",", "'Embed dimension must be divisible by 4 for sin-cos 2D position embedding'", "\n", "pos_dim", "=", "dim", "//", "4", "\n", "bands", "=", "inv_freq_bands", "(", "pos_dim", ",", "temperature", "=", "temperature", ",", "step", "=", "1", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "\n", "if", "reverse_coord", ":", "\n", "        ", "feat_shape", "=", "feat_shape", "[", ":", ":", "-", "1", "]", "# stack W, H instead of H, W", "\n", "", "grid", "=", "torch", ".", "stack", "(", "\n", "torch", ".", "meshgrid", "(", "[", "torch", ".", "arange", "(", "s", ",", "device", "=", "device", ",", "dtype", "=", "dtype", ")", "for", "s", "in", "feat_shape", "]", ")", ")", ".", "flatten", "(", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "pos2", "=", "grid", ".", "unsqueeze", "(", "-", "1", ")", "*", "bands", ".", "unsqueeze", "(", "0", ")", "\n", "# FIXME add support for unflattened spatial dim?", "\n", "\n", "stack_dim", "=", "2", "if", "interleave_sin_cos", "else", "1", "# stack sin, cos, sin, cos  instead of sin sin cos cos", "\n", "pos_emb", "=", "torch", ".", "stack", "(", "[", "torch", ".", "sin", "(", "pos2", ")", ",", "torch", ".", "cos", "(", "pos2", ")", "]", ",", "dim", "=", "stack_dim", ")", ".", "flatten", "(", "1", ")", "\n", "return", "pos_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.build_fourier_pos_embed": [[72, 110], ["torch.stack.unsqueeze", "torch.stack", "torch.stack", "pos.sin", "pos.cos", "torch.cat", "pos_embed.pixel_freq_bands", "pos_embed.inv_freq_bands", "torch.meshgrid", "torch.meshgrid", "float", "torch.linspace", "torch.arange"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.pixel_freq_bands", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.inv_freq_bands"], ["", "def", "build_fourier_pos_embed", "(", "\n", "feat_shape", ":", "List", "[", "int", "]", ",", "\n", "bands", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "num_bands", ":", "int", "=", "64", ",", "\n", "max_res", ":", "int", "=", "224", ",", "\n", "linear_bands", ":", "bool", "=", "False", ",", "\n", "include_grid", ":", "bool", "=", "False", ",", "\n", "concat_out", ":", "bool", "=", "True", ",", "\n", "in_pixels", ":", "bool", "=", "True", ",", "\n", "dtype", ":", "torch", ".", "dtype", "=", "torch", ".", "float32", ",", "\n", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "    ", "if", "bands", "is", "None", ":", "\n", "        ", "if", "in_pixels", ":", "\n", "            ", "bands", "=", "pixel_freq_bands", "(", "num_bands", ",", "float", "(", "max_res", ")", ",", "linear_bands", "=", "linear_bands", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "            ", "bands", "=", "inv_freq_bands", "(", "num_bands", ",", "step", "=", "1", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "device", "is", "None", ":", "\n", "            ", "device", "=", "bands", ".", "device", "\n", "", "if", "dtype", "is", "None", ":", "\n", "            ", "dtype", "=", "bands", ".", "dtype", "\n", "\n", "", "", "if", "in_pixels", ":", "\n", "        ", "grid", "=", "torch", ".", "stack", "(", "torch", ".", "meshgrid", "(", "\n", "[", "torch", ".", "linspace", "(", "-", "1.", ",", "1.", ",", "steps", "=", "s", ",", "device", "=", "device", ",", "dtype", "=", "dtype", ")", "for", "s", "in", "feat_shape", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "grid", "=", "torch", ".", "stack", "(", "torch", ".", "meshgrid", "(", "\n", "[", "torch", ".", "arange", "(", "s", ",", "device", "=", "device", ",", "dtype", "=", "dtype", ")", "for", "s", "in", "feat_shape", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "grid", "=", "grid", ".", "unsqueeze", "(", "-", "1", ")", "\n", "pos", "=", "grid", "*", "bands", "\n", "\n", "pos_sin", ",", "pos_cos", "=", "pos", ".", "sin", "(", ")", ",", "pos", ".", "cos", "(", ")", "\n", "out", "=", "(", "grid", ",", "pos_sin", ",", "pos_cos", ")", "if", "include_grid", "else", "(", "pos_sin", ",", "pos_cos", ")", "\n", "# FIXME torchscript doesn't like multiple return types, probably need to always cat?", "\n", "if", "concat_out", ":", "\n", "        ", "out", "=", "torch", ".", "cat", "(", "out", ",", "dim", "=", "-", "1", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.rot": [[144, 146], ["torch.stack().reshape", "torch.stack"], "function", ["None"], ["", "", "def", "rot", "(", "x", ")", ":", "\n", "    ", "return", "torch", ".", "stack", "(", "[", "-", "x", "[", "...", ",", "1", ":", ":", "2", "]", ",", "x", "[", "...", ",", ":", ":", "2", "]", "]", ",", "-", "1", ")", ".", "reshape", "(", "x", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.apply_rot_embed": [[148, 150], ["pos_embed.rot"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.rot"], ["", "def", "apply_rot_embed", "(", "x", ":", "torch", ".", "Tensor", ",", "sin_emb", ",", "cos_emb", ")", ":", "\n", "    ", "return", "x", "*", "cos_emb", "+", "rot", "(", "x", ")", "*", "sin_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.apply_rot_embed_list": [[152, 156], ["isinstance", "pos_embed.rot"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.rot"], ["", "def", "apply_rot_embed_list", "(", "x", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "sin_emb", ",", "cos_emb", ")", ":", "\n", "    ", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "x", "=", "[", "x", "]", "\n", "", "return", "[", "t", "*", "cos_emb", "+", "rot", "(", "t", ")", "*", "sin_emb", "for", "t", "in", "x", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.apply_rot_embed_split": [[158, 161], ["pos_embed.rot"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.rot"], ["", "def", "apply_rot_embed_split", "(", "x", ":", "torch", ".", "Tensor", ",", "emb", ")", ":", "\n", "    ", "split", "=", "emb", ".", "shape", "[", "-", "1", "]", "//", "2", "\n", "return", "x", "*", "emb", "[", ":", ",", ":", "split", "]", "+", "rot", "(", "x", ")", "*", "emb", "[", ":", ",", "split", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.build_rotary_pos_embed": [[163, 184], ["torch.Size", "pos_embed.build_fourier_pos_embed", "torch.Size.numel", "sin_emb.reshape().repeat_interleave.reshape().repeat_interleave", "cos_emb.reshape().repeat_interleave.reshape().repeat_interleave", "sin_emb.reshape().repeat_interleave.reshape", "cos_emb.reshape().repeat_interleave.reshape"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.build_fourier_pos_embed"], ["", "def", "build_rotary_pos_embed", "(", "\n", "feat_shape", ":", "List", "[", "int", "]", ",", "\n", "bands", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "dim", ":", "int", "=", "64", ",", "\n", "max_freq", ":", "float", "=", "224", ",", "\n", "linear_bands", ":", "bool", "=", "False", ",", "\n", "dtype", ":", "torch", ".", "dtype", "=", "torch", ".", "float32", ",", "\n", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    NOTE: shape arg should include spatial dim only\n    \"\"\"", "\n", "feat_shape", "=", "torch", ".", "Size", "(", "feat_shape", ")", "\n", "\n", "sin_emb", ",", "cos_emb", "=", "build_fourier_pos_embed", "(", "\n", "feat_shape", ",", "bands", "=", "bands", ",", "num_bands", "=", "dim", "//", "4", ",", "max_res", "=", "max_freq", ",", "linear_bands", "=", "linear_bands", ",", "\n", "concat_out", "=", "False", ",", "device", "=", "device", ",", "dtype", "=", "dtype", ")", "\n", "N", "=", "feat_shape", ".", "numel", "(", ")", "\n", "sin_emb", "=", "sin_emb", ".", "reshape", "(", "N", ",", "-", "1", ")", ".", "repeat_interleave", "(", "2", ",", "-", "1", ")", "\n", "cos_emb", "=", "cos_emb", ".", "reshape", "(", "N", ",", "-", "1", ")", ".", "repeat_interleave", "(", "2", ",", "-", "1", ")", "\n", "return", "sin_emb", ",", "cos_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.bottleneck_attn.PosEmbedRel.__init__": [[61, 67], ["torch.Module.__init__", "helpers.to_2tuple", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "feat_size", ",", "dim_head", ",", "scale", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "height", ",", "self", ".", "width", "=", "to_2tuple", "(", "feat_size", ")", "\n", "self", ".", "dim_head", "=", "dim_head", "\n", "self", ".", "height_rel", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "self", ".", "height", "*", "2", "-", "1", ",", "dim_head", ")", "*", "scale", ")", "\n", "self", ".", "width_rel", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "self", ".", "width", "*", "2", "-", "1", ",", "dim_head", ")", "*", "scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.bottleneck_attn.PosEmbedRel.forward": [[68, 82], ["q.transpose.transpose.reshape", "bottleneck_attn.rel_logits_1d", "q.transpose.transpose.transpose", "bottleneck_attn.rel_logits_1d", "rel_logits.reshape.reshape.reshape"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.halo_attn.rel_logits_1d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.halo_attn.rel_logits_1d"], ["", "def", "forward", "(", "self", ",", "q", ")", ":", "\n", "        ", "B", ",", "HW", ",", "_", "=", "q", ".", "shape", "\n", "\n", "# relative logits in width dimension.", "\n", "q", "=", "q", ".", "reshape", "(", "B", ",", "self", ".", "height", ",", "self", ".", "width", ",", "-", "1", ")", "\n", "rel_logits_w", "=", "rel_logits_1d", "(", "q", ",", "self", ".", "width_rel", ",", "permute_mask", "=", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ")", ")", "\n", "\n", "# relative logits in height dimension.", "\n", "q", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", "\n", "rel_logits_h", "=", "rel_logits_1d", "(", "q", ",", "self", ".", "height_rel", ",", "permute_mask", "=", "(", "0", ",", "3", ",", "1", ",", "4", ",", "2", ")", ")", "\n", "\n", "rel_logits", "=", "rel_logits_h", "+", "rel_logits_w", "\n", "rel_logits", "=", "rel_logits", ".", "reshape", "(", "B", ",", "HW", ",", "HW", ")", "\n", "return", "rel_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.bottleneck_attn.BottleneckAttn.__init__": [[106, 129], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "bottleneck_attn.PosEmbedRel", "bottleneck_attn.BottleneckAttn.reset_parameters", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Identity", "torch.Identity", "torch.Identity", "helpers.make_divisible"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["def", "__init__", "(", "\n", "self", ",", "dim", ",", "dim_out", "=", "None", ",", "feat_size", "=", "None", ",", "stride", "=", "1", ",", "num_heads", "=", "4", ",", "dim_head", "=", "None", ",", "\n", "qk_ratio", "=", "1.0", ",", "qkv_bias", "=", "False", ",", "scale_pos_embed", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "feat_size", "is", "not", "None", ",", "'A concrete feature size matching expected input (H, W) is required'", "\n", "dim_out", "=", "dim_out", "or", "dim", "\n", "assert", "dim_out", "%", "num_heads", "==", "0", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dim_head_qk", "=", "dim_head", "or", "make_divisible", "(", "dim_out", "*", "qk_ratio", ",", "divisor", "=", "8", ")", "//", "num_heads", "\n", "self", ".", "dim_head_v", "=", "dim_out", "//", "self", ".", "num_heads", "\n", "self", ".", "dim_out_qk", "=", "num_heads", "*", "self", ".", "dim_head_qk", "\n", "self", ".", "dim_out_v", "=", "num_heads", "*", "self", ".", "dim_head_v", "\n", "self", ".", "scale", "=", "self", ".", "dim_head_qk", "**", "-", "0.5", "\n", "self", ".", "scale_pos_embed", "=", "scale_pos_embed", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Conv2d", "(", "dim", ",", "self", ".", "dim_out_qk", "*", "2", "+", "self", ".", "dim_out_v", ",", "1", ",", "bias", "=", "qkv_bias", ")", "\n", "\n", "# NOTE I'm only supporting relative pos embedding for now", "\n", "self", ".", "pos_embed", "=", "PosEmbedRel", "(", "feat_size", ",", "dim_head", "=", "self", ".", "dim_head_qk", ",", "scale", "=", "self", ".", "scale", ")", "\n", "\n", "self", ".", "pool", "=", "nn", ".", "AvgPool2d", "(", "2", ",", "2", ")", "if", "stride", "==", "2", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.bottleneck_attn.BottleneckAttn.reset_parameters": [[130, 134], ["weight_init.trunc_normal_", "weight_init.trunc_normal_", "weight_init.trunc_normal_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "trunc_normal_", "(", "self", ".", "qkv", ".", "weight", ",", "std", "=", "self", ".", "qkv", ".", "weight", ".", "shape", "[", "1", "]", "**", "-", "0.5", ")", "# fan-in", "\n", "trunc_normal_", "(", "self", ".", "pos_embed", ".", "height_rel", ",", "std", "=", "self", ".", "scale", ")", "\n", "trunc_normal_", "(", "self", ".", "pos_embed", ".", "width_rel", ",", "std", "=", "self", ".", "scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.bottleneck_attn.BottleneckAttn.forward": [[135, 158], ["trace_utils._assert", "trace_utils._assert", "bottleneck_attn.BottleneckAttn.qkv", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "q.reshape().transpose.reshape().transpose.reshape().transpose", "k.reshape.reshape.reshape", "v.reshape().transpose.reshape().transpose.reshape().transpose", "attn.softmax.softmax.softmax", "bottleneck_attn.BottleneckAttn.pool", "q.reshape().transpose.reshape().transpose.reshape", "v.reshape().transpose.reshape().transpose.reshape", "bottleneck_attn.BottleneckAttn.pos_embed", "bottleneck_attn.BottleneckAttn.pos_embed"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "_assert", "(", "H", "==", "self", ".", "pos_embed", ".", "height", ",", "''", ")", "\n", "_assert", "(", "W", "==", "self", ".", "pos_embed", ".", "width", ",", "''", ")", "\n", "\n", "x", "=", "self", ".", "qkv", "(", "x", ")", "# B, (2 * dim_head_qk + dim_head_v) * num_heads, H, W", "\n", "\n", "# NOTE head vs channel split ordering in qkv projection was decided before I allowed qk to differ from v", "\n", "# So, this is more verbose than if heads were before qkv splits, but throughput is not impacted.", "\n", "q", ",", "k", ",", "v", "=", "torch", ".", "split", "(", "x", ",", "[", "self", ".", "dim_out_qk", ",", "self", ".", "dim_out_qk", ",", "self", ".", "dim_out_v", "]", ",", "dim", "=", "1", ")", "\n", "q", "=", "q", ".", "reshape", "(", "B", "*", "self", ".", "num_heads", ",", "self", ".", "dim_head_qk", ",", "-", "1", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "k", "=", "k", ".", "reshape", "(", "B", "*", "self", ".", "num_heads", ",", "self", ".", "dim_head_qk", ",", "-", "1", ")", "# no transpose, for q @ k", "\n", "v", "=", "v", ".", "reshape", "(", "B", "*", "self", ".", "num_heads", ",", "self", ".", "dim_head_v", ",", "-", "1", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "\n", "if", "self", ".", "scale_pos_embed", ":", "\n", "            ", "attn", "=", "(", "q", "@", "k", "+", "self", ".", "pos_embed", "(", "q", ")", ")", "*", "self", ".", "scale", "# B * num_heads, H * W, H * W", "\n", "", "else", ":", "\n", "            ", "attn", "=", "(", "q", "@", "k", ")", "*", "self", ".", "scale", "+", "self", ".", "pos_embed", "(", "q", ")", "\n", "", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "out", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ".", "reshape", "(", "B", ",", "self", ".", "dim_out_v", ",", "H", ",", "W", ")", "# B, dim_out, H, W", "\n", "out", "=", "self", ".", "pool", "(", "out", ")", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.bottleneck_attn.rel_logits_1d": [[28, 54], ["x.reshape().expand.reshape", "torch.pad().flatten", "torch.pad", "x_pad.reshape.reshape", "x.reshape().expand.reshape().expand", "x.reshape().expand.permute", "rel_k.transpose", "torch.pad", "x.reshape().expand.reshape"], "function", ["None"], ["def", "rel_logits_1d", "(", "q", ",", "rel_k", ",", "permute_mask", ":", "List", "[", "int", "]", ")", ":", "\n", "    ", "\"\"\" Compute relative logits along one dimension\n\n    As per: https://gist.github.com/aravindsrinivas/56359b79f0ce4449bcb04ab4b56a57a2\n    Originally from: `Attention Augmented Convolutional Networks` - https://arxiv.org/abs/1904.09925\n\n    Args:\n        q: (batch, heads, height, width, dim)\n        rel_k: (2 * width - 1, dim)\n        permute_mask: permute output dim according to this\n    \"\"\"", "\n", "B", ",", "H", ",", "W", ",", "dim", "=", "q", ".", "shape", "\n", "x", "=", "(", "q", "@", "rel_k", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "x", "=", "x", ".", "reshape", "(", "-", "1", ",", "W", ",", "2", "*", "W", "-", "1", ")", "\n", "\n", "# pad to shift from relative to absolute indexing", "\n", "x_pad", "=", "F", ".", "pad", "(", "x", ",", "[", "0", ",", "1", "]", ")", ".", "flatten", "(", "1", ")", "\n", "x_pad", "=", "F", ".", "pad", "(", "x_pad", ",", "[", "0", ",", "W", "-", "1", "]", ")", "\n", "\n", "# reshape and slice out the padded elements", "\n", "x_pad", "=", "x_pad", ".", "reshape", "(", "-", "1", ",", "W", "+", "1", ",", "2", "*", "W", "-", "1", ")", "\n", "x", "=", "x_pad", "[", ":", ",", ":", "W", ",", "W", "-", "1", ":", "]", "\n", "\n", "# reshape and tile", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "H", ",", "1", ",", "W", ",", "W", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "H", ",", "-", "1", ",", "-", "1", ")", "\n", "return", "x", ".", "permute", "(", "permute_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.blur_pool.BlurPool2d.__init__": [[29, 39], ["torch.Module.__init__", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "[].repeat", "blur_pool.BlurPool2d.register_buffer", "padding.get_padding", "numpy.poly1d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_padding"], ["def", "__init__", "(", "self", ",", "channels", ",", "filt_size", "=", "3", ",", "stride", "=", "2", ")", "->", "None", ":", "\n", "        ", "super", "(", "BlurPool2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "filt_size", ">", "1", "\n", "self", ".", "channels", "=", "channels", "\n", "self", ".", "filt_size", "=", "filt_size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "[", "get_padding", "(", "filt_size", ",", "stride", ",", "dilation", "=", "1", ")", "]", "*", "4", "\n", "coeffs", "=", "torch", ".", "tensor", "(", "(", "np", ".", "poly1d", "(", "(", "0.5", ",", "0.5", ")", ")", "**", "(", "self", ".", "filt_size", "-", "1", ")", ")", ".", "coeffs", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "blur_filter", "=", "(", "coeffs", "[", ":", ",", "None", "]", "*", "coeffs", "[", "None", ",", ":", "]", ")", "[", "None", ",", "None", ",", ":", ",", ":", "]", ".", "repeat", "(", "self", ".", "channels", ",", "1", ",", "1", ",", "1", ")", "\n", "self", ".", "register_buffer", "(", "'filt'", ",", "blur_filter", ",", "persistent", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.blur_pool.BlurPool2d.forward": [[40, 43], ["torch.pad", "torch.pad", "torch.pad", "torch.conv2d", "torch.conv2d", "torch.conv2d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "x", "=", "F", ".", "pad", "(", "x", ",", "self", ".", "padding", ",", "'reflect'", ")", "\n", "return", "F", ".", "conv2d", "(", "x", ",", "self", ".", "filt", ",", "stride", "=", "self", ".", "stride", ",", "groups", "=", "self", ".", "channels", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.set_no_jit.__init__": [[30, 34], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mode", ":", "bool", ")", "->", "None", ":", "\n", "        ", "global", "_NO_JIT", "\n", "self", ".", "prev", "=", "_NO_JIT", "\n", "_NO_JIT", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.set_no_jit.__enter__": [[35, 37], ["None"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.set_no_jit.__exit__": [[38, 42], ["None"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "*", "args", ":", "Any", ")", "->", "bool", ":", "\n", "        ", "global", "_NO_JIT", "\n", "_NO_JIT", "=", "self", ".", "prev", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.set_exportable.__init__": [[49, 53], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mode", ":", "bool", ")", "->", "None", ":", "\n", "        ", "global", "_EXPORTABLE", "\n", "self", ".", "prev", "=", "_EXPORTABLE", "\n", "_EXPORTABLE", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.set_exportable.__enter__": [[54, 56], ["None"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.set_exportable.__exit__": [[57, 61], ["None"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "*", "args", ":", "Any", ")", "->", "bool", ":", "\n", "        ", "global", "_EXPORTABLE", "\n", "_EXPORTABLE", "=", "self", ".", "prev", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.set_scriptable.__init__": [[68, 72], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mode", ":", "bool", ")", "->", "None", ":", "\n", "        ", "global", "_SCRIPTABLE", "\n", "self", ".", "prev", "=", "_SCRIPTABLE", "\n", "_SCRIPTABLE", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.set_scriptable.__enter__": [[73, 75], ["None"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.set_scriptable.__exit__": [[76, 80], ["None"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "*", "args", ":", "Any", ")", "->", "bool", ":", "\n", "        ", "global", "_SCRIPTABLE", "\n", "_SCRIPTABLE", "=", "self", ".", "prev", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.set_layer_config.__init__": [[86, 105], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "scriptable", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "exportable", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "no_jit", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "no_activation_jit", ":", "Optional", "[", "bool", "]", "=", "None", ")", ":", "\n", "        ", "global", "_SCRIPTABLE", "\n", "global", "_EXPORTABLE", "\n", "global", "_NO_JIT", "\n", "global", "_NO_ACTIVATION_JIT", "\n", "self", ".", "prev", "=", "_SCRIPTABLE", ",", "_EXPORTABLE", ",", "_NO_JIT", ",", "_NO_ACTIVATION_JIT", "\n", "if", "scriptable", "is", "not", "None", ":", "\n", "            ", "_SCRIPTABLE", "=", "scriptable", "\n", "", "if", "exportable", "is", "not", "None", ":", "\n", "            ", "_EXPORTABLE", "=", "exportable", "\n", "", "if", "no_jit", "is", "not", "None", ":", "\n", "            ", "_NO_JIT", "=", "no_jit", "\n", "", "if", "no_activation_jit", "is", "not", "None", ":", "\n", "            ", "_NO_ACTIVATION_JIT", "=", "no_activation_jit", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.set_layer_config.__enter__": [[106, 108], ["None"], "methods", ["None"], ["", "", "def", "__enter__", "(", "self", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.set_layer_config.__exit__": [[109, 116], ["None"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "*", "args", ":", "Any", ")", "->", "bool", ":", "\n", "        ", "global", "_SCRIPTABLE", "\n", "global", "_EXPORTABLE", "\n", "global", "_NO_JIT", "\n", "global", "_NO_ACTIVATION_JIT", "\n", "_SCRIPTABLE", ",", "_EXPORTABLE", ",", "_NO_JIT", ",", "_NO_ACTIVATION_JIT", "=", "self", ".", "prev", "\n", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.is_no_jit": [[25, 27], ["None"], "function", ["None"], ["def", "is_no_jit", "(", ")", ":", "\n", "    ", "return", "_NO_JIT", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.is_exportable": [[44, 46], ["None"], "function", ["None"], ["", "", "def", "is_exportable", "(", ")", ":", "\n", "    ", "return", "_EXPORTABLE", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.is_scriptable": [[63, 65], ["None"], "function", ["None"], ["", "", "def", "is_scriptable", "(", ")", ":", "\n", "    ", "return", "_SCRIPTABLE", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cbam.ChannelAttn.__init__": [[22, 32], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "act_layer", "torch.nn.Conv2d", "torch.nn.Conv2d", "create_act.create_act_layer", "helpers.make_divisible"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["def", "__init__", "(", "\n", "self", ",", "channels", ",", "rd_ratio", "=", "1.", "/", "16", ",", "rd_channels", "=", "None", ",", "rd_divisor", "=", "1", ",", "\n", "act_layer", "=", "nn", ".", "ReLU", ",", "gate_layer", "=", "'sigmoid'", ",", "mlp_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", "ChannelAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "rd_channels", ":", "\n", "            ", "rd_channels", "=", "make_divisible", "(", "channels", "*", "rd_ratio", ",", "rd_divisor", ",", "round_limit", "=", "0.", ")", "\n", "", "self", ".", "fc1", "=", "nn", ".", "Conv2d", "(", "channels", ",", "rd_channels", ",", "1", ",", "bias", "=", "mlp_bias", ")", "\n", "self", ".", "act", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Conv2d", "(", "rd_channels", ",", "channels", ",", "1", ",", "bias", "=", "mlp_bias", ")", "\n", "self", ".", "gate", "=", "create_act_layer", "(", "gate_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cbam.ChannelAttn.forward": [[33, 37], ["cbam.ChannelAttn.fc2", "cbam.ChannelAttn.fc2", "cbam.ChannelAttn.act", "cbam.ChannelAttn.act", "cbam.ChannelAttn.gate", "cbam.ChannelAttn.fc1", "cbam.ChannelAttn.fc1", "x.mean", "x.amax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_avg", "=", "self", ".", "fc2", "(", "self", ".", "act", "(", "self", ".", "fc1", "(", "x", ".", "mean", "(", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", ")", ")", ")", "\n", "x_max", "=", "self", ".", "fc2", "(", "self", ".", "act", "(", "self", ".", "fc1", "(", "x", ".", "amax", "(", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", ")", ")", ")", "\n", "return", "x", "*", "self", ".", "gate", "(", "x_avg", "+", "x_max", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cbam.LightChannelAttn.__init__": [[42, 47], ["cbam.ChannelAttn.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "channels", ",", "rd_ratio", "=", "1.", "/", "16", ",", "rd_channels", "=", "None", ",", "rd_divisor", "=", "1", ",", "\n", "act_layer", "=", "nn", ".", "ReLU", ",", "gate_layer", "=", "'sigmoid'", ",", "mlp_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", "LightChannelAttn", ",", "self", ")", ".", "__init__", "(", "\n", "channels", ",", "rd_ratio", ",", "rd_channels", ",", "rd_divisor", ",", "act_layer", ",", "gate_layer", ",", "mlp_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cbam.LightChannelAttn.forward": [[48, 52], ["cbam.LightChannelAttn.fc2", "cbam.LightChannelAttn.act", "torch.sigmoid", "torch.sigmoid", "x.mean", "x.amax", "cbam.LightChannelAttn.fc1"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_pool", "=", "0.5", "*", "x", ".", "mean", "(", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "+", "0.5", "*", "x", ".", "amax", "(", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "x_attn", "=", "self", ".", "fc2", "(", "self", ".", "act", "(", "self", ".", "fc1", "(", "x_pool", ")", ")", ")", "\n", "return", "x", "*", "F", ".", "sigmoid", "(", "x_attn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cbam.SpatialAttn.__init__": [[57, 61], ["torch.nn.Module.__init__", "conv_bn_act.ConvNormAct", "create_act.create_act_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer"], ["def", "__init__", "(", "self", ",", "kernel_size", "=", "7", ",", "gate_layer", "=", "'sigmoid'", ")", ":", "\n", "        ", "super", "(", "SpatialAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "ConvNormAct", "(", "2", ",", "1", ",", "kernel_size", ",", "apply_act", "=", "False", ")", "\n", "self", ".", "gate", "=", "create_act_layer", "(", "gate_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cbam.SpatialAttn.forward": [[62, 66], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "cbam.SpatialAttn.conv", "cbam.SpatialAttn.gate", "x.mean", "x.amax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_attn", "=", "torch", ".", "cat", "(", "[", "x", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ",", "x", ".", "amax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "]", ",", "dim", "=", "1", ")", "\n", "x_attn", "=", "self", ".", "conv", "(", "x_attn", ")", "\n", "return", "x", "*", "self", ".", "gate", "(", "x_attn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cbam.LightSpatialAttn.__init__": [[71, 75], ["torch.nn.Module.__init__", "conv_bn_act.ConvNormAct", "create_act.create_act_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer"], ["def", "__init__", "(", "self", ",", "kernel_size", "=", "7", ",", "gate_layer", "=", "'sigmoid'", ")", ":", "\n", "        ", "super", "(", "LightSpatialAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "ConvNormAct", "(", "1", ",", "1", ",", "kernel_size", ",", "apply_act", "=", "False", ")", "\n", "self", ".", "gate", "=", "create_act_layer", "(", "gate_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cbam.LightSpatialAttn.forward": [[76, 80], ["cbam.LightSpatialAttn.conv", "cbam.LightSpatialAttn.gate", "x.mean", "x.amax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_attn", "=", "0.5", "*", "x", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "+", "0.5", "*", "x", ".", "amax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "x_attn", "=", "self", ".", "conv", "(", "x_attn", ")", "\n", "return", "x", "*", "self", ".", "gate", "(", "x_attn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cbam.CbamModule.__init__": [[83, 91], ["torch.nn.Module.__init__", "cbam.ChannelAttn", "cbam.SpatialAttn"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "channels", ",", "rd_ratio", "=", "1.", "/", "16", ",", "rd_channels", "=", "None", ",", "rd_divisor", "=", "1", ",", "\n", "spatial_kernel_size", "=", "7", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "gate_layer", "=", "'sigmoid'", ",", "mlp_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", "CbamModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "channel", "=", "ChannelAttn", "(", "\n", "channels", ",", "rd_ratio", "=", "rd_ratio", ",", "rd_channels", "=", "rd_channels", ",", "\n", "rd_divisor", "=", "rd_divisor", ",", "act_layer", "=", "act_layer", ",", "gate_layer", "=", "gate_layer", ",", "mlp_bias", "=", "mlp_bias", ")", "\n", "self", ".", "spatial", "=", "SpatialAttn", "(", "spatial_kernel_size", ",", "gate_layer", "=", "gate_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cbam.CbamModule.forward": [[92, 96], ["cbam.CbamModule.channel", "cbam.CbamModule.spatial"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "channel", "(", "x", ")", "\n", "x", "=", "self", ".", "spatial", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cbam.LightCbamModule.__init__": [[99, 107], ["torch.nn.Module.__init__", "cbam.LightChannelAttn", "cbam.LightSpatialAttn"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "channels", ",", "rd_ratio", "=", "1.", "/", "16", ",", "rd_channels", "=", "None", ",", "rd_divisor", "=", "1", ",", "\n", "spatial_kernel_size", "=", "7", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "gate_layer", "=", "'sigmoid'", ",", "mlp_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", "LightCbamModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "channel", "=", "LightChannelAttn", "(", "\n", "channels", ",", "rd_ratio", "=", "rd_ratio", ",", "rd_channels", "=", "rd_channels", ",", "\n", "rd_divisor", "=", "rd_divisor", ",", "act_layer", "=", "act_layer", ",", "gate_layer", "=", "gate_layer", ",", "mlp_bias", "=", "mlp_bias", ")", "\n", "self", ".", "spatial", "=", "LightSpatialAttn", "(", "spatial_kernel_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cbam.LightCbamModule.forward": [[108, 112], ["cbam.LightCbamModule.channel", "cbam.LightCbamModule.spatial"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "channel", "(", "x", ")", "\n", "x", "=", "self", ".", "spatial", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.eca.EcaModule.__init__": [[60, 83], ["torch.nn.Module.__init__", "create_act.create_act_layer", "int", "max", "torch.nn.Conv1d", "create_act.create_act_layer", "torch.nn.Conv1d", "torch.nn.Conv1d", "helpers.make_divisible", "abs", "math.log"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["def", "__init__", "(", "\n", "self", ",", "channels", "=", "None", ",", "kernel_size", "=", "3", ",", "gamma", "=", "2", ",", "beta", "=", "1", ",", "act_layer", "=", "None", ",", "gate_layer", "=", "'sigmoid'", ",", "\n", "rd_ratio", "=", "1", "/", "8", ",", "rd_channels", "=", "None", ",", "rd_divisor", "=", "8", ",", "use_mlp", "=", "False", ")", ":", "\n", "        ", "super", "(", "EcaModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "channels", "is", "not", "None", ":", "\n", "            ", "t", "=", "int", "(", "abs", "(", "math", ".", "log", "(", "channels", ",", "2", ")", "+", "beta", ")", "/", "gamma", ")", "\n", "kernel_size", "=", "max", "(", "t", "if", "t", "%", "2", "else", "t", "+", "1", ",", "3", ")", "\n", "", "assert", "kernel_size", "%", "2", "==", "1", "\n", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", "\n", "if", "use_mlp", ":", "\n", "# NOTE 'mlp' mode is a timm experiment, not in paper", "\n", "            ", "assert", "channels", "is", "not", "None", "\n", "if", "rd_channels", "is", "None", ":", "\n", "                ", "rd_channels", "=", "make_divisible", "(", "channels", "*", "rd_ratio", ",", "divisor", "=", "rd_divisor", ")", "\n", "", "act_layer", "=", "act_layer", "or", "nn", ".", "ReLU", "\n", "self", ".", "conv", "=", "nn", ".", "Conv1d", "(", "1", ",", "rd_channels", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "True", ")", "\n", "self", ".", "act", "=", "create_act_layer", "(", "act_layer", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv1d", "(", "rd_channels", ",", "1", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", ",", "bias", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv", "=", "nn", ".", "Conv1d", "(", "1", ",", "1", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", ",", "bias", "=", "False", ")", "\n", "self", ".", "act", "=", "None", "\n", "self", ".", "conv2", "=", "None", "\n", "", "self", ".", "gate", "=", "create_act_layer", "(", "gate_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.eca.EcaModule.forward": [[84, 92], ["x.mean().view", "eca.EcaModule.conv", "eca.EcaModule.gate().view", "eca.EcaModule.act", "eca.EcaModule.conv2", "eca.EcaModule.expand_as", "x.mean", "eca.EcaModule.gate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "y", "=", "x", ".", "mean", "(", "(", "2", ",", "3", ")", ")", ".", "view", "(", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "-", "1", ")", "# view for 1d conv", "\n", "y", "=", "self", ".", "conv", "(", "y", ")", "\n", "if", "self", ".", "conv2", "is", "not", "None", ":", "\n", "            ", "y", "=", "self", ".", "act", "(", "y", ")", "\n", "y", "=", "self", ".", "conv2", "(", "y", ")", "\n", "", "y", "=", "self", ".", "gate", "(", "y", ")", ".", "view", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "return", "x", "*", "y", ".", "expand_as", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.eca.CecaModule.__init__": [[121, 135], ["torch.nn.Module.__init__", "torch.nn.Conv1d", "create_act.create_act_layer", "int", "max", "abs", "math.log"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer"], ["def", "__init__", "(", "self", ",", "channels", "=", "None", ",", "kernel_size", "=", "3", ",", "gamma", "=", "2", ",", "beta", "=", "1", ",", "act_layer", "=", "None", ",", "gate_layer", "=", "'sigmoid'", ")", ":", "\n", "        ", "super", "(", "CecaModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "channels", "is", "not", "None", ":", "\n", "            ", "t", "=", "int", "(", "abs", "(", "math", ".", "log", "(", "channels", ",", "2", ")", "+", "beta", ")", "/", "gamma", ")", "\n", "kernel_size", "=", "max", "(", "t", "if", "t", "%", "2", "else", "t", "+", "1", ",", "3", ")", "\n", "", "has_act", "=", "act_layer", "is", "not", "None", "\n", "assert", "kernel_size", "%", "2", "==", "1", "\n", "\n", "# PyTorch circular padding mode is buggy as of pytorch 1.4", "\n", "# see https://github.com/pytorch/pytorch/pull/17240", "\n", "# implement manual circular padding", "\n", "self", ".", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", "\n", "self", ".", "conv", "=", "nn", ".", "Conv1d", "(", "1", ",", "1", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "0", ",", "bias", "=", "has_act", ")", "\n", "self", ".", "gate", "=", "create_act_layer", "(", "gate_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.eca.CecaModule.forward": [[136, 143], ["x.mean().view", "torch.pad", "eca.CecaModule.conv", "eca.CecaModule.gate().view", "eca.CecaModule.expand_as", "x.mean", "eca.CecaModule.gate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "y", "=", "x", ".", "mean", "(", "(", "2", ",", "3", ")", ")", ".", "view", "(", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "-", "1", ")", "\n", "# Manually implement circular padding, F.pad does not seemed to be bugged", "\n", "y", "=", "F", ".", "pad", "(", "y", ",", "(", "self", ".", "padding", ",", "self", ".", "padding", ")", ",", "mode", "=", "'circular'", ")", "\n", "y", "=", "self", ".", "conv", "(", "y", ")", "\n", "y", "=", "self", ".", "gate", "(", "y", ")", ".", "view", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "return", "x", "*", "y", ".", "expand_as", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.global_context.GlobalContext.__init__": [[21, 42], ["torch.nn.Module.__init__", "create_act.get_act_layer", "create_act.create_act_layer", "global_context.GlobalContext.reset_parameters", "torch.nn.Conv2d", "helpers.make_divisible", "mlp.ConvMlp", "mlp.ConvMlp"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["    ", "def", "__init__", "(", "self", ",", "channels", ",", "use_attn", "=", "True", ",", "fuse_add", "=", "False", ",", "fuse_scale", "=", "True", ",", "init_last_zero", "=", "False", ",", "\n", "rd_ratio", "=", "1.", "/", "8", ",", "rd_channels", "=", "None", ",", "rd_divisor", "=", "1", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "gate_layer", "=", "'sigmoid'", ")", ":", "\n", "        ", "super", "(", "GlobalContext", ",", "self", ")", ".", "__init__", "(", ")", "\n", "act_layer", "=", "get_act_layer", "(", "act_layer", ")", "\n", "\n", "self", ".", "conv_attn", "=", "nn", ".", "Conv2d", "(", "channels", ",", "1", ",", "kernel_size", "=", "1", ",", "bias", "=", "True", ")", "if", "use_attn", "else", "None", "\n", "\n", "if", "rd_channels", "is", "None", ":", "\n", "            ", "rd_channels", "=", "make_divisible", "(", "channels", "*", "rd_ratio", ",", "rd_divisor", ",", "round_limit", "=", "0.", ")", "\n", "", "if", "fuse_add", ":", "\n", "            ", "self", ".", "mlp_add", "=", "ConvMlp", "(", "channels", ",", "rd_channels", ",", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "LayerNorm2d", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "mlp_add", "=", "None", "\n", "", "if", "fuse_scale", ":", "\n", "            ", "self", ".", "mlp_scale", "=", "ConvMlp", "(", "channels", ",", "rd_channels", ",", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "LayerNorm2d", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "mlp_scale", "=", "None", "\n", "\n", "", "self", ".", "gate", "=", "create_act_layer", "(", "gate_layer", ")", "\n", "self", ".", "init_last_zero", "=", "init_last_zero", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.global_context.GlobalContext.reset_parameters": [[43, 48], ["torch.nn.init.kaiming_normal_", "torch.nn.init.zeros_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "conv_attn", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "conv_attn", ".", "weight", ",", "mode", "=", "'fan_in'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "if", "self", ".", "mlp_add", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "mlp_add", ".", "fc2", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.global_context.GlobalContext.forward": [[49, 68], ["global_context.GlobalContext.conv_attn().reshape", "torch.softmax().unsqueeze", "x.mean.view", "x.mean", "global_context.GlobalContext.mlp_scale", "global_context.GlobalContext.mlp_add", "x.reshape().unsqueeze", "global_context.GlobalContext.gate", "global_context.GlobalContext.conv_attn", "torch.softmax", "x.reshape"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "\n", "if", "self", ".", "conv_attn", "is", "not", "None", ":", "\n", "            ", "attn", "=", "self", ".", "conv_attn", "(", "x", ")", ".", "reshape", "(", "B", ",", "1", ",", "H", "*", "W", ")", "# (B, 1, H * W)", "\n", "attn", "=", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "-", "1", ")", ".", "unsqueeze", "(", "3", ")", "# (B, 1, H * W, 1)", "\n", "context", "=", "x", ".", "reshape", "(", "B", ",", "C", ",", "H", "*", "W", ")", ".", "unsqueeze", "(", "1", ")", "@", "attn", "\n", "context", "=", "context", ".", "view", "(", "B", ",", "C", ",", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "context", "=", "x", ".", "mean", "(", "dim", "=", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "\n", "", "if", "self", ".", "mlp_scale", "is", "not", "None", ":", "\n", "            ", "mlp_x", "=", "self", ".", "mlp_scale", "(", "context", ")", "\n", "x", "=", "x", "*", "self", ".", "gate", "(", "mlp_x", ")", "\n", "", "if", "self", ".", "mlp_add", "is", "not", "None", ":", "\n", "            ", "mlp_x", "=", "self", ".", "mlp_add", "(", "context", ")", "\n", "x", "=", "x", "+", "mlp_x", "\n", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.median_pool.MedianPool2d.__init__": [[18, 24], ["torch.Module.__init__", "helpers.to_2tuple", "helpers.to_2tuple", "helpers.to_4tuple"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "same", "=", "False", ")", ":", "\n", "        ", "super", "(", "MedianPool2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "k", "=", "to_2tuple", "(", "kernel_size", ")", "\n", "self", ".", "stride", "=", "to_2tuple", "(", "stride", ")", "\n", "self", ".", "padding", "=", "to_4tuple", "(", "padding", ")", "# convert to l, r, t, b", "\n", "self", ".", "same", "=", "same", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.median_pool.MedianPool2d._padding": [[25, 44], ["x.size", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_padding", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "same", ":", "\n", "            ", "ih", ",", "iw", "=", "x", ".", "size", "(", ")", "[", "2", ":", "]", "\n", "if", "ih", "%", "self", ".", "stride", "[", "0", "]", "==", "0", ":", "\n", "                ", "ph", "=", "max", "(", "self", ".", "k", "[", "0", "]", "-", "self", ".", "stride", "[", "0", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "                ", "ph", "=", "max", "(", "self", ".", "k", "[", "0", "]", "-", "(", "ih", "%", "self", ".", "stride", "[", "0", "]", ")", ",", "0", ")", "\n", "", "if", "iw", "%", "self", ".", "stride", "[", "1", "]", "==", "0", ":", "\n", "                ", "pw", "=", "max", "(", "self", ".", "k", "[", "1", "]", "-", "self", ".", "stride", "[", "1", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "                ", "pw", "=", "max", "(", "self", ".", "k", "[", "1", "]", "-", "(", "iw", "%", "self", ".", "stride", "[", "1", "]", ")", ",", "0", ")", "\n", "", "pl", "=", "pw", "//", "2", "\n", "pr", "=", "pw", "-", "pl", "\n", "pt", "=", "ph", "//", "2", "\n", "pb", "=", "ph", "-", "pt", "\n", "padding", "=", "(", "pl", ",", "pr", ",", "pt", ",", "pb", ")", "\n", "", "else", ":", "\n", "            ", "padding", "=", "self", ".", "padding", "\n", "", "return", "padding", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.median_pool.MedianPool2d.forward": [[45, 50], ["torch.pad", "torch.pad", "x.unfold().unfold.unfold().unfold.unfold().unfold", "median_pool.MedianPool2d._padding", "x.unfold().unfold.unfold().unfold.contiguous().view().median", "x.unfold().unfold.unfold().unfold.unfold", "x.unfold().unfold.unfold().unfold.contiguous().view", "x.unfold().unfold.unfold().unfold.contiguous", "x.unfold().unfold.unfold().unfold.size"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.median_pool.MedianPool2d._padding"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "pad", "(", "x", ",", "self", ".", "_padding", "(", "x", ")", ",", "mode", "=", "'reflect'", ")", "\n", "x", "=", "x", ".", "unfold", "(", "2", ",", "self", ".", "k", "[", "0", "]", ",", "self", ".", "stride", "[", "0", "]", ")", ".", "unfold", "(", "3", ",", "self", ".", "k", "[", "1", "]", ",", "self", ".", "stride", "[", "1", "]", ")", "\n", "x", "=", "x", ".", "contiguous", "(", ")", ".", "view", "(", "x", ".", "size", "(", ")", "[", ":", "4", "]", "+", "(", "-", "1", ",", ")", ")", ".", "median", "(", "dim", "=", "-", "1", ")", "[", "0", "]", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.split_batchnorm.SplitBatchNorm2d.__init__": [[20, 27], ["super().__init__", "torch.ModuleList", "torch.ModuleList", "torch.BatchNorm2d", "torch.BatchNorm2d", "range"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "\n", "track_running_stats", "=", "True", ",", "num_splits", "=", "2", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_features", ",", "eps", ",", "momentum", ",", "affine", ",", "track_running_stats", ")", "\n", "assert", "num_splits", ">", "1", ",", "'Should have at least one aux BN layer (num_splits at least 2)'", "\n", "self", ".", "num_splits", "=", "num_splits", "\n", "self", ".", "aux_bn", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "BatchNorm2d", "(", "num_features", ",", "eps", ",", "momentum", ",", "affine", ",", "track_running_stats", ")", "for", "_", "in", "range", "(", "num_splits", "-", "1", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.split_batchnorm.SplitBatchNorm2d.forward": [[28, 39], ["input.split", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "super().forward", "super().forward", "x.append", "a"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.forward", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.forward"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "# aux BN only relevant while training", "\n", "            ", "split_size", "=", "input", ".", "shape", "[", "0", "]", "//", "self", ".", "num_splits", "\n", "assert", "input", ".", "shape", "[", "0", "]", "==", "split_size", "*", "self", ".", "num_splits", ",", "\"batch size must be evenly divisible by num_splits\"", "\n", "split_input", "=", "input", ".", "split", "(", "split_size", ")", "\n", "x", "=", "[", "super", "(", ")", ".", "forward", "(", "split_input", "[", "0", "]", ")", "]", "\n", "for", "i", ",", "a", "in", "enumerate", "(", "self", ".", "aux_bn", ")", ":", "\n", "                ", "x", ".", "append", "(", "a", "(", "split_input", "[", "i", "+", "1", "]", ")", ")", "\n", "", "return", "torch", ".", "cat", "(", "x", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "return", "super", "(", ")", ".", "forward", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.split_batchnorm.convert_splitbn_model": [[41, 76], ["isinstance", "isinstance", "module.named_children", "split_batchnorm.SplitBatchNorm2d", "SplitBatchNorm2d.add_module", "module.weight.data.clone().detach", "module.bias.data.clone().detach", "module.running_mean.clone", "module.running_var.clone", "module.num_batches_tracked.clone", "split_batchnorm.convert_splitbn_model", "module.weight.data.clone().detach", "module.bias.data.clone().detach", "module.weight.data.clone", "module.bias.data.clone", "module.weight.data.clone", "module.bias.data.clone"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.split_batchnorm.convert_splitbn_model"], ["", "", "", "def", "convert_splitbn_model", "(", "module", ",", "num_splits", "=", "2", ")", ":", "\n", "    ", "\"\"\"\n    Recursively traverse module and its children to replace all instances of\n    ``torch.nn.modules.batchnorm._BatchNorm`` with `SplitBatchnorm2d`.\n    Args:\n        module (torch.nn.Module): input module\n        num_splits: number of separate batchnorm layers to split input across\n    Example::\n        >>> # model is an instance of torch.nn.Module\n        >>> model = timm.models.convert_splitbn_model(model, num_splits=2)\n    \"\"\"", "\n", "mod", "=", "module", "\n", "if", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "modules", ".", "instancenorm", ".", "_InstanceNorm", ")", ":", "\n", "        ", "return", "module", "\n", "", "if", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "modules", ".", "batchnorm", ".", "_BatchNorm", ")", ":", "\n", "        ", "mod", "=", "SplitBatchNorm2d", "(", "\n", "module", ".", "num_features", ",", "module", ".", "eps", ",", "module", ".", "momentum", ",", "module", ".", "affine", ",", "\n", "module", ".", "track_running_stats", ",", "num_splits", "=", "num_splits", ")", "\n", "mod", ".", "running_mean", "=", "module", ".", "running_mean", "\n", "mod", ".", "running_var", "=", "module", ".", "running_var", "\n", "mod", ".", "num_batches_tracked", "=", "module", ".", "num_batches_tracked", "\n", "if", "module", ".", "affine", ":", "\n", "            ", "mod", ".", "weight", ".", "data", "=", "module", ".", "weight", ".", "data", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "mod", ".", "bias", ".", "data", "=", "module", ".", "bias", ".", "data", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "for", "aux", "in", "mod", ".", "aux_bn", ":", "\n", "            ", "aux", ".", "running_mean", "=", "module", ".", "running_mean", ".", "clone", "(", ")", "\n", "aux", ".", "running_var", "=", "module", ".", "running_var", ".", "clone", "(", ")", "\n", "aux", ".", "num_batches_tracked", "=", "module", ".", "num_batches_tracked", ".", "clone", "(", ")", "\n", "if", "module", ".", "affine", ":", "\n", "                ", "aux", ".", "weight", ".", "data", "=", "module", ".", "weight", ".", "data", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "aux", ".", "bias", ".", "data", "=", "module", ".", "bias", ".", "data", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "", "", "for", "name", ",", "child", "in", "module", ".", "named_children", "(", ")", ":", "\n", "        ", "mod", ".", "add_module", "(", "name", ",", "convert_splitbn_model", "(", "child", ",", "num_splits", "=", "num_splits", ")", ")", "\n", "", "del", "module", "\n", "return", "mod", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.halo_attn.PosEmbedRel.__init__": [[67, 80], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "block_size", ",", "win_size", ",", "dim_head", ",", "scale", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            block_size (int): block size\n            win_size (int): neighbourhood window size\n            dim_head (int): attention head dim\n            scale (float): scale factor (for init)\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "block_size", "=", "block_size", "\n", "self", ".", "dim_head", "=", "dim_head", "\n", "self", ".", "height_rel", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "win_size", "*", "2", "-", "1", ",", "dim_head", ")", "*", "scale", ")", "\n", "self", ".", "width_rel", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "win_size", "*", "2", "-", "1", ",", "dim_head", ")", "*", "scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.halo_attn.PosEmbedRel.forward": [[81, 95], ["q.transpose.transpose.reshape", "halo_attn.rel_logits_1d", "q.transpose.transpose.transpose", "halo_attn.rel_logits_1d", "rel_logits.reshape.reshape.reshape"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.halo_attn.rel_logits_1d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.halo_attn.rel_logits_1d"], ["", "def", "forward", "(", "self", ",", "q", ")", ":", "\n", "        ", "B", ",", "BB", ",", "HW", ",", "_", "=", "q", ".", "shape", "\n", "\n", "# relative logits in width dimension.", "\n", "q", "=", "q", ".", "reshape", "(", "-", "1", ",", "self", ".", "block_size", ",", "self", ".", "block_size", ",", "self", ".", "dim_head", ")", "\n", "rel_logits_w", "=", "rel_logits_1d", "(", "q", ",", "self", ".", "width_rel", ",", "permute_mask", "=", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ")", ")", "\n", "\n", "# relative logits in height dimension.", "\n", "q", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", "\n", "rel_logits_h", "=", "rel_logits_1d", "(", "q", ",", "self", ".", "height_rel", ",", "permute_mask", "=", "(", "0", ",", "3", ",", "1", ",", "4", ",", "2", ")", ")", "\n", "\n", "rel_logits", "=", "rel_logits_h", "+", "rel_logits_w", "\n", "rel_logits", "=", "rel_logits", ".", "reshape", "(", "B", ",", "BB", ",", "HW", ",", "-", "1", ")", "\n", "return", "rel_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.halo_attn.HaloAttn.__init__": [[125, 161], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "halo_attn.PosEmbedRel", "halo_attn.HaloAttn.reset_parameters", "torch.nn.AvgPool2d", "torch.nn.AvgPool2d", "torch.nn.Identity", "torch.nn.Identity", "helpers.make_divisible"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["def", "__init__", "(", "\n", "self", ",", "dim", ",", "dim_out", "=", "None", ",", "feat_size", "=", "None", ",", "stride", "=", "1", ",", "num_heads", "=", "8", ",", "dim_head", "=", "None", ",", "block_size", "=", "8", ",", "halo_size", "=", "3", ",", "\n", "qk_ratio", "=", "1.0", ",", "qkv_bias", "=", "False", ",", "avg_down", "=", "False", ",", "scale_pos_embed", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "dim_out", "=", "dim_out", "or", "dim", "\n", "assert", "dim_out", "%", "num_heads", "==", "0", "\n", "assert", "stride", "in", "(", "1", ",", "2", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dim_head_qk", "=", "dim_head", "or", "make_divisible", "(", "dim_out", "*", "qk_ratio", ",", "divisor", "=", "8", ")", "//", "num_heads", "\n", "self", ".", "dim_head_v", "=", "dim_out", "//", "self", ".", "num_heads", "\n", "self", ".", "dim_out_qk", "=", "num_heads", "*", "self", ".", "dim_head_qk", "\n", "self", ".", "dim_out_v", "=", "num_heads", "*", "self", ".", "dim_head_v", "\n", "self", ".", "scale", "=", "self", ".", "dim_head_qk", "**", "-", "0.5", "\n", "self", ".", "scale_pos_embed", "=", "scale_pos_embed", "\n", "self", ".", "block_size", "=", "self", ".", "block_size_ds", "=", "block_size", "\n", "self", ".", "halo_size", "=", "halo_size", "\n", "self", ".", "win_size", "=", "block_size", "+", "halo_size", "*", "2", "# neighbourhood window size", "\n", "self", ".", "block_stride", "=", "1", "\n", "use_avg_pool", "=", "False", "\n", "if", "stride", ">", "1", ":", "\n", "            ", "use_avg_pool", "=", "avg_down", "or", "block_size", "%", "stride", "!=", "0", "\n", "self", ".", "block_stride", "=", "1", "if", "use_avg_pool", "else", "stride", "\n", "self", ".", "block_size_ds", "=", "self", ".", "block_size", "//", "self", ".", "block_stride", "\n", "\n", "# FIXME not clear if this stride behaviour is what the paper intended", "\n", "# Also, the paper mentions using a 3D conv for dealing with the blocking/gather, and leaving", "\n", "# data in unfolded block form. I haven't wrapped my head around how that'd look.", "\n", "", "self", ".", "q", "=", "nn", ".", "Conv2d", "(", "dim", ",", "self", ".", "dim_out_qk", ",", "1", ",", "stride", "=", "self", ".", "block_stride", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "kv", "=", "nn", ".", "Conv2d", "(", "dim", ",", "self", ".", "dim_out_qk", "+", "self", ".", "dim_out_v", ",", "1", ",", "bias", "=", "qkv_bias", ")", "\n", "\n", "self", ".", "pos_embed", "=", "PosEmbedRel", "(", "\n", "block_size", "=", "self", ".", "block_size_ds", ",", "win_size", "=", "self", ".", "win_size", ",", "dim_head", "=", "self", ".", "dim_head_qk", ",", "scale", "=", "self", ".", "scale", ")", "\n", "\n", "self", ".", "pool", "=", "nn", ".", "AvgPool2d", "(", "2", ",", "2", ")", "if", "use_avg_pool", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.halo_attn.HaloAttn.reset_parameters": [[162, 168], ["weight_init.trunc_normal_", "weight_init.trunc_normal_", "weight_init.trunc_normal_", "weight_init.trunc_normal_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "std", "=", "self", ".", "q", ".", "weight", ".", "shape", "[", "1", "]", "**", "-", "0.5", "# fan-in", "\n", "trunc_normal_", "(", "self", ".", "q", ".", "weight", ",", "std", "=", "std", ")", "\n", "trunc_normal_", "(", "self", ".", "kv", ".", "weight", ",", "std", "=", "std", ")", "\n", "trunc_normal_", "(", "self", ".", "pos_embed", ".", "height_rel", ",", "std", "=", "self", ".", "scale", ")", "\n", "trunc_normal_", "(", "self", ".", "pos_embed", ".", "width_rel", ",", "std", "=", "self", ".", "scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.halo_attn.HaloAttn.forward": [[169, 211], ["trace_utils._assert", "trace_utils._assert", "halo_attn.HaloAttn.q", "q.reshape().transpose.reshape().transpose.reshape().permute", "q.reshape().transpose.reshape().transpose.reshape().transpose", "halo_attn.HaloAttn.kv", "torch.pad", "torch.pad", "kv.unfold().unfold().reshape().permute.unfold().unfold().reshape().permute.unfold().unfold().reshape().permute", "torch.split", "torch.split", "torch.split", "torch.split", "attn.softmax.softmax.softmax", "halo_attn.HaloAttn.reshape", "halo_attn.HaloAttn.permute().contiguous().view", "halo_attn.HaloAttn.pool", "q.reshape().transpose.reshape().transpose.reshape", "q.reshape().transpose.reshape().transpose.reshape", "kv.unfold().unfold().reshape().permute.unfold().unfold().reshape().permute.unfold().unfold().reshape", "halo_attn.HaloAttn.pos_embed", "halo_attn.HaloAttn.permute().contiguous", "halo_attn.HaloAttn.pos_embed", "kv.unfold().unfold().reshape().permute.unfold().unfold().reshape().permute.unfold().unfold", "k.transpose", "k.transpose", "halo_attn.HaloAttn.permute", "kv.unfold().unfold().reshape().permute.unfold().unfold().reshape().permute.unfold"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "_assert", "(", "H", "%", "self", ".", "block_size", "==", "0", ",", "''", ")", "\n", "_assert", "(", "W", "%", "self", ".", "block_size", "==", "0", ",", "''", ")", "\n", "num_h_blocks", "=", "H", "//", "self", ".", "block_size", "\n", "num_w_blocks", "=", "W", "//", "self", ".", "block_size", "\n", "num_blocks", "=", "num_h_blocks", "*", "num_w_blocks", "\n", "\n", "q", "=", "self", ".", "q", "(", "x", ")", "\n", "# unfold", "\n", "q", "=", "q", ".", "reshape", "(", "\n", "-", "1", ",", "self", ".", "dim_head_qk", ",", "\n", "num_h_blocks", ",", "self", ".", "block_size_ds", ",", "num_w_blocks", ",", "self", ".", "block_size_ds", ")", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "5", ",", "2", ",", "4", ")", "\n", "# B, num_heads * dim_head * block_size ** 2, num_blocks", "\n", "q", "=", "q", ".", "reshape", "(", "B", "*", "self", ".", "num_heads", ",", "self", ".", "dim_head_qk", ",", "-", "1", ",", "num_blocks", ")", ".", "transpose", "(", "1", ",", "3", ")", "\n", "# B * num_heads, num_blocks, block_size ** 2, dim_head", "\n", "\n", "kv", "=", "self", ".", "kv", "(", "x", ")", "\n", "# Generate overlapping windows for kv. This approach is good for GPU and CPU. However, unfold() is not", "\n", "# lowered for PyTorch XLA so it will be very slow. See code at bottom of file for XLA friendly approach.", "\n", "# FIXME figure out how to switch impl between this and conv2d if XLA being used.", "\n", "kv", "=", "F", ".", "pad", "(", "kv", ",", "[", "self", ".", "halo_size", ",", "self", ".", "halo_size", ",", "self", ".", "halo_size", ",", "self", ".", "halo_size", "]", ")", "\n", "kv", "=", "kv", ".", "unfold", "(", "2", ",", "self", ".", "win_size", ",", "self", ".", "block_size", ")", ".", "unfold", "(", "3", ",", "self", ".", "win_size", ",", "self", ".", "block_size", ")", ".", "reshape", "(", "\n", "B", "*", "self", ".", "num_heads", ",", "self", ".", "dim_head_qk", "+", "self", ".", "dim_head_v", ",", "num_blocks", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "k", ",", "v", "=", "torch", ".", "split", "(", "kv", ",", "[", "self", ".", "dim_head_qk", ",", "self", ".", "dim_head_v", "]", ",", "dim", "=", "-", "1", ")", "\n", "# B * num_heads, num_blocks, win_size ** 2, dim_head_qk or dim_head_v", "\n", "\n", "if", "self", ".", "scale_pos_embed", ":", "\n", "            ", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "+", "self", ".", "pos_embed", "(", "q", ")", ")", "*", "self", ".", "scale", "\n", "", "else", ":", "\n", "            ", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "*", "self", ".", "scale", "+", "self", ".", "pos_embed", "(", "q", ")", "\n", "# B * num_heads, num_blocks, block_size ** 2, win_size ** 2", "\n", "", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "out", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "3", ")", "# B * num_heads, dim_head_v, block_size ** 2, num_blocks", "\n", "# fold", "\n", "out", "=", "out", ".", "reshape", "(", "-", "1", ",", "self", ".", "block_size_ds", ",", "self", ".", "block_size_ds", ",", "num_h_blocks", ",", "num_w_blocks", ")", "\n", "out", "=", "out", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "4", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "B", ",", "self", ".", "dim_out_v", ",", "H", "//", "self", ".", "block_stride", ",", "W", "//", "self", ".", "block_stride", ")", "\n", "# B, dim_out, H // block_stride, W // block_stride", "\n", "out", "=", "self", ".", "pool", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.halo_attn.rel_logits_1d": [[30, 59], ["x.reshape().expand.reshape", "torch.pad().flatten", "torch.pad", "x_pad.reshape.reshape", "x.reshape().expand.reshape().expand", "x.reshape().expand.permute", "rel_k.transpose", "torch.pad", "x.reshape().expand.reshape"], "function", ["None"], ["def", "rel_logits_1d", "(", "q", ",", "rel_k", ",", "permute_mask", ":", "List", "[", "int", "]", ")", ":", "\n", "    ", "\"\"\" Compute relative logits along one dimension\n\n    As per: https://gist.github.com/aravindsrinivas/56359b79f0ce4449bcb04ab4b56a57a2\n    Originally from: `Attention Augmented Convolutional Networks` - https://arxiv.org/abs/1904.09925\n\n    Args:\n        q: (batch, height, width, dim)\n        rel_k: (2 * window - 1, dim)\n        permute_mask: permute output dim according to this\n    \"\"\"", "\n", "B", ",", "H", ",", "W", ",", "dim", "=", "q", ".", "shape", "\n", "rel_size", "=", "rel_k", ".", "shape", "[", "0", "]", "\n", "win_size", "=", "(", "rel_size", "+", "1", ")", "//", "2", "\n", "\n", "x", "=", "(", "q", "@", "rel_k", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "x", "=", "x", ".", "reshape", "(", "-", "1", ",", "W", ",", "rel_size", ")", "\n", "\n", "# pad to shift from relative to absolute indexing", "\n", "x_pad", "=", "F", ".", "pad", "(", "x", ",", "[", "0", ",", "1", "]", ")", ".", "flatten", "(", "1", ")", "\n", "x_pad", "=", "F", ".", "pad", "(", "x_pad", ",", "[", "0", ",", "rel_size", "-", "W", "]", ")", "\n", "\n", "# reshape and slice out the padded elements", "\n", "x_pad", "=", "x_pad", ".", "reshape", "(", "-", "1", ",", "W", "+", "1", ",", "rel_size", ")", "\n", "x", "=", "x_pad", "[", ":", ",", ":", "W", ",", "win_size", "-", "1", ":", "]", "\n", "\n", "# reshape and tile", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "H", ",", "1", ",", "W", ",", "win_size", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "win_size", ",", "-", "1", ",", "-", "1", ")", "\n", "return", "x", ".", "permute", "(", "permute_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.conv_bn_act.ConvNormAct.__init__": [[12, 25], ["torch.nn.Module.__init__", "create_conv2d.create_conv2d.create_conv2d", "create_norm_act.get_norm_act_layer", "create_norm_act.get_norm_act_layer.", "dict"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "''", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "\n", "bias", "=", "False", ",", "apply_act", "=", "True", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "drop_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "ConvNormAct", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "create_conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "groups", "=", "groups", ",", "bias", "=", "bias", ")", "\n", "\n", "# NOTE for backwards compatibility with models that use separate norm and act layer definitions", "\n", "norm_act_layer", "=", "get_norm_act_layer", "(", "norm_layer", ",", "act_layer", ")", "\n", "# NOTE for backwards (weight) compatibility, norm layer name remains `.bn`", "\n", "norm_kwargs", "=", "dict", "(", "drop_layer", "=", "drop_layer", ")", "if", "drop_layer", "is", "not", "None", "else", "{", "}", "\n", "self", ".", "bn", "=", "norm_act_layer", "(", "out_channels", ",", "apply_act", "=", "apply_act", ",", "**", "norm_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.conv_bn_act.ConvNormAct.in_channels": [[26, 29], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "in_channels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "conv", ".", "in_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.conv_bn_act.ConvNormAct.out_channels": [[30, 33], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "out_channels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "conv", ".", "out_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.conv_bn_act.ConvNormAct.forward": [[34, 38], ["conv_bn_act.ConvNormAct.conv", "conv_bn_act.ConvNormAct.bn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.conv_bn_act.ConvNormActAa.__init__": [[44, 60], ["torch.nn.Module.__init__", "create_conv2d.create_conv2d.create_conv2d", "create_norm_act.get_norm_act_layer", "create_norm_act.get_norm_act_layer.", "dict", "aa_layer", "torch.nn.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "''", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "\n", "bias", "=", "False", ",", "apply_act", "=", "True", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "aa_layer", "=", "None", ",", "drop_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "ConvNormActAa", ",", "self", ")", ".", "__init__", "(", ")", "\n", "use_aa", "=", "aa_layer", "is", "not", "None", "\n", "\n", "self", ".", "conv", "=", "create_conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", "if", "use_aa", "else", "stride", ",", "\n", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "groups", "=", "groups", ",", "bias", "=", "bias", ")", "\n", "\n", "# NOTE for backwards compatibility with models that use separate norm and act layer definitions", "\n", "norm_act_layer", "=", "get_norm_act_layer", "(", "norm_layer", ",", "act_layer", ")", "\n", "# NOTE for backwards (weight) compatibility, norm layer name remains `.bn`", "\n", "norm_kwargs", "=", "dict", "(", "drop_layer", "=", "drop_layer", ")", "if", "drop_layer", "is", "not", "None", "else", "{", "}", "\n", "self", ".", "bn", "=", "norm_act_layer", "(", "out_channels", ",", "apply_act", "=", "apply_act", ",", "**", "norm_kwargs", ")", "\n", "self", ".", "aa", "=", "aa_layer", "(", "channels", "=", "out_channels", ")", "if", "stride", "==", "2", "and", "use_aa", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.conv_bn_act.ConvNormActAa.in_channels": [[61, 64], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "in_channels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "conv", ".", "in_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.conv_bn_act.ConvNormActAa.out_channels": [[65, 68], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "out_channels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "conv", ".", "out_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.conv_bn_act.ConvNormActAa.forward": [[69, 74], ["conv_bn_act.ConvNormActAa.conv", "conv_bn_act.ConvNormActAa.bn", "conv_bn_act.ConvNormActAa.aa"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "x", "=", "self", ".", "aa", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.ml_decoder.TransformerDecoderLayerOptimal.__init__": [[36, 55], ["torch.nn.Module.__init__", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.MultiheadAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.modules.transformer._get_activation_fn"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "nhead", "=", "8", ",", "dim_feedforward", "=", "2048", ",", "dropout", "=", "0.1", ",", "activation", "=", "\"relu\"", ",", "\n", "layer_norm_eps", "=", "1e-5", ")", "->", "None", ":", "\n", "        ", "super", "(", "TransformerDecoderLayerOptimal", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm1", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout1", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout2", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout3", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "multihead_attn", "=", "nn", ".", "MultiheadAttention", "(", "d_model", ",", "nhead", ",", "dropout", "=", "dropout", ")", "\n", "\n", "# Implementation of Feedforward model", "\n", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "d_model", ",", "dim_feedforward", ")", "\n", "self", ".", "linear2", "=", "nn", ".", "Linear", "(", "dim_feedforward", ",", "d_model", ")", "\n", "\n", "self", ".", "norm2", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "layer_norm_eps", ")", "\n", "self", ".", "norm3", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "layer_norm_eps", ")", "\n", "\n", "self", ".", "activation", "=", "_get_activation_fn", "(", "activation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.ml_decoder.TransformerDecoderLayerOptimal.__setstate__": [[56, 60], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.ml_decoder.TransformerDecoderLayerOptimal.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "'activation'", "not", "in", "state", ":", "\n", "            ", "state", "[", "'activation'", "]", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "\n", "", "super", "(", "TransformerDecoderLayerOptimal", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.ml_decoder.TransformerDecoderLayerOptimal.forward": [[61, 74], ["ml_decoder.TransformerDecoderLayerOptimal.norm1", "ml_decoder.TransformerDecoderLayerOptimal.norm2", "ml_decoder.TransformerDecoderLayerOptimal.linear2", "ml_decoder.TransformerDecoderLayerOptimal.norm3", "ml_decoder.TransformerDecoderLayerOptimal.dropout1", "ml_decoder.TransformerDecoderLayerOptimal.multihead_attn", "ml_decoder.TransformerDecoderLayerOptimal.dropout2", "ml_decoder.TransformerDecoderLayerOptimal.dropout", "ml_decoder.TransformerDecoderLayerOptimal.dropout3", "ml_decoder.TransformerDecoderLayerOptimal.activation", "ml_decoder.TransformerDecoderLayerOptimal.linear1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tgt", ":", "Tensor", ",", "memory", ":", "Tensor", ",", "tgt_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "memory_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "tgt_key_padding_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "memory_key_padding_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ")", "->", "Tensor", ":", "\n", "        ", "tgt", "=", "tgt", "+", "self", ".", "dropout1", "(", "tgt", ")", "\n", "tgt", "=", "self", ".", "norm1", "(", "tgt", ")", "\n", "tgt2", "=", "self", ".", "multihead_attn", "(", "tgt", ",", "memory", ",", "memory", ")", "[", "0", "]", "\n", "tgt", "=", "tgt", "+", "self", ".", "dropout2", "(", "tgt2", ")", "\n", "tgt", "=", "self", ".", "norm2", "(", "tgt", ")", "\n", "tgt2", "=", "self", ".", "linear2", "(", "self", ".", "dropout", "(", "self", ".", "activation", "(", "self", ".", "linear1", "(", "tgt", ")", ")", ")", ")", "\n", "tgt", "=", "tgt", "+", "self", ".", "dropout3", "(", "tgt2", ")", "\n", "tgt", "=", "self", ".", "norm3", "(", "tgt", ")", "\n", "return", "tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.ml_decoder.GroupFC.__init__": [[93, 95], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "embed_len_decoder", ":", "int", ")", ":", "\n", "        ", "self", ".", "embed_len_decoder", "=", "embed_len_decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.ml_decoder.GroupFC.__call__": [[96, 101], ["range", "torch.matmul"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "h", ":", "torch", ".", "Tensor", ",", "duplicate_pooling", ":", "torch", ".", "Tensor", ",", "out_extrap", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "embed_len_decoder", ")", ":", "\n", "            ", "h_i", "=", "h", "[", ":", ",", "i", ",", ":", "]", "\n", "w_i", "=", "duplicate_pooling", "[", "i", ",", ":", ",", ":", "]", "\n", "out_extrap", "[", ":", ",", "i", ",", ":", "]", "=", "torch", ".", "matmul", "(", "h_i", ",", "w_i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.ml_decoder.MLDecoder.__init__": [[104, 135], ["torch.nn.Module.__init__", "torch.nn.Linear", "ml_decoder.TransformerDecoderLayerOptimal", "torch.nn.TransformerDecoder", "torch.nn.Embedding", "ml_decoder.MLDecoder.query_embed.requires_grad_", "int", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.xavier_normal_", "torch.nn.init.constant_", "ml_decoder.GroupFC", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_classes", ",", "num_of_groups", "=", "-", "1", ",", "decoder_embedding", "=", "768", ",", "initial_num_features", "=", "2048", ")", ":", "\n", "        ", "super", "(", "MLDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "embed_len_decoder", "=", "100", "if", "num_of_groups", "<", "0", "else", "num_of_groups", "\n", "if", "embed_len_decoder", ">", "num_classes", ":", "\n", "            ", "embed_len_decoder", "=", "num_classes", "\n", "\n", "# switching to 768 initial embeddings", "\n", "", "decoder_embedding", "=", "768", "if", "decoder_embedding", "<", "0", "else", "decoder_embedding", "\n", "self", ".", "embed_standart", "=", "nn", ".", "Linear", "(", "initial_num_features", ",", "decoder_embedding", ")", "\n", "\n", "# decoder", "\n", "decoder_dropout", "=", "0.1", "\n", "num_layers_decoder", "=", "1", "\n", "dim_feedforward", "=", "2048", "\n", "layer_decode", "=", "TransformerDecoderLayerOptimal", "(", "d_model", "=", "decoder_embedding", ",", "\n", "dim_feedforward", "=", "dim_feedforward", ",", "dropout", "=", "decoder_dropout", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "TransformerDecoder", "(", "layer_decode", ",", "num_layers", "=", "num_layers_decoder", ")", "\n", "\n", "# non-learnable queries", "\n", "self", ".", "query_embed", "=", "nn", ".", "Embedding", "(", "embed_len_decoder", ",", "decoder_embedding", ")", "\n", "self", ".", "query_embed", ".", "requires_grad_", "(", "False", ")", "\n", "\n", "# group fully-connected", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "duplicate_factor", "=", "int", "(", "num_classes", "/", "embed_len_decoder", "+", "0.999", ")", "\n", "self", ".", "duplicate_pooling", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "embed_len_decoder", ",", "decoder_embedding", ",", "self", ".", "duplicate_factor", ")", ")", "\n", "self", ".", "duplicate_pooling_bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_classes", ")", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "duplicate_pooling", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "self", ".", "duplicate_pooling_bias", ",", "0", ")", "\n", "self", ".", "group_fc", "=", "GroupFC", "(", "embed_len_decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.ml_decoder.MLDecoder.forward": [[136, 157], ["ml_decoder.MLDecoder.embed_standart", "torch.nn.functional.relu", "query_embed.unsqueeze().expand", "ml_decoder.MLDecoder.decoder", "h.transpose.transpose.transpose", "torch.zeros", "ml_decoder.MLDecoder.group_fc", "len", "x.flatten().transpose", "torch.nn.functional.relu.transpose", "torch.zeros.flatten", "query_embed.unsqueeze", "x.flatten"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "len", "(", "x", ".", "shape", ")", "==", "4", ":", "# [bs,2048, 7,7]", "\n", "            ", "embedding_spatial", "=", "x", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "", "else", ":", "# [bs, 197,468]", "\n", "            ", "embedding_spatial", "=", "x", "\n", "", "embedding_spatial_786", "=", "self", ".", "embed_standart", "(", "embedding_spatial", ")", "\n", "embedding_spatial_786", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "embedding_spatial_786", ",", "inplace", "=", "True", ")", "\n", "\n", "bs", "=", "embedding_spatial_786", ".", "shape", "[", "0", "]", "\n", "query_embed", "=", "self", ".", "query_embed", ".", "weight", "\n", "# tgt = query_embed.unsqueeze(1).repeat(1, bs, 1)", "\n", "tgt", "=", "query_embed", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "bs", ",", "-", "1", ")", "# no allocation of memory with expand", "\n", "h", "=", "self", ".", "decoder", "(", "tgt", ",", "embedding_spatial_786", ".", "transpose", "(", "0", ",", "1", ")", ")", "# [embed_len_decoder, batch, 768]", "\n", "h", "=", "h", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "out_extrap", "=", "torch", ".", "zeros", "(", "h", ".", "shape", "[", "0", "]", ",", "h", ".", "shape", "[", "1", "]", ",", "self", ".", "duplicate_factor", ",", "device", "=", "h", ".", "device", ",", "dtype", "=", "h", ".", "dtype", ")", "\n", "self", ".", "group_fc", "(", "h", ",", "self", ".", "duplicate_pooling", ",", "out_extrap", ")", "\n", "h_out", "=", "out_extrap", ".", "flatten", "(", "1", ")", "[", ":", ",", ":", "self", ".", "num_classes", "]", "\n", "h_out", "+=", "self", ".", "duplicate_pooling_bias", "\n", "logits", "=", "h_out", "\n", "return", "logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.ml_decoder.add_ml_decoder_head": [[9, 33], ["hasattr", "hasattr", "hasattr", "torch.nn.Identity", "ml_decoder.MLDecoder", "hasattr", "hasattr", "torch.nn.Identity", "ml_decoder.MLDecoder", "ml_decoder.MLDecoder", "print", "exit", "model._get_name", "model._get_name"], "function", ["None"], ["def", "add_ml_decoder_head", "(", "model", ")", ":", "\n", "    ", "if", "hasattr", "(", "model", ",", "'global_pool'", ")", "and", "hasattr", "(", "model", ",", "'fc'", ")", ":", "# most CNN models, like Resnet50", "\n", "        ", "model", ".", "global_pool", "=", "nn", ".", "Identity", "(", ")", "\n", "del", "model", ".", "fc", "\n", "num_classes", "=", "model", ".", "num_classes", "\n", "num_features", "=", "model", ".", "num_features", "\n", "model", ".", "fc", "=", "MLDecoder", "(", "num_classes", "=", "num_classes", ",", "initial_num_features", "=", "num_features", ")", "\n", "", "elif", "hasattr", "(", "model", ",", "'global_pool'", ")", "and", "hasattr", "(", "model", ",", "'classifier'", ")", ":", "# EfficientNet", "\n", "        ", "model", ".", "global_pool", "=", "nn", ".", "Identity", "(", ")", "\n", "del", "model", ".", "classifier", "\n", "num_classes", "=", "model", ".", "num_classes", "\n", "num_features", "=", "model", ".", "num_features", "\n", "model", ".", "classifier", "=", "MLDecoder", "(", "num_classes", "=", "num_classes", ",", "initial_num_features", "=", "num_features", ")", "\n", "", "elif", "'RegNet'", "in", "model", ".", "_get_name", "(", ")", "or", "'TResNet'", "in", "model", ".", "_get_name", "(", ")", ":", "# hasattr(model, 'head')", "\n", "        ", "del", "model", ".", "head", "\n", "num_classes", "=", "model", ".", "num_classes", "\n", "num_features", "=", "model", ".", "num_features", "\n", "model", ".", "head", "=", "MLDecoder", "(", "num_classes", "=", "num_classes", ",", "initial_num_features", "=", "num_features", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Model code-writing is not aligned currently with ml-decoder\"", ")", "\n", "exit", "(", "-", "1", ")", "\n", "", "if", "hasattr", "(", "model", ",", "'drop_rate'", ")", ":", "# Ml-Decoder has inner dropout", "\n", "        ", "model", ".", "drop_rate", "=", "0", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.norm.GroupNorm.__init__": [[9, 12], ["torch.GroupNorm.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_channels", ",", "num_groups", "=", "32", ",", "eps", "=", "1e-5", ",", "affine", "=", "True", ")", ":", "\n", "# NOTE num_channels is swapped to first arg for consistency in swapping norm layers with BN", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_groups", ",", "num_channels", ",", "eps", "=", "eps", ",", "affine", "=", "affine", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.norm.GroupNorm.forward": [[13, 15], ["torch.group_norm", "torch.group_norm", "torch.group_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "F", ".", "group_norm", "(", "x", ",", "self", ".", "num_groups", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.norm.LayerNorm2d.__init__": [[19, 21], ["torch.LayerNorm.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "num_channels", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.norm.LayerNorm2d.forward": [[22, 25], ["torch.layer_norm().permute", "torch.layer_norm().permute", "torch.layer_norm().permute", "torch.layer_norm", "torch.layer_norm", "torch.layer_norm", "x.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "return", "F", ".", "layer_norm", "(", "\n", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ",", "self", ".", "normalized_shape", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "eps", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mixed_conv2d.MixedConv2d.__init__": [[26, 46], ["torch.nn.ModuleDict.__init__", "len", "mixed_conv2d._split_channels", "mixed_conv2d._split_channels", "sum", "sum", "enumerate", "isinstance", "zip", "mixed_conv2d.MixedConv2d.add_module", "str", "conv2d_same.create_conv2d_pad"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mixed_conv2d._split_channels", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mixed_conv2d._split_channels", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.conv2d_same.create_conv2d_pad"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "padding", "=", "''", ",", "dilation", "=", "1", ",", "depthwise", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MixedConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "kernel_size", "=", "kernel_size", "if", "isinstance", "(", "kernel_size", ",", "list", ")", "else", "[", "kernel_size", "]", "\n", "num_groups", "=", "len", "(", "kernel_size", ")", "\n", "in_splits", "=", "_split_channels", "(", "in_channels", ",", "num_groups", ")", "\n", "out_splits", "=", "_split_channels", "(", "out_channels", ",", "num_groups", ")", "\n", "self", ".", "in_channels", "=", "sum", "(", "in_splits", ")", "\n", "self", ".", "out_channels", "=", "sum", "(", "out_splits", ")", "\n", "for", "idx", ",", "(", "k", ",", "in_ch", ",", "out_ch", ")", "in", "enumerate", "(", "zip", "(", "kernel_size", ",", "in_splits", ",", "out_splits", ")", ")", ":", "\n", "            ", "conv_groups", "=", "in_ch", "if", "depthwise", "else", "1", "\n", "# use add_module to keep key space clean", "\n", "self", ".", "add_module", "(", "\n", "str", "(", "idx", ")", ",", "\n", "create_conv2d_pad", "(", "\n", "in_ch", ",", "out_ch", ",", "k", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "groups", "=", "conv_groups", ",", "**", "kwargs", ")", "\n", ")", "\n", "", "self", ".", "splits", "=", "in_splits", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mixed_conv2d.MixedConv2d.forward": [[47, 52], ["torch.split", "torch.cat", "c", "enumerate", "mixed_conv2d.MixedConv2d.values"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_split", "=", "torch", ".", "split", "(", "x", ",", "self", ".", "splits", ",", "1", ")", "\n", "x_out", "=", "[", "c", "(", "x_split", "[", "i", "]", ")", "for", "i", ",", "c", "in", "enumerate", "(", "self", ".", "values", "(", ")", ")", "]", "\n", "x", "=", "torch", ".", "cat", "(", "x_out", ",", "1", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mixed_conv2d._split_channels": [[14, 18], ["sum", "range"], "function", ["None"], ["def", "_split_channels", "(", "num_chan", ",", "num_groups", ")", ":", "\n", "    ", "split", "=", "[", "num_chan", "//", "num_groups", "for", "_", "in", "range", "(", "num_groups", ")", "]", "\n", "split", "[", "0", "]", "+=", "num_chan", "-", "sum", "(", "split", ")", "\n", "return", "split", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_fn": [[105, 123], ["isinstance", "config.is_no_jit", "config.is_exportable", "config.is_scriptable", "config.is_no_jit", "config.is_exportable"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.is_no_jit", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.is_exportable", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.is_scriptable", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.is_no_jit", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.is_exportable"], ["", "def", "get_act_fn", "(", "name", ":", "Union", "[", "Callable", ",", "str", "]", "=", "'relu'", ")", ":", "\n", "    ", "\"\"\" Activation Function Factory\n    Fetching activation fns by name with this function allows export or torch script friendly\n    functions to be returned dynamically based on current config.\n    \"\"\"", "\n", "if", "not", "name", ":", "\n", "        ", "return", "None", "\n", "", "if", "isinstance", "(", "name", ",", "Callable", ")", ":", "\n", "        ", "return", "name", "\n", "", "if", "not", "(", "is_no_jit", "(", ")", "or", "is_exportable", "(", ")", "or", "is_scriptable", "(", ")", ")", ":", "\n", "# If not exporting or scripting the model, first look for a memory-efficient version with", "\n", "# custom autograd, then fallback", "\n", "        ", "if", "name", "in", "_ACT_FN_ME", ":", "\n", "            ", "return", "_ACT_FN_ME", "[", "name", "]", "\n", "", "", "if", "not", "(", "is_no_jit", "(", ")", "or", "is_exportable", "(", ")", ")", ":", "\n", "        ", "if", "name", "in", "_ACT_FN_JIT", ":", "\n", "            ", "return", "_ACT_FN_JIT", "[", "name", "]", "\n", "", "", "return", "_ACT_FN_DEFAULT", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer": [[125, 142], ["isinstance", "config.is_no_jit", "config.is_exportable", "config.is_scriptable", "config.is_no_jit", "config.is_exportable"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.is_no_jit", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.is_exportable", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.is_scriptable", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.is_no_jit", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.config.is_exportable"], ["", "def", "get_act_layer", "(", "name", ":", "Union", "[", "Type", "[", "nn", ".", "Module", "]", ",", "str", "]", "=", "'relu'", ")", ":", "\n", "    ", "\"\"\" Activation Layer Factory\n    Fetching activation layers by name with this function allows export or torch script friendly\n    functions to be returned dynamically based on current config.\n    \"\"\"", "\n", "if", "not", "name", ":", "\n", "        ", "return", "None", "\n", "", "if", "not", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "# callable, module, etc", "\n", "        ", "return", "name", "\n", "", "if", "not", "(", "is_no_jit", "(", ")", "or", "is_exportable", "(", ")", "or", "is_scriptable", "(", ")", ")", ":", "\n", "        ", "if", "name", "in", "_ACT_LAYER_ME", ":", "\n", "            ", "return", "_ACT_LAYER_ME", "[", "name", "]", "\n", "", "", "if", "not", "(", "is_no_jit", "(", ")", "or", "is_exportable", "(", ")", ")", ":", "\n", "        ", "if", "name", "in", "_ACT_LAYER_JIT", ":", "\n", "            ", "return", "_ACT_LAYER_JIT", "[", "name", "]", "\n", "", "", "return", "_ACT_LAYER_DEFAULT", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer": [[144, 149], ["create_act.get_act_layer", "get_act_layer.", "get_act_layer."], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer"], ["", "def", "create_act_layer", "(", "name", ":", "Union", "[", "nn", ".", "Module", ",", "str", "]", ",", "inplace", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "act_layer", "=", "get_act_layer", "(", "name", ")", "\n", "if", "act_layer", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "return", "act_layer", "(", "**", "kwargs", ")", "if", "inplace", "is", "None", "else", "act_layer", "(", "inplace", "=", "inplace", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.DropBlock2d.__init__": [[108, 125], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "drop_prob", ":", "float", "=", "0.1", ",", "\n", "block_size", ":", "int", "=", "7", ",", "\n", "gamma_scale", ":", "float", "=", "1.0", ",", "\n", "with_noise", ":", "bool", "=", "False", ",", "\n", "inplace", ":", "bool", "=", "False", ",", "\n", "batchwise", ":", "bool", "=", "False", ",", "\n", "fast", ":", "bool", "=", "True", ")", ":", "\n", "        ", "super", "(", "DropBlock2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "drop_prob", "=", "drop_prob", "\n", "self", ".", "gamma_scale", "=", "gamma_scale", "\n", "self", ".", "block_size", "=", "block_size", "\n", "self", ".", "with_noise", "=", "with_noise", "\n", "self", ".", "inplace", "=", "inplace", "\n", "self", ".", "batchwise", "=", "batchwise", "\n", "self", ".", "fast", "=", "fast", "# FIXME finish comparisons of fast vs not", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.DropBlock2d.forward": [[126, 135], ["drop.drop_block_fast_2d", "drop.drop_block_2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_block_fast_2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_block_2d"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "not", "self", ".", "training", "or", "not", "self", ".", "drop_prob", ":", "\n", "            ", "return", "x", "\n", "", "if", "self", ".", "fast", ":", "\n", "            ", "return", "drop_block_fast_2d", "(", "\n", "x", ",", "self", ".", "drop_prob", ",", "self", ".", "block_size", ",", "self", ".", "gamma_scale", ",", "self", ".", "with_noise", ",", "self", ".", "inplace", ")", "\n", "", "else", ":", "\n", "            ", "return", "drop_block_2d", "(", "\n", "x", ",", "self", ".", "drop_prob", ",", "self", ".", "block_size", ",", "self", ".", "gamma_scale", ",", "self", ".", "with_noise", ",", "self", ".", "inplace", ",", "self", ".", "batchwise", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.DropPath.__init__": [[160, 164], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "drop_prob", ":", "float", "=", "0.", ",", "scale_by_keep", ":", "bool", "=", "True", ")", ":", "\n", "        ", "super", "(", "DropPath", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "drop_prob", "=", "drop_prob", "\n", "self", ".", "scale_by_keep", "=", "scale_by_keep", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.DropPath.forward": [[165, 167], ["drop.drop_path"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "drop_path", "(", "x", ",", "self", ".", "drop_prob", ",", "self", ".", "training", ",", "self", ".", "scale_by_keep", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_block_2d": [[22, 68], ["min", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "min", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.rand", "torch.rand", "torch.rand", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.max_pool2d", "torch.reshape", "torch.reshape", "torch.reshape", "torch.randn", "torch.randn", "torch.randn", "torch.randn_like", "torch.randn_like", "torch.randn_like", "x.mul_().add_", "x.mul_", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "x.mul_", "block_mask.numel", "block_mask.to().sum().add", "block_mask.to().sum", "block_mask.to"], "function", ["None"], ["def", "drop_block_2d", "(", "\n", "x", ",", "drop_prob", ":", "float", "=", "0.1", ",", "block_size", ":", "int", "=", "7", ",", "gamma_scale", ":", "float", "=", "1.0", ",", "\n", "with_noise", ":", "bool", "=", "False", ",", "inplace", ":", "bool", "=", "False", ",", "batchwise", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\" DropBlock. See https://arxiv.org/pdf/1810.12890.pdf\n\n    DropBlock with an experimental gaussian noise option. This layer has been tested on a few training\n    runs with success, but needs further validation and possibly optimization for lower runtime impact.\n    \"\"\"", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "total_size", "=", "W", "*", "H", "\n", "clipped_block_size", "=", "min", "(", "block_size", ",", "min", "(", "W", ",", "H", ")", ")", "\n", "# seed_drop_rate, the gamma parameter", "\n", "gamma", "=", "gamma_scale", "*", "drop_prob", "*", "total_size", "/", "clipped_block_size", "**", "2", "/", "(", "\n", "(", "W", "-", "block_size", "+", "1", ")", "*", "(", "H", "-", "block_size", "+", "1", ")", ")", "\n", "\n", "# Forces the block to be inside the feature map.", "\n", "w_i", ",", "h_i", "=", "torch", ".", "meshgrid", "(", "torch", ".", "arange", "(", "W", ")", ".", "to", "(", "x", ".", "device", ")", ",", "torch", ".", "arange", "(", "H", ")", ".", "to", "(", "x", ".", "device", ")", ")", "\n", "valid_block", "=", "(", "(", "w_i", ">=", "clipped_block_size", "//", "2", ")", "&", "(", "w_i", "<", "W", "-", "(", "clipped_block_size", "-", "1", ")", "//", "2", ")", ")", "&", "(", "(", "h_i", ">=", "clipped_block_size", "//", "2", ")", "&", "(", "h_i", "<", "H", "-", "(", "clipped_block_size", "-", "1", ")", "//", "2", ")", ")", "\n", "valid_block", "=", "torch", ".", "reshape", "(", "valid_block", ",", "(", "1", ",", "1", ",", "H", ",", "W", ")", ")", ".", "to", "(", "dtype", "=", "x", ".", "dtype", ")", "\n", "\n", "if", "batchwise", ":", "\n", "# one mask for whole batch, quite a bit faster", "\n", "        ", "uniform_noise", "=", "torch", ".", "rand", "(", "(", "1", ",", "C", ",", "H", ",", "W", ")", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", "\n", "", "else", ":", "\n", "        ", "uniform_noise", "=", "torch", ".", "rand_like", "(", "x", ")", "\n", "", "block_mask", "=", "(", "(", "2", "-", "gamma", "-", "valid_block", "+", "uniform_noise", ")", ">=", "1", ")", ".", "to", "(", "dtype", "=", "x", ".", "dtype", ")", "\n", "block_mask", "=", "-", "F", ".", "max_pool2d", "(", "\n", "-", "block_mask", ",", "\n", "kernel_size", "=", "clipped_block_size", ",", "# block_size,", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "clipped_block_size", "//", "2", ")", "\n", "\n", "if", "with_noise", ":", "\n", "        ", "normal_noise", "=", "torch", ".", "randn", "(", "(", "1", ",", "C", ",", "H", ",", "W", ")", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", "if", "batchwise", "else", "torch", ".", "randn_like", "(", "x", ")", "\n", "if", "inplace", ":", "\n", "            ", "x", ".", "mul_", "(", "block_mask", ")", ".", "add_", "(", "normal_noise", "*", "(", "1", "-", "block_mask", ")", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", "*", "block_mask", "+", "normal_noise", "*", "(", "1", "-", "block_mask", ")", "\n", "", "", "else", ":", "\n", "        ", "normalize_scale", "=", "(", "block_mask", ".", "numel", "(", ")", "/", "block_mask", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", ".", "sum", "(", ")", ".", "add", "(", "1e-7", ")", ")", ".", "to", "(", "x", ".", "dtype", ")", "\n", "if", "inplace", ":", "\n", "            ", "x", ".", "mul_", "(", "block_mask", "*", "normalize_scale", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", "*", "block_mask", "*", "normalize_scale", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_block_fast_2d": [[70, 102], ["min", "torch.empty_like().bernoulli_", "torch.empty_like().bernoulli_", "torch.empty_like().bernoulli_", "torch.max_pool2d", "min", "F.max_pool2d.to", "torch.empty_like().normal_", "torch.empty_like().normal_", "torch.empty_like().normal_", "torch.empty_like", "torch.empty_like", "torch.empty_like", "x.mul_().add_", "x.mul_", "torch.empty_like", "torch.empty_like", "torch.empty_like", "x.mul_", "F.max_pool2d.numel", "F.max_pool2d.to().sum().add", "F.max_pool2d.to().sum", "F.max_pool2d.to"], "function", ["None"], ["", "def", "drop_block_fast_2d", "(", "\n", "x", ":", "torch", ".", "Tensor", ",", "drop_prob", ":", "float", "=", "0.1", ",", "block_size", ":", "int", "=", "7", ",", "\n", "gamma_scale", ":", "float", "=", "1.0", ",", "with_noise", ":", "bool", "=", "False", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\" DropBlock. See https://arxiv.org/pdf/1810.12890.pdf\n\n    DropBlock with an experimental gaussian noise option. Simplied from above without concern for valid\n    block mask at edges.\n    \"\"\"", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "total_size", "=", "W", "*", "H", "\n", "clipped_block_size", "=", "min", "(", "block_size", ",", "min", "(", "W", ",", "H", ")", ")", "\n", "gamma", "=", "gamma_scale", "*", "drop_prob", "*", "total_size", "/", "clipped_block_size", "**", "2", "/", "(", "\n", "(", "W", "-", "block_size", "+", "1", ")", "*", "(", "H", "-", "block_size", "+", "1", ")", ")", "\n", "\n", "block_mask", "=", "torch", ".", "empty_like", "(", "x", ")", ".", "bernoulli_", "(", "gamma", ")", "\n", "block_mask", "=", "F", ".", "max_pool2d", "(", "\n", "block_mask", ".", "to", "(", "x", ".", "dtype", ")", ",", "kernel_size", "=", "clipped_block_size", ",", "stride", "=", "1", ",", "padding", "=", "clipped_block_size", "//", "2", ")", "\n", "\n", "if", "with_noise", ":", "\n", "        ", "normal_noise", "=", "torch", ".", "empty_like", "(", "x", ")", ".", "normal_", "(", ")", "\n", "if", "inplace", ":", "\n", "            ", "x", ".", "mul_", "(", "1.", "-", "block_mask", ")", ".", "add_", "(", "normal_noise", "*", "block_mask", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", "*", "(", "1.", "-", "block_mask", ")", "+", "normal_noise", "*", "block_mask", "\n", "", "", "else", ":", "\n", "        ", "block_mask", "=", "1", "-", "block_mask", "\n", "normalize_scale", "=", "(", "block_mask", ".", "numel", "(", ")", "/", "block_mask", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", ".", "sum", "(", ")", ".", "add", "(", "1e-6", ")", ")", ".", "to", "(", "dtype", "=", "x", ".", "dtype", ")", "\n", "if", "inplace", ":", "\n", "            ", "x", ".", "mul_", "(", "block_mask", "*", "normalize_scale", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", "*", "block_mask", "*", "normalize_scale", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.drop.drop_path": [[137, 155], ["x.new_empty().bernoulli_", "x.new_empty().bernoulli_.div_", "x.new_empty"], "function", ["None"], ["", "", "", "def", "drop_path", "(", "x", ",", "drop_prob", ":", "float", "=", "0.", ",", "training", ":", "bool", "=", "False", ",", "scale_by_keep", ":", "bool", "=", "True", ")", ":", "\n", "    ", "\"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n\n    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n    'survival rate' as the argument.\n\n    \"\"\"", "\n", "if", "drop_prob", "==", "0.", "or", "not", "training", ":", "\n", "        ", "return", "x", "\n", "", "keep_prob", "=", "1", "-", "drop_prob", "\n", "shape", "=", "(", "x", ".", "shape", "[", "0", "]", ",", ")", "+", "(", "1", ",", ")", "*", "(", "x", ".", "ndim", "-", "1", ")", "# work with diff dim tensors, not just 2D ConvNets", "\n", "random_tensor", "=", "x", ".", "new_empty", "(", "shape", ")", ".", "bernoulli_", "(", "keep_prob", ")", "\n", "if", "keep_prob", ">", "0.0", "and", "scale_by_keep", ":", "\n", "        ", "random_tensor", ".", "div_", "(", "keep_prob", ")", "\n", "", "return", "x", "*", "random_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.SwishJitAutoFn.symbolic": [[33, 36], ["g.op", "g.op"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "symbolic", "(", "g", ",", "x", ")", ":", "\n", "        ", "return", "g", ".", "op", "(", "\"Mul\"", ",", "x", ",", "g", ".", "op", "(", "\"Sigmoid\"", ",", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.SwishJitAutoFn.forward": [[37, 41], ["ctx.save_for_backward", "activations_me.swish_jit_fwd"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.swish_jit_fwd"], ["", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ")", ":", "\n", "        ", "ctx", ".", "save_for_backward", "(", "x", ")", "\n", "return", "swish_jit_fwd", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.SwishJitAutoFn.backward": [[42, 46], ["activations_me.swish_jit_bwd"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.swish_jit_bwd"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "x", "=", "ctx", ".", "saved_tensors", "[", "0", "]", "\n", "return", "swish_jit_bwd", "(", "x", ",", "grad_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.SwishMe.__init__": [[53, 55], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "SwishMe", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.SwishMe.forward": [[56, 58], ["SwishJitAutoFn.apply"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "SwishJitAutoFn", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.MishJitAutoFn.forward": [[76, 80], ["ctx.save_for_backward", "activations_me.mish_jit_fwd"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.mish_jit_fwd"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ")", ":", "\n", "        ", "ctx", ".", "save_for_backward", "(", "x", ")", "\n", "return", "mish_jit_fwd", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.MishJitAutoFn.backward": [[81, 85], ["activations_me.mish_jit_bwd"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.mish_jit_bwd"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "x", "=", "ctx", ".", "saved_tensors", "[", "0", "]", "\n", "return", "mish_jit_bwd", "(", "x", ",", "grad_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.MishMe.__init__": [[92, 94], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "MishMe", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.MishMe.forward": [[95, 97], ["MishJitAutoFn.apply"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "MishJitAutoFn", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.HardSigmoidJitAutoFn.forward": [[111, 115], ["ctx.save_for_backward", "activations_me.hard_sigmoid_jit_fwd"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.hard_sigmoid_jit_fwd"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ")", ":", "\n", "        ", "ctx", ".", "save_for_backward", "(", "x", ")", "\n", "return", "hard_sigmoid_jit_fwd", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.HardSigmoidJitAutoFn.backward": [[116, 120], ["activations_me.hard_sigmoid_jit_bwd"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.hard_sigmoid_jit_bwd"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "x", "=", "ctx", ".", "saved_tensors", "[", "0", "]", "\n", "return", "hard_sigmoid_jit_bwd", "(", "x", ",", "grad_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.HardSigmoidMe.__init__": [[127, 129], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "HardSigmoidMe", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.HardSigmoidMe.forward": [[130, 132], ["HardSigmoidJitAutoFn.apply"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "HardSigmoidJitAutoFn", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.HardSwishJitAutoFn.forward": [[148, 152], ["ctx.save_for_backward", "activations_me.hard_swish_jit_fwd"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.hard_swish_jit_fwd"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ")", ":", "\n", "        ", "ctx", ".", "save_for_backward", "(", "x", ")", "\n", "return", "hard_swish_jit_fwd", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.HardSwishJitAutoFn.backward": [[153, 157], ["activations_me.hard_swish_jit_bwd"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.hard_swish_jit_bwd"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "x", "=", "ctx", ".", "saved_tensors", "[", "0", "]", "\n", "return", "hard_swish_jit_bwd", "(", "x", ",", "grad_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.HardSwishJitAutoFn.symbolic": [[158, 164], ["g.op", "g.op", "g.op", "g.op", "g.op", "g.op", "g.op", "g.op", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "symbolic", "(", "g", ",", "self", ")", ":", "\n", "        ", "input", "=", "g", ".", "op", "(", "\"Add\"", ",", "self", ",", "g", ".", "op", "(", "'Constant'", ",", "value_t", "=", "torch", ".", "tensor", "(", "3", ",", "dtype", "=", "torch", ".", "float", ")", ")", ")", "\n", "hardtanh_", "=", "g", ".", "op", "(", "\"Clip\"", ",", "input", ",", "g", ".", "op", "(", "'Constant'", ",", "value_t", "=", "torch", ".", "tensor", "(", "0", ",", "dtype", "=", "torch", ".", "float", ")", ")", ",", "g", ".", "op", "(", "'Constant'", ",", "value_t", "=", "torch", ".", "tensor", "(", "6", ",", "dtype", "=", "torch", ".", "float", ")", ")", ")", "\n", "hardtanh_", "=", "g", ".", "op", "(", "\"Div\"", ",", "hardtanh_", ",", "g", ".", "op", "(", "'Constant'", ",", "value_t", "=", "torch", ".", "tensor", "(", "6", ",", "dtype", "=", "torch", ".", "float", ")", ")", ")", "\n", "return", "g", ".", "op", "(", "\"Mul\"", ",", "self", ",", "hardtanh_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.HardSwishMe.__init__": [[171, 173], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "HardSwishMe", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.HardSwishMe.forward": [[174, 176], ["HardSwishJitAutoFn.apply"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "HardSwishJitAutoFn", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.HardMishJitAutoFn.forward": [[195, 199], ["ctx.save_for_backward", "activations_me.hard_mish_jit_fwd"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.hard_mish_jit_fwd"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ")", ":", "\n", "        ", "ctx", ".", "save_for_backward", "(", "x", ")", "\n", "return", "hard_mish_jit_fwd", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.HardMishJitAutoFn.backward": [[200, 204], ["activations_me.hard_mish_jit_bwd"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.hard_mish_jit_bwd"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "x", "=", "ctx", ".", "saved_tensors", "[", "0", "]", "\n", "return", "hard_mish_jit_bwd", "(", "x", ",", "grad_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.HardMishMe.__init__": [[211, 213], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "HardMishMe", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.HardMishMe.forward": [[214, 216], ["HardMishJitAutoFn.apply"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "HardMishJitAutoFn", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.swish_jit_fwd": [[17, 20], ["x.mul", "torch.sigmoid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid"], ["@", "torch", ".", "jit", ".", "script", "\n", "def", "swish_jit_fwd", "(", "x", ")", ":", "\n", "    ", "return", "x", ".", "mul", "(", "torch", ".", "sigmoid", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.swish_jit_bwd": [[22, 26], ["torch.sigmoid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "swish_jit_bwd", "(", "x", ",", "grad_output", ")", ":", "\n", "    ", "x_sigmoid", "=", "torch", ".", "sigmoid", "(", "x", ")", "\n", "return", "grad_output", "*", "(", "x_sigmoid", "*", "(", "1", "+", "x", "*", "(", "1", "-", "x_sigmoid", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.swish_me": [[48, 50], ["SwishJitAutoFn.apply"], "function", ["None"], ["", "", "def", "swish_me", "(", "x", ",", "inplace", "=", "False", ")", ":", "\n", "    ", "return", "SwishJitAutoFn", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.mish_jit_fwd": [[60, 63], ["x.mul", "torch.tanh", "torch.nn.functional.softplus"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.tanh"], ["", "", "@", "torch", ".", "jit", ".", "script", "\n", "def", "mish_jit_fwd", "(", "x", ")", ":", "\n", "    ", "return", "x", ".", "mul", "(", "torch", ".", "tanh", "(", "F", ".", "softplus", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.mish_jit_bwd": [[65, 70], ["torch.sigmoid", "torch.nn.functional.softplus().tanh", "grad_output.mul", "torch.nn.functional.softplus"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.tanh"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "mish_jit_bwd", "(", "x", ",", "grad_output", ")", ":", "\n", "    ", "x_sigmoid", "=", "torch", ".", "sigmoid", "(", "x", ")", "\n", "x_tanh_sp", "=", "F", ".", "softplus", "(", "x", ")", ".", "tanh", "(", ")", "\n", "return", "grad_output", ".", "mul", "(", "x_tanh_sp", "+", "x", "*", "x_sigmoid", "*", "(", "1", "-", "x_tanh_sp", "*", "x_tanh_sp", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.mish_me": [[87, 89], ["MishJitAutoFn.apply"], "function", ["None"], ["", "", "def", "mish_me", "(", "x", ",", "inplace", "=", "False", ")", ":", "\n", "    ", "return", "MishJitAutoFn", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.hard_sigmoid_jit_fwd": [[99, 102], ["None"], "function", ["None"], ["", "", "@", "torch", ".", "jit", ".", "script", "\n", "def", "hard_sigmoid_jit_fwd", "(", "x", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "return", "(", "x", "+", "3", ")", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "6", ")", ".", "div", "(", "6.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.hard_sigmoid_jit_bwd": [[104, 108], ["torch.ones_like"], "function", ["None"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "hard_sigmoid_jit_bwd", "(", "x", ",", "grad_output", ")", ":", "\n", "    ", "m", "=", "torch", ".", "ones_like", "(", "x", ")", "*", "(", "(", "x", ">=", "-", "3.", ")", "&", "(", "x", "<=", "3.", ")", ")", "/", "6.", "\n", "return", "grad_output", "*", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.hard_sigmoid_me": [[122, 124], ["HardSigmoidJitAutoFn.apply"], "function", ["None"], ["", "", "def", "hard_sigmoid_me", "(", "x", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "return", "HardSigmoidJitAutoFn", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.hard_swish_jit_fwd": [[134, 137], ["None"], "function", ["None"], ["", "", "@", "torch", ".", "jit", ".", "script", "\n", "def", "hard_swish_jit_fwd", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "(", "x", "+", "3", ")", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "6", ")", ".", "div", "(", "6.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.hard_swish_jit_bwd": [[139, 144], ["torch.where", "torch.ones_like"], "function", ["None"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "hard_swish_jit_bwd", "(", "x", ",", "grad_output", ")", ":", "\n", "    ", "m", "=", "torch", ".", "ones_like", "(", "x", ")", "*", "(", "x", ">=", "3.", ")", "\n", "m", "=", "torch", ".", "where", "(", "(", "x", ">=", "-", "3.", ")", "&", "(", "x", "<=", "3.", ")", ",", "x", "/", "3.", "+", ".5", ",", "m", ")", "\n", "return", "grad_output", "*", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.hard_swish_me": [[166, 168], ["HardSwishJitAutoFn.apply"], "function", ["None"], ["", "", "def", "hard_swish_me", "(", "x", ",", "inplace", "=", "False", ")", ":", "\n", "    ", "return", "HardSwishJitAutoFn", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.hard_mish_jit_fwd": [[178, 181], ["None"], "function", ["None"], ["", "", "@", "torch", ".", "jit", ".", "script", "\n", "def", "hard_mish_jit_fwd", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "x", "+", "2", ")", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.hard_mish_jit_bwd": [[183, 188], ["torch.where", "torch.ones_like"], "function", ["None"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "hard_mish_jit_bwd", "(", "x", ",", "grad_output", ")", ":", "\n", "    ", "m", "=", "torch", ".", "ones_like", "(", "x", ")", "*", "(", "x", ">=", "-", "2.", ")", "\n", "m", "=", "torch", ".", "where", "(", "(", "x", ">=", "-", "2.", ")", "&", "(", "x", "<=", "0.", ")", ",", "x", "+", "1.", ",", "m", ")", "\n", "return", "grad_output", "*", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations_me.hard_mish_me": [[206, 208], ["HardMishJitAutoFn.apply"], "function", ["None"], ["", "", "def", "hard_mish_me", "(", "x", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "return", "HardMishJitAutoFn", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.filter_response_norm.FilterResponseNormTlu2d.__init__": [[20, 29], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "filter_response_norm.FilterResponseNormTlu2d.reset_parameters", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "apply_act", "=", "True", ",", "eps", "=", "1e-5", ",", "rms", "=", "True", ",", "**", "_", ")", ":", "\n", "        ", "super", "(", "FilterResponseNormTlu2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "apply_act", "=", "apply_act", "# apply activation (non-linearity)", "\n", "self", ".", "rms", "=", "rms", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_features", ")", ")", "\n", "self", ".", "tau", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_features", ")", ")", "if", "apply_act", "else", "None", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.filter_response_norm.FilterResponseNormTlu2d.reset_parameters": [[30, 35], ["torch.init.ones_", "torch.init.ones_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "ones_", "(", "self", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "bias", ")", "\n", "if", "self", ".", "tau", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "tau", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.filter_response_norm.FilterResponseNormTlu2d.forward": [[36, 43], ["trace_utils._assert", "filter_response_norm.inv_instance_rms", "filter_response_norm.FilterResponseNormTlu2d.bias.view().to", "torch.maximum", "torch.maximum", "torch.maximum", "torch.maximum", "x.dim", "filter_response_norm.FilterResponseNormTlu2d.weight.view().to", "filter_response_norm.FilterResponseNormTlu2d.tau.reshape().to", "filter_response_norm.FilterResponseNormTlu2d.bias.view", "filter_response_norm.FilterResponseNormTlu2d.weight.view", "filter_response_norm.FilterResponseNormTlu2d.tau.reshape"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.filter_response_norm.inv_instance_rms"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_assert", "(", "x", ".", "dim", "(", ")", "==", "4", ",", "'expected 4D input'", ")", "\n", "x_dtype", "=", "x", ".", "dtype", "\n", "v_shape", "=", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "x", "=", "x", "*", "inv_instance_rms", "(", "x", ",", "self", ".", "eps", ")", "\n", "x", "=", "x", "*", "self", ".", "weight", ".", "view", "(", "v_shape", ")", ".", "to", "(", "dtype", "=", "x_dtype", ")", "+", "self", ".", "bias", ".", "view", "(", "v_shape", ")", ".", "to", "(", "dtype", "=", "x_dtype", ")", "\n", "return", "torch", ".", "maximum", "(", "x", ",", "self", ".", "tau", ".", "reshape", "(", "v_shape", ")", ".", "to", "(", "dtype", "=", "x_dtype", ")", ")", "if", "self", ".", "tau", "is", "not", "None", "else", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.filter_response_norm.FilterResponseNormAct2d.__init__": [[46, 57], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "filter_response_norm.FilterResponseNormAct2d.reset_parameters", "create_act.create_act_layer", "torch.Identity", "torch.Identity", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "apply_act", "=", "True", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "inplace", "=", "None", ",", "rms", "=", "True", ",", "eps", "=", "1e-5", ",", "**", "_", ")", ":", "\n", "        ", "super", "(", "FilterResponseNormAct2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "act_layer", "is", "not", "None", "and", "apply_act", ":", "\n", "            ", "self", ".", "act", "=", "create_act_layer", "(", "act_layer", ",", "inplace", "=", "inplace", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "act", "=", "nn", ".", "Identity", "(", ")", "\n", "", "self", ".", "rms", "=", "rms", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_features", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.filter_response_norm.FilterResponseNormAct2d.reset_parameters": [[58, 61], ["torch.init.ones_", "torch.init.ones_", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "ones_", "(", "self", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.filter_response_norm.FilterResponseNormAct2d.forward": [[62, 69], ["trace_utils._assert", "filter_response_norm.FilterResponseNormAct2d.act", "filter_response_norm.inv_instance_rms", "filter_response_norm.FilterResponseNormAct2d.bias.view().to", "x.dim", "filter_response_norm.FilterResponseNormAct2d.weight.view().to", "filter_response_norm.FilterResponseNormAct2d.bias.view", "filter_response_norm.FilterResponseNormAct2d.weight.view"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.filter_response_norm.inv_instance_rms"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_assert", "(", "x", ".", "dim", "(", ")", "==", "4", ",", "'expected 4D input'", ")", "\n", "x_dtype", "=", "x", ".", "dtype", "\n", "v_shape", "=", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "x", "=", "x", "*", "inv_instance_rms", "(", "x", ",", "self", ".", "eps", ")", "\n", "x", "=", "x", "*", "self", ".", "weight", ".", "view", "(", "v_shape", ")", ".", "to", "(", "dtype", "=", "x_dtype", ")", "+", "self", ".", "bias", ".", "view", "(", "v_shape", ")", ".", "to", "(", "dtype", "=", "x_dtype", ")", "\n", "return", "self", ".", "act", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.filter_response_norm.inv_instance_rms": [[14, 17], ["x.square().float().mean().add().rsqrt().to", "x.square().float().mean().add().rsqrt().to.expand", "x.square().float().mean().add().rsqrt", "x.square().float().mean().add", "x.square().float().mean", "x.square().float", "x.square"], "function", ["None"], ["def", "inv_instance_rms", "(", "x", ",", "eps", ":", "float", "=", "1e-5", ")", ":", "\n", "    ", "rms", "=", "x", ".", "square", "(", ")", ".", "float", "(", ")", ".", "mean", "(", "dim", "=", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", ".", "add", "(", "eps", ")", ".", "rsqrt", "(", ")", ".", "to", "(", "x", ".", "dtype", ")", "\n", "return", "rms", ".", "expand", "(", "x", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.AvgPool2dSame.__init__": [[24, 28], ["helpers.to_2tuple", "helpers.to_2tuple", "torch.AvgPool2d.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "kernel_size", ":", "int", ",", "stride", "=", "None", ",", "padding", "=", "0", ",", "ceil_mode", "=", "False", ",", "count_include_pad", "=", "True", ")", ":", "\n", "        ", "kernel_size", "=", "to_2tuple", "(", "kernel_size", ")", "\n", "stride", "=", "to_2tuple", "(", "stride", ")", "\n", "super", "(", "AvgPool2dSame", ",", "self", ")", ".", "__init__", "(", "kernel_size", ",", "stride", ",", "(", "0", ",", "0", ")", ",", "ceil_mode", ",", "count_include_pad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.AvgPool2dSame.forward": [[29, 33], ["padding.pad_same", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.pad_same"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "pad_same", "(", "x", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", ")", "\n", "return", "F", ".", "avg_pool2d", "(", "\n", "x", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", ",", "self", ".", "padding", ",", "self", ".", "ceil_mode", ",", "self", ".", "count_include_pad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.MaxPool2dSame.__init__": [[45, 50], ["helpers.to_2tuple", "helpers.to_2tuple", "helpers.to_2tuple", "torch.MaxPool2d.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "kernel_size", ":", "int", ",", "stride", "=", "None", ",", "padding", "=", "0", ",", "dilation", "=", "1", ",", "ceil_mode", "=", "False", ")", ":", "\n", "        ", "kernel_size", "=", "to_2tuple", "(", "kernel_size", ")", "\n", "stride", "=", "to_2tuple", "(", "stride", ")", "\n", "dilation", "=", "to_2tuple", "(", "dilation", ")", "\n", "super", "(", "MaxPool2dSame", ",", "self", ")", ".", "__init__", "(", "kernel_size", ",", "stride", ",", "(", "0", ",", "0", ")", ",", "dilation", ",", "ceil_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.MaxPool2dSame.forward": [[51, 54], ["padding.pad_same", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "float"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.pad_same"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "pad_same", "(", "x", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", ",", "value", "=", "-", "float", "(", "'inf'", ")", ")", "\n", "return", "F", ".", "max_pool2d", "(", "x", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", ",", "(", "0", ",", "0", ")", ",", "self", ".", "dilation", ",", "self", ".", "ceil_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.avg_pool2d_same": [[14, 19], ["padding.pad_same", "torch.avg_pool2d"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.pad_same"], ["def", "avg_pool2d_same", "(", "x", ",", "kernel_size", ":", "List", "[", "int", "]", ",", "stride", ":", "List", "[", "int", "]", ",", "padding", ":", "List", "[", "int", "]", "=", "(", "0", ",", "0", ")", ",", "\n", "ceil_mode", ":", "bool", "=", "False", ",", "count_include_pad", ":", "bool", "=", "True", ")", ":", "\n", "# FIXME how to deal with count_include_pad vs not for external padding?", "\n", "    ", "x", "=", "pad_same", "(", "x", ",", "kernel_size", ",", "stride", ")", "\n", "return", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", ",", "stride", ",", "(", "0", ",", "0", ")", ",", "ceil_mode", ",", "count_include_pad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.max_pool2d_same": [[35, 40], ["padding.pad_same", "torch.max_pool2d", "float"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.pad_same"], ["", "", "def", "max_pool2d_same", "(", "\n", "x", ",", "kernel_size", ":", "List", "[", "int", "]", ",", "stride", ":", "List", "[", "int", "]", ",", "padding", ":", "List", "[", "int", "]", "=", "(", "0", ",", "0", ")", ",", "\n", "dilation", ":", "List", "[", "int", "]", "=", "(", "1", ",", "1", ")", ",", "ceil_mode", ":", "bool", "=", "False", ")", ":", "\n", "    ", "x", "=", "pad_same", "(", "x", ",", "kernel_size", ",", "stride", ",", "value", "=", "-", "float", "(", "'inf'", ")", ")", "\n", "return", "F", ".", "max_pool2d", "(", "x", ",", "kernel_size", ",", "stride", ",", "(", "0", ",", "0", ")", ",", "dilation", ",", "ceil_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pool2d_same.create_pool2d": [[56, 74], ["kwargs.pop", "padding.get_padding_value", "pool2d_same.AvgPool2dSame", "torch.AvgPool2d", "pool2d_same.MaxPool2dSame", "torch.MaxPool2d"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_padding_value"], ["", "", "def", "create_pool2d", "(", "pool_type", ",", "kernel_size", ",", "stride", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "stride", "=", "stride", "or", "kernel_size", "\n", "padding", "=", "kwargs", ".", "pop", "(", "'padding'", ",", "''", ")", "\n", "padding", ",", "is_dynamic", "=", "get_padding_value", "(", "padding", ",", "kernel_size", ",", "stride", "=", "stride", ",", "**", "kwargs", ")", "\n", "if", "is_dynamic", ":", "\n", "        ", "if", "pool_type", "==", "'avg'", ":", "\n", "            ", "return", "AvgPool2dSame", "(", "kernel_size", ",", "stride", "=", "stride", ",", "**", "kwargs", ")", "\n", "", "elif", "pool_type", "==", "'max'", ":", "\n", "            ", "return", "MaxPool2dSame", "(", "kernel_size", ",", "stride", "=", "stride", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "f'Unsupported pool type {pool_type}'", "\n", "", "", "else", ":", "\n", "        ", "if", "pool_type", "==", "'avg'", ":", "\n", "            ", "return", "nn", ".", "AvgPool2d", "(", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "**", "kwargs", ")", "\n", "", "elif", "pool_type", "==", "'max'", ":", "\n", "            ", "return", "nn", ".", "MaxPool2d", "(", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "f'Unsupported pool type {pool_type}'", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.Mlp.__init__": [[13, 24], ["torch.nn.Module.__init__", "helpers.to_2tuple", "torch.nn.Linear", "act_layer", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "hidden_features", "=", "None", ",", "out_features", "=", "None", ",", "act_layer", "=", "nn", ".", "GELU", ",", "drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "out_features", "=", "out_features", "or", "in_features", "\n", "hidden_features", "=", "hidden_features", "or", "in_features", "\n", "drop_probs", "=", "to_2tuple", "(", "drop", ")", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_features", ",", "hidden_features", ")", "\n", "self", ".", "act", "=", "act_layer", "(", ")", "\n", "self", ".", "drop1", "=", "nn", ".", "Dropout", "(", "drop_probs", "[", "0", "]", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_features", ",", "out_features", ")", "\n", "self", ".", "drop2", "=", "nn", ".", "Dropout", "(", "drop_probs", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.Mlp.forward": [[25, 32], ["mlp.Mlp.fc1", "mlp.Mlp.act", "mlp.Mlp.drop1", "mlp.Mlp.fc2", "mlp.Mlp.drop2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "drop1", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "drop2", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.GluMlp.__init__": [[38, 50], ["torch.nn.Module.__init__", "helpers.to_2tuple", "torch.nn.Linear", "act_layer", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "hidden_features", "=", "None", ",", "out_features", "=", "None", ",", "act_layer", "=", "nn", ".", "Sigmoid", ",", "drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "out_features", "=", "out_features", "or", "in_features", "\n", "hidden_features", "=", "hidden_features", "or", "in_features", "\n", "assert", "hidden_features", "%", "2", "==", "0", "\n", "drop_probs", "=", "to_2tuple", "(", "drop", ")", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_features", ",", "hidden_features", ")", "\n", "self", ".", "act", "=", "act_layer", "(", ")", "\n", "self", ".", "drop1", "=", "nn", ".", "Dropout", "(", "drop_probs", "[", "0", "]", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_features", "//", "2", ",", "out_features", ")", "\n", "self", ".", "drop2", "=", "nn", ".", "Dropout", "(", "drop_probs", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.GluMlp.init_weights": [[51, 56], ["torch.nn.init.ones_", "torch.nn.init.normal_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "# override init of fc1 w/ gate portion set to weight near zero, bias=1", "\n", "        ", "fc1_mid", "=", "self", ".", "fc1", ".", "bias", ".", "shape", "[", "0", "]", "//", "2", "\n", "nn", ".", "init", ".", "ones_", "(", "self", ".", "fc1", ".", "bias", "[", "fc1_mid", ":", "]", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "fc1", ".", "weight", "[", "fc1_mid", ":", "]", ",", "std", "=", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.GluMlp.forward": [[57, 65], ["mlp.GluMlp.fc1", "mlp.GluMlp.chunk", "mlp.GluMlp.drop1", "mlp.GluMlp.fc2", "mlp.GluMlp.drop2", "mlp.GluMlp.act"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", ",", "gates", "=", "x", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "x", "=", "x", "*", "self", ".", "act", "(", "gates", ")", "\n", "x", "=", "self", ".", "drop1", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "drop2", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.GatedMlp.__init__": [[70, 88], ["torch.nn.Module.__init__", "helpers.to_2tuple", "torch.nn.Linear", "act_layer", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Dropout", "gate_layer", "torch.nn.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "hidden_features", "=", "None", ",", "out_features", "=", "None", ",", "act_layer", "=", "nn", ".", "GELU", ",", "\n", "gate_layer", "=", "None", ",", "drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "out_features", "=", "out_features", "or", "in_features", "\n", "hidden_features", "=", "hidden_features", "or", "in_features", "\n", "drop_probs", "=", "to_2tuple", "(", "drop", ")", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_features", ",", "hidden_features", ")", "\n", "self", ".", "act", "=", "act_layer", "(", ")", "\n", "self", ".", "drop1", "=", "nn", ".", "Dropout", "(", "drop_probs", "[", "0", "]", ")", "\n", "if", "gate_layer", "is", "not", "None", ":", "\n", "            ", "assert", "hidden_features", "%", "2", "==", "0", "\n", "self", ".", "gate", "=", "gate_layer", "(", "hidden_features", ")", "\n", "hidden_features", "=", "hidden_features", "//", "2", "# FIXME base reduction on gate property?", "\n", "", "else", ":", "\n", "            ", "self", ".", "gate", "=", "nn", ".", "Identity", "(", ")", "\n", "", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_features", ",", "out_features", ")", "\n", "self", ".", "drop2", "=", "nn", ".", "Dropout", "(", "drop_probs", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.GatedMlp.forward": [[89, 97], ["mlp.GatedMlp.fc1", "mlp.GatedMlp.act", "mlp.GatedMlp.drop1", "mlp.GatedMlp.gate", "mlp.GatedMlp.fc2", "mlp.GatedMlp.drop2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "drop1", "(", "x", ")", "\n", "x", "=", "self", ".", "gate", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "drop2", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.ConvMlp.__init__": [[102, 112], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "act_layer", "torch.nn.Conv2d", "torch.nn.Dropout", "norm_layer", "torch.nn.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "\n", "self", ",", "in_features", ",", "hidden_features", "=", "None", ",", "out_features", "=", "None", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "None", ",", "drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "out_features", "=", "out_features", "or", "in_features", "\n", "hidden_features", "=", "hidden_features", "or", "in_features", "\n", "self", ".", "fc1", "=", "nn", ".", "Conv2d", "(", "in_features", ",", "hidden_features", ",", "kernel_size", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "hidden_features", ")", "if", "norm_layer", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "act", "=", "act_layer", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Conv2d", "(", "hidden_features", ",", "out_features", ",", "kernel_size", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.mlp.ConvMlp.forward": [[113, 120], ["mlp.ConvMlp.fc1", "mlp.ConvMlp.norm", "mlp.ConvMlp.act", "mlp.ConvMlp.drop", "mlp.ConvMlp.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.split_attn.RadixSoftmax.__init__": [[17, 21], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "radix", ",", "cardinality", ")", ":", "\n", "        ", "super", "(", "RadixSoftmax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "radix", "=", "radix", "\n", "self", ".", "cardinality", "=", "cardinality", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.split_attn.RadixSoftmax.forward": [[22, 31], ["torch.sigmoid.size", "torch.sigmoid.size", "torch.sigmoid.view().transpose", "torch.sigmoid.view().transpose", "torch.softmax", "torch.softmax", "torch.sigmoid.reshape", "torch.sigmoid.reshape", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid.view", "torch.sigmoid.view"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "batch", "=", "x", ".", "size", "(", "0", ")", "\n", "if", "self", ".", "radix", ">", "1", ":", "\n", "            ", "x", "=", "x", ".", "view", "(", "batch", ",", "self", ".", "cardinality", ",", "self", ".", "radix", ",", "-", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "F", ".", "softmax", "(", "x", ",", "dim", "=", "1", ")", "\n", "x", "=", "x", ".", "reshape", "(", "batch", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "torch", ".", "sigmoid", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.split_attn.SplitAttn.__init__": [[36, 60], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "act_layer", "torch.nn.Conv2d", "torch.nn.Conv2d", "act_layer", "torch.nn.Conv2d", "torch.nn.Conv2d", "split_attn.RadixSoftmax", "helpers.make_divisible", "norm_layer", "torch.nn.Identity", "torch.nn.Identity", "drop_layer", "torch.nn.Identity", "torch.nn.Identity", "norm_layer", "torch.nn.Identity", "torch.nn.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", "=", "None", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "None", ",", "\n", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "False", ",", "radix", "=", "2", ",", "rd_ratio", "=", "0.25", ",", "rd_channels", "=", "None", ",", "rd_divisor", "=", "8", ",", "\n", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "None", ",", "drop_layer", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SplitAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "out_channels", "=", "out_channels", "or", "in_channels", "\n", "self", ".", "radix", "=", "radix", "\n", "mid_chs", "=", "out_channels", "*", "radix", "\n", "if", "rd_channels", "is", "None", ":", "\n", "            ", "attn_chs", "=", "make_divisible", "(", "in_channels", "*", "radix", "*", "rd_ratio", ",", "min_value", "=", "32", ",", "divisor", "=", "rd_divisor", ")", "\n", "", "else", ":", "\n", "            ", "attn_chs", "=", "rd_channels", "*", "radix", "\n", "\n", "", "padding", "=", "kernel_size", "//", "2", "if", "padding", "is", "None", "else", "padding", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "mid_chs", ",", "kernel_size", ",", "stride", ",", "padding", ",", "dilation", ",", "\n", "groups", "=", "groups", "*", "radix", ",", "bias", "=", "bias", ",", "**", "kwargs", ")", "\n", "self", ".", "bn0", "=", "norm_layer", "(", "mid_chs", ")", "if", "norm_layer", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "drop", "=", "drop_layer", "(", ")", "if", "drop_layer", "is", "not", "None", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "act0", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Conv2d", "(", "out_channels", ",", "attn_chs", ",", "1", ",", "groups", "=", "groups", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "attn_chs", ")", "if", "norm_layer", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "act1", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Conv2d", "(", "attn_chs", ",", "mid_chs", ",", "1", ",", "groups", "=", "groups", ")", "\n", "self", ".", "rsoftmax", "=", "RadixSoftmax", "(", "radix", ",", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.split_attn.SplitAttn.forward": [[61, 85], ["split_attn.SplitAttn.conv", "split_attn.SplitAttn.bn0", "split_attn.SplitAttn.drop", "split_attn.SplitAttn.act0", "x.reshape.sum.mean", "split_attn.SplitAttn.fc1", "split_attn.SplitAttn.bn1", "split_attn.SplitAttn.act1", "split_attn.SplitAttn.fc2", "split_attn.SplitAttn.rsoftmax().view", "out.contiguous", "x.reshape.reshape.reshape", "x.reshape.reshape.sum", "split_attn.SplitAttn.rsoftmax", "split_attn.SplitAttn.reshape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "self", ".", "bn0", "(", "x", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "x", "=", "self", ".", "act0", "(", "x", ")", "\n", "\n", "B", ",", "RC", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "if", "self", ".", "radix", ">", "1", ":", "\n", "            ", "x", "=", "x", ".", "reshape", "(", "(", "B", ",", "self", ".", "radix", ",", "RC", "//", "self", ".", "radix", ",", "H", ",", "W", ")", ")", "\n", "x_gap", "=", "x", ".", "sum", "(", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "x_gap", "=", "x", "\n", "", "x_gap", "=", "x_gap", ".", "mean", "(", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "x_gap", "=", "self", ".", "fc1", "(", "x_gap", ")", "\n", "x_gap", "=", "self", ".", "bn1", "(", "x_gap", ")", "\n", "x_gap", "=", "self", ".", "act1", "(", "x_gap", ")", "\n", "x_attn", "=", "self", ".", "fc2", "(", "x_gap", ")", "\n", "\n", "x_attn", "=", "self", ".", "rsoftmax", "(", "x_attn", ")", ".", "view", "(", "B", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "if", "self", ".", "radix", ">", "1", ":", "\n", "            ", "out", "=", "(", "x", "*", "x_attn", ".", "reshape", "(", "(", "B", ",", "self", ".", "radix", ",", "RC", "//", "self", ".", "radix", ",", "1", ",", "1", ")", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "x", "*", "x_attn", "\n", "", "return", "out", ".", "contiguous", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.patch_embed.PatchEmbed.__init__": [[18, 30], ["torch.nn.Module.__init__", "helpers.to_2tuple", "helpers.to_2tuple", "torch.nn.Conv2d", "norm_layer", "torch.nn.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "embed_dim", "=", "768", ",", "norm_layer", "=", "None", ",", "flatten", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "patch_size", "=", "to_2tuple", "(", "patch_size", ")", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "self", ".", "grid_size", "=", "(", "img_size", "[", "0", "]", "//", "patch_size", "[", "0", "]", ",", "img_size", "[", "1", "]", "//", "patch_size", "[", "1", "]", ")", "\n", "self", ".", "num_patches", "=", "self", ".", "grid_size", "[", "0", "]", "*", "self", ".", "grid_size", "[", "1", "]", "\n", "self", ".", "flatten", "=", "flatten", "\n", "\n", "self", ".", "proj", "=", "nn", ".", "Conv2d", "(", "in_chans", ",", "embed_dim", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "patch_size", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "if", "norm_layer", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.patch_embed.PatchEmbed.forward": [[31, 40], ["trace_utils._assert", "trace_utils._assert", "patch_embed.PatchEmbed.proj", "patch_embed.PatchEmbed.norm", "x.flatten().transpose.flatten().transpose.flatten().transpose", "x.flatten().transpose.flatten().transpose.flatten"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "_assert", "(", "H", "==", "self", ".", "img_size", "[", "0", "]", ",", "f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\"", ")", "\n", "_assert", "(", "W", "==", "self", ".", "img_size", "[", "1", "]", ",", "f\"Input image width ({W}) doesn't match model ({self.img_size[1]}).\"", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "if", "self", ".", "flatten", ":", "\n", "            ", "x", "=", "x", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "# BCHW -> BNC", "\n", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.FastAdaptiveAvgPool2d.__init__": [[53, 56], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "flatten", "=", "False", ")", ":", "\n", "        ", "super", "(", "FastAdaptiveAvgPool2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "flatten", "=", "flatten", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.FastAdaptiveAvgPool2d.forward": [[57, 59], ["x.mean"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", ".", "mean", "(", "(", "2", ",", "3", ")", ",", "keepdim", "=", "not", "self", ".", "flatten", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.AdaptiveAvgMaxPool2d.__init__": [[62, 65], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", "=", "1", ")", ":", "\n", "        ", "super", "(", "AdaptiveAvgMaxPool2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.AdaptiveAvgMaxPool2d.forward": [[66, 68], ["adaptive_avgmax_pool.adaptive_avgmax_pool2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.adaptive_avgmax_pool2d"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "adaptive_avgmax_pool2d", "(", "x", ",", "self", ".", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.AdaptiveCatAvgMaxPool2d.__init__": [[71, 74], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", "=", "1", ")", ":", "\n", "        ", "super", "(", "AdaptiveCatAvgMaxPool2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.AdaptiveCatAvgMaxPool2d.forward": [[75, 77], ["adaptive_avgmax_pool.adaptive_catavgmax_pool2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.adaptive_catavgmax_pool2d"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "adaptive_catavgmax_pool2d", "(", "x", ",", "self", ".", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.SelectAdaptivePool2d.__init__": [[82, 102], ["torch.Module.__init__", "torch.Flatten", "torch.Flatten", "torch.Flatten", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "adaptive_avgmax_pool.FastAdaptiveAvgPool2d", "torch.Identity", "torch.Identity", "torch.Identity", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "adaptive_avgmax_pool.AdaptiveAvgMaxPool2d", "adaptive_avgmax_pool.AdaptiveCatAvgMaxPool2d", "torch.AdaptiveMaxPool2d", "torch.AdaptiveMaxPool2d", "torch.AdaptiveMaxPool2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "output_size", "=", "1", ",", "pool_type", "=", "'fast'", ",", "flatten", "=", "False", ")", ":", "\n", "        ", "super", "(", "SelectAdaptivePool2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pool_type", "=", "pool_type", "or", "''", "# convert other falsy values to empty string for consistent TS typing", "\n", "self", ".", "flatten", "=", "nn", ".", "Flatten", "(", "1", ")", "if", "flatten", "else", "nn", ".", "Identity", "(", ")", "\n", "if", "pool_type", "==", "''", ":", "\n", "            ", "self", ".", "pool", "=", "nn", ".", "Identity", "(", ")", "# pass through", "\n", "", "elif", "pool_type", "==", "'fast'", ":", "\n", "            ", "assert", "output_size", "==", "1", "\n", "self", ".", "pool", "=", "FastAdaptiveAvgPool2d", "(", "flatten", ")", "\n", "self", ".", "flatten", "=", "nn", ".", "Identity", "(", ")", "\n", "", "elif", "pool_type", "==", "'avg'", ":", "\n", "            ", "self", ".", "pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "output_size", ")", "\n", "", "elif", "pool_type", "==", "'avgmax'", ":", "\n", "            ", "self", ".", "pool", "=", "AdaptiveAvgMaxPool2d", "(", "output_size", ")", "\n", "", "elif", "pool_type", "==", "'catavgmax'", ":", "\n", "            ", "self", ".", "pool", "=", "AdaptiveCatAvgMaxPool2d", "(", "output_size", ")", "\n", "", "elif", "pool_type", "==", "'max'", ":", "\n", "            ", "self", ".", "pool", "=", "nn", ".", "AdaptiveMaxPool2d", "(", "output_size", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "'Invalid pool type: %s'", "%", "pool_type", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.SelectAdaptivePool2d.is_identity": [[103, 105], ["None"], "methods", ["None"], ["", "", "def", "is_identity", "(", "self", ")", ":", "\n", "        ", "return", "not", "self", ".", "pool_type", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.SelectAdaptivePool2d.forward": [[106, 110], ["adaptive_avgmax_pool.SelectAdaptivePool2d.pool", "adaptive_avgmax_pool.SelectAdaptivePool2d.flatten"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "x", "=", "self", ".", "flatten", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.SelectAdaptivePool2d.feat_mult": [[111, 113], ["adaptive_avgmax_pool.adaptive_pool_feat_mult"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.adaptive_pool_feat_mult"], ["", "def", "feat_mult", "(", "self", ")", ":", "\n", "        ", "return", "adaptive_pool_feat_mult", "(", "self", ".", "pool_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.SelectAdaptivePool2d.__repr__": [[114, 118], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "' ('", "+", "'pool_type='", "+", "self", ".", "pool_type", "+", "', flatten='", "+", "str", "(", "self", ".", "flatten", ")", "+", "')'", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.adaptive_pool_feat_mult": [[17, 22], ["None"], "function", ["None"], ["def", "adaptive_pool_feat_mult", "(", "pool_type", "=", "'avg'", ")", ":", "\n", "    ", "if", "pool_type", "==", "'catavgmax'", ":", "\n", "        ", "return", "2", "\n", "", "else", ":", "\n", "        ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.adaptive_avgmax_pool2d": [[24, 28], ["torch.adaptive_avg_pool2d", "torch.adaptive_max_pool2d"], "function", ["None"], ["", "", "def", "adaptive_avgmax_pool2d", "(", "x", ",", "output_size", "=", "1", ")", ":", "\n", "    ", "x_avg", "=", "F", ".", "adaptive_avg_pool2d", "(", "x", ",", "output_size", ")", "\n", "x_max", "=", "F", ".", "adaptive_max_pool2d", "(", "x", ",", "output_size", ")", "\n", "return", "0.5", "*", "(", "x_avg", "+", "x_max", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.adaptive_catavgmax_pool2d": [[30, 34], ["torch.adaptive_avg_pool2d", "torch.adaptive_max_pool2d", "torch.cat", "torch.cat", "torch.cat"], "function", ["None"], ["", "def", "adaptive_catavgmax_pool2d", "(", "x", ",", "output_size", "=", "1", ")", ":", "\n", "    ", "x_avg", "=", "F", ".", "adaptive_avg_pool2d", "(", "x", ",", "output_size", ")", "\n", "x_max", "=", "F", ".", "adaptive_max_pool2d", "(", "x", ",", "output_size", ")", "\n", "return", "torch", ".", "cat", "(", "(", "x_avg", ",", "x_max", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.select_adaptive_pool2d": [[36, 50], ["torch.adaptive_avg_pool2d", "adaptive_avgmax_pool.adaptive_avgmax_pool2d", "adaptive_avgmax_pool.adaptive_catavgmax_pool2d", "torch.adaptive_max_pool2d"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.adaptive_avgmax_pool2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.adaptive_catavgmax_pool2d"], ["", "def", "select_adaptive_pool2d", "(", "x", ",", "pool_type", "=", "'avg'", ",", "output_size", "=", "1", ")", ":", "\n", "    ", "\"\"\"Selectable global pooling function with dynamic input kernel size\n    \"\"\"", "\n", "if", "pool_type", "==", "'avg'", ":", "\n", "        ", "x", "=", "F", ".", "adaptive_avg_pool2d", "(", "x", ",", "output_size", ")", "\n", "", "elif", "pool_type", "==", "'avgmax'", ":", "\n", "        ", "x", "=", "adaptive_avgmax_pool2d", "(", "x", ",", "output_size", ")", "\n", "", "elif", "pool_type", "==", "'catavgmax'", ":", "\n", "        ", "x", "=", "adaptive_catavgmax_pool2d", "(", "x", ",", "output_size", ")", "\n", "", "elif", "pool_type", "==", "'max'", ":", "\n", "        ", "x", "=", "F", ".", "adaptive_max_pool2d", "(", "x", ",", "output_size", ")", "\n", "", "else", ":", "\n", "        ", "assert", "False", ",", "'Invalid pool type: %s'", "%", "pool_type", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers._ntuple": [[10, 16], ["isinstance", "tuple", "itertools.repeat"], "function", ["None"], ["# from .features import FeatureListNet, FeatureDictNet, FeatureHookNet", "\n", "# from .hub import has_hf_hub, download_cached_file, load_state_dict_from_hf, load_state_dict_from_url", "\n", "# from .layers import Conv2dSame, Linear", "\n", "\n", "_logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "def", "extract_layer", "(", "model", ",", "layer", ")", ":", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible": [[25, 32], ["max", "int"], "function", ["None"], ["            ", "if", "not", "l", ".", "isdigit", "(", ")", ":", "\n", "                ", "module", "=", "getattr", "(", "module", ",", "l", ")", "\n", "", "else", ":", "\n", "                ", "module", "=", "module", "[", "int", "(", "l", ")", "]", "\n", "", "", "else", ":", "\n", "            ", "return", "module", "\n", "", "", "return", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.separable_conv.SeparableConvNormAct.__init__": [[17, 32], ["torch.nn.Module.__init__", "create_conv2d.create_conv2d.create_conv2d", "create_conv2d.create_conv2d.create_conv2d", "create_norm_act.get_norm_act_layer", "create_norm_act.get_norm_act_layer.", "int", "int", "dict"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "padding", "=", "''", ",", "bias", "=", "False", ",", "\n", "channel_multiplier", "=", "1.0", ",", "pw_kernel_size", "=", "1", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "\n", "apply_act", "=", "True", ",", "drop_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "SeparableConvNormAct", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv_dw", "=", "create_conv2d", "(", "\n", "in_channels", ",", "int", "(", "in_channels", "*", "channel_multiplier", ")", ",", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "padding", "=", "padding", ",", "depthwise", "=", "True", ")", "\n", "\n", "self", ".", "conv_pw", "=", "create_conv2d", "(", "\n", "int", "(", "in_channels", "*", "channel_multiplier", ")", ",", "out_channels", ",", "pw_kernel_size", ",", "padding", "=", "padding", ",", "bias", "=", "bias", ")", "\n", "\n", "norm_act_layer", "=", "get_norm_act_layer", "(", "norm_layer", ",", "act_layer", ")", "\n", "norm_kwargs", "=", "dict", "(", "drop_layer", "=", "drop_layer", ")", "if", "drop_layer", "is", "not", "None", "else", "{", "}", "\n", "self", ".", "bn", "=", "norm_act_layer", "(", "out_channels", ",", "apply_act", "=", "apply_act", ",", "**", "norm_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.separable_conv.SeparableConvNormAct.in_channels": [[33, 36], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "in_channels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "conv_dw", ".", "in_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.separable_conv.SeparableConvNormAct.out_channels": [[37, 40], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "out_channels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "conv_pw", ".", "out_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.separable_conv.SeparableConvNormAct.forward": [[41, 46], ["separable_conv.SeparableConvNormAct.conv_dw", "separable_conv.SeparableConvNormAct.conv_pw", "separable_conv.SeparableConvNormAct.bn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv_dw", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_pw", "(", "x", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.separable_conv.SeparableConv2d.__init__": [[54, 64], ["torch.nn.Module.__init__", "create_conv2d.create_conv2d.create_conv2d", "create_conv2d.create_conv2d.create_conv2d", "int", "int"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "padding", "=", "''", ",", "bias", "=", "False", ",", "\n", "channel_multiplier", "=", "1.0", ",", "pw_kernel_size", "=", "1", ")", ":", "\n", "        ", "super", "(", "SeparableConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv_dw", "=", "create_conv2d", "(", "\n", "in_channels", ",", "int", "(", "in_channels", "*", "channel_multiplier", ")", ",", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "padding", "=", "padding", ",", "depthwise", "=", "True", ")", "\n", "\n", "self", ".", "conv_pw", "=", "create_conv2d", "(", "\n", "int", "(", "in_channels", "*", "channel_multiplier", ")", ",", "out_channels", ",", "pw_kernel_size", ",", "padding", "=", "padding", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.separable_conv.SeparableConv2d.in_channels": [[65, 68], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "in_channels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "conv_dw", ".", "in_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.separable_conv.SeparableConv2d.out_channels": [[69, 72], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "out_channels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "conv_pw", ".", "out_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.separable_conv.SeparableConv2d.forward": [[73, 77], ["separable_conv.SeparableConv2d.conv_dw", "separable_conv.SeparableConv2d.conv_pw"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv_dw", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_pw", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init._no_grad_trunc_normal_": [[8, 42], ["warnings.warn", "torch.no_grad", "weight_init._no_grad_trunc_normal_.norm_cdf"], "function", ["None"], ["def", "_no_grad_trunc_normal_", "(", "tensor", ",", "mean", ",", "std", ",", "a", ",", "b", ")", ":", "\n", "# Cut & paste from PyTorch official master until it's in a few official releases - RW", "\n", "# Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf", "\n", "    ", "def", "norm_cdf", "(", "x", ")", ":", "\n", "# Computes standard normal cumulative distribution function", "\n", "        ", "return", "(", "1.", "+", "math", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.", ")", ")", ")", "/", "2.", "\n", "\n", "", "if", "(", "mean", "<", "a", "-", "2", "*", "std", ")", "or", "(", "mean", ">", "b", "+", "2", "*", "std", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"", "\n", "\"The distribution of values may be incorrect.\"", ",", "\n", "stacklevel", "=", "2", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Values are generated by using a truncated uniform distribution and", "\n", "# then using the inverse CDF for the normal distribution.", "\n", "# Get upper and lower cdf values", "\n", "        ", "l", "=", "norm_cdf", "(", "(", "a", "-", "mean", ")", "/", "std", ")", "\n", "u", "=", "norm_cdf", "(", "(", "b", "-", "mean", ")", "/", "std", ")", "\n", "\n", "# Uniformly fill tensor with values from [l, u], then translate to", "\n", "# [2l-1, 2u-1].", "\n", "tensor", ".", "uniform_", "(", "2", "*", "l", "-", "1", ",", "2", "*", "u", "-", "1", ")", "\n", "\n", "# Use inverse cdf transform for normal distribution to get truncated", "\n", "# standard normal", "\n", "tensor", ".", "erfinv_", "(", ")", "\n", "\n", "# Transform to proper mean, std", "\n", "tensor", ".", "mul_", "(", "std", "*", "math", ".", "sqrt", "(", "2.", ")", ")", "\n", "tensor", ".", "add_", "(", "mean", ")", "\n", "\n", "# Clamp to ensure it's in the proper range", "\n", "tensor", ".", "clamp_", "(", "min", "=", "a", ",", "max", "=", "b", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_": [[44, 63], ["weight_init._no_grad_trunc_normal_"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init._no_grad_trunc_normal_"], ["", "", "def", "trunc_normal_", "(", "tensor", ",", "mean", "=", "0.", ",", "std", "=", "1.", ",", "a", "=", "-", "2.", ",", "b", "=", "2.", ")", ":", "\n", "# type: (Tensor, float, float, float, float) -> Tensor", "\n", "    ", "r\"\"\"Fills the input Tensor with values drawn from a truncated\n    normal distribution. The values are effectively drawn from the\n    normal distribution :math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`\n    with values outside :math:`[a, b]` redrawn until they are within\n    the bounds. The method used for generating the random values works\n    best when :math:`a \\leq \\text{mean} \\leq b`.\n    Args:\n        tensor: an n-dimensional `torch.Tensor`\n        mean: the mean of the normal distribution\n        std: the standard deviation of the normal distribution\n        a: the minimum cutoff value\n        b: the maximum cutoff value\n    Examples:\n        >>> w = torch.empty(3, 5)\n        >>> nn.init.trunc_normal_(w)\n    \"\"\"", "\n", "return", "_no_grad_trunc_normal_", "(", "tensor", ",", "mean", ",", "std", ",", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.variance_scaling_": [[65, 86], ["torch.nn.init._calculate_fan_in_and_fan_out", "weight_init.trunc_normal_", "tensor.normal_", "math.sqrt", "tensor.uniform_", "ValueError", "math.sqrt", "math.sqrt"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "def", "variance_scaling_", "(", "tensor", ",", "scale", "=", "1.0", ",", "mode", "=", "'fan_in'", ",", "distribution", "=", "'normal'", ")", ":", "\n", "    ", "fan_in", ",", "fan_out", "=", "_calculate_fan_in_and_fan_out", "(", "tensor", ")", "\n", "if", "mode", "==", "'fan_in'", ":", "\n", "        ", "denom", "=", "fan_in", "\n", "", "elif", "mode", "==", "'fan_out'", ":", "\n", "        ", "denom", "=", "fan_out", "\n", "", "elif", "mode", "==", "'fan_avg'", ":", "\n", "        ", "denom", "=", "(", "fan_in", "+", "fan_out", ")", "/", "2", "\n", "\n", "", "variance", "=", "scale", "/", "denom", "\n", "\n", "if", "distribution", "==", "\"truncated_normal\"", ":", "\n", "# constant is stddev of standard normal truncated to (-2, 2)", "\n", "        ", "trunc_normal_", "(", "tensor", ",", "std", "=", "math", ".", "sqrt", "(", "variance", ")", "/", ".87962566103423978", ")", "\n", "", "elif", "distribution", "==", "\"normal\"", ":", "\n", "        ", "tensor", ".", "normal_", "(", "std", "=", "math", ".", "sqrt", "(", "variance", ")", ")", "\n", "", "elif", "distribution", "==", "\"uniform\"", ":", "\n", "        ", "bound", "=", "math", ".", "sqrt", "(", "3", "*", "variance", ")", "\n", "tensor", ".", "uniform_", "(", "-", "bound", ",", "bound", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"invalid distribution {distribution}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.lecun_normal_": [[88, 90], ["weight_init.variance_scaling_"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.variance_scaling_"], ["", "", "def", "lecun_normal_", "(", "tensor", ")", ":", "\n", "    ", "variance_scaling_", "(", "tensor", ",", "mode", "=", "'fan_in'", ",", "distribution", "=", "'truncated_normal'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.lambda_layer.LambdaLayer.__init__": [[67, 101], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "lambda_layer.LambdaLayer.reset_parameters", "torch.nn.Conv3d", "torch.nn.Conv3d", "helpers.to_2tuple", "torch.nn.Parameter", "torch.nn.Parameter", "lambda_layer.LambdaLayer.register_buffer", "torch.nn.AvgPool2d", "torch.nn.AvgPool2d", "torch.nn.Identity", "torch.nn.Identity", "helpers.make_divisible", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "lambda_layer.rel_pos_indices"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.lambda_layer.rel_pos_indices"], ["def", "__init__", "(", "\n", "self", ",", "dim", ",", "dim_out", "=", "None", ",", "feat_size", "=", "None", ",", "stride", "=", "1", ",", "num_heads", "=", "4", ",", "dim_head", "=", "16", ",", "r", "=", "9", ",", "\n", "qk_ratio", "=", "1.0", ",", "qkv_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "dim_out", "=", "dim_out", "or", "dim", "\n", "assert", "dim_out", "%", "num_heads", "==", "0", ",", "' should be divided by num_heads'", "\n", "self", ".", "dim_qk", "=", "dim_head", "or", "make_divisible", "(", "dim_out", "*", "qk_ratio", ",", "divisor", "=", "8", ")", "//", "num_heads", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dim_v", "=", "dim_out", "//", "num_heads", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Conv2d", "(", "\n", "dim", ",", "\n", "num_heads", "*", "self", ".", "dim_qk", "+", "self", ".", "dim_qk", "+", "self", ".", "dim_v", ",", "\n", "kernel_size", "=", "1", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "norm_q", "=", "nn", ".", "BatchNorm2d", "(", "num_heads", "*", "self", ".", "dim_qk", ")", "\n", "self", ".", "norm_v", "=", "nn", ".", "BatchNorm2d", "(", "self", ".", "dim_v", ")", "\n", "\n", "if", "r", "is", "not", "None", ":", "\n", "# local lambda convolution for pos", "\n", "            ", "self", ".", "conv_lambda", "=", "nn", ".", "Conv3d", "(", "1", ",", "self", ".", "dim_qk", ",", "(", "r", ",", "r", ",", "1", ")", ",", "padding", "=", "(", "r", "//", "2", ",", "r", "//", "2", ",", "0", ")", ")", "\n", "self", ".", "pos_emb", "=", "None", "\n", "self", ".", "rel_pos_indices", "=", "None", "\n", "", "else", ":", "\n", "# relative pos embedding", "\n", "            ", "assert", "feat_size", "is", "not", "None", "\n", "feat_size", "=", "to_2tuple", "(", "feat_size", ")", "\n", "rel_size", "=", "[", "2", "*", "s", "-", "1", "for", "s", "in", "feat_size", "]", "\n", "self", ".", "conv_lambda", "=", "None", "\n", "self", ".", "pos_emb", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "rel_size", "[", "0", "]", ",", "rel_size", "[", "1", "]", ",", "self", ".", "dim_qk", ")", ")", "\n", "self", ".", "register_buffer", "(", "'rel_pos_indices'", ",", "rel_pos_indices", "(", "feat_size", ")", ",", "persistent", "=", "False", ")", "\n", "\n", "", "self", ".", "pool", "=", "nn", ".", "AvgPool2d", "(", "2", ",", "2", ")", "if", "stride", "==", "2", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.lambda_layer.LambdaLayer.reset_parameters": [[102, 108], ["weight_init.trunc_normal_", "weight_init.trunc_normal_", "weight_init.trunc_normal_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "trunc_normal_", "(", "self", ".", "qkv", ".", "weight", ",", "std", "=", "self", ".", "qkv", ".", "weight", ".", "shape", "[", "1", "]", "**", "-", "0.5", ")", "# fan-in", "\n", "if", "self", ".", "conv_lambda", "is", "not", "None", ":", "\n", "            ", "trunc_normal_", "(", "self", ".", "conv_lambda", ".", "weight", ",", "std", "=", "self", ".", "dim_qk", "**", "-", "0.5", ")", "\n", "", "if", "self", ".", "pos_emb", "is", "not", "None", ":", "\n", "            ", "trunc_normal_", "(", "self", ".", "pos_emb", ",", "std", "=", ".02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.lambda_layer.LambdaLayer.forward": [[109, 134], ["lambda_layer.LambdaLayer.qkv", "torch.split", "torch.split", "torch.split", "torch.split", "lambda_layer.LambdaLayer.norm_q().reshape().transpose", "lambda_layer.LambdaLayer.norm_v().reshape().transpose", "torch.softmax", "torch.softmax", "lambda_layer.LambdaLayer.pool", "torch.softmax.reshape", "content_lam.unsqueeze", "lambda_layer.LambdaLayer.conv_lambda", "position_lam.reshape().transpose.reshape().transpose.reshape().transpose", "lambda_layer.LambdaLayer.pos_emb[].expand", "lambda_layer.LambdaLayer.norm_q().reshape", "lambda_layer.LambdaLayer.norm_v().reshape", "lambda_layer.LambdaLayer.reshape", "position_lam.reshape().transpose.reshape().transpose.reshape", "lambda_layer.LambdaLayer.unsqueeze", "lambda_layer.LambdaLayer.norm_q", "lambda_layer.LambdaLayer.norm_v", "lambda_layer.LambdaLayer.transpose", "lambda_layer.LambdaLayer.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "M", "=", "H", "*", "W", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", "\n", "q", ",", "k", ",", "v", "=", "torch", ".", "split", "(", "qkv", ",", "[", "\n", "self", ".", "num_heads", "*", "self", ".", "dim_qk", ",", "self", ".", "dim_qk", ",", "self", ".", "dim_v", "]", ",", "dim", "=", "1", ")", "\n", "q", "=", "self", ".", "norm_q", "(", "q", ")", ".", "reshape", "(", "B", ",", "self", ".", "num_heads", ",", "self", ".", "dim_qk", ",", "M", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "# B, num_heads, M, K", "\n", "v", "=", "self", ".", "norm_v", "(", "v", ")", ".", "reshape", "(", "B", ",", "self", ".", "dim_v", ",", "M", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "# B, M, V", "\n", "k", "=", "F", ".", "softmax", "(", "k", ".", "reshape", "(", "B", ",", "self", ".", "dim_qk", ",", "M", ")", ",", "dim", "=", "-", "1", ")", "# B, K, M", "\n", "\n", "content_lam", "=", "k", "@", "v", "# B, K, V", "\n", "content_out", "=", "q", "@", "content_lam", ".", "unsqueeze", "(", "1", ")", "# B, num_heads, M, V", "\n", "\n", "if", "self", ".", "pos_emb", "is", "None", ":", "\n", "            ", "position_lam", "=", "self", ".", "conv_lambda", "(", "v", ".", "reshape", "(", "B", ",", "1", ",", "H", ",", "W", ",", "self", ".", "dim_v", ")", ")", "# B, H, W, V, K", "\n", "position_lam", "=", "position_lam", ".", "reshape", "(", "B", ",", "1", ",", "self", ".", "dim_qk", ",", "H", "*", "W", ",", "self", ".", "dim_v", ")", ".", "transpose", "(", "2", ",", "3", ")", "# B, 1, M, K, V", "\n", "", "else", ":", "\n", "# FIXME relative pos embedding path not fully verified", "\n", "            ", "pos_emb", "=", "self", ".", "pos_emb", "[", "self", ".", "rel_pos_indices", "[", "0", "]", ",", "self", ".", "rel_pos_indices", "[", "1", "]", "]", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "position_lam", "=", "(", "pos_emb", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "@", "v", ".", "unsqueeze", "(", "1", ")", ")", ".", "unsqueeze", "(", "1", ")", "# B, 1, M, K, V", "\n", "", "position_out", "=", "(", "q", ".", "unsqueeze", "(", "-", "2", ")", "@", "position_lam", ")", ".", "squeeze", "(", "-", "2", ")", "# B, num_heads, M, V", "\n", "\n", "out", "=", "(", "content_out", "+", "position_out", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ".", "reshape", "(", "B", ",", "C", ",", "H", ",", "W", ")", "# B, C (num_heads * V), H, W", "\n", "out", "=", "self", ".", "pool", "(", "out", ")", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.lambda_layer.rel_pos_indices": [[31, 38], ["helpers.to_2tuple", "torch.stack().flatten", "torch.stack().flatten", "torch.stack", "torch.stack", "torch.meshgrid", "torch.meshgrid", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "function", ["None"], ["def", "rel_pos_indices", "(", "size", ")", ":", "\n", "    ", "size", "=", "to_2tuple", "(", "size", ")", "\n", "pos", "=", "torch", ".", "stack", "(", "torch", ".", "meshgrid", "(", "torch", ".", "arange", "(", "size", "[", "0", "]", ")", ",", "torch", ".", "arange", "(", "size", "[", "1", "]", ")", ")", ")", ".", "flatten", "(", "1", ")", "\n", "rel_pos", "=", "pos", "[", ":", ",", "None", ",", ":", "]", "-", "pos", "[", ":", ",", ":", ",", "None", "]", "\n", "rel_pos", "[", "0", "]", "+=", "size", "[", "0", "]", "-", "1", "\n", "rel_pos", "[", "1", "]", "+=", "size", "[", "1", "]", "-", "1", "\n", "return", "rel_pos", "# 2, H * W, H * W", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.attention_pool2d.RotAttentionPool2d.__init__": [[30, 51], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "pos_embed.RotaryEmbedding", "weight_init.trunc_normal_", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_features", ":", "int", ",", "\n", "out_features", ":", "int", "=", "None", ",", "\n", "embed_dim", ":", "int", "=", "None", ",", "\n", "num_heads", ":", "int", "=", "4", ",", "\n", "qkv_bias", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "embed_dim", "=", "embed_dim", "or", "in_features", "\n", "out_features", "=", "out_features", "or", "in_features", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "in_features", ",", "embed_dim", "*", "3", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "out_features", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "assert", "embed_dim", "%", "num_heads", "==", "0", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "self", ".", "scale", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "self", ".", "pos_embed", "=", "RotaryEmbedding", "(", "self", ".", "head_dim", ")", "\n", "\n", "trunc_normal_", "(", "self", ".", "qkv", ".", "weight", ",", "std", "=", "in_features", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "qkv", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.attention_pool2d.RotAttentionPool2d.forward": [[52, 77], ["attention_pool2d.RotAttentionPool2d.reshape().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "attention_pool2d.RotAttentionPool2d.qkv().reshape().permute", "attention_pool2d.RotAttentionPool2d.pos_embed.get_embed", "pos_embed.apply_rot_embed", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pos_embed.apply_rot_embed", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "attn.softmax.softmax.softmax", "attention_pool2d.RotAttentionPool2d.proj", "attention_pool2d.RotAttentionPool2d.reshape", "attention_pool2d.RotAttentionPool2d.mean", "attention_pool2d.RotAttentionPool2d.qkv().reshape", "torch.cat.transpose", "torch.cat.transpose", "attention_pool2d.RotAttentionPool2d.qkv"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.RotaryEmbedding.get_embed", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.apply_rot_embed", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.pos_embed.apply_rot_embed"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "_", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "N", "=", "H", "*", "W", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "-", "1", ",", "N", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", ",", "x", "]", ",", "dim", "=", "1", ")", "\n", "\n", "x", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", "+", "1", ",", "3", ",", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", ",", "v", "=", "x", "[", "0", "]", ",", "x", "[", "1", "]", ",", "x", "[", "2", "]", "\n", "\n", "qc", ",", "q", "=", "q", "[", ":", ",", ":", ",", ":", "1", "]", ",", "q", "[", ":", ",", ":", ",", "1", ":", "]", "\n", "sin_emb", ",", "cos_emb", "=", "self", ".", "pos_embed", ".", "get_embed", "(", "(", "H", ",", "W", ")", ")", "\n", "q", "=", "apply_rot_embed", "(", "q", ",", "sin_emb", ",", "cos_emb", ")", "\n", "q", "=", "torch", ".", "cat", "(", "[", "qc", ",", "q", "]", ",", "dim", "=", "2", ")", "\n", "\n", "kc", ",", "k", "=", "k", "[", ":", ",", ":", ",", ":", "1", "]", ",", "k", "[", ":", ",", ":", ",", "1", ":", "]", "\n", "k", "=", "apply_rot_embed", "(", "k", ",", "sin_emb", ",", "cos_emb", ")", "\n", "k", "=", "torch", ".", "cat", "(", "[", "kc", ",", "k", "]", ",", "dim", "=", "2", ")", "\n", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "*", "self", ".", "scale", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "N", "+", "1", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "return", "x", "[", ":", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.attention_pool2d.AttentionPool2d.__init__": [[88, 114], ["torch.Module.__init__", "helpers.to_2tuple", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "weight_init.trunc_normal_", "weight_init.trunc_normal_", "torch.init.zeros_", "torch.init.zeros_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.weight_init.trunc_normal_"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_features", ":", "int", ",", "\n", "feat_size", ":", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "int", "]", "]", ",", "\n", "out_features", ":", "int", "=", "None", ",", "\n", "embed_dim", ":", "int", "=", "None", ",", "\n", "num_heads", ":", "int", "=", "4", ",", "\n", "qkv_bias", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "embed_dim", "=", "embed_dim", "or", "in_features", "\n", "out_features", "=", "out_features", "or", "in_features", "\n", "assert", "embed_dim", "%", "num_heads", "==", "0", "\n", "self", ".", "feat_size", "=", "to_2tuple", "(", "feat_size", ")", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "in_features", ",", "embed_dim", "*", "3", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "out_features", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "self", ".", "scale", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n", "spatial_dim", "=", "self", ".", "feat_size", "[", "0", "]", "*", "self", ".", "feat_size", "[", "1", "]", "\n", "self", ".", "pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "spatial_dim", "+", "1", ",", "in_features", ")", ")", "\n", "trunc_normal_", "(", "self", ".", "pos_embed", ",", "std", "=", "in_features", "**", "-", "0.5", ")", "\n", "trunc_normal_", "(", "self", ".", "qkv", ".", "weight", ",", "std", "=", "in_features", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "qkv", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.attention_pool2d.AttentionPool2d.forward": [[115, 132], ["attention_pool2d.AttentionPool2d.reshape().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "attention_pool2d.AttentionPool2d.qkv().reshape().permute", "attn.softmax.softmax.softmax", "attention_pool2d.AttentionPool2d.proj", "attention_pool2d.AttentionPool2d.pos_embed.unsqueeze().to", "attention_pool2d.AttentionPool2d.reshape", "attention_pool2d.AttentionPool2d.mean", "attention_pool2d.AttentionPool2d.qkv().reshape", "k.transpose", "attention_pool2d.AttentionPool2d.pos_embed.unsqueeze", "attention_pool2d.AttentionPool2d.qkv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "_", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "N", "=", "H", "*", "W", "\n", "assert", "self", ".", "feat_size", "[", "0", "]", "==", "H", "\n", "assert", "self", ".", "feat_size", "[", "1", "]", "==", "W", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "-", "1", ",", "N", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", ",", "x", "]", ",", "dim", "=", "1", ")", "\n", "x", "=", "x", "+", "self", ".", "pos_embed", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "x", ".", "dtype", ")", "\n", "\n", "x", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", "+", "1", ",", "3", ",", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", ",", "v", "=", "x", "[", "0", "]", ",", "x", "[", "1", "]", ",", "x", "[", "2", "]", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "*", "self", ".", "scale", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "N", "+", "1", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "return", "x", "[", ":", ",", "0", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_padding": [[12, 15], ["None"], "function", ["None"], ["def", "get_padding", "(", "kernel_size", ":", "int", ",", "stride", ":", "int", "=", "1", ",", "dilation", ":", "int", "=", "1", ",", "**", "_", ")", "->", "int", ":", "\n", "    ", "padding", "=", "(", "(", "stride", "-", "1", ")", "+", "dilation", "*", "(", "kernel_size", "-", "1", ")", ")", "//", "2", "\n", "return", "padding", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_same_padding": [[18, 20], ["max", "math.ceil"], "function", ["None"], ["", "def", "get_same_padding", "(", "x", ":", "int", ",", "k", ":", "int", ",", "s", ":", "int", ",", "d", ":", "int", ")", ":", "\n", "    ", "return", "max", "(", "(", "math", ".", "ceil", "(", "x", "/", "s", ")", "-", "1", ")", "*", "s", "+", "(", "k", "-", "1", ")", "*", "d", "+", "1", "-", "x", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.is_static_pad": [[23, 25], ["None"], "function", ["None"], ["", "def", "is_static_pad", "(", "kernel_size", ":", "int", ",", "stride", ":", "int", "=", "1", ",", "dilation", ":", "int", "=", "1", ",", "**", "_", ")", ":", "\n", "    ", "return", "stride", "==", "1", "and", "(", "dilation", "*", "(", "kernel_size", "-", "1", ")", ")", "%", "2", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.pad_same": [[28, 34], ["F.pad.size", "padding.get_same_padding", "padding.get_same_padding", "torch.pad"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_same_padding", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_same_padding"], ["", "def", "pad_same", "(", "x", ",", "k", ":", "List", "[", "int", "]", ",", "s", ":", "List", "[", "int", "]", ",", "d", ":", "List", "[", "int", "]", "=", "(", "1", ",", "1", ")", ",", "value", ":", "float", "=", "0", ")", ":", "\n", "    ", "ih", ",", "iw", "=", "x", ".", "size", "(", ")", "[", "-", "2", ":", "]", "\n", "pad_h", ",", "pad_w", "=", "get_same_padding", "(", "ih", ",", "k", "[", "0", "]", ",", "s", "[", "0", "]", ",", "d", "[", "0", "]", ")", ",", "get_same_padding", "(", "iw", ",", "k", "[", "1", "]", ",", "s", "[", "1", "]", ",", "d", "[", "1", "]", ")", "\n", "if", "pad_h", ">", "0", "or", "pad_w", ">", "0", ":", "\n", "        ", "x", "=", "F", ".", "pad", "(", "x", ",", "[", "pad_w", "//", "2", ",", "pad_w", "-", "pad_w", "//", "2", ",", "pad_h", "//", "2", ",", "pad_h", "-", "pad_h", "//", "2", "]", ",", "value", "=", "value", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_padding_value": [[36, 57], ["isinstance", "get_padding.lower", "padding.is_static_pad", "padding.get_padding", "padding.get_padding"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.is_static_pad", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_padding", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_padding"], ["", "def", "get_padding_value", "(", "padding", ",", "kernel_size", ",", "**", "kwargs", ")", "->", "Tuple", "[", "Tuple", ",", "bool", "]", ":", "\n", "    ", "dynamic", "=", "False", "\n", "if", "isinstance", "(", "padding", ",", "str", ")", ":", "\n", "# for any string padding, the padding will be calculated for you, one of three ways", "\n", "        ", "padding", "=", "padding", ".", "lower", "(", ")", "\n", "if", "padding", "==", "'same'", ":", "\n", "# TF compatible 'SAME' padding, has a performance and GPU memory allocation impact", "\n", "            ", "if", "is_static_pad", "(", "kernel_size", ",", "**", "kwargs", ")", ":", "\n", "# static case, no extra overhead", "\n", "                ", "padding", "=", "get_padding", "(", "kernel_size", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "# dynamic 'SAME' padding, has runtime/GPU memory overhead", "\n", "                ", "padding", "=", "0", "\n", "dynamic", "=", "True", "\n", "", "", "elif", "padding", "==", "'valid'", ":", "\n", "# 'VALID' padding, same as padding=0", "\n", "            ", "padding", "=", "0", "\n", "", "else", ":", "\n", "# Default to PyTorch style 'same'-ish symmetric padding", "\n", "            ", "padding", "=", "get_padding", "(", "kernel_size", ",", "**", "kwargs", ")", "\n", "", "", "return", "padding", ",", "dynamic", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.non_local_attn.NonLocalAttn.__init__": [[23, 34], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "non_local_attn.NonLocalAttn.reset_parameters", "helpers.make_divisible"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "use_scale", "=", "True", ",", "rd_ratio", "=", "1", "/", "8", ",", "rd_channels", "=", "None", ",", "rd_divisor", "=", "8", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "NonLocalAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "rd_channels", "is", "None", ":", "\n", "            ", "rd_channels", "=", "make_divisible", "(", "in_channels", "*", "rd_ratio", ",", "divisor", "=", "rd_divisor", ")", "\n", "", "self", ".", "scale", "=", "in_channels", "**", "-", "0.5", "if", "use_scale", "else", "1.0", "\n", "self", ".", "t", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "rd_channels", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "p", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "rd_channels", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "g", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "rd_channels", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "z", "=", "nn", ".", "Conv2d", "(", "rd_channels", ",", "in_channels", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "norm", "=", "nn", ".", "BatchNorm2d", "(", "in_channels", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.non_local_attn.NonLocalAttn.forward": [[35, 56], ["non_local_attn.NonLocalAttn.t", "non_local_attn.NonLocalAttn.p", "non_local_attn.NonLocalAttn.g", "t.view().permute.view().permute.size", "t.view().permute.view().permute.view().permute", "p.view.view.view", "g.view().permute.view().permute.view().permute", "torch.nn.functional.softmax", "torch.bmm", "non_local_attn.NonLocalAttn.permute().reshape", "non_local_attn.NonLocalAttn.z", "torch.bmm", "non_local_attn.NonLocalAttn.norm", "t.view().permute.view().permute.view", "g.view().permute.view().permute.view", "non_local_attn.NonLocalAttn.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "shortcut", "=", "x", "\n", "\n", "t", "=", "self", ".", "t", "(", "x", ")", "\n", "p", "=", "self", ".", "p", "(", "x", ")", "\n", "g", "=", "self", ".", "g", "(", "x", ")", "\n", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "t", ".", "size", "(", ")", "\n", "t", "=", "t", ".", "view", "(", "B", ",", "C", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "p", "=", "p", ".", "view", "(", "B", ",", "C", ",", "-", "1", ")", "\n", "g", "=", "g", ".", "view", "(", "B", ",", "C", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "att", "=", "torch", ".", "bmm", "(", "t", ",", "p", ")", "*", "self", ".", "scale", "\n", "att", "=", "F", ".", "softmax", "(", "att", ",", "dim", "=", "2", ")", "\n", "x", "=", "torch", ".", "bmm", "(", "att", ",", "g", ")", "\n", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "reshape", "(", "B", ",", "C", ",", "H", ",", "W", ")", "\n", "x", "=", "self", ".", "z", "(", "x", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "+", "shortcut", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.non_local_attn.NonLocalAttn.reset_parameters": [[57, 70], ["non_local_attn.NonLocalAttn.named_modules", "isinstance", "torch.nn.init.kaiming_normal_", "isinstance", "len", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "isinstance", "list", "torch.nn.init.constant_", "torch.nn.init.constant_", "m.parameters"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.helpers.named_modules"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "name", ",", "m", "in", "self", ".", "named_modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "\n", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "if", "len", "(", "list", "(", "m", ".", "parameters", "(", ")", ")", ")", ">", "1", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "GroupNorm", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.non_local_attn.BilinearAttnTransform.__init__": [[74, 84], ["torch.nn.Module.__init__", "conv_bn_act.ConvNormAct", "torch.nn.Conv2d", "torch.nn.Conv2d", "conv_bn_act.ConvNormAct"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "block_size", ",", "groups", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "BilinearAttnTransform", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "ConvNormAct", "(", "in_channels", ",", "groups", ",", "1", ",", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "conv_p", "=", "nn", ".", "Conv2d", "(", "groups", ",", "block_size", "*", "block_size", "*", "groups", ",", "kernel_size", "=", "(", "block_size", ",", "1", ")", ")", "\n", "self", ".", "conv_q", "=", "nn", ".", "Conv2d", "(", "groups", ",", "block_size", "*", "block_size", "*", "groups", ",", "kernel_size", "=", "(", "1", ",", "block_size", ")", ")", "\n", "self", ".", "conv2", "=", "ConvNormAct", "(", "in_channels", ",", "in_channels", ",", "1", ",", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "block_size", "=", "block_size", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.non_local_attn.BilinearAttnTransform.resize_mat": [[85, 97], ["trace_utils._assert", "x.view.view.view", "x.view.view.view", "torch.cat", "torch.cat", "x.view.view.view", "torch.eye", "torch.split", "torch.split"], "methods", ["None"], ["", "def", "resize_mat", "(", "self", ",", "x", ",", "t", ":", "int", ")", ":", "\n", "        ", "B", ",", "C", ",", "block_size", ",", "block_size1", "=", "x", ".", "shape", "\n", "_assert", "(", "block_size", "==", "block_size1", ",", "''", ")", "\n", "if", "t", "<=", "1", ":", "\n", "            ", "return", "x", "\n", "", "x", "=", "x", ".", "view", "(", "B", "*", "C", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "x", "=", "x", "*", "torch", ".", "eye", "(", "t", ",", "t", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", "\n", "x", "=", "x", ".", "view", "(", "B", "*", "C", ",", "block_size", ",", "block_size", ",", "t", ",", "t", ")", "\n", "x", "=", "torch", ".", "cat", "(", "torch", ".", "split", "(", "x", ",", "1", ",", "dim", "=", "1", ")", ",", "dim", "=", "3", ")", "\n", "x", "=", "torch", ".", "cat", "(", "torch", ".", "split", "(", "x", ",", "1", ",", "dim", "=", "2", ")", ",", "dim", "=", "4", ")", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "C", ",", "block_size", "*", "t", ",", "block_size", "*", "t", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.non_local_attn.BilinearAttnTransform.forward": [[98, 122], ["trace_utils._assert", "trace_utils._assert", "non_local_attn.BilinearAttnTransform.conv1", "torch.nn.functional.adaptive_max_pool2d", "torch.nn.functional.adaptive_max_pool2d", "non_local_attn.BilinearAttnTransform.conv_p().view().sigmoid", "non_local_attn.BilinearAttnTransform.conv_q().view().sigmoid", "non_local_attn.BilinearAttnTransform.view().expand().contiguous", "non_local_attn.BilinearAttnTransform.view", "non_local_attn.BilinearAttnTransform.view().expand().contiguous", "non_local_attn.BilinearAttnTransform.view", "non_local_attn.BilinearAttnTransform.resize_mat", "non_local_attn.BilinearAttnTransform.resize_mat", "non_local_attn.BilinearAttnTransform.matmul", "non_local_attn.BilinearAttnTransform.matmul", "non_local_attn.BilinearAttnTransform.conv2", "non_local_attn.BilinearAttnTransform.sum", "non_local_attn.BilinearAttnTransform.sum", "non_local_attn.BilinearAttnTransform.conv_p().view", "non_local_attn.BilinearAttnTransform.conv_q().view", "non_local_attn.BilinearAttnTransform.view().expand", "non_local_attn.BilinearAttnTransform.view().expand", "x.size", "x.size", "non_local_attn.BilinearAttnTransform.conv_p", "non_local_attn.BilinearAttnTransform.conv_q", "non_local_attn.BilinearAttnTransform.view", "non_local_attn.BilinearAttnTransform.view"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.non_local_attn.BilinearAttnTransform.resize_mat", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.non_local_attn.BilinearAttnTransform.resize_mat"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_assert", "(", "x", ".", "shape", "[", "-", "1", "]", "%", "self", ".", "block_size", "==", "0", ",", "''", ")", "\n", "_assert", "(", "x", ".", "shape", "[", "-", "2", "]", "%", "self", ".", "block_size", "==", "0", ",", "''", ")", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "rp", "=", "F", ".", "adaptive_max_pool2d", "(", "out", ",", "(", "self", ".", "block_size", ",", "1", ")", ")", "\n", "cp", "=", "F", ".", "adaptive_max_pool2d", "(", "out", ",", "(", "1", ",", "self", ".", "block_size", ")", ")", "\n", "p", "=", "self", ".", "conv_p", "(", "rp", ")", ".", "view", "(", "B", ",", "self", ".", "groups", ",", "self", ".", "block_size", ",", "self", ".", "block_size", ")", ".", "sigmoid", "(", ")", "\n", "q", "=", "self", ".", "conv_q", "(", "cp", ")", ".", "view", "(", "B", ",", "self", ".", "groups", ",", "self", ".", "block_size", ",", "self", ".", "block_size", ")", ".", "sigmoid", "(", ")", "\n", "p", "=", "p", "/", "p", ".", "sum", "(", "dim", "=", "3", ",", "keepdim", "=", "True", ")", "\n", "q", "=", "q", "/", "q", ".", "sum", "(", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "p", "=", "p", ".", "view", "(", "B", ",", "self", ".", "groups", ",", "1", ",", "self", ".", "block_size", ",", "self", ".", "block_size", ")", ".", "expand", "(", "x", ".", "size", "(", "\n", "0", ")", ",", "self", ".", "groups", ",", "C", "//", "self", ".", "groups", ",", "self", ".", "block_size", ",", "self", ".", "block_size", ")", ".", "contiguous", "(", ")", "\n", "p", "=", "p", ".", "view", "(", "B", ",", "C", ",", "self", ".", "block_size", ",", "self", ".", "block_size", ")", "\n", "q", "=", "q", ".", "view", "(", "B", ",", "self", ".", "groups", ",", "1", ",", "self", ".", "block_size", ",", "self", ".", "block_size", ")", ".", "expand", "(", "x", ".", "size", "(", "\n", "0", ")", ",", "self", ".", "groups", ",", "C", "//", "self", ".", "groups", ",", "self", ".", "block_size", ",", "self", ".", "block_size", ")", ".", "contiguous", "(", ")", "\n", "q", "=", "q", ".", "view", "(", "B", ",", "C", ",", "self", ".", "block_size", ",", "self", ".", "block_size", ")", "\n", "p", "=", "self", ".", "resize_mat", "(", "p", ",", "H", "//", "self", ".", "block_size", ")", "\n", "q", "=", "self", ".", "resize_mat", "(", "q", ",", "W", "//", "self", ".", "block_size", ")", "\n", "y", "=", "p", ".", "matmul", "(", "x", ")", "\n", "y", "=", "y", ".", "matmul", "(", "q", ")", "\n", "\n", "y", "=", "self", ".", "conv2", "(", "y", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.non_local_attn.BatNonLocalAttn.__init__": [[129, 139], ["torch.nn.Module.__init__", "conv_bn_act.ConvNormAct", "non_local_attn.BilinearAttnTransform", "conv_bn_act.ConvNormAct", "torch.nn.Dropout2d", "helpers.make_divisible"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["def", "__init__", "(", "\n", "self", ",", "in_channels", ",", "block_size", "=", "7", ",", "groups", "=", "2", ",", "rd_ratio", "=", "0.25", ",", "rd_channels", "=", "None", ",", "rd_divisor", "=", "8", ",", "\n", "drop_rate", "=", "0.2", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "**", "_", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "rd_channels", "is", "None", ":", "\n", "            ", "rd_channels", "=", "make_divisible", "(", "in_channels", "*", "rd_ratio", ",", "divisor", "=", "rd_divisor", ")", "\n", "", "self", ".", "conv1", "=", "ConvNormAct", "(", "in_channels", ",", "rd_channels", ",", "1", ",", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "ba", "=", "BilinearAttnTransform", "(", "rd_channels", ",", "block_size", ",", "groups", ",", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "conv2", "=", "ConvNormAct", "(", "rd_channels", ",", "in_channels", ",", "1", ",", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout2d", "(", "p", "=", "drop_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.non_local_attn.BatNonLocalAttn.forward": [[140, 146], ["non_local_attn.BatNonLocalAttn.conv1", "non_local_attn.BatNonLocalAttn.ba", "non_local_attn.BatNonLocalAttn.conv2", "non_local_attn.BatNonLocalAttn.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "xl", "=", "self", ".", "conv1", "(", "x", ")", "\n", "y", "=", "self", ".", "ba", "(", "xl", ")", "\n", "y", "=", "self", ".", "conv2", "(", "y", ")", "\n", "y", "=", "self", ".", "dropout", "(", "y", ")", "\n", "return", "y", "+", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.Swish.__init__": [[21, 24], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "Swish", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inplace", "=", "inplace", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.Swish.forward": [[25, 27], ["activations.swish"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.swish"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "swish", "(", "x", ",", "self", ".", "inplace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.Mish.__init__": [[39, 41], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "Mish", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.Mish.forward": [[42, 44], ["activations.mish"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.mish"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "mish", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.Sigmoid.__init__": [[52, 55], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "Sigmoid", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inplace", "=", "inplace", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.Sigmoid.forward": [[56, 58], ["x.sigmoid_", "x.sigmoid"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", ".", "sigmoid_", "(", ")", "if", "self", ".", "inplace", "else", "x", ".", "sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.Tanh.__init__": [[66, 69], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "Tanh", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inplace", "=", "inplace", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.Tanh.forward": [[70, 72], ["x.tanh_", "x.tanh"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.tanh"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", ".", "tanh_", "(", ")", "if", "self", ".", "inplace", "else", "x", ".", "tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.HardSwish.__init__": [[80, 83], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "HardSwish", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inplace", "=", "inplace", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.HardSwish.forward": [[84, 86], ["activations.hard_swish"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.hard_swish"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "hard_swish", "(", "x", ",", "self", ".", "inplace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.HardSigmoid.__init__": [[96, 99], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "HardSigmoid", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inplace", "=", "inplace", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.HardSigmoid.forward": [[100, 102], ["activations.hard_sigmoid"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.hard_sigmoid"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "hard_sigmoid", "(", "x", ",", "self", ".", "inplace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.HardMish.__init__": [[116, 119], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "HardMish", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inplace", "=", "inplace", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.HardMish.forward": [[120, 122], ["activations.hard_mish"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.hard_mish"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "hard_mish", "(", "x", ",", "self", ".", "inplace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.PReLU.__init__": [[127, 129], ["torch.nn.PReLU.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "num_parameters", ":", "int", "=", "1", ",", "init", ":", "float", "=", "0.25", ",", "inplace", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", "PReLU", ",", "self", ")", ".", "__init__", "(", "num_parameters", "=", "num_parameters", ",", "init", "=", "init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.PReLU.forward": [[130, 132], ["torch.nn.functional.prelu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "return", "F", ".", "prelu", "(", "input", ",", "self", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.GELU.__init__": [[141, 143], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["def", "__init__", "(", "self", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "GELU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.GELU.forward": [[144, 146], ["torch.nn.functional.gelu"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.gelu"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "return", "F", ".", "gelu", "(", "input", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.swish": [[14, 18], ["x.mul_", "x.mul", "x.sigmoid", "x.sigmoid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid"], ["def", "swish", "(", "x", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Swish - Described in: https://arxiv.org/abs/1710.05941\n    \"\"\"", "\n", "return", "x", ".", "mul_", "(", "x", ".", "sigmoid", "(", ")", ")", "if", "inplace", "else", "x", ".", "mul", "(", "x", ".", "sigmoid", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.mish": [[29, 34], ["x.mul", "torch.nn.functional.softplus().tanh", "torch.nn.functional.softplus"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.tanh"], ["", "", "def", "mish", "(", "x", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Mish: A Self Regularized Non-Monotonic Neural Activation Function - https://arxiv.org/abs/1908.08681\n    NOTE: I don't have a working inplace variant\n    \"\"\"", "\n", "return", "x", ".", "mul", "(", "F", ".", "softplus", "(", "x", ")", ".", "tanh", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid": [[46, 48], ["x.sigmoid_", "x.sigmoid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.sigmoid"], ["", "", "def", "sigmoid", "(", "x", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "return", "x", ".", "sigmoid_", "(", ")", "if", "inplace", "else", "x", ".", "sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.tanh": [[60, 62], ["x.tanh_", "x.tanh"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.tanh"], ["", "", "def", "tanh", "(", "x", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "return", "x", ".", "tanh_", "(", ")", "if", "inplace", "else", "x", ".", "tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.hard_swish": [[74, 77], ["torch.nn.functional.relu6().div_", "x.mul_", "x.mul", "torch.nn.functional.relu6"], "function", ["None"], ["", "", "def", "hard_swish", "(", "x", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "inner", "=", "F", ".", "relu6", "(", "x", "+", "3.", ")", ".", "div_", "(", "6.", ")", "\n", "return", "x", ".", "mul_", "(", "inner", ")", "if", "inplace", "else", "x", ".", "mul", "(", "inner", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.hard_sigmoid": [[88, 93], ["x.add_().clamp_().div_", "torch.nn.functional.relu6", "x.add_().clamp_", "x.add_"], "function", ["None"], ["", "", "def", "hard_sigmoid", "(", "x", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "if", "inplace", ":", "\n", "        ", "return", "x", ".", "add_", "(", "3.", ")", ".", "clamp_", "(", "0.", ",", "6.", ")", ".", "div_", "(", "6.", ")", "\n", "", "else", ":", "\n", "        ", "return", "F", ".", "relu6", "(", "x", "+", "3.", ")", "/", "6.", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.hard_mish": [[104, 113], ["x.mul_"], "function", ["None"], ["", "", "def", "hard_mish", "(", "x", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\" Hard Mish\n    Experimental, based on notes by Mish author Diganta Misra at\n      https://github.com/digantamisra98/H-Mish/blob/0da20d4bc58e696b6803f2523c58d3c8a82782d0/README.md\n    \"\"\"", "\n", "if", "inplace", ":", "\n", "        ", "return", "x", ".", "mul_", "(", "0.5", "*", "(", "x", "+", "2", ")", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "2", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "0.5", "*", "x", "*", "(", "x", "+", "2", ")", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.gelu": [[134, 136], ["torch.nn.functional.gelu"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.activations.gelu"], ["", "", "def", "gelu", "(", "x", ":", "torch", ".", "Tensor", ",", "inplace", ":", "bool", "=", "False", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "return", "F", ".", "gelu", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.linear.Linear.forward": [[14, 20], ["torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "linear.Linear.bias.to", "linear.Linear.weight.to"], "methods", ["None"], ["def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "bias", "=", "self", ".", "bias", ".", "to", "(", "dtype", "=", "input", ".", "dtype", ")", "if", "self", ".", "bias", "is", "not", "None", "else", "None", "\n", "return", "F", ".", "linear", "(", "input", ",", "self", ".", "weight", ".", "to", "(", "dtype", "=", "input", ".", "dtype", ")", ",", "bias", "=", "bias", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "linear", "(", "input", ",", "self", ".", "weight", ",", "self", ".", "bias", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dB0.__init__": [[100, 110], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "evo_norm.EvoNorm2dB0.register_buffer", "evo_norm.EvoNorm2dB0.reset_parameters", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "apply_act", "=", "True", ",", "momentum", "=", "0.1", ",", "eps", "=", "1e-3", ",", "**", "_", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "apply_act", "=", "apply_act", "# apply activation (non-linearity)", "\n", "self", ".", "momentum", "=", "momentum", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_features", ")", ")", "\n", "self", ".", "v", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_features", ")", ")", "if", "apply_act", "else", "None", "\n", "self", ".", "register_buffer", "(", "'running_var'", ",", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dB0.reset_parameters": [[111, 116], ["torch.init.ones_", "torch.init.ones_", "torch.init.ones_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.ones_", "torch.init.ones_", "torch.init.ones_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "ones_", "(", "self", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "bias", ")", "\n", "if", "self", ".", "v", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "ones_", "(", "self", ".", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dB0.forward": [[117, 136], ["trace_utils._assert", "x.float().var.add().sqrt_().to().view().expand_as", "evo_norm.EvoNorm2dB0.v.to().view", "evo_norm.EvoNorm2dB0.bias.to().view", "x.dim", "x.float().var", "evo_norm.EvoNorm2dB0.running_var.copy_", "evo_norm.instance_std", "x.float().var.add().sqrt_().to().view().expand_as.max", "evo_norm.EvoNorm2dB0.weight.to().view", "x.numel", "x.float().var.add().sqrt_().to().view", "evo_norm.EvoNorm2dB0.v.to", "evo_norm.EvoNorm2dB0.bias.to", "x.float", "evo_norm.EvoNorm2dB0.weight.to", "x.float().var.add().sqrt_().to", "x.float().var.detach", "x.float().var.add().sqrt_", "x.float().var.add"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.instance_std"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_assert", "(", "x", ".", "dim", "(", ")", "==", "4", ",", "'expected 4D input'", ")", "\n", "x_dtype", "=", "x", ".", "dtype", "\n", "v_shape", "=", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "if", "self", ".", "v", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "training", ":", "\n", "                ", "var", "=", "x", ".", "float", "(", ")", ".", "var", "(", "dim", "=", "(", "0", ",", "2", ",", "3", ")", ",", "unbiased", "=", "False", ")", "\n", "# var = manual_var(x, dim=(0, 2, 3)).squeeze()", "\n", "n", "=", "x", ".", "numel", "(", ")", "/", "x", ".", "shape", "[", "1", "]", "\n", "self", ".", "running_var", ".", "copy_", "(", "\n", "self", ".", "running_var", "*", "(", "1", "-", "self", ".", "momentum", ")", "+", "\n", "var", ".", "detach", "(", ")", "*", "self", ".", "momentum", "*", "(", "n", "/", "(", "n", "-", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "var", "=", "self", ".", "running_var", "\n", "", "left", "=", "var", ".", "add", "(", "self", ".", "eps", ")", ".", "sqrt_", "(", ")", ".", "to", "(", "x_dtype", ")", ".", "view", "(", "v_shape", ")", ".", "expand_as", "(", "x", ")", "\n", "v", "=", "self", ".", "v", ".", "to", "(", "x_dtype", ")", ".", "view", "(", "v_shape", ")", "\n", "right", "=", "x", "*", "v", "+", "instance_std", "(", "x", ",", "self", ".", "eps", ")", "\n", "x", "=", "x", "/", "left", ".", "max", "(", "right", ")", "\n", "", "return", "x", "*", "self", ".", "weight", ".", "to", "(", "x_dtype", ")", ".", "view", "(", "v_shape", ")", "+", "self", ".", "bias", ".", "to", "(", "x_dtype", ")", ".", "view", "(", "v_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dB1.__init__": [[139, 148], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "evo_norm.EvoNorm2dB1.register_buffer", "evo_norm.EvoNorm2dB1.reset_parameters", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "apply_act", "=", "True", ",", "momentum", "=", "0.1", ",", "eps", "=", "1e-5", ",", "**", "_", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "apply_act", "=", "apply_act", "# apply activation (non-linearity)", "\n", "self", ".", "momentum", "=", "momentum", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'running_var'", ",", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dB1.reset_parameters": [[149, 152], ["torch.init.ones_", "torch.init.ones_", "torch.init.ones_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "ones_", "(", "self", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dB1.forward": [[153, 171], ["trace_utils._assert", "x.float().var.to().view", "x.float().var.add().sqrt_", "evo_norm.EvoNorm2dB1.bias.view().to", "x.dim", "x.float().var", "evo_norm.EvoNorm2dB1.running_var.copy_", "evo_norm.instance_rms", "x.float().var.add().sqrt_.max", "evo_norm.EvoNorm2dB1.weight.view().to", "x.numel", "x.float().var.to", "x.float().var.add", "evo_norm.EvoNorm2dB1.bias.view", "x.float", "evo_norm.EvoNorm2dB1.weight.view", "x.float().var.detach().to", "x.float().var.detach"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.instance_rms"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_assert", "(", "x", ".", "dim", "(", ")", "==", "4", ",", "'expected 4D input'", ")", "\n", "x_dtype", "=", "x", ".", "dtype", "\n", "v_shape", "=", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "if", "self", ".", "apply_act", ":", "\n", "            ", "if", "self", ".", "training", ":", "\n", "                ", "var", "=", "x", ".", "float", "(", ")", ".", "var", "(", "dim", "=", "(", "0", ",", "2", ",", "3", ")", ",", "unbiased", "=", "False", ")", "\n", "n", "=", "x", ".", "numel", "(", ")", "/", "x", ".", "shape", "[", "1", "]", "\n", "self", ".", "running_var", ".", "copy_", "(", "\n", "self", ".", "running_var", "*", "(", "1", "-", "self", ".", "momentum", ")", "+", "\n", "var", ".", "detach", "(", ")", ".", "to", "(", "self", ".", "running_var", ".", "dtype", ")", "*", "self", ".", "momentum", "*", "(", "n", "/", "(", "n", "-", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "var", "=", "self", ".", "running_var", "\n", "", "var", "=", "var", ".", "to", "(", "x_dtype", ")", ".", "view", "(", "v_shape", ")", "\n", "left", "=", "var", ".", "add", "(", "self", ".", "eps", ")", ".", "sqrt_", "(", ")", "\n", "right", "=", "(", "x", "+", "1", ")", "*", "instance_rms", "(", "x", ",", "self", ".", "eps", ")", "\n", "x", "=", "x", "/", "left", ".", "max", "(", "right", ")", "\n", "", "return", "x", "*", "self", ".", "weight", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "+", "self", ".", "bias", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dB2.__init__": [[174, 183], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "evo_norm.EvoNorm2dB2.register_buffer", "evo_norm.EvoNorm2dB2.reset_parameters", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "apply_act", "=", "True", ",", "momentum", "=", "0.1", ",", "eps", "=", "1e-5", ",", "**", "_", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "apply_act", "=", "apply_act", "# apply activation (non-linearity)", "\n", "self", ".", "momentum", "=", "momentum", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'running_var'", ",", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dB2.reset_parameters": [[184, 187], ["torch.init.ones_", "torch.init.ones_", "torch.init.ones_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "ones_", "(", "self", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dB2.forward": [[188, 206], ["trace_utils._assert", "x.float().var.to().view", "x.float().var.add().sqrt_", "evo_norm.EvoNorm2dB2.bias.view().to", "x.dim", "x.float().var", "evo_norm.EvoNorm2dB2.running_var.copy_", "evo_norm.instance_rms", "x.float().var.add().sqrt_.max", "evo_norm.EvoNorm2dB2.weight.view().to", "x.numel", "x.float().var.to", "x.float().var.add", "evo_norm.EvoNorm2dB2.bias.view", "x.float", "evo_norm.EvoNorm2dB2.weight.view", "x.float().var.detach().to", "x.float().var.detach"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.instance_rms"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_assert", "(", "x", ".", "dim", "(", ")", "==", "4", ",", "'expected 4D input'", ")", "\n", "x_dtype", "=", "x", ".", "dtype", "\n", "v_shape", "=", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "if", "self", ".", "apply_act", ":", "\n", "            ", "if", "self", ".", "training", ":", "\n", "                ", "var", "=", "x", ".", "float", "(", ")", ".", "var", "(", "dim", "=", "(", "0", ",", "2", ",", "3", ")", ",", "unbiased", "=", "False", ")", "\n", "n", "=", "x", ".", "numel", "(", ")", "/", "x", ".", "shape", "[", "1", "]", "\n", "self", ".", "running_var", ".", "copy_", "(", "\n", "self", ".", "running_var", "*", "(", "1", "-", "self", ".", "momentum", ")", "+", "\n", "var", ".", "detach", "(", ")", ".", "to", "(", "self", ".", "running_var", ".", "dtype", ")", "*", "self", ".", "momentum", "*", "(", "n", "/", "(", "n", "-", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "var", "=", "self", ".", "running_var", "\n", "", "var", "=", "var", ".", "to", "(", "x_dtype", ")", ".", "view", "(", "v_shape", ")", "\n", "left", "=", "var", ".", "add", "(", "self", ".", "eps", ")", ".", "sqrt_", "(", ")", "\n", "right", "=", "instance_rms", "(", "x", ",", "self", ".", "eps", ")", "-", "x", "\n", "x", "=", "x", "/", "left", ".", "max", "(", "right", ")", "\n", "", "return", "x", "*", "self", ".", "weight", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "+", "self", ".", "bias", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dS0.__init__": [[209, 222], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "evo_norm.EvoNorm2dS0.reset_parameters", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "groups", "=", "32", ",", "group_size", "=", "None", ",", "apply_act", "=", "True", ",", "eps", "=", "1e-5", ",", "**", "_", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "apply_act", "=", "apply_act", "# apply activation (non-linearity)", "\n", "if", "group_size", ":", "\n", "            ", "assert", "num_features", "%", "group_size", "==", "0", "\n", "self", ".", "groups", "=", "num_features", "//", "group_size", "\n", "", "else", ":", "\n", "            ", "self", ".", "groups", "=", "groups", "\n", "", "self", ".", "eps", "=", "eps", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_features", ")", ")", "\n", "self", ".", "v", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_features", ")", ")", "if", "apply_act", "else", "None", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dS0.reset_parameters": [[223, 228], ["torch.init.ones_", "torch.init.ones_", "torch.init.ones_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.ones_", "torch.init.ones_", "torch.init.ones_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "ones_", "(", "self", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "bias", ")", "\n", "if", "self", ".", "v", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "ones_", "(", "self", ".", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dS0.forward": [[229, 237], ["trace_utils._assert", "evo_norm.EvoNorm2dS0.v.view().to", "evo_norm.EvoNorm2dS0.bias.view().to", "x.dim", "evo_norm.group_std", "evo_norm.EvoNorm2dS0.weight.view().to", "evo_norm.EvoNorm2dS0.v.view", "evo_norm.EvoNorm2dS0.bias.view", "evo_norm.EvoNorm2dS0.weight.view"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.group_std"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_assert", "(", "x", ".", "dim", "(", ")", "==", "4", ",", "'expected 4D input'", ")", "\n", "x_dtype", "=", "x", ".", "dtype", "\n", "v_shape", "=", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "if", "self", ".", "v", "is", "not", "None", ":", "\n", "            ", "v", "=", "self", ".", "v", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "\n", "x", "=", "x", "*", "(", "x", "*", "v", ")", ".", "sigmoid", "(", ")", "/", "group_std", "(", "x", ",", "self", ".", "groups", ",", "self", ".", "eps", ")", "\n", "", "return", "x", "*", "self", ".", "weight", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "+", "self", ".", "bias", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dS0a.__init__": [[240, 243], ["evo_norm.EvoNorm2dS0.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "groups", "=", "32", ",", "group_size", "=", "None", ",", "apply_act", "=", "True", ",", "eps", "=", "1e-3", ",", "**", "_", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "num_features", ",", "groups", "=", "groups", ",", "group_size", "=", "group_size", ",", "apply_act", "=", "apply_act", ",", "eps", "=", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dS0a.forward": [[244, 254], ["trace_utils._assert", "evo_norm.group_std", "evo_norm.EvoNorm2dS0a.v.view().to", "evo_norm.EvoNorm2dS0a.bias.view().to", "x.dim", "evo_norm.EvoNorm2dS0a.weight.view().to", "evo_norm.EvoNorm2dS0a.v.view", "evo_norm.EvoNorm2dS0a.bias.view", "evo_norm.EvoNorm2dS0a.weight.view"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.group_std"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_assert", "(", "x", ".", "dim", "(", ")", "==", "4", ",", "'expected 4D input'", ")", "\n", "x_dtype", "=", "x", ".", "dtype", "\n", "v_shape", "=", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "d", "=", "group_std", "(", "x", ",", "self", ".", "groups", ",", "self", ".", "eps", ")", "\n", "if", "self", ".", "v", "is", "not", "None", ":", "\n", "            ", "v", "=", "self", ".", "v", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "\n", "x", "=", "x", "*", "(", "x", "*", "v", ")", ".", "sigmoid", "(", ")", "\n", "", "x", "=", "x", "/", "d", "\n", "return", "x", "*", "self", ".", "weight", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "+", "self", ".", "bias", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dS1.__init__": [[257, 276], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "evo_norm.EvoNorm2dS1.reset_parameters", "create_act.create_act_layer", "torch.Identity", "torch.Identity", "torch.Identity", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer"], ["    ", "def", "__init__", "(", "\n", "self", ",", "num_features", ",", "groups", "=", "32", ",", "group_size", "=", "None", ",", "\n", "apply_act", "=", "True", ",", "act_layer", "=", "nn", ".", "SiLU", ",", "eps", "=", "1e-5", ",", "**", "_", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "apply_act", "=", "apply_act", "# apply activation (non-linearity)", "\n", "if", "act_layer", "is", "not", "None", "and", "apply_act", ":", "\n", "            ", "self", ".", "act", "=", "create_act_layer", "(", "act_layer", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "act", "=", "nn", ".", "Identity", "(", ")", "\n", "", "if", "group_size", ":", "\n", "            ", "assert", "num_features", "%", "group_size", "==", "0", "\n", "self", ".", "groups", "=", "num_features", "//", "group_size", "\n", "", "else", ":", "\n", "            ", "self", ".", "groups", "=", "groups", "\n", "", "self", ".", "eps", "=", "eps", "\n", "self", ".", "pre_act_norm", "=", "False", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_features", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dS1.reset_parameters": [[277, 280], ["torch.init.ones_", "torch.init.ones_", "torch.init.ones_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "ones_", "(", "self", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dS1.forward": [[281, 288], ["trace_utils._assert", "evo_norm.EvoNorm2dS1.bias.view().to", "x.dim", "evo_norm.EvoNorm2dS1.act", "evo_norm.group_std", "evo_norm.EvoNorm2dS1.weight.view().to", "evo_norm.EvoNorm2dS1.bias.view", "evo_norm.EvoNorm2dS1.weight.view"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.group_std"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_assert", "(", "x", ".", "dim", "(", ")", "==", "4", ",", "'expected 4D input'", ")", "\n", "x_dtype", "=", "x", ".", "dtype", "\n", "v_shape", "=", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "if", "self", ".", "apply_act", ":", "\n", "            ", "x", "=", "self", ".", "act", "(", "x", ")", "/", "group_std", "(", "x", ",", "self", ".", "groups", ",", "self", ".", "eps", ")", "\n", "", "return", "x", "*", "self", ".", "weight", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "+", "self", ".", "bias", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dS1a.__init__": [[291, 296], ["evo_norm.EvoNorm2dS1.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "num_features", ",", "groups", "=", "32", ",", "group_size", "=", "None", ",", "\n", "apply_act", "=", "True", ",", "act_layer", "=", "nn", ".", "SiLU", ",", "eps", "=", "1e-3", ",", "**", "_", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "num_features", ",", "groups", "=", "groups", ",", "group_size", "=", "group_size", ",", "apply_act", "=", "apply_act", ",", "act_layer", "=", "act_layer", ",", "eps", "=", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dS1a.forward": [[297, 303], ["trace_utils._assert", "evo_norm.EvoNorm2dS1a.act", "evo_norm.group_std", "evo_norm.EvoNorm2dS1a.bias.view().to", "x.dim", "evo_norm.EvoNorm2dS1a.weight.view().to", "evo_norm.EvoNorm2dS1a.bias.view", "evo_norm.EvoNorm2dS1a.weight.view"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.group_std"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_assert", "(", "x", ".", "dim", "(", ")", "==", "4", ",", "'expected 4D input'", ")", "\n", "x_dtype", "=", "x", ".", "dtype", "\n", "v_shape", "=", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "/", "group_std", "(", "x", ",", "self", ".", "groups", ",", "self", ".", "eps", ")", "\n", "return", "x", "*", "self", ".", "weight", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "+", "self", ".", "bias", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dS2.__init__": [[306, 324], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "evo_norm.EvoNorm2dS2.reset_parameters", "create_act.create_act_layer", "torch.Identity", "torch.Identity", "torch.Identity", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer"], ["    ", "def", "__init__", "(", "\n", "self", ",", "num_features", ",", "groups", "=", "32", ",", "group_size", "=", "None", ",", "\n", "apply_act", "=", "True", ",", "act_layer", "=", "nn", ".", "SiLU", ",", "eps", "=", "1e-5", ",", "**", "_", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "apply_act", "=", "apply_act", "# apply activation (non-linearity)", "\n", "if", "act_layer", "is", "not", "None", "and", "apply_act", ":", "\n", "            ", "self", ".", "act", "=", "create_act_layer", "(", "act_layer", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "act", "=", "nn", ".", "Identity", "(", ")", "\n", "", "if", "group_size", ":", "\n", "            ", "assert", "num_features", "%", "group_size", "==", "0", "\n", "self", ".", "groups", "=", "num_features", "//", "group_size", "\n", "", "else", ":", "\n", "            ", "self", ".", "groups", "=", "groups", "\n", "", "self", ".", "eps", "=", "eps", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_features", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dS2.reset_parameters": [[325, 328], ["torch.init.ones_", "torch.init.ones_", "torch.init.ones_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "ones_", "(", "self", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dS2.forward": [[329, 336], ["trace_utils._assert", "evo_norm.EvoNorm2dS2.bias.view().to", "x.dim", "evo_norm.EvoNorm2dS2.act", "evo_norm.group_rms", "evo_norm.EvoNorm2dS2.weight.view().to", "evo_norm.EvoNorm2dS2.bias.view", "evo_norm.EvoNorm2dS2.weight.view"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.group_rms"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_assert", "(", "x", ".", "dim", "(", ")", "==", "4", ",", "'expected 4D input'", ")", "\n", "x_dtype", "=", "x", ".", "dtype", "\n", "v_shape", "=", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "if", "self", ".", "apply_act", ":", "\n", "            ", "x", "=", "self", ".", "act", "(", "x", ")", "/", "group_rms", "(", "x", ",", "self", ".", "groups", ",", "self", ".", "eps", ")", "\n", "", "return", "x", "*", "self", ".", "weight", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "+", "self", ".", "bias", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dS2a.__init__": [[339, 344], ["evo_norm.EvoNorm2dS2.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "num_features", ",", "groups", "=", "32", ",", "group_size", "=", "None", ",", "\n", "apply_act", "=", "True", ",", "act_layer", "=", "nn", ".", "SiLU", ",", "eps", "=", "1e-3", ",", "**", "_", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "num_features", ",", "groups", "=", "groups", ",", "group_size", "=", "group_size", ",", "apply_act", "=", "apply_act", ",", "act_layer", "=", "act_layer", ",", "eps", "=", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.EvoNorm2dS2a.forward": [[345, 351], ["trace_utils._assert", "evo_norm.EvoNorm2dS2a.act", "evo_norm.group_rms", "evo_norm.EvoNorm2dS2a.bias.view().to", "x.dim", "evo_norm.EvoNorm2dS2a.weight.view().to", "evo_norm.EvoNorm2dS2a.bias.view", "evo_norm.EvoNorm2dS2a.weight.view"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.group_rms"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_assert", "(", "x", ".", "dim", "(", ")", "==", "4", ",", "'expected 4D input'", ")", "\n", "x_dtype", "=", "x", ".", "dtype", "\n", "v_shape", "=", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "/", "group_rms", "(", "x", ",", "self", ".", "groups", ",", "self", ".", "eps", ")", "\n", "return", "x", "*", "self", ".", "weight", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "+", "self", ".", "bias", ".", "view", "(", "v_shape", ")", ".", "to", "(", "x_dtype", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.instance_std": [[36, 39], ["x.float().var().add().sqrt().to", "x.float().var().add().sqrt().to.expand", "x.float().var().add().sqrt", "x.float().var().add", "x.float().var", "x.float"], "function", ["None"], ["def", "instance_std", "(", "x", ",", "eps", ":", "float", "=", "1e-5", ")", ":", "\n", "    ", "std", "=", "x", ".", "float", "(", ")", ".", "var", "(", "dim", "=", "(", "2", ",", "3", ")", ",", "unbiased", "=", "False", ",", "keepdim", "=", "True", ")", ".", "add", "(", "eps", ")", ".", "sqrt", "(", ")", ".", "to", "(", "x", ".", "dtype", ")", "\n", "return", "std", ".", "expand", "(", "x", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.instance_std_tpu": [[41, 44], ["manual_var().add().sqrt", "manual_var().add().sqrt.expand", "manual_var().add", "evo_norm.manual_var"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.manual_var"], ["", "def", "instance_std_tpu", "(", "x", ",", "eps", ":", "float", "=", "1e-5", ")", ":", "\n", "    ", "std", "=", "manual_var", "(", "x", ",", "dim", "=", "(", "2", ",", "3", ")", ")", ".", "add", "(", "eps", ")", ".", "sqrt", "(", ")", "\n", "return", "std", ".", "expand", "(", "x", ".", "shape", ")", "\n", "# instance_std = instance_std_tpu", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.instance_rms": [[47, 50], ["x.float().square().mean().add().sqrt().to", "x.float().square().mean().add().sqrt().to.expand", "x.float().square().mean().add().sqrt", "x.float().square().mean().add", "x.float().square().mean", "x.float().square", "x.float"], "function", ["None"], ["", "def", "instance_rms", "(", "x", ",", "eps", ":", "float", "=", "1e-5", ")", ":", "\n", "    ", "rms", "=", "x", ".", "float", "(", ")", ".", "square", "(", ")", ".", "mean", "(", "dim", "=", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", ".", "add", "(", "eps", ")", ".", "sqrt", "(", ")", ".", "to", "(", "x", ".", "dtype", ")", "\n", "return", "rms", ".", "expand", "(", "x", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.manual_var": [[52, 60], ["x.mean"], "function", ["None"], ["", "def", "manual_var", "(", "x", ",", "dim", ":", "Union", "[", "int", ",", "Sequence", "[", "int", "]", "]", ",", "diff_sqm", ":", "bool", "=", "False", ")", ":", "\n", "    ", "xm", "=", "x", ".", "mean", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "\n", "if", "diff_sqm", ":", "\n", "# difference of squared mean and mean squared, faster on TPU can be less stable", "\n", "        ", "var", "=", "(", "(", "x", "*", "x", ")", ".", "mean", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "-", "(", "xm", "*", "xm", ")", ")", ".", "clamp", "(", "0", ")", "\n", "", "else", ":", "\n", "        ", "var", "=", "(", "(", "x", "-", "xm", ")", "*", "(", "x", "-", "xm", ")", ")", ".", "mean", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "\n", "", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.group_std": [[62, 73], ["trace_utils._assert", "x.float().var().add().sqrt().to.expand().reshape", "x.reshape.reshape", "x.reshape.float().var().add().sqrt().to", "x.reshape.reshape", "x.reshape.float().var().add().sqrt().to", "x.float().var().add().sqrt().to.expand", "x.reshape.float().var().add().sqrt", "x.reshape.float().var().add().sqrt", "x.reshape.float().var().add", "x.reshape.float().var().add", "x.reshape.float().var", "x.reshape.float().var", "x.reshape.float", "x.reshape.float"], "function", ["None"], ["", "def", "group_std", "(", "x", ",", "groups", ":", "int", "=", "32", ",", "eps", ":", "float", "=", "1e-5", ",", "flatten", ":", "bool", "=", "False", ")", ":", "\n", "    ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "x_dtype", "=", "x", ".", "dtype", "\n", "_assert", "(", "C", "%", "groups", "==", "0", ",", "''", ")", "\n", "if", "flatten", ":", "\n", "        ", "x", "=", "x", ".", "reshape", "(", "B", ",", "groups", ",", "-", "1", ")", "# FIXME simpler shape causing TPU / XLA issues", "\n", "std", "=", "x", ".", "float", "(", ")", ".", "var", "(", "dim", "=", "2", ",", "unbiased", "=", "False", ",", "keepdim", "=", "True", ")", ".", "add", "(", "eps", ")", ".", "sqrt", "(", ")", ".", "to", "(", "x_dtype", ")", "\n", "", "else", ":", "\n", "        ", "x", "=", "x", ".", "reshape", "(", "B", ",", "groups", ",", "C", "//", "groups", ",", "H", ",", "W", ")", "\n", "std", "=", "x", ".", "float", "(", ")", ".", "var", "(", "dim", "=", "(", "2", ",", "3", ",", "4", ")", ",", "unbiased", "=", "False", ",", "keepdim", "=", "True", ")", ".", "add", "(", "eps", ")", ".", "sqrt", "(", ")", ".", "to", "(", "x_dtype", ")", "\n", "", "return", "std", ".", "expand", "(", "x", ".", "shape", ")", ".", "reshape", "(", "B", ",", "C", ",", "H", ",", "W", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.group_std_tpu": [[75, 87], ["trace_utils._assert", "manual_var.add().sqrt().expand().reshape", "x.reshape.reshape", "evo_norm.manual_var", "x.reshape.reshape", "evo_norm.manual_var", "manual_var.add().sqrt().expand", "manual_var.add().sqrt", "manual_var.add"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.manual_var", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.manual_var"], ["", "def", "group_std_tpu", "(", "x", ",", "groups", ":", "int", "=", "32", ",", "eps", ":", "float", "=", "1e-5", ",", "diff_sqm", ":", "bool", "=", "False", ",", "flatten", ":", "bool", "=", "False", ")", ":", "\n", "# This is a workaround for some stability / odd behaviour of .var and .std", "\n", "# running on PyTorch XLA w/ TPUs. These manual var impl are producing much better results", "\n", "    ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "_assert", "(", "C", "%", "groups", "==", "0", ",", "''", ")", "\n", "if", "flatten", ":", "\n", "        ", "x", "=", "x", ".", "reshape", "(", "B", ",", "groups", ",", "-", "1", ")", "# FIXME simpler shape causing TPU / XLA issues", "\n", "var", "=", "manual_var", "(", "x", ",", "dim", "=", "-", "1", ",", "diff_sqm", "=", "diff_sqm", ")", "\n", "", "else", ":", "\n", "        ", "x", "=", "x", ".", "reshape", "(", "B", ",", "groups", ",", "C", "//", "groups", ",", "H", ",", "W", ")", "\n", "var", "=", "manual_var", "(", "x", ",", "dim", "=", "(", "2", ",", "3", ",", "4", ")", ",", "diff_sqm", "=", "diff_sqm", ")", "\n", "", "return", "var", ".", "add", "(", "eps", ")", ".", "sqrt", "(", ")", ".", "expand", "(", "x", ".", "shape", ")", ".", "reshape", "(", "B", ",", "C", ",", "H", ",", "W", ")", "\n", "#group_std = group_std_tpu  # FIXME TPU temporary", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.evo_norm.group_rms": [[90, 97], ["trace_utils._assert", "x.reshape.reshape", "x.reshape.float().square().mean().add().sqrt_().to", "x.float().square().mean().add().sqrt_().to.expand().reshape", "x.reshape.float().square().mean().add().sqrt_", "x.float().square().mean().add().sqrt_().to.expand", "x.reshape.float().square().mean().add", "x.reshape.float().square().mean", "x.reshape.float().square", "x.reshape.float"], "function", ["None"], ["", "def", "group_rms", "(", "x", ",", "groups", ":", "int", "=", "32", ",", "eps", ":", "float", "=", "1e-5", ")", ":", "\n", "    ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "_assert", "(", "C", "%", "groups", "==", "0", ",", "''", ")", "\n", "x_dtype", "=", "x", ".", "dtype", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "groups", ",", "C", "//", "groups", ",", "H", ",", "W", ")", "\n", "rms", "=", "x", ".", "float", "(", ")", ".", "square", "(", ")", ".", "mean", "(", "dim", "=", "(", "2", ",", "3", ",", "4", ")", ",", "keepdim", "=", "True", ")", ".", "add", "(", "eps", ")", ".", "sqrt_", "(", ")", ".", "to", "(", "x_dtype", ")", "\n", "return", "rms", ".", "expand", "(", "x", ".", "shape", ")", ".", "reshape", "(", "B", ",", "C", ",", "H", ",", "W", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.squeeze_excite.SEModule.__init__": [[28, 40], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "create_act.create_act_layer", "torch.nn.Conv2d", "create_act.create_act_layer", "helpers.make_divisible", "norm_layer", "torch.nn.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["def", "__init__", "(", "\n", "self", ",", "channels", ",", "rd_ratio", "=", "1.", "/", "16", ",", "rd_channels", "=", "None", ",", "rd_divisor", "=", "8", ",", "add_maxpool", "=", "False", ",", "\n", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "None", ",", "gate_layer", "=", "'sigmoid'", ")", ":", "\n", "        ", "super", "(", "SEModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "add_maxpool", "=", "add_maxpool", "\n", "if", "not", "rd_channels", ":", "\n", "            ", "rd_channels", "=", "make_divisible", "(", "channels", "*", "rd_ratio", ",", "rd_divisor", ",", "round_limit", "=", "0.", ")", "\n", "", "self", ".", "fc1", "=", "nn", ".", "Conv2d", "(", "channels", ",", "rd_channels", ",", "kernel_size", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "bn", "=", "norm_layer", "(", "rd_channels", ")", "if", "norm_layer", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "act", "=", "create_act_layer", "(", "act_layer", ",", "inplace", "=", "True", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Conv2d", "(", "rd_channels", ",", "channels", ",", "kernel_size", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "gate", "=", "create_act_layer", "(", "gate_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.squeeze_excite.SEModule.forward": [[41, 50], ["x.mean", "squeeze_excite.SEModule.fc1", "squeeze_excite.SEModule.act", "squeeze_excite.SEModule.fc2", "squeeze_excite.SEModule.bn", "squeeze_excite.SEModule.gate", "x.amax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_se", "=", "x", ".", "mean", "(", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "if", "self", ".", "add_maxpool", ":", "\n", "# experimental codepath, may remove or change", "\n", "            ", "x_se", "=", "0.5", "*", "x_se", "+", "0.5", "*", "x", ".", "amax", "(", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "", "x_se", "=", "self", ".", "fc1", "(", "x_se", ")", "\n", "x_se", "=", "self", ".", "act", "(", "self", ".", "bn", "(", "x_se", ")", ")", "\n", "x_se", "=", "self", ".", "fc2", "(", "x_se", ")", "\n", "return", "x", "*", "self", ".", "gate", "(", "x_se", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.squeeze_excite.EffectiveSEModule.__init__": [[59, 64], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "create_act.create_act_layer"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer"], ["def", "__init__", "(", "self", ",", "channels", ",", "add_maxpool", "=", "False", ",", "gate_layer", "=", "'hard_sigmoid'", ",", "**", "_", ")", ":", "\n", "        ", "super", "(", "EffectiveSEModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "add_maxpool", "=", "add_maxpool", "\n", "self", ".", "fc", "=", "nn", ".", "Conv2d", "(", "channels", ",", "channels", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", "\n", "self", ".", "gate", "=", "create_act_layer", "(", "gate_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.squeeze_excite.EffectiveSEModule.forward": [[65, 72], ["x.mean", "squeeze_excite.EffectiveSEModule.fc", "squeeze_excite.EffectiveSEModule.gate", "x.amax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_se", "=", "x", ".", "mean", "(", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "if", "self", ".", "add_maxpool", ":", "\n", "# experimental codepath, may remove or change", "\n", "            ", "x_se", "=", "0.5", "*", "x_se", "+", "0.5", "*", "x", ".", "amax", "(", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "", "x_se", "=", "self", ".", "fc", "(", "x_se", ")", "\n", "return", "x", "*", "self", ".", "gate", "(", "x_se", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.create_norm_act_layer": [[43, 49], ["create_norm_act.get_norm_act_layer", "get_norm_act_layer.", "torch.jit.script"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer"], ["def", "create_norm_act_layer", "(", "layer_name", ",", "num_features", ",", "act_layer", "=", "None", ",", "apply_act", "=", "True", ",", "jit", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "layer", "=", "get_norm_act_layer", "(", "layer_name", ",", "act_layer", "=", "act_layer", ")", "\n", "layer_instance", "=", "layer", "(", "num_features", ",", "apply_act", "=", "apply_act", ",", "**", "kwargs", ")", "\n", "if", "jit", ":", "\n", "        ", "layer_instance", "=", "torch", ".", "jit", ".", "script", "(", "layer_instance", ")", "\n", "", "return", "layer_instance", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_norm_act.get_norm_act_layer": [[51, 89], ["isinstance", "isinstance", "isinstance", "isinstance", "norm_act_kwargs.update", "_NORM_ACT_MAP.get", "norm_act_kwargs.setdefault", "functools.partial", "norm_layer.replace().lower().split", "isinstance", "norm_layer.__name__.lower", "norm_layer.__name__.lower.startswith", "norm_layer.replace().lower", "norm_layer.__name__.lower.startswith", "norm_layer.__name__.lower.startswith", "norm_layer.replace", "norm_layer.__name__.lower.startswith"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.features.FeatureInfo.get"], ["", "def", "get_norm_act_layer", "(", "norm_layer", ",", "act_layer", "=", "None", ")", ":", "\n", "    ", "assert", "isinstance", "(", "norm_layer", ",", "(", "type", ",", "str", ",", "types", ".", "FunctionType", ",", "functools", ".", "partial", ")", ")", "\n", "assert", "act_layer", "is", "None", "or", "isinstance", "(", "act_layer", ",", "(", "type", ",", "str", ",", "types", ".", "FunctionType", ",", "functools", ".", "partial", ")", ")", "\n", "norm_act_kwargs", "=", "{", "}", "\n", "\n", "# unbind partial fn, so args can be rebound later", "\n", "if", "isinstance", "(", "norm_layer", ",", "functools", ".", "partial", ")", ":", "\n", "        ", "norm_act_kwargs", ".", "update", "(", "norm_layer", ".", "keywords", ")", "\n", "norm_layer", "=", "norm_layer", ".", "func", "\n", "\n", "", "if", "isinstance", "(", "norm_layer", ",", "str", ")", ":", "\n", "        ", "layer_name", "=", "norm_layer", ".", "replace", "(", "'_'", ",", "''", ")", ".", "lower", "(", ")", ".", "split", "(", "'-'", ")", "[", "0", "]", "\n", "norm_act_layer", "=", "_NORM_ACT_MAP", ".", "get", "(", "layer_name", ",", "None", ")", "\n", "", "elif", "norm_layer", "in", "_NORM_ACT_TYPES", ":", "\n", "        ", "norm_act_layer", "=", "norm_layer", "\n", "", "elif", "isinstance", "(", "norm_layer", ",", "types", ".", "FunctionType", ")", ":", "\n", "# if function type, must be a lambda/fn that creates a norm_act layer", "\n", "        ", "norm_act_layer", "=", "norm_layer", "\n", "", "else", ":", "\n", "        ", "type_name", "=", "norm_layer", ".", "__name__", ".", "lower", "(", ")", "\n", "if", "type_name", ".", "startswith", "(", "'batchnorm'", ")", ":", "\n", "            ", "norm_act_layer", "=", "BatchNormAct2d", "\n", "", "elif", "type_name", ".", "startswith", "(", "'groupnorm'", ")", ":", "\n", "            ", "norm_act_layer", "=", "GroupNormAct", "\n", "", "elif", "type_name", ".", "startswith", "(", "'layernorm2d'", ")", ":", "\n", "            ", "norm_act_layer", "=", "LayerNormAct2d", "\n", "", "elif", "type_name", ".", "startswith", "(", "'layernorm'", ")", ":", "\n", "            ", "norm_act_layer", "=", "LayerNormAct", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "f\"No equivalent norm_act layer for {type_name}\"", "\n", "\n", "", "", "if", "norm_act_layer", "in", "_NORM_ACT_REQUIRES_ARG", ":", "\n", "# pass `act_layer` through for backwards compat where `act_layer=None` implies no activation.", "\n", "# In the future, may force use of `apply_act` with `act_layer` arg bound to relevant NormAct types", "\n", "        ", "norm_act_kwargs", ".", "setdefault", "(", "'act_layer'", ",", "act_layer", ")", "\n", "", "if", "norm_act_kwargs", ":", "\n", "        ", "norm_act_layer", "=", "functools", ".", "partial", "(", "norm_act_layer", ",", "**", "norm_act_kwargs", ")", "# bind/rebind args", "\n", "", "return", "norm_act_layer", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.gather_excite.GatherExcite.__init__": [[28, 69], ["torch.nn.Module.__init__", "create_act.get_act_layer", "create_act.create_act_layer", "torch.nn.Sequential", "helpers.make_divisible", "mlp.ConvMlp", "torch.nn.Identity", "gather_excite.GatherExcite.gather.add_module", "int", "range", "create_conv2d.create_conv2d.create_conv2d", "gather_excite.GatherExcite.gather.add_module", "math.log2", "gather_excite.GatherExcite.gather.add_module", "torch.nn.BatchNorm2d", "create_conv2d.create_conv2d.create_conv2d", "gather_excite.GatherExcite.gather.add_module", "gather_excite.GatherExcite.gather.add_module", "torch.nn.BatchNorm2d", "create_act.get_act_layer."], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.create_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_conv2d.create_conv2d"], ["def", "__init__", "(", "\n", "self", ",", "channels", ",", "feat_size", "=", "None", ",", "extra_params", "=", "False", ",", "extent", "=", "0", ",", "use_mlp", "=", "True", ",", "\n", "rd_ratio", "=", "1.", "/", "16", ",", "rd_channels", "=", "None", ",", "rd_divisor", "=", "1", ",", "add_maxpool", "=", "False", ",", "\n", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "gate_layer", "=", "'sigmoid'", ")", ":", "\n", "        ", "super", "(", "GatherExcite", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "add_maxpool", "=", "add_maxpool", "\n", "act_layer", "=", "get_act_layer", "(", "act_layer", ")", "\n", "self", ".", "extent", "=", "extent", "\n", "if", "extra_params", ":", "\n", "            ", "self", ".", "gather", "=", "nn", ".", "Sequential", "(", ")", "\n", "if", "extent", "==", "0", ":", "\n", "                ", "assert", "feat_size", "is", "not", "None", ",", "'spatial feature size must be specified for global extent w/ params'", "\n", "self", ".", "gather", ".", "add_module", "(", "\n", "'conv1'", ",", "create_conv2d", "(", "channels", ",", "channels", ",", "kernel_size", "=", "feat_size", ",", "stride", "=", "1", ",", "depthwise", "=", "True", ")", ")", "\n", "if", "norm_layer", ":", "\n", "                    ", "self", ".", "gather", ".", "add_module", "(", "f'norm1'", ",", "nn", ".", "BatchNorm2d", "(", "channels", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "assert", "extent", "%", "2", "==", "0", "\n", "num_conv", "=", "int", "(", "math", ".", "log2", "(", "extent", ")", ")", "\n", "for", "i", "in", "range", "(", "num_conv", ")", ":", "\n", "                    ", "self", ".", "gather", ".", "add_module", "(", "\n", "f'conv{i + 1}'", ",", "\n", "create_conv2d", "(", "channels", ",", "channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "depthwise", "=", "True", ")", ")", "\n", "if", "norm_layer", ":", "\n", "                        ", "self", ".", "gather", ".", "add_module", "(", "f'norm{i + 1}'", ",", "nn", ".", "BatchNorm2d", "(", "channels", ")", ")", "\n", "", "if", "i", "!=", "num_conv", "-", "1", ":", "\n", "                        ", "self", ".", "gather", ".", "add_module", "(", "f'act{i + 1}'", ",", "act_layer", "(", "inplace", "=", "True", ")", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "self", ".", "gather", "=", "None", "\n", "if", "self", ".", "extent", "==", "0", ":", "\n", "                ", "self", ".", "gk", "=", "0", "\n", "self", ".", "gs", "=", "0", "\n", "", "else", ":", "\n", "                ", "assert", "extent", "%", "2", "==", "0", "\n", "self", ".", "gk", "=", "self", ".", "extent", "*", "2", "-", "1", "\n", "self", ".", "gs", "=", "self", ".", "extent", "\n", "\n", "", "", "if", "not", "rd_channels", ":", "\n", "            ", "rd_channels", "=", "make_divisible", "(", "channels", "*", "rd_ratio", ",", "rd_divisor", ",", "round_limit", "=", "0.", ")", "\n", "", "self", ".", "mlp", "=", "ConvMlp", "(", "channels", ",", "rd_channels", ",", "act_layer", "=", "act_layer", ")", "if", "use_mlp", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "gate", "=", "create_act_layer", "(", "gate_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.gather_excite.GatherExcite.forward": [[70, 91], ["gather_excite.GatherExcite.mlp", "gather_excite.GatherExcite.gather", "torch.interpolate", "gather_excite.GatherExcite.gate", "x.mean", "torch.avg_pool2d", "x.amax", "torch.max_pool2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.models.coat.ParallelBlock.interpolate"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "size", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "\n", "if", "self", ".", "gather", "is", "not", "None", ":", "\n", "            ", "x_ge", "=", "self", ".", "gather", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "extent", "==", "0", ":", "\n", "# global extent", "\n", "                ", "x_ge", "=", "x", ".", "mean", "(", "dim", "=", "(", "2", ",", "3", ")", ",", "keepdims", "=", "True", ")", "\n", "if", "self", ".", "add_maxpool", ":", "\n", "# experimental codepath, may remove or change", "\n", "                    ", "x_ge", "=", "0.5", "*", "x_ge", "+", "0.5", "*", "x", ".", "amax", "(", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "", "", "else", ":", "\n", "                ", "x_ge", "=", "F", ".", "avg_pool2d", "(", "\n", "x", ",", "kernel_size", "=", "self", ".", "gk", ",", "stride", "=", "self", ".", "gs", ",", "padding", "=", "self", ".", "gk", "//", "2", ",", "count_include_pad", "=", "False", ")", "\n", "if", "self", ".", "add_maxpool", ":", "\n", "# experimental codepath, may remove or change", "\n", "                    ", "x_ge", "=", "0.5", "*", "x_ge", "+", "0.5", "*", "F", ".", "max_pool2d", "(", "x", ",", "kernel_size", "=", "self", ".", "gk", ",", "stride", "=", "self", ".", "gs", ",", "padding", "=", "self", ".", "gk", "//", "2", ")", "\n", "", "", "", "x_ge", "=", "self", ".", "mlp", "(", "x_ge", ")", "\n", "if", "x_ge", ".", "shape", "[", "-", "1", "]", "!=", "1", "or", "x_ge", ".", "shape", "[", "-", "2", "]", "!=", "1", ":", "\n", "            ", "x_ge", "=", "F", ".", "interpolate", "(", "x_ge", ",", "size", "=", "size", ")", "\n", "", "return", "x", "*", "self", ".", "gate", "(", "x_ge", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.norm_act.BatchNormAct2d.__init__": [[20, 32], ["torch.nn.BatchNorm2d.__init__", "create_act.get_act_layer", "drop_layer", "torch.nn.Identity", "create_act.get_act_layer.", "torch.nn.Identity", "dict"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer"], ["def", "__init__", "(", "\n", "self", ",", "num_features", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ",", "\n", "apply_act", "=", "True", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "inplace", "=", "True", ",", "drop_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "BatchNormAct2d", ",", "self", ")", ".", "__init__", "(", "\n", "num_features", ",", "eps", "=", "eps", ",", "momentum", "=", "momentum", ",", "affine", "=", "affine", ",", "track_running_stats", "=", "track_running_stats", ")", "\n", "self", ".", "drop", "=", "drop_layer", "(", ")", "if", "drop_layer", "is", "not", "None", "else", "nn", ".", "Identity", "(", ")", "\n", "act_layer", "=", "get_act_layer", "(", "act_layer", ")", "# string -> nn.Module", "\n", "if", "act_layer", "is", "not", "None", "and", "apply_act", ":", "\n", "            ", "act_args", "=", "dict", "(", "inplace", "=", "True", ")", "if", "inplace", "else", "{", "}", "\n", "self", ".", "act", "=", "act_layer", "(", "**", "act_args", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "act", "=", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.norm_act.BatchNormAct2d.forward": [[33, 82], ["trace_utils._assert", "torch.nn.functional.batch_norm", "norm_act.BatchNormAct2d.drop", "norm_act.BatchNormAct2d.act", "float"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# cut & paste of torch.nn.BatchNorm2d.forward impl to avoid issues with torchscript and tracing", "\n", "        ", "_assert", "(", "x", ".", "ndim", "==", "4", ",", "f'expected 4D input (got {x.ndim}D input)'", ")", "\n", "\n", "# exponential_average_factor is set to self.momentum", "\n", "# (when it is available) only so that it gets updated", "\n", "# in ONNX graph when this node is exported to ONNX.", "\n", "if", "self", ".", "momentum", "is", "None", ":", "\n", "            ", "exponential_average_factor", "=", "0.0", "\n", "", "else", ":", "\n", "            ", "exponential_average_factor", "=", "self", ".", "momentum", "\n", "\n", "", "if", "self", ".", "training", "and", "self", ".", "track_running_stats", ":", "\n", "# TODO: if statement only here to tell the jit to skip emitting this when it is None", "\n", "            ", "if", "self", ".", "num_batches_tracked", "is", "not", "None", ":", "# type: ignore[has-type]", "\n", "                ", "self", ".", "num_batches_tracked", "=", "self", ".", "num_batches_tracked", "+", "1", "# type: ignore[has-type]", "\n", "if", "self", ".", "momentum", "is", "None", ":", "# use cumulative moving average", "\n", "                    ", "exponential_average_factor", "=", "1.0", "/", "float", "(", "self", ".", "num_batches_tracked", ")", "\n", "", "else", ":", "# use exponential moving average", "\n", "                    ", "exponential_average_factor", "=", "self", ".", "momentum", "\n", "\n", "", "", "", "r\"\"\"\n        Decide whether the mini-batch stats should be used for normalization rather than the buffers.\n        Mini-batch stats are used in training mode, and in eval mode when buffers are None.\n        \"\"\"", "\n", "if", "self", ".", "training", ":", "\n", "            ", "bn_training", "=", "True", "\n", "", "else", ":", "\n", "            ", "bn_training", "=", "(", "self", ".", "running_mean", "is", "None", ")", "and", "(", "self", ".", "running_var", "is", "None", ")", "\n", "\n", "", "r\"\"\"\n        Buffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\n        passed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\n        used for normalization (i.e. in eval mode when buffers are not None).\n        \"\"\"", "\n", "x", "=", "F", ".", "batch_norm", "(", "\n", "x", ",", "\n", "# If buffers are not to be tracked, ensure that they won't be updated", "\n", "self", ".", "running_mean", "if", "not", "self", ".", "training", "or", "self", ".", "track_running_stats", "else", "None", ",", "\n", "self", ".", "running_var", "if", "not", "self", ".", "training", "or", "self", ".", "track_running_stats", "else", "None", ",", "\n", "self", ".", "weight", ",", "\n", "self", ".", "bias", ",", "\n", "bn_training", ",", "\n", "exponential_average_factor", ",", "\n", "self", ".", "eps", ",", "\n", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.norm_act.GroupNormAct.__init__": [[93, 105], ["torch.nn.GroupNorm.__init__", "create_act.get_act_layer", "norm_act._num_groups", "drop_layer", "torch.nn.Identity", "create_act.get_act_layer.", "torch.nn.Identity", "dict"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.norm_act._num_groups"], ["    ", "def", "__init__", "(", "\n", "self", ",", "num_channels", ",", "num_groups", "=", "32", ",", "eps", "=", "1e-5", ",", "affine", "=", "True", ",", "group_size", "=", "None", ",", "\n", "apply_act", "=", "True", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "inplace", "=", "True", ",", "drop_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "GroupNormAct", ",", "self", ")", ".", "__init__", "(", "\n", "_num_groups", "(", "num_channels", ",", "num_groups", ",", "group_size", ")", ",", "num_channels", ",", "eps", "=", "eps", ",", "affine", "=", "affine", ")", "\n", "self", ".", "drop", "=", "drop_layer", "(", ")", "if", "drop_layer", "is", "not", "None", "else", "nn", ".", "Identity", "(", ")", "\n", "act_layer", "=", "get_act_layer", "(", "act_layer", ")", "# string -> nn.Module", "\n", "if", "act_layer", "is", "not", "None", "and", "apply_act", ":", "\n", "            ", "act_args", "=", "dict", "(", "inplace", "=", "True", ")", "if", "inplace", "else", "{", "}", "\n", "self", ".", "act", "=", "act_layer", "(", "**", "act_args", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "act", "=", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.norm_act.GroupNormAct.forward": [[106, 111], ["torch.nn.functional.group_norm", "norm_act.GroupNormAct.drop", "norm_act.GroupNormAct.act"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "group_norm", "(", "x", ",", "self", ".", "num_groups", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "eps", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.norm_act.LayerNormAct.__init__": [[114, 125], ["torch.nn.LayerNorm.__init__", "create_act.get_act_layer", "drop_layer", "torch.nn.Identity", "create_act.get_act_layer.", "torch.nn.Identity", "dict"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer"], ["    ", "def", "__init__", "(", "\n", "self", ",", "normalization_shape", ":", "Union", "[", "int", ",", "List", "[", "int", "]", ",", "torch", ".", "Size", "]", ",", "eps", "=", "1e-5", ",", "affine", "=", "True", ",", "\n", "apply_act", "=", "True", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "inplace", "=", "True", ",", "drop_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "LayerNormAct", ",", "self", ")", ".", "__init__", "(", "normalization_shape", ",", "eps", "=", "eps", ",", "elementwise_affine", "=", "affine", ")", "\n", "self", ".", "drop", "=", "drop_layer", "(", ")", "if", "drop_layer", "is", "not", "None", "else", "nn", ".", "Identity", "(", ")", "\n", "act_layer", "=", "get_act_layer", "(", "act_layer", ")", "# string -> nn.Module", "\n", "if", "act_layer", "is", "not", "None", "and", "apply_act", ":", "\n", "            ", "act_args", "=", "dict", "(", "inplace", "=", "True", ")", "if", "inplace", "else", "{", "}", "\n", "self", ".", "act", "=", "act_layer", "(", "**", "act_args", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "act", "=", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.norm_act.LayerNormAct.forward": [[126, 131], ["torch.nn.functional.layer_norm", "norm_act.LayerNormAct.drop", "norm_act.LayerNormAct.act"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "layer_norm", "(", "x", ",", "self", ".", "normalized_shape", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "eps", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.norm_act.LayerNormAct2d.__init__": [[134, 145], ["torch.nn.LayerNorm.__init__", "create_act.get_act_layer", "drop_layer", "torch.nn.Identity", "create_act.get_act_layer.", "torch.nn.Identity", "dict"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_act.get_act_layer"], ["    ", "def", "__init__", "(", "\n", "self", ",", "num_channels", ",", "eps", "=", "1e-5", ",", "affine", "=", "True", ",", "\n", "apply_act", "=", "True", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "inplace", "=", "True", ",", "drop_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "LayerNormAct2d", ",", "self", ")", ".", "__init__", "(", "num_channels", ",", "eps", "=", "eps", ",", "elementwise_affine", "=", "affine", ")", "\n", "self", ".", "drop", "=", "drop_layer", "(", ")", "if", "drop_layer", "is", "not", "None", "else", "nn", ".", "Identity", "(", ")", "\n", "act_layer", "=", "get_act_layer", "(", "act_layer", ")", "# string -> nn.Module", "\n", "if", "act_layer", "is", "not", "None", "and", "apply_act", ":", "\n", "            ", "act_args", "=", "dict", "(", "inplace", "=", "True", ")", "if", "inplace", "else", "{", "}", "\n", "self", ".", "act", "=", "act_layer", "(", "**", "act_args", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "act", "=", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.norm_act.LayerNormAct2d.forward": [[146, 152], ["torch.nn.functional.layer_norm().permute", "norm_act.LayerNormAct2d.drop", "norm_act.LayerNormAct2d.act", "torch.nn.functional.layer_norm", "norm_act.LayerNormAct2d.permute"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "layer_norm", "(", "\n", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ",", "self", ".", "normalized_shape", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "eps", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.norm_act._num_groups": [[84, 89], ["None"], "function", ["None"], ["", "", "def", "_num_groups", "(", "num_channels", ",", "num_groups", ",", "group_size", ")", ":", "\n", "    ", "if", "group_size", ":", "\n", "        ", "assert", "num_channels", "%", "group_size", "==", "0", "\n", "return", "num_channels", "//", "group_size", "\n", "", "return", "num_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.get_attn": [[21, 82], ["isinstance", "isinstance", "attn_type.lower.lower", "isinstance", "functools.partial", "functools.partial"], "function", ["None"], ["def", "get_attn", "(", "attn_type", ")", ":", "\n", "    ", "if", "isinstance", "(", "attn_type", ",", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "        ", "return", "attn_type", "\n", "", "module_cls", "=", "None", "\n", "if", "attn_type", "is", "not", "None", ":", "\n", "        ", "if", "isinstance", "(", "attn_type", ",", "str", ")", ":", "\n", "            ", "attn_type", "=", "attn_type", ".", "lower", "(", ")", "\n", "# Lightweight attention modules (channel and/or coarse spatial).", "\n", "# Typically added to existing network architecture blocks in addition to existing convolutions.", "\n", "if", "attn_type", "==", "'se'", ":", "\n", "                ", "module_cls", "=", "SEModule", "\n", "", "elif", "attn_type", "==", "'ese'", ":", "\n", "                ", "module_cls", "=", "EffectiveSEModule", "\n", "", "elif", "attn_type", "==", "'eca'", ":", "\n", "                ", "module_cls", "=", "EcaModule", "\n", "", "elif", "attn_type", "==", "'ecam'", ":", "\n", "                ", "module_cls", "=", "partial", "(", "EcaModule", ",", "use_mlp", "=", "True", ")", "\n", "", "elif", "attn_type", "==", "'ceca'", ":", "\n", "                ", "module_cls", "=", "CecaModule", "\n", "", "elif", "attn_type", "==", "'ge'", ":", "\n", "                ", "module_cls", "=", "GatherExcite", "\n", "", "elif", "attn_type", "==", "'gc'", ":", "\n", "                ", "module_cls", "=", "GlobalContext", "\n", "", "elif", "attn_type", "==", "'gca'", ":", "\n", "                ", "module_cls", "=", "partial", "(", "GlobalContext", ",", "fuse_add", "=", "True", ",", "fuse_scale", "=", "False", ")", "\n", "", "elif", "attn_type", "==", "'cbam'", ":", "\n", "                ", "module_cls", "=", "CbamModule", "\n", "", "elif", "attn_type", "==", "'lcbam'", ":", "\n", "                ", "module_cls", "=", "LightCbamModule", "\n", "\n", "# Attention / attention-like modules w/ significant params", "\n", "# Typically replace some of the existing workhorse convs in a network architecture.", "\n", "# All of these accept a stride argument and can spatially downsample the input.", "\n", "", "elif", "attn_type", "==", "'sk'", ":", "\n", "                ", "module_cls", "=", "SelectiveKernel", "\n", "", "elif", "attn_type", "==", "'splat'", ":", "\n", "                ", "module_cls", "=", "SplitAttn", "\n", "\n", "# Self-attention / attention-like modules w/ significant compute and/or params", "\n", "# Typically replace some of the existing workhorse convs in a network architecture.", "\n", "# All of these accept a stride argument and can spatially downsample the input.", "\n", "", "elif", "attn_type", "==", "'lambda'", ":", "\n", "                ", "return", "LambdaLayer", "\n", "", "elif", "attn_type", "==", "'bottleneck'", ":", "\n", "                ", "return", "BottleneckAttn", "\n", "", "elif", "attn_type", "==", "'halo'", ":", "\n", "                ", "return", "HaloAttn", "\n", "", "elif", "attn_type", "==", "'nl'", ":", "\n", "                ", "module_cls", "=", "NonLocalAttn", "\n", "", "elif", "attn_type", "==", "'bat'", ":", "\n", "                ", "module_cls", "=", "BatNonLocalAttn", "\n", "\n", "# Woops!", "\n", "", "else", ":", "\n", "                ", "assert", "False", ",", "\"Invalid attn module (%s)\"", "%", "attn_type", "\n", "", "", "elif", "isinstance", "(", "attn_type", ",", "bool", ")", ":", "\n", "            ", "if", "attn_type", ":", "\n", "                ", "module_cls", "=", "SEModule", "\n", "", "", "else", ":", "\n", "            ", "module_cls", "=", "attn_type", "\n", "", "", "return", "module_cls", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.create_attn": [[84, 90], ["create_attn.get_attn", "get_attn."], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.create_attn.get_attn"], ["", "def", "create_attn", "(", "attn_type", ",", "channels", ",", "**", "kwargs", ")", ":", "\n", "    ", "module_cls", "=", "get_attn", "(", "attn_type", ")", "\n", "if", "module_cls", "is", "not", "None", ":", "\n", "# NOTE: it's expected the first (positional) argument of all attention layers is the # input channels", "\n", "        ", "return", "module_cls", "(", "channels", ",", "**", "kwargs", ")", "\n", "", "return", "None", "\n", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cond_conv2d.CondConv2d.__init__": [[43, 72], ["torch.nn.Module.__init__", "helpers.to_2tuple", "helpers.to_2tuple", "padding.get_padding_value", "helpers.to_2tuple", "helpers.to_2tuple", "torch.nn.Parameter", "cond_conv2d.CondConv2d.reset_parameters", "torch.Tensor", "torch.nn.Parameter", "cond_conv2d.CondConv2d.register_parameter", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.padding.get_padding_value", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "padding", "=", "''", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "False", ",", "num_experts", "=", "4", ")", ":", "\n", "        ", "super", "(", "CondConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "to_2tuple", "(", "kernel_size", ")", "\n", "self", ".", "stride", "=", "to_2tuple", "(", "stride", ")", "\n", "padding_val", ",", "is_padding_dynamic", "=", "get_padding_value", "(", "\n", "padding", ",", "kernel_size", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ")", "\n", "self", ".", "dynamic_padding", "=", "is_padding_dynamic", "# if in forward to work with torchscript", "\n", "self", ".", "padding", "=", "to_2tuple", "(", "padding_val", ")", "\n", "self", ".", "dilation", "=", "to_2tuple", "(", "dilation", ")", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "num_experts", "=", "num_experts", "\n", "\n", "self", ".", "weight_shape", "=", "(", "self", ".", "out_channels", ",", "self", ".", "in_channels", "//", "self", ".", "groups", ")", "+", "self", ".", "kernel_size", "\n", "weight_num_param", "=", "1", "\n", "for", "wd", "in", "self", ".", "weight_shape", ":", "\n", "            ", "weight_num_param", "*=", "wd", "\n", "", "self", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_experts", ",", "weight_num_param", ")", ")", "\n", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias_shape", "=", "(", "self", ".", "out_channels", ",", ")", "\n", "self", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_experts", ",", "self", ".", "out_channels", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cond_conv2d.CondConv2d.reset_parameters": [[73, 83], ["cond_conv2d.get_condconv_initializer", "get_condconv_initializer.", "functools.partial", "numpy.prod", "cond_conv2d.get_condconv_initializer", "get_condconv_initializer.", "math.sqrt", "functools.partial", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cond_conv2d.get_condconv_initializer", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cond_conv2d.get_condconv_initializer"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "init_weight", "=", "get_condconv_initializer", "(", "\n", "partial", "(", "nn", ".", "init", ".", "kaiming_uniform_", ",", "a", "=", "math", ".", "sqrt", "(", "5", ")", ")", ",", "self", ".", "num_experts", ",", "self", ".", "weight_shape", ")", "\n", "init_weight", "(", "self", ".", "weight", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "fan_in", "=", "np", ".", "prod", "(", "self", ".", "weight_shape", "[", "1", ":", "]", ")", "\n", "bound", "=", "1", "/", "math", ".", "sqrt", "(", "fan_in", ")", "\n", "init_bias", "=", "get_condconv_initializer", "(", "\n", "partial", "(", "nn", ".", "init", ".", "uniform_", ",", "a", "=", "-", "bound", ",", "b", "=", "bound", ")", ",", "self", ".", "num_experts", ",", "self", ".", "bias_shape", ")", "\n", "init_bias", "(", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cond_conv2d.CondConv2d.forward": [[84, 123], ["torch.matmul", "weight.view.view.view", "x.view.view.view", "torch.nn.functional.conv2d.permute().view", "torch.matmul", "bias.view.view.view", "conv2d_same.conv2d_same.conv2d_same", "torch.nn.functional.conv2d", "torch.nn.functional.conv2d.permute"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.conv2d_same.conv2d_same"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "routing_weights", ")", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "weight", "=", "torch", ".", "matmul", "(", "routing_weights", ",", "self", ".", "weight", ")", "\n", "new_weight_shape", "=", "(", "B", "*", "self", ".", "out_channels", ",", "self", ".", "in_channels", "//", "self", ".", "groups", ")", "+", "self", ".", "kernel_size", "\n", "weight", "=", "weight", ".", "view", "(", "new_weight_shape", ")", "\n", "bias", "=", "None", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "bias", "=", "torch", ".", "matmul", "(", "routing_weights", ",", "self", ".", "bias", ")", "\n", "bias", "=", "bias", ".", "view", "(", "B", "*", "self", ".", "out_channels", ")", "\n", "# move batch elements with channels so each batch element can be efficiently convolved with separate kernel", "\n", "", "x", "=", "x", ".", "view", "(", "1", ",", "B", "*", "C", ",", "H", ",", "W", ")", "\n", "if", "self", ".", "dynamic_padding", ":", "\n", "            ", "out", "=", "conv2d_same", "(", "\n", "x", ",", "weight", ",", "bias", ",", "stride", "=", "self", ".", "stride", ",", "padding", "=", "self", ".", "padding", ",", "\n", "dilation", "=", "self", ".", "dilation", ",", "groups", "=", "self", ".", "groups", "*", "B", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "F", ".", "conv2d", "(", "\n", "x", ",", "weight", ",", "bias", ",", "stride", "=", "self", ".", "stride", ",", "padding", "=", "self", ".", "padding", ",", "\n", "dilation", "=", "self", ".", "dilation", ",", "groups", "=", "self", ".", "groups", "*", "B", ")", "\n", "", "out", "=", "out", ".", "permute", "(", "[", "1", ",", "0", ",", "2", ",", "3", "]", ")", ".", "view", "(", "B", ",", "self", ".", "out_channels", ",", "out", ".", "shape", "[", "-", "2", "]", ",", "out", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "# Literal port (from TF definition)", "\n", "# x = torch.split(x, 1, 0)", "\n", "# weight = torch.split(weight, 1, 0)", "\n", "# if self.bias is not None:", "\n", "#     bias = torch.matmul(routing_weights, self.bias)", "\n", "#     bias = torch.split(bias, 1, 0)", "\n", "# else:", "\n", "#     bias = [None] * B", "\n", "# out = []", "\n", "# for xi, wi, bi in zip(x, weight, bias):", "\n", "#     wi = wi.view(*self.weight_shape)", "\n", "#     if bi is not None:", "\n", "#         bi = bi.view(*self.bias_shape)", "\n", "#     out.append(self.conv_fn(", "\n", "#         xi, wi, bi, stride=self.stride, padding=self.padding,", "\n", "#         dilation=self.dilation, groups=self.groups))", "\n", "# out = torch.cat(out, 0)", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.cond_conv2d.get_condconv_initializer": [[21, 32], ["numpy.prod", "range", "ValueError", "initializer", "len", "weight[].view"], "function", ["None"], ["def", "get_condconv_initializer", "(", "initializer", ",", "num_experts", ",", "expert_shape", ")", ":", "\n", "    ", "def", "condconv_initializer", "(", "weight", ")", ":", "\n", "        ", "\"\"\"CondConv initializer function.\"\"\"", "\n", "num_params", "=", "np", ".", "prod", "(", "expert_shape", ")", "\n", "if", "(", "len", "(", "weight", ".", "shape", ")", "!=", "2", "or", "weight", ".", "shape", "[", "0", "]", "!=", "num_experts", "or", "\n", "weight", ".", "shape", "[", "1", "]", "!=", "num_params", ")", ":", "\n", "            ", "raise", "(", "ValueError", "(", "\n", "'CondConv variables must have shape [num_experts, num_params]'", ")", ")", "\n", "", "for", "i", "in", "range", "(", "num_experts", ")", ":", "\n", "            ", "initializer", "(", "weight", "[", "i", "]", ".", "view", "(", "expert_shape", ")", ")", "\n", "", "", "return", "condconv_initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.space_to_depth.SpaceToDepth.__init__": [[6, 10], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "block_size", "=", "4", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "block_size", "==", "4", "\n", "self", ".", "bs", "=", "block_size", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.space_to_depth.SpaceToDepth.forward": [[11, 17], ["x.view.view.size", "x.view.view.view", "x.view.view.permute().contiguous", "x.view.view.view", "x.view.view.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "N", ",", "C", ",", "H", ",", "W", "=", "x", ".", "size", "(", ")", "\n", "x", "=", "x", ".", "view", "(", "N", ",", "C", ",", "H", "//", "self", ".", "bs", ",", "self", ".", "bs", ",", "W", "//", "self", ".", "bs", ",", "self", ".", "bs", ")", "# (N, C, H//bs, bs, W//bs, bs)", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "3", ",", "5", ",", "1", ",", "2", ",", "4", ")", ".", "contiguous", "(", ")", "# (N, bs, bs, C, H//bs, W//bs)", "\n", "x", "=", "x", ".", "view", "(", "N", ",", "C", "*", "(", "self", ".", "bs", "**", "2", ")", ",", "H", "//", "self", ".", "bs", ",", "W", "//", "self", ".", "bs", ")", "# (N, C*bs^2, H//bs, W//bs)", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.space_to_depth.SpaceToDepthJit.__call__": [[21, 28], ["x.view.view.size", "x.view.view.view", "x.view.view.permute().contiguous", "x.view.view.view", "x.view.view.permute"], "methods", ["None"], ["    ", "def", "__call__", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "# assuming hard-coded that block_size==4 for acceleration", "\n", "        ", "N", ",", "C", ",", "H", ",", "W", "=", "x", ".", "size", "(", ")", "\n", "x", "=", "x", ".", "view", "(", "N", ",", "C", ",", "H", "//", "4", ",", "4", ",", "W", "//", "4", ",", "4", ")", "# (N, C, H//bs, bs, W//bs, bs)", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "3", ",", "5", ",", "1", ",", "2", ",", "4", ")", ".", "contiguous", "(", ")", "# (N, bs, bs, C, H//bs, W//bs)", "\n", "x", "=", "x", ".", "view", "(", "N", ",", "C", "*", "16", ",", "H", "//", "4", ",", "W", "//", "4", ")", "# (N, C*bs^2, H//bs, W//bs)", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.space_to_depth.SpaceToDepthModule.__init__": [[31, 37], ["torch.Module.__init__", "space_to_depth.SpaceToDepthJit", "space_to_depth.SpaceToDepth"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "no_jit", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "not", "no_jit", ":", "\n", "            ", "self", ".", "op", "=", "SpaceToDepthJit", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "op", "=", "SpaceToDepth", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.space_to_depth.SpaceToDepthModule.forward": [[38, 40], ["space_to_depth.SpaceToDepthModule.op"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "op", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.space_to_depth.DepthToSpace.__init__": [[44, 47], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "block_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bs", "=", "block_size", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.space_to_depth.DepthToSpace.forward": [[48, 54], ["x.view.view.size", "x.view.view.view", "x.view.view.permute().contiguous", "x.view.view.view", "x.view.view.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "N", ",", "C", ",", "H", ",", "W", "=", "x", ".", "size", "(", ")", "\n", "x", "=", "x", ".", "view", "(", "N", ",", "self", ".", "bs", ",", "self", ".", "bs", ",", "C", "//", "(", "self", ".", "bs", "**", "2", ")", ",", "H", ",", "W", ")", "# (N, bs, bs, C//bs^2, H, W)", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "3", ",", "4", ",", "1", ",", "5", ",", "2", ")", ".", "contiguous", "(", ")", "# (N, C//bs^2, H, bs, W, bs)", "\n", "x", "=", "x", ".", "view", "(", "N", ",", "C", "//", "(", "self", ".", "bs", "**", "2", ")", ",", "H", "*", "self", ".", "bs", ",", "W", "*", "self", ".", "bs", ")", "# (N, C//bs^2, H * bs, W * bs)", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.selective_kernel.SelectiveKernelAttn.__init__": [[23, 35], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "norm_layer", "act_layer", "torch.nn.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channels", ",", "num_paths", "=", "2", ",", "attn_channels", "=", "32", ",", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "\"\"\" Selective Kernel Attention Module\n\n        Selective Kernel attention mechanism factored out into its own module.\n\n        \"\"\"", "\n", "super", "(", "SelectiveKernelAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_paths", "=", "num_paths", "\n", "self", ".", "fc_reduce", "=", "nn", ".", "Conv2d", "(", "channels", ",", "attn_channels", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn", "=", "norm_layer", "(", "attn_channels", ")", "\n", "self", ".", "act", "=", "act_layer", "(", "inplace", "=", "True", ")", "\n", "self", ".", "fc_select", "=", "nn", ".", "Conv2d", "(", "attn_channels", ",", "channels", "*", "num_paths", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.selective_kernel.SelectiveKernelAttn.forward": [[36, 47], ["trace_utils._assert", "torch.softmax.sum().mean", "selective_kernel.SelectiveKernelAttn.fc_reduce", "selective_kernel.SelectiveKernelAttn.bn", "selective_kernel.SelectiveKernelAttn.act", "selective_kernel.SelectiveKernelAttn.fc_select", "torch.softmax.view", "torch.softmax", "torch.softmax.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_assert", "(", "x", ".", "shape", "[", "1", "]", "==", "self", ".", "num_paths", ",", "''", ")", "\n", "x", "=", "x", ".", "sum", "(", "1", ")", ".", "mean", "(", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "self", ".", "fc_reduce", "(", "x", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "fc_select", "(", "x", ")", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "self", ".", "num_paths", ",", "C", "//", "self", ".", "num_paths", ",", "H", ",", "W", ")", "\n", "x", "=", "torch", ".", "softmax", "(", "x", ",", "dim", "=", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.selective_kernel.SelectiveKernel.__init__": [[51, 108], ["torch.nn.Module.__init__", "selective_kernel._kernel_valid", "len", "min", "dict", "torch.nn.ModuleList", "selective_kernel.SelectiveKernelAttn", "isinstance", "helpers.make_divisible", "len", "len", "conv_bn_act.ConvNormActAa", "zip"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.selective_kernel._kernel_valid", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.helpers.make_divisible"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", "=", "None", ",", "kernel_size", "=", "None", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "\n", "rd_ratio", "=", "1.", "/", "16", ",", "rd_channels", "=", "None", ",", "rd_divisor", "=", "8", ",", "keep_3x3", "=", "True", ",", "split_input", "=", "True", ",", "\n", "act_layer", "=", "nn", ".", "ReLU", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "aa_layer", "=", "None", ",", "drop_layer", "=", "None", ")", ":", "\n", "        ", "\"\"\" Selective Kernel Convolution Module\n\n        As described in Selective Kernel Networks (https://arxiv.org/abs/1903.06586) with some modifications.\n\n        Largest change is the input split, which divides the input channels across each convolution path, this can\n        be viewed as a grouping of sorts, but the output channel counts expand to the module level value. This keeps\n        the parameter count from ballooning when the convolutions themselves don't have groups, but still provides\n        a noteworthy increase in performance over similar param count models without this attention layer. -Ross W\n\n        Args:\n            in_channels (int):  module input (feature) channel count\n            out_channels (int):  module output (feature) channel count\n            kernel_size (int, list): kernel size for each convolution branch\n            stride (int): stride for convolutions\n            dilation (int): dilation for module as a whole, impacts dilation of each branch\n            groups (int): number of groups for each branch\n            rd_ratio (int, float): reduction factor for attention features\n            keep_3x3 (bool): keep all branch convolution kernels as 3x3, changing larger kernels for dilations\n            split_input (bool): split input channels evenly across each convolution branch, keeps param count lower,\n                can be viewed as grouping by path, output expands to module out_channels count\n            act_layer (nn.Module): activation layer to use\n            norm_layer (nn.Module): batchnorm/norm layer to use\n            aa_layer (nn.Module): anti-aliasing module\n            drop_layer (nn.Module): spatial drop module in convs (drop block, etc)\n        \"\"\"", "\n", "super", "(", "SelectiveKernel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "out_channels", "=", "out_channels", "or", "in_channels", "\n", "kernel_size", "=", "kernel_size", "or", "[", "3", ",", "5", "]", "# default to one 3x3 and one 5x5 branch. 5x5 -> 3x3 + dilation", "\n", "_kernel_valid", "(", "kernel_size", ")", "\n", "if", "not", "isinstance", "(", "kernel_size", ",", "list", ")", ":", "\n", "            ", "kernel_size", "=", "[", "kernel_size", "]", "*", "2", "\n", "", "if", "keep_3x3", ":", "\n", "            ", "dilation", "=", "[", "dilation", "*", "(", "k", "-", "1", ")", "//", "2", "for", "k", "in", "kernel_size", "]", "\n", "kernel_size", "=", "[", "3", "]", "*", "len", "(", "kernel_size", ")", "\n", "", "else", ":", "\n", "            ", "dilation", "=", "[", "dilation", "]", "*", "len", "(", "kernel_size", ")", "\n", "", "self", ".", "num_paths", "=", "len", "(", "kernel_size", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "split_input", "=", "split_input", "\n", "if", "self", ".", "split_input", ":", "\n", "            ", "assert", "in_channels", "%", "self", ".", "num_paths", "==", "0", "\n", "in_channels", "=", "in_channels", "//", "self", ".", "num_paths", "\n", "", "groups", "=", "min", "(", "out_channels", ",", "groups", ")", "\n", "\n", "conv_kwargs", "=", "dict", "(", "\n", "stride", "=", "stride", ",", "groups", "=", "groups", ",", "act_layer", "=", "act_layer", ",", "norm_layer", "=", "norm_layer", ",", "\n", "aa_layer", "=", "aa_layer", ",", "drop_layer", "=", "drop_layer", ")", "\n", "self", ".", "paths", "=", "nn", ".", "ModuleList", "(", "[", "\n", "ConvNormActAa", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "k", ",", "dilation", "=", "d", ",", "**", "conv_kwargs", ")", "\n", "for", "k", ",", "d", "in", "zip", "(", "kernel_size", ",", "dilation", ")", "]", ")", "\n", "\n", "attn_channels", "=", "rd_channels", "or", "make_divisible", "(", "out_channels", "*", "rd_ratio", ",", "divisor", "=", "rd_divisor", ")", "\n", "self", ".", "attn", "=", "SelectiveKernelAttn", "(", "out_channels", ",", "self", ".", "num_paths", ",", "attn_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.selective_kernel.SelectiveKernel.forward": [[109, 120], ["torch.stack", "selective_kernel.SelectiveKernel.attn", "torch.sum", "torch.split", "op", "op", "enumerate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "split_input", ":", "\n", "            ", "x_split", "=", "torch", ".", "split", "(", "x", ",", "self", ".", "in_channels", "//", "self", ".", "num_paths", ",", "1", ")", "\n", "x_paths", "=", "[", "op", "(", "x_split", "[", "i", "]", ")", "for", "i", ",", "op", "in", "enumerate", "(", "self", ".", "paths", ")", "]", "\n", "", "else", ":", "\n", "            ", "x_paths", "=", "[", "op", "(", "x", ")", "for", "op", "in", "self", ".", "paths", "]", "\n", "", "x", "=", "torch", ".", "stack", "(", "x_paths", ",", "dim", "=", "1", ")", "\n", "x_attn", "=", "self", ".", "attn", "(", "x", ")", "\n", "x", "=", "x", "*", "x_attn", "\n", "x", "=", "torch", ".", "sum", "(", "x", ",", "dim", "=", "1", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.selective_kernel._kernel_valid": [[15, 20], ["isinstance", "selective_kernel._kernel_valid"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.selective_kernel._kernel_valid"], ["def", "_kernel_valid", "(", "k", ")", ":", "\n", "    ", "if", "isinstance", "(", "k", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "for", "ki", "in", "k", ":", "\n", "            ", "return", "_kernel_valid", "(", "ki", ")", "\n", "", "", "assert", "k", ">=", "3", "and", "k", "%", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.ClassifierHead.__init__": [[41, 47], ["torch.nn.Module.__init__", "classifier._create_pool", "classifier._create_fc", "torch.nn.Flatten", "torch.nn.Identity"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier._create_pool", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier._create_fc"], ["def", "__init__", "(", "self", ",", "in_chs", ",", "num_classes", ",", "pool_type", "=", "'avg'", ",", "drop_rate", "=", "0.", ",", "use_conv", "=", "False", ")", ":", "\n", "        ", "super", "(", "ClassifierHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "global_pool", ",", "num_pooled_features", "=", "_create_pool", "(", "in_chs", ",", "num_classes", ",", "pool_type", ",", "use_conv", "=", "use_conv", ")", "\n", "self", ".", "fc", "=", "_create_fc", "(", "num_pooled_features", ",", "num_classes", ",", "use_conv", "=", "use_conv", ")", "\n", "self", ".", "flatten", "=", "nn", ".", "Flatten", "(", "1", ")", "if", "use_conv", "and", "pool_type", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.ClassifierHead.forward": [[48, 57], ["classifier.ClassifierHead.global_pool", "torch.nn.functional.dropout", "classifier.ClassifierHead.flatten", "classifier.ClassifierHead.fc", "classifier.ClassifierHead.flatten", "float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "pre_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "global_pool", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "float", "(", "self", ".", "drop_rate", ")", ",", "training", "=", "self", ".", "training", ")", "\n", "", "if", "pre_logits", ":", "\n", "            ", "return", "x", ".", "flatten", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "self", ".", "flatten", "(", "x", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier._create_pool": [[11, 20], ["adaptive_avgmax_pool.SelectAdaptivePool2d", "adaptive_avgmax_pool.SelectAdaptivePool2d.feat_mult"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.adaptive_avgmax_pool.SelectAdaptivePool2d.feat_mult"], ["def", "_create_pool", "(", "num_features", ",", "num_classes", ",", "pool_type", "=", "'avg'", ",", "use_conv", "=", "False", ")", ":", "\n", "    ", "flatten_in_pool", "=", "not", "use_conv", "# flatten when we use a Linear layer after pooling", "\n", "if", "not", "pool_type", ":", "\n", "        ", "assert", "num_classes", "==", "0", "or", "use_conv", ",", "'Pooling can only be disabled if classifier is also removed or conv classifier is used'", "\n", "flatten_in_pool", "=", "False", "# disable flattening if pooling is pass-through (no pooling)", "\n", "", "global_pool", "=", "SelectAdaptivePool2d", "(", "pool_type", "=", "pool_type", ",", "flatten", "=", "flatten_in_pool", ")", "\n", "num_pooled_features", "=", "num_features", "*", "global_pool", ".", "feat_mult", "(", ")", "\n", "return", "global_pool", ",", "num_pooled_features", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier._create_fc": [[22, 30], ["torch.nn.Identity", "torch.nn.Conv2d", "torch.nn.Linear"], "function", ["None"], ["", "def", "_create_fc", "(", "num_features", ",", "num_classes", ",", "use_conv", "=", "False", ")", ":", "\n", "    ", "if", "num_classes", "<=", "0", ":", "\n", "        ", "fc", "=", "nn", ".", "Identity", "(", ")", "# pass-through (no classifier)", "\n", "", "elif", "use_conv", ":", "\n", "        ", "fc", "=", "nn", ".", "Conv2d", "(", "num_features", ",", "num_classes", ",", "1", ",", "bias", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "fc", "=", "nn", ".", "Linear", "(", "num_features", ",", "num_classes", ",", "bias", "=", "True", ")", "\n", "", "return", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier.create_classifier": [[32, 36], ["classifier._create_pool", "classifier._create_fc"], "function", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier._create_pool", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.classifier._create_fc"], ["", "def", "create_classifier", "(", "num_features", ",", "num_classes", ",", "pool_type", "=", "'avg'", ",", "use_conv", "=", "False", ")", ":", "\n", "    ", "global_pool", ",", "num_pooled_features", "=", "_create_pool", "(", "num_features", ",", "num_classes", ",", "pool_type", ",", "use_conv", "=", "use_conv", ")", "\n", "fc", "=", "_create_fc", "(", "num_pooled_features", ",", "num_classes", ",", "use_conv", "=", "use_conv", ")", "\n", "return", "global_pool", ",", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__": [[40, 73], ["torch.nn.Module.__init__", "inplace_abn.InplaceAbn.register_buffer", "inplace_abn.InplaceAbn.register_buffer", "inplace_abn.InplaceAbn.reset_parameters", "isinstance", "torch.nn.Parameter", "torch.nn.Parameter", "inplace_abn.InplaceAbn.register_parameter", "inplace_abn.InplaceAbn.register_parameter", "torch.zeros", "torch.ones", "torch.ones", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.__init__", "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters"], ["def", "__init__", "(", "self", ",", "num_features", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "apply_act", "=", "True", ",", "\n", "act_layer", "=", "\"leaky_relu\"", ",", "act_param", "=", "0.01", ",", "drop_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "InplaceAbn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "affine", "=", "affine", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "momentum", "=", "momentum", "\n", "if", "apply_act", ":", "\n", "            ", "if", "isinstance", "(", "act_layer", ",", "str", ")", ":", "\n", "                ", "assert", "act_layer", "in", "(", "'leaky_relu'", ",", "'elu'", ",", "'identity'", ",", "''", ")", "\n", "self", ".", "act_name", "=", "act_layer", "if", "act_layer", "else", "'identity'", "\n", "", "else", ":", "\n", "# convert act layer passed as type to string", "\n", "                ", "if", "act_layer", "==", "nn", ".", "ELU", ":", "\n", "                    ", "self", ".", "act_name", "=", "'elu'", "\n", "", "elif", "act_layer", "==", "nn", ".", "LeakyReLU", ":", "\n", "                    ", "self", ".", "act_name", "=", "'leaky_relu'", "\n", "", "elif", "act_layer", "is", "None", "or", "act_layer", "==", "nn", ".", "Identity", ":", "\n", "                    ", "self", ".", "act_name", "=", "'identity'", "\n", "", "else", ":", "\n", "                    ", "assert", "False", ",", "f'Invalid act layer {act_layer.__name__} for IABN'", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "act_name", "=", "'identity'", "\n", "", "self", ".", "act_param", "=", "act_param", "\n", "if", "self", ".", "affine", ":", "\n", "            ", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_features", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'weight'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "", "self", ".", "register_buffer", "(", "'running_mean'", ",", "torch", ".", "zeros", "(", "num_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'running_var'", ",", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.reset_parameters": [[74, 80], ["torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "running_mean", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "running_var", ",", "1", ")", "\n", "if", "self", ".", "affine", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alibaba-miil_solving_imagenet.layers.inplace_abn.InplaceAbn.forward": [[81, 88], ["inplace_abn", "isinstance"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output", "=", "inplace_abn", "(", "\n", "x", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "running_mean", ",", "self", ".", "running_var", ",", "\n", "self", ".", "training", ",", "self", ".", "momentum", ",", "self", ".", "eps", ",", "self", ".", "act_name", ",", "self", ".", "act_param", ")", "\n", "if", "isinstance", "(", "output", ",", "tuple", ")", ":", "\n", "            ", "output", "=", "output", "[", "0", "]", "\n", "", "return", "output", "\n", "", "", ""]]}