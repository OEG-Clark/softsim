{"home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.valence_classifier.combine_feature_vectors": [[14, 17], ["pandas.concat"], "function", ["None"], ["def", "combine_feature_vectors", "(", "X_f1", ",", "X_f2", ")", ":", "\n", "    ", "return", "pd", ".", "concat", "(", "\n", "[", "X_f1", ",", "X_f2", "]", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.valence_classifier.extract_features": [[18, 77], ["pandas.concat", "valence_classifier.fill_partitions", "pandas.concat().drop", "valence_classifier.fill_partitions", "valence_classifier.normalize_data", "features.append", "pandas.concat", "valence_classifier.fill_partitions", "features.append", "os.path.isfile", "features.append", "os.path.isfile", "print", "valence.scripts.feature_extraction.fasttext_extractor.write_fasttext_features", "os.path.isfile", "print", "valence.scripts.feature_extraction.polarity_extractor.write_sentiment_features", "ft_polarity.append", "os.path.isfile", "print", "valence.scripts.feature_extraction.tfidf_extractor.write_TFIDF_features", "pandas.read_csv", "pandas.read_csv", "[].reset_index", "pandas.concat", "valence_classifier.normalize_data", "print", "pandas.read_csv().reset_index", "pandas.concat", "valence_classifier.combine_feature_vectors", "pandas.read_csv().reset_index", "valence_classifier.fill_partitions", "fasttext[].reset_index", "polarity[].reset_index", "pandas.read_csv", "pandas.read_csv().reset_index", "pandas.read_csv", "pd.read_csv.join", "pd.read_csv.set_index", "pandas.read_csv"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.valence_classifier.fill_partitions", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.valence_classifier.fill_partitions", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.fasttext_extractor.normalize_data", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.valence_classifier.fill_partitions", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.fasttext_extractor.write_fasttext_features", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.polarity_extractor.write_sentiment_features", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.tfidf_extractor.write_TFIDF_features", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.fasttext_extractor.normalize_data", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.valence_classifier.combine_feature_vectors", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.valence_classifier.fill_partitions"], ["", "def", "extract_features", "(", ")", ":", "\n", "### COMPUTE TFIDF Feature Vectorizer ###", "\n", "    ", "features", "=", "[", "]", "\n", "feature_descr", "=", "[", "'ft_polarity'", ",", "'bows'", ",", "'dict'", "]", "\n", "source_path", "=", "\"data/features/\"", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "source_path", "+", "'fasttext_features.csv'", ")", ":", "\n", "        ", "print", "(", "\"Fasttext features are not in the expected data/features folder.. We will extract them now.. \"", ")", "\n", "### Fasttext Feature Extractor ###", "\n", "fasttext_extractor", ".", "write_fasttext_features", "(", "raw_data", "[", "\"machine_translation\"", "]", ",", "\n", "source_path", "+", "\"fasttext_features.csv\"", ")", "\n", "\n", "", "fasttext_features", "=", "pd", ".", "concat", "(", "[", "raw_data", "[", "[", "'partition'", ",", "'FoldID'", "]", "]", ",", "pd", ".", "read_csv", "(", "\n", "source_path", "+", "\"fasttext_features.csv\"", ",", "\n", "sep", "=", "\",\"", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "]", ",", "\n", "axis", "=", "1", ")", "\n", "fasttext", "=", "fill_partitions", "(", "fasttext_features", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "source_path", "+", "'polarity_features.csv'", ")", ":", "\n", "        ", "print", "(", "\"Polarity features are not in the expected data/features folder.. We will extract them now.. \"", ")", "\n", "polarity_extractor", ".", "write_sentiment_features", "(", "raw_data", "[", "'machine_translation'", "]", ",", "\n", "source_path", ")", "\n", "\n", "", "polarity_features", "=", "pd", ".", "concat", "(", "[", "raw_data", "[", "[", "'partition'", ",", "'FoldID'", "]", "]", ",", "\n", "pd", ".", "read_csv", "(", "source_path", "+", "\"polarity_features.csv\"", ",", "sep", "=", "\",\"", ")", ".", "\n", "reset_index", "(", "drop", "=", "True", ")", "]", ",", "axis", "=", "1", ")", ".", "drop", "(", "columns", "=", "[", "'ID_story'", "]", ")", "\n", "polarity", "=", "fill_partitions", "(", "polarity_features", ")", "\n", "polarity", "=", "normalize_data", "(", "polarity", ")", "\n", "\n", "ft_polarity", "=", "[", "]", "\n", "for", "i", "in", "[", "0", ",", "1", ",", "2", "]", ":", "\n", "        ", "ft_polarity", ".", "append", "(", "\n", "combine_feature_vectors", "(", "fasttext", "[", "i", "]", ".", "reset_index", "(", "drop", "=", "True", ")", ",", "polarity", "[", "i", "]", ".", "reset_index", "(", "drop", "=", "True", ")", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "ft_polarity", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "source_path", "+", "'TFIDF_features.csv'", ")", ":", "\n", "        ", "print", "(", "\"TFIDF features are not in the expected data/features folder.. We will extract them now.. \"", ")", "\n", "tfidf_extractor", ".", "write_TFIDF_features", "(", "raw_data", "[", "'machine_translation'", "]", ",", "source_path", "+", "\"TFIDF_features.csv\"", ")", "\n", "", "bows_features", "=", "pd", ".", "concat", "(", "\n", "[", "raw_data", "[", "[", "'partition'", ",", "'FoldID'", "]", "]", ",", "pd", ".", "read_csv", "(", "source_path", "+", "\"TFIDF_features.csv\"", ",", "sep", "=", "\",\"", ")", ".", "\n", "reset_index", "(", "drop", "=", "True", ")", "]", ",", "axis", "=", "1", ")", "\n", "bows", "=", "fill_partitions", "(", "bows_features", ")", "\n", "\n", "features", ".", "append", "(", "bows", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "source_path", "+", "'sentiWS_features.csv'", ")", ":", "\n", "## Dictionary Features", "\n", "        ", "features_1", "=", "pd", ".", "read_csv", "(", "source_path", "+", "'sentiWS_features.csv'", ")", "\n", "features_2", "=", "pd", ".", "read_csv", "(", "source_path", "+", "'sentiWordNet_features.csv'", ")", "\n", "dict_features", "=", "features_1", ".", "join", "(", "features_2", ".", "set_index", "(", "'ID_story'", ")", ",", "on", "=", "'ID_story'", ")", "[", "dict_selected_features", "]", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "dict_features", "=", "pd", ".", "concat", "(", "[", "raw_data", "[", "[", "'partition'", ",", "'FoldID'", "]", "]", ",", "dict_features", "]", ",", "axis", "=", "1", ")", "\n", "dict", "=", "normalize_data", "(", "fill_partitions", "(", "dict_features", ")", ")", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Dictionary features are not in the expected data/features folder.. We will extract them now.. \"", ")", "\n", "", "features", ".", "append", "(", "dict", ")", "\n", "\n", "return", "(", "features", ",", "feature_descr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.valence_classifier.train_models": [[78, 90], ["os.listdir", "len", "len", "print", "valence.scripts.UAREvaluation.k_fold_cv", "print", "filename.startswith"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.UAREvaluation.k_fold_cv"], ["", "def", "train_models", "(", "features", ",", "features_descr", ")", ":", "\n", "    ", "file_list", "=", "os", ".", "listdir", "(", "\"data/models\"", ")", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "features", ")", ":", "\n", "        ", "num_models", "=", "[", "filename", "for", "filename", "in", "file_list", "if", "filename", ".", "startswith", "(", "features_descr", "[", "i", "]", ")", "]", "\n", "if", "len", "(", "num_models", ")", "!=", "3", ":", "\n", "            ", "print", "(", "features_descr", "[", "i", "]", "+", "\" models are not located under the data/models folder.. Training starts.. \"", ")", "\n", "UAREvaluation", ".", "k_fold_cv", "(", "features", "[", "i", "]", "[", "0", "]", ",", "y", "[", "0", "]", ",", "features_descr", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "features_descr", "[", "i", "]", "+", "\" models are already located in the data/models folder.\"", ")", "\n", "", "i", "+=", "1", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.valence_classifier.normalize_data": [[91, 98], ["sklearn.preprocessing.StandardScaler", "scaler.fit.fit", "pandas.DataFrame", "scaler.fit.transform"], "function", ["None"], ["", "def", "normalize_data", "(", "X", ")", ":", "\n", "    ", "scaler", "=", "StandardScaler", "(", ")", "\n", "scaler", "=", "scaler", ".", "fit", "(", "X", "[", "0", "]", ")", "\n", "# scale train/dev/test partitions", "\n", "for", "i", "in", "[", "0", ",", "1", ",", "2", "]", ":", "\n", "        ", "X", "[", "i", "]", "=", "pd", ".", "DataFrame", "(", "scaler", ".", "transform", "(", "X", "[", "i", "]", ")", ")", "\n", "", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.valence_classifier.fill_partitions": [[99, 111], ["df_new.append", "df_new.append", "df_new[].drop().drop", "df_new.append", "df.loc[].drop", "[].drop", "df.loc[].drop", "df_new[].drop"], "function", ["None"], ["", "def", "fill_partitions", "(", "df", ")", ":", "\n", "    ", "df_new", "=", "[", "]", "\n", "df_new", ".", "append", "(", "df", ".", "loc", "[", "(", "df", "[", "'partition'", "]", "==", "'train'", ")", "|", "(", "df", "[", "'partition'", "]", "==", "'devel'", ")", "]", ".", "\n", "drop", "(", "columns", "=", "[", "'partition'", "]", ")", ")", "\n", "# Use Fold id 4 as blind set for the experiments", "\n", "# [0] - > (Training + Development set) - Fold 4", "\n", "# [1] -> Fold 4 (in dev set) as blind set", "\n", "# [2] -> Test partition", "\n", "df_new", ".", "append", "(", "df_new", "[", "0", "]", "[", "df_new", "[", "0", "]", "[", "'FoldID'", "]", "==", "fold_id", "]", ".", "drop", "(", "columns", "=", "[", "'FoldID'", "]", ")", ")", "\n", "df_new", "[", "0", "]", "=", "df_new", "[", "0", "]", ".", "drop", "(", "df_new", "[", "1", "]", ".", "index", ")", ".", "drop", "(", "columns", "=", "[", "'FoldID'", "]", ")", "\n", "df_new", ".", "append", "(", "df", ".", "loc", "[", "df", "[", "'partition'", "]", "==", "'test'", "]", ".", "drop", "(", "columns", "=", "[", "'partition'", ",", "'FoldID'", "]", ")", ")", "\n", "return", "df_new", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.UAREvaluation.majority": [[9, 26], ["collections.Counter", "len", "collections.Counter.items"], "function", ["None"], ["def", "majority", "(", "arr", ")", ":", "\n", "# convert array into dictionary", "\n", "    ", "freqDict", "=", "Counter", "(", "arr", ")", "\n", "# traverse dictionary and check majority element", "\n", "size", "=", "len", "(", "arr", ")", "\n", "major_key", "=", "None", "\n", "major_val", "=", "1", "\n", "for", "(", "key", ",", "val", ")", "in", "freqDict", ".", "items", "(", ")", ":", "\n", "        ", "if", "(", "val", ">", "(", "size", "/", "2", ")", ")", ":", "\n", "            ", "return", "key", "\n", "", "else", ":", "\n", "            ", "if", "val", ">", "major_val", ":", "\n", "                ", "major_key", "=", "key", "\n", "major_val", "=", "val", "\n", "", "elif", "val", "==", "major_val", ":", "\n", "                ", "major_key", "=", "None", "\n", "", "", "", "return", "major_key", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.UAREvaluation.majority_voting_pred": [[27, 44], ["len", "list", "UAREvaluation.majority", "voted_preds.append", "map"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.UAREvaluation.majority"], ["", "def", "majority_voting_pred", "(", "predictions", ",", "weight_index", "=", "None", ")", ":", "\n", "    ", "i", "=", "0", "\n", "voted_preds", "=", "[", "]", "\n", "len_pred", "=", "len", "(", "predictions", "[", "0", "]", ")", "\n", "while", "i", "<", "len_pred", ":", "\n", "        ", "pred_arr", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "i", "]", ",", "predictions", ")", ")", "\n", "mv", "=", "majority", "(", "pred_arr", ")", "\n", "default_val", "=", "'M'", "\n", "if", "mv", "is", "None", ":", "\n", "            ", "if", "weight_index", "is", "not", "None", ":", "\n", "                ", "mv", "=", "predictions", "[", "weight_index", "]", "[", "i", "]", "\n", "# Medium is chosen if each classifier predicts a different label", "\n", "", "else", ":", "\n", "                ", "mv", "=", "default_val", "\n", "", "", "voted_preds", ".", "append", "(", "mv", ")", "\n", "i", "+=", "1", "\n", "", "return", "voted_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.UAREvaluation.maximum": [[45, 48], ["max"], "function", ["None"], ["", "def", "maximum", "(", "a", ",", "b", ",", "c", ")", ":", "\n", "    ", "list", "=", "[", "a", ",", "b", ",", "c", "]", "\n", "return", "max", "(", "list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.UAREvaluation.ensemble_different_models": [[49, 81], ["UAREvaluation.majority_voting_pred", "len", "UAREvaluation.majority_voting_pred", "pandas.DataFrame().to_csv", "print", "pandas.DataFrame().to_csv", "joblib.load", "clf_pred.append", "print", "UAREvaluation.evaluate", "joblib.load.predict", "UAREvaluation.evaluate", "pandas.DataFrame", "pandas.DataFrame", "str"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.UAREvaluation.majority_voting_pred", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.UAREvaluation.majority_voting_pred", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.load", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.UAREvaluation.evaluate", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.UAREvaluation.evaluate"], ["", "def", "ensemble_different_models", "(", "features", ",", "features_descr", ",", "y", ")", ":", "\n", "    ", "clf_pred", "=", "[", "]", "\n", "majority_pred", "=", "{", "}", "\n", "num_models", "=", "3", "\n", "f", "=", "0", "\n", "i", "=", "0", "\n", "for", "exp", "in", "[", "\"dev\"", ",", "\"test\"", "]", ":", "\n", "        ", "x_index", "=", "1", "if", "exp", "==", "\"dev\"", "else", "0", "\n", "y_test", "=", "y", "[", "1", "]", "if", "exp", "==", "'dev'", "else", "None", "\n", "while", "f", "<", "len", "(", "features_descr", ")", ":", "\n", "            ", "while", "i", "<", "num_models", ":", "\n", "                ", "clf", "=", "joblib", ".", "load", "(", "\"data/models/\"", "+", "features_descr", "[", "f", "]", "+", "\"_fold\"", "+", "str", "(", "i", ")", "+", "\".pkl\"", ")", "\n", "clf_pred", ".", "append", "(", "clf", ".", "predict", "(", "features", "[", "f", "]", "[", "x_index", "]", ")", ")", "\n", "i", "+=", "1", "\n", "", "i", "=", "0", "\n", "hard_pred", "=", "majority_voting_pred", "(", "clf_pred", ")", "\n", "if", "exp", "==", "\"dev\"", ":", "\n", "                ", "print", "(", "\n", "\"DEVEL SCORE: of the majority voting of 3 models that are trained on different set for the feature \"", ",", "\n", "features_descr", "[", "f", "]", ",", "evaluate", "(", "hard_pred", ",", "y_test", ")", ")", "\n", "", "majority_pred", "[", "features_descr", "[", "f", "]", "]", "=", "hard_pred", "\n", "clf_pred", "=", "[", "]", "\n", "f", "+=", "1", "\n", "", "ensemble_pred", "=", "majority_voting_pred", "(", "[", "majority_pred", "[", "\"ft_polarity\"", "]", ",", "majority_pred", "[", "\"bows\"", "]", ",", "majority_pred", "[", "\"dict\"", "]", "]", ",", "\n", "weight_index", "=", "0", ")", "\n", "if", "exp", "==", "\"dev\"", ":", "\n", "            ", "pd", ".", "DataFrame", "(", "ensemble_pred", ")", ".", "to_csv", "(", "\"data/predictions/fold4_dev_predictions.csv\"", ")", "\n", "print", "(", "\"DEVEL SCORE: (Majority voting) score of the ensemble model (Fasttext+Polarity - TFIDF - Dictionary) \"", "\n", "\"on blind set: \"", ",", "evaluate", "(", "ensemble_pred", ",", "y_test", ")", ")", "\n", "", "else", ":", "\n", "            ", "pd", ".", "DataFrame", "(", "ensemble_pred", ")", ".", "to_csv", "(", "\"data/predictions/test_predictions.csv\"", ")", "\n", "", "", "return", "ensemble_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.UAREvaluation.tune_on_devset": [[82, 116], ["max", "print", "print", "print", "sklearn.svm.SVC", "sklearn.svm.SVC.fit", "str", "sklearn.svm.SVC", "sklearn.svm.SVC.fit", "sklearn.svm.SVC.predict", "UAREvaluation.evaluate", "uar_scores.append", "sklearn.svm.SVC.predict", "UAREvaluation.evaluate", "str"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.UAREvaluation.evaluate", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.UAREvaluation.evaluate"], ["", "def", "tune_on_devset", "(", "X_train", ",", "y_train", ",", "X_devel", ",", "y_devel", ")", ":", "\n", "    ", "uar_scores", "=", "[", "]", "\n", "# score representations with SVM on different complexity levels", "\n", "complexities", "=", "[", "1e-5", ",", "1e-4", ",", "1e-3", ",", "1e-2", ",", "1e-1", ",", "1e0", ",", "0.20", ",", "0.25", ",", "0.30", ",", "0.58", ",", "0.8", ",", "0.9", ",", "1", ",", "1.1", ",", "1.2", ",", "1.4", ",", "1.5", ",", "2", ",", "10", "]", "\n", "kernels", "=", "[", "\"sigmoid\"", ",", "\"linear\"", ",", "\"rbf\"", ",", "\"poly\"", "]", "\n", "gamma_val", "=", "[", "1e-1", ",", "1", ",", "1e1", ",", "'scale'", "]", "\n", "kernel_dict", "=", "{", "}", "\n", "complexity_dict", "=", "{", "}", "\n", "gamma_dict", "=", "{", "}", "\n", "best_train_uar", "=", "{", "}", "\n", "for", "k", "in", "kernels", ":", "\n", "        ", "for", "g", "in", "gamma_val", ":", "\n", "            ", "for", "c", "in", "complexities", ":", "\n", "                ", "clf", "=", "SVC", "(", "C", "=", "c", ",", "random_state", "=", "0", ",", "kernel", "=", "k", ",", "gamma", "=", "g", ",", "probability", "=", "True", ")", "\n", "clf", ".", "fit", "(", "X_train", ",", "y_train", ")", "\n", "y_pred", "=", "clf", ".", "predict", "(", "X_devel", ")", "\n", "UAR_score", "=", "evaluate", "(", "y_pred", ",", "y_devel", ")", "\n", "uar_scores", ".", "append", "(", "UAR_score", ")", "\n", "y_train_pred", "=", "clf", ".", "predict", "(", "X_train", ")", "\n", "best_train_uar", "[", "str", "(", "UAR_score", ")", "]", "=", "evaluate", "(", "y_train_pred", ",", "y_train", ")", "\n", "kernel_dict", "[", "uar_scores", "[", "-", "1", "]", "]", "=", "k", "\n", "complexity_dict", "[", "uar_scores", "[", "-", "1", "]", "]", "=", "c", "\n", "gamma_dict", "[", "uar_scores", "[", "-", "1", "]", "]", "=", "g", "\n", "", "", "", "UAR_dev", "=", "max", "(", "uar_scores", ")", "\n", "print", "(", "\"UAR dev is\"", ",", "UAR_dev", ")", "\n", "train_UAR", "=", "best_train_uar", "[", "str", "(", "UAR_dev", ")", "]", "\n", "print", "(", "\"UAR train is\"", ",", "train_UAR", ")", "\n", "best_kernel", "=", "kernel_dict", "[", "UAR_dev", "]", "\n", "best_comp", "=", "complexity_dict", "[", "UAR_dev", "]", "\n", "best_gamma", "=", "gamma_dict", "[", "UAR_dev", "]", "\n", "print", "(", "\"best kernel and best comp pair: \"", ",", "best_kernel", ",", "best_comp", ",", "best_gamma", ")", "\n", "clf", "=", "SVC", "(", "C", "=", "best_comp", ",", "random_state", "=", "0", ",", "kernel", "=", "best_kernel", ",", "gamma", "=", "best_gamma", ",", "probability", "=", "True", ")", "\n", "clf", ".", "fit", "(", "X_train", ",", "y_train", ")", "\n", "return", "clf", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.UAREvaluation.evaluate": [[117, 120], ["sklearn.metrics.recall_score"], "function", ["None"], ["", "def", "evaluate", "(", "y_pred", ",", "y", ")", ":", "\n", "# Evaluation", "\n", "    ", "return", "recall_score", "(", "y", ",", "y_pred", ",", "average", "=", "'macro'", ")", "*", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.UAREvaluation.k_fold_cv": [[121, 134], ["sklearn.model_selection.PredefinedSplit", "sklearn.model_selection.PredefinedSplit.split", "UAREvaluation.tune_on_devset", "joblib.dump", "pandas.read_csv", "str"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.scripts.UAREvaluation.tune_on_devset"], ["", "def", "k_fold_cv", "(", "X", ",", "y", ",", "feature_desc", ")", ":", "\n", "# since fold 4 will be used as a blind set and not part of training, it is removed from fold_ids list.", "\n", "    ", "fold_ids", "=", "pd", ".", "read_csv", "(", "\"data/raw_data/CV_fold_ids_trval.csv\"", ")", "[", "'FoldID'", "]", "[", "0", ":", "132", "]", "\n", "ps", "=", "PredefinedSplit", "(", "fold_ids", ")", "\n", "fold_id", "=", "0", "\n", "y", "=", "y", "[", "valence_classifier", ".", "label_type", "]", "\n", "for", "train_index", ",", "test_index", "in", "ps", ".", "split", "(", ")", ":", "\n", "        ", "X_train", ",", "X_test", "=", "X", ".", "iloc", "[", "train_index", "]", ",", "X", ".", "iloc", "[", "test_index", "]", "\n", "y_train", ",", "y_test", "=", "y", "[", "train_index", "]", ",", "y", "[", "test_index", "]", "\n", "clf", "=", "tune_on_devset", "(", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ")", "\n", "joblib", ".", "dump", "(", "clf", ",", "\"data/models/\"", "+", "feature_desc", "+", "\"_fold\"", "+", "str", "(", "fold_id", ")", "+", "'.pkl'", ")", "\n", "fold_id", "+=", "1", "\n", "", "return", "\n", "", ""]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.polarity_extractor.read_data": [[12, 15], ["pandas.read_csv"], "function", ["None"], ["def", "read_data", "(", "filename", ",", "delim", ")", ":", "\n", "  ", "df", "=", "pd", ".", "read_csv", "(", "filename", ",", "delimiter", "=", "delim", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.polarity_extractor.load_analyzer": [[16, 21], ["nltk.download", "nltk.sentiment.vader.SentimentIntensityAnalyzer", "flair.models.TextClassifier.load"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.load"], ["", "def", "load_analyzer", "(", ")", ":", "\n", "  ", "nltk", ".", "download", "(", "'vader_lexicon'", ")", "\n", "sid", "=", "SentimentIntensityAnalyzer", "(", ")", "\n", "flair_sentiment", "=", "flair", ".", "models", ".", "TextClassifier", ".", "load", "(", "'en-sentiment'", ")", "\n", "return", "(", "sid", ",", "flair_sentiment", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.polarity_extractor.nltk_get_sentiment": [[24, 26], ["sid.polarity_scores"], "function", ["None"], ["def", "nltk_get_sentiment", "(", "sentence", ")", ":", "\n", "    ", "return", "sid", ".", "polarity_scores", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.polarity_extractor.textblob_get_sentiment": [[27, 30], ["textblob.TextBlob"], "function", ["None"], ["", "def", "textblob_get_sentiment", "(", "sentence", ")", ":", "\n", "# we can use subjectivity analysis from textblob result since polarity prediction is not as good as NLTK.", "\n", "    ", "return", "TextBlob", "(", "sentence", ")", ".", "sentiment", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.polarity_extractor.flair_get_sentiment": [[31, 40], ["flair.data.Sentence", "flair_sentiment.predict", "map", "flair.data.Sentence.find", "abs", "flair.data.Sentence.find", "float"], "function", ["None"], ["", "def", "flair_get_sentiment", "(", "sentence", ")", ":", "\n", "    ", "s", "=", "flair", ".", "data", ".", "Sentence", "(", "sentence", ")", "\n", "flair_sentiment", ".", "predict", "(", "s", ")", "\n", "total_sentiment", "=", "s", ".", "labels", "\n", "s", "=", "' '", ".", "join", "(", "map", "(", "str", ",", "total_sentiment", ")", ")", "\n", "prob", "=", "s", "[", "s", ".", "find", "(", "\"(\"", ")", "+", "1", ":", "s", ".", "find", "(", "\")\"", ")", "]", "\n", "if", "\"NEGATIVE\"", "in", "s", ":", "\n", "        ", "prob", "=", "1", "-", "abs", "(", "float", "(", "prob", ")", ")", "\n", "", "return", "(", "prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.polarity_extractor.write_sentiment_features": [[42, 56], ["pandas.DataFrame", "polarity_extractor.get_sentiment_features_per_story", "numpy.asarray", "pd.DataFrame.to_csv"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.polarity_extractor.get_sentiment_features_per_story"], ["", "def", "write_sentiment_features", "(", "df", ",", "filename", ")", ":", "\n", "    ", "df_final", "=", "pd", ".", "DataFrame", "(", ")", "\n", "sent_arr", "=", "get_sentiment_features_per_story", "(", "df", ")", "\n", "polarity_features", "=", "np", ".", "asarray", "(", "sent_arr", ")", "\n", "df_final", "[", "\"polarity\"", "]", "=", "polarity_features", "[", ":", ",", "0", "]", "\n", "df_final", "[", "\"pos\"", "]", "=", "polarity_features", "[", ":", ",", "1", "]", "\n", "df_final", "[", "\"neg\"", "]", "=", "polarity_features", "[", ":", ",", "2", "]", "\n", "df_final", "[", "\"neu\"", "]", "=", "polarity_features", "[", ":", ",", "3", "]", "\n", "df_final", "[", "\"compound\"", "]", "=", "polarity_features", "[", ":", ",", "4", "]", "\n", "df_final", "[", "\"subjectivity\"", "]", "=", "polarity_features", "[", ":", ",", "5", "]", "\n", "df_final", "[", "\"flair_prob\"", "]", "=", "polarity_features", "[", ":", ",", "6", "]", "\n", "df_final", "[", "\"flair_label\"", "]", "=", "polarity_features", "[", ":", ",", "7", "]", "\n", "\n", "df_final", ".", "to_csv", "(", "filename", "+", "\"polarity_features.csv\"", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.polarity_extractor.compute_all_sent_features": [[57, 63], ["polarity_extractor.nltk_get_sentiment", "polarity_extractor.textblob_get_sentiment", "polarity_extractor.flair_get_sentiment"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.polarity_extractor.nltk_get_sentiment", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.polarity_extractor.textblob_get_sentiment", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.polarity_extractor.flair_get_sentiment"], ["", "def", "compute_all_sent_features", "(", "text", ")", ":", "\n", "    ", "sentiment", "=", "nltk_get_sentiment", "(", "text", ")", "\n", "textblob_sent", "=", "textblob_get_sentiment", "(", "text", ")", "\n", "(", "flair_prob", ")", "=", "flair_get_sentiment", "(", "text", ")", "\n", "return", "(", "[", "textblob_sent", "[", "0", "]", ",", "sentiment", "[", "\"pos\"", "]", ",", "sentiment", "[", "\"neg\"", "]", ",", "\n", "sentiment", "[", "\"neu\"", "]", ",", "sentiment", "[", "\"compound\"", "]", ",", "textblob_sent", "[", "1", "]", ",", "flair_prob", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.polarity_extractor.get_sentiment_features_per_story": [[64, 75], ["story_arr.append", "print", "story_arr.append", "polarity_extractor.compute_all_sent_features"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.polarity_extractor.compute_all_sent_features"], ["", "def", "get_sentiment_features_per_story", "(", "X", ")", ":", "\n", "    ", "story_arr", "=", "[", "]", "\n", "i", "=", "0", "\n", "for", "story", "in", "X", ":", "\n", "        ", "if", "story", "is", "not", "None", ":", "\n", "          ", "story_arr", ".", "append", "(", "compute_all_sent_features", "(", "story", ")", ")", "\n", "i", "=", "i", "+", "1", "\n", "print", "(", "\"story\"", ",", "i", ")", "\n", "", "else", ":", "\n", "            ", "story_arr", ".", "append", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "", "return", "story_arr", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.load": [[13, 17], ["os.path.join", "pandas.read_csv"], "function", ["None"], ["def", "load", "(", "path", ")", ":", "\n", "\t", "path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'SentiWordNet.csv'", ")", "\n", "senti_dict", "=", "pd", ".", "read_csv", "(", "path", ",", "dtype", "=", "{", "'ID'", ":", "int", "}", ")", "\n", "return", "senti_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.tokenize_text": [[18, 39], ["nltk.word_tokenize", "len", "token_list.append", "token_list.append", "len"], "function", ["None"], ["", "def", "tokenize_text", "(", "txt", ",", "negation", "=", "False", ")", ":", "\n", "\n", "# find all the combinations of letters (1+)", "\n", "\t", "tokens", "=", "nltk", ".", "word_tokenize", "(", "txt", ")", "\n", "\n", "if", "negation", ":", "\n", "\n", "\t\t", "i", "=", "0", "\n", "token_list", "=", "[", "]", "\n", "\n", "while", "i", "<", "len", "(", "tokens", ")", ":", "\n", "\t\t\t", "if", "tokens", "[", "i", "]", "==", "'not'", "and", "i", "!=", "len", "(", "tokens", ")", "-", "1", ":", "\n", "\t\t\t\t", "token_list", ".", "append", "(", "tokens", "[", "i", "]", "+", "' '", "+", "tokens", "[", "i", "+", "1", "]", ")", "\n", "i", "+=", "1", "\n", "", "else", ":", "\n", "\t\t\t\t", "token_list", ".", "append", "(", "tokens", "[", "i", "]", ")", "\n", "", "i", "+=", "1", "\n", "", "return", "token_list", "\n", "\n", "", "else", ":", "\n", "\t\t", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.map_pos": [[41, 47], ["None"], "function", ["None"], ["", "", "def", "map_pos", "(", "pos", ")", ":", "\n", "\n", "\t", "if", "pos", "==", "'j'", ":", "\n", "\t\t", "return", "'a'", "\n", "", "else", ":", "\n", "\t\t", "return", "pos", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.look_up": [[49, 66], ["[].to_list", "all", "numpy.round", "numpy.mean"], "function", ["None"], ["", "", "def", "look_up", "(", "token", ",", "pos", ",", "ref_dict", ",", "score_type", ",", "flip", ")", ":", "\n", "\n", "# Find the right token", "\n", "\t", "score_list", "=", "ref_dict", "[", "ref_dict", "[", "'Word'", "]", "==", "token", "]", "[", "score_type", "]", ".", "to_list", "(", ")", "\n", "\n", "# Find the right Part of Speech", "\n", "# score_list = score_list[score_list['POS']==pos]", "\n", "\n", "if", "not", "all", "(", "v", "==", "0", "for", "v", "in", "score_list", ")", ":", "\n", "\t\t", "score", "=", "np", ".", "round", "(", "np", ".", "mean", "(", "score_list", ")", ",", "5", ")", "\n", "if", "flip", ":", "\n", "\t\t\t", "score", "=", "-", "score", "\n", "token", "=", "flip", "+", "' '", "+", "token", "\n", "", "return", "(", "token", ",", "pos", ",", "score", ")", "\n", "\n", "", "else", ":", "\n", "\t\t", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.calc_score": [[67, 133], ["pbar.update", "[].lower", "SentiWordNet.map_pos", "SentiWordNet.look_up", "lemmatizer.lemmatize.startswith", "scores.append", "len", "lemmatizer.lemmatize.split", "lemmatizer.lemmatize.split", "lemmatizer.lemmatize", "SentiWordNet.look_up", "lemmatizer.lemmatize.split", "scores.append"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.map_pos", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.look_up", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.look_up"], ["", "", "def", "calc_score", "(", "tokens", ",", "score_type", ",", "ref_dict", ",", "lemmatizer", ",", "pbar", ")", ":", "\n", "\t", "'''\n\tFind the scores associated with each token return a dictionary with words as keys and scores as values  \n\n\tAccepts:\n\t\ttokens - a list of words\n\t\tref_dict - sentiment dictionary \n\n\tReturns:\n\t\tscore_dict - a dictionary of scores \n\t'''", "\n", "scores", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "\n", "# find an average score for all different uses of the same word", "\n", "\t\t", "pos_tag", "=", "token", "[", "1", "]", "[", "0", "]", ".", "lower", "(", ")", "\n", "pos_tag", "=", "map_pos", "(", "pos_tag", ")", "\n", "token", "=", "token", "[", "0", "]", "\n", "\n", "flip", "=", "False", "\n", "if", "len", "(", "token", ".", "split", "(", "' '", ")", ")", "==", "2", "and", "token", ".", "startswith", "(", "'no'", ")", ":", "\n", "\t\t\t", "flip", "=", "token", ".", "split", "(", "' '", ")", "[", "0", "]", "\n", "token", "=", "token", ".", "split", "(", "' '", ")", "[", "1", "]", "\n", "\n", "\n", "", "new_score", "=", "look_up", "(", "token", ",", "pos_tag", ",", "ref_dict", ",", "score_type", ",", "flip", "=", "flip", ")", "\n", "if", "new_score", ":", "\n", "\t\t\t", "scores", ".", "append", "(", "new_score", ")", "\n", "\n", "# Repeat for the lemmata", "\n", "", "else", ":", "\n", "\t\t\t", "try", ":", "\n", "\t\t\t\t", "token", "=", "lemmatizer", ".", "lemmatize", "(", "token", ",", "pos", "=", "pos_tag", ")", "\n", "new_score", "=", "look_up", "(", "token", ",", "pos_tag", ",", "ref_dict", ",", "score_type", ",", "flip", "=", "flip", ")", "\n", "if", "new_score", ":", "\n", "\t\t\t\t\t", "scores", ".", "append", "(", "new_score", ")", "\n", "", "", "except", ":", "\n", "\t\t\t\t", "pass", "\n", "\n", "", "", "", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "\n", "# if len(t_score) == 0:", "\n", "\n", "# \tinf_df = ref_dict[ref_dict['Word'] == t_lemma]", "\n", "# \tif len(inf_df) >= 1:", "\n", "\n", "# \t\tscore_list = list(inf_df['PosScore'].values)", "\n", "# \t\tif not all(v == 0 for v in score_list):", "\n", "# \t\t\tif flip:", "\n", "# \t\t\t\tscore_list = [-x for x in score_list]", "\n", "# \t\t\t\ttoken = neg_part + ' ' + token", "\n", "\n", "# \t\t\tscore_dict[token] = score_list", "\n", "\n", "# else:", "\n", "# \tscore_list = list(ref_dict[ref_dict['Word'] == token]['PosScore'].values)", "\n", "\n", "# \tif not all(v == 0 for v in score_list):", "\n", "# \t\tif flip:", "\n", "# \t\t\tscore_list = [-x for x in score_list]", "\n", "# \t\t\ttoken = neg_part + ' ' + token", "\n", "\n", "# \t\tscore_dict[token] = score_list", "\n", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.calc_pos_score_old": [[134, 191], ["score_dict.keys", "len", "lemmatizer.lemmatize", "len", "list", "token.split", "token.split", "token.split", "len", "list", "all", "all"], "function", ["None"], ["", "def", "calc_pos_score_old", "(", "tokens", ",", "ref_dict", ")", ":", "\n", "\t", "'''\n\tFind the scores associated with each token return a dictionary with words as keys and scores as values  \n\n\tAccepts:\n\t\ttokens - a list of words\n\t\tref_dict - sentiment dictionary \n\n\tReturns:\n\t\tscore_dict - a dictionary of scores \n\t'''", "\n", "score_dict", "=", "{", "}", "\n", "for", "token", "in", "tokens", ":", "\n", "\n", "\t\t", "if", "token", "in", "score_dict", ".", "keys", "(", ")", ":", "\n", "\t\t\t", "break", "\n", "\n", "", "flip", "=", "False", "\n", "\n", "# Process tokens with negation", "\n", "if", "len", "(", "token", ".", "split", "(", "' '", ")", ")", "==", "2", ":", "\n", "\t\t\t", "neg_part", "=", "token", ".", "split", "(", "' '", ")", "[", "0", "]", "\n", "token", "=", "token", ".", "split", "(", "' '", ")", "[", "1", "]", "\n", "flip", "=", "True", "\n", "\n", "", "try", ":", "\n", "\t\t\t", "t_lemma", "=", "lemmatizer", ".", "lemmatize", "(", "token", ")", "\n", "", "except", ":", "\n", "\t\t\t", "t_lemma", "=", "None", "\n", "\n", "# find an average score for all different uses of the same word", "\n", "", "t_score", "=", "ref_dict", "[", "ref_dict", "[", "'Word'", "]", "==", "token", "]", "[", "'PosScore'", "]", "\n", "\n", "if", "len", "(", "t_score", ")", "==", "0", ":", "\n", "\n", "\t\t\t", "inf_df", "=", "ref_dict", "[", "ref_dict", "[", "'Word'", "]", "==", "t_lemma", "]", "\n", "if", "len", "(", "inf_df", ")", ">=", "1", ":", "\n", "\n", "\t\t\t\t", "score_list", "=", "list", "(", "inf_df", "[", "'PosScore'", "]", ".", "values", ")", "\n", "if", "not", "all", "(", "v", "==", "0", "for", "v", "in", "score_list", ")", ":", "\n", "\t\t\t\t\t", "if", "flip", ":", "\n", "\t\t\t\t\t\t", "score_list", "=", "[", "-", "x", "for", "x", "in", "score_list", "]", "\n", "token", "=", "neg_part", "+", "' '", "+", "token", "\n", "\n", "", "score_dict", "[", "token", "]", "=", "score_list", "\n", "\n", "", "", "", "else", ":", "\n", "\t\t\t", "score_list", "=", "list", "(", "ref_dict", "[", "ref_dict", "[", "'Word'", "]", "==", "token", "]", "[", "'PosScore'", "]", ".", "values", ")", "\n", "\n", "if", "not", "all", "(", "v", "==", "0", "for", "v", "in", "score_list", ")", ":", "\n", "\t\t\t\t", "if", "flip", ":", "\n", "\t\t\t\t\t", "score_list", "=", "[", "-", "x", "for", "x", "in", "score_list", "]", "\n", "token", "=", "neg_part", "+", "' '", "+", "token", "\n", "\n", "", "score_dict", "[", "token", "]", "=", "score_list", "\n", "\n", "", "", "", "return", "score_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.calc_neg_score": [[193, 253], ["score_dict.keys", "len", "lemmatizer.lemmatize", "len", "list", "token.split", "token.split", "token.split", "len", "list", "all", "all"], "function", ["None"], ["", "def", "calc_neg_score", "(", "tokens", ",", "ref_dict", ")", ":", "\n", "\t", "'''\n\tFind the scores associated with each token return a dictionary with words as keys and scores as values \n\n\tAccepts:\n\t\ttokens - a list of words\n\t\tref_dict - sentiment dictionary \n\n\tReturns:\n\t\tscore_dict - a dictionary of scores \n\t'''", "\n", "\n", "score_dict", "=", "{", "}", "\n", "for", "token", "in", "tokens", ":", "\n", "\n", "\t\t", "if", "token", "in", "score_dict", ".", "keys", "(", ")", ":", "\n", "\t\t\t", "break", "\n", "\n", "", "flip", "=", "False", "\n", "\n", "# Process tokens with negation", "\n", "if", "len", "(", "token", ".", "split", "(", "' '", ")", ")", "==", "2", ":", "\n", "\t\t\t", "neg_part", "=", "token", ".", "split", "(", "' '", ")", "[", "0", "]", "\n", "token", "=", "token", ".", "split", "(", "' '", ")", "[", "1", "]", "\n", "flip", "=", "True", "\n", "\n", "", "try", ":", "\n", "\t\t\t", "t_lemma", "=", "lemmatizer", ".", "lemmatize", "(", "token", ")", "\n", "", "except", ":", "\n", "\t\t\t", "t_lemma", "=", "None", "\n", "\n", "# find an average score for all different uses of the same word", "\n", "", "t_score", "=", "ref_dict", "[", "ref_dict", "[", "'Word'", "]", "==", "token", "]", "[", "'NegScore'", "]", "\n", "\n", "if", "len", "(", "t_score", ")", "==", "0", ":", "\n", "\n", "\t\t\t", "inf_df", "=", "ref_dict", "[", "ref_dict", "[", "'Word'", "]", "==", "t_lemma", "]", "\n", "if", "len", "(", "inf_df", ")", ">=", "1", ":", "\n", "\n", "\t\t\t\t", "score_list", "=", "list", "(", "inf_df", "[", "'NegScore'", "]", ".", "values", ")", "\n", "if", "not", "all", "(", "v", "==", "0", "for", "v", "in", "score_list", ")", ":", "\n", "\t\t\t\t\t", "if", "flip", ":", "\n", "\t\t\t\t\t\t", "score_list", "=", "[", "-", "x", "for", "x", "in", "score_list", "]", "\n", "token", "=", "neg_part", "+", "' '", "+", "token", "\n", "\n", "", "score_list", "=", "[", "-", "x", "for", "x", "in", "score_list", "]", "\n", "score_dict", "[", "token", "]", "=", "score_list", "\n", "\n", "", "", "", "else", ":", "\n", "\t\t\t", "score_list", "=", "list", "(", "ref_dict", "[", "ref_dict", "[", "'Word'", "]", "==", "token", "]", "[", "'NegScore'", "]", ".", "values", ")", "\n", "\n", "if", "not", "all", "(", "v", "==", "0", "for", "v", "in", "score_list", ")", ":", "\n", "\t\t\t\t", "if", "flip", ":", "\n", "\t\t\t\t\t", "score_list", "=", "[", "-", "x", "for", "x", "in", "score_list", "]", "\n", "token", "=", "neg_part", "+", "' '", "+", "token", "\n", "\n", "", "score_list", "=", "[", "-", "x", "for", "x", "in", "score_list", "]", "\n", "score_dict", "[", "token", "]", "=", "score_list", "\n", "\n", "", "", "", "return", "score_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.calc_score_old": [[255, 263], ["text.lower.lower", "SentiWordNet.tokenize_text", "nltk.pos_tag", "function"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.tfidf_extractor.tokenize_text"], ["", "def", "calc_score_old", "(", "text", ",", "function", ",", "ref_dict", ",", "negation", ")", ":", "\n", "\n", "\n", "\t", "text", "=", "text", ".", "lower", "(", ")", "\n", "tokens", "=", "tokenize_text", "(", "text", ",", "negation", ")", "\n", "pos_tokens", "=", "nltk", ".", "pos_tag", "(", "tokens", ")", "\n", "score", "=", "function", "(", "tokens", ",", "ref_dict", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.merge_dicts": [[265, 280], ["dict2.keys", "dict1.keys", "dict1[].append"], "function", ["None"], ["", "def", "merge_dicts", "(", "dict1", ",", "dict2", ")", ":", "\n", "\t", "'''\n\tArguments:\n\t\tdict1 - series with dict of positive values\n\t\tdict2 - series with dict of negative values\n\t'''", "\n", "\n", "for", "key", "in", "dict2", ".", "keys", "(", ")", ":", "\n", "\t\t", "if", "key", "not", "in", "dict1", ".", "keys", "(", ")", ":", "\n", "\t\t\t", "dict1", "[", "key", "]", "=", "[", "]", "\n", "\n", "", "for", "val", "in", "dict2", "[", "key", "]", ":", "\n", "\t\t\t", "dict1", "[", "key", "]", ".", "append", "(", "val", ")", "\n", "\n", "", "", "return", "dict1", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.merge_scores": [[282, 295], ["range", "len", "len", "len", "total_scores.append", "SentiWordNet.merge_dicts"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.merge_dicts"], ["", "def", "merge_scores", "(", "pos", ",", "neg", ")", ":", "\n", "\t", "'''\n\tArguments:\n\t\tpos - series with dict of positive values\n\t\tneg - series with dict of negative values\n\t'''", "\n", "\n", "total_scores", "=", "[", "]", "\n", "assert", "len", "(", "pos", ")", "==", "len", "(", "neg", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "pos", ")", ")", ":", "\n", "\t\t", "total_scores", ".", "append", "(", "merge_dicts", "(", "pos", ".", "iloc", "[", "i", "]", ",", "neg", ".", "iloc", "[", "i", "]", ")", ")", "\n", "\n", "", "return", "total_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.find_sum": [[297, 313], ["json.loads.keys", "json.loads", "numpy.sum", "json.loads.replace", "list"], "function", ["None"], ["", "def", "find_sum", "(", "score_dict", ")", ":", "\n", "\t", "'''\n\tArguments:\n\t\tscore_dict - dictionary with original scores for every word\n\tReturns:\n\t\tdictionary with a single sum score for every word\n\t'''", "\n", "try", ":", "\n", "\t\t", "score_dict", "=", "json", ".", "loads", "(", "score_dict", ".", "replace", "(", "'\\''", ",", "'\\\"'", ")", ")", "\n", "", "except", ":", "\n", "\t\t", "pass", "\n", "", "new_dict", "=", "{", "}", "\n", "for", "key", "in", "score_dict", ".", "keys", "(", ")", ":", "\n", "\t\t", "new_dict", "[", "key", "]", "=", "np", ".", "sum", "(", "list", "(", "score_dict", "[", "key", "]", ")", ")", "\n", "\n", "", "return", "new_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.find_mean": [[315, 331], ["json.loads.keys", "json.loads", "numpy.mean", "json.loads.replace", "list"], "function", ["None"], ["", "def", "find_mean", "(", "score_dict", ")", ":", "\n", "\t", "'''\n\tArguments:\n\t\tscore_dict - dictionary with original scores for every word\n\tReturns:\n\t\tdictionary with a single mean score for every word\n\t'''", "\n", "try", ":", "\n", "\t\t", "score_dict", "=", "json", ".", "loads", "(", "score_dict", ".", "replace", "(", "'\\''", ",", "'\\\"'", ")", ")", "\n", "", "except", ":", "\n", "\t\t", "pass", "\n", "", "new_dict", "=", "{", "}", "\n", "for", "key", "in", "score_dict", ".", "keys", "(", ")", ":", "\n", "\t\t", "new_dict", "[", "key", "]", "=", "np", ".", "mean", "(", "list", "(", "score_dict", "[", "key", "]", ")", ")", "\n", "\n", "", "return", "new_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.find_min": [[333, 348], ["json.loads.keys", "json.loads", "numpy.min", "json.loads.replace", "list"], "function", ["None"], ["", "def", "find_min", "(", "score_dict", ")", ":", "\n", "\t", "'''\n\tArguments:\n\t\tscore_dict - dictionary with original scores for every word\n\tReturns:\n\t\tdictionary with a single mean score for every word\n\t'''", "\n", "try", ":", "\n", "\t\t", "score_dict", "=", "json", ".", "loads", "(", "score_dict", ".", "replace", "(", "'\\''", ",", "'\\\"'", ")", ")", "\n", "", "except", ":", "\n", "\t\t", "pass", "\n", "", "new_dict", "=", "{", "}", "\n", "for", "key", "in", "score_dict", ".", "keys", "(", ")", ":", "\n", "\t\t", "new_dict", "[", "key", "]", "=", "np", ".", "min", "(", "list", "(", "score_dict", "[", "key", "]", ")", ")", "\n", "", "return", "new_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.find_max": [[350, 365], ["json.loads.keys", "json.loads", "numpy.max", "json.loads.replace", "list"], "function", ["None"], ["", "def", "find_max", "(", "score_dict", ")", ":", "\n", "\t", "'''\n\tArguments:\n\t\tscore_dict - dictionary with original scores for every word\n\tReturns:\n\t\tdictionary with a single mean score for every word\n\t'''", "\n", "try", ":", "\n", "\t\t", "score_dict", "=", "json", ".", "loads", "(", "score_dict", ".", "replace", "(", "'\\''", ",", "'\\\"'", ")", ")", "\n", "", "except", ":", "\n", "\t\t", "pass", "\n", "", "new_dict", "=", "{", "}", "\n", "for", "key", "in", "score_dict", ".", "keys", "(", ")", ":", "\n", "\t\t", "new_dict", "[", "key", "]", "=", "np", ".", "max", "(", "list", "(", "score_dict", "[", "key", "]", ")", ")", "\n", "", "return", "new_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.get_tokens": [[367, 409], ["nltk.sent_tokenize", "print", "txt.replace.lower", "txt.replace.replace", "nltk.word_tokenize", "nltk.pos_tag", "final_token_list.append", "len", "token_list.append", "token_list.append", "len"], "function", ["None"], ["", "def", "get_tokens", "(", "txt_list", ",", "negation", ")", ":", "\n", "\t", "'''\n\tCreates tokens of type (word, pos)\n\n\tArguments:\n\t\ttxt_list - list of strings\n\n\tReturns:\n\t\tlist of tuples   \n\t'''", "\n", "final_token_list", "=", "[", "]", "\n", "for", "txt", "in", "nltk", ".", "sent_tokenize", "(", "txt_list", ")", ":", "\n", "\t\t", "print", "(", "txt", ")", "\n", "txt", "=", "txt", ".", "lower", "(", ")", "\n", "txt", "=", "txt", ".", "replace", "(", "r'&quot;'", ",", "r'\"'", ")", "\n", "tokens", "=", "nltk", ".", "word_tokenize", "(", "txt", ")", "\n", "tokens", "=", "nltk", ".", "pos_tag", "(", "tokens", ")", "\n", "final_token_list", ".", "append", "(", "tokens", ")", "\n", "\n", "# ignore for now", "\n", "if", "negation", ":", "\n", "\n", "\t\t\t", "i", "=", "0", "\n", "token_list", "=", "[", "]", "\n", "\n", "while", "i", "<", "len", "(", "tokens", ")", ":", "\n", "\n", "\t\t\t\t", "if", "tokens", "[", "i", "]", "[", "0", "]", "in", "[", "'n\\'t'", ",", "'no'", ",", "'not'", "]", "and", "i", "!=", "len", "(", "tokens", ")", "-", "1", ":", "\n", "\t\t\t\t\t", "if", "tokens", "[", "i", "]", "[", "0", "]", "==", "'n\\'t'", ":", "\n", "\t\t\t\t\t\t", "n", "=", "'not'", "\n", "", "else", ":", "\n", "\t\t\t\t\t\t", "n", "=", "tokens", "[", "i", "]", "[", "0", "]", "\n", "\n", "", "new_token", "=", "(", "n", "+", "' '", "+", "tokens", "[", "i", "+", "1", "]", "[", "0", "]", ",", "tokens", "[", "i", "+", "1", "]", "[", "1", "]", ")", "\n", "token_list", ".", "append", "(", "new_token", ")", "\n", "i", "+=", "1", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "token_list", ".", "append", "(", "tokens", "[", "i", "]", ")", "\n", "", "i", "+=", "1", "\n", "", "return", "token_list", "\n", "\n", "", "", "return", "final_token_list", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.get_scores": [[411, 431], ["print", "data[].apply", "print", "nltk.stem.WordNetLemmatizer", "print", "tqdm.tqdm", "data[].apply.apply", "tqdm.tqdm.close", "print", "tqdm.tqdm", "data[].apply.apply", "tqdm.tqdm.close", "len", "len"], "function", ["None"], ["", "def", "get_scores", "(", "data", ",", "data_column", ",", "s_dict", ",", "negation", "=", "False", ")", ":", "\n", "\t", "print", "(", "data", ".", "columns", ")", "\n", "tokens", "=", "data", "[", "data_column", "]", ".", "apply", "(", "get_tokens", ",", "args", "=", "(", "negation", ",", ")", ")", "\n", "print", "(", "tokens", ")", "\n", "lemmatizer", "=", "WordNetLemmatizer", "(", ")", "\n", "\n", "\n", "print", "(", "'Calculating positive scores'", ")", "\n", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "data", ")", ")", "\n", "pos", "=", "tokens", ".", "apply", "(", "calc_score", ",", "args", "=", "(", "'PosScore'", ",", "s_dict", ",", "lemmatizer", ",", "pbar", ")", ")", "\n", "pbar", ".", "close", "(", ")", "\n", "\n", "print", "(", "'Calculating negative scores'", ")", "\n", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "data", ")", ")", "\n", "neg", "=", "tokens", ".", "apply", "(", "calc_score", ",", "args", "=", "(", "'NegScore'", ",", "s_dict", ",", "lemmatizer", ",", "pbar", ")", ")", "\n", "pbar", ".", "close", "(", ")", "\n", "\n", "data", "[", "'scores_pos_SentiWordNet'", "]", "=", "pos", "\n", "data", "[", "'scores_neg_SentiWordNet'", "]", "=", "neg", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.get_scores_old": [[433, 468], ["print", "data[].apply", "print", "print", "data[].apply", "print", "print", "SentiWordNet.merge_scores", "print", "data[].apply", "data[].apply", "data[].apply", "data[].apply", "lemmatizer.lemmatize"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.merge_scores"], ["", "def", "get_scores_old", "(", "data", ",", "s_dict", ",", "negation", "=", "False", ")", ":", "\n", "\t", "'''\n\tAdd a new column to dataframe that holds a dictionary with words as keys and \n\tsentiment scores from the dictionary as values\n\n\tAccepts:\n\t\tdata - a series with text\n\t\ts_dict - a dataframe with sentiment dictionary words and scores\n\tReturns:\n\t\ta series holding sentiment scores as values of a dictionary \n\t'''", "\n", "try", ":", "\n", "\t\t", "lemma_check", "=", "lemmatizer", ".", "lemmatize", "(", "'check'", ")", "\n", "", "except", ":", "\n", "\t\t", "pass", "\n", "\n", "", "print", "(", "'    Calculating positive scores'", ")", "\n", "pos", "=", "data", "[", "'machine_translation'", "]", ".", "apply", "(", "calc_score", ",", "args", "=", "(", "calc_pos_score_old", ",", "s_dict", ",", "negation", ")", ")", "\n", "print", "(", "pos", ")", "\n", "\n", "print", "(", "'    Calculating negative scores'", ")", "\n", "neg", "=", "data", "[", "'machine_translation'", "]", ".", "apply", "(", "calc_score", ",", "args", "=", "(", "calc_neg_score", ",", "s_dict", ",", "negation", ")", ")", "\n", "print", "(", "neg", ")", "\n", "\n", "print", "(", "'    Merging'", ")", "\n", "both", "=", "merge_scores", "(", "pos", ",", "neg", ")", "\n", "data", "[", "'scores_SentiWordNet'", "]", "=", "both", "\n", "\n", "print", "(", "'    Calculating statistics'", ")", "\n", "data", "[", "'scores_SentiWordNet_min'", "]", "=", "data", "[", "'scores_SentiWordNet'", "]", ".", "apply", "(", "find_min", ")", "\n", "data", "[", "'scores_SentiWordNet_max'", "]", "=", "data", "[", "'scores_SentiWordNet'", "]", ".", "apply", "(", "find_max", ")", "\n", "data", "[", "'scores_SentiWordNet_mean'", "]", "=", "data", "[", "'scores_SentiWordNet'", "]", ".", "apply", "(", "find_mean", ")", "\n", "data", "[", "'scores_SentiWordNet_sum'", "]", "=", "data", "[", "'scores_SentiWordNet'", "]", ".", "apply", "(", "find_sum", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.add_stats_from_list": [[470, 484], ["scores.apply", "scores.apply", "scores.apply", "scores.apply", "scores.apply", "scores.apply"], "function", ["None"], ["", "def", "add_stats_from_list", "(", "data", ")", ":", "\n", "\n", "\t", "for", "s", "in", "[", "'pos'", ",", "'neg'", "]", ":", "\n", "\n", "\t\t", "scores", "=", "data", "[", "'scores_{}_SentiWordNet'", ".", "format", "(", "s", ")", "]", "\n", "\n", "data", "[", "'min_{}_SentiWordNet'", ".", "format", "(", "s", ")", "]", "=", "scores", ".", "apply", "(", "stats", ".", "calc_min_from_list", ")", "\n", "data", "[", "'max_{}_SentiWordNet'", ".", "format", "(", "s", ")", "]", "=", "scores", ".", "apply", "(", "stats", ".", "calc_max_from_list", ")", "\n", "data", "[", "'range_{}_SentiWordNet'", ".", "format", "(", "s", ")", "]", "=", "scores", ".", "apply", "(", "stats", ".", "calc_range_from_list", ")", "\n", "data", "[", "'sum_{}_SentiWordNet'", ".", "format", "(", "s", ")", "]", "=", "scores", ".", "apply", "(", "stats", ".", "calc_sum_from_list", ")", "\n", "data", "[", "'mean_{}_SentiWordNet'", ".", "format", "(", "s", ")", "]", "=", "scores", ".", "apply", "(", "stats", ".", "calc_mean_from_list", ")", "\n", "data", "[", "'num_{}_SentiWordNet'", ".", "format", "(", "s", ")", "]", "=", "scores", ".", "apply", "(", "stats", ".", "calc_num_from_list", ")", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.fasttext_extractor.write_fasttext_features": [[7, 15], ["gensim.models.FastText.load", "fasttext_extractor.normalize_text_fasttext", "pandas.DataFrame", "print", "pd.DataFrame.to_csv"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.load", "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.fasttext_extractor.normalize_text_fasttext"], ["def", "write_fasttext_features", "(", "df", ",", "file_path", ")", ":", "\n", "#load fine-tuned fasttext model.", "\n", "    ", "ft", "=", "FastText", ".", "load", "(", "'data/models/improved_fasttext_model'", ")", "\n", "X_vector", "=", "normalize_text_fasttext", "(", "df", ",", "ft", ")", "\n", "df2", "=", "pd", ".", "DataFrame", "(", "X_vector", ")", "\n", "print", "(", "df2", ".", "shape", ")", "\n", "df2", ".", "to_csv", "(", "file_path", ",", "index", "=", "False", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.fasttext_extractor.normalize_text_fasttext": [[16, 23], ["numpy.array", "list", "result_arr.append", "map", "numpy.mean", "nltk.tokenize.word_tokenize", "x.lower"], "function", ["None"], ["", "def", "normalize_text_fasttext", "(", "data", ",", "ft", ")", ":", "\n", "    ", "result_arr", "=", "[", "]", "\n", "for", "instance", "in", "data", ":", "\n", "        ", "ins_vec", "=", "list", "(", "map", "(", "lambda", "x", ":", "ft", ".", "wv", "[", "x", ".", "lower", "(", ")", "]", ",", "word_tokenize", "(", "instance", ")", ")", ")", "\n", "result_arr", ".", "append", "(", "np", ".", "mean", "(", "ins_vec", ",", "axis", "=", "0", ",", "dtype", "=", "np", ".", "float64", ")", ")", "\n", "", "res_vector", "=", "np", ".", "array", "(", "result_arr", ")", "\n", "return", "res_vector", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.fasttext_extractor.normalize_data": [[24, 30], ["sklearn.preprocessing.StandardScaler", "scaler.fit.fit", "scaler.fit.transform", "scaler.fit.transform"], "function", ["None"], ["", "def", "normalize_data", "(", "X_train", ",", "X_devel", ")", ":", "\n", "    ", "scaler", "=", "StandardScaler", "(", ")", "\n", "scaler", "=", "scaler", ".", "fit", "(", "X_train", ")", "\n", "X_train", "=", "scaler", ".", "transform", "(", "X_train", ")", "\n", "X_devel", "=", "scaler", ".", "transform", "(", "X_devel", ")", "\n", "return", "(", "X_train", ",", "X_devel", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.tfidf_extractor.set_vectorizer": [[7, 10], ["tfidf_extractor.get_tfidf_vector"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.tfidf_extractor.get_tfidf_vector"], ["def", "set_vectorizer", "(", "text_f", ")", ":", "\n", "    ", "vectorizer", "=", "get_tfidf_vector", "(", "text_f", ")", "\n", "return", "vectorizer", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.tfidf_extractor.get_tfidf_vector": [[11, 15], ["sklearn.feature_extraction.text.TfidfVectorizer", "sklearn.feature_extraction.text.TfidfVectorizer.fit_transform"], "function", ["None"], ["", "def", "get_tfidf_vector", "(", "X_all", ")", ":", "\n", "    ", "vectorizer", "=", "TfidfVectorizer", "(", "stop_words", "=", "\"english\"", ",", "ngram_range", "=", "(", "1", ",", "2", ")", ",", "tokenizer", "=", "tokenize_text", ")", "\n", "vectorizer", ".", "fit_transform", "(", "X_all", ")", "\n", "return", "vectorizer", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.tfidf_extractor.tokenize_text": [[16, 26], ["nltk.stem.porter.PorterStemmer", "nltk.sent_tokenize", "nltk.word_tokenize", "nltk.stem.porter.PorterStemmer.stem", "tokens.append", "len", "word.lower"], "function", ["None"], ["", "def", "tokenize_text", "(", "text", ")", ":", "\n", "    ", "tokens", "=", "[", "]", "\n", "stemmer", "=", "PorterStemmer", "(", ")", "\n", "for", "sent", "in", "nltk", ".", "sent_tokenize", "(", "text", ")", ":", "\n", "        ", "for", "word", "in", "nltk", ".", "word_tokenize", "(", "sent", ")", ":", "\n", "            ", "if", "len", "(", "word", ")", "<", "2", ":", "\n", "                ", "continue", "\n", "", "tokens", ".", "append", "(", "word", ".", "lower", "(", ")", ")", "\n", "", "", "stems", "=", "[", "stemmer", ".", "stem", "(", "item", ")", "for", "item", "in", "tokens", "]", "\n", "return", "stems", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.tfidf_extractor.normalize_text_data": [[27, 29], ["set_vectorizer().transform", "tfidf_extractor.set_vectorizer"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.tfidf_extractor.set_vectorizer"], ["", "def", "normalize_text_data", "(", "X", ")", ":", "\n", "    ", "return", "(", "set_vectorizer", "(", "X", ")", ".", "transform", "(", "X", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.tfidf_extractor.write_TFIDF_features": [[30, 35], ["tfidf_extractor.normalize_text_data", "pandas.DataFrame", "pd.DataFrame.to_csv", "normalize_text_data.toarray"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.tfidf_extractor.normalize_text_data"], ["", "def", "write_TFIDF_features", "(", "df", ",", "file_path", ")", ":", "\n", "    ", "X_vector", "=", "normalize_text_data", "(", "df", ")", "\n", "df2", "=", "pd", ".", "DataFrame", "(", "X_vector", ".", "toarray", "(", ")", ")", "\n", "df2", ".", "to_csv", "(", "file_path", ",", "index", "=", "False", ")", "\n", "return", "df2", "\n", "", ""]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.stats.calc_min_from_list": [[4, 8], ["pandas.DataFrame", "df[].min", "eval"], "function", ["None"], ["def", "calc_min_from_list", "(", "score_list", ")", ":", "\n", "\n", "\t", "df", "=", "pd", ".", "DataFrame", "(", "eval", "(", "score_list", ")", ",", "columns", "=", "[", "'word'", ",", "'pos'", ",", "'score'", "]", ")", "\n", "return", "df", "[", "'score'", "]", ".", "min", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.stats.calc_max_from_list": [[10, 14], ["pandas.DataFrame", "df[].max", "eval"], "function", ["None"], ["", "def", "calc_max_from_list", "(", "score_list", ")", ":", "\n", "\n", "\t", "df", "=", "pd", ".", "DataFrame", "(", "eval", "(", "score_list", ")", ",", "columns", "=", "[", "'word'", ",", "'pos'", ",", "'score'", "]", ")", "\n", "return", "df", "[", "'score'", "]", ".", "max", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.stats.calc_mean_from_list": [[16, 20], ["pandas.DataFrame", "df[].mean", "eval"], "function", ["None"], ["", "def", "calc_mean_from_list", "(", "score_list", ")", ":", "\n", "\n", "\t", "df", "=", "pd", ".", "DataFrame", "(", "eval", "(", "score_list", ")", ",", "columns", "=", "[", "'word'", ",", "'pos'", ",", "'score'", "]", ")", "\n", "return", "df", "[", "'score'", "]", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.stats.calc_sum_from_list": [[22, 26], ["pandas.DataFrame", "df[].sum", "eval"], "function", ["None"], ["", "def", "calc_sum_from_list", "(", "score_list", ")", ":", "\n", "\n", "\t", "df", "=", "pd", ".", "DataFrame", "(", "eval", "(", "score_list", ")", ",", "columns", "=", "[", "'word'", ",", "'pos'", ",", "'score'", "]", ")", "\n", "return", "df", "[", "'score'", "]", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.stats.calc_num_from_list": [[28, 31], ["len", "eval"], "function", ["None"], ["", "def", "calc_num_from_list", "(", "score_list", ")", ":", "\n", "\n", "\t", "return", "len", "(", "eval", "(", "score_list", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.stats.calc_num_pos_from_list": [[32, 38], ["pandas.DataFrame", "len", "eval"], "function", ["None"], ["", "def", "calc_num_pos_from_list", "(", "score_list", ")", ":", "\n", "\n", "\t", "df", "=", "pd", ".", "DataFrame", "(", "eval", "(", "score_list", ")", ",", "columns", "=", "[", "'word'", ",", "'pos'", ",", "'score'", "]", ")", "\n", "df", "=", "df", "[", "df", "[", "'score'", "]", ">", "0", "]", "\n", "\n", "return", "len", "(", "df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.stats.calc_num_neg_from_list": [[39, 45], ["pandas.DataFrame", "len", "eval"], "function", ["None"], ["", "def", "calc_num_neg_from_list", "(", "score_list", ")", ":", "\n", "\n", "\t", "df", "=", "pd", ".", "DataFrame", "(", "eval", "(", "score_list", ")", ",", "columns", "=", "[", "'word'", ",", "'pos'", ",", "'score'", "]", ")", "\n", "df", "=", "df", "[", "df", "[", "'score'", "]", "<", "0", "]", "\n", "\n", "return", "len", "(", "df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.stats.calc_range_from_list": [[47, 53], ["pandas.DataFrame", "df[].max", "df[].min", "eval"], "function", ["None"], ["", "def", "calc_range_from_list", "(", "score_list", ")", ":", "\n", "\n", "\t", "df", "=", "pd", ".", "DataFrame", "(", "eval", "(", "score_list", ")", ",", "columns", "=", "[", "'word'", ",", "'pos'", ",", "'score'", "]", ")", "\n", "max_val", "=", "df", "[", "'score'", "]", ".", "max", "(", ")", "\n", "min_val", "=", "df", "[", "'score'", "]", ".", "min", "(", ")", "\n", "return", "max_val", "-", "min_val", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.stats.calc_sum_from_dict": [[55, 70], ["json.loads", "json.loads.keys", "json.loads.replace"], "function", ["None"], ["", "def", "calc_sum_from_dict", "(", "score_dict", ")", ":", "\n", "\n", "\t", "try", ":", "\n", "\t\t", "score_dict", "=", "json", ".", "loads", "(", "score_dict", ".", "replace", "(", "'\\''", ",", "'\\\"'", ")", ")", "\n", "", "except", ":", "\n", "\t\t", "pass", "\n", "\n", "", "total_sum", "=", "0", "\n", "if", "score_dict", ":", "\n", "\t\t", "for", "k", "in", "score_dict", ".", "keys", "(", ")", ":", "\n", "\t\t\t", "total_sum", "+=", "score_dict", "[", "k", "]", "\n", "\n", "", "return", "total_sum", "\n", "", "else", ":", "\n", "\t\t", "return", "np", ".", "nan", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.stats.calc_min_from_dict": [[72, 81], ["json.loads", "numpy.min", "json.loads.replace", "list", "json.loads.values"], "function", ["None"], ["", "", "def", "calc_min_from_dict", "(", "score_dict", ")", ":", "\n", "\t", "try", ":", "\n", "\t\t", "score_dict", "=", "json", ".", "loads", "(", "score_dict", ".", "replace", "(", "'\\''", ",", "'\\\"'", ")", ")", "\n", "", "except", ":", "\n", "\t\t", "pass", "\n", "", "if", "score_dict", ":", "\n", "\t\t", "return", "np", ".", "min", "(", "list", "(", "score_dict", ".", "values", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "\t\t", "return", "np", ".", "nan", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.stats.calc_max_from_dict": [[83, 92], ["json.loads", "numpy.max", "json.loads.replace", "list", "json.loads.values"], "function", ["None"], ["", "", "def", "calc_max_from_dict", "(", "score_dict", ")", ":", "\n", "\t", "try", ":", "\n", "\t\t", "score_dict", "=", "json", ".", "loads", "(", "score_dict", ".", "replace", "(", "'\\''", ",", "'\\\"'", ")", ")", "\n", "", "except", ":", "\n", "\t\t", "pass", "\n", "", "if", "score_dict", ":", "\n", "\t\t", "return", "np", ".", "max", "(", "list", "(", "score_dict", ".", "values", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "\t\t", "return", "np", ".", "nan", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.stats.calc_range_from_dict": [[94, 105], ["json.loads", "list", "json.loads.replace", "json.loads.values", "numpy.max", "numpy.min"], "function", ["None"], ["", "", "def", "calc_range_from_dict", "(", "score_dict", ")", ":", "\n", "\t", "try", ":", "\n", "\t\t", "score_dict", "=", "json", ".", "loads", "(", "score_dict", ".", "replace", "(", "'\\''", ",", "'\\\"'", ")", ")", "\n", "", "except", ":", "\n", "\t\t", "pass", "\n", "\n", "", "if", "score_dict", ":", "\n", "\t\t", "values", "=", "list", "(", "score_dict", ".", "values", "(", ")", ")", "\n", "return", "np", ".", "max", "(", "values", ")", "-", "np", ".", "min", "(", "values", ")", "\n", "", "else", ":", "\n", "\t\t", "return", "np", ".", "nan", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.stats.calc_mean_from_dict": [[107, 116], ["json.loads", "numpy.mean", "json.loads.replace", "list", "json.loads.values"], "function", ["None"], ["", "", "def", "calc_mean_from_dict", "(", "score_dict", ")", ":", "\n", "\t", "try", ":", "\n", "\t\t", "score_dict", "=", "json", ".", "loads", "(", "score_dict", ".", "replace", "(", "'\\''", ",", "'\\\"'", ")", ")", "\n", "", "except", ":", "\n", "\t\t", "pass", "\n", "", "if", "score_dict", ":", "\n", "\t\t", "return", "np", ".", "mean", "(", "list", "(", "score_dict", ".", "values", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "\t\t", "return", "np", ".", "nan", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.stats.calc_num_neg_from_dict": [[118, 131], ["json.loads", "json.loads.values", "json.loads.replace"], "function", ["None"], ["", "", "def", "calc_num_neg_from_dict", "(", "score_dict", ")", ":", "\n", "\t", "try", ":", "\n", "\t\t", "score_dict", "=", "json", ".", "loads", "(", "score_dict", ".", "replace", "(", "'\\''", ",", "'\\\"'", ")", ")", "\n", "", "except", ":", "\n", "\t\t", "pass", "\n", "", "count", "=", "0", "\n", "if", "score_dict", ":", "\n", "\t\t", "for", "val", "in", "score_dict", ".", "values", "(", ")", ":", "\n", "\t\t\t", "if", "val", "<", "0", ":", "\n", "\t\t\t\t", "count", "+=", "1", "\n", "", "", "return", "count", "\n", "", "else", ":", "\n", "\t\t", "return", "np", ".", "nan", "\n", "\n"]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.stats.calc_num_pos_from_dict": [[133, 146], ["json.loads", "json.loads.values", "json.loads.replace"], "function", ["None"], ["", "", "def", "calc_num_pos_from_dict", "(", "score_dict", ")", ":", "\n", "\t", "try", ":", "\n", "\t\t", "score_dict", "=", "json", ".", "loads", "(", "score_dict", ".", "replace", "(", "'\\''", ",", "'\\\"'", ")", ")", "\n", "", "except", ":", "\n", "\t\t", "pass", "\n", "", "count", "=", "0", "\n", "if", "score_dict", ":", "\n", "\t\t", "for", "val", "in", "score_dict", ".", "values", "(", ")", ":", "\n", "\t\t\t", "if", "val", ">", "0", ":", "\n", "\t\t\t\t", "count", "+=", "1", "\n", "", "", "return", "count", "\n", "", "else", ":", "\n", "\t\t", "return", "np", ".", "nan", "\n", "", "", ""]], "home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.get_scores.write_senti_scores": [[5, 19], ["print", "SentiWordNet.get_scores", "SentiWordNet_scores.drop.drop", "SentiWordNet_scores.drop.to_csv", "os.path.join"], "function", ["home.repos.pwc.inspect_result.gizemsogancioglu_elderly-emotion-SC.feature_extraction.SentiWordNet.get_scores"], ["def", "write_senti_scores", "(", "data", ",", "split", ",", "text_column", ")", ":", "\n", "# Get dictionary scores", "\n", "\t", "print", "(", "'SentiWordNet'", ")", "\n", "SentiWordNet_scores", "=", "SentiWordNet", ".", "get_scores", "(", "data", ",", "text_column", ",", "SentiWordNet_dict", ",", "negation", "=", "True", ")", "\n", "\n", "# Remove unnecessary columns", "\n", "drop_col", "=", "[", "'id'", ",", "'text'", "]", "\n", "\n", "# PolArt_scores = PolArt_scores.drop(drop_col, axis=1)", "\n", "SentiWordNet_scores", "=", "SentiWordNet_scores", ".", "drop", "(", "drop_col", ",", "axis", "=", "1", ")", "\n", "# print('SentiWordNet\\n', SentiWordNet_scores.head())", "\n", "\n", "# Save the scores", "\n", "SentiWordNet_scores", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "ROOT", ",", "'dictionaries'", ",", "'personality_traits_dict_scores'", "+", "split", "+", "\".csv\"", ")", ",", "index", "=", "None", ")", "\n", "\n"]]}