{"home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_plain_stumps_iter": [[12, 22], ["numba.jit", "robust_boosting.coord_descent_exp_loss", "numpy.mean", "numpy.sum", "numpy.sum", "numpy.exp"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.coord_descent_exp_loss"], ["@", "jit", "(", "nopython", "=", "True", ",", "nogil", "=", "nogil", ")", "\n", "def", "fit_plain_stumps_iter", "(", "X_proj", ",", "y", ",", "gamma", ",", "b_vals_i", ",", "sum_1", ",", "sum_m1", ",", "max_weight", ")", ":", "\n", "    ", "ind", "=", "X_proj", ">=", "b_vals_i", "\n", "sum_1_1", ",", "sum_1_m1", "=", "np", ".", "sum", "(", "ind", "*", "(", "y", "==", "1", ")", "*", "gamma", ")", ",", "np", ".", "sum", "(", "ind", "*", "(", "y", "==", "-", "1", ")", "*", "gamma", ")", "\n", "sum_0_1", ",", "sum_0_m1", "=", "sum_1", "-", "sum_1_1", ",", "sum_m1", "-", "sum_1_m1", "\n", "w_l", ",", "w_r", "=", "coord_descent_exp_loss", "(", "sum_1_1", ",", "sum_1_m1", ",", "sum_0_1", ",", "sum_0_m1", ",", "max_weight", ")", "\n", "\n", "fmargin", "=", "y", "*", "w_l", "+", "y", "*", "w_r", "*", "ind", "\n", "loss", "=", "np", ".", "mean", "(", "gamma", "*", "np", ".", "exp", "(", "-", "fmargin", ")", ")", "\n", "return", "loss", ",", "w_l", ",", "w_r", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_plain_stumps": [[24, 37], ["numba.jit", "numpy.full", "numpy.full", "numpy.full", "numba.prange", "numpy.sum", "numpy.sum", "robust_boosting.fit_plain_stumps_iter"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_plain_stumps_iter"], ["", "@", "jit", "(", "nopython", "=", "True", ",", "nogil", "=", "nogil", ",", "parallel", "=", "parallel", ")", "# really matters, especially with independent iterations", "\n", "def", "fit_plain_stumps", "(", "X_proj", ",", "y", ",", "gamma", ",", "b_vals", ",", "max_weight", ")", ":", "\n", "    ", "n_thresholds", "=", "b_vals", ".", "shape", "[", "0", "]", "\n", "\n", "losses", "=", "np", ".", "full", "(", "n_thresholds", ",", "np", ".", "inf", ",", "dtype", "=", "dtype", ")", "\n", "w_l_vals", "=", "np", ".", "full", "(", "n_thresholds", ",", "np", ".", "inf", ",", "dtype", "=", "dtype", ")", "\n", "w_r_vals", "=", "np", ".", "full", "(", "n_thresholds", ",", "np", ".", "inf", ",", "dtype", "=", "dtype", ")", "\n", "sum_1", ",", "sum_m1", "=", "np", ".", "sum", "(", "(", "y", "==", "1", ")", "*", "gamma", ")", ",", "np", ".", "sum", "(", "(", "y", "==", "-", "1", ")", "*", "gamma", ")", "\n", "for", "i", "in", "prange", "(", "n_thresholds", ")", ":", "\n", "# due to a numba bug, if we don't use a separate function inside a prange-loop, we experience a memory leak", "\n", "        ", "losses", "[", "i", "]", ",", "w_l_vals", "[", "i", "]", ",", "w_r_vals", "[", "i", "]", "=", "fit_plain_stumps_iter", "(", "\n", "X_proj", ",", "y", ",", "gamma", ",", "b_vals", "[", "i", "]", ",", "sum_1", ",", "sum_m1", ",", "max_weight", ")", "\n", "", "return", "losses", ",", "w_l_vals", ",", "w_r_vals", ",", "b_vals", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_robust_bound_stumps_iter": [[39, 48], ["numba.jit", "robust_boosting.basic_case_two_intervals"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.basic_case_two_intervals"], ["", "@", "jit", "(", "nopython", "=", "True", ",", "nogil", "=", "nogil", ")", "\n", "def", "fit_robust_bound_stumps_iter", "(", "X_proj", ",", "y", ",", "gamma", ",", "b_vals_i", ",", "sum_1", ",", "sum_m1", ",", "eps", ",", "max_weight", ")", ":", "\n", "# Certification for the previous ensemble O(n)", "\n", "    ", "split_lbs", ",", "split_ubs", "=", "X_proj", "-", "eps", ",", "X_proj", "+", "eps", "\n", "guaranteed_right", "=", "split_lbs", ">", "b_vals_i", "\n", "uncertain", "=", "(", "split_lbs", "<=", "b_vals_i", ")", "*", "(", "split_ubs", ">=", "b_vals_i", ")", "\n", "\n", "loss", ",", "w_l", ",", "w_r", "=", "basic_case_two_intervals", "(", "y", ",", "gamma", ",", "guaranteed_right", ",", "uncertain", ",", "sum_1", ",", "sum_m1", ",", "max_weight", ")", "\n", "return", "loss", ",", "w_l", ",", "w_r", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_robust_bound_stumps": [[50, 63], ["numba.jit", "numpy.full", "numpy.full", "numpy.full", "numba.prange", "numpy.sum", "numpy.sum", "robust_boosting.fit_robust_bound_stumps_iter"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_robust_bound_stumps_iter"], ["", "@", "jit", "(", "nopython", "=", "True", ",", "nogil", "=", "nogil", ",", "parallel", "=", "parallel", ")", "# parallel=True really matters, especially with independent iterations", "\n", "def", "fit_robust_bound_stumps", "(", "X_proj", ",", "y", ",", "gamma", ",", "b_vals", ",", "eps", ",", "max_weight", ")", ":", "\n", "    ", "n_thresholds", "=", "b_vals", ".", "shape", "[", "0", "]", "\n", "\n", "losses", "=", "np", ".", "full", "(", "n_thresholds", ",", "np", ".", "inf", ",", "dtype", "=", "dtype", ")", "\n", "w_l_vals", "=", "np", ".", "full", "(", "n_thresholds", ",", "np", ".", "inf", ",", "dtype", "=", "dtype", ")", "\n", "w_r_vals", "=", "np", ".", "full", "(", "n_thresholds", ",", "np", ".", "inf", ",", "dtype", "=", "dtype", ")", "\n", "sum_1", ",", "sum_m1", "=", "np", ".", "sum", "(", "(", "y", "==", "1", ")", "*", "gamma", ")", ",", "np", ".", "sum", "(", "(", "y", "==", "-", "1", ")", "*", "gamma", ")", "\n", "for", "i", "in", "prange", "(", "n_thresholds", ")", ":", "\n", "        ", "losses", "[", "i", "]", ",", "w_l_vals", "[", "i", "]", ",", "w_r_vals", "[", "i", "]", "=", "fit_robust_bound_stumps_iter", "(", "\n", "X_proj", ",", "y", ",", "gamma", ",", "b_vals", "[", "i", "]", ",", "sum_1", ",", "sum_m1", ",", "eps", ",", "max_weight", ")", "\n", "\n", "", "return", "losses", ",", "w_l_vals", ",", "w_r_vals", ",", "b_vals", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_robust_exact_stumps_iter": [[65, 80], ["numba.jit", "robust_boosting.calc_h", "robust_boosting.basic_case_two_intervals", "robust_boosting.bisect_coord_descent", "numpy.sum", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.calc_h", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.basic_case_two_intervals", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.bisect_coord_descent"], ["", "@", "jit", "(", "nopython", "=", "True", ",", "nogil", "=", "nogil", ")", "\n", "def", "fit_robust_exact_stumps_iter", "(", "X_proj", ",", "y", ",", "gamma", ",", "w_rs", ",", "bs", ",", "b_vals_i", ",", "sum_1", ",", "sum_m1", ",", "eps", ",", "max_weight", ")", ":", "\n", "# Certification for the previous ensemble O(n)", "\n", "    ", "split_lbs", ",", "split_ubs", "=", "X_proj", "-", "eps", ",", "X_proj", "+", "eps", "\n", "guaranteed_right", "=", "split_lbs", ">", "b_vals_i", "\n", "uncertain", "=", "(", "split_lbs", "<=", "b_vals_i", ")", "*", "(", "split_ubs", ">=", "b_vals_i", ")", "\n", "\n", "h_l", ",", "h_r", "=", "calc_h", "(", "X_proj", ",", "y", ",", "w_rs", ",", "bs", ",", "b_vals_i", ",", "eps", ")", "\n", "# there should be quite many useless coordinates which do not have any stumps in the ensemble", "\n", "# thus h_l=h_r=0  =>  suffices to check just 2 regions without applying bisection", "\n", "if", "np", ".", "sum", "(", "h_l", ")", "==", "0.0", "and", "np", ".", "sum", "(", "h_r", ")", "==", "0.0", ":", "\n", "        ", "loss", ",", "w_l", ",", "w_r", "=", "basic_case_two_intervals", "(", "y", ",", "gamma", ",", "guaranteed_right", ",", "uncertain", ",", "sum_1", ",", "sum_m1", ",", "max_weight", ")", "\n", "", "else", ":", "# general case; happens only when `coord` was already splitted in the previous iterations", "\n", "        ", "loss", ",", "w_l", ",", "w_r", "=", "bisect_coord_descent", "(", "y", ",", "gamma", ",", "h_l", ",", "h_r", ",", "guaranteed_right", ",", "uncertain", ",", "max_weight", ")", "\n", "", "return", "loss", ",", "w_l", ",", "w_r", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_robust_exact_stumps": [[82, 95], ["numba.jit", "numpy.full", "numpy.full", "numpy.full", "numba.prange", "numpy.sum", "numpy.sum", "robust_boosting.fit_robust_exact_stumps_iter"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_robust_exact_stumps_iter"], ["", "@", "jit", "(", "nopython", "=", "True", ",", "nogil", "=", "nogil", ",", "parallel", "=", "parallel", ")", "# parallel=True really matters, especially with independent iterations", "\n", "def", "fit_robust_exact_stumps", "(", "X_proj", ",", "y", ",", "gamma", ",", "b_vals", ",", "eps", ",", "w_rs", ",", "bs", ",", "max_weight", ")", ":", "\n", "    ", "n_thresholds", "=", "b_vals", ".", "shape", "[", "0", "]", "\n", "\n", "losses", "=", "np", ".", "full", "(", "n_thresholds", ",", "np", ".", "inf", ",", "dtype", "=", "dtype", ")", "\n", "w_l_vals", "=", "np", ".", "full", "(", "n_thresholds", ",", "np", ".", "inf", ",", "dtype", "=", "dtype", ")", "\n", "w_r_vals", "=", "np", ".", "full", "(", "n_thresholds", ",", "np", ".", "inf", ",", "dtype", "=", "dtype", ")", "\n", "sum_1", ",", "sum_m1", "=", "np", ".", "sum", "(", "(", "y", "==", "1", ")", "*", "gamma", ")", ",", "np", ".", "sum", "(", "(", "y", "==", "-", "1", ")", "*", "gamma", ")", "\n", "for", "i", "in", "prange", "(", "n_thresholds", ")", ":", "\n", "        ", "losses", "[", "i", "]", ",", "w_l_vals", "[", "i", "]", ",", "w_r_vals", "[", "i", "]", "=", "fit_robust_exact_stumps_iter", "(", "\n", "X_proj", ",", "y", ",", "gamma", ",", "w_rs", ",", "bs", ",", "b_vals", "[", "i", "]", ",", "sum_1", ",", "sum_m1", ",", "eps", ",", "max_weight", ")", "\n", "\n", "", "return", "losses", ",", "w_l_vals", ",", "w_r_vals", ",", "b_vals", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.coord_descent_exp_loss": [[97, 142], ["numba.jit", "utils.clip", "utils.clip", "math.log", "math.log", "math.log", "math.exp", "math.exp", "math.log", "numpy.abs", "numpy.abs", "math.log", "math.exp", "math.exp", "math.log", "math.exp", "math.exp"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip"], ["", "@", "jit", "(", "nopython", "=", "True", ",", "nogil", "=", "nogil", ")", "# almost 2 times speed-up by njit for this loop!", "\n", "def", "coord_descent_exp_loss", "(", "sum_1_1", ",", "sum_1_m1", ",", "sum_0_1", ",", "sum_0_m1", ",", "max_weight", ")", ":", "\n", "    ", "m", "=", "1e-10", "\n", "# if sum_0_1 + sum_0_m1 == 0 or sum_1_1 + sum_1_m1 == 0:", "\n", "#     return np.inf, np.inf", "\n", "# w_l = (sum_0_1 - sum_0_m1) / (sum_0_1 + sum_0_m1)", "\n", "# w_r = (sum_1_1 - sum_1_m1) / (sum_1_1 + sum_1_m1) - w_l", "\n", "\n", "# 1e-4 up to 20-50 iters; 1e-6 up to 100-200 iters which leads to a significant slowdown in practice", "\n", "eps_precision", "=", "1e-4", "\n", "\n", "# We have to properly handle the cases when the optimal leaf value is +-inf.", "\n", "if", "sum_1_m1", "<", "m", "and", "sum_0_1", "<", "m", ":", "\n", "        ", "w_l", ",", "w_r", "=", "-", "max_weight", ",", "2", "*", "max_weight", "\n", "", "elif", "sum_1_1", "<", "m", "and", "sum_0_m1", "<", "m", ":", "\n", "        ", "w_l", ",", "w_r", "=", "max_weight", ",", "-", "2", "*", "max_weight", "\n", "", "elif", "sum_1_m1", "<", "m", ":", "\n", "        ", "w_r", "=", "max_weight", "\n", "w_l", "=", "0.5", "*", "math", ".", "log", "(", "(", "math", ".", "exp", "(", "-", "w_r", ")", "*", "sum_1_1", "+", "sum_0_1", ")", "/", "(", "math", ".", "exp", "(", "w_r", ")", "*", "sum_1_m1", "+", "sum_0_m1", ")", ")", "\n", "", "elif", "sum_1_1", "<", "m", ":", "\n", "        ", "w_r", "=", "-", "max_weight", "\n", "w_l", "=", "0.5", "*", "math", ".", "log", "(", "(", "math", ".", "exp", "(", "-", "w_r", ")", "*", "sum_1_1", "+", "sum_0_1", ")", "/", "(", "math", ".", "exp", "(", "w_r", ")", "*", "sum_1_m1", "+", "sum_0_m1", ")", ")", "\n", "", "elif", "sum_0_1", "<", "m", ":", "\n", "        ", "w_l", "=", "-", "max_weight", "\n", "w_r", "=", "0.5", "*", "math", ".", "log", "(", "sum_1_1", "/", "sum_1_m1", ")", "-", "w_l", "\n", "", "elif", "sum_0_m1", "<", "m", ":", "\n", "        ", "w_l", "=", "max_weight", "\n", "w_r", "=", "0.5", "*", "math", ".", "log", "(", "sum_1_1", "/", "sum_1_m1", ")", "-", "w_l", "\n", "", "else", ":", "# main case", "\n", "        ", "w_r", "=", "0.0", "\n", "w_l", "=", "0.0", "\n", "w_r_prev", ",", "w_l_prev", "=", "np", ".", "inf", ",", "np", ".", "inf", "\n", "i", "=", "0", "\n", "# Note: ideally one has to calculate the loss, but O(n) factor would slow down everything here", "\n", "while", "(", "np", ".", "abs", "(", "w_r", "-", "w_r_prev", ")", ">", "eps_precision", ")", "or", "(", "np", ".", "abs", "(", "w_l", "-", "w_l_prev", ")", ">", "eps_precision", ")", ":", "\n", "            ", "i", "+=", "1", "\n", "w_r_prev", ",", "w_l_prev", "=", "w_r", ",", "w_l", "\n", "w_r", "=", "0.5", "*", "math", ".", "log", "(", "sum_1_1", "/", "sum_1_m1", ")", "-", "w_l", "\n", "w_l", "=", "0.5", "*", "math", ".", "log", "(", "(", "math", ".", "exp", "(", "-", "w_r", ")", "*", "sum_1_1", "+", "sum_0_1", ")", "/", "(", "math", ".", "exp", "(", "w_r", ")", "*", "sum_1_m1", "+", "sum_0_m1", ")", ")", "\n", "if", "i", "==", "50", ":", "\n", "                ", "break", "\n", "", "", "", "left_leaf", "=", "clip", "(", "w_l", ",", "-", "max_weight", ",", "max_weight", ")", "\n", "right_leaf", "=", "clip", "(", "left_leaf", "+", "w_r", ",", "-", "max_weight", ",", "max_weight", ")", "\n", "w_l", ",", "w_r", "=", "left_leaf", ",", "right_leaf", "-", "left_leaf", "\n", "return", "w_l", ",", "w_r", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.calc_h": [[144, 184], ["numba.jit", "range", "numpy.argsort", "range", "numpy.zeros", "numpy.zeros", "len", "len", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "len", "utils.minimum", "utils.minimum", "numpy.sum", "numpy.maximum"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.minimum", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.minimum"], ["", "@", "jit", "(", "nopython", "=", "True", ",", "nogil", "=", "nogil", ")", "\n", "def", "calc_h", "(", "X_proj", ",", "y", ",", "w_rs", ",", "bs", ",", "b_curr", ",", "eps", ")", ":", "\n", "    ", "num", "=", "X_proj", ".", "shape", "[", "0", "]", "\n", "h_l_base", ",", "h_r_base", "=", "np", ".", "zeros", "(", "num", ")", ",", "np", ".", "zeros", "(", "num", ")", "\n", "if", "len", "(", "bs", ")", "==", "0", ":", "\n", "        ", "return", "h_l_base", ",", "h_r_base", "\n", "\n", "# Has to be calculated inside of the loop since depends on the current b", "\n", "", "for", "i", "in", "range", "(", "len", "(", "w_rs", ")", ")", ":", "\n", "# idea: accumulate all the thresholds that preceed the leftmost point", "\n", "        ", "h_l_base", "+=", "y", "*", "w_rs", "[", "i", "]", "*", "(", "X_proj", "-", "eps", ">=", "bs", "[", "i", "]", ")", "# leftmost point is `X_proj - eps`", "\n", "h_r_base", "+=", "y", "*", "w_rs", "[", "i", "]", "*", "(", "np", ".", "maximum", "(", "b_curr", ",", "X_proj", "-", "eps", ")", ">=", "bs", "[", "i", "]", ")", "# leftmost point is max(b_curr, x-eps)", "\n", "# check all thresholds, and afterwards check if they are in (x-eps, x+eps]", "\n", "", "idx", "=", "np", ".", "argsort", "(", "bs", ")", "\n", "sorted_thresholds", "=", "bs", "[", "idx", "]", "\n", "sorted_w_r", "=", "w_rs", "[", "idx", "]", "\n", "\n", "min_left", ",", "min_right", "=", "np", ".", "zeros", "(", "num", ")", ",", "np", ".", "zeros", "(", "num", ")", "\n", "cumsum_left", ",", "cumsum_right", "=", "np", ".", "zeros", "(", "num", ")", ",", "np", ".", "zeros", "(", "num", ")", "\n", "for", "i_t", "in", "range", "(", "len", "(", "sorted_thresholds", ")", ")", ":", "\n", "# consider the threshold if it belongs to (x-eps, min(b, x+eps)] (x-eps is excluded since already evaluated)", "\n", "        ", "idx_x_left", "=", "(", "X_proj", "-", "eps", "<", "sorted_thresholds", "[", "i_t", "]", ")", "*", "(", "sorted_thresholds", "[", "i_t", "]", "<=", "b_curr", ")", "*", "(", "\n", "sorted_thresholds", "[", "i_t", "]", "<=", "X_proj", "+", "eps", ")", "\n", "# consider the threshold if it belongs to (max(b, x-eps), x+eps] (b is excluded since already evaluated)", "\n", "idx_x_right", "=", "(", "b_curr", "<", "sorted_thresholds", "[", "i_t", "]", ")", "*", "(", "X_proj", "-", "eps", "<", "sorted_thresholds", "[", "i_t", "]", ")", "*", "(", "\n", "sorted_thresholds", "[", "i_t", "]", "<=", "X_proj", "+", "eps", ")", "\n", "assert", "np", ".", "sum", "(", "idx_x_left", "*", "idx_x_right", ")", "==", "0", "# mutually exclusive  =>  cannot be True at the same time", "\n", "diff_left", "=", "y", "*", "sorted_w_r", "[", "i_t", "]", "*", "idx_x_left", "\n", "diff_right", "=", "y", "*", "sorted_w_r", "[", "i_t", "]", "*", "idx_x_right", "\n", "# Note: numba doesn't support cumsum over axis=1 nor min over axis=1", "\n", "cumsum_left", "+=", "diff_left", "\n", "cumsum_right", "+=", "diff_right", "\n", "min_left", "=", "minimum", "(", "cumsum_left", ",", "min_left", ")", "\n", "min_right", "=", "minimum", "(", "cumsum_right", ",", "min_right", ")", "\n", "", "h_l", "=", "h_l_base", "+", "min_left", "\n", "h_r", "=", "h_r_base", "+", "min_right", "\n", "# That was the case when b is in [x-eps, x+eps]. If not, then:", "\n", "h_l", "=", "h_l", "*", "(", "b_curr", ">=", "X_proj", "-", "eps", ")", "# zero out if b_curr < X_proj - eps", "\n", "h_r", "=", "h_r", "*", "(", "b_curr", "<=", "X_proj", "+", "eps", ")", "# zero out if b_curr > X_proj + eps", "\n", "return", "h_l", ",", "h_r", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.bisection": [[186, 214], ["numba.jit", "numpy.mean", "numpy.mean", "numpy.abs", "numpy.exp"], "function", ["None"], ["", "@", "jit", "(", "nopython", "=", "True", ",", "nogil", "=", "nogil", ")", "\n", "def", "bisection", "(", "w_l", ",", "y", ",", "gamma", ",", "h_l", ",", "h_r", ",", "guaranteed_right", ",", "uncertain", ",", "max_weight", ")", ":", "\n", "# bisection to find w_r* for the current w_l", "\n", "    ", "eps_precision", "=", "1e-5", "# 1e-5: 21 steps, 1e-4: 18 steps (assuming max_weight=10)", "\n", "w_r", "=", "0.0", "\n", "w_r_lower", ",", "w_r_upper", "=", "-", "max_weight", ",", "max_weight", "\n", "loss_best", "=", "np", ".", "inf", "\n", "i", "=", "0", "\n", "while", "i", "==", "0", "or", "np", ".", "abs", "(", "w_r_upper", "-", "w_r_lower", ")", ">", "eps_precision", ":", "\n", "        ", "w_r", "=", "(", "w_r_lower", "+", "w_r_upper", ")", "/", "2", "\n", "ind", "=", "guaranteed_right", "+", "(", "y", "*", "w_r", "<", "h_l", "-", "h_r", ")", "*", "uncertain", "\n", "\n", "# Calculate the indicator function based on the known h_l - h_r", "\n", "fmargin", "=", "y", "*", "w_l", "+", "h_l", "+", "(", "h_r", "-", "h_l", "+", "y", "*", "w_r", ")", "*", "ind", "\n", "losses_per_pt", "=", "gamma", "*", "np", ".", "exp", "(", "-", "fmargin", ")", "\n", "loss", "=", "np", ".", "mean", "(", "losses_per_pt", ")", "# also O(n)", "\n", "# derivative wrt w_r for bisection", "\n", "derivative", "=", "np", ".", "mean", "(", "-", "losses_per_pt", "*", "y", "*", "ind", ")", "\n", "\n", "if", "loss", "<", "loss_best", ":", "\n", "            ", "w_r_best", ",", "loss_best", "=", "w_r", ",", "loss", "\n", "", "if", "derivative", ">=", "0", ":", "\n", "            ", "w_r_upper", "=", "w_r", "\n", "", "else", ":", "\n", "            ", "w_r_lower", "=", "w_r", "\n", "\n", "", "i", "+=", "1", "\n", "", "return", "w_r", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.bisect_coord_descent": [[216, 241], ["numba.jit", "numpy.mean", "robust_boosting.bisection", "numpy.abs", "numpy.abs", "numpy.exp", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "math.log", "numpy.exp", "math.exp", "math.exp"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.bisection"], ["", "@", "jit", "(", "nopython", "=", "True", ",", "nogil", "=", "nogil", ")", "\n", "def", "bisect_coord_descent", "(", "y", ",", "gamma", ",", "h_l", ",", "h_r", ",", "guaranteed_right", ",", "uncertain", ",", "max_weight", ")", ":", "\n", "    ", "eps_precision", "=", "1e-5", "\n", "w_l_prev", ",", "w_r_prev", "=", "np", ".", "inf", ",", "np", ".", "inf", "\n", "w_l", ",", "w_r", "=", "0.0", ",", "0.0", "\n", "i", "=", "0", "\n", "while", "np", ".", "abs", "(", "w_l", "-", "w_l_prev", ")", ">", "eps_precision", "or", "np", ".", "abs", "(", "w_r", "-", "w_r_prev", ")", ">", "eps_precision", ":", "\n", "        ", "w_r_prev", "=", "w_r", "\n", "w_r", "=", "bisection", "(", "w_l", ",", "y", ",", "gamma", ",", "h_l", ",", "h_r", ",", "guaranteed_right", ",", "uncertain", ",", "max_weight", ")", "\n", "\n", "ind", "=", "guaranteed_right", "+", "(", "y", "*", "w_r", "<", "h_l", "-", "h_r", ")", "*", "uncertain", "\n", "gamma_with_h", "=", "gamma", "*", "np", ".", "exp", "(", "-", "(", "~", "ind", "*", "h_l", "+", "ind", "*", "h_r", ")", ")", "# only for the coord descent step", "\n", "sum_1_1", ",", "sum_1_m1", "=", "np", ".", "sum", "(", "ind", "*", "(", "y", "==", "1", ")", "*", "gamma_with_h", ")", ",", "np", ".", "sum", "(", "ind", "*", "(", "y", "==", "-", "1", ")", "*", "gamma_with_h", ")", "\n", "sum_0_1", ",", "sum_0_m1", "=", "np", ".", "sum", "(", "~", "ind", "*", "(", "y", "==", "1", ")", "*", "gamma_with_h", ")", ",", "np", ".", "sum", "(", "~", "ind", "*", "(", "y", "==", "-", "1", ")", "*", "gamma_with_h", ")", "\n", "w_l_prev", "=", "w_l", "\n", "w_l", "=", "0.5", "*", "math", ".", "log", "(", "(", "math", ".", "exp", "(", "-", "w_r", ")", "*", "sum_1_1", "+", "sum_0_1", ")", "/", "(", "math", ".", "exp", "(", "w_r", ")", "*", "sum_1_m1", "+", "sum_0_m1", ")", ")", "\n", "i", "+=", "1", "\n", "if", "i", "==", "10", ":", "\n", "            ", "break", "\n", "\n", "", "", "ind", "=", "guaranteed_right", "+", "(", "y", "*", "w_r", "<", "h_l", "-", "h_r", ")", "*", "uncertain", "\n", "fmargin", "=", "y", "*", "w_l", "+", "h_l", "+", "(", "h_r", "-", "h_l", "+", "y", "*", "w_r", ")", "*", "ind", "\n", "loss", "=", "np", ".", "mean", "(", "gamma", "*", "np", ".", "exp", "(", "-", "fmargin", ")", ")", "\n", "\n", "return", "loss", ",", "w_l", ",", "w_r", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.exp_loss_robust": [[243, 259], ["numpy.mean", "dtype", "robust_boosting.calc_h", "numpy.zeros", "numpy.zeros", "numpy.exp"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.calc_h"], ["", "def", "exp_loss_robust", "(", "X_proj", ",", "y", ",", "gamma", ",", "w_l", ",", "w_r", ",", "w_rs", ",", "bs", ",", "b_curr", ",", "eps", ",", "h_flag", ")", ":", "\n", "    ", "num", "=", "X_proj", ".", "shape", "[", "0", "]", "\n", "if", "h_flag", ":", "\n", "        ", "h_l", ",", "h_r", "=", "calc_h", "(", "X_proj", ",", "y", ",", "w_rs", ",", "bs", ",", "b_curr", ",", "eps", ")", "\n", "", "else", ":", "\n", "        ", "h_l", ",", "h_r", "=", "np", ".", "zeros", "(", "num", ")", ",", "np", ".", "zeros", "(", "num", ")", "\n", "\n", "", "split_lbs", ",", "split_ubs", "=", "X_proj", "-", "eps", ",", "X_proj", "+", "eps", "\n", "guaranteed_right", "=", "split_lbs", ">", "b_curr", "\n", "uncertain", "=", "(", "split_lbs", "<=", "b_curr", ")", "*", "(", "split_ubs", ">=", "b_curr", ")", "\n", "\n", "ind", "=", "guaranteed_right", "+", "(", "y", "*", "w_r", "<", "h_l", "-", "h_r", ")", "*", "uncertain", "\n", "fmargin", "=", "y", "*", "w_l", "+", "h_l", "+", "(", "h_r", "-", "h_l", "+", "y", "*", "w_r", ")", "*", "ind", "\n", "loss", "=", "np", ".", "mean", "(", "gamma", "*", "np", ".", "exp", "(", "-", "fmargin", ")", ")", "\n", "loss", "=", "dtype", "(", "loss", ")", "# important for the proper selection of the final threshold", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.basic_case_two_intervals": [[261, 289], ["numba.jit", "robust_boosting.coord_descent_exp_loss", "numpy.mean", "numpy.sum", "numpy.sum", "max", "utils.clip", "math.log", "math.copysign", "numpy.exp", "math.log", "math.exp", "math.exp", "math.exp"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.coord_descent_exp_loss", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip"], ["", "@", "jit", "(", "nopython", "=", "True", ",", "nogil", "=", "nogil", ")", "\n", "def", "basic_case_two_intervals", "(", "y", ",", "gamma", ",", "guaranteed_right", ",", "uncertain", ",", "sum_1", ",", "sum_m1", ",", "max_weight", ")", ":", "\n", "    ", "loss_best", ",", "w_r_best", ",", "w_l_best", "=", "np", ".", "inf", ",", "np", ".", "inf", ",", "np", ".", "inf", "\n", "for", "sign_w_r", "in", "(", "-", "1", ",", "1", ")", ":", "\n", "# Calculate the indicator function based on the known `sign_w_r`", "\n", "        ", "ind", "=", "guaranteed_right", "+", "(", "y", "*", "sign_w_r", "<", "0", ")", "*", "uncertain", "\n", "\n", "# Calculate all partial sums", "\n", "sum_1_1", ",", "sum_1_m1", "=", "np", ".", "sum", "(", "ind", "*", "(", "y", "==", "1", ")", "*", "gamma", ")", ",", "np", ".", "sum", "(", "ind", "*", "(", "y", "==", "-", "1", ")", "*", "gamma", ")", "\n", "sum_0_1", ",", "sum_0_m1", "=", "sum_1", "-", "sum_1_1", ",", "sum_m1", "-", "sum_1_m1", "\n", "# Minimizer of w_l, w_r on the current interval", "\n", "w_l", ",", "w_r", "=", "coord_descent_exp_loss", "(", "sum_1_1", ",", "sum_1_m1", ",", "sum_0_1", ",", "sum_0_m1", ",", "max_weight", ")", "\n", "# if w_r is on the different side from 0, then sign_w_r*w_r < 0  =>  w_r:=0", "\n", "w_r", "=", "sign_w_r", "*", "max", "(", "sign_w_r", "*", "w_r", ",", "0", ")", "\n", "\n", "# If w_r now become 0, we need to readjust w_l", "\n", "if", "sum_1_m1", "!=", "0", "and", "sum_0_m1", "!=", "0", ":", "\n", "            ", "w_l", "=", "0.5", "*", "math", ".", "log", "(", "(", "math", ".", "exp", "(", "-", "w_r", ")", "*", "sum_1_1", "+", "sum_0_1", ")", "/", "(", "math", ".", "exp", "(", "w_r", ")", "*", "sum_1_m1", "+", "sum_0_m1", ")", ")", "\n", "w_l", "=", "clip", "(", "w_l", ",", "-", "max_weight", ",", "max_weight", ")", "\n", "", "else", ":", "# to prevent a division over zero", "\n", "            ", "w_l", "=", "max_weight", "*", "math", ".", "copysign", "(", "1", ",", "0.5", "*", "math", ".", "log", "(", "(", "math", ".", "exp", "(", "-", "w_r", ")", "*", "sum_1_1", "+", "sum_0_1", ")", ")", ")", "\n", "\n", "", "preds_adv", "=", "w_l", "+", "w_r", "*", "ind", "\n", "\n", "loss", "=", "np", ".", "mean", "(", "gamma", "*", "np", ".", "exp", "(", "-", "y", "*", "preds_adv", ")", ")", "# also O(n)", "\n", "if", "loss", "<", "loss_best", ":", "\n", "            ", "loss_best", ",", "w_l_best", ",", "w_r_best", "=", "loss", ",", "w_l", ",", "w_r", "\n", "", "", "return", "loss_best", ",", "w_l_best", ",", "w_r_best", "\n", "", ""]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.__init__": [[68, 76], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "id_", "=", "-", "1", ",", "left", "=", "None", ",", "right", "=", "None", ",", "w_l", "=", "0.0", ",", "w_r", "=", "0.0", ",", "b", "=", "0.0", ",", "coord", "=", "0", ",", "loss", "=", "0.0", ")", ":", "\n", "# (left == None and right == None)  =>  leaf", "\n", "# else  =>  intermediate node", "\n", "        ", "self", ".", "id", ",", "self", ".", "left", ",", "self", ".", "right", "=", "id_", ",", "left", ",", "right", "\n", "# Note: w_l/w_r can have some values, but if left AND right is not None, then w_l/w_r are just ignored.", "\n", "# However, we still may need them because of pruning - if a leaf node was pruned, then its parent kicks in.", "\n", "self", ".", "w_l", ",", "self", ".", "w_r", ",", "self", ".", "b", ",", "self", ".", "coord", ",", "self", ".", "loss", "=", "w_l", ",", "w_r", ",", "b", ",", "coord", ",", "loss", "\n", "self", ".", "node_list", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.__repr__": [[77, 94], ["tree_ensemble.Tree.right.__repr__", "tree_ensemble.Tree.left.__repr__", "tree_ensemble.Tree.left.__repr__", "tree_ensemble.Tree.right.__repr__"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.__repr__", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.__repr__", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.__repr__", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "lval", ",", "rval", ",", "threshold", "=", "self", ".", "w_l", ",", "self", ".", "w_r", "+", "self", ".", "w_l", ",", "self", ".", "b", "\n", "\n", "if", "self", ".", "left", "is", "None", "and", "self", ".", "right", "is", "None", ":", "\n", "            ", "return", "'if x[{}] < {:.4f}: {:.4f} else {:.4f}    '", ".", "format", "(", "self", ".", "coord", ",", "threshold", ",", "lval", ",", "rval", ")", "\n", "", "if", "self", ".", "left", "is", "None", ":", "\n", "            ", "return", "'if x[{}] < {:.4f}: {:.4f}  '", ".", "format", "(", "self", ".", "coord", ",", "threshold", ",", "lval", ")", "+", "self", ".", "right", ".", "__repr__", "(", ")", "\n", "", "if", "self", ".", "right", "is", "None", ":", "\n", "            ", "return", "self", ".", "left", ".", "__repr__", "(", ")", "+", "'if x[{}] >= {:.4f}: {:.4f}  '", ".", "format", "(", "self", ".", "coord", ",", "threshold", ",", "rval", ")", "\n", "\n", "", "s", "=", "''", "\n", "if", "self", ".", "left", "is", "not", "None", ":", "\n", "            ", "s", "+=", "'if x[{}] < {:.4f} and '", ".", "format", "(", "self", ".", "coord", ",", "threshold", ")", "+", "self", ".", "left", ".", "__repr__", "(", ")", "\n", "", "if", "self", ".", "right", "is", "not", "None", ":", "\n", "            ", "s", "+=", "'if x[{}] >= {:.4f} and '", ".", "format", "(", "self", ".", "coord", ",", "threshold", ")", "+", "self", ".", "right", ".", "__repr__", "(", ")", "\n", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.__eq__": [[95, 101], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "\"\"\" Overrides the default equality comparison operator == \"\"\"", "\n", "if", "isinstance", "(", "other", ",", "Tree", ")", ":", "\n", "            ", "return", "(", "self", ".", "left", "==", "other", ".", "left", "and", "self", ".", "right", "==", "other", ".", "right", "and", "self", ".", "w_l", "==", "other", ".", "w_l", "and", "\n", "self", ".", "w_r", "==", "other", ".", "w_r", "and", "self", ".", "b", "==", "other", ".", "b", "and", "self", ".", "coord", "==", "other", ".", "coord", ")", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.to_list": [[102, 113], ["tree_ensemble.Tree.left.to_list", "tree_ensemble.Tree.right.to_list"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.to_list", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.to_list"], ["", "def", "to_list", "(", "self", ")", ":", "\n", "        ", "tree_lst_left", ",", "tree_lst_right", "=", "[", "]", ",", "[", "]", "\n", "id_left", ",", "id_right", "=", "-", "1", ",", "-", "1", "\n", "if", "self", ".", "left", "is", "not", "None", ":", "\n", "            ", "tree_lst_left", "=", "self", ".", "left", ".", "to_list", "(", ")", "\n", "id_left", "=", "self", ".", "left", ".", "id", "\n", "", "if", "self", ".", "right", "is", "not", "None", ":", "\n", "            ", "tree_lst_right", "=", "self", ".", "right", ".", "to_list", "(", ")", "\n", "id_right", "=", "self", ".", "right", ".", "id", "\n", "", "curr_node", "=", "(", "self", ".", "id", ",", "id_left", ",", "id_right", ",", "self", ".", "w_l", ",", "self", ".", "w_r", ",", "self", ".", "b", ",", "self", ".", "coord", ",", "self", ".", "loss", ")", "\n", "return", "[", "curr_node", "]", "+", "tree_lst_left", "+", "tree_lst_right", "# concatenate both lists", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.to_array_contiguous": [[114, 122], ["numpy.array", "int", "numpy.zeros", "tree_ensemble.Tree.to_list", "nodes[].max", "len", "int"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.to_list"], ["", "def", "to_array_contiguous", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make ids correspond to node positions in the array. \"\"\"", "\n", "nodes", "=", "np", ".", "array", "(", "self", ".", "to_list", "(", ")", ")", "\n", "max_node_id", "=", "int", "(", "nodes", "[", ":", ",", "0", "]", ".", "max", "(", ")", ")", "\n", "nodes_new", "=", "np", ".", "zeros", "(", "[", "max_node_id", "+", "1", ",", "len", "(", "nodes", "[", "0", "]", ")", "]", ")", "\n", "for", "node", "in", "nodes", ":", "\n", "            ", "nodes_new", "[", "int", "(", "node", "[", "0", "]", ")", "]", "=", "node", "\n", "", "return", "nodes_new", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.predict": [[123, 129], ["tree_ensemble.predict_tree_par", "tree_ensemble.Tree.predict_native", "len"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.predict_tree_par", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.predict_native"], ["", "def", "predict", "(", "self", ",", "X", ")", ":", "\n", "        ", "parallel", "=", "True", "\n", "if", "parallel", "and", "len", "(", "self", ".", "node_list", ")", ">", "0", ":", "# 2nd condition is needed to prevent an error in predict_tree_par()", "\n", "            ", "return", "predict_tree_par", "(", "self", ".", "node_list", ",", "X", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "predict_native", "(", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.predict_native": [[130, 157], ["numpy.full", "numpy.zeros", "tree_ensemble.Tree.predict_native.predict_recursive"], "methods", ["None"], ["", "", "def", "predict_native", "(", "self", ",", "X", ")", ":", "\n", "        ", "def", "predict_recursive", "(", "curr_tree", ",", "idx", ")", ":", "\n", "            ", "\"\"\" To avoid copying the whole matrix X many times, we use global indices `idx` to directly use\n            the single matrix X as a closure variable. The only overhead is that the threshold comparison is done\n            for *all* examples.\n\n            Note: the parallel version using numba should be preferred.\n            \"\"\"", "\n", "# route some points to the left and some to the right nodes", "\n", "idx_left_superset", "=", "X", "[", ":", ",", "curr_tree", ".", "coord", "]", "<", "curr_tree", ".", "b", "\n", "idx_left", "=", "idx", "*", "idx_left_superset", "\n", "idx_right", "=", "idx", "*", "~", "idx_left_superset", "\n", "\n", "if", "curr_tree", ".", "left", "is", "None", ":", "\n", "                ", "f", "[", "idx_left", "]", "=", "curr_tree", ".", "w_l", "\n", "", "else", ":", "\n", "                ", "predict_recursive", "(", "curr_tree", ".", "left", ",", "idx_left", ")", "\n", "\n", "", "if", "curr_tree", ".", "right", "is", "None", ":", "\n", "                ", "f", "[", "idx_right", "]", "=", "curr_tree", ".", "w_l", "+", "curr_tree", ".", "w_r", "\n", "", "else", ":", "\n", "                ", "predict_recursive", "(", "curr_tree", ".", "right", ",", "idx_right", ")", "\n", "\n", "", "", "idx", "=", "np", ".", "full", "(", "X", ".", "shape", "[", "0", "]", ",", "True", ")", "\n", "f", "=", "np", ".", "zeros", "(", "len", "(", "idx", ")", ")", "\n", "predict_recursive", "(", "self", ",", "idx", ")", "# modifies the closure variable `f` in-place", "\n", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.find_min_yf": [[158, 164], ["tree_ensemble.find_min_yf_tree_par", "tree_ensemble.Tree.find_min_yf_native", "len"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.find_min_yf_tree_par", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.find_min_yf_native"], ["", "def", "find_min_yf", "(", "self", ",", "X", ",", "y", ",", "eps", ")", ":", "\n", "        ", "parallel", "=", "True", "# really crucial; 1-2x orders of magnitude speed-up over the native python version", "\n", "if", "parallel", "and", "len", "(", "self", ".", "node_list", ")", ">", "0", ":", "# 2nd condition is needed to prevent an error in predict_tree_par()", "\n", "            ", "return", "find_min_yf_tree_par", "(", "self", ".", "node_list", ",", "X", ",", "y", ",", "eps", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "find_min_yf_native", "(", "X", ",", "y", ",", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.find_min_yf_native": [[165, 193], ["numpy.zeros", "numpy.minimum", "tree_ensemble.Tree.left.find_min_yf", "tree_ensemble.Tree.left.find_min_yf", "tree_ensemble.Tree.right.find_min_yf", "tree_ensemble.Tree.right.find_min_yf"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.minimum", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.find_min_yf", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.find_min_yf", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.find_min_yf", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.find_min_yf"], ["", "", "def", "find_min_yf_native", "(", "self", ",", "X", ",", "y", ",", "eps", ")", ":", "\n", "        ", "split_lbs", ",", "split_ubs", "=", "X", "[", ":", ",", "self", ".", "coord", "]", "-", "eps", ",", "X", "[", ":", ",", "self", ".", "coord", "]", "+", "eps", "\n", "lval", ",", "rval", "=", "self", ".", "w_l", ",", "self", ".", "w_r", "+", "self", ".", "w_l", "\n", "\n", "guaranteed_left", "=", "split_ubs", "<", "self", ".", "b", "\n", "guaranteed_right", "=", "split_lbs", ">", "self", ".", "b", "\n", "uncertain", "=", "(", "split_lbs", "<=", "self", ".", "b", ")", "*", "(", "split_ubs", ">=", "self", ".", "b", ")", "\n", "\n", "if", "self", ".", "left", "is", "None", ":", "\n", "            ", "left_min_yf", "=", "y", "[", "guaranteed_left", "]", "*", "lval", "\n", "uleft_min_yf", "=", "y", "[", "uncertain", "]", "*", "lval", "\n", "", "else", ":", "\n", "            ", "left_min_yf", "=", "self", ".", "left", ".", "find_min_yf", "(", "X", "[", "guaranteed_left", "]", ",", "y", "[", "guaranteed_left", "]", ",", "eps", ")", "\n", "uleft_min_yf", "=", "self", ".", "left", ".", "find_min_yf", "(", "X", "[", "uncertain", "]", ",", "y", "[", "uncertain", "]", ",", "eps", ")", "\n", "\n", "", "if", "self", ".", "right", "is", "None", ":", "\n", "            ", "right_min_yf", "=", "y", "[", "guaranteed_right", "]", "*", "rval", "\n", "uright_min_yf", "=", "y", "[", "uncertain", "]", "*", "rval", "\n", "", "else", ":", "\n", "            ", "right_min_yf", "=", "self", ".", "right", ".", "find_min_yf", "(", "X", "[", "guaranteed_right", "]", ",", "y", "[", "guaranteed_right", "]", ",", "eps", ")", "\n", "uright_min_yf", "=", "self", ".", "right", ".", "find_min_yf", "(", "X", "[", "uncertain", "]", ",", "y", "[", "uncertain", "]", ",", "eps", ")", "\n", "\n", "", "min_yf", "=", "np", ".", "zeros", "(", "X", ".", "shape", "[", "0", "]", ")", "\n", "min_yf", "[", "guaranteed_left", "]", "=", "left_min_yf", "\n", "min_yf", "[", "guaranteed_right", "]", "=", "right_min_yf", "\n", "min_yf", "[", "uncertain", "]", "=", "np", ".", "minimum", "(", "uleft_min_yf", ",", "uright_min_yf", ")", "\n", "\n", "return", "min_yf", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_n_nodes": [[194, 202], ["tree_ensemble.Tree.left.get_n_nodes", "tree_ensemble.Tree.right.get_n_nodes"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_n_nodes", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_n_nodes"], ["", "def", "get_n_nodes", "(", "self", ")", ":", "\n", "        ", "left_n", ",", "right_n", "=", "0", ",", "0", "\n", "if", "self", ".", "left", "is", "not", "None", ":", "\n", "            ", "left_n", "=", "self", ".", "left", ".", "get_n_nodes", "(", ")", "\n", "", "if", "self", ".", "right", "is", "not", "None", ":", "\n", "            ", "right_n", "=", "self", ".", "right", ".", "get_n_nodes", "(", ")", "\n", "", "subtree_n", "=", "left_n", "+", "right_n", "# n nodes of the subtree rooted at the current node", "\n", "return", "subtree_n", "+", "1", "# which means that a decision stump is a tree of depth=1", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_depth": [[203, 211], ["max", "tree_ensemble.Tree.left.get_depth", "tree_ensemble.Tree.right.get_depth"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_depth", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_depth"], ["", "def", "get_depth", "(", "self", ")", ":", "\n", "        ", "left_depth", ",", "right_depth", "=", "0", ",", "0", "\n", "if", "self", ".", "left", "is", "not", "None", ":", "\n", "            ", "left_depth", "=", "self", ".", "left", ".", "get_depth", "(", ")", "\n", "", "if", "self", ".", "right", "is", "not", "None", ":", "\n", "            ", "right_depth", "=", "self", ".", "right", ".", "get_depth", "(", ")", "\n", "", "subtree_depth", "=", "max", "(", "left_depth", ",", "right_depth", ")", "# depth of the subtree rooted at the current node", "\n", "return", "subtree_depth", "+", "1", "# which means that a decision stump is a tree of depth=1", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_some_leaf": [[212, 219], ["tree_ensemble.Tree.left.get_some_leaf", "tree_ensemble.Tree.right.get_some_leaf"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_some_leaf", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_some_leaf"], ["", "def", "get_some_leaf", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "left", "is", "None", "and", "self", ".", "right", "is", "None", ":", "\n", "            ", "return", "self", "\n", "", "if", "self", ".", "left", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "left", ".", "get_some_leaf", "(", ")", "\n", "", "if", "self", ".", "right", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "right", ".", "get_some_leaf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.rm_leaf": [[220, 231], ["tree_ensemble.Tree.left.rm_leaf", "tree_ensemble.Tree.right.rm_leaf"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.rm_leaf", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.rm_leaf"], ["", "", "def", "rm_leaf", "(", "self", ",", "leaf_to_rm", ")", ":", "\n", "        ", "if", "self", ".", "left", "==", "leaf_to_rm", ":", "\n", "            ", "self", ".", "left", "=", "None", "\n", "", "if", "self", ".", "right", "==", "leaf_to_rm", ":", "\n", "            ", "self", ".", "right", "=", "None", "\n", "\n", "# Left-first search", "\n", "", "if", "self", ".", "left", "is", "not", "None", ":", "\n", "            ", "self", ".", "left", ".", "rm_leaf", "(", "leaf_to_rm", ")", "\n", "", "if", "self", ".", "right", "is", "not", "None", ":", "\n", "            ", "self", ".", "right", ".", "rm_leaf", "(", "leaf_to_rm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.rm_bottom_layer": [[232, 241], ["tree_ensemble.Tree.left.rm_bottom_layer", "tree_ensemble.Tree.right.rm_bottom_layer"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.rm_bottom_layer", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.rm_bottom_layer"], ["", "", "def", "rm_bottom_layer", "(", "self", ",", "depth", ",", "max_depth", ")", ":", "\n", "        ", "if", "depth", "+", "1", "==", "max_depth", ":", "\n", "# print('rm a node from depth {} (max_depth={})'.format(depth+1, max_depth))", "\n", "            ", "self", ".", "left", "=", "None", "\n", "self", ".", "right", "=", "None", "\n", "", "if", "self", ".", "left", "is", "not", "None", ":", "\n", "            ", "self", ".", "left", ".", "rm_bottom_layer", "(", "depth", "+", "1", ",", "max_depth", ")", "\n", "", "if", "self", ".", "right", "is", "not", "None", ":", "\n", "            ", "self", ".", "right", ".", "rm_bottom_layer", "(", "depth", "+", "1", ",", "max_depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_empty_leaf": [[242, 249], ["tree_ensemble.Tree.left.get_empty_leaf", "tree_ensemble.Tree.right.get_empty_leaf"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_empty_leaf", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_empty_leaf"], ["", "", "def", "get_empty_leaf", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "left", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "left", ".", "get_empty_leaf", "(", ")", "\n", "", "if", "self", ".", "right", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "right", ".", "get_empty_leaf", "(", ")", "\n", "", "if", "self", ".", "left", "is", "None", "and", "self", ".", "right", "is", "None", "and", "self", ".", "w_l", "==", "0.0", "and", "self", ".", "w_r", "==", "0.0", ":", "\n", "            ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_json_dict": [[250, 279], ["children_list.append", "tree_ensemble.Tree.left.get_json_dict", "children_list.append", "children_list.append", "tree_ensemble.Tree.right.get_json_dict", "children_list.append", "round", "str", "round", "round"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.get_json_dict", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.get_json_dict"], ["", "", "def", "get_json_dict", "(", "self", ",", "counter_terminal_nodes", ")", ":", "\n", "        ", "\"\"\"\n        counter_terminal_nodes: needed to assign nodeid's to terminal nodes (negative to prevent collisions)\n        \"\"\"", "\n", "precision", "=", "5", "\n", "\n", "children_list", "=", "[", "]", "\n", "if", "self", ".", "left", "is", "None", ":", "\n", "            ", "id_left", "=", "counter_terminal_nodes", "\n", "counter_terminal_nodes", "-=", "1", "\n", "children_list", ".", "append", "(", "{", "'nodeid'", ":", "id_left", ",", "'leaf'", ":", "round", "(", "self", ".", "w_l", ",", "precision", ")", "}", ")", "# end node", "\n", "", "else", ":", "\n", "            ", "id_left", "=", "self", ".", "left", ".", "id", "\n", "children", ",", "counter_terminal_nodes", "=", "self", ".", "left", ".", "get_json_dict", "(", "counter_terminal_nodes", ")", "\n", "children_list", ".", "append", "(", "children", ")", "\n", "\n", "", "if", "self", ".", "right", "is", "None", ":", "\n", "            ", "id_right", "=", "counter_terminal_nodes", "\n", "counter_terminal_nodes", "-=", "1", "\n", "children_list", ".", "append", "(", "{", "'nodeid'", ":", "id_right", ",", "'leaf'", ":", "round", "(", "self", ".", "w_l", "+", "self", ".", "w_r", ",", "precision", ")", "}", ")", "# end node", "\n", "", "else", ":", "\n", "            ", "id_right", "=", "self", ".", "right", ".", "id", "\n", "children", ",", "counter_terminal_nodes", "=", "self", ".", "right", ".", "get_json_dict", "(", "counter_terminal_nodes", ")", "\n", "children_list", ".", "append", "(", "children", ")", "\n", "\n", "", "tree_dict", "=", "{", "'nodeid'", ":", "self", ".", "id", ",", "'split'", ":", "'f'", "+", "str", "(", "self", ".", "coord", ")", ",", "'split_condition'", ":", "round", "(", "self", ".", "b", ",", "precision", ")", ",", "\n", "'yes'", ":", "id_left", ",", "'no'", ":", "id_right", ",", "'children'", ":", "children_list", "}", "\n", "\n", "return", "tree_dict", ",", "counter_terminal_nodes", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.TreeEnsemble.__init__": [[282, 298], ["collections.OrderedDict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "weak_learner", ",", "n_trials_coord", ",", "lr", ",", "min_samples_split", ",", "min_samples_leaf", ",", "idx_clsf", ",", "max_depth", ",", "\n", "gamma_hp", "=", "0.0", ",", "n_bins", "=", "-", "1", ",", "max_weight", "=", "1.0", ")", ":", "\n", "        ", "self", ".", "weak_learner", "=", "weak_learner", "\n", "self", ".", "n_trials_coord", "=", "n_trials_coord", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "min_samples_split", "=", "min_samples_split", "\n", "self", ".", "min_samples_leaf", "=", "min_samples_leaf", "\n", "self", ".", "max_depth", "=", "max_depth", "\n", "self", ".", "gamma_hp", "=", "gamma_hp", "# depth pruning coefficient", "\n", "self", ".", "n_bins", "=", "n_bins", "\n", "self", ".", "idx_clsf", "=", "idx_clsf", "# class index that this ensemble correspond to in the one-vs-all scheme", "\n", "self", ".", "max_weight", "=", "max_weight", "\n", "self", ".", "trees", "=", "[", "]", "\n", "self", ".", "coords_trees", "=", "OrderedDict", "(", ")", "\n", "self", ".", "ens_nodes_array", "=", "[", "]", "\n", "self", ".", "max_tree_node_id", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.TreeEnsemble.__repr__": [[299, 302], ["sorted", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "sorted_trees", "=", "sorted", "(", "self", ".", "trees", ",", "key", "=", "lambda", "tree", ":", "tree", ".", "coord", ")", "\n", "return", "'\\n'", ".", "join", "(", "[", "str", "(", "t", ")", "for", "t", "in", "sorted_trees", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.TreeEnsemble.copy": [[303, 310], ["tree_ensemble.TreeEnsemble", "tree_ensemble.TreeEnsemble.add_weak_learner"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.add_weak_learner"], ["", "def", "copy", "(", "self", ")", ":", "\n", "        ", "ensemble_new", "=", "TreeEnsemble", "(", "self", ".", "weak_learner", ",", "self", ".", "n_trials_coord", ",", "self", ".", "lr", ",", "self", ".", "min_samples_split", ",", "\n", "self", ".", "min_samples_leaf", ",", "self", ".", "idx_clsf", ",", "self", ".", "max_depth", ",", "self", ".", "gamma_hp", ",", "self", ".", "n_bins", ",", "\n", "self", ".", "max_weight", ")", "\n", "for", "tree", "in", "self", ".", "trees", ":", "\n", "            ", "ensemble_new", ".", "add_weak_learner", "(", "tree", ",", "apply_lr", "=", "False", ")", "\n", "", "return", "ensemble_new", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.TreeEnsemble.load": [[311, 337], ["numpy.sort", "list", "range", "ensemble_dict.keys", "len", "tree_ensemble.TreeEnsemble.add_weak_learner", "root.to_array_contiguous", "numpy.all", "tree_ensemble.Tree", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.add_weak_learner", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.to_array_contiguous"], ["", "def", "load", "(", "self", ",", "ensemble_dict", ",", "iteration", ")", ":", "\n", "        ", "tree_indices", "=", "np", ".", "sort", "(", "list", "(", "ensemble_dict", ".", "keys", "(", ")", ")", ")", "# just a list of contiguous indices [0, 1, ..., n_trees]", "\n", "if", "iteration", "!=", "-", "1", ":", "# take only the tree ensemble up to a certain iteration", "\n", "            ", "tree_indices", "=", "tree_indices", "[", "tree_indices", "<=", "iteration", "]", "\n", "", "for", "i_tree", "in", "tree_indices", ":", "\n", "# first create all tree nodes and maintain a dictionary with all nodes (for easier look-up later on)", "\n", "            ", "node_dict", "=", "{", "}", "\n", "for", "i_node", "in", "range", "(", "len", "(", "ensemble_dict", "[", "i_tree", "]", ")", ")", ":", "\n", "                ", "if", "not", "np", ".", "all", "(", "ensemble_dict", "[", "i_tree", "]", "[", "i_node", "]", "==", "0", ")", ":", "\n", "                    ", "id_", ",", "id_left", ",", "id_right", ",", "w_l", ",", "w_r", ",", "b", ",", "coord", ",", "loss", "=", "ensemble_dict", "[", "i_tree", "]", "[", "i_node", "]", "\n", "id_", ",", "id_left", ",", "id_right", ",", "coord", "=", "int", "(", "id_", ")", ",", "int", "(", "id_left", ")", ",", "int", "(", "id_right", ")", ",", "int", "(", "coord", ")", "\n", "# create a node, but without any connections to its children", "\n", "tree", "=", "Tree", "(", "id_", ",", "None", ",", "None", ",", "w_l", ",", "w_r", ",", "b", ",", "coord", ",", "loss", ")", "\n", "node_dict", "[", "id_", "]", "=", "(", "tree", ",", "id_left", ",", "id_right", ")", "\n", "# then establish the right connections between the nodes of the tree", "\n", "", "", "for", "node", "in", "node_dict", ":", "\n", "                ", "tree", ",", "id_left", ",", "id_right", "=", "node_dict", "[", "node", "]", "\n", "if", "id_left", "!=", "-", "1", ":", "\n", "                    ", "tree", ".", "left", "=", "node_dict", "[", "id_left", "]", "[", "0", "]", "\n", "", "if", "id_right", "!=", "-", "1", ":", "\n", "                    ", "tree", ".", "right", "=", "node_dict", "[", "id_right", "]", "[", "0", "]", "\n", "# add the root as the next element of the ensemble", "\n", "", "", "if", "ensemble_dict", "[", "i_tree", "]", "!=", "[", "]", ":", "\n", "                ", "root", "=", "node_dict", "[", "ensemble_dict", "[", "i_tree", "]", "[", "0", "]", "[", "0", "]", "]", "[", "0", "]", "\n", "self", ".", "add_weak_learner", "(", "root", ",", "apply_lr", "=", "False", ")", "\n", "root", ".", "node_list", "=", "root", ".", "to_array_contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.TreeEnsemble.export_model": [[338, 344], ["enumerate", "numpy.array"], "methods", ["None"], ["", "", "", "def", "export_model", "(", "self", ")", ":", "\n", "# note: every tree has potentially a different number of nodes, thus we save it in a dictionary", "\n", "        ", "ensemble_dict", "=", "{", "}", "\n", "for", "i", ",", "tree", "in", "enumerate", "(", "self", ".", "trees", ")", ":", "\n", "            ", "ensemble_dict", "[", "i", "]", "=", "np", ".", "array", "(", "tree", ".", "node_list", ")", "# all tree nodes are in this array", "\n", "", "return", "ensemble_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.TreeEnsemble.add_weak_learner": [[345, 367], ["tree_ensemble.TreeEnsemble.trees.append", "tree_ensemble.TreeEnsemble.coords_trees[].append", "tree_ensemble.Tree", "tree_ensemble.TreeEnsemble.add_weak_learner.adjust_lr"], "methods", ["None"], ["", "def", "add_weak_learner", "(", "self", ",", "tree", ",", "apply_lr", "=", "True", ")", ":", "\n", "        ", "def", "adjust_lr", "(", "tree", ",", "lr", ")", ":", "\n", "            ", "\"\"\" Recursively goes over all node values and scales the weights by the learning rate. \"\"\"", "\n", "tree", ".", "w_l", ",", "tree", ".", "w_r", "=", "tree", ".", "w_l", "*", "lr", ",", "tree", ".", "w_r", "*", "lr", "\n", "if", "tree", ".", "node_list", "!=", "[", "]", ":", "# i.e. if root", "\n", "                ", "for", "node_tuple", "in", "tree", ".", "node_list", ":", "\n", "                    ", "node_tuple", "[", "3", "]", ",", "node_tuple", "[", "4", "]", "=", "node_tuple", "[", "3", "]", "*", "lr", ",", "node_tuple", "[", "4", "]", "*", "lr", "\n", "", "", "if", "tree", ".", "left", "is", "not", "None", ":", "\n", "                ", "adjust_lr", "(", "tree", ".", "left", ",", "lr", ")", "\n", "", "if", "tree", ".", "right", "is", "not", "None", ":", "\n", "                ", "adjust_lr", "(", "tree", ".", "right", ",", "lr", ")", "\n", "", "return", "tree", "\n", "\n", "", "if", "tree", "is", "None", ":", "# can happen if no splits whatsoever were made", "\n", "            ", "tree", "=", "Tree", "(", ")", "\n", "", "if", "apply_lr", ":", "\n", "            ", "tree", "=", "adjust_lr", "(", "tree", ",", "self", ".", "lr", ")", "\n", "", "self", ".", "trees", ".", "append", "(", "tree", ")", "\n", "\n", "if", "tree", ".", "coord", "not", "in", "self", ".", "coords_trees", ":", "\n", "            ", "self", ".", "coords_trees", "[", "tree", ".", "coord", "]", "=", "[", "]", "\n", "", "self", ".", "coords_trees", "[", "tree", ".", "coord", "]", ".", "append", "(", "tree", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.TreeEnsemble.predict": [[368, 373], ["numpy.zeros", "tree.predict"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict"], ["", "def", "predict", "(", "self", ",", "X", ")", ":", "\n", "        ", "f", "=", "np", ".", "zeros", "(", "X", ".", "shape", "[", "0", "]", ")", "\n", "for", "tree", "in", "self", ".", "trees", ":", "\n", "            ", "f", "+=", "tree", ".", "predict", "(", "X", ")", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.TreeEnsemble.certify_treewise": [[374, 379], ["numpy.zeros", "tree.find_min_yf"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.find_min_yf"], ["", "def", "certify_treewise", "(", "self", ",", "X", ",", "y", ",", "eps", ")", ":", "\n", "        ", "lb_ensemble", "=", "np", ".", "zeros", "(", "X", ".", "shape", "[", "0", "]", ")", "\n", "for", "tree", "in", "self", ".", "trees", ":", "\n", "            ", "lb_ensemble", "+=", "tree", ".", "find_min_yf", "(", "X", ",", "y", ",", "eps", ")", "\n", "", "return", "lb_ensemble", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.TreeEnsemble.prune_last_tree": [[380, 420], ["numpy.exp", "numpy.mean", "copy.deepcopy", "copy.deepcopy", "numpy.mean", "copy.deepcopy.get_depth", "copy.deepcopy.rm_leaf", "copy.deepcopy.to_array_contiguous", "numpy.mean", "ValueError", "copy.deepcopy.get_some_leaf", "numpy.mean", "copy.deepcopy.get_depth", "copy.deepcopy", "numpy.exp", "numpy.mean", "ValueError", "numpy.exp", "numpy.exp", "copy.deepcopy.predict", "numpy.exp", "copy.deepcopy.find_min_yf", "copy.deepcopy.predict", "copy.deepcopy.find_min_yf"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_depth", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.rm_leaf", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.to_array_contiguous", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_some_leaf", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_depth", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.find_min_yf", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.find_min_yf"], ["", "def", "prune_last_tree", "(", "self", ",", "X", ",", "y", ",", "margin_prev", ",", "eps", ",", "model", ")", ":", "\n", "        ", "\"\"\"\n        Recursive procedure for building a single tree.\n\n        Note: this function belongs to the tree, and not to the ensemble because the ensemble doesn't matter anymore\n        once the vector gamma is fixed.\n        \"\"\"", "\n", "gamma", "=", "np", ".", "exp", "(", "-", "margin_prev", ")", "\n", "loss_prev_ensemble", "=", "np", ".", "mean", "(", "gamma", ")", "\n", "\n", "best_tree", "=", "copy", ".", "deepcopy", "(", "self", ".", "trees", "[", "-", "1", "]", ")", "# copy the whole tree since we will change its leaves", "\n", "if", "model", "in", "[", "'plain'", ",", "'da_uniform'", ",", "'at_cube'", "]", ":", "\n", "            ", "best_loss", "=", "np", ".", "mean", "(", "gamma", "*", "np", ".", "exp", "(", "-", "y", "*", "best_tree", ".", "predict", "(", "X", ")", ")", ")", "\n", "", "elif", "model", "==", "'robust_bound'", ":", "\n", "            ", "best_loss", "=", "np", ".", "mean", "(", "gamma", "*", "np", ".", "exp", "(", "-", "best_tree", ".", "find_min_yf", "(", "X", ",", "y", ",", "eps", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'wrong model type'", ")", "\n", "", "best_loss", "+=", "self", ".", "gamma_hp", "*", "best_tree", ".", "get_depth", "(", ")", "# introduce depth penalization", "\n", "if", "best_loss", "<", "loss_prev_ensemble", ":", "\n", "            ", "return", "\n", "\n", "", "curr_tree", "=", "copy", ".", "deepcopy", "(", "best_tree", ")", "\n", "# stop when best_loss is better than the previous loss or curr_tree became just a stump", "\n", "while", "best_loss", ">=", "loss_prev_ensemble", "and", "not", "(", "curr_tree", ".", "left", "is", "None", "and", "curr_tree", ".", "right", "is", "None", ")", ":", "\n", "            ", "curr_tree", ".", "rm_leaf", "(", "curr_tree", ".", "get_some_leaf", "(", ")", ")", "# gradual pruning", "\n", "# curr_tree.rm_bottom_layer(depth=1, max_depth=curr_tree.get_depth())  # agressive pruning", "\n", "curr_tree", ".", "node_list", "=", "curr_tree", ".", "to_array_contiguous", "(", ")", "\n", "if", "model", "in", "[", "'plain'", ",", "'da_uniform'", ",", "'at_cube'", "]", ":", "\n", "                ", "loss_pruned", "=", "np", ".", "mean", "(", "gamma", "*", "np", ".", "exp", "(", "-", "y", "*", "curr_tree", ".", "predict", "(", "X", ")", ")", ")", "\n", "", "elif", "model", "==", "'robust_bound'", ":", "\n", "                ", "loss_pruned", "=", "np", ".", "mean", "(", "gamma", "*", "np", ".", "exp", "(", "-", "curr_tree", ".", "find_min_yf", "(", "X", ",", "y", ",", "eps", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'wrong model type'", ")", "\n", "", "loss_pruned", "+=", "self", ".", "gamma_hp", "*", "curr_tree", ".", "get_depth", "(", ")", "# introduce depth penalization", "\n", "# print('{:.4f} {:.4f} {}'.format(loss_pruned, best_loss, curr_tree))", "\n", "if", "loss_pruned", "<", "best_loss", ":", "\n", "                ", "best_loss", "=", "loss_pruned", "\n", "best_tree", "=", "copy", ".", "deepcopy", "(", "curr_tree", ")", "\n", "# print('best loss: {:.4f}, best tree: {}'.format(best_loss, best_tree))", "\n", "", "", "self", ".", "trees", "[", "-", "1", "]", "=", "best_tree", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.TreeEnsemble.fit_tree": [[421, 478], ["tree_ensemble.TreeEnsemble.fit_stumps_over_coords", "tree_ensemble.Tree", "numpy.mean", "tree_ensemble.TreeEnsemble.fit_tree", "tree_ensemble.TreeEnsemble.fit_tree", "tree_ensemble.Tree.to_array_contiguous", "ValueError", "concurrent.futures.ThreadPoolExecutor", "executor.submit", "executor.submit", "executor.submit.result", "executor.submit.result"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.fit_stumps_over_coords", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.TreeEnsemble.fit_tree", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.TreeEnsemble.fit_tree", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.to_array_contiguous"], ["", "def", "fit_tree", "(", "self", ",", "X", ",", "y", ",", "gamma", ",", "model", ",", "eps", ",", "depth", ")", ":", "\n", "        ", "\"\"\"\n        Recursive procedure for building a single tree.\n        Returning None means that tree.left or tree.right will be set to None, i.e. no child.\n\n        TODO: the problem currently is that there is a minor memory leak in the current implementation. One can try to\n        get rid of it by rewriting this function in a non-recursive way (similarly to, e.g. how predict_point() is done)\n        \"\"\"", "\n", "parallel", "=", "True", "# causes a minor memory leak; disable if the memory is limited", "\n", "\n", "if", "depth", "==", "1", ":", "\n", "            ", "self", ".", "max_tree_node_id", "=", "0", "# if we start a new tree, set the counter to 0 (needed for efficient predict())", "\n", "", "if", "depth", ">", "self", ".", "max_depth", ":", "# and (X.shape[0] <= 10000 or depth > 2*self.max_depth):  # adaptive depth", "\n", "            ", "return", "None", "\n", "", "if", "X", ".", "shape", "[", "0", "]", "<", "self", ".", "min_samples_split", ":", "\n", "            ", "return", "None", "\n", "", "if", "(", "y", "==", "-", "1", ")", ".", "all", "(", ")", "or", "(", "y", "==", "1", ")", ".", "all", "(", ")", ":", "# if already pure, don't branch anymore", "\n", "            ", "return", "None", "\n", "\n", "# create a new tree that will become a node (if further splits are needed)", "\n", "# or a leaf (if max_depth or min_samples_leaf is reached)", "\n", "", "w_l", ",", "w_r", ",", "b", ",", "coord", ",", "loss", "=", "self", ".", "fit_stumps_over_coords", "(", "X", ",", "y", ",", "gamma", ",", "model", ",", "eps", ",", "depth", ")", "\n", "\n", "if", "coord", "==", "-", "1", ":", "# no further splits because min_samples_leaf is reached", "\n", "            ", "return", "None", "\n", "", "if", "loss", ">=", "np", ".", "mean", "(", "gamma", ")", ":", "# if the stump doesn't help, don't add it at all; very unlikely situation", "\n", "# print('Did not make this split since old_loss={:.4} <= new_loss={:.4}'.format(np.mean(gamma), loss))", "\n", "            ", "return", "None", "\n", "\n", "", "tree", "=", "Tree", "(", "self", ".", "max_tree_node_id", ",", "None", ",", "None", ",", "w_l", ",", "w_r", ",", "b", ",", "coord", ",", "loss", ")", "\n", "self", ".", "max_tree_node_id", "+=", "1", "# increment the counter", "\n", "\n", "if", "model", "in", "[", "'plain'", ",", "'da_uniform'", ",", "'at_cube'", "]", ":", "\n", "            ", "idx_left", "=", "(", "X", "[", ":", ",", "tree", ".", "coord", "]", "<", "tree", ".", "b", ")", "\n", "idx_right", "=", "(", "X", "[", ":", ",", "tree", ".", "coord", "]", ">=", "tree", ".", "b", ")", "\n", "", "elif", "model", "==", "'robust_bound'", ":", "\n", "            ", "idx_left", "=", "(", "X", "[", ":", ",", "tree", ".", "coord", "]", "<", "tree", ".", "b", "+", "eps", ")", "\n", "idx_right", "=", "(", "X", "[", ":", ",", "tree", ".", "coord", "]", ">=", "tree", ".", "b", "-", "eps", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'wrong model type'", ")", "\n", "\n", "", "if", "parallel", "and", "depth", "<=", "4", ":", "\n", "            ", "with", "ThreadPoolExecutor", "(", "max_workers", "=", "2", ")", "as", "executor", ":", "\n", "                ", "proc_left", "=", "executor", ".", "submit", "(", "self", ".", "fit_tree", ",", "X", "[", "idx_left", ",", ":", "]", ",", "y", "[", "idx_left", "]", ",", "gamma", "[", "idx_left", "]", ",", "model", ",", "eps", ",", "depth", "+", "1", ")", "\n", "proc_right", "=", "executor", ".", "submit", "(", "self", ".", "fit_tree", ",", "X", "[", "idx_right", ",", ":", "]", ",", "y", "[", "idx_right", "]", ",", "gamma", "[", "idx_right", "]", ",", "model", ",", "eps", ",", "depth", "+", "1", ")", "\n", "tree", ".", "left", "=", "proc_left", ".", "result", "(", ")", "\n", "tree", ".", "right", "=", "proc_right", ".", "result", "(", ")", "\n", "", "", "else", ":", "\n", "# print(\"left subtree: {:d} examples\".format(np.sum(idx_left)))", "\n", "            ", "tree", ".", "left", "=", "self", ".", "fit_tree", "(", "X", "[", "idx_left", ",", ":", "]", ",", "y", "[", "idx_left", "]", ",", "gamma", "[", "idx_left", "]", ",", "model", ",", "eps", ",", "depth", "+", "1", ")", "\n", "# print(\"right subtree: {:d} examples\".format(np.sum(idx_right)))", "\n", "tree", ".", "right", "=", "self", ".", "fit_tree", "(", "X", "[", "idx_right", ",", ":", "]", ",", "y", "[", "idx_right", "]", ",", "gamma", "[", "idx_right", "]", ",", "model", ",", "eps", ",", "depth", "+", "1", ")", "\n", "\n", "", "if", "depth", "==", "1", ":", "\n", "# a list of all nodes at the root is needed for fast parallel predictions", "\n", "            ", "tree", ".", "node_list", "=", "tree", ".", "to_array_contiguous", "(", ")", "\n", "", "return", "tree", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.TreeEnsemble.fit_stumps_over_coords": [[479, 527], ["numpy.mean", "len", "min_losses.argmin", "int", "X.astype", "y.astype", "gamma.astype", "numpy.abs().sum", "numpy.random.permutation", "numpy.zeros", "numpy.full", "utils.get_n_proc", "min", "enumerate", "numpy.float32", "print", "min", "concurrent.futures.ThreadPoolExecutor", "range", "range", "tree_ensemble.fit_stump", "numpy.abs", "numpy.where", "procs.append", "procs[].result", "executor.submit"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.get_n_proc", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.fit_stump"], ["", "def", "fit_stumps_over_coords", "(", "self", ",", "X", ",", "y", ",", "gamma", ",", "model", ",", "eps", ",", "depth", ")", ":", "\n", "        ", "verbose", "=", "False", "\n", "parallel", "=", "True", "\n", "n_ex", "=", "X", ".", "shape", "[", "0", "]", "\n", "X", ",", "y", ",", "gamma", "=", "X", ".", "astype", "(", "dtype", ")", ",", "y", ".", "astype", "(", "dtype", ")", ",", "gamma", ".", "astype", "(", "dtype", ")", "\n", "prev_loss", "=", "np", ".", "mean", "(", "gamma", ")", "\n", "\n", "# 151 features are always 0.0 on MNIST 2 vs 6. And this number is even higher for smaller subsets of MNIST,", "\n", "# i.e. subsets of examples partitioned by tree splits.", "\n", "idx_non_trivial", "=", "np", ".", "abs", "(", "X", ")", ".", "sum", "(", "axis", "=", "0", ")", ">", "0.0", "\n", "features_to_check", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "where", "(", "idx_non_trivial", ")", "[", "0", "]", ")", "[", ":", "self", ".", "n_trials_coord", "]", "\n", "\n", "n_coords", "=", "len", "(", "features_to_check", ")", "\n", "params", ",", "min_losses", "=", "np", ".", "zeros", "(", "(", "n_coords", ",", "4", ")", ")", ",", "np", ".", "full", "(", "n_coords", ",", "np", ".", "inf", ")", "\n", "\n", "if", "parallel", ":", "\n", "            ", "n_proc", "=", "get_n_proc", "(", "n_ex", ")", "\n", "n_proc", "=", "min", "(", "n_coords", ",", "min", "(", "100", ",", "n_proc", ")", ")", "\n", "batch_size", "=", "n_coords", "//", "n_proc", "\n", "n_batches", "=", "n_coords", "//", "batch_size", "+", "1", "\n", "\n", "with", "ThreadPoolExecutor", "(", "max_workers", "=", "n_proc", ")", "as", "executor", ":", "\n", "                ", "procs", "=", "[", "]", "\n", "for", "i_batch", "in", "range", "(", "n_batches", ")", ":", "\n", "                    ", "coords", "=", "features_to_check", "[", "i_batch", "*", "batch_size", ":", "(", "i_batch", "+", "1", ")", "*", "batch_size", "]", "\n", "args", "=", "(", "X", "[", ":", ",", "coords", "]", ",", "y", ",", "gamma", ",", "model", ",", "eps", ",", "coords", ",", "self", ".", "n_bins", ",", "self", ".", "min_samples_leaf", ",", "self", ".", "max_weight", ")", "\n", "procs", ".", "append", "(", "executor", ".", "submit", "(", "fit_stump_batch", ",", "*", "args", ")", ")", "\n", "\n", "# Process the results", "\n", "", "i_coord", "=", "0", "\n", "for", "i_batch", "in", "range", "(", "n_batches", ")", ":", "\n", "                    ", "res_many", "=", "procs", "[", "i_batch", "]", ".", "result", "(", ")", "\n", "for", "res", "in", "res_many", ":", "\n", "                        ", "min_losses", "[", "i_coord", "]", ",", "*", "params", "[", "i_coord", ",", ":", "]", "=", "res", "\n", "i_coord", "+=", "1", "\n", "", "", "", "", "else", ":", "\n", "            ", "for", "i_coord", ",", "coord", "in", "enumerate", "(", "features_to_check", ")", ":", "\n", "                ", "min_losses", "[", "i_coord", "]", ",", "*", "params", "[", "i_coord", ",", ":", "]", "=", "fit_stump", "(", "\n", "X", "[", ":", ",", "coord", "]", ",", "y", ",", "gamma", ",", "model", ",", "eps", ",", "coord", ",", "self", ".", "n_bins", ",", "self", ".", "min_samples_leaf", ",", "self", ".", "max_weight", ")", "\n", "\n", "", "", "id_best_coord", "=", "min_losses", ".", "argmin", "(", ")", "\n", "min_loss", "=", "min_losses", "[", "id_best_coord", "]", "\n", "best_coord", "=", "int", "(", "params", "[", "id_best_coord", "]", "[", "3", "]", ")", "# float to int is necessary for a coordinate", "\n", "best_wl", ",", "best_wr", ",", "best_b", "=", "params", "[", "id_best_coord", "]", "[", "0", "]", ",", "params", "[", "id_best_coord", "]", "[", "1", "]", ",", "np", ".", "float32", "(", "params", "[", "id_best_coord", "]", "[", "2", "]", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'[{}-vs-all] depth {}: n_ex {}, n_coords {} -- loss {:.5f}->{:.5f}, b={:.3f} wl={:.3f} wr={:.3f} at coord {}'", ".", "format", "(", "\n", "self", ".", "idx_clsf", ",", "depth", ",", "n_ex", ",", "n_coords", ",", "prev_loss", ",", "min_loss", ",", "best_b", ",", "best_wl", ",", "best_wr", ",", "best_coord", ")", ")", "\n", "", "return", "best_wl", ",", "best_wr", ",", "best_b", ",", "best_coord", ",", "min_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.find_min_yf_point": [[10, 29], ["numba.njit", "len", "int", "int", "int", "node_ids_to_explore.pop", "node_ids_to_explore.append", "min", "node_ids_to_explore.append", "min", "int", "int"], "function", ["None"], ["@", "njit", "(", "nogil", "=", "True", ")", "\n", "def", "find_min_yf_point", "(", "nodes", ",", "x", ",", "y", ",", "eps", ")", ":", "\n", "# Every node is: (self.id, id_left, id_right, self.w_l, self.w_r, self.b, self.coord, self.loss)", "\n", "    ", "node_ids_to_explore", "=", "[", "0", "]", "# root node id", "\n", "min_val", "=", "np", ".", "inf", "\n", "while", "len", "(", "node_ids_to_explore", ")", ">", "0", ":", "\n", "        ", "node", "=", "nodes", "[", "node_ids_to_explore", ".", "pop", "(", ")", "]", "\n", "id_left", ",", "id_right", ",", "w_l", ",", "w_r", ",", "b", ",", "coord", "=", "int", "(", "node", "[", "1", "]", ")", ",", "int", "(", "node", "[", "2", "]", ")", ",", "node", "[", "3", "]", ",", "node", "[", "4", "]", ",", "node", "[", "5", "]", ",", "int", "(", "node", "[", "6", "]", ")", "\n", "if", "x", "[", "coord", "]", "<=", "b", "+", "eps", ":", "\n", "            ", "if", "id_left", "!=", "-", "1", ":", "\n", "                ", "node_ids_to_explore", ".", "append", "(", "int", "(", "nodes", "[", "id_left", "]", "[", "0", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "min_val", "=", "min", "(", "min_val", ",", "y", "*", "w_l", ")", "\n", "", "", "if", "x", "[", "coord", "]", ">=", "b", "-", "eps", ":", "\n", "            ", "if", "id_right", "!=", "-", "1", ":", "\n", "                ", "node_ids_to_explore", ".", "append", "(", "int", "(", "nodes", "[", "id_right", "]", "[", "0", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "min_val", "=", "min", "(", "min_val", ",", "y", "*", "(", "w_l", "+", "w_r", ")", ")", "\n", "", "", "", "return", "min_val", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.find_min_yf_tree_par": [[31, 39], ["numba.njit", "numpy.float32", "numpy.zeros", "numba.prange", "tree_ensemble.find_min_yf_point"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.find_min_yf_point"], ["", "@", "njit", "(", "parallel", "=", "True", ",", "nogil", "=", "True", ")", "\n", "def", "find_min_yf_tree_par", "(", "nodes", ",", "X", ",", "y", ",", "eps", ")", ":", "\n", "# == works as expected only if all numbers are in float32; float32 is the preferred choice due to less memory", "\n", "    ", "eps", "=", "np", ".", "float32", "(", "eps", ")", "\n", "f", "=", "np", ".", "zeros", "(", "X", ".", "shape", "[", "0", "]", ")", "\n", "for", "i", "in", "prange", "(", "X", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "f", "[", "i", "]", "=", "find_min_yf_point", "(", "nodes", ",", "X", "[", "i", "]", ",", "y", "[", "i", "]", ",", "eps", ")", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.predict_point": [[41, 57], ["numba.njit", "int", "int", "int"], "function", ["None"], ["", "@", "njit", "(", "nogil", "=", "True", ")", "\n", "def", "predict_point", "(", "nodes", ",", "x", ")", ":", "\n", "# Every node is: (self.id, id_left, id_right, self.w_l, self.w_r, self.b, self.coord, self.loss)", "\n", "    ", "node", "=", "nodes", "[", "0", "]", "# take the root node", "\n", "while", "True", ":", "\n", "        ", "id_left", ",", "id_right", ",", "w_l", ",", "w_r", ",", "b", ",", "coord", "=", "int", "(", "node", "[", "1", "]", ")", ",", "int", "(", "node", "[", "2", "]", ")", ",", "node", "[", "3", "]", ",", "node", "[", "4", "]", ",", "node", "[", "5", "]", ",", "int", "(", "node", "[", "6", "]", ")", "\n", "if", "x", "[", "coord", "]", "<", "b", ":", "\n", "            ", "if", "id_left", "!=", "-", "1", ":", "\n", "                ", "node", "=", "nodes", "[", "id_left", "]", "\n", "", "else", ":", "\n", "                ", "return", "w_l", "\n", "", "", "else", ":", "\n", "            ", "if", "id_right", "!=", "-", "1", ":", "\n", "                ", "node", "=", "nodes", "[", "id_right", "]", "\n", "", "else", ":", "\n", "                ", "return", "w_l", "+", "w_r", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.predict_tree_par": [[59, 65], ["numba.njit", "numpy.zeros", "numba.prange", "tree_ensemble.predict_point"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.predict_point"], ["", "", "", "", "@", "njit", "(", "parallel", "=", "True", ",", "nogil", "=", "True", ")", "\n", "def", "predict_tree_par", "(", "nodes", ",", "X", ")", ":", "\n", "    ", "f", "=", "np", ".", "zeros", "(", "X", ".", "shape", "[", "0", "]", ")", "\n", "for", "i", "in", "prange", "(", "X", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "f", "[", "i", "]", "=", "predict_point", "(", "nodes", ",", "X", "[", "i", "]", ")", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.fit_stump_batch": [[529, 534], ["numpy.zeros", "enumerate", "tree_ensemble.fit_stump", "len"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.fit_stump"], ["", "", "def", "fit_stump_batch", "(", "Xs", ",", "y", ",", "gamma", ",", "model", ",", "eps", ",", "coords", ",", "n_bins", ",", "min_samples_leaf", ",", "max_weight", ")", ":", "\n", "    ", "res", "=", "np", ".", "zeros", "(", "[", "len", "(", "coords", ")", ",", "5", "]", ")", "\n", "for", "i", ",", "coord", "in", "enumerate", "(", "coords", ")", ":", "\n", "        ", "res", "[", "i", "]", "=", "fit_stump", "(", "Xs", "[", ":", ",", "i", "]", ",", "y", ",", "gamma", ",", "model", ",", "eps", ",", "coord", ",", "n_bins", ",", "min_samples_leaf", ",", "max_weight", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.fit_stump": [[536, 628], ["numpy.min", "numpy.sort", "utils.get_contiguous_indices", "numpy.clip", "numpy.clip", "numpy.array", "numpy.sort", "numpy.unique", "numpy.sort", "robust_boosting.fit_plain_stumps", "robust_boosting.fit_plain_stumps", "numpy.abs", "print", "len", "numpy.copy", "numpy.concatenate", "numpy.clip", "len", "numpy.concatenate", "robust_boosting.fit_robust_bound_stumps", "ValueError", "numpy.where", "len", "len", "robust_boosting.exp_loss_robust", "robust_boosting.exp_loss_robust", "ValueError", "robust_boosting.fit_robust_bound_stumps", "ValueError", "numpy.arange", "numpy.arange", "len", "numpy.full", "numpy.full"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.get_contiguous_indices", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_plain_stumps", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_plain_stumps", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.copy", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_robust_bound_stumps", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.exp_loss_robust", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.exp_loss_robust", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_robust_bound_stumps"], ["", "def", "fit_stump", "(", "X_proj", ",", "y", ",", "gamma", ",", "model", ",", "eps", ",", "coord", ",", "n_bins", ",", "min_samples_leaf", ",", "max_weight", ")", ":", "\n", "    ", "min_prec_val", "=", "1e-7", "\n", "min_val", ",", "max_val", "=", "0.0", ",", "1.0", "# can be changed if the features are in a different range", "\n", "\n", "if", "n_bins", ">", "0", ":", "\n", "        ", "if", "model", "==", "'robust_bound'", ":", "\n", "# e.g. that's the thresholds that one gets with n_bins=10: [0.31, 0.41, 0.5, 0.59, 0.69]", "\n", "            ", "b_vals", "=", "np", ".", "arange", "(", "eps", "*", "n_bins", ",", "n_bins", "-", "eps", "*", "n_bins", "+", "1", ")", "/", "n_bins", "\n", "# to have some margin to make the thresholds not adversarially reachable from 0 or 1", "\n", "b_vals", "[", "b_vals", "<", "0.5", "]", "+=", "0.1", "*", "1", "/", "n_bins", "\n", "b_vals", "[", "b_vals", ">", "0.5", "]", "-=", "0.1", "*", "1", "/", "n_bins", "\n", "", "else", ":", "\n", "            ", "b_vals", "=", "np", ".", "arange", "(", "1", ",", "n_bins", ")", "/", "n_bins", "\n", "", "", "else", ":", "\n", "        ", "threshold_candidates", "=", "np", ".", "sort", "(", "X_proj", ")", "\n", "if", "min_samples_leaf", ">", "0", ":", "\n", "            ", "threshold_candidates", "=", "threshold_candidates", "[", "min_samples_leaf", ":", "-", "min_samples_leaf", "]", "\n", "", "if", "len", "(", "threshold_candidates", ")", "==", "0", ":", "# if no samples left according to min_samples_leaf", "\n", "            ", "return", "[", "np", ".", "inf", ",", "0.0", ",", "0.0", ",", "0.0", ",", "-", "1", "]", "\n", "", "if", "model", "not", "in", "[", "'robust_bound'", "]", "or", "eps", "==", "0.0", ":", "# plain or da_uniform training", "\n", "            ", "b_vals", "=", "np", ".", "copy", "(", "threshold_candidates", ")", "\n", "b_vals", "+=", "min_prec_val", "# to break the ties", "\n", "", "else", ":", "# robust training", "\n", "            ", "b_vals", "=", "np", ".", "concatenate", "(", "(", "threshold_candidates", "-", "eps", ",", "threshold_candidates", "+", "eps", ")", ",", "axis", "=", "0", ")", "\n", "b_vals", "=", "np", ".", "clip", "(", "b_vals", ",", "min_val", ",", "max_val", ")", "# save computations (often goes 512 -> 360 thresholds on MNIST)", "\n", "# to make in the overlapping case [---x-[--]-x---] output 2 different losses in the middle", "\n", "n_bs", "=", "len", "(", "threshold_candidates", ")", "\n", "b_vals", "+=", "np", ".", "concatenate", "(", "(", "-", "np", ".", "full", "(", "n_bs", ",", "min_prec_val", ")", ",", "np", ".", "full", "(", "n_bs", ",", "min_prec_val", ")", ")", ",", "axis", "=", "0", ")", "\n", "", "b_vals", "=", "np", ".", "unique", "(", "b_vals", ")", "# use only unique b's", "\n", "b_vals", "=", "np", ".", "sort", "(", "b_vals", ")", "# still important to sort because of the final threshold selection", "\n", "\n", "", "if", "model", "in", "[", "'plain'", ",", "'da_uniform'", ",", "'at_cube'", "]", ":", "\n", "        ", "losses", ",", "w_l_vals", ",", "w_r_vals", ",", "b_vals", "=", "fit_plain_stumps", "(", "X_proj", ",", "y", ",", "gamma", ",", "b_vals", ",", "max_weight", ")", "\n", "", "elif", "model", "==", "'robust_bound'", ":", "\n", "        ", "losses", ",", "w_l_vals", ",", "w_r_vals", ",", "b_vals", "=", "fit_robust_bound_stumps", "(", "X_proj", ",", "y", ",", "gamma", ",", "b_vals", ",", "eps", ",", "max_weight", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'wrong model'", ")", "\n", "\n", "", "min_loss", "=", "np", ".", "min", "(", "losses", ")", "\n", "# probably, they are already sorted, but to be 100% sure since it is not explicitly mentioned in the docs", "\n", "indices_opt_init", "=", "np", ".", "sort", "(", "np", ".", "where", "(", "losses", "==", "min_loss", ")", "[", "0", "]", ")", "\n", "indices_opt", "=", "get_contiguous_indices", "(", "indices_opt_init", ")", "\n", "id_opt", "=", "indices_opt", "[", "len", "(", "indices_opt", ")", "//", "2", "]", "\n", "\n", "idx_prev", "=", "np", ".", "clip", "(", "indices_opt", "[", "0", "]", "-", "1", ",", "0", ",", "len", "(", "b_vals", ")", "-", "1", ")", "# to prevent stepping out of the array", "\n", "idx_next", "=", "np", ".", "clip", "(", "indices_opt", "[", "-", "1", "]", "+", "1", ",", "0", ",", "len", "(", "b_vals", ")", "-", "1", ")", "# to prevent stepping out of the array", "\n", "b_prev", ",", "w_l_prev", ",", "w_r_prev", "=", "b_vals", "[", "idx_prev", "]", ",", "w_l_vals", "[", "idx_prev", "]", ",", "w_r_vals", "[", "idx_prev", "]", "\n", "b_next", ",", "w_l_next", ",", "w_r_next", "=", "b_vals", "[", "idx_next", "]", ",", "w_l_vals", "[", "idx_next", "]", ",", "w_r_vals", "[", "idx_next", "]", "\n", "# initialization", "\n", "b_leftmost", ",", "b_rightmost", "=", "b_vals", "[", "indices_opt", "[", "0", "]", "]", ",", "b_vals", "[", "indices_opt", "[", "-", "1", "]", "]", "\n", "\n", "if", "n_bins", ">", "0", ":", "# note that one shouldn't average thresholds since it's unpredictable what is in between", "\n", "        ", "return", "[", "min_loss", ",", "w_l_vals", "[", "id_opt", "]", ",", "w_r_vals", "[", "id_opt", "]", ",", "b_vals", "[", "id_opt", "]", ",", "coord", "]", "\n", "\n", "# more involved, since with +-eps, an additional check of the loss is needed", "\n", "", "if", "model", "in", "[", "'plain'", ",", "'da_uniform'", ",", "'at_cube'", "]", ":", "\n", "        ", "b_rightmost", "=", "b_next", "\n", "", "elif", "model", "in", "[", "'robust_bound'", "]", ":", "\n", "        ", "b_prev_half", "=", "(", "b_prev", "+", "b_vals", "[", "indices_opt", "[", "0", "]", "]", ")", "/", "2", "\n", "loss_prev_half", "=", "exp_loss_robust", "(", "X_proj", ",", "y", ",", "gamma", ",", "w_l_prev", ",", "w_r_prev", ",", "[", "]", ",", "[", "]", ",", "b_prev_half", ",", "eps", ",", "False", ")", "\n", "\n", "b_next_half", "=", "(", "b_vals", "[", "indices_opt", "[", "-", "1", "]", "]", "+", "b_next", ")", "/", "2", "\n", "loss_next_half", "=", "exp_loss_robust", "(", "X_proj", ",", "y", ",", "gamma", ",", "w_l_next", ",", "w_r_next", ",", "[", "]", ",", "[", "]", ",", "b_next_half", ",", "eps", ",", "False", ")", "\n", "\n", "# we extend the interval of the constant loss to the left and to the right if there the loss is", "\n", "# the same at b_prev_half or b_next_half", "\n", "if", "loss_prev_half", "==", "losses", "[", "id_opt", "]", ":", "\n", "            ", "b_leftmost", "=", "b_prev", "\n", "", "if", "loss_next_half", "==", "losses", "[", "id_opt", "]", ":", "\n", "            ", "b_rightmost", "=", "b_next", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'wrong model'", ")", "\n", "# we put in the middle of the interval of the constant loss", "\n", "", "b_opt", "=", "(", "b_leftmost", "+", "b_rightmost", ")", "/", "2", "\n", "\n", "# For the chosen threshold, we need to calculate w_l, w_r", "\n", "# Some of w_l, w_r that correspond to min_loss may not be optimal anymore", "\n", "b_val_final", "=", "np", ".", "array", "(", "[", "b_opt", "]", ")", "\n", "if", "model", "in", "[", "'plain'", ",", "'da_uniform'", ",", "'at_cube'", "]", ":", "\n", "        ", "loss", ",", "w_l_opt", ",", "w_r_opt", ",", "_", "=", "fit_plain_stumps", "(", "X_proj", ",", "y", ",", "gamma", ",", "b_val_final", ",", "max_weight", ")", "\n", "", "elif", "model", "==", "'robust_bound'", ":", "\n", "        ", "loss", ",", "w_l_opt", ",", "w_r_opt", ",", "_", "=", "fit_robust_bound_stumps", "(", "X_proj", ",", "y", ",", "gamma", ",", "b_val_final", ",", "eps", ",", "max_weight", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'wrong model'", ")", "\n", "", "loss", ",", "w_l_opt", ",", "w_r_opt", "=", "loss", "[", "0", "]", ",", "w_l_opt", "[", "0", "]", ",", "w_r_opt", "[", "0", "]", "\n", "\n", "# recalculation of w_l, w_r shouldn't change the min loss", "\n", "if", "np", ".", "abs", "(", "loss", "-", "min_loss", ")", ">", "1e7", ":", "\n", "        ", "print", "(", "'New loss: {:.5f}, min loss before: {:.5f}'", ".", "format", "(", "loss", ",", "min_loss", ")", ")", "\n", "\n", "", "best_loss", "=", "losses", "[", "id_opt", "]", "\n", "return", "[", "best_loss", ",", "w_l_opt", ",", "w_r_opt", ",", "b_opt", ",", "coord", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.__init__": [[6, 9], ["len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "models", ")", ":", "\n", "        ", "self", ".", "models", "=", "models", "\n", "self", ".", "n_clsf", "=", "len", "(", "models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.predict": [[10, 15], ["numpy.zeros", "range", "classifiers.OneVsAllClassifier.models[].predict"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict"], ["", "def", "predict", "(", "self", ",", "X", ")", ":", "\n", "        ", "preds", "=", "np", ".", "zeros", "(", "[", "self", ".", "n_clsf", ",", "X", ".", "shape", "[", "0", "]", "]", ")", "\n", "for", "i_cls", "in", "range", "(", "self", ".", "n_clsf", ")", ":", "\n", "            ", "preds", "[", "i_cls", "]", "=", "self", ".", "models", "[", "i_cls", "]", ".", "predict", "(", "X", ")", "\n", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.predict_class": [[16, 22], ["classifiers.OneVsAllClassifier.predict", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict"], ["", "def", "predict_class", "(", "self", ",", "X", ")", ":", "\n", "        ", "preds", "=", "self", ".", "predict", "(", "X", ")", "\n", "if", "self", ".", "n_clsf", "==", "1", ":", "\n", "            ", "return", "(", "0.5", "*", "(", "(", "preds", ">", "0", ")", "+", "1", ")", ")", ".", "astype", "(", "int", ")", ".", "flatten", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "argmax", "(", "preds", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.certify_treewise": [[23, 28], ["numpy.zeros", "range", "classifiers.OneVsAllClassifier.models[].certify_treewise"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.certify_treewise"], ["", "", "def", "certify_treewise", "(", "self", ",", "X", ",", "y", ",", "eps", ")", ":", "\n", "        ", "preds", "=", "np", ".", "zeros", "(", "[", "self", ".", "n_clsf", ",", "X", ".", "shape", "[", "0", "]", "]", ")", "\n", "for", "i_cls", "in", "range", "(", "self", ".", "n_clsf", ")", ":", "\n", "            ", "preds", "[", "i_cls", "]", "=", "self", ".", "models", "[", "i_cls", "]", ".", "certify_treewise", "(", "X", ",", "y", "[", "i_cls", "]", ",", "eps", ")", "\n", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.certify_exact": [[29, 34], ["numpy.zeros", "range", "classifiers.OneVsAllClassifier.models[].certify_exact"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.certify_exact"], ["", "def", "certify_exact", "(", "self", ",", "X", ",", "y", ",", "eps", ")", ":", "\n", "        ", "preds", "=", "np", ".", "zeros", "(", "[", "self", ".", "n_clsf", ",", "X", ".", "shape", "[", "0", "]", "]", ")", "\n", "for", "i_cls", "in", "range", "(", "self", ".", "n_clsf", ")", ":", "\n", "            ", "preds", "[", "i_cls", "]", "=", "self", ".", "models", "[", "i_cls", "]", ".", "certify_exact", "(", "X", ",", "y", "[", "i_cls", "]", ",", "eps", ")", "\n", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.fmargin": [[35, 46], ["classifiers.OneVsAllClassifier.predict", "diff.min"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict"], ["", "def", "fmargin", "(", "self", ",", "X", ",", "y", ",", "fx_vals", "=", "None", ")", ":", "\n", "        ", "if", "fx_vals", "is", "None", ":", "# if fx_vals have not been provided", "\n", "            ", "fx_vals", "=", "self", ".", "predict", "(", "X", ")", "\n", "", "if", "self", ".", "n_clsf", ">", "1", ":", "\n", "            ", "preds_correct_class", "=", "(", "fx_vals", "*", "(", "y", "==", "1", ")", ")", ".", "sum", "(", "0", ",", "keepdims", "=", "True", ")", "\n", "diff", "=", "preds_correct_class", "-", "fx_vals", "# difference between the correct class and all other classes", "\n", "diff", "[", "y", "==", "1", "]", "=", "np", ".", "inf", "# to exclude zeros coming from f_correct - f_correct", "\n", "fx_vals", "=", "diff", ".", "min", "(", "0", ",", "keepdims", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "fx_vals", "=", "y", "*", "fx_vals", "\n", "", "return", "fx_vals", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.fmargin_treewise": [[47, 55], ["classifiers.OneVsAllClassifier.certify_treewise", "numpy.min"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.certify_treewise"], ["", "def", "fmargin_treewise", "(", "self", ",", "X", ",", "y", ",", "eps", ",", "fx_vals", "=", "None", ")", ":", "\n", "        ", "if", "fx_vals", "is", "None", ":", "# if fx_vals have not been provided", "\n", "            ", "fx_vals", "=", "self", ".", "certify_treewise", "(", "X", ",", "y", ",", "eps", ")", "\n", "", "if", "self", ".", "n_clsf", ">", "1", ":", "\n", "            ", "cert_correct_class", "=", "(", "fx_vals", "*", "(", "y", "==", "1", ")", ")", ".", "sum", "(", "0", ",", "keepdims", "=", "True", ")", "\n", "diff", "=", "cert_correct_class", "+", "fx_vals", "# plus because of [min -f] in cert for all classes", "\n", "fx_vals", "=", "np", ".", "min", "(", "diff", ",", "0", ",", "keepdims", "=", "True", ")", "\n", "", "return", "fx_vals", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.fmargin_exact": [[56, 63], ["classifiers.OneVsAllClassifier.certify_exact", "numpy.min"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.certify_exact"], ["", "def", "fmargin_exact", "(", "self", ",", "X", ",", "y", ",", "eps", ")", ":", "\n", "        ", "fx_vals", "=", "self", ".", "certify_exact", "(", "X", ",", "y", ",", "eps", ")", "\n", "if", "self", ".", "n_clsf", ">", "1", ":", "\n", "            ", "cert_correct_class", "=", "(", "fx_vals", "*", "(", "y", "==", "1", ")", ")", ".", "sum", "(", "0", ",", "keepdims", "=", "True", ")", "\n", "diff", "=", "cert_correct_class", "+", "fx_vals", "# plus because of [min -f] in cert for all classes", "\n", "fx_vals", "=", "np", ".", "min", "(", "diff", ",", "0", ",", "keepdims", "=", "True", ")", "\n", "", "return", "fx_vals", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.save": [[64, 71], ["numpy.array", "numpy.save", "model_lst.append", "model.export_model"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.save", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.export_model"], ["", "def", "save", "(", "self", ",", "model_path", ")", ":", "\n", "        ", "if", "model_path", "!=", "''", ":", "\n", "            ", "model_lst", "=", "[", "]", "\n", "for", "model", "in", "self", ".", "models", ":", "\n", "                ", "model_lst", ".", "append", "(", "model", ".", "export_model", "(", ")", ")", "\n", "", "model_arr", "=", "np", ".", "array", "(", "model_lst", ")", "\n", "np", ".", "save", "(", "model_path", ",", "model_arr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.load": [[72, 82], ["numpy.load", "range", "print", "classifiers.OneVsAllClassifier.models[].load", "type", "max", "model_data[].keys"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.load", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.load"], ["", "", "def", "load", "(", "self", ",", "model_path", ",", "iteration", "=", "-", "1", ")", ":", "\n", "        ", "model_data", "=", "np", ".", "load", "(", "model_path", ",", "allow_pickle", "=", "True", ")", "\n", "for", "i_clsf", "in", "range", "(", "self", ".", "n_clsf", ")", ":", "\n", "            ", "self", ".", "models", "[", "i_clsf", "]", ".", "load", "(", "model_data", "[", "i_clsf", "]", ",", "iteration", ")", "\n", "", "if", "type", "(", "model_data", "[", "0", "]", ")", "is", "dict", ":", "\n", "            ", "n_trees", "=", "max", "(", "model_data", "[", "0", "]", ".", "keys", "(", ")", ")", "+", "1", "\n", "", "else", ":", "\n", "            ", "n_trees", "=", "model_data", ".", "shape", "[", "1", "]", "\n", "", "true_iteration", "=", "iteration", "+", "1", "if", "iteration", "!=", "-", "1", "else", "n_trees", "\n", "print", "(", "'Ensemble of {}/{} trees restored: {}'", ".", "format", "(", "true_iteration", ",", "n_trees", ",", "model_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.dump_model": [[83, 100], ["len", "max", "range", "range", "len", "tree_ensemble.Tree.get_json_dict", "list_of_tree_dicts.append", "len", "tree_ensemble.Tree"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.get_json_dict"], ["", "def", "dump_model", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the model in JSON format compatible with XGBoost. \"\"\"", "\n", "# Works for trees", "\n", "n_cls", "=", "len", "(", "self", ".", "models", ")", "\n", "n_trees", "=", "max", "(", "[", "len", "(", "model", ".", "trees", ")", "for", "model", "in", "self", ".", "models", "]", ")", "\n", "\n", "list_of_tree_dicts", "=", "[", "]", "\n", "for", "i_tree", "in", "range", "(", "n_trees", ")", ":", "\n", "            ", "for", "i_cls", "in", "range", "(", "n_cls", ")", ":", "\n", "                ", "if", "i_tree", "<", "len", "(", "self", ".", "models", "[", "i_cls", "]", ".", "trees", ")", ":", "\n", "                    ", "tree", "=", "self", ".", "models", "[", "i_cls", "]", ".", "trees", "[", "i_tree", "]", "\n", "", "else", ":", "\n", "                    ", "tree", "=", "Tree", "(", ")", "\n", "", "tree_dict", ",", "_", "=", "tree", ".", "get_json_dict", "(", "counter_terminal_nodes", "=", "-", "10", ")", "\n", "list_of_tree_dicts", ".", "append", "(", "tree_dict", ")", "\n", "\n", "", "", "return", "list_of_tree_dicts", "\n", "", "", ""]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.train.eval_metrics": [[14, 58], ["range", "model_ova.fmargin", "attacks.cube_attack", "model_ova.fmargin_treewise", "len", "model_ova.models[].trees[].predict", "time.time", "model_ova.models[].trees[].find_min_yf", "time.time", "model_ova.fmargin_exact", "is_correct.mean", "is_rob_lb.mean", "is_rob_exact.mean", "is_rob_ub.mean", "time.time", "time.time", "numpy.sum", "log.print", "numpy.sum", "log.print", "numpy.sum", "log.print", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.where", "numpy.where", "numpy.where"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.fmargin", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.attacks.cube_attack", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.fmargin_treewise", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.find_min_yf", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.fmargin_exact", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print"], ["def", "eval_metrics", "(", "model_ova", ",", "X", ",", "y", ",", "pred", ",", "cert_tw", ",", "time_cert", ",", "deltas", ",", "weak_learner", ",", "eps_eval", ",", "log", ",", "n_trials_attack", ",", "check_bounds", "=", "True", ")", ":", "\n", "    ", "\"\"\" Evaluation metrics for validation and test sets. \"\"\"", "\n", "if", "X", ".", "shape", "[", "0", "]", "==", "0", ":", "# if no examples provided (e.g., the validation set is empty)", "\n", "        ", "return", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ",", "pred", ",", "cert_tw", ",", "time_cert", ",", "deltas", "\n", "\n", "# To save some computations, in particular for `find_min_yf()` which is slow for deep trees", "\n", "", "for", "i_clsf", "in", "range", "(", "len", "(", "model_ova", ".", "models", ")", ")", ":", "\n", "        ", "pred", "[", "i_clsf", "]", "+=", "model_ova", ".", "models", "[", "i_clsf", "]", ".", "trees", "[", "-", "1", "]", ".", "predict", "(", "X", ")", "\n", "time_before_cert", "=", "time", ".", "time", "(", ")", "\n", "cert_tw", "[", "i_clsf", "]", "+=", "model_ova", ".", "models", "[", "i_clsf", "]", ".", "trees", "[", "-", "1", "]", ".", "find_min_yf", "(", "X", ",", "y", "[", "i_clsf", "]", ",", "eps_eval", ")", "\n", "time_cert", "+=", "time", ".", "time", "(", ")", "-", "time_before_cert", "\n", "\n", "", "yf", "=", "model_ova", ".", "fmargin", "(", "X", ",", "y", ",", "fx_vals", "=", "pred", ")", "\n", "min_yf_ub", ",", "deltas", "=", "cube_attack", "(", "model_ova", ",", "X", ",", "y", ",", "eps_eval", ",", "n_trials_attack", ",", "deltas_init", "=", "deltas", ")", "\n", "min_yf_lb", "=", "model_ova", ".", "fmargin_treewise", "(", "X", ",", "y", ",", "eps_eval", ",", "fx_vals", "=", "cert_tw", ")", "\n", "if", "weak_learner", "==", "'stump'", ":", "\n", "        ", "time_before_cert", "=", "time", ".", "time", "(", ")", "\n", "min_yf_exact", "=", "model_ova", ".", "fmargin_exact", "(", "X", ",", "y", ",", "eps_eval", ")", "\n", "time_cert", "=", "time", ".", "time", "(", ")", "-", "time_before_cert", "\n", "", "else", ":", "# for trees, yf_exact just gets assigned min_yf_lb", "\n", "        ", "min_yf_exact", "=", "min_yf_lb", "\n", "\n", "", "is_correct", "=", "yf", ">", "0.0", "\n", "is_rob_ub", "=", "min_yf_lb", ">", "0.0", "\n", "is_rob_lb", "=", "min_yf_ub", ">", "0.0", "\n", "is_rob_exact", "=", "min_yf_exact", ">", "0.0", "\n", "\n", "err", "=", "1", "-", "is_correct", ".", "mean", "(", ")", "\n", "adv_err_lb", "=", "1", "-", "is_rob_lb", ".", "mean", "(", ")", "\n", "adv_err", "=", "1", "-", "is_rob_exact", ".", "mean", "(", ")", "\n", "adv_err_ub", "=", "1", "-", "is_rob_ub", ".", "mean", "(", ")", "\n", "\n", "if", "check_bounds", ":", "\n", "        ", "if", "np", ".", "sum", "(", "is_correct", "<", "is_rob_lb", ")", ">", "0", ":", "\n", "            ", "log", ".", "print", "(", "'Number pts violated correct < attack: {} ({})'", ".", "format", "(", "\n", "np", ".", "sum", "(", "is_correct", "<", "is_rob_lb", ")", ",", "np", ".", "where", "(", "is_correct", "<", "is_rob_lb", ")", "[", "0", "]", ")", ")", "\n", "", "if", "np", ".", "sum", "(", "is_rob_lb", "<", "is_rob_exact", ")", ">", "0", ":", "\n", "            ", "log", ".", "print", "(", "'Number pts violated attack < exact: {} ({})'", ".", "format", "(", "\n", "np", ".", "sum", "(", "is_rob_lb", "<", "is_rob_exact", ")", ",", "np", ".", "where", "(", "is_rob_lb", "<", "is_rob_exact", ")", "[", "0", "]", ")", ")", "\n", "", "if", "np", ".", "sum", "(", "is_rob_exact", "<", "is_rob_ub", ")", ">", "0", ":", "\n", "            ", "log", ".", "print", "(", "'Number pts violated exact < rob_ub: {} ({})'", ".", "format", "(", "\n", "np", ".", "sum", "(", "is_rob_exact", "<", "is_rob_ub", ")", ",", "np", ".", "where", "(", "is_rob_exact", "<", "is_rob_ub", ")", "[", "0", "]", ")", ")", "\n", "\n", "", "", "return", "err", ",", "adv_err_lb", ",", "adv_err", ",", "adv_err_ub", ",", "pred", ",", "cert_tw", ",", "time_cert", ",", "deltas", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.train.update_margin": [[60, 75], ["numpy.exp", "ensemble_new.trees[].predict", "ensemble_new.trees[].find_min_yf", "numpy.exp", "ensemble_new.certify_exact", "numpy.exp", "ValueError"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.find_min_yf", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.certify_exact"], ["", "def", "update_margin", "(", "ensemble_new", ",", "X_train", ",", "y_train", ",", "margin", ",", "gamma", ",", "model", ",", "eps_train", ")", ":", "\n", "    ", "if", "model", "in", "[", "'plain'", ",", "'da_uniform'", ",", "'at_cube'", "]", ":", "\n", "        ", "yf", "=", "y_train", "*", "ensemble_new", ".", "trees", "[", "-", "1", "]", ".", "predict", "(", "X_train", ")", "\n", "margin", "+=", "yf", "\n", "gamma", "*=", "np", ".", "exp", "(", "-", "yf", ")", "\n", "", "elif", "model", "==", "'robust_bound'", ":", "\n", "        ", "min_yf_lb", "=", "ensemble_new", ".", "trees", "[", "-", "1", "]", ".", "find_min_yf", "(", "X_train", ",", "y_train", ",", "eps_train", ")", "\n", "margin", "+=", "min_yf_lb", "\n", "gamma", "*=", "np", ".", "exp", "(", "-", "min_yf_lb", ")", "\n", "", "elif", "model", "==", "'robust_exact'", ":", "\n", "        ", "margin", "=", "ensemble_new", ".", "certify_exact", "(", "X_train", ",", "y_train", ",", "eps_train", ")", "\n", "gamma", "=", "np", ".", "exp", "(", "-", "margin", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'wrong model'", ")", "\n", "", "return", "margin", ",", "gamma", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.train.perturb_dataset": [[77, 97], ["numpy.copy", "numpy.random.uniform", "numpy.clip", "attacks.cube_attack", "attacks.cube_attack"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.copy", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.attacks.cube_attack", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.attacks.cube_attack"], ["", "def", "perturb_dataset", "(", "X_train", ",", "y_train", ",", "model_ova", ",", "model", ",", "eps_train", ",", "kantchelian_at", ")", ":", "\n", "    ", "n_iter_at", "=", "10", "\n", "num", "=", "X_train", ".", "shape", "[", "0", "]", "\n", "\n", "X_train_fit", "=", "np", ".", "copy", "(", "X_train", ")", "\n", "# Note: da_uniform in the current form (continuous noise) can lead to a significant slowdown since we have to", "\n", "# check much more thresholds than usually (n instead of 256 for image datasets)", "\n", "if", "model", "==", "'da_uniform'", ":", "# or (model == 'at_cube' and model_ova.models[0].trees == []):", "\n", "        ", "deltas", "=", "np", ".", "random", ".", "uniform", "(", "-", "eps_train", ",", "eps_train", ",", "size", "=", "X_train", ".", "shape", ")", "\n", "X_train_fit", "=", "np", ".", "clip", "(", "X_train", "+", "deltas", ",", "0.0", ",", "1.0", ")", "# preserve the valid data range", "\n", "", "elif", "model", "==", "'at_cube'", ":", "\n", "        ", "if", "kantchelian_at", ":", "\n", "            ", "_", ",", "deltas_at", "=", "cube_attack", "(", "model_ova", ",", "X_train", "[", "num", "//", "2", ":", "]", ",", "y_train", "[", ":", ",", "num", "//", "2", ":", "]", ",", "eps_train", ",", "\n", "n_trials", "=", "n_iter_at", ",", "independent_delta", "=", "True", ")", "\n", "X_train_fit", "[", "num", "//", "2", ":", "]", "=", "X_train", "[", "num", "//", "2", ":", "]", "+", "deltas_at", "\n", "", "else", ":", "\n", "            ", "_", ",", "deltas_at", "=", "cube_attack", "(", "model_ova", ",", "X_train", ",", "y_train", ",", "eps_train", ",", "n_trials", "=", "n_iter_at", ",", "\n", "independent_delta", "=", "True", ")", "\n", "X_train_fit", "=", "X_train", "+", "deltas_at", "\n", "", "", "return", "X_train_fit", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.train.train_iter_binary_clsf": [[99, 132], ["ensemble_prev.copy", "numpy.mean", "train.update_margin", "numpy.mean", "numpy.exp", "numpy.copy", "numpy.copy", "ensemble_prev.fit_stumps_over_coords", "ensemble_prev.copy.add_weak_learner", "ensemble_prev.add_weak_learner", "print", "ensemble_prev.predict", "ensemble_prev.fit_tree", "ensemble_prev.copy.add_weak_learner", "print", "ensemble_prev.copy.prune_last_tree", "print", "ValueError", "tree_ensemble.Tree", "ensemble_prev.copy.trees[].get_depth", "ensemble_prev.copy.trees[].get_n_nodes"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.copy", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.train.update_margin", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.copy", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.copy", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.fit_stumps_over_coords", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.add_weak_learner", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.add_weak_learner", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.TreeEnsemble.fit_tree", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.add_weak_learner", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.TreeEnsemble.prune_last_tree", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_depth", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.get_n_nodes"], ["", "def", "train_iter_binary_clsf", "(", "ensemble_prev", ",", "X_train", ",", "y_train", ",", "gamma", ",", "margin", ",", "model", ",", "weak_learner_type", ",", "eps_train", ",", "i_clsf", ")", ":", "\n", "    ", "if", "model", "in", "[", "'da_uniform'", ",", "'at_cube'", "]", ":", "# we recalculate gammas if the training set changes every iteration", "\n", "        ", "margin", "=", "y_train", "*", "ensemble_prev", ".", "predict", "(", "X_train", ")", "\n", "gamma", "=", "np", ".", "exp", "(", "-", "margin", ")", "\n", "", "ensemble_new", "=", "ensemble_prev", ".", "copy", "(", ")", "\n", "gamma_prev", ",", "margin_prev", "=", "np", ".", "copy", "(", "gamma", ")", ",", "np", ".", "copy", "(", "margin", ")", "\n", "loss_prev", "=", "np", ".", "mean", "(", "gamma_prev", ")", "\n", "\n", "if", "weak_learner_type", "==", "'stump'", ":", "\n", "        ", "weak_learner", "=", "ensemble_prev", ".", "fit_stumps_over_coords", "(", "X_train", ",", "y_train", ",", "gamma", ",", "model", ",", "eps_train", ")", "\n", "ensemble_new", ".", "add_weak_learner", "(", "weak_learner", ")", "\n", "tree_depth", ",", "tree_n_nodes", "=", "1", ",", "1", "\n", "", "elif", "weak_learner_type", "==", "'tree'", ":", "\n", "# depth=1 means that we start counting from 1 (i.e. decision stumps are counted as trees of depth=1)", "\n", "        ", "weak_learner", "=", "ensemble_prev", ".", "fit_tree", "(", "X_train", ",", "y_train", ",", "gamma", ",", "model", ",", "eps_train", ",", "depth", "=", "1", ")", "\n", "# add a new weak learner to a new ensemble without modifying yet the main ensemble", "\n", "ensemble_new", ".", "add_weak_learner", "(", "weak_learner", ")", "\n", "print", "(", "'Starting pruning for class {}...'", ".", "format", "(", "i_clsf", ")", ")", "\n", "ensemble_new", ".", "prune_last_tree", "(", "X_train", ",", "y_train", ",", "margin", ",", "eps_train", ",", "model", ")", "\n", "print", "(", "'Finished pruning for class {}...'", ".", "format", "(", "i_clsf", ")", ")", "\n", "tree_depth", ",", "tree_n_nodes", "=", "ensemble_new", ".", "trees", "[", "-", "1", "]", ".", "get_depth", "(", ")", ",", "ensemble_new", ".", "trees", "[", "-", "1", "]", ".", "get_n_nodes", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'wrong weak learner'", ")", "\n", "\n", "", "margin", ",", "gamma", "=", "update_margin", "(", "ensemble_new", ",", "X_train", ",", "y_train", ",", "margin", ",", "gamma", ",", "model", ",", "eps_train", ")", "\n", "\n", "loss", "=", "np", ".", "mean", "(", "gamma", ")", "\n", "if", "model", "not", "in", "[", "'da_uniform'", ",", "'at_cube'", "]", "and", "loss", ">=", "loss_prev", ":", "# we return the new ensemble only if it reduces the loss", "\n", "        ", "ensemble_prev", ".", "add_weak_learner", "(", "Tree", "(", ")", ")", "\n", "print", "(", "'Added empty weak learner (loss_new={:.4} >= loss_prev={:.4})'", ".", "format", "(", "loss", ",", "loss_prev", ")", ")", "\n", "return", "ensemble_prev", ",", "gamma_prev", ",", "margin_prev", ",", "0", ",", "0", "\n", "", "else", ":", "# to make `# weak learners` == `n_iter`, just add a constant stump/tree", "\n", "        ", "return", "ensemble_new", ",", "gamma", ",", "margin", ",", "tree_depth", ",", "tree_n_nodes", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.train.robust_boost": [[134, 224], ["len", "min", "time.time", "numpy.zeros", "numpy.ones", "range", "log.print", "numpy.vstack", "numpy.hstack", "numpy.zeros_like", "numpy.zeros_like", "numpy.zeros_like", "numpy.zeros_like", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "multiprocessing.Pool", "range", "print", "numpy.mean", "train.eval_metrics", "train.eval_metrics", "train.eval_metrics", "log.print", "metrics.append", "log.print", "log.print", "numpy.zeros", "numpy.zeros", "train.perturb_dataset", "range", "numpy.mean", "numpy.mean", "log.print", "time.time", "model_ova.save", "numpy.savetxt", "procs.append", "train.train_iter_binary_clsf", "procs[].get", "multiprocessing.Pool.apply_async", "time.time", "time.time"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.train.eval_metrics", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.train.eval_metrics", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.train.eval_metrics", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.train.perturb_dataset", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.save", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.train.train_iter_binary_clsf"], ["", "", "def", "robust_boost", "(", "model_ova", ",", "X_train", ",", "y_train", ",", "X_valid", ",", "y_valid", ",", "X_test", ",", "y_test", ",", "weak_learner_type", ",", "n_trees", ",", "\n", "eps_train", ",", "eps_eval", ",", "n_trials_attack", ",", "cb_weights", ",", "model", ",", "log", ",", "model_path", ",", "metrics_path", ",", "debug", ")", ":", "\n", "    ", "n_clsf", "=", "len", "(", "model_ova", ".", "models", ")", "\n", "parallel", "=", "True", "if", "n_clsf", ">", "1", "else", "False", "\n", "# If AT is applied, then it's done as in Kantchelian et al (i.e. 50% clean + 50% adversarial) => works better", "\n", "kantchelian_at", "=", "True", "\n", "if", "model", "==", "'at_cube'", "and", "kantchelian_at", ":", "\n", "        ", "X_train", "=", "np", ".", "vstack", "(", "[", "X_train", ",", "X_train", "]", ")", "\n", "y_train", "=", "np", ".", "hstack", "(", "[", "y_train", ",", "y_train", "]", ")", "\n", "\n", "", "n_eval_train", "=", "min", "(", "X_train", ".", "shape", "[", "0", "]", ",", "5000", ")", "# number of training examples to use for evaluation (not too critical, but helps for speed-up)", "\n", "time_start", "=", "time", ".", "time", "(", ")", "\n", "n_train", ",", "n_valid", ",", "n_test", "=", "X_train", ".", "shape", "[", "0", "]", ",", "X_valid", ".", "shape", "[", "0", "]", ",", "X_test", ".", "shape", "[", "0", "]", "\n", "time_cert_train", ",", "time_cert_valid", ",", "time_cert_test", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "deltas_at", ",", "deltas_train", "=", "np", ".", "zeros_like", "(", "X_train", ")", ",", "np", ".", "zeros_like", "(", "X_train", ")", "\n", "deltas_valid", ",", "deltas_test", "=", "np", ".", "zeros_like", "(", "X_valid", ")", ",", "np", ".", "zeros_like", "(", "X_test", ")", "\n", "\n", "metrics", "=", "[", "]", "# all metrics are collected in this list", "\n", "margin", "=", "np", ".", "zeros", "(", "[", "n_clsf", ",", "n_train", "]", ")", "\n", "pred_train", ",", "pred_valid", ",", "pred_test", "=", "np", ".", "zeros", "(", "[", "n_clsf", ",", "n_eval_train", "]", ")", ",", "np", ".", "zeros", "(", "[", "n_clsf", ",", "n_valid", "]", ")", ",", "np", ".", "zeros", "(", "[", "n_clsf", ",", "n_test", "]", ")", "\n", "cert_tw_train", ",", "cert_tw_valid", ",", "cert_tw_test", "=", "np", ".", "zeros", "(", "[", "n_clsf", ",", "n_eval_train", "]", ")", ",", "np", ".", "zeros", "(", "[", "n_clsf", ",", "n_valid", "]", ")", ",", "np", ".", "zeros", "(", "[", "n_clsf", ",", "n_test", "]", ")", "\n", "gamma", "=", "np", ".", "ones", "(", "[", "n_clsf", ",", "n_train", "]", ")", "# note: no normalization since it is unnecessary and ambiguous for robust training", "\n", "if", "cb_weights", ":", "# class-balancing weights", "\n", "        ", "for", "i_clsf", "in", "range", "(", "n_clsf", ")", ":", "\n", "            ", "gamma", "[", "i_clsf", "]", "[", "y_train", "[", "i_clsf", "]", "==", "1", "]", "*=", "(", "y_train", "[", "i_clsf", "]", "==", "-", "1", ")", ".", "sum", "(", ")", "/", "(", "y_train", "[", "i_clsf", "]", "==", "1", ")", ".", "sum", "(", ")", "\n", "\n", "", "", "X_train_fit", "=", "X_train", "\n", "if", "parallel", ":", "\n", "        ", "proc_pool", "=", "Pool", "(", "n_clsf", ")", "\n", "", "for", "it", "in", "range", "(", "1", ",", "n_trees", "+", "1", ")", ":", "\n", "        ", "tree_depths", ",", "tree_ns_nodes", "=", "np", ".", "zeros", "(", "n_clsf", ")", ",", "np", ".", "zeros", "(", "n_clsf", ")", "\n", "procs", "=", "[", "]", "\n", "\n", "# # changing the dataset at every iteration doesn't seem to work very well with boosting", "\n", "# X_train_fit = data.data_augment(X_train, dataset) if data_augm and dataset in data.datasets_img_shapes else X_train", "\n", "X_train_fit", "=", "perturb_dataset", "(", "X_train_fit", ",", "y_train", ",", "model_ova", ",", "model", ",", "eps_train", ",", "kantchelian_at", ")", "if", "model", "in", "[", "'da_uniform'", ",", "'at_cube'", "]", "else", "X_train", "\n", "for", "i_clsf", "in", "range", "(", "n_clsf", ")", ":", "# start all the processes in parallel", "\n", "            ", "ensemble", "=", "model_ova", ".", "models", "[", "i_clsf", "]", "\n", "if", "parallel", ":", "\n", "                ", "train_iter_args", "=", "(", "ensemble", ",", "X_train_fit", ",", "y_train", "[", "i_clsf", "]", ",", "gamma", "[", "i_clsf", "]", ",", "margin", "[", "i_clsf", "]", ",", "model", ",", "\n", "weak_learner_type", ",", "eps_train", ",", "i_clsf", ")", "\n", "procs", ".", "append", "(", "proc_pool", ".", "apply_async", "(", "train_iter_binary_clsf", ",", "args", "=", "train_iter_args", ")", ")", "\n", "", "else", ":", "\n", "                ", "model_ova", ".", "models", "[", "i_clsf", "]", ",", "gamma", "[", "i_clsf", "]", ",", "margin", "[", "i_clsf", "]", ",", "tree_depths", "[", "i_clsf", "]", ",", "tree_ns_nodes", "[", "i_clsf", "]", "=", "train_iter_binary_clsf", "(", "\n", "ensemble", ",", "X_train_fit", ",", "y_train", "[", "i_clsf", "]", ",", "gamma", "[", "i_clsf", "]", ",", "margin", "[", "i_clsf", "]", ",", "model", ",", "weak_learner_type", ",", "eps_train", ",", "i_clsf", ")", "\n", "", "", "if", "parallel", ":", "\n", "            ", "for", "i_clsf", "in", "range", "(", "n_clsf", ")", ":", "# wait until the results are done and fetch them", "\n", "                ", "model_ova", ".", "models", "[", "i_clsf", "]", ",", "gamma", "[", "i_clsf", "]", ",", "margin", "[", "i_clsf", "]", ",", "tree_depths", "[", "i_clsf", "]", ",", "tree_ns_nodes", "[", "i_clsf", "]", "=", "procs", "[", "i_clsf", "]", ".", "get", "(", ")", "\n", "\n", "# Evaluations: currently designed in a way that we neeed to do it *every* iteration", "\n", "", "", "print", "(", "'starting evaluation ({:.2f}s)'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "time_start", ")", ")", "\n", "tree_depth", ",", "tree_n_nodes", "=", "np", ".", "mean", "(", "tree_depths", ")", ",", "np", ".", "mean", "(", "tree_ns_nodes", ")", "\n", "train_loss", "=", "np", ".", "mean", "(", "gamma", ")", "# mean over classes (axis=0) and examples (axis=1)", "\n", "if", "it", ">", "1", "and", "train_loss", ">", "metrics", "[", "-", "1", "]", "[", "7", "]", "+", "1e-7", ":", "\n", "            ", "log", ".", "print", "(", "'The train loss increases: prev {:.5f} now {:.5f}'", ".", "format", "(", "metrics", "[", "-", "1", "]", "[", "7", "]", ",", "train_loss", ")", ")", "\n", "\n", "", "train_err", ",", "train_adv_err_lb", ",", "train_adv_err", ",", "train_adv_err_ub", ",", "pred_train", ",", "cert_tw_train", ",", "time_cert_train", ",", "deltas_train", "=", "eval_metrics", "(", "\n", "model_ova", ",", "X_train", "[", ":", "n_eval_train", "]", ",", "y_train", "[", ":", ",", ":", "n_eval_train", "]", ",", "pred_train", ",", "cert_tw_train", ",", "time_cert_train", ",", "\n", "deltas_train", "[", ":", "n_eval_train", "]", ",", "weak_learner_type", ",", "eps_eval", ",", "log", ",", "n_trials_attack", "=", "0", ",", "check_bounds", "=", "False", ")", "\n", "valid_err", ",", "valid_adv_err_lb", ",", "valid_adv_err", ",", "valid_adv_err_ub", ",", "pred_valid", ",", "cert_tw_valid", ",", "time_cert_valid", ",", "deltas_valid", "=", "eval_metrics", "(", "\n", "model_ova", ",", "X_valid", ",", "y_valid", ",", "pred_valid", ",", "cert_tw_valid", ",", "time_cert_valid", ",", "deltas_valid", ",", "weak_learner_type", ",", "eps_eval", ",", "log", ",", "n_trials_attack", ")", "\n", "test_err", ",", "test_adv_err_lb", ",", "test_adv_err", ",", "test_adv_err_ub", ",", "pred_test", ",", "cert_tw_test", ",", "time_cert_test", ",", "deltas_test", "=", "eval_metrics", "(", "\n", "model_ova", ",", "X_test", ",", "y_test", ",", "pred_test", ",", "cert_tw_test", ",", "time_cert_test", ",", "deltas_test", ",", "weak_learner_type", ",", "eps_eval", ",", "log", ",", "n_trials_attack", ")", "\n", "\n", "train_str", "=", "'[train] err {:.2%} adv_err {:.2%} loss {:.5f}'", ".", "format", "(", "\n", "train_err", ",", "train_adv_err", ",", "train_loss", ")", "\n", "valid_str", "=", "'[valid] err {:.2%} adv_err {:.2%}'", ".", "format", "(", "valid_err", ",", "valid_adv_err", ")", "\n", "str_adv_err", "=", "'adv_err {:.2%} '", ".", "format", "(", "test_adv_err", ")", "if", "weak_learner_type", "==", "'stump'", "else", "''", "\n", "test_str", "=", "'[test] err {:.2%} adv_err_lb {:.2%} {}adv_err_ub {:.2%}'", ".", "format", "(", "\n", "test_err", ",", "test_adv_err_lb", ",", "str_adv_err", ",", "test_adv_err_ub", ")", "\n", "\n", "if", "weak_learner_type", "==", "'tree'", ":", "\n", "            ", "tree_info_str", "=", "'[tree] depth {:.2f} nodes {:.2f}'", ".", "format", "(", "tree_depth", ",", "tree_n_nodes", ")", "\n", "", "else", ":", "\n", "            ", "tree_info_str", "=", "''", "\n", "", "time_elapsed", "=", "time", ".", "time", "(", ")", "-", "time_start", "\n", "\n", "log", ".", "print", "(", "'iter: {} {} | {} | {} | {} ({:.3f}s, {:.3f}s)'", ".", "format", "(", "it", ",", "test_str", ",", "valid_str", ",", "train_str", ",", "tree_info_str", ",", "time_elapsed", ",", "time_cert_test", ")", ")", "\n", "metrics", ".", "append", "(", "[", "it", ",", "test_err", ",", "test_adv_err_lb", ",", "test_adv_err", ",", "test_adv_err_ub", ",", "train_err", ",", "train_adv_err", ",", "\n", "train_loss", ",", "valid_err", ",", "valid_adv_err_lb", ",", "valid_adv_err", ",", "valid_adv_err_ub", ",", "time_elapsed", ",", "time_cert_test", ",", "\n", "tree_depth", ",", "tree_n_nodes", "]", ")", "\n", "\n", "if", "not", "debug", "and", "(", "it", "%", "5", "==", "0", "or", "it", "==", "n_trees", ")", "and", "metrics_path", "!=", "''", ":", "\n", "            ", "model_ova", ".", "save", "(", "model_path", ")", "\n", "np", ".", "savetxt", "(", "metrics_path", ",", "metrics", ")", "\n", "\n", "", "", "log", ".", "print", "(", "'(done in {:.2f} min)'", ".", "format", "(", "(", "time", ".", "time", "(", ")", "-", "time_start", ")", "/", "60", ")", ")", "\n", "if", "not", "debug", ":", "\n", "        ", "log", ".", "print", "(", "'Model path: {}.npy'", ".", "format", "(", "model_path", ")", ")", "\n", "log", ".", "print", "(", "'Metrics path: {}'", ".", "format", "(", "metrics_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.train.main": [[226, 321], ["numpy.random.seed", "numpy.set_printoptions", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "data.split_train_validation", "data.transform_labels_one_vs_all", "utils.Logger", "utils.Logger.print", "range", "classifiers.OneVsAllClassifier", "train.robust_boost", "data.convert_to_float32", "data.convert_to_float32", "int", "data.extend_dataset", "numpy.tile", "str", "ensembles.append", "ValueError", "np.tile.max", "datetime.datetime.now", "stump_ensemble.StumpEnsemble", "tree_ensemble.TreeEnsemble", "ValueError"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.split_train_validation", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.transform_labels_one_vs_all", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.train.robust_boost", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.convert_to_float32", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.convert_to_float32", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.extend_dataset"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "1", ")", "\n", "np", ".", "set_printoptions", "(", "precision", "=", "10", ")", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Define hyperparameters.'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "type", "=", "str", ",", "default", "=", "'mnist'", ",", "\n", "help", "=", "'breast_cancer, diabetes, cod_rna, mnist_1_5, mnist_2_6, fmnist_sandal_sneaker, gts_30_70,'", "\n", "' gts_100_roadworks'", ")", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "'plain'", ",", "\n", "help", "=", "'plain, da_uniform, at_cube, robust_exact, robust_bound.'", ")", "\n", "parser", ".", "add_argument", "(", "'--weak_learner'", ",", "type", "=", "str", ",", "default", "=", "'tree'", ",", "help", "=", "'stump or tree'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_depth'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'Depth of trees (only used when weak_learner==tree).'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_weight'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'The maximum leaf weight.'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_bins'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'By default we check all thresholds.'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "'Shrinkage parameter (aka learning rate).'", ")", "\n", "parser", ".", "add_argument", "(", "'--eps'", ",", "type", "=", "float", ",", "default", "=", "-", "1", ",", "help", "=", "'Linf epsilon. -1 means to use the default epsilons.'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_train'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'Number of training points to take.'", ")", "\n", "parser", ".", "add_argument", "(", "'--debug'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Debugging mode: not many samples for the attack.'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "weak_learner", "==", "'stump'", "or", "(", "args", ".", "weak_learner", "==", "'tree'", "and", "args", ".", "max_depth", "==", "1", ")", ":", "\n", "        ", "n_iter", "=", "300", "\n", "", "elif", "args", ".", "weak_learner", "==", "'tree'", ":", "\n", "        ", "depth_iters_map", "=", "{", "2", ":", "300", ",", "4", ":", "150", ",", "6", ":", "100", ",", "8", ":", "75", "}", "\n", "if", "args", ".", "max_depth", "in", "depth_iters_map", ":", "\n", "            ", "n_iter", "=", "depth_iters_map", "[", "args", ".", "max_depth", "]", "\n", "", "else", ":", "\n", "            ", "n_iter", "=", "300", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'wrong weak learner'", ")", "\n", "\n", "# max value of the leaf weights; has an important regularization effect similar to the learning rate", "\n", "", "max_weight", "=", "args", ".", "max_weight", "\n", "# to prevent extreme overfitting to a few points", "\n", "min_samples_split", "=", "10", "if", "args", ".", "dataset", "not", "in", "[", "'mnist'", ",", "'fmnist'", ",", "'cifar10'", "]", "else", "200", "\n", "min_samples_leaf", "=", "5", "\n", "n_trials_attack", "=", "20", "if", "args", ".", "dataset", "not", "in", "[", "'mnist'", ",", "'fmnist'", ",", "'cifar10'", "]", "else", "10", "\n", "n_trials_attack", "=", "n_trials_attack", "if", "args", ".", "weak_learner", "==", "'tree'", "else", "1", "# 1 iter is more of a sanity check", "\n", "frac_valid", "=", "0.2", "if", "args", ".", "dataset", "not", "in", "[", "'mnist'", ",", "'fmnist'", ",", "'cifar10'", "]", "else", "0.0", "\n", "extend_dataset", "=", "True", "if", "args", ".", "dataset", "in", "[", "'mnist'", ",", "'fmnist'", ",", "'cifar10'", "]", "else", "False", "\n", "\n", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "eps_dataset", "=", "data", ".", "all_datasets_dict", "[", "args", ".", "dataset", "]", "(", ")", "\n", "X_train", ",", "X_test", "=", "data", ".", "convert_to_float32", "(", "X_train", ")", ",", "data", ".", "convert_to_float32", "(", "X_test", ")", "\n", "X_train", ",", "y_train", ",", "X_valid", ",", "y_valid", "=", "data", ".", "split_train_validation", "(", "X_train", ",", "y_train", ",", "frac_valid", ",", "shuffle", "=", "True", ")", "\n", "if", "args", ".", "n_train", "!=", "-", "1", ":", "\n", "        ", "X_train", ",", "y_train", "=", "X_train", "[", ":", "args", ".", "n_train", "]", ",", "y_train", "[", ":", "args", ".", "n_train", "]", "\n", "\n", "", "n_cls", "=", "int", "(", "y_train", ".", "max", "(", ")", ")", "+", "1", "\n", "cb_weights", "=", "True", "if", "n_cls", ">", "2", "else", "False", "# helps to convergence speed and URTE (especially, on MNIST)", "\n", "y_train", ",", "y_valid", ",", "y_test", "=", "data", ".", "transform_labels_one_vs_all", "(", "y_train", ",", "y_valid", ",", "y_test", ")", "\n", "\n", "if", "extend_dataset", ":", "\n", "        ", "X_train", "=", "data", ".", "extend_dataset", "(", "X_train", ",", "args", ".", "dataset", ")", "\n", "y_train", "=", "np", ".", "tile", "(", "y_train", ",", "[", "1", ",", "X_train", ".", "shape", "[", "0", "]", "//", "y_train", ".", "shape", "[", "1", "]", "]", ")", "\n", "\n", "", "n_trials_coord", "=", "X_train", ".", "shape", "[", "1", "]", "# we check all coordinates for every split", "\n", "\n", "if", "args", ".", "eps", "==", "-", "1", ":", "# then use the default one if not specified from cmd", "\n", "        ", "eps_train", "=", "eps_eval", "=", "eps_dataset", "if", "args", ".", "model", "!=", "'plain'", "else", "0.0", "# not strictly needed", "\n", "", "else", ":", "\n", "        ", "eps_train", "=", "eps_eval", "=", "args", ".", "eps", "\n", "\n", "", "cur_timestamp", "=", "str", "(", "datetime", ".", "now", "(", ")", ")", "[", ":", "-", "7", "]", "\n", "hps_str_full", "=", "'dataset={} weak_learner={} model={} n_train={} n_iter={} n_trials_coord={} eps={:.3f} min_samples_split={} '", "'min_samples_leaf={} max_depth={} max_weight={} lr={} n_trials_attack={} cb_weights={} max_weight={} n_bins={} '", "'expand_train_set={}'", ".", "format", "(", "\n", "args", ".", "dataset", ",", "args", ".", "weak_learner", ",", "args", ".", "model", ",", "args", ".", "n_train", ",", "n_iter", ",", "n_trials_coord", ",", "eps_train", ",", "min_samples_split", ",", "\n", "min_samples_leaf", ",", "args", ".", "max_depth", ",", "max_weight", ",", "args", ".", "lr", ",", "n_trials_attack", ",", "cb_weights", ",", "max_weight", ",", "args", ".", "n_bins", ",", "extend_dataset", ")", "\n", "hps_str_short", "=", "'dataset={} weak_learner={} model={} n_train={} n_trials_coord={} eps={:.3f} max_depth={} max_weight={} lr={}'", ".", "format", "(", "\n", "args", ".", "dataset", ",", "args", ".", "weak_learner", ",", "args", ".", "model", ",", "args", ".", "n_train", ",", "n_trials_coord", ",", "eps_train", ",", "args", ".", "max_depth", ",", "max_weight", ",", "args", ".", "lr", ")", "\n", "\n", "exp_folder", "=", "'exps_test'", "\n", "log_path", "=", "'{}/{} {}.log'", ".", "format", "(", "exp_folder", ",", "cur_timestamp", ",", "hps_str_short", ")", "\n", "model_path", "=", "'{}/{} {}.model'", ".", "format", "(", "exp_folder", ",", "cur_timestamp", ",", "hps_str_short", ")", "\n", "metrics_path", "=", "'{}/{} {}.metrics'", ".", "format", "(", "exp_folder", ",", "cur_timestamp", ",", "hps_str_short", ")", "\n", "\n", "log", "=", "Logger", "(", "log_path", ")", "\n", "log", ".", "print", "(", "'Boosting started: {} {}'", ".", "format", "(", "cur_timestamp", ",", "hps_str_full", ")", ")", "\n", "\n", "ensembles", "=", "[", "]", "\n", "n_classifiers", "=", "n_cls", "if", "n_cls", ">", "2", "else", "1", "\n", "for", "i_clsf", "in", "range", "(", "n_classifiers", ")", ":", "\n", "        ", "if", "args", ".", "weak_learner", "==", "'stump'", ":", "\n", "            ", "ensemble", "=", "StumpEnsemble", "(", "args", ".", "weak_learner", ",", "n_trials_coord", ",", "args", ".", "lr", ",", "i_clsf", ",", "args", ".", "n_bins", ",", "max_weight", ")", "\n", "", "elif", "args", ".", "weak_learner", "==", "'tree'", ":", "\n", "            ", "ensemble", "=", "TreeEnsemble", "(", "args", ".", "weak_learner", ",", "n_trials_coord", ",", "args", ".", "lr", ",", "min_samples_split", ",", "min_samples_leaf", ",", "i_clsf", ",", "\n", "args", ".", "max_depth", ",", "gamma_hp", "=", "0.0", ",", "n_bins", "=", "args", ".", "n_bins", ",", "max_weight", "=", "max_weight", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'wrong weak learner'", ")", "\n", "", "ensembles", ".", "append", "(", "ensemble", ")", "\n", "", "model_ova", "=", "OneVsAllClassifier", "(", "ensembles", ")", "\n", "\n", "robust_boost", "(", "model_ova", ",", "X_train", ",", "y_train", ",", "X_valid", ",", "y_valid", ",", "X_test", ",", "y_test", ",", "args", ".", "weak_learner", ",", "n_iter", ",", "eps_train", ",", "\n", "eps_eval", ",", "n_trials_attack", ",", "cb_weights", ",", "args", ".", "model", ",", "log", ",", "model_path", ",", "metrics_path", ",", "\n", "args", ".", "debug", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.split_train_test": [[10, 23], ["int"], "function", ["None"], ["def", "split_train_test", "(", "X_all", ",", "y_all", ",", "frac_train", ")", ":", "\n", "    ", "\"\"\"\n    The first X% of X_all, y_all become the training set, the rest (1-X)% become the test set.\n    Note that this assumes that the samples are already shuffled or if not (e.g. if we were to split MNIST) that\n    this behavior is intended.\n    \"\"\"", "\n", "num_total", "=", "X_all", ".", "shape", "[", "0", "]", "\n", "num_train", "=", "int", "(", "frac_train", "*", "num_total", ")", "\n", "\n", "X_train", ",", "y_train", "=", "X_all", "[", ":", "num_train", "]", ",", "y_all", "[", ":", "num_train", "]", "\n", "X_test", ",", "y_test", "=", "X_all", "[", "num_train", ":", "]", ",", "y_all", "[", "num_train", ":", "]", "\n", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.normalize_per_feature_0_1": [[25, 34], ["X_train.max", "X_train.min"], "function", ["None"], ["", "def", "normalize_per_feature_0_1", "(", "X_train", ",", "X_test", ")", ":", "\n", "    ", "\"\"\"\n    We are not allowed to touch the test data, thus we do the normalization just based on the training data.\n    \"\"\"", "\n", "X_train_max", "=", "X_train", ".", "max", "(", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "X_train_min", "=", "X_train", ".", "min", "(", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "X_train", "=", "(", "X_train", "-", "X_train_min", ")", "/", "(", "X_train_max", "-", "X_train_min", ")", "\n", "X_test", "=", "(", "X_test", "-", "X_train_min", ")", "/", "(", "X_train_max", "-", "X_train_min", ")", "\n", "return", "X_train", ",", "X_test", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.split_train_validation": [[36, 56], ["int", "numpy.random.permutation", "numpy.arange", "numpy.unique", "int", "idx_valid.extend", "idx_train.extend", "numpy.array", "numpy.array", "numpy.where", "len", "list", "list"], "function", ["None"], ["", "def", "split_train_validation", "(", "X_train_orig", ",", "y_train_orig", ",", "frac_valid", ",", "shuffle", "=", "True", ")", ":", "\n", "    ", "num_total", "=", "X_train_orig", ".", "shape", "[", "0", "]", "\n", "n_valid", "=", "int", "(", "frac_valid", "*", "num_total", ")", "\n", "idx", "=", "np", ".", "random", ".", "permutation", "(", "num_total", ")", "if", "shuffle", "else", "np", ".", "arange", "(", "num_total", ")", "\n", "if", "shuffle", ":", "\n", "        ", "X_valid", ",", "y_valid", "=", "X_train_orig", "[", "idx", "]", "[", ":", "n_valid", "]", ",", "y_train_orig", "[", "idx", "]", "[", ":", "n_valid", "]", "\n", "X_train", ",", "y_train", "=", "X_train_orig", "[", "idx", "]", "[", "n_valid", ":", "]", ",", "y_train_orig", "[", "idx", "]", "[", "n_valid", ":", "]", "\n", "", "else", ":", "\n", "# If no shuffle, then one has to ensure that the classes are balanced", "\n", "        ", "idx_valid", ",", "idx_train", "=", "[", "]", ",", "[", "]", "\n", "for", "cls", "in", "np", ".", "unique", "(", "y_train_orig", ")", ":", "\n", "            ", "indices_cls", "=", "np", ".", "where", "(", "y_train_orig", "==", "cls", ")", "[", "0", "]", "\n", "proportion_cls", "=", "len", "(", "indices_cls", ")", "/", "num_total", "\n", "n_class_balanced_valid", "=", "int", "(", "proportion_cls", "*", "n_valid", ")", "\n", "idx_valid", ".", "extend", "(", "list", "(", "indices_cls", "[", ":", "n_class_balanced_valid", "]", ")", ")", "\n", "idx_train", ".", "extend", "(", "list", "(", "indices_cls", "[", "n_class_balanced_valid", ":", "]", ")", ")", "\n", "", "idx_valid", ",", "idx_train", "=", "np", ".", "array", "(", "idx_valid", ")", ",", "np", ".", "array", "(", "idx_train", ")", "\n", "X_valid", ",", "y_valid", "=", "X_train_orig", "[", "idx_valid", "]", ",", "y_train_orig", "[", "idx_valid", "]", "\n", "X_train", ",", "y_train", "=", "X_train_orig", "[", "idx_train", "]", ",", "y_train_orig", "[", "idx_train", "]", "\n", "", "return", "X_train", ",", "y_train", ",", "X_valid", ",", "y_valid", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.binary_from_multiclass": [[58, 70], ["numpy.array"], "function", ["None"], ["", "def", "binary_from_multiclass", "(", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "classes", ")", ":", "\n", "    ", "classes", "=", "np", ".", "array", "(", "classes", ")", "# for indexing only arrays work, not lists", "\n", "\n", "idx_train1", ",", "idx_train2", "=", "y_train", "==", "classes", "[", "0", "]", ",", "y_train", "==", "classes", "[", "1", "]", "\n", "idx_test1", ",", "idx_test2", "=", "y_test", "==", "classes", "[", "0", "]", ",", "y_test", "==", "classes", "[", "1", "]", "\n", "X_train", ",", "X_test", "=", "X_train", "[", "idx_train1", "+", "idx_train2", "]", ",", "X_test", "[", "idx_test1", "+", "idx_test2", "]", "\n", "\n", "y_train", "=", "idx_train1", "*", "1", "+", "idx_train2", "*", "-", "1", "\n", "y_test", "=", "idx_test1", "*", "1", "+", "idx_test2", "*", "-", "1", "\n", "y_train", ",", "y_test", "=", "y_train", "[", "idx_train1", "+", "idx_train2", "]", ",", "y_test", "[", "idx_test1", "+", "idx_test2", "]", "\n", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.transform_labels_one_vs_all": [[72, 87], ["numpy.unique", "len", "range", "int", "numpy.zeros", "numpy.zeros", "numpy.zeros", "y_train_orig.max"], "function", ["None"], ["", "def", "transform_labels_one_vs_all", "(", "y_train_orig", ",", "y_valid_orig", ",", "y_test_orig", ")", ":", "\n", "    ", "n_cls", "=", "int", "(", "y_train_orig", ".", "max", "(", ")", ")", "+", "1", "\n", "if", "n_cls", "==", "2", ":", "\n", "        ", "return", "y_train_orig", "[", "None", ",", ":", "]", ",", "y_valid_orig", "[", "None", ",", ":", "]", ",", "y_test_orig", "[", "None", ",", ":", "]", "\n", "\n", "", "labels", "=", "np", ".", "unique", "(", "y_train_orig", ")", "\n", "n_cls", "=", "len", "(", "labels", ")", "\n", "n_train", ",", "n_valid", ",", "n_test", "=", "y_train_orig", ".", "shape", "[", "0", "]", ",", "y_valid_orig", ".", "shape", "[", "0", "]", ",", "y_test_orig", ".", "shape", "[", "0", "]", "\n", "y_train", ",", "y_valid", ",", "y_test", "=", "np", ".", "zeros", "(", "[", "n_cls", ",", "n_train", "]", ")", ",", "np", ".", "zeros", "(", "[", "n_cls", ",", "n_valid", "]", ")", ",", "np", ".", "zeros", "(", "[", "n_cls", ",", "n_test", "]", ")", "\n", "for", "i_cls", "in", "range", "(", "n_cls", ")", ":", "\n", "# convert from False/True to -1/1 compatible with One-vs-All formulation", "\n", "        ", "y_train", "[", "i_cls", "]", "=", "2", "*", "(", "y_train_orig", "==", "i_cls", ")", "-", "1", "\n", "y_valid", "[", "i_cls", "]", "=", "2", "*", "(", "y_valid_orig", "==", "i_cls", ")", "-", "1", "\n", "y_test", "[", "i_cls", "]", "=", "2", "*", "(", "y_test_orig", "==", "i_cls", ")", "-", "1", "\n", "", "return", "y_train", ",", "y_valid", ",", "y_test", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.toy_2d_stumps": [[89, 100], ["numpy.array", "numpy.array"], "function", ["None"], ["", "def", "toy_2d_stumps", "(", ")", ":", "\n", "    ", "X", "=", "np", ".", "array", "(", "[", "[", "0.38", ",", "0.75", "]", ",", "[", "0.50", ",", "0.93", "]", ",", "[", "0.05", ",", "0.70", "]", ",", "[", "0.30", ",", "0.90", "]", ",", "[", "0.15", ",", "0.80", "]", ",", "\n", "# [0.15, 1.0], [0.125, 0.75], [0.1, 0.85], [0.045, 0.22], [0.725, 0.955],  # small margin", "\n", "# [0.15, 1.0], [0.125, 0.75], [0.1, 0.85], [0.075, 0.2], [0.775, 0.925],  # small margin", "\n", "[", "0.15", ",", "1.0", "]", ",", "[", "0.125", ",", "0.5", "]", ",", "[", "0.1", ",", "0.85", "]", ",", "[", "0.02", ",", "0.25", "]", ",", "[", "0.775", ",", "0.975", "]", ",", "\n", "[", "0.05", ",", "0.05", "]", ",", "[", "0.2", ",", "0.1", "]", ",", "[", "0.4", ",", "0.075", "]", ",", "[", "0.6", ",", "0.22", "]", ",", "[", "0.8", ",", "0.1", "]", ",", "\n", "[", "0.95", ",", "0.05", "]", ",", "[", "0.9", ",", "0.2", "]", ",", "[", "0.925", ",", "0.4", "]", ",", "[", "0.79", ",", "0.6", "]", ",", "[", "0.81", ",", "0.8", "]", "]", ")", "\n", "y", "=", "np", ".", "array", "(", "[", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "\n", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "eps_dataset", "=", "0.075", "\n", "return", "X", ",", "y", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.toy_2d_trees": [[102, 111], ["numpy.array", "numpy.array"], "function", ["None"], ["", "def", "toy_2d_trees", "(", ")", ":", "\n", "    ", "X", "=", "np", ".", "array", "(", "[", "[", "0.38", ",", "0.75", "]", ",", "[", "0.50", ",", "0.93", "]", ",", "[", "0.05", ",", "0.70", "]", ",", "[", "0.30", ",", "0.90", "]", ",", "[", "0.15", ",", "0.80", "]", ",", "\n", "[", "0.75", ",", "0.38", "]", ",", "[", "0.95", ",", "0.48", "]", ",", "[", "0.70", ",", "0.05", "]", ",", "[", "0.65", ",", "0.30", "]", ",", "[", "0.80", ",", "0.30", "]", ",", "\n", "[", "0.05", ",", "0.1", "]", ",", "[", "0.35", ",", "0.1", "]", ",", "[", "0.45", ",", "0.075", "]", ",", "[", "0.3", ",", "0.2", "]", ",", "[", "0.25", ",", "0.1", "]", ",", "\n", "[", "0.95", ",", "0.65", "]", ",", "[", "0.7", ",", "0.9", "]", ",", "[", "0.925", ",", "0.7", "]", ",", "[", "0.79", ",", "0.55", "]", ",", "[", "0.81", ",", "0.8", "]", "]", ")", "\n", "y", "=", "np", ".", "array", "(", "[", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "\n", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "eps_dataset", "=", "0.075", "\n", "return", "X", ",", "y", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.toy_2d_xor": [[113, 118], ["numpy.array", "numpy.array"], "function", ["None"], ["", "def", "toy_2d_xor", "(", ")", ":", "\n", "    ", "X", "=", "np", ".", "array", "(", "[", "[", "0.05", ",", "0.05", "]", ",", "[", "0.95", ",", "0.95", "]", ",", "[", "0.05", ",", "0.95", "]", ",", "[", "0.95", ",", "0.05", "]", "]", ")", "\n", "y", "=", "np", ".", "array", "(", "[", "-", "1", ",", "-", "1", ",", "1", ",", "1", "]", ")", "\n", "eps_dataset", "=", "0.15", "\n", "return", "X", ",", "y", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.toy_2d_wong": [[120, 137], ["numpy.random.seed", "numpy.array", "numpy.sign", "numpy.random.uniform", "len", "numpy.random.uniform", "numpy.random.uniform", "min", "x.append", "numpy.abs().sum", "numpy.abs"], "function", ["None"], ["", "def", "toy_2d_wong", "(", ")", ":", "\n", "# random points at least 2r apart", "\n", "    ", "m", "=", "12", "\n", "# seed=10 illustrates that by default the margin can be easily close to 0", "\n", "# both plain and robust model have 0 train error, but the robust model additionally enforces a large margin", "\n", "np", ".", "random", ".", "seed", "(", "10", ")", "\n", "x", "=", "[", "np", ".", "random", ".", "uniform", "(", "size", "=", "2", ")", "]", "\n", "r", "=", "0.16", "\n", "while", "len", "(", "x", ")", "<", "m", ":", "\n", "        ", "p", "=", "np", ".", "random", ".", "uniform", "(", "size", "=", "2", ")", "\n", "if", "min", "(", "np", ".", "abs", "(", "p", "-", "a", ")", ".", "sum", "(", ")", "for", "a", "in", "x", ")", ">", "2", "*", "r", ":", "\n", "            ", "x", ".", "append", "(", "p", ")", "\n", "", "", "eps_dataset", "=", "r", "/", "2", "\n", "\n", "X", "=", "np", ".", "array", "(", "x", ")", "\n", "y", "=", "np", ".", "sign", "(", "np", ".", "random", ".", "uniform", "(", "-", "0.5", ",", "0.5", ",", "size", "=", "m", ")", ")", "\n", "return", "X", ",", "y", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.breast_cancer": [[139, 163], ["csv.reader", "numpy.array", "data.split_train_test", "data.normalize_per_feature_0_1", "open().readlines", "lst.append", "open"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.split_train_test", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.normalize_per_feature_0_1"], ["", "def", "breast_cancer", "(", ")", ":", "\n", "    ", "\"\"\"\n    Taken from the UCI repository:\n    http://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+%28diagnostic%29 file: breast-cancer-wisconsin.data\n\n    After filtering the points with missing data, we have exactly the same as Chen et al, 2019\n    train: 546x10, test: 137x10\n    \"\"\"", "\n", "eps_dataset", "=", "0.3", "# same as in Chen et al, 2019, worked well for them", "\n", "path", "=", "data_dir", "+", "'breast_cancer/breast-cancer-wisconsin.data'", "\n", "\n", "lst", "=", "[", "]", "\n", "for", "line", "in", "csv", ".", "reader", "(", "open", "(", "path", ",", "'r'", ")", ".", "readlines", "(", ")", ")", ":", "\n", "        ", "if", "'?'", "not", "in", "line", ":", "\n", "            ", "lst", ".", "append", "(", "line", ")", "\n", "", "", "data_arr", "=", "np", ".", "array", "(", "lst", ",", "dtype", "=", "int", ")", "\n", "\n", "X_all", ",", "y_all", "=", "data_arr", "[", ":", ",", ":", "10", "]", ",", "data_arr", "[", ":", ",", "10", "]", "\n", "y_all", "[", "y_all", "==", "2", "]", ",", "y_all", "[", "y_all", "==", "4", "]", "=", "-", "1", ",", "1", "# from 2, 4 to -1, 1", "\n", "\n", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", "=", "split_train_test", "(", "X_all", ",", "y_all", ",", "frac_train", "=", "0.8", ")", "\n", "X_train", ",", "X_test", "=", "normalize_per_feature_0_1", "(", "X_train", ",", "X_test", ")", "\n", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.diabetes": [[165, 183], ["numpy.loadtxt", "data.split_train_test", "data.normalize_per_feature_0_1"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.split_train_test", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.normalize_per_feature_0_1"], ["", "def", "diabetes", "(", ")", ":", "\n", "    ", "\"\"\"\n    Taken from Kaggle:\n    https://www.kaggle.com/uciml/pima-indians-diabetes-database file: diabetes.csv\n\n    train: 614x8, test: 154x8\n    \"\"\"", "\n", "eps_dataset", "=", "0.05", "# Chen et al, 2019 used 0.2, but it was too high", "\n", "path", "=", "data_dir", "+", "'diabetes/diabetes.csv'", "\n", "data_arr", "=", "np", ".", "loadtxt", "(", "path", ",", "delimiter", "=", "','", ",", "skiprows", "=", "1", ")", "# loaded as float64", "\n", "\n", "X_all", ",", "y_all", "=", "data_arr", "[", ":", ",", ":", "8", "]", ",", "data_arr", "[", ":", ",", "8", "]", "\n", "y_all", "[", "y_all", "==", "0", "]", ",", "y_all", "[", "y_all", "==", "1", "]", "=", "-", "1", ",", "1", "# from 0, 1 to -1, 1", "\n", "\n", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", "=", "split_train_test", "(", "X_all", ",", "y_all", ",", "frac_train", "=", "0.8", ")", "\n", "X_train", ",", "X_test", "=", "normalize_per_feature_0_1", "(", "X_train", ",", "X_test", ")", "\n", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.ijcnn1": [[185, 236], ["numpy.zeros", "numpy.zeros", "enumerate", "enumerate", "numpy.zeros", "numpy.zeros", "enumerate", "data.normalize_per_feature_0_1", "open().readlines", "int", "open().readlines", "int", "open().readlines", "int", "float", "line.split", "s.replace().split", "float", "line.split", "s.replace().split", "float", "line.split", "s.replace().split", "open", "float", "open", "float", "open", "float", "line.split", "s.replace", "int", "line.split", "s.replace", "int", "line.split", "s.replace", "int"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.normalize_per_feature_0_1"], ["", "def", "ijcnn1", "(", ")", ":", "\n", "    ", "\"\"\"\n    Taken from LIBSVM data repository:\n    https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html\n\n    train: 49990x22, test: 91701x22\n    note: imbalanced classes (-1: 90.3% vs 1: 9.7%)\n    \"\"\"", "\n", "eps_dataset", "=", "0.01", "# Chen et al, 2019 used 0.1, but it was too high", "\n", "folder", "=", "data_dir", "+", "'ijcnn1/'", "\n", "path_train", ",", "path_val", ",", "path_test", "=", "folder", "+", "'ijcnn1.tr'", ",", "folder", "+", "'ijcnn1.val'", ",", "folder", "+", "'ijcnn1.t'", "\n", "\n", "num_train", ",", "num_test", ",", "dim", "=", "49990", ",", "91701", ",", "22", "\n", "X_train", "=", "np", ".", "zeros", "(", "(", "num_train", ",", "dim", ")", ")", "\n", "y_train", "=", "np", ".", "zeros", "(", "num_train", ")", "\n", "num_train_orig", "=", "0", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "open", "(", "path_train", ",", "'r'", ")", ".", "readlines", "(", ")", ")", ":", "\n", "        ", "y_train", "[", "i", "]", "=", "int", "(", "float", "(", "line", ".", "split", "(", "' '", ")", "[", "0", "]", ")", ")", "# -1 or 1", "\n", "for", "s", "in", "line", ".", "split", "(", "' '", ")", "[", "1", ":", "]", ":", "\n", "            ", "coord_str", ",", "val_str", "=", "s", ".", "replace", "(", "'\\n'", ",", "''", ")", ".", "split", "(", "':'", ")", "\n", "coord", ",", "val", "=", "int", "(", "coord_str", ")", "-", "1", ",", "float", "(", "val_str", ")", "# -1 is needed to have pythonic numeration from 0", "\n", "X_train", "[", "i", ",", "coord", "]", "=", "val", "\n", "", "num_train_orig", "+=", "1", "\n", "\n", "", "num_val_orig", "=", "0", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "open", "(", "path_val", ",", "'r'", ")", ".", "readlines", "(", ")", ")", ":", "\n", "        ", "y_train", "[", "num_train_orig", "+", "i", "]", "=", "int", "(", "float", "(", "line", ".", "split", "(", "' '", ")", "[", "0", "]", ")", ")", "# -1 or 1", "\n", "for", "s", "in", "line", ".", "split", "(", "' '", ")", "[", "1", ":", "]", ":", "\n", "            ", "coord_str", ",", "val_str", "=", "s", ".", "replace", "(", "'\\n'", ",", "''", ")", ".", "split", "(", "':'", ")", "\n", "coord", ",", "val", "=", "int", "(", "coord_str", ")", "-", "1", ",", "float", "(", "val_str", ")", "\n", "X_train", "[", "num_train_orig", "+", "i", ",", "coord", "]", "=", "val", "\n", "", "num_val_orig", "+=", "1", "\n", "\n", "", "assert", "num_train", "==", "num_train_orig", "+", "num_val_orig", "# Check that we have not introduced extra zero rows", "\n", "\n", "X_test", "=", "np", ".", "zeros", "(", "(", "num_test", ",", "dim", ")", ")", "\n", "y_test", "=", "np", ".", "zeros", "(", "num_test", ")", "\n", "num_test_orig", "=", "0", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "open", "(", "path_test", ",", "'r'", ")", ".", "readlines", "(", ")", ")", ":", "\n", "        ", "y_test", "[", "i", "]", "=", "int", "(", "float", "(", "line", ".", "split", "(", "' '", ")", "[", "0", "]", ")", ")", "# -1 or 1", "\n", "for", "s", "in", "line", ".", "split", "(", "' '", ")", "[", "1", ":", "]", ":", "\n", "            ", "coord_str", ",", "val_str", "=", "s", ".", "replace", "(", "'\\n'", ",", "''", ")", ".", "split", "(", "':'", ")", "\n", "coord", ",", "val", "=", "int", "(", "coord_str", ")", "-", "1", ",", "float", "(", "val_str", ")", "\n", "X_test", "[", "i", ",", "coord", "]", "=", "val", "\n", "", "num_test_orig", "+=", "1", "\n", "\n", "", "assert", "num_test", "==", "num_test_orig", "\n", "\n", "X_train", ",", "X_test", "=", "normalize_per_feature_0_1", "(", "X_train", ",", "X_test", ")", "\n", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.cod_rna": [[238, 283], ["numpy.zeros", "numpy.zeros", "enumerate", "numpy.zeros", "numpy.zeros", "enumerate", "data.normalize_per_feature_0_1", "open().readlines", "int", "open().readlines", "int", "numpy.random.permutation", "float", "line.split", "s.replace().split", "float", "line.split", "s.replace().split", "open", "float", "open", "float", "line.split", "s.replace", "int", "line.split", "s.replace", "int"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.normalize_per_feature_0_1"], ["", "def", "cod_rna", "(", ")", ":", "\n", "    ", "\"\"\"\n    Taken from LIBSVM data repository:\n    https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html\n\n    train: 59535x8, test: 271617x8\n    \"\"\"", "\n", "eps_dataset", "=", "0.025", "# Chen et al, 2019 used 0.2, but it was too high", "\n", "folder", "=", "data_dir", "+", "'cod_rna/'", "\n", "path_train", ",", "path_test", "=", "folder", "+", "'cod-rna.tr'", ",", "folder", "+", "'cod-rna.t'", "\n", "\n", "num_train", ",", "num_test", ",", "dim", "=", "59535", ",", "271617", ",", "8", "\n", "X_train", "=", "np", ".", "zeros", "(", "(", "num_train", ",", "dim", ")", ")", "\n", "y_train", "=", "np", ".", "zeros", "(", "num_train", ")", "\n", "num_train_orig", "=", "0", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "open", "(", "path_train", ",", "'r'", ")", ".", "readlines", "(", ")", ")", ":", "\n", "        ", "y_train", "[", "i", "]", "=", "int", "(", "float", "(", "line", ".", "split", "(", "' '", ")", "[", "0", "]", ")", ")", "# -1 or 1", "\n", "for", "s", "in", "line", ".", "split", "(", "' '", ")", "[", "1", ":", "]", ":", "\n", "            ", "coord_str", ",", "val_str", "=", "s", ".", "replace", "(", "'\\n'", ",", "''", ")", ".", "split", "(", "':'", ")", "\n", "coord", ",", "val", "=", "int", "(", "coord_str", ")", "-", "1", ",", "float", "(", "val_str", ")", "# -1 is needed to have pythonic numeration from 0", "\n", "X_train", "[", "i", ",", "coord", "]", "=", "val", "\n", "", "num_train_orig", "+=", "1", "\n", "\n", "", "assert", "num_train", "==", "num_train_orig", "# Check that we have not introduced extra zero rows", "\n", "\n", "X_test", "=", "np", ".", "zeros", "(", "(", "num_test", ",", "dim", ")", ")", "\n", "y_test", "=", "np", ".", "zeros", "(", "num_test", ")", "\n", "num_test_orig", "=", "0", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "open", "(", "path_test", ",", "'r'", ")", ".", "readlines", "(", ")", ")", ":", "\n", "        ", "y_test", "[", "i", "]", "=", "int", "(", "float", "(", "line", ".", "split", "(", "' '", ")", "[", "0", "]", ")", ")", "# -1 or 1", "\n", "for", "s", "in", "line", ".", "split", "(", "' '", ")", "[", "1", ":", "]", ":", "\n", "            ", "coord_str", ",", "val_str", "=", "s", ".", "replace", "(", "'\\n'", ",", "''", ")", ".", "split", "(", "':'", ")", "\n", "coord", ",", "val", "=", "int", "(", "coord_str", ")", "-", "1", ",", "float", "(", "val_str", ")", "\n", "X_test", "[", "i", ",", "coord", "]", "=", "val", "\n", "", "num_test_orig", "+=", "1", "\n", "\n", "", "assert", "num_test", "==", "num_test_orig", "\n", "\n", "X_train", ",", "X_test", "=", "normalize_per_feature_0_1", "(", "X_train", ",", "X_test", ")", "\n", "\n", "# n_test_final = 10000  # take 10k test examples instead of all 270k", "\n", "n_test_final", "=", "num_test", "\n", "idx", "=", "np", ".", "random", ".", "permutation", "(", "num_test", ")", "[", ":", "n_test_final", "]", "\n", "X_test", ",", "y_test", "=", "X_test", "[", "idx", "]", ",", "y_test", "[", "idx", "]", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.mnist_1_5": [[285, 299], ["tensorflow.keras.datasets.mnist.load_data", "numpy.reshape", "numpy.reshape", "data.binary_from_multiclass", "np.reshape.astype", "np.reshape.astype"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.binary_from_multiclass"], ["", "def", "mnist_1_5", "(", ")", ":", "\n", "    ", "\"\"\"\n    train: (12163, 784), test: (2027, 784)\n    \"\"\"", "\n", "eps_dataset", "=", "0.3", "\n", "classes", "=", "[", "1", ",", "5", "]", "# 2 is 1, 6 is -1 in the binary classification scheme", "\n", "\n", "(", "X_train", ",", "y_train", ")", ",", "(", "X_test", ",", "y_test", ")", "=", "mnist_keras", ".", "load_data", "(", ")", "\n", "X_train", ",", "X_test", "=", "X_train", ".", "astype", "(", "np", ".", "float64", ")", "/", "255.0", ",", "X_test", ".", "astype", "(", "np", ".", "float64", ")", "/", "255.0", "\n", "X_train", "=", "np", ".", "reshape", "(", "X_train", ",", "[", "X_train", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "X_test", "=", "np", ".", "reshape", "(", "X_test", ",", "[", "X_test", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "\n", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", "=", "binary_from_multiclass", "(", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "classes", ")", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.mnist_2_6": [[301, 315], ["tensorflow.keras.datasets.mnist.load_data", "numpy.reshape", "numpy.reshape", "data.binary_from_multiclass", "np.reshape.astype", "np.reshape.astype"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.binary_from_multiclass"], ["", "def", "mnist_2_6", "(", ")", ":", "\n", "    ", "\"\"\"\n    train: (11876, 784), test: (1990, 784)\n    \"\"\"", "\n", "eps_dataset", "=", "0.3", "\n", "classes", "=", "[", "2", ",", "6", "]", "# 2 is 1, 6 is -1 in the binary classification scheme", "\n", "\n", "(", "X_train", ",", "y_train", ")", ",", "(", "X_test", ",", "y_test", ")", "=", "mnist_keras", ".", "load_data", "(", ")", "\n", "X_train", ",", "X_test", "=", "X_train", ".", "astype", "(", "np", ".", "float64", ")", "/", "255.0", ",", "X_test", ".", "astype", "(", "np", ".", "float64", ")", "/", "255.0", "\n", "X_train", "=", "np", ".", "reshape", "(", "X_train", ",", "[", "X_train", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "X_test", "=", "np", ".", "reshape", "(", "X_test", ",", "[", "X_test", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "\n", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", "=", "binary_from_multiclass", "(", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "classes", ")", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.mnist": [[317, 329], ["tensorflow.keras.datasets.mnist.load_data", "numpy.reshape", "numpy.reshape", "np.reshape.astype", "np.reshape.astype"], "function", ["None"], ["", "def", "mnist", "(", ")", ":", "\n", "    ", "\"\"\"\n    train: (60000, 784), test: (10000, 784)\n    \"\"\"", "\n", "eps_dataset", "=", "0.3", "\n", "\n", "(", "X_train", ",", "y_train", ")", ",", "(", "X_test", ",", "y_test", ")", "=", "mnist_keras", ".", "load_data", "(", ")", "\n", "X_train", ",", "X_test", "=", "X_train", ".", "astype", "(", "np", ".", "float64", ")", "/", "255.0", ",", "X_test", ".", "astype", "(", "np", ".", "float64", ")", "/", "255.0", "\n", "X_train", "=", "np", ".", "reshape", "(", "X_train", ",", "[", "X_train", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "X_test", "=", "np", ".", "reshape", "(", "X_test", ",", "[", "X_test", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.cifar10": [[331, 345], ["tensorflow.keras.datasets.cifar10.load_data", "numpy.reshape", "numpy.reshape", "y_train.flatten", "y_test.flatten", "np.reshape.astype", "np.reshape.astype"], "function", ["None"], ["", "def", "cifar10", "(", ")", ":", "\n", "    ", "\"\"\"\n    train: (60000, 3072), test: (10000, 3072)\n    \"\"\"", "\n", "eps_dataset", "=", "8", "/", "255", "\n", "\n", "(", "X_train", ",", "y_train", ")", ",", "(", "X_test", ",", "y_test", ")", "=", "cifar10_keras", ".", "load_data", "(", ")", "\n", "X_train", ",", "X_test", "=", "X_train", ".", "astype", "(", "np", ".", "float64", ")", "/", "255.0", ",", "X_test", ".", "astype", "(", "np", ".", "float64", ")", "/", "255.0", "\n", "X_train", "=", "np", ".", "reshape", "(", "X_train", ",", "[", "X_train", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "X_test", "=", "np", ".", "reshape", "(", "X_test", ",", "[", "X_test", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "\n", "y_train", ",", "y_test", "=", "y_train", ".", "flatten", "(", ")", ",", "y_test", ".", "flatten", "(", ")", "\n", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.fmnist_sandal_sneaker": [[347, 373], ["tensorflow.keras.datasets.fashion_mnist.load_data", "numpy.reshape", "numpy.reshape", "data.binary_from_multiclass", "np.reshape.astype", "np.reshape.astype"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.binary_from_multiclass"], ["", "def", "fmnist_sandal_sneaker", "(", ")", ":", "\n", "    ", "\"\"\"\n    Classes:\n    0\tT-shirt/top\n    1\tTrouser\n    2\tPullover\n    3\tDress\n    4\tCoat\n    5\tSandal\n    6\tShirt\n    7\tSneaker\n    8\tBag\n    9\tAnkle boot\n\n    train: (12000, 784), test: (2000, 784)\n    \"\"\"", "\n", "eps_dataset", "=", "0.1", "\n", "classes", "=", "[", "5", ",", "7", "]", "# 5 is 1, 7 is -1 in the binary classification scheme", "\n", "\n", "(", "X_train", ",", "y_train", ")", ",", "(", "X_test", ",", "y_test", ")", "=", "fashion_mnist_keras", ".", "load_data", "(", ")", "\n", "X_train", ",", "X_test", "=", "X_train", ".", "astype", "(", "np", ".", "float64", ")", "/", "255.0", ",", "X_test", ".", "astype", "(", "np", ".", "float64", ")", "/", "255.0", "\n", "X_train", "=", "np", ".", "reshape", "(", "X_train", ",", "[", "X_train", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "X_test", "=", "np", ".", "reshape", "(", "X_test", ",", "[", "X_test", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "\n", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", "=", "binary_from_multiclass", "(", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "classes", ")", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.fmnist": [[375, 387], ["tensorflow.keras.datasets.fashion_mnist.load_data", "numpy.reshape", "numpy.reshape", "np.reshape.astype", "np.reshape.astype"], "function", ["None"], ["", "def", "fmnist", "(", ")", ":", "\n", "    ", "\"\"\"\n    train: (60000, 784), test: (10000, 784)\n    \"\"\"", "\n", "eps_dataset", "=", "0.1", "\n", "\n", "(", "X_train", ",", "y_train", ")", ",", "(", "X_test", ",", "y_test", ")", "=", "fashion_mnist_keras", ".", "load_data", "(", ")", "\n", "X_train", ",", "X_test", "=", "X_train", ".", "astype", "(", "np", ".", "float64", ")", "/", "255.0", ",", "X_test", ".", "astype", "(", "np", ".", "float64", ")", "/", "255.0", "\n", "X_train", "=", "np", ".", "reshape", "(", "X_train", ",", "[", "X_train", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "X_test", "=", "np", ".", "reshape", "(", "X_test", ",", "[", "X_test", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.gts_100_roadworks": [[389, 409], ["scipy.io.loadmat", "scipy.io.loadmat", "data.binary_from_multiclass", "X_train.reshape", "X_test.reshape"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.binary_from_multiclass"], ["", "def", "gts_100_roadworks", "(", ")", ":", "\n", "    ", "\"\"\"\n    the class ids can be checked in the original data folders, for example:\n    1: speed 30, 4: speed 70, 7: speed 100, 8: speed 120, 18: warning, 25: roadworks\n\n    train: (2940, 3072), test: (930, 3072)\n    \"\"\"", "\n", "eps_dataset", "=", "8", "/", "255", "# following Madry et al, 2017 for cifar10", "\n", "classes", "=", "[", "7", ",", "25", "]", "\n", "\n", "# Originally, all pixels values are uint8 values in [0, 255]", "\n", "train", "=", "scipy", ".", "io", ".", "loadmat", "(", "data_dir", "+", "'gts/gts_int_train.mat'", ")", "\n", "test", "=", "scipy", ".", "io", ".", "loadmat", "(", "data_dir", "+", "'gts/gts_int_test.mat'", ")", "\n", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", "=", "train", "[", "'images'", "]", ",", "train", "[", "'labels'", "]", ",", "test", "[", "'images'", "]", ",", "test", "[", "'labels'", "]", "\n", "X_train", ",", "X_test", "=", "X_train", ".", "reshape", "(", "X_train", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ",", "X_test", ".", "reshape", "(", "X_test", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "X_train", ",", "X_test", "=", "X_train", "/", "255.0", ",", "X_test", "/", "255.0", "\n", "y_train", ",", "y_test", "=", "y_train", "[", "0", "]", ",", "y_test", "[", "0", "]", "# get rid of the extra dimension", "\n", "\n", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", "=", "binary_from_multiclass", "(", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "classes", ")", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.gts_30_70": [[411, 431], ["scipy.io.loadmat", "scipy.io.loadmat", "data.binary_from_multiclass", "X_train.reshape", "X_test.reshape"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.binary_from_multiclass"], ["", "def", "gts_30_70", "(", ")", ":", "\n", "    ", "\"\"\"\n    the class ids can be checked in the original data folders, for example:\n    1: speed 30, 4: speed 70, 7: speed 100, 8: speed 120, 18: warning, 25: roadworks\n\n    train: 4200x3072, test: 1380x3072\n    \"\"\"", "\n", "eps_dataset", "=", "8", "/", "255", "# following Madry et al, 2017 for cifar10", "\n", "classes", "=", "[", "1", ",", "4", "]", "\n", "\n", "# Originally, all pixels values are uint8 values in [0, 255]", "\n", "train", "=", "scipy", ".", "io", ".", "loadmat", "(", "data_dir", "+", "'gts/gts_int_train.mat'", ")", "\n", "test", "=", "scipy", ".", "io", ".", "loadmat", "(", "data_dir", "+", "'gts/gts_int_test.mat'", ")", "\n", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", "=", "train", "[", "'images'", "]", ",", "train", "[", "'labels'", "]", ",", "test", "[", "'images'", "]", ",", "test", "[", "'labels'", "]", "\n", "X_train", ",", "X_test", "=", "X_train", ".", "reshape", "(", "X_train", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ",", "X_test", ".", "reshape", "(", "X_test", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "X_train", ",", "X_test", "=", "X_train", "/", "255.0", ",", "X_test", "/", "255.0", "\n", "y_train", ",", "y_test", "=", "y_train", "[", "0", "]", ",", "y_test", "[", "0", "]", "# get rid of the extra dimension", "\n", "\n", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", "=", "binary_from_multiclass", "(", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "classes", ")", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.har": [[433, 450], ["numpy.loadtxt", "numpy.loadtxt", "numpy.loadtxt", "numpy.loadtxt"], "function", ["None"], ["", "def", "har", "(", ")", ":", "\n", "    ", "\"\"\"\n    Human activity recognition dataset from https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones\n    Note: Wong and Kolter, ICML 2018 used eps=0.05, but the data points were from -1 to 1.\n    We use equivalently eps=0.025, but data points from 0 to 1.\n\n    The labels are in {0, 1, 2, 3, 4, 5}.\n\n    train: (7352, 561), test: (2947, 561), n classes: 6.\n    \"\"\"", "\n", "eps_dataset", "=", "0.025", "\n", "path_train", ",", "path_test", "=", "data_dir", "+", "'har/train/'", ",", "data_dir", "+", "'har/test/'", "\n", "X_train", ",", "X_test", "=", "np", ".", "loadtxt", "(", "path_train", "+", "'X_train.txt'", ")", ",", "np", ".", "loadtxt", "(", "path_test", "+", "'X_test.txt'", ")", "\n", "y_train", ",", "y_test", "=", "np", ".", "loadtxt", "(", "path_train", "+", "'y_train.txt'", ")", ",", "np", ".", "loadtxt", "(", "path_test", "+", "'y_test.txt'", ")", "\n", "y_train", ",", "y_test", "=", "y_train", "-", "1", ",", "y_test", "-", "1", "# make the class numeration start from 0", "\n", "X_train", ",", "X_test", "=", "(", "X_train", "+", "1", ")", "/", "2", ",", "(", "X_test", "+", "1", ")", "/", "2", "# from [-1, 1] to [0, 1]", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "eps_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.convert_to_float32": [[452, 454], ["X.astype"], "function", ["None"], ["", "def", "convert_to_float32", "(", "X", ")", ":", "\n", "    ", "return", "X", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.random_crop": [[456, 464], ["numpy.random.randint", "numpy.random.randint"], "function", ["None"], ["", "def", "random_crop", "(", "image", ",", "n_crop", ")", ":", "\n", "    ", "h", ",", "w", ",", "_", "=", "image", ".", "shape", "\n", "top", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "n_crop", ")", "\n", "left", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "n_crop", ")", "\n", "bottom", "=", "h", "-", "(", "n_crop", "-", "top", ")", "\n", "right", "=", "w", "-", "(", "n_crop", "-", "left", ")", "\n", "image", "=", "image", "[", "top", ":", "bottom", ",", "left", ":", "right", ",", ":", "]", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.horizontal_flip": [[466, 470], ["numpy.random.rand"], "function", ["None"], ["", "def", "horizontal_flip", "(", "images", ",", "prob", "=", "0.5", ")", ":", "\n", "    ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "prob", ":", "\n", "        ", "images", "=", "images", "[", ":", ",", ":", ",", ":", ":", "-", "1", ",", ":", "]", "\n", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.data_augment": [[472, 488], ["numpy.reshape", "numpy.pad", "range", "numpy.reshape", "numpy.copy", "len", "data.random_crop", "data.horizontal_flip"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.copy", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.random_crop", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.horizontal_flip"], ["", "def", "data_augment", "(", "X", ",", "dataset", ")", ":", "\n", "    ", "num", ",", "dim", "=", "X", ".", "shape", "\n", "img_shape", "=", "datasets_img_shapes", "[", "dataset", "]", "\n", "X_img", "=", "np", ".", "reshape", "(", "np", ".", "copy", "(", "X", ")", ",", "[", "num", ",", "*", "img_shape", "]", ")", "\n", "if", "len", "(", "img_shape", ")", "==", "2", ":", "# introduce a fake last dimension for grayscale datasets", "\n", "        ", "X_img", "=", "X_img", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "\n", "", "n_crop", "=", "2", "\n", "X_img_pad", "=", "np", ".", "pad", "(", "X_img", ",", "[", "(", "0", ",", "0", ")", ",", "(", "n_crop", "//", "2", ",", "n_crop", "//", "2", ")", ",", "(", "n_crop", "//", "2", ",", "n_crop", "//", "2", ")", ",", "(", "0", ",", "0", ")", "]", ",", "'constant'", ",", "constant_values", "=", "0", ")", "# zero padding", "\n", "for", "i", "in", "range", "(", "num", ")", ":", "\n", "        ", "X_img", "[", "i", "]", "=", "random_crop", "(", "X_img_pad", "[", "i", "]", ",", "n_crop", "=", "n_crop", ")", "# up to `n_crop` pixels are cropped", "\n", "\n", "", "if", "dataset", "in", "[", "'cifar10'", "]", ":", "\n", "        ", "X_img", "=", "horizontal_flip", "(", "X_img", ")", "\n", "\n", "", "return", "np", ".", "reshape", "(", "X_img", ",", "[", "num", ",", "dim", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.crop_batch": [[490, 494], ["None"], "function", ["None"], ["", "def", "crop_batch", "(", "X_img", ",", "n_h", ",", "n_w", ",", "n_crop", ")", ":", "\n", "    ", "_", ",", "h", ",", "w", ",", "_", "=", "X_img", ".", "shape", "\n", "bottom", ",", "right", "=", "h", "-", "(", "n_crop", "-", "n_h", ")", ",", "w", "-", "(", "n_crop", "-", "n_w", ")", "\n", "return", "X_img", "[", ":", ",", "n_h", ":", "bottom", ",", "n_w", ":", "right", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.extend_dataset": [[496, 521], ["numpy.reshape", "numpy.pad", "data.crop_batch", "data.crop_batch", "data.crop_batch", "data.crop_batch", "numpy.vstack", "numpy.reshape", "numpy.copy", "len"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.crop_batch", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.crop_batch", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.crop_batch", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.data.crop_batch", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.copy"], ["", "def", "extend_dataset", "(", "X", ",", "dataset", ")", ":", "\n", "    ", "num", ",", "dim", "=", "X", ".", "shape", "\n", "img_shape", "=", "datasets_img_shapes", "[", "dataset", "]", "\n", "X_img", "=", "np", ".", "reshape", "(", "np", ".", "copy", "(", "X", ")", ",", "[", "num", ",", "*", "img_shape", "]", ")", "\n", "if", "len", "(", "img_shape", ")", "==", "2", ":", "# introduce a fake last dimension for grayscale datasets", "\n", "        ", "X_img", "=", "X_img", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "\n", "", "n_crop", "=", "2", "\n", "X_img_pad", "=", "np", ".", "pad", "(", "X_img", ",", "[", "(", "0", ",", "0", ")", ",", "(", "n_crop", "//", "2", ",", "n_crop", "//", "2", ")", ",", "(", "n_crop", "//", "2", ",", "n_crop", "//", "2", ")", ",", "(", "0", ",", "0", ")", "]", ",", "'constant'", ",", "\n", "constant_values", "=", "0", ")", "\n", "\n", "# Note: (1, 1) is the original image", "\n", "X_img_l", "=", "crop_batch", "(", "X_img_pad", ",", "1", ",", "0", ",", "n_crop", ")", "\n", "X_img_r", "=", "crop_batch", "(", "X_img_pad", ",", "1", ",", "2", ",", "n_crop", ")", "\n", "X_img_t", "=", "crop_batch", "(", "X_img_pad", ",", "0", ",", "1", ",", "n_crop", ")", "\n", "X_img_b", "=", "crop_batch", "(", "X_img_pad", ",", "2", ",", "1", ",", "n_crop", ")", "\n", "\n", "X_img_extended", "=", "np", ".", "vstack", "(", "[", "X_img", ",", "X_img_l", ",", "X_img_r", ",", "X_img_t", ",", "X_img_b", "]", ")", "\n", "\n", "# if dataset in ['cifar10']:  # would lead to 10x expansion of the training data - might be too comp. expensive", "\n", "#     X_img_horiz_flip = X_img_extended[:, :, ::-1, :]", "\n", "#     X_img_extended = np.vstack([X_img_extended, X_img_horiz_flip])", "\n", "\n", "X_final", "=", "np", ".", "reshape", "(", "X_img_extended", ",", "[", "-", "1", ",", "dim", "]", ")", "\n", "return", "X_final", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.attacks.sampling_attack": [[4, 23], ["numpy.zeros", "numpy.random.uniform", "range", "f.fmargin", "numpy.argmin", "numpy.clip", "f.fmargin", "numpy.ones"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.fmargin", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.fmargin"], ["def", "sampling_attack", "(", "f", ",", "X", ",", "y", ",", "eps", ",", "n_trials", ")", ":", "\n", "    ", "\"\"\" A simple attack just by sampling in the Linf-box around the points. More of a sanity check.\n        `f` is any function that has f.predict() method that returns class scores.\n    \"\"\"", "\n", "num", ",", "dim", "=", "X", ".", "shape", "\n", "f_x_vals", "=", "np", ".", "zeros", "(", "(", "num", ",", "n_trials", ")", ")", "\n", "# Note: for efficiency, we sample the same random direction for all points", "\n", "deltas", "=", "np", ".", "random", ".", "uniform", "(", "-", "eps", ",", "eps", ",", "size", "=", "(", "dim", ",", "n_trials", ")", ")", "\n", "for", "i", "in", "range", "(", "n_trials", "-", "1", ")", ":", "\n", "# let's keep them as real images, although not strictly needed", "\n", "        ", "perturbed_pts", "=", "np", ".", "clip", "(", "X", "+", "deltas", "[", ":", ",", "i", "]", ",", "0.0", ",", "1.0", ")", "\n", "f_x_vals", "[", ":", ",", "i", "]", "=", "f", ".", "fmargin", "(", "perturbed_pts", ")", "\n", "# maybe in some corner cases, the predictions at the original point is more worst-case than the sampled points", "\n", "", "f_x_vals", "[", ":", ",", "n_trials", "-", "1", "]", "=", "f", ".", "fmargin", "(", "X", ",", "np", ".", "ones", "(", "X", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "idx_min", "=", "np", ".", "argmin", "(", "y", "[", ":", ",", "None", "]", "*", "f_x_vals", ",", "axis", "=", "1", ")", "\n", "f_x_min", "=", "(", "y", "[", ":", ",", "None", "]", "*", "f_x_vals", ")", "[", "idx_min", "]", "\n", "deltas", "=", "deltas", "[", ":", ",", "idx_min", "]", "\n", "return", "f_x_min", ",", "deltas", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.attacks.cube_attack": [[25, 73], ["f.fmargin", "numpy.zeros", "numpy.clip", "f.fmargin", "numpy.random.choice", "numpy.clip", "f.fmargin", "type", "type", "numpy.maximum", "numpy.minimum", "numpy.maximum", "numpy.minimum"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.fmargin", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.fmargin", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.fmargin", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.minimum", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.minimum"], ["", "def", "cube_attack", "(", "f", ",", "X", ",", "y", ",", "eps", ",", "n_trials", ",", "p", "=", "0.5", ",", "deltas_init", "=", "None", ",", "independent_delta", "=", "False", ",", "min_val", "=", "0.0", ",", "max_val", "=", "1.0", ")", ":", "\n", "    ", "\"\"\" A simple, but efficient black-box attack that just adds random steps of values in {-2eps, 0, 2eps}\n    (i.e., the considered points are always corners). The random change is added if the loss decreases for a\n    particular point. The only disadvantage of this method is that it will never find decision regions inside the\n    Linf-ball which do not intersect any corner. But tight LRTE (compared to RTE/URTE) suggest that this doesn't happen.\n        `f` is any function that has f.fmargin() method that returns class scores.\n        `eps` can be a scalar or a vector of size X.shape[0].\n        `min_val`, `max_val` are min/max allowed values for values in X (e.g. 0 and 1 for images). This can be adjusted\n        depending on the feature range of the data. It's also possible to specify the as numpy vectors.\n    \"\"\"", "\n", "assert", "type", "(", "eps", ")", "is", "float", "or", "type", "(", "eps", ")", "is", "np", ".", "ndarray", "\n", "\n", "p_neg_eps", "=", "p", "/", "2", "# probability of sampling -2eps", "\n", "p_pos_eps", "=", "p", "/", "2", "# probability of sampling +2eps", "\n", "p_zero", "=", "1", "-", "p", "# probability of not doing an update", "\n", "num", ",", "dim", "=", "X", ".", "shape", "\n", "# independent deltas work better for adv. training but slow down attacks", "\n", "size_delta", "=", "(", "num", ",", "dim", ")", "if", "independent_delta", "else", "(", "1", ",", "dim", ")", "\n", "\n", "if", "deltas_init", "is", "None", ":", "\n", "        ", "deltas_init", "=", "np", ".", "zeros", "(", "size_delta", ")", "\n", "# this init is important, s.t. there is no violation of bounds", "\n", "", "f_x_vals_min", "=", "f", ".", "fmargin", "(", "X", ",", "y", ")", "\n", "\n", "if", "deltas_init", "is", "not", "None", ":", "# evaluate the provided deltas and take them if they are better", "\n", "        ", "X_adv", "=", "np", ".", "clip", "(", "X", "+", "deltas_init", ",", "np", ".", "maximum", "(", "min_val", ",", "X", "-", "eps", ")", ",", "np", ".", "minimum", "(", "max_val", ",", "X", "+", "eps", ")", ")", "\n", "deltas", "=", "X_adv", "-", "X", "# because of the projection above, the new delta vector is not just +-eps", "\n", "f_x_vals", "=", "f", ".", "fmargin", "(", "X_adv", ",", "y", ")", "\n", "idx_improved", "=", "f_x_vals", "<", "f_x_vals_min", "\n", "f_x_vals_min", "=", "idx_improved", "*", "f_x_vals", "+", "~", "idx_improved", "*", "f_x_vals_min", "\n", "deltas", "=", "idx_improved", "[", ":", ",", "None", "]", "*", "deltas_init", "+", "~", "idx_improved", "[", ":", ",", "None", "]", "*", "deltas", "\n", "", "else", ":", "\n", "        ", "deltas", "=", "deltas_init", "\n", "\n", "", "i_trial", "=", "0", "\n", "while", "i_trial", "<", "n_trials", ":", "\n", "# +-2*eps is *very* important to escape local minima; +-eps has very unstable performance", "\n", "        ", "new_deltas", "=", "np", ".", "random", ".", "choice", "(", "[", "-", "1", ",", "0", ",", "1", "]", ",", "p", "=", "[", "p_neg_eps", ",", "p_zero", ",", "p_pos_eps", "]", ",", "size", "=", "size_delta", ")", "\n", "new_deltas", "=", "2", "*", "eps", "*", "new_deltas", "# if eps is a vector, then it's an outer product num x 1 times 1 x dim", "\n", "X_adv", "=", "np", ".", "clip", "(", "X", "+", "deltas", "+", "new_deltas", ",", "np", ".", "maximum", "(", "min_val", ",", "X", "-", "eps", ")", ",", "np", ".", "minimum", "(", "max_val", ",", "X", "+", "eps", ")", ")", "\n", "new_deltas", "=", "X_adv", "-", "X", "# because of the projection above, the new delta vector is not just +-eps", "\n", "f_x_vals", "=", "f", ".", "fmargin", "(", "X_adv", ",", "y", ")", "\n", "idx_improved", "=", "f_x_vals", "<", "f_x_vals_min", "\n", "f_x_vals_min", "=", "idx_improved", "*", "f_x_vals", "+", "~", "idx_improved", "*", "f_x_vals_min", "\n", "deltas", "=", "idx_improved", "[", ":", ",", "None", "]", "*", "new_deltas", "+", "~", "idx_improved", "[", ":", ",", "None", "]", "*", "deltas", "\n", "i_trial", "+=", "1", "\n", "\n", "", "return", "f_x_vals_min", ",", "deltas", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.attacks.binary_search_attack": [[75, 115], ["numpy.zeros", "numpy.ones", "range", "f.fmargin", "print", "numpy.any", "f.fmargin", "print", "numpy.any", "attack", "print", "print", "range", "print", "numpy.abs().max", "numpy.copy", "f.fmargin", "numpy.abs().max", "np.ones.flatten", "numpy.abs", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.fmargin", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.fmargin", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.copy", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.fmargin"], ["", "def", "binary_search_attack", "(", "attack", ",", "f", ",", "X", ",", "y", ",", "n_trials_attack", ",", "cleanup", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Binary search to find the minimal perturbation that changes the class using `attack`.\n    Supports a single eps only.\n    \"\"\"", "\n", "n_iter_bs", "=", "10", "# precision up to the 4th digit", "\n", "num", ",", "dim", "=", "X", ".", "shape", "\n", "deltas", "=", "np", ".", "zeros", "(", "[", "num", ",", "dim", "]", ")", "\n", "eps", "=", "np", ".", "ones", "(", "(", "num", ",", "1", ")", ")", "\n", "eps_step", "=", "1.0", "\n", "for", "i_iter_bs", "in", "range", "(", "n_iter_bs", ")", ":", "\n", "        ", "f_x_vals", ",", "new_deltas", "=", "attack", "(", "f", ",", "X", ",", "y", ",", "eps", ",", "n_trials_attack", ",", "p", "=", "0.5", ",", "deltas_init", "=", "deltas", ")", "\n", "print", "(", "'iter_bs {}: yf={}, eps={}'", ".", "format", "(", "i_iter_bs", ",", "f_x_vals", ",", "eps", ".", "flatten", "(", ")", ")", ")", "\n", "idx_adv", "=", "f_x_vals", "[", ":", ",", "None", "]", "<", "0.0", "# if adversarial, reduce the eps", "\n", "eps", "=", "idx_adv", "*", "(", "eps", "-", "eps_step", "/", "2", ")", "+", "~", "idx_adv", "*", "(", "eps", "+", "eps_step", "/", "2", ")", "\n", "deltas", "=", "idx_adv", "*", "new_deltas", "+", "~", "idx_adv", "*", "deltas", "\n", "eps_step", "/=", "2", "\n", "\n", "", "yf", "=", "f", ".", "fmargin", "(", "X", "+", "deltas", ",", "y", ")", "\n", "print", "(", "'yf after binary search: yf={}, Linf={}'", ".", "format", "(", "yf", ",", "np", ".", "abs", "(", "deltas", ")", ".", "max", "(", "1", ")", ")", ")", "\n", "if", "np", ".", "any", "(", "yf", ">=", "0.0", ")", ":", "\n", "        ", "print", "(", "'The class was not changed (before cleanup)! Some bug apparently!'", ")", "\n", "\n", "", "if", "cleanup", ":", "\n", "# If some eps/-eps do not change the prediction for a particular example, use delta_i = 0 instead.", "\n", "# Better for interpretability. Caution: needs num * dim function evaluations, thus advisable to use only", "\n", "# for visualizations, but not for LRTE.", "\n", "        ", "for", "i", "in", "range", "(", "dim", ")", ":", "\n", "            ", "deltas_i_zeroed", "=", "np", ".", "copy", "(", "deltas", ")", "\n", "deltas_i_zeroed", "[", ":", ",", "i", "]", "=", "0.0", "\n", "f_x_vals", "=", "f", ".", "fmargin", "(", "X", "+", "deltas_i_zeroed", ",", "y", ")", "\n", "idx_adv", "=", "f_x_vals", "<", "0.0", "\n", "deltas", "=", "idx_adv", "[", ":", ",", "None", "]", "*", "deltas_i_zeroed", "+", "~", "idx_adv", "[", ":", ",", "None", "]", "*", "deltas", "\n", "\n", "", "", "yf", "=", "f", ".", "fmargin", "(", "X", "+", "deltas", ",", "y", ")", "\n", "print", "(", "'yf after cleanup: yf={}, Linf={}'", ".", "format", "(", "yf", ",", "np", ".", "abs", "(", "deltas", ")", ".", "max", "(", "1", ")", ")", ")", "\n", "if", "np", ".", "any", "(", "yf", ">=", "0.0", ")", ":", "\n", "        ", "print", "(", "'The class was not changed (after cleanup)! Some bug apparently!'", ")", "\n", "\n", "", "return", "deltas", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.attacks.coord_descent_attack_trees": [[117, 159], ["numpy.zeros", "numpy.argsort", "numpy.zeros", "f.fmargin", "numpy.where", "numpy.clip", "numpy.array", "numpy.clip", "numpy.maximum", "numpy.minimum", "tree.to_list", "numpy.maximum", "numpy.minimum", "f.fmargin", "len"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.fmargin", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.minimum", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.tree_ensemble.Tree.to_list", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.minimum", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.classifiers.OneVsAllClassifier.fmargin"], ["", "def", "coord_descent_attack_trees", "(", "f", ",", "X", ",", "y", ",", "eps", ",", "n_trials", ",", "deltas", "=", "None", ")", ":", "\n", "    ", "\"\"\" A simple, but relatively efficient (if multiple passes through the coordinates are allowed) white-box attack\n    just by iterating over coordinates (in the importance order) and checking whether -eps, 0 or eps is better.\n    Needs 2 function evaluations per coordinate.\n        `f` is a TreeEnsemble object.\n    \"\"\"", "\n", "num", ",", "dim", "=", "X", ".", "shape", "\n", "if", "deltas", "is", "None", ":", "\n", "        ", "deltas", "=", "np", ".", "zeros", "(", "(", "num", ",", "dim", ")", ")", "\n", "# this init is important, s.t. there is no violation of bounds", "\n", "", "f_x_vals_min", "=", "y", "*", "f", ".", "fmargin", "(", "np", ".", "clip", "(", "X", "+", "deltas", ",", "np", ".", "maximum", "(", "0.0", ",", "X", "-", "eps", ")", ",", "np", ".", "minimum", "(", "1.0", ",", "X", "+", "eps", ")", ")", ")", "\n", "\n", "coords_per_tree", "=", "np", ".", "zeros", "(", "dim", ")", "\n", "for", "tree", "in", "f", ".", "trees", ":", "\n", "        ", "coords_curr_tree", "=", "np", ".", "array", "(", "tree", ".", "to_list", "(", ")", ",", "dtype", "=", "int", ")", "[", ":", ",", "6", "]", "\n", "for", "coord", "in", "coords_curr_tree", ":", "# 6 is coord, 7 is min_loss", "\n", "            ", "coords_per_tree", "[", "coord", "]", "+=", "1", "\n", "", "", "idx_coords_sorted", "=", "np", ".", "argsort", "(", "-", "coords_per_tree", ")", "# sort in the reverse order", "\n", "coords_nnz_usage", "=", "np", ".", "where", "(", "coords_per_tree", "[", "idx_coords_sorted", "]", "!=", "0", ")", "[", "0", "]", "\n", "coords_to_consider", "=", "idx_coords_sorted", "[", "coords_nnz_usage", "]", "\n", "# print('The most important coords:', coords_to_consider[:20])", "\n", "\n", "i_trial", ",", "id_coord", "=", "0", ",", "0", "\n", "X_adv", "=", "X", "\n", "while", "i_trial", "<", "n_trials", ":", "\n", "# if len(coords_to_consider) < n_trials, then we do more than 1 cycle of the coordinate descent scheme", "\n", "        ", "coord", "=", "coords_to_consider", "[", "id_coord", "%", "len", "(", "coords_to_consider", ")", "]", "\n", "for", "new_delta", "in", "[", "-", "eps", ",", "eps", "]", ":", "\n", "            ", "X_adv_new", "=", "X", "+", "deltas", "\n", "# because of multiple cycles of coordinate descent, we also need to consider +-eps constraints", "\n", "X_adv_new", "[", ":", ",", "coord", "]", "=", "np", ".", "clip", "(", "X_adv_new", "[", ":", ",", "coord", "]", "+", "new_delta", ",", "np", ".", "maximum", "(", "0.0", ",", "X", "[", ":", ",", "coord", "]", "-", "eps", ")", ",", "\n", "np", ".", "minimum", "(", "1.0", ",", "X", "[", ":", ",", "coord", "]", "+", "eps", ")", ")", "\n", "# because of constraint projections, the new delta vector is not just +-eps", "\n", "new_delta_vector", "=", "X_adv_new", "[", ":", ",", "coord", "]", "-", "X_adv", "[", ":", ",", "coord", "]", "\n", "f_x_vals", "=", "y", "*", "f", ".", "fmargin", "(", "X_adv_new", ")", "\n", "improved", "=", "(", "f_x_vals", "<", "f_x_vals_min", ")", "\n", "f_x_vals_min", "=", "improved", "*", "f_x_vals", "+", "~", "improved", "*", "f_x_vals_min", "\n", "deltas", "[", ":", ",", "coord", "]", "=", "improved", "*", "new_delta_vector", "+", "~", "improved", "*", "deltas", "[", ":", ",", "coord", "]", "\n", "i_trial", "+=", "1", "\n", "", "id_coord", "+=", "1", "\n", "\n", "", "return", "f_x_vals_min", ",", "deltas", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.attacks.exact_attack_stumps": [[161, 230], ["numpy.zeros", "numpy.full", "range", "numpy.array", "numpy.sort", "print", "numpy.zeros", "f.coords_trees.keys", "numpy.clip", "float", "print", "f.predict", "print", "numpy.array", "numpy.array", "numpy.argsort", "numpy.cumsum", "np.cumsum.argmin", "numpy.abs", "np.cumsum.min", "f.predict", "numpy.abs().max", "tree.predict", "tree.predict", "np.array.append", "np.array.append", "numpy.array", "numpy.abs", "numpy.sign"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict"], ["", "def", "exact_attack_stumps", "(", "f", ",", "X", ",", "y", ")", ":", "\n", "    ", "\"\"\" Fast exact adv. examples for boosted stumps.\n        `f` is a StumpEnsemble object.\n    \"\"\"", "\n", "min_val", "=", "1e-7", "\n", "num", ",", "dim", "=", "X", ".", "shape", "\n", "deltas", "=", "np", ".", "zeros", "(", "[", "num", ",", "dim", "]", ")", "\n", "db_dists", "=", "np", ".", "full", "(", "num", ",", "np", ".", "inf", ")", "\n", "\n", "for", "i", "in", "range", "(", "num", ")", ":", "\n", "# 0.0 means we just check whether the point is originally misclassified; if yes  =>  db_dist=0", "\n", "        ", "eps_all_i", "=", "np", ".", "array", "(", "[", "0.0", "]", "+", "[", "np", ".", "abs", "(", "tree", ".", "b", "-", "X", "[", "i", ",", "tree", ".", "coord", "]", "+", "min_val", "*", "np", ".", "sign", "(", "tree", ".", "b", "-", "X", "[", "i", ",", "tree", ".", "coord", "]", ")", ")", "\n", "for", "tree", "in", "f", ".", "trees", "]", ")", "\n", "eps_sorted", "=", "np", ".", "sort", "(", "eps_all_i", ")", "\n", "for", "eps", "in", "eps_sorted", ":", "\n", "# Vectorized but obscure version that doesn't return deltas; just a sanity check for eps", "\n", "# f_x_min = self.certify_exact(X[None, i], y[None, i], eps)", "\n", "\n", "# Clear unvectorized version", "\n", "            ", "yf_min", "=", "0.0", "\n", "delta", "=", "np", ".", "zeros", "(", "dim", ")", "\n", "for", "coord", "in", "f", ".", "coords_trees", ".", "keys", "(", ")", ":", "\n", "                ", "trees_current_coord", "=", "f", ".", "coords_trees", "[", "coord", "]", "\n", "\n", "yf_min_coord_base", ",", "yf_orig_pt", "=", "0.0", ",", "0.0", "\n", "for", "tree", "in", "trees_current_coord", ":", "\n", "                    ", "yf_min_coord_base", "+=", "y", "[", "i", "]", "*", "tree", ".", "predict", "(", "X", "[", "None", ",", "i", "]", "-", "eps", ")", "\n", "yf_orig_pt", "+=", "y", "[", "i", "]", "*", "tree", ".", "predict", "(", "X", "[", "None", ",", "i", "]", ")", "\n", "\n", "", "unstable_thresholds", ",", "unstable_wr_values", "=", "[", "X", "[", "i", ",", "coord", "]", "-", "eps", "]", ",", "[", "0.0", "]", "\n", "for", "tree", "in", "trees_current_coord", ":", "\n", "# excluding the left equality since we have already evaluated it", "\n", "                    ", "if", "X", "[", "i", ",", "coord", "]", "-", "eps", "<", "tree", ".", "b", "<=", "X", "[", "i", ",", "coord", "]", "+", "eps", ":", "\n", "                        ", "unstable_thresholds", ".", "append", "(", "tree", ".", "b", ")", "\n", "unstable_wr_values", ".", "append", "(", "tree", ".", "w_r", ")", "\n", "", "", "unstable_thresholds", "=", "np", ".", "array", "(", "unstable_thresholds", ")", "\n", "unstable_wr_values", "=", "np", ".", "array", "(", "unstable_wr_values", ")", "\n", "idx", "=", "np", ".", "argsort", "(", "unstable_thresholds", ")", "\n", "unstable_thresholds", "=", "unstable_thresholds", "[", "idx", "]", "\n", "\n", "sorted_y_wr", "=", "(", "y", "[", "i", "]", "*", "np", ".", "array", "(", "unstable_wr_values", ")", ")", "[", "idx", "]", "\n", "yf_coord_interval_vals", "=", "np", ".", "cumsum", "(", "sorted_y_wr", ")", "\n", "yf_min_coord", "=", "yf_min_coord_base", "+", "yf_coord_interval_vals", ".", "min", "(", ")", "\n", "yf_min", "+=", "yf_min_coord", "\n", "\n", "i_opt_threshold", "=", "yf_coord_interval_vals", ".", "argmin", "(", ")", "\n", "# if the min value is attained at the point itself, take it instead; so that we do not take", "\n", "# unnecessary -eps deltas (which would not anyway influence Linf size, but would bias the picture)", "\n", "if", "yf_min_coord", "==", "yf_orig_pt", ":", "\n", "                    ", "opt_threshold", "=", "X", "[", "i", ",", "coord", "]", "# i.e. the final delta is 0.0", "\n", "", "else", ":", "\n", "                    ", "opt_threshold", "=", "unstable_thresholds", "[", "i_opt_threshold", "]", "\n", "", "delta", "[", "coord", "]", "=", "opt_threshold", "-", "X", "[", "i", ",", "coord", "]", "\n", "\n", "", "x_adv_clipped", "=", "np", ".", "clip", "(", "X", "[", "i", "]", "+", "delta", ",", "0", ",", "1", ")", "# make sure that the images are valid", "\n", "delta", "=", "x_adv_clipped", "-", "X", "[", "i", "]", "\n", "\n", "yf", "=", "float", "(", "y", "[", "i", "]", "*", "f", ".", "predict", "(", "X", "[", "None", ",", "i", "]", "+", "delta", "[", "None", "]", ")", ")", "\n", "print", "(", "'eps_max={:.3f}, eps_delta={:.3f}, yf={:.3f}, nnz={}'", ".", "format", "(", "\n", "eps", ",", "np", ".", "abs", "(", "delta", ")", ".", "max", "(", ")", ",", "yf", ",", "(", "delta", "!=", "0.0", ")", ".", "sum", "(", ")", ")", ")", "\n", "if", "yf_min", "<", "0", ":", "\n", "                ", "db_dists", "[", "i", "]", "=", "eps", "\n", "deltas", "[", "i", "]", "=", "delta", "\n", "break", "\n", "", "", "print", "(", ")", "\n", "yf", "=", "y", "[", "i", "]", "*", "f", ".", "predict", "(", "X", "[", "None", ",", "i", "]", "+", "deltas", "[", "None", ",", "i", "]", ")", "\n", "if", "yf", ">=", "0.0", ":", "\n", "            ", "print", "(", "'The class was not changed! Some bug apparently!'", ")", "\n", "", "", "return", "deltas", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.__init__": [[10, 14], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "w_l", ",", "w_r", ",", "b", ",", "coord", ",", "loss", ")", ":", "\n", "# `loss` is the loss of the whole ensemble after applying this stump", "\n", "        ", "self", ".", "w_l", ",", "self", ".", "w_r", ",", "self", ".", "b", ",", "self", ".", "coord", ",", "self", ".", "loss", "=", "w_l", ",", "w_r", ",", "b", ",", "coord", ",", "loss", "\n", "self", ".", "left", ",", "self", ".", "right", "=", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.predict": [[15, 18], ["None"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "X", ")", ":", "\n", "        ", "value", "=", "self", ".", "w_l", "+", "self", ".", "w_r", "*", "(", "X", "[", ":", ",", "self", ".", "coord", "]", ">=", "self", ".", "b", ")", "\n", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.find_min_yf": [[19, 31], ["numpy.minimum"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.minimum"], ["", "def", "find_min_yf", "(", "self", ",", "X", ",", "y", ",", "eps", ")", ":", "\n", "        ", "split_lbs", ",", "split_ubs", "=", "X", "[", ":", ",", "self", ".", "coord", "]", "-", "eps", ",", "X", "[", ":", ",", "self", ".", "coord", "]", "+", "eps", "\n", "lval", ",", "rval", "=", "self", ".", "w_l", ",", "self", ".", "w_r", "+", "self", ".", "w_l", "\n", "\n", "# Fast vectorized version", "\n", "guaranteed_left", "=", "split_ubs", "<", "self", ".", "b", "\n", "guaranteed_right", "=", "split_lbs", ">", "self", ".", "b", "\n", "uncertain", "=", "(", "split_lbs", "<=", "self", ".", "b", ")", "*", "(", "split_ubs", ">=", "self", ".", "b", ")", "\n", "\n", "lbs", "=", "y", "*", "lval", "*", "guaranteed_left", "+", "y", "*", "rval", "*", "guaranteed_right", "+", "np", ".", "minimum", "(", "y", "*", "lval", ",", "y", "*", "rval", ")", "*", "uncertain", "\n", "\n", "return", "lbs", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.__repr__": [[32, 35], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "lval", ",", "rval", ",", "threshold", "=", "self", ".", "w_l", ",", "self", ".", "w_r", "+", "self", ".", "w_l", ",", "self", ".", "b", "\n", "return", "'Tree: if x[{}] < {:.4f}: {:.4f} else {:.4f}'", ".", "format", "(", "self", ".", "coord", ",", "threshold", ",", "lval", ",", "rval", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.get_json_dict": [[36, 47], ["round", "round", "round", "str", "int"], "methods", ["None"], ["", "def", "get_json_dict", "(", "self", ",", "counter_terminal_nodes", ")", ":", "\n", "        ", "\"\"\"\n        counter_terminal_nodes: not used here\n        \"\"\"", "\n", "precision", "=", "5", "\n", "children_list", "=", "[", "{", "'nodeid'", ":", "1", ",", "'leaf'", ":", "round", "(", "self", ".", "w_l", ",", "precision", ")", "}", ",", "\n", "{", "'nodeid'", ":", "2", ",", "'leaf'", ":", "round", "(", "self", ".", "w_l", "+", "self", ".", "w_r", ",", "precision", ")", "}", "]", "\n", "stump_dict", "=", "{", "'nodeid'", ":", "0", ",", "'split'", ":", "'f'", "+", "str", "(", "int", "(", "self", ".", "coord", ")", ")", ",", "'split_condition'", ":", "round", "(", "self", ".", "b", ",", "precision", ")", ",", "\n", "'yes'", ":", "1", ",", "'no'", ":", "2", ",", "'children'", ":", "children_list", "}", "\n", "\n", "return", "stump_dict", ",", "counter_terminal_nodes", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.__init__": [[50, 59], ["collections.OrderedDict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "weak_learner", ",", "n_trials_coord", ",", "lr", ",", "idx_clsf", ",", "n_bins", "=", "-", "1", ",", "max_weight", "=", "1.0", ")", ":", "\n", "        ", "self", ".", "weak_learner", "=", "weak_learner", "\n", "self", ".", "n_trials_coord", "=", "n_trials_coord", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "idx_clsf", "=", "idx_clsf", "\n", "self", ".", "n_bins", "=", "n_bins", "\n", "self", ".", "max_weight", "=", "max_weight", "\n", "self", ".", "trees", "=", "[", "]", "\n", "self", ".", "coords_trees", "=", "OrderedDict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.__repr__": [[60, 63], ["sorted", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "sorted_trees", "=", "sorted", "(", "self", ".", "trees", ",", "key", "=", "lambda", "tree", ":", "tree", ".", "coord", ")", "\n", "return", "'\\n'", ".", "join", "(", "[", "str", "(", "t", ")", "for", "t", "in", "sorted_trees", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.copy": [[64, 70], ["stump_ensemble.StumpEnsemble", "stump_ensemble.StumpEnsemble.add_weak_learner"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.add_weak_learner"], ["", "def", "copy", "(", "self", ")", ":", "\n", "        ", "ensemble_new", "=", "StumpEnsemble", "(", "self", ".", "weak_learner", ",", "self", ".", "n_trials_coord", ",", "self", ".", "lr", ",", "self", ".", "idx_clsf", ",", "self", ".", "n_bins", ",", "\n", "self", ".", "max_weight", ")", "\n", "for", "tree", "in", "self", ".", "trees", ":", "\n", "            ", "ensemble_new", ".", "add_weak_learner", "(", "tree", ",", "apply_lr", "=", "False", ")", "\n", "", "return", "ensemble_new", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.load": [[71, 80], ["range", "int", "stump_ensemble.Stump", "stump_ensemble.StumpEnsemble.add_weak_learner"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.add_weak_learner"], ["", "def", "load", "(", "self", ",", "ensemble_arr", ",", "iteration", "=", "-", "1", ")", ":", "\n", "        ", "if", "iteration", "!=", "-", "1", ":", "# take up to some iteration", "\n", "            ", "ensemble_arr", "=", "ensemble_arr", "[", ":", "iteration", "+", "1", "]", "\n", "", "for", "i", "in", "range", "(", "ensemble_arr", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "w_l", ",", "w_r", ",", "b", ",", "coord", ",", "loss", "=", "ensemble_arr", "[", "i", ",", ":", "]", "\n", "coord", "=", "int", "(", "coord", ")", "\n", "tree", "=", "Stump", "(", "w_l", ",", "w_r", ",", "b", ",", "coord", ",", "loss", ")", "\n", "# the values of w_l and w_r should be already scaled by lr, would be wrong to do this again", "\n", "self", ".", "add_weak_learner", "(", "tree", ",", "apply_lr", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.export_model": [[81, 86], ["numpy.zeros", "enumerate", "len"], "methods", ["None"], ["", "", "def", "export_model", "(", "self", ")", ":", "\n", "        ", "ensemble_arr", "=", "np", ".", "zeros", "(", "[", "len", "(", "self", ".", "trees", ")", ",", "5", "]", ")", "\n", "for", "i", ",", "tree", "in", "enumerate", "(", "self", ".", "trees", ")", ":", "\n", "            ", "ensemble_arr", "[", "i", ",", ":", "]", "=", "[", "tree", ".", "w_l", ",", "tree", ".", "w_r", ",", "tree", ".", "b", ",", "tree", ".", "coord", ",", "tree", ".", "loss", "]", "\n", "", "return", "ensemble_arr", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.save": [[87, 90], ["numpy.save", "stump_ensemble.StumpEnsemble.export_model"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.save", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.export_model"], ["", "def", "save", "(", "self", ",", "path", ")", ":", "\n", "        ", "if", "path", "!=", "''", ":", "\n", "            ", "np", ".", "save", "(", "path", ",", "self", ".", "export_model", "(", ")", ",", "allow_pickle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.add_weak_learner": [[91, 98], ["stump_ensemble.StumpEnsemble.trees.append", "stump_ensemble.StumpEnsemble.coords_trees[].append"], "methods", ["None"], ["", "", "def", "add_weak_learner", "(", "self", ",", "tree", ",", "apply_lr", "=", "True", ")", ":", "\n", "        ", "if", "apply_lr", ":", "\n", "            ", "tree", ".", "w_l", ",", "tree", ".", "w_r", "=", "tree", ".", "w_l", "*", "self", ".", "lr", ",", "tree", ".", "w_r", "*", "self", ".", "lr", "\n", "", "self", ".", "trees", ".", "append", "(", "tree", ")", "\n", "if", "tree", ".", "coord", "not", "in", "self", ".", "coords_trees", ":", "\n", "            ", "self", ".", "coords_trees", "[", "tree", ".", "coord", "]", "=", "[", "]", "\n", "", "self", ".", "coords_trees", "[", "tree", ".", "coord", "]", ".", "append", "(", "tree", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.add_empty_weak_learner": [[99, 102], ["stump_ensemble.Stump", "stump_ensemble.StumpEnsemble.add_weak_learner"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.add_weak_learner"], ["", "def", "add_empty_weak_learner", "(", "self", ")", ":", "\n", "        ", "empty_stump", "=", "Stump", "(", "0.0", ",", "0.0", ",", "0.0", ",", "0", ",", "0.0", ")", "\n", "self", ".", "add_weak_learner", "(", "empty_stump", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict": [[103, 108], ["numpy.zeros", "tree.predict"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict"], ["", "def", "predict", "(", "self", ",", "X", ")", ":", "\n", "        ", "Fx", "=", "np", ".", "zeros", "(", "X", ".", "shape", "[", "0", "]", ")", "\n", "for", "tree", "in", "self", ".", "trees", ":", "\n", "            ", "Fx", "+=", "tree", ".", "predict", "(", "X", ")", "\n", "", "return", "Fx", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.attack_by_sampling": [[109, 124], ["numpy.zeros", "numpy.random.uniform", "range", "stump_ensemble.StumpEnsemble.predict", "numpy.min", "numpy.clip", "stump_ensemble.StumpEnsemble.predict"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict"], ["", "def", "attack_by_sampling", "(", "self", ",", "X", ",", "y", ",", "eps", ",", "n_trials", ")", ":", "\n", "        ", "\"\"\" A simple attack just by sampling in the Linf-box around the points. More of a sanity check. \"\"\"", "\n", "num", ",", "dim", "=", "X", ".", "shape", "\n", "f_x_vals", "=", "np", ".", "zeros", "(", "(", "num", ",", "n_trials", ")", ")", "\n", "# Note: for efficiency, we sample the same random direction for all points", "\n", "deltas", "=", "np", ".", "random", ".", "uniform", "(", "-", "eps", ",", "eps", ",", "size", "=", "(", "dim", ",", "n_trials", ")", ")", "\n", "for", "i", "in", "range", "(", "n_trials", "-", "1", ")", ":", "\n", "# let's keep them as real images, although not strictly needed", "\n", "            ", "perturbed_pts", "=", "np", ".", "clip", "(", "X", "+", "deltas", "[", ":", ",", "i", "]", ",", "0.0", ",", "1.0", ")", "\n", "f_x_vals", "[", ":", ",", "i", "]", "=", "self", ".", "predict", "(", "perturbed_pts", ")", "\n", "# maybe in some corner cases, the predictions at the original point is more worst-case than the sampled points", "\n", "", "f_x_vals", "[", ":", ",", "n_trials", "-", "1", "]", "=", "self", ".", "predict", "(", "X", ")", "\n", "\n", "f_x_min", "=", "np", ".", "min", "(", "y", "[", ":", ",", "None", "]", "*", "f_x_vals", ",", "axis", "=", "1", ")", "\n", "return", "f_x_min", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.certify_treewise": [[125, 132], ["numpy.zeros", "tree.find_min_yf"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.Stump.find_min_yf"], ["", "def", "certify_treewise", "(", "self", ",", "X", ",", "y", ",", "eps", ")", ":", "\n", "        ", "lb_ensemble", "=", "np", ".", "zeros", "(", "X", ".", "shape", "[", "0", "]", ")", "\n", "\n", "# The naive tree-wise bounded on the merged trees", "\n", "for", "tree", "in", "self", ".", "trees", ":", "\n", "            ", "lb_ensemble", "+=", "tree", ".", "find_min_yf", "(", "X", ",", "y", ",", "eps", ")", "\n", "", "return", "lb_ensemble", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.find_min_coord_diff": [[133, 149], ["numba.jit", "numpy.argsort", "range", "numpy.zeros", "numpy.zeros", "len", "utils.minimum"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.minimum"], ["", "@", "staticmethod", "\n", "@", "jit", "(", "nopython", "=", "True", ")", "\n", "def", "find_min_coord_diff", "(", "X_proj", ",", "y", ",", "thresholds", ",", "w_r_values", ",", "eps", ")", ":", "\n", "# parallel=True doesn't help here; not sure if jit here is helpful at all. maybe if there are many thresholds", "\n", "        ", "num", "=", "X_proj", ".", "shape", "[", "0", "]", "\n", "idx", "=", "np", ".", "argsort", "(", "thresholds", ")", "\n", "sorted_thresholds", "=", "thresholds", "[", "idx", "]", "\n", "sorted_w_r", "=", "w_r_values", "[", "idx", "]", "\n", "f_x_min_coord_diff", ",", "f_x_cumsum", "=", "np", ".", "zeros", "(", "num", ")", ",", "np", ".", "zeros", "(", "num", ")", "\n", "for", "i_t", "in", "range", "(", "len", "(", "sorted_thresholds", ")", ")", ":", "\n", "# consider the threshold if it belongs to (x-eps, x+eps] (x-eps is excluded since already evaluated)", "\n", "            ", "idx_x_eps_close_to_threshold", "=", "(", "X_proj", "-", "eps", "<", "sorted_thresholds", "[", "i_t", "]", ")", "*", "(", "sorted_thresholds", "[", "i_t", "]", "<=", "X_proj", "+", "eps", ")", "\n", "f_diff", "=", "y", "*", "sorted_w_r", "[", "i_t", "]", "*", "idx_x_eps_close_to_threshold", "\n", "f_x_cumsum", "+=", "f_diff", "\n", "f_x_min_coord_diff", "=", "minimum", "(", "f_x_cumsum", ",", "f_x_min_coord_diff", ")", "\n", "", "return", "f_x_min_coord_diff", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.certify_exact": [[150, 177], ["numpy.zeros", "stump_ensemble.StumpEnsemble.coords_trees.keys", "numpy.zeros", "range", "numpy.unique", "numpy.zeros", "numpy.zeros", "len", "thresholds_list.append", "w_r_values_list.append", "numpy.array", "numpy.array", "stump_ensemble.StumpEnsemble.find_min_coord_diff", "len", "len", "tree.predict", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.find_min_coord_diff", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict"], ["", "def", "certify_exact", "(", "self", ",", "X", ",", "y", ",", "eps", ",", "coords_to_ignore", "=", "(", ")", ")", ":", "\n", "# Idea: iterate over all thresholds, and then check if they are in (x-eps, x+eps]", "\n", "        ", "num", ",", "dim", "=", "X", ".", "shape", "\n", "f_x_min", "=", "np", ".", "zeros", "(", "num", ")", "\n", "\n", "# Fast, vectorized version", "\n", "for", "coord", "in", "self", ".", "coords_trees", ".", "keys", "(", ")", ":", "\n", "            ", "if", "coord", "in", "coords_to_ignore", ":", "\n", "                ", "continue", "\n", "", "trees_current_coord", "=", "self", ".", "coords_trees", "[", "coord", "]", "\n", "\n", "f_x_min_coord_base", "=", "np", ".", "zeros", "(", "num", ")", "\n", "thresholds", ",", "w_r_values", "=", "np", ".", "zeros", "(", "len", "(", "trees_current_coord", ")", ")", ",", "np", ".", "zeros", "(", "len", "(", "trees_current_coord", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "trees_current_coord", ")", ")", ":", "\n", "                ", "tree", "=", "trees_current_coord", "[", "i", "]", "\n", "f_x_min_coord_base", "+=", "y", "*", "tree", ".", "predict", "(", "X", "-", "eps", ")", "\n", "thresholds", "[", "i", "]", ",", "w_r_values", "[", "i", "]", "=", "tree", ".", "b", ",", "tree", ".", "w_r", "\n", "\n", "# merge trees with the same thresholds to prevent an overestimation (lower bounding) of the true minimum", "\n", "", "thresholds_list", ",", "w_r_values_list", "=", "[", "]", ",", "[", "]", "\n", "for", "threshold", "in", "np", ".", "unique", "(", "thresholds", ")", ":", "\n", "                ", "thresholds_list", ".", "append", "(", "threshold", ")", "\n", "w_r_values_list", ".", "append", "(", "np", ".", "sum", "(", "w_r_values", "[", "thresholds", "==", "threshold", "]", ")", ")", "\n", "", "thresholds", ",", "w_r_values", "=", "np", ".", "array", "(", "thresholds_list", ")", ",", "np", ".", "array", "(", "w_r_values_list", ")", "\n", "\n", "f_x_min", "+=", "f_x_min_coord_base", "+", "self", ".", "find_min_coord_diff", "(", "X", "[", ":", ",", "coord", "]", ",", "y", ",", "thresholds", ",", "w_r_values", ",", "eps", ")", "\n", "", "return", "f_x_min", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.fit_stumps_over_coords": [[178, 226], ["numpy.mean", "len", "min_losses.argmin", "int", "stump_ensemble.Stump", "X.astype", "y.astype", "gamma.astype", "numpy.abs().sum", "numpy.random.permutation", "numpy.zeros", "numpy.full", "utils.get_n_proc", "min", "enumerate", "numpy.float32", "print", "min", "concurrent.futures.ThreadPoolExecutor", "range", "range", "stump_ensemble.StumpEnsemble.fit_stump", "numpy.abs", "numpy.where", "procs.append", "procs[].result", "executor.submit"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.get_n_proc", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.fit_stump"], ["", "def", "fit_stumps_over_coords", "(", "self", ",", "X", ",", "y", ",", "gamma", ",", "model", ",", "eps", ")", ":", "\n", "        ", "verbose", "=", "False", "\n", "parallel", "=", "False", "# can speed up the training on large datasets", "\n", "n_ex", "=", "X", ".", "shape", "[", "0", "]", "\n", "X", ",", "y", ",", "gamma", "=", "X", ".", "astype", "(", "dtype", ")", ",", "y", ".", "astype", "(", "dtype", ")", ",", "gamma", ".", "astype", "(", "dtype", ")", "\n", "prev_loss", "=", "np", ".", "mean", "(", "gamma", ")", "\n", "\n", "# 151 features are always 0.0 on MNIST 2 vs 6. And this number is even higher for smaller subsets of MNIST,", "\n", "# i.e. subsets of examples partitioned by tree splits.", "\n", "idx_non_trivial", "=", "np", ".", "abs", "(", "X", ")", ".", "sum", "(", "axis", "=", "0", ")", ">", "0.0", "\n", "features_to_check", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "where", "(", "idx_non_trivial", ")", "[", "0", "]", ")", "[", ":", "self", ".", "n_trials_coord", "]", "\n", "\n", "n_coords", "=", "len", "(", "features_to_check", ")", "\n", "params", ",", "min_losses", "=", "np", ".", "zeros", "(", "(", "n_coords", ",", "4", ")", ")", ",", "np", ".", "full", "(", "n_coords", ",", "np", ".", "inf", ")", "\n", "\n", "if", "parallel", ":", "\n", "            ", "n_proc", "=", "get_n_proc", "(", "n_ex", ")", "\n", "n_proc", "=", "min", "(", "n_coords", ",", "min", "(", "100", ",", "n_proc", ")", ")", "\n", "batch_size", "=", "n_coords", "//", "n_proc", "\n", "n_batches", "=", "n_coords", "//", "batch_size", "+", "1", "\n", "\n", "with", "ThreadPoolExecutor", "(", "max_workers", "=", "n_proc", ")", "as", "executor", ":", "\n", "                ", "procs", "=", "[", "]", "\n", "for", "i_batch", "in", "range", "(", "n_batches", ")", ":", "\n", "                    ", "coords", "=", "features_to_check", "[", "i_batch", "*", "batch_size", ":", "(", "i_batch", "+", "1", ")", "*", "batch_size", "]", "\n", "args", "=", "(", "X", ",", "X", "[", ":", ",", "coords", "]", ",", "y", ",", "gamma", ",", "model", ",", "eps", ",", "coords", ")", "\n", "procs", ".", "append", "(", "executor", ".", "submit", "(", "self", ".", "fit_stump_batch", ",", "*", "args", ")", ")", "\n", "\n", "# Process the results", "\n", "", "i_coord", "=", "0", "\n", "for", "i_batch", "in", "range", "(", "n_batches", ")", ":", "\n", "                    ", "res_many", "=", "procs", "[", "i_batch", "]", ".", "result", "(", ")", "\n", "for", "res", "in", "res_many", ":", "\n", "                        ", "min_losses", "[", "i_coord", "]", ",", "*", "params", "[", "i_coord", ",", ":", "]", "=", "res", "\n", "i_coord", "+=", "1", "\n", "", "", "", "", "else", ":", "\n", "            ", "for", "i_coord", ",", "coord", "in", "enumerate", "(", "features_to_check", ")", ":", "\n", "                ", "min_losses", "[", "i_coord", "]", ",", "*", "params", "[", "i_coord", ",", ":", "]", "=", "self", ".", "fit_stump", "(", "\n", "X", ",", "X", "[", ":", ",", "coord", "]", ",", "y", ",", "gamma", ",", "model", ",", "eps", ",", "coord", ")", "\n", "\n", "", "", "id_best_coord", "=", "min_losses", ".", "argmin", "(", ")", "\n", "min_loss", "=", "min_losses", "[", "id_best_coord", "]", "\n", "best_coord", "=", "int", "(", "params", "[", "id_best_coord", "]", "[", "3", "]", ")", "# float to int is necessary for a coordinate", "\n", "best_wl", ",", "best_wr", ",", "best_b", "=", "params", "[", "id_best_coord", "]", "[", "0", "]", ",", "params", "[", "id_best_coord", "]", "[", "1", "]", ",", "np", ".", "float32", "(", "params", "[", "id_best_coord", "]", "[", "2", "]", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'[{}-vs-all]: n_ex {}, n_coords {} -- loss {:.5f}->{:.5f}, b={:.3f} wl={:.3f} wr={:.3f} at coord {}'", ".", "format", "(", "\n", "self", ".", "idx_clsf", ",", "n_ex", ",", "n_coords", ",", "prev_loss", ",", "min_loss", ",", "best_b", ",", "best_wl", ",", "best_wr", ",", "best_coord", ")", ")", "\n", "", "return", "Stump", "(", "best_wl", ",", "best_wr", ",", "best_b", ",", "best_coord", ",", "min_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.fit_stump_batch": [[227, 232], ["numpy.zeros", "enumerate", "stump_ensemble.StumpEnsemble.fit_stump", "len"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.fit_stump"], ["", "def", "fit_stump_batch", "(", "self", ",", "X", ",", "Xs", ",", "y", ",", "gamma", ",", "model", ",", "eps", ",", "coords", ")", ":", "\n", "        ", "res", "=", "np", ".", "zeros", "(", "[", "len", "(", "coords", ")", ",", "5", "]", ")", "\n", "for", "i", ",", "coord", "in", "enumerate", "(", "coords", ")", ":", "\n", "            ", "res", "[", "i", "]", "=", "self", ".", "fit_stump", "(", "X", ",", "Xs", "[", ":", ",", "i", "]", ",", "y", ",", "gamma", ",", "model", ",", "eps", ",", "coord", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.fit_stump": [[233, 341], ["range", "numpy.min", "numpy.sort", "utils.get_contiguous_indices", "numpy.clip", "numpy.clip", "numpy.array", "numpy.zeros", "numpy.zeros", "len", "stump_ensemble.StumpEnsemble.certify_exact", "numpy.sum", "numpy.exp", "numpy.sort", "numpy.unique", "numpy.sort", "robust_boosting.fit_plain_stumps", "robust_boosting.fit_plain_stumps", "numpy.abs", "print", "len", "len", "len", "numpy.copy", "numpy.concatenate", "numpy.clip", "len", "numpy.concatenate", "robust_boosting.fit_robust_bound_stumps", "numpy.where", "len", "len", "robust_boosting.exp_loss_robust", "robust_boosting.exp_loss_robust", "ValueError", "robust_boosting.fit_robust_bound_stumps", "numpy.arange", "numpy.arange", "robust_boosting.fit_robust_exact_stumps", "ValueError", "len", "robust_boosting.fit_robust_exact_stumps", "ValueError", "numpy.full", "numpy.full"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.get_contiguous_indices", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.certify_exact", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_plain_stumps", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_plain_stumps", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.copy", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_robust_bound_stumps", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.exp_loss_robust", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.exp_loss_robust", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_robust_bound_stumps", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_robust_exact_stumps", "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.robust_boosting.fit_robust_exact_stumps"], ["", "def", "fit_stump", "(", "self", ",", "X", ",", "X_proj", ",", "y", ",", "gamma_global", ",", "model", ",", "eps", ",", "coord", ")", ":", "\n", "        ", "min_prec_val", "=", "1e-7", "\n", "min_val", ",", "max_val", "=", "0.0", ",", "1.0", "# can be changed if the features are in a different range", "\n", "n_bins", "=", "self", ".", "n_bins", "\n", "\n", "# Needed for exact robust optimization with stumps", "\n", "trees_current_coord", "=", "self", ".", "coords_trees", "[", "coord", "]", "if", "coord", "in", "self", ".", "coords_trees", "else", "[", "]", "\n", "w_rs", ",", "bs", "=", "np", ".", "zeros", "(", "len", "(", "trees_current_coord", ")", ")", ",", "np", ".", "zeros", "(", "len", "(", "trees_current_coord", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "trees_current_coord", ")", ")", ":", "\n", "            ", "w_rs", "[", "i", "]", "=", "trees_current_coord", "[", "i", "]", ".", "w_r", "\n", "bs", "[", "i", "]", "=", "trees_current_coord", "[", "i", "]", ".", "b", "\n", "\n", "", "if", "model", "==", "'robust_exact'", "and", "trees_current_coord", "!=", "[", "]", ":", "# note: the previous gamma is just ignored", "\n", "            ", "min_Fx_y_exact_without_j", "=", "self", ".", "certify_exact", "(", "X", ",", "y", ",", "eps", ",", "coords_to_ignore", "=", "(", "coord", ",", ")", ")", "\n", "w_ls", "=", "np", ".", "sum", "(", "[", "tree", ".", "w_l", "for", "tree", "in", "trees_current_coord", "]", ")", "\n", "gamma", "=", "np", ".", "exp", "(", "-", "min_Fx_y_exact_without_j", "-", "y", "*", "w_ls", ")", "\n", "", "else", ":", "\n", "            ", "gamma", "=", "gamma_global", "\n", "\n", "", "if", "n_bins", ">", "0", ":", "\n", "            ", "if", "model", "==", "'robust_bound'", ":", "\n", "# b_vals = np.array([0.31, 0.41, 0.5, 0.59, 0.69])  # that's the thresholds that one gets with n_bins=10", "\n", "                ", "b_vals", "=", "np", ".", "arange", "(", "eps", "*", "n_bins", ",", "n_bins", "-", "eps", "*", "n_bins", "+", "1", ")", "/", "n_bins", "\n", "# to have some margin to make the thresholds not adversarially reachable from 0 or 1", "\n", "b_vals", "[", "b_vals", "<", "0.5", "]", "+=", "0.1", "*", "1", "/", "n_bins", "\n", "b_vals", "[", "b_vals", ">", "0.5", "]", "-=", "0.1", "*", "1", "/", "n_bins", "\n", "", "else", ":", "\n", "                ", "b_vals", "=", "np", ".", "arange", "(", "1", ",", "n_bins", ")", "/", "n_bins", "\n", "", "", "else", ":", "\n", "            ", "threshold_candidates", "=", "np", ".", "sort", "(", "X_proj", ")", "\n", "if", "len", "(", "threshold_candidates", ")", "==", "0", ":", "# if no samples left according to min_samples_leaf", "\n", "                ", "return", "[", "np", ".", "inf", ",", "0.0", ",", "0.0", ",", "0.0", ",", "-", "1", "]", "\n", "", "if", "model", "not", "in", "[", "'robust_bound'", ",", "'robust_exact'", "]", "or", "eps", "==", "0.0", ":", "# plain, da_uniform or at_cube training", "\n", "                ", "b_vals", "=", "np", ".", "copy", "(", "threshold_candidates", ")", "\n", "b_vals", "+=", "min_prec_val", "# to break the ties", "\n", "", "else", ":", "# robust training", "\n", "                ", "b_vals", "=", "np", ".", "concatenate", "(", "(", "threshold_candidates", "-", "eps", ",", "threshold_candidates", "+", "eps", ")", ",", "axis", "=", "0", ")", "\n", "b_vals", "=", "np", ".", "clip", "(", "b_vals", ",", "min_val", ",", "max_val", ")", "# save computations (often goes 512 -> 360 thresholds on MNIST)", "\n", "# to make in the overlapping case [---x-[--]-x---] output 2 different losses in the middle", "\n", "n_bs", "=", "len", "(", "threshold_candidates", ")", "\n", "b_vals", "+=", "np", ".", "concatenate", "(", "(", "-", "np", ".", "full", "(", "n_bs", ",", "min_prec_val", ")", ",", "np", ".", "full", "(", "n_bs", ",", "min_prec_val", ")", ")", ",", "axis", "=", "0", ")", "\n", "", "b_vals", "=", "np", ".", "unique", "(", "b_vals", ")", "# use only unique b's", "\n", "b_vals", "=", "np", ".", "sort", "(", "b_vals", ")", "# still important to sort because of the final threshold selection", "\n", "\n", "", "if", "model", "in", "[", "'plain'", ",", "'da_uniform'", ",", "'at_cube'", "]", ":", "\n", "            ", "losses", ",", "w_l_vals", ",", "w_r_vals", ",", "b_vals", "=", "fit_plain_stumps", "(", "X_proj", ",", "y", ",", "gamma", ",", "b_vals", ",", "self", ".", "max_weight", ")", "\n", "", "elif", "model", "==", "'robust_bound'", ":", "\n", "            ", "losses", ",", "w_l_vals", ",", "w_r_vals", ",", "b_vals", "=", "fit_robust_bound_stumps", "(", "X_proj", ",", "y", ",", "gamma", ",", "b_vals", ",", "eps", ",", "self", ".", "max_weight", ")", "\n", "", "elif", "model", "==", "'robust_exact'", ":", "\n", "            ", "losses", ",", "w_l_vals", ",", "w_r_vals", ",", "b_vals", "=", "fit_robust_exact_stumps", "(", "X_proj", ",", "y", ",", "gamma", ",", "b_vals", ",", "eps", ",", "w_rs", ",", "bs", ",", "self", ".", "max_weight", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'wrong model'", ")", "\n", "\n", "", "min_loss", "=", "np", ".", "min", "(", "losses", ")", "\n", "# probably, they are already sorted, but to be 100% sure since it is not explicitly mentioned in the docs", "\n", "indices_opt_init", "=", "np", ".", "sort", "(", "np", ".", "where", "(", "losses", "==", "min_loss", ")", "[", "0", "]", ")", "\n", "indices_opt", "=", "get_contiguous_indices", "(", "indices_opt_init", ")", "\n", "id_opt", "=", "indices_opt", "[", "len", "(", "indices_opt", ")", "//", "2", "]", "\n", "\n", "idx_prev", "=", "np", ".", "clip", "(", "indices_opt", "[", "0", "]", "-", "1", ",", "0", ",", "len", "(", "b_vals", ")", "-", "1", ")", "# to prevent stepping out of the array", "\n", "idx_next", "=", "np", ".", "clip", "(", "indices_opt", "[", "-", "1", "]", "+", "1", ",", "0", ",", "len", "(", "b_vals", ")", "-", "1", ")", "# to prevent stepping out of the array", "\n", "b_prev", ",", "w_l_prev", ",", "w_r_prev", "=", "b_vals", "[", "idx_prev", "]", ",", "w_l_vals", "[", "idx_prev", "]", ",", "w_r_vals", "[", "idx_prev", "]", "\n", "b_next", ",", "w_l_next", ",", "w_r_next", "=", "b_vals", "[", "idx_next", "]", ",", "w_l_vals", "[", "idx_next", "]", ",", "w_r_vals", "[", "idx_next", "]", "\n", "# initialization", "\n", "b_leftmost", ",", "b_rightmost", "=", "b_vals", "[", "indices_opt", "[", "0", "]", "]", ",", "b_vals", "[", "indices_opt", "[", "-", "1", "]", "]", "\n", "# more involved, since with +-eps, an additional check of the loss is needed", "\n", "if", "model", "in", "[", "'plain'", ",", "'da_uniform'", ",", "'at_cube'", "]", ":", "\n", "            ", "b_rightmost", "=", "b_next", "\n", "", "elif", "model", "in", "[", "'robust_bound'", ",", "'robust_exact'", "]", ":", "\n", "            ", "h_flag", "=", "False", "if", "model", "==", "'robust_bound'", "else", "True", "\n", "\n", "b_prev_half", "=", "(", "b_prev", "+", "b_vals", "[", "indices_opt", "[", "0", "]", "]", ")", "/", "2", "\n", "loss_prev_half", "=", "exp_loss_robust", "(", "X_proj", ",", "y", ",", "gamma", ",", "w_l_prev", ",", "w_r_prev", ",", "w_rs", ",", "bs", ",", "b_prev_half", ",", "eps", ",", "h_flag", ")", "\n", "\n", "b_next_half", "=", "(", "b_vals", "[", "indices_opt", "[", "-", "1", "]", "]", "+", "b_next", ")", "/", "2", "\n", "loss_next_half", "=", "exp_loss_robust", "(", "X_proj", ",", "y", ",", "gamma", ",", "w_l_next", ",", "w_r_next", ",", "w_rs", ",", "bs", ",", "b_next_half", ",", "eps", ",", "h_flag", ")", "\n", "\n", "# we extend the interval of the constant loss to the left and to the right if there the loss is", "\n", "# the same at b_prev_half or b_next_half", "\n", "if", "loss_prev_half", "==", "losses", "[", "id_opt", "]", ":", "\n", "                ", "b_leftmost", "=", "b_prev", "\n", "", "if", "loss_next_half", "==", "losses", "[", "id_opt", "]", ":", "\n", "                ", "b_rightmost", "=", "b_next", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'wrong model'", ")", "\n", "\n", "# we put in the middle of the interval of the constant loss", "\n", "", "b_opt", "=", "(", "b_leftmost", "+", "b_rightmost", ")", "/", "2", "\n", "\n", "# For the chosen threshold, we need to calculate w_l, w_r", "\n", "# Some of w_l, w_r that correspond to min_loss may not be optimal anymore", "\n", "b_val_final", "=", "np", ".", "array", "(", "[", "b_opt", "]", ")", "\n", "if", "model", "in", "[", "'plain'", ",", "'da_uniform'", ",", "'at_cube'", "]", ":", "\n", "            ", "loss", ",", "w_l_opt", ",", "w_r_opt", ",", "_", "=", "fit_plain_stumps", "(", "X_proj", ",", "y", ",", "gamma", ",", "b_val_final", ",", "self", ".", "max_weight", ")", "\n", "", "elif", "model", "==", "'robust_bound'", ":", "\n", "            ", "loss", ",", "w_l_opt", ",", "w_r_opt", ",", "_", "=", "fit_robust_bound_stumps", "(", "X_proj", ",", "y", ",", "gamma", ",", "b_val_final", ",", "eps", ",", "self", ".", "max_weight", ")", "\n", "", "elif", "model", "==", "'robust_exact'", ":", "\n", "            ", "loss", ",", "w_l_opt", ",", "w_r_opt", ",", "_", "=", "fit_robust_exact_stumps", "(", "X_proj", ",", "y", ",", "gamma", ",", "b_val_final", ",", "eps", ",", "w_rs", ",", "bs", ",", "self", ".", "max_weight", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'wrong model'", ")", "\n", "", "loss", ",", "w_l_opt", ",", "w_r_opt", "=", "loss", "[", "0", "]", ",", "w_l_opt", "[", "0", "]", ",", "w_r_opt", "[", "0", "]", "\n", "# recalculation of w_l, w_r shouldn't change the min loss", "\n", "\n", "if", "np", ".", "abs", "(", "loss", "-", "min_loss", ")", ">", "1e7", ":", "\n", "            ", "print", "(", "'New loss: {:.5f}, min loss before: {:.5f}'", ".", "format", "(", "loss", ",", "min_loss", ")", ")", "\n", "\n", "", "best_loss", "=", "losses", "[", "id_opt", "]", "\n", "return", "[", "best_loss", ",", "w_l_opt", ",", "w_r_opt", ",", "b_opt", ",", "coord", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.__init__": [[8, 14], ["os.path.exists", "os.makedirs", "path.split"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "path", "=", "path", "\n", "if", "path", "!=", "''", ":", "\n", "            ", "folder", "=", "'/'", ".", "join", "(", "path", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "folder", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print": [[15, 21], ["utils.Logger.print"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print"], ["", "", "", "def", "print", "(", "self", ",", "message", ")", ":", "\n", "        ", "print", "(", "message", ")", "\n", "if", "self", ".", "path", "!=", "''", ":", "\n", "            ", "with", "open", "(", "self", ".", "path", ",", "'a'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "message", "+", "'\\n'", ")", "\n", "f", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.get_contiguous_indices": [[23, 38], ["numpy.where", "len", "numpy.sum", "len", "len", "Exception", "numpy.ones", "len"], "function", ["None"], ["", "", "", "", "def", "get_contiguous_indices", "(", "indices_opt_init", ")", ":", "\n", "# needed when indices_opt_init are not contiguous (e.g. mnist_2_6: coord=613 has [12, 13, 15, 16, 18])", "\n", "    ", "running_diffs", "=", "indices_opt_init", "[", "1", ":", "]", "-", "indices_opt_init", "[", ":", "-", "1", "]", "# [1, 2, 1, 2]", "\n", "where_change_contiguous_regions", "=", "np", ".", "where", "(", "running_diffs", "!=", "1", ")", "[", "0", "]", "# find the last contiguous index - 1", "\n", "\n", "if", "len", "(", "where_change_contiguous_regions", ")", ">", "0", ":", "\n", "        ", "last_el_first_contiguous_region", "=", "where_change_contiguous_regions", "[", "0", "]", "\n", "", "elif", "np", ".", "sum", "(", "running_diffs", "!=", "np", ".", "ones", "(", "len", "(", "running_diffs", ")", ")", ")", "==", "0", ":", "# if all are optimal (mnist_2_6: coord=72)", "\n", "        ", "last_el_first_contiguous_region", "=", "len", "(", "running_diffs", ")", "\n", "", "elif", "len", "(", "indices_opt_init", ")", "==", "1", ":", "# the easiest and most common situation - just 1 optimal index", "\n", "        ", "last_el_first_contiguous_region", "=", "0", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'this case has not been handled'", ")", "\n", "", "indices_opt", "=", "indices_opt_init", "[", ":", "last_el_first_contiguous_region", "+", "1", "]", "# [12, 13]", "\n", "return", "indices_opt", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.minimum": [[40, 44], ["numba.jit"], "function", ["None"], ["", "@", "jit", "(", "nopython", "=", "True", ")", "\n", "def", "minimum", "(", "arr1", ",", "arr2", ")", ":", "\n", "# take element-wise minimum of 2 arrays compatible with numba (instead of np.minimum(arr1, arr2))", "\n", "    ", "return", "arr1", "*", "(", "arr1", "<", "arr2", ")", "+", "arr2", "*", "(", "arr1", ">=", "arr2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.clip": [[46, 50], ["numba.jit", "min", "max"], "function", ["None"], ["", "@", "jit", "(", "nopython", "=", "True", ")", "\n", "def", "clip", "(", "val", ",", "val_min", ",", "val_max", ")", ":", "\n", "# identical to np.clip", "\n", "    ", "return", "min", "(", "max", "(", "val", ",", "val_min", ")", ",", "val_max", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.print_arr": [[52, 59], ["enumerate", "print"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.Logger.print"], ["", "def", "print_arr", "(", "arr", ")", ":", "\n", "    ", "\"\"\" Pretty printing of a 2D numpy array. \"\"\"", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "arr", ")", ":", "\n", "        ", "string", "=", "''", "\n", "for", "el", "in", "row", ":", "\n", "            ", "string", "+=", "'{:.3f} '", ".", "format", "(", "el", ")", "\n", "", "print", "(", "i", "+", "1", ",", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.extract_hyperparam": [[61, 63], ["[].split", "model_name.split"], "function", ["None"], ["", "", "def", "extract_hyperparam", "(", "model_name", ",", "substr", ")", ":", "\n", "    ", "return", "model_name", ".", "split", "(", "substr", ")", "[", "1", "]", ".", "split", "(", "' '", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.finalize_curr_row": [[65, 92], ["dict", "enumerate", "zip", "latex_str.split", "metrics_str.split", "metrics_curr_row[].append", "enumerate", "curr_str_bf.strip", "curr_row.split", "int", "float", "dict.values", "curr_row.split", "range", "min", "str"], "function", ["None"], ["", "def", "finalize_curr_row", "(", "latex_str", ",", "weak_learner", ",", "flag_n_trees_latex", ")", ":", "\n", "# finalizing the current row: apply boldfacing and add \\\\", "\n", "# (relies on the fact that we have only 3 metrics, i.e. TE,RTE,URTE or TE,LRTE,URTE or 4 metrics if flag_n_trees_latex is on)", "\n", "# result: 'breast-cancer & 0.3 & 0.7 & 85.4 & 85.4 & 5.1 & 11.7 & 11.7 & 5.1 & 11.7 & 11.7'", "\n", "    ", "curr_row", "=", "latex_str", ".", "split", "(", "r'\\\\'", ")", "[", "-", "1", "]", "\n", "curr_str_bf", "=", "' & '", ".", "join", "(", "curr_row", ".", "split", "(", "' & '", ")", "[", ":", "2", "]", ")", "+", "' &   '", "\n", "metrics_str", "=", "' & '", ".", "join", "(", "curr_row", ".", "split", "(", "' & '", ")", "[", "2", ":", "]", ")", "\n", "n_metrics", "=", "4", "if", "flag_n_trees_latex", "else", "3", "\n", "metrics_curr_row", "=", "dict", "(", "[", "(", "i", ",", "[", "]", ")", "for", "i", "in", "range", "(", "n_metrics", ")", "]", ")", "\n", "# result: {0: [0.7, 5.1, 5.1], 1: [85.4, 11.7, 11.7], 2: [85.4, 11.7, 11.7]}", "\n", "for", "i_val", ",", "val_str", "in", "enumerate", "(", "metrics_str", ".", "split", "(", "' & '", ")", ")", ":", "\n", "# for n_trees we need int, for the rest float", "\n", "        ", "val", "=", "int", "(", "val_str", ")", "if", "flag_n_trees_latex", "and", "i_val", "%", "n_metrics", "==", "n_metrics", "-", "1", "else", "float", "(", "val_str", ")", "\n", "metrics_curr_row", "[", "i_val", "%", "n_metrics", "]", ".", "append", "(", "val", ")", "\n", "# form the boldfaced str that corresponds to the current row", "\n", "", "for", "tup", "in", "zip", "(", "*", "metrics_curr_row", ".", "values", "(", ")", ")", ":", "\n", "        ", "for", "i_m", ",", "m", "in", "enumerate", "(", "tup", ")", ":", "\n", "# boldfacing condition: if minimum and it's not the number of trees (if the flag is turned on)", "\n", "            ", "if", "(", "m", "==", "min", "(", "metrics_curr_row", "[", "i_m", "]", ")", "and", "not", "(", "flag_n_trees_latex", "and", "i_m", "==", "3", ")", "and", "\n", "not", "(", "weak_learner", "==", "'stump'", "and", "i_m", "==", "2", ")", ")", ":", "# if URTE for stumps, don't boldface", "\n", "                ", "curr_str_bf", "+=", "'\\\\textbf{'", "+", "str", "(", "m", ")", "+", "'} & '", "\n", "", "else", ":", "\n", "                ", "curr_str_bf", "+=", "'{} & '", ".", "format", "(", "m", ")", "\n", "", "", "curr_str_bf", "+=", "'  '", "# just a margin for better latex code quality", "\n", "", "curr_str_bf", "=", "curr_str_bf", ".", "strip", "(", ")", "[", ":", "-", "1", "]", "# get rid of the last ' &   '", "\n", "curr_row_final", "=", "curr_str_bf", "+", "r'\\\\'", "+", "'\\n'", "# new table line", "\n", "return", "curr_row_final", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.get_model_names": [[94, 109], ["glob.glob", "glob.glob.sort", "str", "model_names.append", "os.path.getmtime", "[].split", "model_name_final.split"], "function", ["None"], ["", "def", "get_model_names", "(", "datasets", ",", "models", ",", "exp_folder", ",", "weak_learner", ",", "tree_depth", ")", ":", "\n", "    ", "model_names", "=", "[", "]", "\n", "for", "dataset", "in", "datasets", ":", "\n", "        ", "for", "model", "in", "models", ":", "\n", "            ", "depth_str", "=", "'max_depth='", "+", "str", "(", "tree_depth", ")", "if", "weak_learner", "==", "'tree'", "else", "''", "\n", "search_str", "=", "'{}/*dataset={} weak_learner={} model={}*{}*.metrics'", ".", "format", "(", "\n", "exp_folder", ",", "dataset", ",", "weak_learner", ",", "model", ",", "depth_str", ")", "\n", "model_names_curr", "=", "glob", ".", "glob", "(", "search_str", ")", "\n", "model_names_curr", ".", "sort", "(", "key", "=", "lambda", "x", ":", "os", ".", "path", ".", "getmtime", "(", "x", ")", ")", "\n", "if", "model_names_curr", "!=", "[", "]", ":", "\n", "# model_name_final = model_names_curr[-1]", "\n", "                ", "for", "model_name_final", "in", "model_names_curr", ":", "\n", "                    ", "model_name_final", "=", "model_name_final", ".", "split", "(", "'.metrics'", ")", "[", "0", "]", ".", "split", "(", "exp_folder", "+", "'/'", ")", "[", "1", "]", "\n", "model_names", ".", "append", "(", "model_name_final", ")", "\n", "", "", "", "", "return", "model_names", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.utils.get_n_proc": [[111, 125], ["None"], "function", ["None"], ["", "def", "get_n_proc", "(", "n_ex", ")", ":", "\n", "    ", "if", "n_ex", ">", "40000", ":", "\n", "        ", "n_proc", "=", "50", "\n", "", "elif", "n_ex", ">", "20000", ":", "\n", "        ", "n_proc", "=", "40", "\n", "", "elif", "n_ex", ">", "2500", ":", "\n", "        ", "n_proc", "=", "25", "\n", "", "elif", "n_ex", ">", "1000", ":", "\n", "        ", "n_proc", "=", "10", "\n", "", "elif", "n_ex", ">", "200", ":", "\n", "        ", "n_proc", "=", "5", "\n", "", "else", ":", "\n", "        ", "n_proc", "=", "1", "\n", "", "return", "n_proc", "\n", "", ""]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.robustml.robustml_fmnist.Model.__init__": [[21, 27], ["robustml_fmnist.load_model", "robustml.dataset.FMNIST", "robustml.threat_model.Linf"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.robustml.robustml_mnist.load_model"], ["    ", "def", "__init__", "(", "self", ",", "sess", ")", ":", "\n", "        ", "model_path", "=", "\"models/models_trees_multiclass/2019-08-06 14:59:51 dataset=fmnist weak_learner=tree model=robust_bound n_train=-1 n_trials_coord=784 eps=0.100 max_depth=30 lr=0.05.model.npy\"", "\n", "self", ".", "model", "=", "load_model", "(", "model_path", ")", "\n", "\n", "self", ".", "_dataset", "=", "robustml", ".", "dataset", ".", "FMNIST", "(", ")", "\n", "self", ".", "_threat_model", "=", "robustml", ".", "threat_model", ".", "Linf", "(", "epsilon", "=", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.robustml.robustml_fmnist.Model.dataset": [[28, 31], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.robustml.robustml_fmnist.Model.threat_model": [[32, 35], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "threat_model", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_threat_model", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.robustml.robustml_fmnist.Model.classify": [[36, 40], ["robustml_fmnist.Model.model.predict", "robustml_fmnist.Model.argmax"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict"], ["", "def", "classify", "(", "self", ",", "x", ")", ":", "\n", "        ", "predictions", "=", "self", ".", "model", ".", "predict", "(", "x", ")", "\n", "pred_label", "=", "predictions", ".", "argmax", "(", ")", "# label as a number", "\n", "return", "pred_label", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.robustml.robustml_fmnist.load_model": [[8, 18], ["range", "classifiers.OneVsAllClassifier", "classifiers.OneVsAllClassifier.load", "ensembles.append", "tree_ensemble.TreeEnsemble"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.load"], ["def", "load_model", "(", "model_path", ")", ":", "\n", "    ", "n_classifiers", ",", "weak_learner", ",", "ensembles", "=", "10", ",", "'tree'", ",", "[", "]", "\n", "\n", "for", "i_clsf", "in", "range", "(", "n_classifiers", ")", ":", "\n", "# hyperparameters are not important when loading", "\n", "        ", "ensembles", ".", "append", "(", "TreeEnsemble", "(", "weak_learner", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ")", ")", "\n", "\n", "", "model_ova", "=", "OneVsAllClassifier", "(", "ensembles", ")", "\n", "model_ova", ".", "load", "(", "model_path", ")", "\n", "return", "model_ova", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.robustml.robustml_mnist.Model.__init__": [[21, 27], ["robustml_mnist.load_model", "robustml.dataset.MNIST", "robustml.threat_model.Linf"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.robustml.robustml_mnist.load_model"], ["    ", "def", "__init__", "(", "self", ",", "sess", ")", ":", "\n", "        ", "model_path", "=", "\"models/models_trees_multiclass/2019-08-05 21:02:49 dataset=mnist weak_learner=tree model=robust_bound n_train=-1 n_trials_coord=784 eps=0.300 max_depth=30 lr=0.05.model.npy\"", "\n", "self", ".", "model", "=", "load_model", "(", "model_path", ")", "\n", "\n", "self", ".", "_dataset", "=", "robustml", ".", "dataset", ".", "MNIST", "(", ")", "\n", "self", ".", "_threat_model", "=", "robustml", ".", "threat_model", ".", "Linf", "(", "epsilon", "=", "0.3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.robustml.robustml_mnist.Model.dataset": [[28, 31], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dataset", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.robustml.robustml_mnist.Model.threat_model": [[32, 35], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "threat_model", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_threat_model", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.robustml.robustml_mnist.Model.classify": [[36, 40], ["robustml_mnist.Model.model.predict", "robustml_mnist.Model.argmax"], "methods", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.predict"], ["", "def", "classify", "(", "self", ",", "x", ")", ":", "\n", "        ", "predictions", "=", "self", ".", "model", ".", "predict", "(", "x", ")", "\n", "pred_label", "=", "predictions", ".", "argmax", "(", ")", "# label as a number", "\n", "return", "pred_label", "\n", "\n"]], "home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.robustml.robustml_mnist.load_model": [[8, 18], ["range", "classifiers.OneVsAllClassifier", "classifiers.OneVsAllClassifier.load", "ensembles.append", "tree_ensemble.TreeEnsemble"], "function", ["home.repos.pwc.inspect_result.max-andr_provably-robust-boosting.None.stump_ensemble.StumpEnsemble.load"], ["def", "load_model", "(", "model_path", ")", ":", "\n", "    ", "n_classifiers", ",", "weak_learner", ",", "ensembles", "=", "10", ",", "'tree'", ",", "[", "]", "\n", "\n", "for", "i_clsf", "in", "range", "(", "n_classifiers", ")", ":", "\n", "# hyperparameters are not important when loading", "\n", "        ", "ensembles", ".", "append", "(", "TreeEnsemble", "(", "weak_learner", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ")", ")", "\n", "\n", "", "model_ova", "=", "OneVsAllClassifier", "(", "ensembles", ")", "\n", "model_ova", ".", "load", "(", "model_path", ")", "\n", "return", "model_ova", "\n", "\n"]]}