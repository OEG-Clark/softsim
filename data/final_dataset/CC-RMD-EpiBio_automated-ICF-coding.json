{"home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.InputExample.__init__": [[130, 146], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "    ", "\"\"\"Constructs a InputExample.\n\n    Args:\n      guid: Unique id for the example.\n      text_a: string. The untokenized text of the first sequence. For single\n        sequence tasks, only this sequence must be specified.\n      text_b: (Optional) string. The untokenized text of the second sequence.\n        Only must be specified for sequence pair tasks.\n      label: (Optional) string. The label of the example. This should be\n        specified for train and dev examples, but not for test examples.\n    \"\"\"", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.InputFeatures.__init__": [[164, 175], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "input_ids", ",", "\n", "input_mask", ",", "\n", "segment_ids", ",", "\n", "label_id", ",", "\n", "is_real_example", "=", "True", ")", ":", "\n", "    ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "label_id", "=", "label_id", "\n", "self", ".", "is_real_example", "=", "is_real_example", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor.get_train_examples": [[180, 183], ["NotImplementedError"], "methods", ["None"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor.get_dev_examples": [[184, 187], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor.get_test_examples": [[188, 191], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"Gets a collection of `InputExample`s for prediction.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor.get_labels": [[192, 195], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "    ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor._read_tsv": [[196, 205], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_read_tsv", "(", "cls", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "    ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "      ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "        ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.XnliProcessor.__init__": [[210, 212], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "self", ".", "language", "=", "\"zh\"", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.XnliProcessor.get_train_examples": [[213, 231], ["modified_BERT_run_classifier.XnliProcessor._read_tsv", "enumerate", "os.path.join", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "examples.append", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "modified_BERT_run_classifier.InputExample"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "lines", "=", "self", ".", "_read_tsv", "(", "\n", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"multinli\"", ",", "\n", "\"multinli.train.%s.tsv\"", "%", "self", ".", "language", ")", ")", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "      ", "if", "i", "==", "0", ":", "\n", "        ", "continue", "\n", "", "guid", "=", "\"train-%d\"", "%", "(", "i", ")", "\n", "text_a", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "0", "]", ")", "\n", "text_b", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "1", "]", ")", "\n", "label", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "2", "]", ")", "\n", "if", "label", "==", "tokenization", ".", "convert_to_unicode", "(", "\"contradictory\"", ")", ":", "\n", "        ", "label", "=", "tokenization", ".", "convert_to_unicode", "(", "\"contradiction\"", ")", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.XnliProcessor.get_dev_examples": [[232, 249], ["modified_BERT_run_classifier.XnliProcessor._read_tsv", "enumerate", "os.path.join", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "examples.append", "tokenization.convert_to_unicode", "modified_BERT_run_classifier.InputExample"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "lines", "=", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"xnli.dev.tsv\"", ")", ")", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "      ", "if", "i", "==", "0", ":", "\n", "        ", "continue", "\n", "", "guid", "=", "\"dev-%d\"", "%", "(", "i", ")", "\n", "language", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "0", "]", ")", "\n", "if", "language", "!=", "tokenization", ".", "convert_to_unicode", "(", "self", ".", "language", ")", ":", "\n", "        ", "continue", "\n", "", "text_a", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "6", "]", ")", "\n", "text_b", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "7", "]", ")", "\n", "label", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "1", "]", ")", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.XnliProcessor.get_labels": [[250, 253], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"contradiction\"", ",", "\"entailment\"", ",", "\"neutral\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.MnliProcessor.get_train_examples": [[258, 262], ["modified_BERT_run_classifier.MnliProcessor._create_examples", "modified_BERT_run_classifier.MnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor._create_examples", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor._read_tsv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.MnliProcessor.get_dev_examples": [[263, 268], ["modified_BERT_run_classifier.MnliProcessor._create_examples", "modified_BERT_run_classifier.MnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor._create_examples", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev_matched.tsv\"", ")", ")", ",", "\n", "\"dev_matched\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.MnliProcessor.get_test_examples": [[269, 273], ["modified_BERT_run_classifier.MnliProcessor._create_examples", "modified_BERT_run_classifier.MnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor._create_examples", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor._read_tsv"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test_matched.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.MnliProcessor.get_labels": [[274, 277], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"contradiction\"", ",", "\"entailment\"", ",", "\"neutral\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.MnliProcessor._create_examples": [[278, 294], ["enumerate", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "examples.append", "tokenization.convert_to_unicode", "modified_BERT_run_classifier.InputExample", "tokenization.convert_to_unicode"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "    ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "      ", "if", "i", "==", "0", ":", "\n", "        ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "0", "]", ")", ")", "\n", "text_a", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "8", "]", ")", "\n", "text_b", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "9", "]", ")", "\n", "if", "set_type", "==", "\"test\"", ":", "\n", "        ", "label", "=", "\"contradiction\"", "\n", "", "else", ":", "\n", "        ", "label", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "-", "1", "]", ")", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.MrpcProcessor.get_train_examples": [[299, 303], ["modified_BERT_run_classifier.MrpcProcessor._create_examples", "modified_BERT_run_classifier.MrpcProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor._create_examples", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor._read_tsv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.MrpcProcessor.get_dev_examples": [[304, 308], ["modified_BERT_run_classifier.MrpcProcessor._create_examples", "modified_BERT_run_classifier.MrpcProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor._create_examples", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.MrpcProcessor.get_test_examples": [[309, 313], ["modified_BERT_run_classifier.MrpcProcessor._create_examples", "modified_BERT_run_classifier.MrpcProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor._create_examples", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor._read_tsv"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.MrpcProcessor.get_labels": [[314, 317], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.MrpcProcessor._create_examples": [[318, 334], ["enumerate", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "examples.append", "tokenization.convert_to_unicode", "modified_BERT_run_classifier.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "    ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "      ", "if", "i", "==", "0", ":", "\n", "        ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text_a", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "3", "]", ")", "\n", "text_b", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "4", "]", ")", "\n", "if", "set_type", "==", "\"test\"", ":", "\n", "        ", "label", "=", "\"0\"", "\n", "", "else", ":", "\n", "        ", "label", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "0", "]", ")", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ColaProcessor.get_train_examples": [[339, 343], ["modified_BERT_run_classifier.ColaProcessor._create_examples", "modified_BERT_run_classifier.ColaProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor._create_examples", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor._read_tsv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ColaProcessor.get_dev_examples": [[344, 348], ["modified_BERT_run_classifier.ColaProcessor._create_examples", "modified_BERT_run_classifier.ColaProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor._create_examples", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ColaProcessor.get_test_examples": [[349, 353], ["modified_BERT_run_classifier.ColaProcessor._create_examples", "modified_BERT_run_classifier.ColaProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor._create_examples", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor._read_tsv"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ColaProcessor.get_labels": [[354, 357], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ColaProcessor._create_examples": [[358, 375], ["enumerate", "examples.append", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "modified_BERT_run_classifier.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "    ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "# Only the test set has a header", "\n", "      ", "if", "set_type", "==", "\"test\"", "and", "i", "==", "0", ":", "\n", "        ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "if", "set_type", "==", "\"test\"", ":", "\n", "        ", "text_a", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "1", "]", ")", "\n", "label", "=", "\"0\"", "\n", "", "else", ":", "\n", "        ", "text_a", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "3", "]", ")", "\n", "label", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "1", "]", ")", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor.get_train_examples": [[381, 385], ["modified_BERT_run_classifier.ICFMobilityProcessor._create_examples", "modified_BERT_run_classifier.ICFMobilityProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor._create_examples", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor._read_tsv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor.get_dev_examples": [[386, 390], ["modified_BERT_run_classifier.ICFMobilityProcessor._create_examples", "modified_BERT_run_classifier.ICFMobilityProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor._create_examples", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor.get_test_examples": [[391, 395], ["modified_BERT_run_classifier.ICFMobilityProcessor._create_examples", "modified_BERT_run_classifier.ICFMobilityProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor._create_examples", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.DataProcessor._read_tsv"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor.get_labels": [[396, 412], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "    ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\n", "'d410'", ",", "\n", "'d415'", ",", "\n", "'d420'", ",", "\n", "'d430'", ",", "\n", "'d435'", ",", "\n", "'d440'", ",", "\n", "'d445'", ",", "\n", "'d450'", ",", "\n", "'d455'", ",", "\n", "'d460'", ",", "\n", "'d470'", ",", "\n", "'d475'", ",", "\n", "'no_code'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor._create_examples": [[414, 431], ["enumerate", "examples.append", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "modified_BERT_run_classifier.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "    ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "# All sets have a header", "\n", "      ", "if", "i", "==", "0", ":", "\n", "        ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", "-", "1", ")", "\n", "if", "set_type", "==", "\"test\"", ":", "\n", "        ", "text_a", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "1", "]", ")", "\n", "label", "=", "\"no_code\"", "\n", "", "else", ":", "\n", "        ", "text_a", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "1", "]", ")", "\n", "label", "=", "tokenization", ".", "convert_to_unicode", "(", "line", "[", "2", "]", ")", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.convert_single_example": [[434, 534], ["isinstance", "enumerate", "tokenizer.tokenize", "tokens.append", "segment_ids.append", "tokens.append", "segment_ids.append", "tokenizer.convert_tokens_to_ids", "modified_BERT_run_classifier.InputFeatures", "modified_BERT_run_classifier.InputFeatures", "tokenizer.tokenize", "modified_BERT_run_classifier._truncate_seq_pair", "tokens.append", "segment_ids.append", "tokens.append", "segment_ids.append", "len", "len", "tokenizer.convert_tokens_to_ids.append", "input_mask.append", "segment_ids.append", "len", "len", "len", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "len", "tokens.append", "segment_ids.append", "tokenization.printable_text", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier._truncate_seq_pair"], ["", "", "def", "convert_single_example", "(", "ex_index", ",", "example", ",", "label_list", ",", "max_seq_length", ",", "\n", "tokenizer", ")", ":", "\n", "  ", "\"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"", "\n", "\n", "if", "isinstance", "(", "example", ",", "PaddingInputExample", ")", ":", "\n", "    ", "return", "InputFeatures", "(", "\n", "input_ids", "=", "[", "0", "]", "*", "max_seq_length", ",", "\n", "input_mask", "=", "[", "0", "]", "*", "max_seq_length", ",", "\n", "segment_ids", "=", "[", "0", "]", "*", "max_seq_length", ",", "\n", "label_id", "=", "0", ",", "\n", "is_real_example", "=", "False", ")", "\n", "\n", "", "label_map", "=", "{", "}", "\n", "for", "(", "i", ",", "label", ")", "in", "enumerate", "(", "label_list", ")", ":", "\n", "    ", "label_map", "[", "label", "]", "=", "i", "\n", "\n", "", "tokens_a", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "    ", "tokens_b", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "\n", "", "if", "tokens_b", ":", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total", "\n", "# length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "    ", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "    ", "if", "len", "(", "tokens_a", ")", ">", "max_seq_length", "-", "2", ":", "\n", "      ", "tokens_a", "=", "tokens_a", "[", "0", ":", "(", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "# The convention in BERT is:", "\n", "# (a) For sequence pairs:", "\n", "#  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]", "\n", "#  type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1", "\n", "# (b) For single sequences:", "\n", "#  tokens:   [CLS] the dog is hairy . [SEP]", "\n", "#  type_ids: 0     0   0   0  0     0 0", "\n", "#", "\n", "# Where \"type_ids\" are used to indicate whether this is the first", "\n", "# sequence or the second sequence. The embedding vectors for `type=0` and", "\n", "# `type=1` were learned during pre-training and are added to the wordpiece", "\n", "# embedding vector (and position vector). This is not *strictly* necessary", "\n", "# since the [SEP] token unambiguously separates the sequences, but it makes", "\n", "# it easier for the model to learn the concept of sequences.", "\n", "#", "\n", "# For classification tasks, the first vector (corresponding to [CLS]) is", "\n", "# used as the \"sentence vector\". Note that this only makes sense because", "\n", "# the entire model is fine-tuned.", "\n", "", "", "tokens", "=", "[", "]", "\n", "segment_ids", "=", "[", "]", "\n", "tokens", ".", "append", "(", "\"[CLS]\"", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "for", "token", "in", "tokens_a", ":", "\n", "    ", "tokens", ".", "append", "(", "token", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "", "tokens", ".", "append", "(", "\"[SEP]\"", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "    ", "for", "token", "in", "tokens_b", ":", "\n", "      ", "tokens", ".", "append", "(", "token", ")", "\n", "segment_ids", ".", "append", "(", "1", ")", "\n", "", "tokens", ".", "append", "(", "\"[SEP]\"", ")", "\n", "segment_ids", ".", "append", "(", "1", ")", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "while", "len", "(", "input_ids", ")", "<", "max_seq_length", ":", "\n", "    ", "input_ids", ".", "append", "(", "0", ")", "\n", "input_mask", ".", "append", "(", "0", ")", "\n", "segment_ids", ".", "append", "(", "0", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "\n", "label_id", "=", "label_map", "[", "example", ".", "label", "]", "\n", "if", "ex_index", "<", "5", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "\n", "[", "tokenization", ".", "printable_text", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"label: %s (id = %d)\"", "%", "(", "example", ".", "label", ",", "label_id", ")", ")", "\n", "\n", "", "feature", "=", "InputFeatures", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "label_id", "=", "label_id", ",", "\n", "is_real_example", "=", "True", ")", "\n", "return", "feature", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.file_based_convert_examples_to_features": [[536, 564], ["tensorflow.python_io.TFRecordWriter", "enumerate", "tf.python_io.TFRecordWriter.close", "modified_BERT_run_classifier.convert_single_example", "collections.OrderedDict", "modified_BERT_run_classifier.file_based_convert_examples_to_features.create_int_feature"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.convert_single_example"], ["", "def", "file_based_convert_examples_to_features", "(", "\n", "examples", ",", "label_list", ",", "max_seq_length", ",", "tokenizer", ",", "output_file", ")", ":", "\n", "  ", "\"\"\"Convert a set of `InputExample`s to a TFRecord file.\"\"\"", "\n", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "output_file", ")", "\n", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "    ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "\"Writing example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "examples", ")", ")", ")", "\n", "\n", "", "feature", "=", "convert_single_example", "(", "ex_index", ",", "example", ",", "label_list", ",", "\n", "max_seq_length", ",", "tokenizer", ")", "\n", "\n", "def", "create_int_feature", "(", "values", ")", ":", "\n", "      ", "f", "=", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "list", "(", "values", ")", ")", ")", "\n", "return", "f", "\n", "\n", "", "features", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "features", "[", "\"input_ids\"", "]", "=", "create_int_feature", "(", "feature", ".", "input_ids", ")", "\n", "features", "[", "\"input_mask\"", "]", "=", "create_int_feature", "(", "feature", ".", "input_mask", ")", "\n", "features", "[", "\"segment_ids\"", "]", "=", "create_int_feature", "(", "feature", ".", "segment_ids", ")", "\n", "features", "[", "\"label_ids\"", "]", "=", "create_int_feature", "(", "[", "feature", ".", "label_id", "]", ")", "\n", "features", "[", "\"is_real_example\"", "]", "=", "create_int_feature", "(", "\n", "[", "int", "(", "feature", ".", "is_real_example", ")", "]", ")", "\n", "\n", "tf_example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "features", ")", ")", "\n", "writer", ".", "write", "(", "tf_example", ".", "SerializeToString", "(", ")", ")", "\n", "", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.file_based_input_fn_builder": [[566, 612], ["tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.parse_single_example", "list", "tensorflow.data.TFRecordDataset", "d.shuffle.apply", "tf.parse_single_example.keys", "d.shuffle.repeat", "d.shuffle.shuffle", "tensorflow.contrib.data.map_and_batch", "tensorflow.to_int32", "modified_BERT_run_classifier.file_based_input_fn_builder._decode_record"], "function", ["None"], ["", "def", "file_based_input_fn_builder", "(", "input_file", ",", "seq_length", ",", "is_training", ",", "\n", "drop_remainder", ")", ":", "\n", "  ", "\"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"", "\n", "\n", "name_to_features", "=", "{", "\n", "\"input_ids\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "seq_length", "]", ",", "tf", ".", "int64", ")", ",", "\n", "\"input_mask\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "seq_length", "]", ",", "tf", ".", "int64", ")", ",", "\n", "\"segment_ids\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "seq_length", "]", ",", "tf", ".", "int64", ")", ",", "\n", "\"label_ids\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "int64", ")", ",", "\n", "\"is_real_example\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "int64", ")", ",", "\n", "}", "\n", "\n", "def", "_decode_record", "(", "record", ",", "name_to_features", ")", ":", "\n", "    ", "\"\"\"Decodes a record to a TensorFlow example.\"\"\"", "\n", "example", "=", "tf", ".", "parse_single_example", "(", "record", ",", "name_to_features", ")", "\n", "\n", "# tf.Example only supports tf.int64, but the TPU only supports tf.int32.", "\n", "# So cast all int64 to int32.", "\n", "for", "name", "in", "list", "(", "example", ".", "keys", "(", ")", ")", ":", "\n", "      ", "t", "=", "example", "[", "name", "]", "\n", "if", "t", ".", "dtype", "==", "tf", ".", "int64", ":", "\n", "        ", "t", "=", "tf", ".", "to_int32", "(", "t", ")", "\n", "", "example", "[", "name", "]", "=", "t", "\n", "\n", "", "return", "example", "\n", "\n", "", "def", "input_fn", "(", "params", ")", ":", "\n", "    ", "\"\"\"The actual input function.\"\"\"", "\n", "batch_size", "=", "params", "[", "\"batch_size\"", "]", "\n", "\n", "# For training, we want a lot of parallel reading and shuffling.", "\n", "# For eval, we want no shuffling and parallel reading doesn't matter.", "\n", "d", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "input_file", ")", "\n", "if", "is_training", ":", "\n", "      ", "d", "=", "d", ".", "repeat", "(", ")", "\n", "d", "=", "d", ".", "shuffle", "(", "buffer_size", "=", "100", ")", "\n", "\n", "", "d", "=", "d", ".", "apply", "(", "\n", "tf", ".", "contrib", ".", "data", ".", "map_and_batch", "(", "\n", "lambda", "record", ":", "_decode_record", "(", "record", ",", "name_to_features", ")", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "drop_remainder", "=", "drop_remainder", ")", ")", "\n", "\n", "return", "d", "\n", "\n", "", "return", "input_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier._truncate_seq_pair": [[614, 629], ["len", "len", "len", "len", "tokens_a.pop", "tokens_b.pop"], "function", ["None"], ["", "def", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_length", ")", ":", "\n", "  ", "\"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"", "\n", "\n", "# This is a simple heuristic which will always truncate the longer sequence", "\n", "# one token at a time. This makes more sense than truncating an equal percent", "\n", "# of tokens from each, since if one sequence is very short then each token", "\n", "# that's truncated likely contains more information than a longer sequence.", "\n", "while", "True", ":", "\n", "    ", "total_length", "=", "len", "(", "tokens_a", ")", "+", "len", "(", "tokens_b", ")", "\n", "if", "total_length", "<=", "max_length", ":", "\n", "      ", "break", "\n", "", "if", "len", "(", "tokens_a", ")", ">", "len", "(", "tokens_b", ")", ":", "\n", "      ", "tokens_a", ".", "pop", "(", ")", "\n", "", "else", ":", "\n", "      ", "tokens_b", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.create_model": [[631, 674], ["modeling.BertModel", "modeling.BertModel.get_pooled_output", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.variable_scope", "tensorflow.matmul", "tensorflow.nn.bias_add", "tensorflow.nn.softmax", "tensorflow.nn.log_softmax", "tensorflow.one_hot", "tensorflow.reduce_mean", "tensorflow.truncated_normal_initializer", "tensorflow.zeros_initializer", "tensorflow.nn.dropout", "tensorflow.reduce_sum"], "function", ["None"], ["", "", "", "def", "create_model", "(", "bert_config", ",", "is_training", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "\n", "labels", ",", "num_labels", ",", "use_one_hot_embeddings", ")", ":", "\n", "  ", "\"\"\"Creates a classification model.\"\"\"", "\n", "model", "=", "modeling", ".", "BertModel", "(", "\n", "config", "=", "bert_config", ",", "\n", "is_training", "=", "is_training", ",", "\n", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "token_type_ids", "=", "segment_ids", ",", "\n", "use_one_hot_embeddings", "=", "use_one_hot_embeddings", ")", "\n", "\n", "# In the demo, we are doing a simple classification task on the entire", "\n", "# segment.", "\n", "#", "\n", "# If you want to use the token-level output, use model.get_sequence_output()", "\n", "# instead.", "\n", "output_layer", "=", "model", ".", "get_pooled_output", "(", ")", "\n", "\n", "hidden_size", "=", "output_layer", ".", "shape", "[", "-", "1", "]", ".", "value", "\n", "\n", "output_weights", "=", "tf", ".", "get_variable", "(", "\n", "\"output_weights\"", ",", "[", "num_labels", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.02", ")", ")", "\n", "\n", "output_bias", "=", "tf", ".", "get_variable", "(", "\n", "\"output_bias\"", ",", "[", "num_labels", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"loss\"", ")", ":", "\n", "    ", "if", "is_training", ":", "\n", "# I.e., 0.1 dropout", "\n", "      ", "output_layer", "=", "tf", ".", "nn", ".", "dropout", "(", "output_layer", ",", "keep_prob", "=", "0.9", ")", "\n", "\n", "", "logits", "=", "tf", ".", "matmul", "(", "output_layer", ",", "output_weights", ",", "transpose_b", "=", "True", ")", "\n", "logits", "=", "tf", ".", "nn", ".", "bias_add", "(", "logits", ",", "output_bias", ")", "\n", "probabilities", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ",", "axis", "=", "-", "1", ")", "\n", "log_probs", "=", "tf", ".", "nn", ".", "log_softmax", "(", "logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "one_hot_labels", "=", "tf", ".", "one_hot", "(", "labels", ",", "depth", "=", "num_labels", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "per_example_loss", "=", "-", "tf", ".", "reduce_sum", "(", "one_hot_labels", "*", "log_probs", ",", "axis", "=", "-", "1", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "per_example_loss", ")", "\n", "\n", "return", "(", "loss", ",", "per_example_loss", ",", "logits", ",", "probabilities", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.model_fn_builder": [[676, 766], ["tensorflow.logging.info", "sorted", "modified_BERT_run_classifier.create_model", "tensorflow.trainable_variables", "tensorflow.logging.info", "features.keys", "tensorflow.logging.info", "tensorflow.cast", "tensorflow.ones", "modeling.get_assignment_map_from_checkpoint", "tensorflow.logging.info", "optimization.create_optimizer", "tensorflow.contrib.tpu.TPUEstimatorSpec", "tensorflow.shape", "tensorflow.train.init_from_checkpoint", "tensorflow.contrib.tpu.TPUEstimatorSpec", "tensorflow.contrib.tpu.TPUEstimatorSpec", "tensorflow.train.init_from_checkpoint", "tensorflow.train.Scaffold", "tensorflow.argmax", "tensorflow.metrics.accuracy", "tensorflow.metrics.mean"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.create_model"], ["", "", "def", "model_fn_builder", "(", "bert_config", ",", "num_labels", ",", "init_checkpoint", ",", "learning_rate", ",", "\n", "num_train_steps", ",", "num_warmup_steps", ",", "use_tpu", ",", "\n", "use_one_hot_embeddings", ")", ":", "\n", "  ", "\"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"", "\n", "\n", "def", "model_fn", "(", "features", ",", "labels", ",", "mode", ",", "params", ")", ":", "# pylint: disable=unused-argument", "\n", "    ", "\"\"\"The `model_fn` for TPUEstimator.\"\"\"", "\n", "\n", "tf", ".", "logging", ".", "info", "(", "\"*** Features ***\"", ")", "\n", "for", "name", "in", "sorted", "(", "features", ".", "keys", "(", ")", ")", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "\"  name = %s, shape = %s\"", "%", "(", "name", ",", "features", "[", "name", "]", ".", "shape", ")", ")", "\n", "\n", "", "input_ids", "=", "features", "[", "\"input_ids\"", "]", "\n", "input_mask", "=", "features", "[", "\"input_mask\"", "]", "\n", "segment_ids", "=", "features", "[", "\"segment_ids\"", "]", "\n", "label_ids", "=", "features", "[", "\"label_ids\"", "]", "\n", "is_real_example", "=", "None", "\n", "if", "\"is_real_example\"", "in", "features", ":", "\n", "      ", "is_real_example", "=", "tf", ".", "cast", "(", "features", "[", "\"is_real_example\"", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "      ", "is_real_example", "=", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "label_ids", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "is_training", "=", "(", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "\n", "(", "total_loss", ",", "per_example_loss", ",", "logits", ",", "probabilities", ")", "=", "create_model", "(", "\n", "bert_config", ",", "is_training", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", ",", "\n", "num_labels", ",", "use_one_hot_embeddings", ")", "\n", "\n", "tvars", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "initialized_variable_names", "=", "{", "}", "\n", "scaffold_fn", "=", "None", "\n", "if", "init_checkpoint", ":", "\n", "      ", "(", "assignment_map", ",", "initialized_variable_names", "\n", ")", "=", "modeling", ".", "get_assignment_map_from_checkpoint", "(", "tvars", ",", "init_checkpoint", ")", "\n", "if", "use_tpu", ":", "\n", "\n", "        ", "def", "tpu_scaffold", "(", ")", ":", "\n", "          ", "tf", ".", "train", ".", "init_from_checkpoint", "(", "init_checkpoint", ",", "assignment_map", ")", "\n", "return", "tf", ".", "train", ".", "Scaffold", "(", ")", "\n", "\n", "", "scaffold_fn", "=", "tpu_scaffold", "\n", "", "else", ":", "\n", "        ", "tf", ".", "train", ".", "init_from_checkpoint", "(", "init_checkpoint", ",", "assignment_map", ")", "\n", "\n", "", "", "tf", ".", "logging", ".", "info", "(", "\"**** Trainable Variables ****\"", ")", "\n", "for", "var", "in", "tvars", ":", "\n", "      ", "init_string", "=", "\"\"", "\n", "if", "var", ".", "name", "in", "initialized_variable_names", ":", "\n", "        ", "init_string", "=", "\", *INIT_FROM_CKPT*\"", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"  name = %s, shape = %s%s\"", ",", "var", ".", "name", ",", "var", ".", "shape", ",", "\n", "init_string", ")", "\n", "\n", "", "output_spec", "=", "None", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ":", "\n", "\n", "      ", "train_op", "=", "optimization", ".", "create_optimizer", "(", "\n", "total_loss", ",", "learning_rate", ",", "num_train_steps", ",", "num_warmup_steps", ",", "use_tpu", ")", "\n", "\n", "output_spec", "=", "tf", ".", "contrib", ".", "tpu", ".", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "total_loss", ",", "\n", "train_op", "=", "train_op", ",", "\n", "scaffold_fn", "=", "scaffold_fn", ")", "\n", "", "elif", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ":", "\n", "\n", "      ", "def", "metric_fn", "(", "per_example_loss", ",", "label_ids", ",", "logits", ",", "is_real_example", ")", ":", "\n", "        ", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "-", "1", ",", "output_type", "=", "tf", ".", "int32", ")", "\n", "accuracy", "=", "tf", ".", "metrics", ".", "accuracy", "(", "\n", "labels", "=", "label_ids", ",", "predictions", "=", "predictions", ",", "weights", "=", "is_real_example", ")", "\n", "loss", "=", "tf", ".", "metrics", ".", "mean", "(", "values", "=", "per_example_loss", ",", "weights", "=", "is_real_example", ")", "\n", "return", "{", "\n", "\"eval_accuracy\"", ":", "accuracy", ",", "\n", "\"eval_loss\"", ":", "loss", ",", "\n", "}", "\n", "\n", "", "eval_metrics", "=", "(", "metric_fn", ",", "\n", "[", "per_example_loss", ",", "label_ids", ",", "logits", ",", "is_real_example", "]", ")", "\n", "output_spec", "=", "tf", ".", "contrib", ".", "tpu", ".", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "loss", "=", "total_loss", ",", "\n", "eval_metrics", "=", "eval_metrics", ",", "\n", "scaffold_fn", "=", "scaffold_fn", ")", "\n", "", "else", ":", "\n", "      ", "output_spec", "=", "tf", ".", "contrib", ".", "tpu", ".", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "\n", "predictions", "=", "{", "\"probabilities\"", ":", "probabilities", "}", ",", "\n", "scaffold_fn", "=", "scaffold_fn", ")", "\n", "", "return", "output_spec", "\n", "\n", "", "return", "model_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.input_fn_builder": [[770, 820], ["all_input_ids.append", "all_input_mask.append", "all_segment_ids.append", "all_label_ids.append", "len", "tensorflow.data.Dataset.from_tensor_slices", "d.shuffle.batch", "d.shuffle.repeat", "d.shuffle.shuffle", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant"], "function", ["None"], ["", "def", "input_fn_builder", "(", "features", ",", "seq_length", ",", "is_training", ",", "drop_remainder", ")", ":", "\n", "  ", "\"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"", "\n", "\n", "all_input_ids", "=", "[", "]", "\n", "all_input_mask", "=", "[", "]", "\n", "all_segment_ids", "=", "[", "]", "\n", "all_label_ids", "=", "[", "]", "\n", "\n", "for", "feature", "in", "features", ":", "\n", "    ", "all_input_ids", ".", "append", "(", "feature", ".", "input_ids", ")", "\n", "all_input_mask", ".", "append", "(", "feature", ".", "input_mask", ")", "\n", "all_segment_ids", ".", "append", "(", "feature", ".", "segment_ids", ")", "\n", "all_label_ids", ".", "append", "(", "feature", ".", "label_id", ")", "\n", "\n", "", "def", "input_fn", "(", "params", ")", ":", "\n", "    ", "\"\"\"The actual input function.\"\"\"", "\n", "batch_size", "=", "params", "[", "\"batch_size\"", "]", "\n", "\n", "num_examples", "=", "len", "(", "features", ")", "\n", "\n", "# This is for demo purposes and does NOT scale to large data sets. We do", "\n", "# not use Dataset.from_generator() because that uses tf.py_func which is", "\n", "# not TPU compatible. The right way to load data is with TFRecordReader.", "\n", "d", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "{", "\n", "\"input_ids\"", ":", "\n", "tf", ".", "constant", "(", "\n", "all_input_ids", ",", "shape", "=", "[", "num_examples", ",", "seq_length", "]", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "\"input_mask\"", ":", "\n", "tf", ".", "constant", "(", "\n", "all_input_mask", ",", "\n", "shape", "=", "[", "num_examples", ",", "seq_length", "]", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "\"segment_ids\"", ":", "\n", "tf", ".", "constant", "(", "\n", "all_segment_ids", ",", "\n", "shape", "=", "[", "num_examples", ",", "seq_length", "]", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "\"label_ids\"", ":", "\n", "tf", ".", "constant", "(", "all_label_ids", ",", "shape", "=", "[", "num_examples", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "}", ")", "\n", "\n", "if", "is_training", ":", "\n", "      ", "d", "=", "d", ".", "repeat", "(", ")", "\n", "d", "=", "d", ".", "shuffle", "(", "buffer_size", "=", "100", ")", "\n", "\n", "", "d", "=", "d", ".", "batch", "(", "batch_size", "=", "batch_size", ",", "drop_remainder", "=", "drop_remainder", ")", "\n", "return", "d", "\n", "\n", "", "return", "input_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.convert_examples_to_features": [[824, 838], ["enumerate", "modified_BERT_run_classifier.convert_single_example", "features.append", "tensorflow.logging.info", "len"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.convert_single_example"], ["", "def", "convert_examples_to_features", "(", "examples", ",", "label_list", ",", "max_seq_length", ",", "\n", "tokenizer", ")", ":", "\n", "  ", "\"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "    ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "\"Writing example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "examples", ")", ")", ")", "\n", "\n", "", "feature", "=", "convert_single_example", "(", "ex_index", ",", "example", ",", "label_list", ",", "\n", "max_seq_length", ",", "tokenizer", ")", "\n", "\n", "features", ".", "append", "(", "feature", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.main": [[840, 1032], ["tensorflow.logging.set_verbosity", "tokenization.validate_case_matches_checkpoint", "modeling.BertConfig.from_json_file", "tensorflow.gfile.MakeDirs", "FLAGS.task_name.lower", "processor.get_labels", "tokenization.FullTokenizer", "tensorflow.contrib.tpu.RunConfig", "modified_BERT_run_classifier.model_fn_builder", "tensorflow.contrib.tpu.TPUEstimator", "ValueError", "ValueError", "ValueError", "tensorflow.contrib.cluster_resolver.TPUClusterResolver", "processor.get_train_examples", "int", "int", "os.path.join", "modified_BERT_run_classifier.file_based_convert_examples_to_features", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "modified_BERT_run_classifier.file_based_input_fn_builder", "tf.contrib.tpu.TPUEstimator.train", "processor.get_dev_examples", "len", "os.path.join", "modified_BERT_run_classifier.file_based_convert_examples_to_features", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "modified_BERT_run_classifier.file_based_input_fn_builder", "tf.contrib.tpu.TPUEstimator.evaluate", "os.path.join", "processor.get_test_examples", "len", "os.path.join", "modified_BERT_run_classifier.file_based_convert_examples_to_features", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "modified_BERT_run_classifier.file_based_input_fn_builder", "tf.contrib.tpu.TPUEstimator.predict", "os.path.join", "tensorflow.contrib.tpu.TPUConfig", "len", "len", "len", "int", "tensorflow.gfile.GFile", "tensorflow.logging.info", "sorted", "len", "tensorflow.gfile.GFile", "tensorflow.logging.info", "enumerate", "processor.get_dev_examples.append", "len", "estimator.predict.keys", "tensorflow.logging.info", "writer.write", "processor.get_test_examples.append", "len", "writer.write", "len", "len", "modified_BERT_run_classifier.PaddingInputExample", "len", "len", "str", "len", "modified_BERT_run_classifier.PaddingInputExample", "str", "str"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor.get_labels", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.model_fn_builder", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor.get_train_examples", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.file_based_convert_examples_to_features", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.file_based_input_fn_builder", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor.get_dev_examples", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.file_based_convert_examples_to_features", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.file_based_input_fn_builder", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.ICFMobilityProcessor.get_test_examples", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.file_based_convert_examples_to_features", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.modified_BERT_run_classifier.file_based_input_fn_builder", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write"], ["", "def", "main", "(", "_", ")", ":", "\n", "  ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "processors", "=", "{", "\n", "\"cola\"", ":", "ColaProcessor", ",", "\n", "\"mnli\"", ":", "MnliProcessor", ",", "\n", "\"mrpc\"", ":", "MrpcProcessor", ",", "\n", "\"xnli\"", ":", "XnliProcessor", ",", "\n", "\"icfmobility\"", ":", "ICFMobilityProcessor", ",", "\n", "}", "\n", "\n", "tokenization", ".", "validate_case_matches_checkpoint", "(", "FLAGS", ".", "do_lower_case", ",", "\n", "FLAGS", ".", "init_checkpoint", ")", "\n", "\n", "if", "not", "FLAGS", ".", "do_train", "and", "not", "FLAGS", ".", "do_eval", "and", "not", "FLAGS", ".", "do_predict", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"At least one of `do_train`, `do_eval` or `do_predict' must be True.\"", ")", "\n", "\n", "", "bert_config", "=", "modeling", ".", "BertConfig", ".", "from_json_file", "(", "FLAGS", ".", "bert_config_file", ")", "\n", "\n", "if", "FLAGS", ".", "max_seq_length", ">", "bert_config", ".", "max_position_embeddings", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"Cannot use sequence length %d because the BERT model \"", "\n", "\"was only trained up to sequence length %d\"", "%", "\n", "(", "FLAGS", ".", "max_seq_length", ",", "bert_config", ".", "max_position_embeddings", ")", ")", "\n", "\n", "", "tf", ".", "gfile", ".", "MakeDirs", "(", "FLAGS", ".", "output_dir", ")", "\n", "\n", "task_name", "=", "FLAGS", ".", "task_name", ".", "lower", "(", ")", "\n", "\n", "if", "task_name", "not", "in", "processors", ":", "\n", "    ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "task_name", ")", ")", "\n", "\n", "", "processor", "=", "processors", "[", "task_name", "]", "(", ")", "\n", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "\n", "tokenizer", "=", "tokenization", ".", "FullTokenizer", "(", "\n", "vocab_file", "=", "FLAGS", ".", "vocab_file", ",", "do_lower_case", "=", "FLAGS", ".", "do_lower_case", ")", "\n", "\n", "tpu_cluster_resolver", "=", "None", "\n", "if", "FLAGS", ".", "use_tpu", "and", "FLAGS", ".", "tpu_name", ":", "\n", "    ", "tpu_cluster_resolver", "=", "tf", ".", "contrib", ".", "cluster_resolver", ".", "TPUClusterResolver", "(", "\n", "FLAGS", ".", "tpu_name", ",", "zone", "=", "FLAGS", ".", "tpu_zone", ",", "project", "=", "FLAGS", ".", "gcp_project", ")", "\n", "\n", "#is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2", "\n", "", "is_per_host", "=", "False", "\n", "run_config", "=", "tf", ".", "contrib", ".", "tpu", ".", "RunConfig", "(", "\n", "cluster", "=", "tpu_cluster_resolver", ",", "\n", "master", "=", "FLAGS", ".", "master", ",", "\n", "model_dir", "=", "FLAGS", ".", "output_dir", ",", "\n", "save_checkpoints_steps", "=", "FLAGS", ".", "save_checkpoints_steps", ",", "\n", "tpu_config", "=", "tf", ".", "contrib", ".", "tpu", ".", "TPUConfig", "(", "\n", "iterations_per_loop", "=", "FLAGS", ".", "iterations_per_loop", ",", "\n", "num_shards", "=", "FLAGS", ".", "num_tpu_cores", ",", "\n", "per_host_input_for_training", "=", "is_per_host", ")", ")", "\n", "\n", "train_examples", "=", "None", "\n", "num_train_steps", "=", "None", "\n", "num_warmup_steps", "=", "None", "\n", "if", "FLAGS", ".", "do_train", ":", "\n", "    ", "train_examples", "=", "processor", ".", "get_train_examples", "(", "FLAGS", ".", "data_dir", ")", "\n", "num_train_steps", "=", "int", "(", "\n", "len", "(", "train_examples", ")", "/", "FLAGS", ".", "train_batch_size", "*", "FLAGS", ".", "num_train_epochs", ")", "\n", "num_warmup_steps", "=", "int", "(", "num_train_steps", "*", "FLAGS", ".", "warmup_proportion", ")", "\n", "\n", "", "model_fn", "=", "model_fn_builder", "(", "\n", "bert_config", "=", "bert_config", ",", "\n", "num_labels", "=", "len", "(", "label_list", ")", ",", "\n", "init_checkpoint", "=", "FLAGS", ".", "init_checkpoint", ",", "\n", "learning_rate", "=", "FLAGS", ".", "learning_rate", ",", "\n", "num_train_steps", "=", "num_train_steps", ",", "\n", "num_warmup_steps", "=", "num_warmup_steps", ",", "\n", "use_tpu", "=", "FLAGS", ".", "use_tpu", ",", "\n", "use_one_hot_embeddings", "=", "FLAGS", ".", "use_tpu", ")", "\n", "\n", "# If TPU is not available, this will fall back to normal Estimator on CPU", "\n", "# or GPU.", "\n", "estimator", "=", "tf", ".", "contrib", ".", "tpu", ".", "TPUEstimator", "(", "\n", "use_tpu", "=", "FLAGS", ".", "use_tpu", ",", "\n", "model_fn", "=", "model_fn", ",", "\n", "config", "=", "run_config", ",", "\n", "train_batch_size", "=", "FLAGS", ".", "train_batch_size", ",", "\n", "eval_batch_size", "=", "FLAGS", ".", "eval_batch_size", ",", "\n", "predict_batch_size", "=", "FLAGS", ".", "predict_batch_size", ")", "\n", "\n", "if", "FLAGS", ".", "do_train", ":", "\n", "    ", "train_file", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "output_dir", ",", "\"train.tf_record\"", ")", "\n", "file_based_convert_examples_to_features", "(", "\n", "train_examples", ",", "label_list", ",", "FLAGS", ".", "max_seq_length", ",", "tokenizer", ",", "train_file", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_examples", ")", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"  Batch size = %d\"", ",", "FLAGS", ".", "train_batch_size", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"  Num steps = %d\"", ",", "num_train_steps", ")", "\n", "train_input_fn", "=", "file_based_input_fn_builder", "(", "\n", "input_file", "=", "train_file", ",", "\n", "seq_length", "=", "FLAGS", ".", "max_seq_length", ",", "\n", "is_training", "=", "True", ",", "\n", "drop_remainder", "=", "True", ")", "\n", "estimator", ".", "train", "(", "input_fn", "=", "train_input_fn", ",", "max_steps", "=", "num_train_steps", ")", "\n", "\n", "", "if", "FLAGS", ".", "do_eval", ":", "\n", "    ", "eval_examples", "=", "processor", ".", "get_dev_examples", "(", "FLAGS", ".", "data_dir", ")", "\n", "num_actual_eval_examples", "=", "len", "(", "eval_examples", ")", "\n", "if", "FLAGS", ".", "use_tpu", ":", "\n", "# TPU requires a fixed batch size for all batches, therefore the number", "\n", "# of examples must be a multiple of the batch size, or else examples", "\n", "# will get dropped. So we pad with fake examples which are ignored", "\n", "# later on. These do NOT count towards the metric (all tf.metrics", "\n", "# support a per-instance weight, and these get a weight of 0.0).", "\n", "      ", "while", "len", "(", "eval_examples", ")", "%", "FLAGS", ".", "eval_batch_size", "!=", "0", ":", "\n", "        ", "eval_examples", ".", "append", "(", "PaddingInputExample", "(", ")", ")", "\n", "\n", "", "", "eval_file", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "output_dir", ",", "\"eval.tf_record\"", ")", "\n", "file_based_convert_examples_to_features", "(", "\n", "eval_examples", ",", "label_list", ",", "FLAGS", ".", "max_seq_length", ",", "tokenizer", ",", "eval_file", ")", "\n", "\n", "tf", ".", "logging", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"  Num examples = %d (%d actual, %d padding)\"", ",", "\n", "len", "(", "eval_examples", ")", ",", "num_actual_eval_examples", ",", "\n", "len", "(", "eval_examples", ")", "-", "num_actual_eval_examples", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"  Batch size = %d\"", ",", "FLAGS", ".", "eval_batch_size", ")", "\n", "\n", "# This tells the estimator to run through the entire set.", "\n", "eval_steps", "=", "None", "\n", "# However, if running eval on the TPU, you will need to specify the", "\n", "# number of steps.", "\n", "if", "FLAGS", ".", "use_tpu", ":", "\n", "      ", "assert", "len", "(", "eval_examples", ")", "%", "FLAGS", ".", "eval_batch_size", "==", "0", "\n", "eval_steps", "=", "int", "(", "len", "(", "eval_examples", ")", "//", "FLAGS", ".", "eval_batch_size", ")", "\n", "\n", "", "eval_drop_remainder", "=", "True", "if", "FLAGS", ".", "use_tpu", "else", "False", "\n", "eval_input_fn", "=", "file_based_input_fn_builder", "(", "\n", "input_file", "=", "eval_file", ",", "\n", "seq_length", "=", "FLAGS", ".", "max_seq_length", ",", "\n", "is_training", "=", "False", ",", "\n", "drop_remainder", "=", "eval_drop_remainder", ")", "\n", "\n", "result", "=", "estimator", ".", "evaluate", "(", "input_fn", "=", "eval_input_fn", ",", "steps", "=", "eval_steps", ")", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "output_dir", ",", "\"eval_results.txt\"", ")", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "", "if", "FLAGS", ".", "do_predict", ":", "\n", "    ", "predict_examples", "=", "processor", ".", "get_test_examples", "(", "FLAGS", ".", "data_dir", ")", "\n", "num_actual_predict_examples", "=", "len", "(", "predict_examples", ")", "\n", "if", "FLAGS", ".", "use_tpu", ":", "\n", "# TPU requires a fixed batch size for all batches, therefore the number", "\n", "# of examples must be a multiple of the batch size, or else examples", "\n", "# will get dropped. So we pad with fake examples which are ignored", "\n", "# later on.", "\n", "      ", "while", "len", "(", "predict_examples", ")", "%", "FLAGS", ".", "predict_batch_size", "!=", "0", ":", "\n", "        ", "predict_examples", ".", "append", "(", "PaddingInputExample", "(", ")", ")", "\n", "\n", "", "", "predict_file", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "output_dir", ",", "\"predict.tf_record\"", ")", "\n", "file_based_convert_examples_to_features", "(", "predict_examples", ",", "label_list", ",", "\n", "FLAGS", ".", "max_seq_length", ",", "tokenizer", ",", "\n", "predict_file", ")", "\n", "\n", "tf", ".", "logging", ".", "info", "(", "\"***** Running prediction*****\"", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"  Num examples = %d (%d actual, %d padding)\"", ",", "\n", "len", "(", "predict_examples", ")", ",", "num_actual_predict_examples", ",", "\n", "len", "(", "predict_examples", ")", "-", "num_actual_predict_examples", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"  Batch size = %d\"", ",", "FLAGS", ".", "predict_batch_size", ")", "\n", "\n", "predict_drop_remainder", "=", "True", "if", "FLAGS", ".", "use_tpu", "else", "False", "\n", "predict_input_fn", "=", "file_based_input_fn_builder", "(", "\n", "input_file", "=", "predict_file", ",", "\n", "seq_length", "=", "FLAGS", ".", "max_seq_length", ",", "\n", "is_training", "=", "False", ",", "\n", "drop_remainder", "=", "predict_drop_remainder", ")", "\n", "\n", "result", "=", "estimator", ".", "predict", "(", "input_fn", "=", "predict_input_fn", ")", "\n", "\n", "output_predict_file", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "output_dir", ",", "\"test_results.tsv\"", ")", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "output_predict_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "      ", "num_written_lines", "=", "0", "\n", "tf", ".", "logging", ".", "info", "(", "\"***** Predict results *****\"", ")", "\n", "for", "(", "i", ",", "prediction", ")", "in", "enumerate", "(", "result", ")", ":", "\n", "        ", "probabilities", "=", "prediction", "[", "\"probabilities\"", "]", "\n", "if", "i", ">=", "num_actual_predict_examples", ":", "\n", "          ", "break", "\n", "", "output_line", "=", "\"\\t\"", ".", "join", "(", "\n", "str", "(", "class_probability", ")", "\n", "for", "class_probability", "in", "probabilities", ")", "+", "\"\\n\"", "\n", "writer", ".", "write", "(", "output_line", ")", "\n", "num_written_lines", "+=", "1", "\n", "", "", "assert", "num_written_lines", "==", "num_actual_predict_examples", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.collapse_hdf5_mention_embeddings.readKeys": [[66, 73], ["codecs.open", "keys.append", "int", "line.split"], "function", ["None"], ["def", "readKeys", "(", "f", ")", ":", "\n", "    ", "keys", "=", "[", "]", "\n", "with", "codecs", ".", "open", "(", "f", ",", "'r'", ",", "'utf-8'", ")", "as", "stream", ":", "\n", "        ", "for", "line", "in", "stream", ":", "\n", "            ", "(", "m_id", ",", "mention_start", ",", "mention_end", ")", "=", "[", "int", "(", "s", ")", "for", "s", "in", "line", ".", "split", "(", "'\\t'", ")", "]", "\n", "keys", ".", "append", "(", "(", "m_id", ",", "mention_start", ",", "mention_end", ")", ")", "\n", "", "", "return", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.collapse_hdf5_mention_embeddings.collapseMentionEmbeddings": [[74, 107], ["hedgepig_logger.log.track", "hedgepig_logger.log.flushTracker", "h5py.File", "range", "len", "numpy.mean", "new_mentions.append", "hedgepig_logger.log.tick", "len", "numpy.mean", "dataset.mention_file.EmbeddedMention", "str"], "function", ["None"], ["", "def", "collapseMentionEmbeddings", "(", "f", ",", "keys", ",", "layer", ",", "mentions_by_id", ",", "action_oracle", ")", ":", "\n", "    ", "log", ".", "track", "(", "message", "=", "'  >> Processed {0}/{1:,} mentions'", ".", "format", "(", "\n", "'{0:,}'", ",", "len", "(", "keys", ")", "\n", ")", ",", "writeInterval", "=", "50", ")", "\n", "new_mentions", "=", "[", "]", "\n", "\n", "with", "h5py", ".", "File", "(", "f", ",", "'r'", ")", "as", "stream", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "keys", ")", ")", ":", "\n", "            ", "(", "m_id", ",", "mention_start", ",", "mention_end", ")", "=", "keys", "[", "i", "]", "\n", "mention_token_embeddings", "=", "stream", "[", "str", "(", "i", ")", "]", "[", "...", "]", "\n", "\n", "if", "layer", "==", "AVERAGE_LAYERS", ":", "\n", "                ", "mention_token_embeddings", "=", "np", ".", "mean", "(", "mention_token_embeddings", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "mention_token_embeddings", "=", "mention_token_embeddings", "[", "layer", ",", ":", ",", ":", "]", "\n", "\n", "", "if", "action_oracle", ":", "\n", "                ", "mention_token_embeddings", "=", "mention_token_embeddings", "[", "mention_start", ":", "mention_end", "]", "\n", "", "mention_embedding", "=", "np", ".", "mean", "(", "mention_token_embeddings", ",", "axis", "=", "0", ")", "\n", "\n", "old_mention", "=", "mentions_by_id", "[", "m_id", "]", "\n", "new_mentions", ".", "append", "(", "mention_file", ".", "EmbeddedMention", "(", "\n", "CUI", "=", "old_mention", ".", "CUI", ",", "\n", "mention_repr", "=", "None", ",", "\n", "context_repr", "=", "mention_embedding", ",", "\n", "candidates", "=", "old_mention", ".", "candidates", ",", "\n", "ID", "=", "old_mention", ".", "ID", "\n", ")", ")", "\n", "\n", "log", ".", "tick", "(", ")", "\n", "", "", "log", ".", "flushTracker", "(", ")", "\n", "\n", "return", "new_mentions", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.compile_bert_predictions.readMentionIDsFromBERTFile": [[59, 69], ["open", "stream.readline", "m_IDs.append", "s.strip", "int", "line.split"], "function", ["None"], ["def", "readMentionIDsFromBERTFile", "(", "f", ")", ":", "\n", "    ", "m_IDs", "=", "[", "]", "\n", "with", "open", "(", "f", ",", "'r'", ")", "as", "stream", ":", "\n", "# skip the header", "\n", "        ", "stream", ".", "readline", "(", ")", "\n", "# for the rest of the file, the mention ID is the first column", "\n", "for", "line", "in", "stream", ":", "\n", "            ", "(", "m_ID", ",", "m_text", ",", "m_lbl", ")", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "line", ".", "split", "(", "'\\t'", ")", "]", "\n", "m_IDs", ".", "append", "(", "int", "(", "m_ID", ")", ")", "\n", "", "", "return", "m_IDs", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.compile_bert_predictions.readScoresFromBERTOutput": [[70, 76], ["open", "scores.append", "float", "line.split"], "function", ["None"], ["", "def", "readScoresFromBERTOutput", "(", "f", ")", ":", "\n", "    ", "scores", "=", "[", "]", "\n", "with", "open", "(", "f", ",", "'r'", ")", "as", "stream", ":", "\n", "        ", "for", "line", "in", "stream", ":", "\n", "            ", "scores", ".", "append", "(", "[", "float", "(", "f", ")", "for", "f", "in", "line", ".", "split", "(", "'\\t'", ")", "]", ")", "\n", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.compile_bert_predictions.reformatScoresToPredictionsFile": [[77, 90], ["range", "len", "analysis.predictions_parser.writePredictionsToStream", "numpy.argmax", "m.candidates.index"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.predictions_parser.writePredictionsToStream"], ["", "def", "reformatScoresToPredictionsFile", "(", "ordered_m_IDs", ",", "ordered_scores", ",", "mentions_by_ID", ",", "stream", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "len", "(", "ordered_m_IDs", ")", ")", ":", "\n", "        ", "m_ID", "=", "ordered_m_IDs", "[", "i", "]", "\n", "scores", "=", "ordered_scores", "[", "i", "]", "\n", "m", "=", "mentions_by_ID", "[", "m_ID", "]", "\n", "\n", "predictions_parser", ".", "writePredictionsToStream", "(", "\n", "stream", ",", "\n", "m", ",", "\n", "scores", ",", "\n", "np", ".", "argmax", "(", "scores", ")", ",", "\n", "m", ".", "candidates", ".", "index", "(", "m", ".", "CUI", ")", ",", "\n", "m", ".", "CUI", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.prep_mentions_for_contextualized_embedding.cleanAndSplit": [[58, 66], ["s.strip", "string.split", "len"], "function", ["None"], ["def", "cleanAndSplit", "(", "string", ")", ":", "\n", "    ", "tokens", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "string", ".", "split", "(", ")", "]", "\n", "tokens", "=", "[", "\n", "t", "\n", "for", "t", "in", "tokens", "\n", "if", "len", "(", "t", ")", ">", "0", "\n", "]", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.prep_mentions_for_contextualized_embedding.writeKeyFile": [[67, 77], ["open", "prep_mentions_for_contextualized_embedding.cleanAndSplit", "prep_mentions_for_contextualized_embedding.cleanAndSplit", "len", "stream.write", "len", "len", "str"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.prep_mentions_for_contextualized_embedding.cleanAndSplit", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.prep_mentions_for_contextualized_embedding.cleanAndSplit", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write"], ["", "def", "writeKeyFile", "(", "ordered_keys", ",", "mentions_by_id", ",", "outf", ")", ":", "\n", "    ", "with", "open", "(", "outf", ",", "'w'", ")", "as", "stream", ":", "\n", "        ", "for", "m_id", "in", "ordered_keys", ":", "\n", "            ", "m", "=", "mentions_by_id", "[", "m_id", "]", "\n", "left_ctx", "=", "cleanAndSplit", "(", "m", ".", "left_context", ")", "\n", "mention", "=", "cleanAndSplit", "(", "m", ".", "mention_text", ")", "\n", "mention_start", "=", "len", "(", "left_ctx", ")", "\n", "mention_end", "=", "len", "(", "left_ctx", ")", "+", "len", "(", "mention", ")", "\n", "stream", ".", "write", "(", "'%s\\t%d\\t%d\\n'", "%", "(", "\n", "str", "(", "m_id", ")", ",", "mention_start", ",", "mention_end", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.prep_mentions_for_contextualized_embedding.writeTextFile": [[79, 88], ["open", "prep_mentions_for_contextualized_embedding.cleanAndSplit", "prep_mentions_for_contextualized_embedding.cleanAndSplit", "prep_mentions_for_contextualized_embedding.cleanAndSplit", "stream.write"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.prep_mentions_for_contextualized_embedding.cleanAndSplit", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.prep_mentions_for_contextualized_embedding.cleanAndSplit", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.utils.prep_mentions_for_contextualized_embedding.cleanAndSplit", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write"], ["", "", "", "def", "writeTextFile", "(", "ordered_keys", ",", "mentions_by_id", ",", "outf", ")", ":", "\n", "    ", "with", "open", "(", "outf", ",", "'w'", ")", "as", "stream", ":", "\n", "        ", "for", "m_id", "in", "ordered_keys", ":", "\n", "            ", "m", "=", "mentions_by_id", "[", "m_id", "]", "\n", "left_ctx", "=", "cleanAndSplit", "(", "m", ".", "left_context", ")", "\n", "mention", "=", "cleanAndSplit", "(", "m", ".", "mention_text", ")", "\n", "right_ctx", "=", "cleanAndSplit", "(", "m", ".", "right_context", ")", "\n", "stream", ".", "write", "(", "'%s\\n'", "%", "(", "' '", ".", "join", "(", "[", "\n", "*", "left_ctx", ",", "*", "mention", ",", "*", "right_ctx", "\n", "]", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.Classifier.tolist": [[85, 91], ["None"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "tolist", "(", ")", ":", "\n", "        ", "return", "[", "\n", "Classifier", ".", "SVM", ",", "\n", "Classifier", ".", "KNN", ",", "\n", "Classifier", ".", "MLP", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.Classifier.default": [[92, 95], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "default", "(", ")", ":", "\n", "        ", "return", "Classifier", ".", "SVM", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.getTextVocabulary": [[96, 105], ["set", "s.strip", "set.add", "context_string.lower().split", "context_string.lower"], "function", ["None"], ["", "", "def", "getTextVocabulary", "(", "mentions", ",", "preprocessed", ",", "options", ")", ":", "\n", "    ", "vocab", "=", "set", "(", ")", "\n", "for", "m", "in", "mentions", ":", "\n", "        ", "strings", "=", "[", "m", ".", "left_context", ",", "m", ".", "right_context", ",", "m", ".", "mention_text", "]", "\n", "for", "context_string", "in", "strings", ":", "\n", "            ", "words", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "context_string", ".", "lower", "(", ")", ".", "split", "(", ")", "]", "\n", "for", "w", "in", "words", ":", "\n", "                ", "vocab", ".", "add", "(", "w", ")", "\n", "", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.extractContexts": [[106, 121], ["s.strip", "tokens.index", "tokens.index", "full_text.split", "print"], "function", ["None"], ["", "def", "extractContexts", "(", "full_text", ")", ":", "\n", "# assuming already tokenized at this point", "\n", "    ", "tokens", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "full_text", ".", "split", "(", ")", "]", "\n", "\n", "try", ":", "\n", "        ", "start_ix", "=", "tokens", ".", "index", "(", "'<e>'", ")", "\n", "end_ix", "=", "tokens", ".", "index", "(", "'</e>'", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "tokens", ")", "\n", "raise", "e", "\n", "\n", "", "left_context", "=", "' '", ".", "join", "(", "tokens", "[", ":", "start_ix", "]", ")", "\n", "right_context", "=", "' '", ".", "join", "(", "tokens", "[", "end_ix", "+", "1", ":", "]", ")", "\n", "\n", "return", "(", "left_context", ",", "right_context", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.preprocessData": [[122, 235], ["types.SimpleNamespace", "cross_validation.crossValidationSplits", "m.CUI.strip().lower", "range", "sklearn_classifiers.getTextVocabulary", "sklearn.feature_extraction.text.CountVectorizer.fit_transform().tocsr", "len", "texts.append", "sklearn_classifiers.getTextVocabulary", "sklearn.feature_extraction.text.TfidfVectorizer", "sklearn.feature_extraction.text.CountVectorizer", "per_fold_unigram_vectorizer.fit_transform().tocsr", "m.CUI.strip", "cleaned_text.extend", "sklearn.feature_extraction.text.TfidfVectorizer", "sklearn.feature_extraction.text.CountVectorizer", "sklearn.feature_extraction.text.CountVectorizer.fit_transform", "range", "per_fold_unigram_vectorizer.fit_transform", "len", "s.strip", "string.lower().split", "string.lower"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.crossValidationSplits", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.getTextVocabulary", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.getTextVocabulary"], ["", "def", "preprocessData", "(", "mentions", ",", "entity_embeds", ",", "ctx_embeds", ",", "options", ")", ":", "\n", "    ", "preprocessed", "=", "SimpleNamespace", "(", ")", "\n", "\n", "preprocessed", ".", "mentions", "=", "mentions", "\n", "preprocessed", ".", "entity_embeds", "=", "entity_embeds", "\n", "preprocessed", ".", "ctx_embeds", "=", "ctx_embeds", "\n", "\n", "preprocessed", ".", "mentions_by_id", "=", "{", "\n", "m", ".", "ID", ":", "m", "\n", "for", "m", "in", "mentions", "\n", "}", "\n", "preprocessed", ".", "labels_by_id", "=", "{", "\n", "m", ".", "ID", ":", "m", ".", "CUI", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "for", "m", "in", "mentions", "\n", "}", "\n", "\n", "persistent_path", "=", "options", ".", "cross_validation_file", "\n", "\n", "preprocessed", ".", "splits", "=", "cross_validation", ".", "crossValidationSplits", "(", "\n", "preprocessed", ".", "labels_by_id", ",", "\n", "n_folds", "=", "options", ".", "n_folds", ",", "\n", "dev_size", "=", "options", ".", "dev_size", ",", "\n", "persistent_path", "=", "persistent_path", ",", "\n", "random_seed", "=", "options", ".", "random_seed", ",", "\n", "log", "=", "log", "\n", ")", "\n", "\n", "# set up unigram features for all mentions", "\n", "# (CountVectorizer needs to call fit_transform on all strings at once to", "\n", "#  set up its vocabulary correctly)", "\n", "if", "options", ".", "unigram_features", ":", "\n", "# first, compile all of the texts of each mention into a single", "\n", "# list, with an index by mention ID", "\n", "        ", "preprocessed", ".", "mention_ID_to_unigram_rows", "=", "{", "}", "\n", "texts", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "mentions", ")", ")", ":", "\n", "            ", "mention_ID", "=", "mentions", "[", "i", "]", ".", "ID", "\n", "preprocessed", ".", "mention_ID_to_unigram_rows", "[", "mention_ID", "]", "=", "i", "\n", "m", "=", "mentions", "[", "i", "]", "\n", "strings", "=", "[", "m", ".", "left_context", ",", "m", ".", "right_context", ",", "m", ".", "mention_text", "]", "\n", "cleaned_text", "=", "[", "]", "\n", "for", "string", "in", "strings", ":", "\n", "                ", "cleaned_text", ".", "extend", "(", "[", "\n", "s", ".", "strip", "(", ")", "\n", "for", "s", "in", "string", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "]", ")", "\n", "", "texts", ".", "append", "(", "' '", ".", "join", "(", "cleaned_text", ")", ")", "\n", "\n", "# identify the words that appear within each fold, then in the", "\n", "# overall collection of all texts (may have more words than any", "\n", "# individual fold)", "\n", "", "per_fold_unigram_vocabs", "=", "[", "\n", "getTextVocabulary", "(", "\n", "[", "\n", "m", "\n", "for", "m", "in", "preprocessed", ".", "mentions", "\n", "if", "m", ".", "ID", "in", "train_ids", "\n", "]", ",", "\n", "preprocessed", ",", "\n", "options", "\n", ")", "\n", "for", "(", "train_ids", ",", "_", ",", "_", ")", "in", "preprocessed", ".", "splits", "\n", "]", "\n", "global_unigram_vocab", "=", "getTextVocabulary", "(", "\n", "preprocessed", ".", "mentions", ",", "\n", "preprocessed", ",", "\n", "options", "\n", ")", "\n", "\n", "# vectorize either with TF-IDF values or with straight binary", "\n", "# counts, depending on runtime configuration", "\n", "if", "options", ".", "unigrams_as_tfidf", ":", "\n", "            ", "per_fold_unigram_vectorizers", "=", "[", "\n", "TfidfVectorizer", "(", "\n", "vocabulary", "=", "per_fold_unigram_vocab", ",", "\n", "binary", "=", "True", "\n", ")", "\n", "for", "per_fold_unigram_vocab", "in", "per_fold_unigram_vocabs", "\n", "]", "\n", "global_unigram_vectorizer", "=", "TfidfVectorizer", "(", "\n", "vocabulary", "=", "global_unigram_vocab", ",", "\n", "binary", "=", "True", "\n", ")", "\n", "", "else", ":", "\n", "            ", "per_fold_unigram_vectorizers", "=", "[", "\n", "CountVectorizer", "(", "\n", "vocabulary", "=", "per_fold_unigram_vocab", ",", "\n", "binary", "=", "True", "\n", ")", "\n", "for", "per_fold_unigram_vocab", "in", "per_fold_unigram_vocabs", "\n", "]", "\n", "global_unigram_vectorizer", "=", "CountVectorizer", "(", "\n", "vocabulary", "=", "global_unigram_vocab", ",", "\n", "binary", "=", "True", "\n", ")", "\n", "\n", "", "preprocessed", ".", "global_unigram_features", "=", "global_unigram_vectorizer", ".", "fit_transform", "(", "\n", "texts", "\n", ")", ".", "tocsr", "(", ")", "\n", "preprocessed", ".", "per_fold_unigram_features", "=", "[", "\n", "per_fold_unigram_vectorizer", ".", "fit_transform", "(", "\n", "texts", "\n", ")", ".", "tocsr", "(", ")", "\n", "for", "per_fold_unigram_vectorizer", "in", "per_fold_unigram_vectorizers", "\n", "]", "\n", "", "else", ":", "\n", "        ", "preprocessed", ".", "mention_ID_to_unigram_rows", "=", "None", "\n", "preprocessed", ".", "global_unigram_features", "=", "None", "\n", "preprocessed", ".", "per_fold_unigram_features", "=", "[", "\n", "None", "for", "_", "in", "range", "(", "len", "(", "preprocessed", ".", "splits", ")", ")", "\n", "]", "\n", "\n", "", "return", "preprocessed", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.prepSample": [[236, 329], ["range", "np.concatenate.append", "range", "len", "len", "util.meanEmbeddings", "np.concatenate.append", "len", "range", "mention.candidates[].strip().lower.strip().lower", "mention.CUI.strip().lower", "scipy.sparse.hstack", "scipy.sparse.hstack", "numpy.concatenate", "strings.append", "np.concatenate.append", "np.concatenate.append", "util.meanEmbeddings", "unigram_feature_set.getrow().tocoo", "len", "mention.candidates[].strip().lower", "scipy.sparse.coo_matrix", "scipy.sparse.coo_matrix", "np.concatenate.append", "np.concatenate.append", "mention.candidates[].strip().lower.strip().lower", "mention.CUI.strip().lower", "mention.candidates[].strip().lower.strip", "mention.CUI.strip", "scipy.sparse.coo_matrix", "scipy.sparse.coo_matrix", "unigram_feature_set.getrow", "mention.candidates[].strip", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "mention.candidates[].strip().lower.strip", "mention.CUI.strip", "scipy.sparse.coo_matrix", "scipy.sparse.coo_matrix", "numpy.dot", "scipy.sparse.coo_matrix", "scipy.sparse.coo_matrix", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.util.meanEmbeddings", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.util.meanEmbeddings"], ["", "def", "prepSample", "(", "mention", ",", "preprocessed", ",", "unigram_feature_set", ",", "options", ")", ":", "\n", "    ", "'''Given a mention, a set of word embeddings, and a list of sets of\n    entity embeddings, returns:\n       (1) Feature vector consisting of:\n            - Average embedding of context words\n            - Embeddings of each candidate entity, for entities in the vocabulary\n           (if no valid context words in vocabulary, this value is None)\n       (2) Point label\n           (or None if correct entity is not in embedding vocabulary)\n    '''", "\n", "feature_vector", ",", "label", "=", "[", "]", ",", "None", "\n", "\n", "# if it's pre-embedded, that's the only context/mention feature we can use", "\n", "if", "options", ".", "pre_embedded", ":", "\n", "        ", "feature_vector", ".", "append", "(", "mention", ".", "context_repr", ")", "\n", "", "else", ":", "\n", "# context embedding", "\n", "        ", "if", "options", ".", "use_ctx_embeddings", ":", "\n", "            ", "strings", "=", "[", "mention", ".", "left_context", ",", "mention", ".", "right_context", "]", "\n", "if", "not", "options", ".", "action_oracle", ":", "\n", "                ", "strings", ".", "append", "(", "mention", ".", "mention_text", ")", "\n", "\n", "", "ctx_embedding", ",", "valid_ctx_embedding", "=", "meanEmbeddings", "(", "\n", "strings", ",", "\n", "preprocessed", ".", "ctx_embeds", "\n", ")", "\n", "if", "not", "options", ".", "unigram_features", ":", "\n", "                ", "feature_vector", ".", "append", "(", "ctx_embedding", ")", "\n", "", "else", ":", "\n", "                ", "feature_vector", ".", "append", "(", "scipy", ".", "sparse", ".", "coo_matrix", "(", "ctx_embedding", ")", ")", "\n", "\n", "# mention text embedding", "\n", "", "if", "options", ".", "action_oracle", ":", "\n", "                ", "mention_embedding", ",", "valid_mention_embedding", "=", "meanEmbeddings", "(", "\n", "[", "mention", ".", "mention_text", "]", ",", "\n", "preprocessed", ".", "ctx_embeds", "\n", ")", "\n", "if", "not", "options", ".", "unigram_features", ":", "\n", "                    ", "feature_vector", ".", "append", "(", "mention_embedding", ")", "\n", "", "else", ":", "\n", "                    ", "feature_vector", ".", "append", "(", "scipy", ".", "sparse", ".", "coo_matrix", "(", "ctx_embedding", ")", ")", "\n", "\n", "# context/mention unigram features (pre-calculated)", "\n", "", "", "", "if", "options", ".", "unigram_features", ":", "\n", "            ", "feature_vector", ".", "append", "(", "\n", "unigram_feature_set", ".", "getrow", "(", "\n", "preprocessed", ".", "mention_ID_to_unigram_rows", "[", "mention", ".", "ID", "]", "\n", ")", ".", "tocoo", "(", ")", "\n", ")", "\n", "\n", "# entity features", "\n", "", "", "if", "options", ".", "use_entity_embeddings", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "entity_embeds", ")", ")", ":", "\n", "            ", "entity_embedding_set", "=", "preprocessed", ".", "entity_embeds", "[", "i", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "mention", ".", "candidates", ")", ")", ":", "\n", "                ", "c", "=", "mention", ".", "candidates", "[", "j", "]", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "if", "options", ".", "use_entity_embeddings", "and", "c", "in", "entity_embedding_set", ":", "\n", "                    ", "if", "options", ".", "full_entity_embeddings", ":", "\n", "                        ", "if", "not", "options", ".", "unigram_features", ":", "\n", "                            ", "feature_vector", ".", "append", "(", "entity_embedding_set", "[", "c", "]", ")", "\n", "", "else", ":", "\n", "                            ", "feature_vector", ".", "append", "(", "scipy", ".", "sparse", ".", "coo_matrix", "(", "[", "entity_embedding_set", "[", "c", "]", "]", ")", ")", "\n", "", "", "else", ":", "\n", "                        ", "c_emb", "=", "entity_embedding_set", "[", "c", "]", "\n", "if", "valid_ctx_embedding", ":", "\n", "                            ", "cos_sim", "=", "(", "\n", "np", ".", "dot", "(", "ctx_embedding", ",", "c_emb", ")", "/", "\n", "(", "np", ".", "linalg", ".", "norm", "(", "ctx_embedding", ")", "*", "np", ".", "linalg", ".", "norm", "(", "c_emb", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "                            ", "cos_sim", "=", "0", "\n", "", "if", "not", "options", ".", "unigram_features", ":", "\n", "                            ", "feature_vector", ".", "append", "(", "[", "cos_sim", "]", ")", "\n", "", "else", ":", "\n", "                            ", "feature_vector", ".", "append", "(", "scipy", ".", "sparse", ".", "coo_matrix", "(", "[", "cos_sim", "]", ")", ")", "\n", "", "", "", "if", "c", ".", "strip", "(", ")", ".", "lower", "(", ")", "==", "mention", ".", "CUI", ".", "strip", "(", ")", ".", "lower", "(", ")", ":", "\n", "                    ", "label", "=", "j", "\n", "", "", "", "", "for", "j", "in", "range", "(", "len", "(", "mention", ".", "candidates", ")", ")", ":", "\n", "        ", "c", "=", "mention", ".", "candidates", "[", "j", "]", "\n", "if", "c", ".", "strip", "(", ")", ".", "lower", "(", ")", "==", "mention", ".", "CUI", ".", "strip", "(", ")", ".", "lower", "(", ")", ":", "\n", "            ", "label", "=", "j", "\n", "\n", "", "", "if", "len", "(", "feature_vector", ")", ">", "0", ":", "\n", "        ", "if", "options", ".", "unigram_features", ":", "\n", "            ", "feature_vector", "=", "scipy", ".", "sparse", ".", "hstack", "(", "feature_vector", ")", "\n", "", "else", ":", "\n", "            ", "feature_vector", "=", "np", ".", "concatenate", "(", "feature_vector", ",", "axis", "=", "0", ")", "\n", "", "", "else", ":", "\n", "        ", "feature_vector", "=", "None", "\n", "\n", "", "return", "(", "\n", "feature_vector", ",", "\n", "label", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.filterMentions": [[331, 353], ["hedgepig_logger.log.track", "hedgepig_logger.log.flushTracker", "sklearn_classifiers.prepSample", "hedgepig_logger.log.tick", "filtered_mentions.append", "len"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.prepSample"], ["", "def", "filterMentions", "(", "preprocessed", ",", "options", ")", ":", "\n", "    ", "filtered_mentions", ",", "skipped", "=", "[", "]", ",", "0", "\n", "log", ".", "track", "(", "message", "=", "'  >> Processed {0:,}/%s mentions'", "%", "'{0:,}'", ".", "format", "(", "len", "(", "preprocessed", ".", "mentions", ")", ")", ",", "writeInterval", "=", "100", ")", "\n", "for", "m", "in", "preprocessed", ".", "mentions", ":", "\n", "        ", "valid", "=", "True", "\n", "(", "feature_vector", ",", "label", ")", "=", "prepSample", "(", "\n", "m", ",", "\n", "preprocessed", ",", "\n", "preprocessed", ".", "global_unigram_features", ",", "\n", "options", "\n", ")", "\n", "# check to ensure we have any features for this point", "\n", "if", "feature_vector", "is", "None", ":", "\n", "            ", "valid", "=", "False", "\n", "skipped", "+=", "1", "\n", "\n", "", "if", "valid", ":", "\n", "            ", "filtered_mentions", ".", "append", "(", "m", ")", "\n", "", "log", ".", "tick", "(", ")", "\n", "", "log", ".", "flushTracker", "(", ")", "\n", "\n", "return", "filtered_mentions", ",", "skipped", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.runCrossfoldExperiment": [[354, 505], ["range", "types.SimpleNamespace", "hedgepig_logger.log.writeln", "range", "numpy.mean", "hedgepig_logger.log.writeln", "len", "hedgepig_logger.log.writeln", "hedgepig_logger.log.writeln", "hedgepig_logger.log.writeln", "sklearn.preprocessing.StandardScaler", "types.SimpleNamespace", "range", "hedgepig_logger.log.writeln", "cross_fold_metrics.append", "len", "hedgepig_logger.log.writeln", "sklearn_classifiers.getTextVocabulary", "sklearn.feature_extraction.text.CountVectorizer", "sklearn_classifiers.prepSample", "scaler.fit_transform.append", "training_labels.append", "sklearn_classifiers.prepSample", "scaler.transform.append", "test_labels.append", "len", "hedgepig_logger.log.writeln", "len", "hedgepig_logger.log.writeln", "scipy.sparse.vstack", "scipy.sparse.vstack", "scipy.sparse.vstack", "scipy.sparse.vstack", "sklearn.preprocessing.StandardScaler.fit_transform", "sklearn.preprocessing.StandardScaler.transform", "hedgepig_logger.log.startTimer", "sklearn.svm.SVC", "sklearn.svm.SVC", "sklearn.svm.SVC", "sklearn.svm.SVC", "sklearn.neural_network.multilayer_perceptron.MLPClassifier.fit", "hedgepig_logger.log.stopTimer", "hedgepig_logger.log.startTimer", "sklearn.neural_network.multilayer_perceptron.MLPClassifier.predict", "hedgepig_logger.log.stopTimer", "len", "float", "train.append", "len", "len", "set", "hedgepig_logger.log.startTimer", "sklearn.neighbors.KNeighborsClassifier", "sklearn.neighbors.KNeighborsClassifier", "sklearn.neighbors.KNeighborsClassifier", "sklearn.neighbors.KNeighborsClassifier", "sklearn.neural_network.multilayer_perceptron.MLPClassifier.fit", "hedgepig_logger.log.stopTimer", "hedgepig_logger.log.startTimer", "sklearn.neural_network.multilayer_perceptron.MLPClassifier.predict", "hedgepig_logger.log.stopTimer", "preds_stream.write", "len", "test.append", "train.append", "test.append", "hedgepig_logger.log.startTimer", "sklearn.neural_network.multilayer_perceptron.MLPClassifier", "sklearn.neural_network.multilayer_perceptron.MLPClassifier", "sklearn.neural_network.multilayer_perceptron.MLPClassifier", "sklearn.neural_network.multilayer_perceptron.MLPClassifier", "sklearn.neural_network.multilayer_perceptron.MLPClassifier.fit", "hedgepig_logger.log.stopTimer", "hedgepig_logger.log.startTimer", "sklearn.neural_network.multilayer_perceptron.MLPClassifier.predict", "hedgepig_logger.log.stopTimer"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.getTextVocabulary", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.prepSample", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.prepSample", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write"], ["", "def", "runCrossfoldExperiment", "(", "preprocessed", ",", "preds_stream", ",", "options", ")", ":", "\n", "    ", "cross_fold_metrics", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "preprocessed", ".", "splits", ")", ")", ":", "\n", "        ", "log", ".", "writeln", "(", "(", "'\\n\\n{0}\\n  Starting fold %d/%d\\n{0}\\n'", ".", "format", "(", "'#'", "*", "80", ")", ")", "%", "(", "i", "+", "1", ",", "len", "(", "preprocessed", ".", "splits", ")", ")", ")", "\n", "\n", "(", "train_ids", ",", "dev_ids", ",", "test_ids", ")", "=", "preprocessed", ".", "splits", "[", "i", "]", "\n", "train", ",", "test", "=", "[", "]", ",", "[", "]", "\n", "for", "_id", "in", "train_ids", ":", "\n", "            ", "if", "_id", "in", "preprocessed", ".", "mentions_by_id", ":", "\n", "                ", "train", ".", "append", "(", "preprocessed", ".", "mentions_by_id", "[", "_id", "]", ")", "\n", "", "", "for", "_id", "in", "dev_ids", ":", "\n", "            ", "if", "_id", "in", "preprocessed", ".", "mentions_by_id", ":", "\n", "                ", "if", "options", ".", "eval_on_dev", ":", "\n", "                    ", "test", ".", "append", "(", "preprocessed", ".", "mentions_by_id", "[", "_id", "]", ")", "\n", "", "else", ":", "\n", "                    ", "train", ".", "append", "(", "preprocessed", ".", "mentions_by_id", "[", "_id", "]", ")", "\n", "", "", "", "if", "not", "options", ".", "eval_on_dev", ":", "\n", "            ", "for", "_id", "in", "test_ids", ":", "\n", "                ", "if", "_id", "in", "preprocessed", ".", "mentions_by_id", ":", "\n", "                    ", "test", ".", "append", "(", "preprocessed", ".", "mentions_by_id", "[", "_id", "]", ")", "\n", "\n", "", "", "", "if", "options", ".", "unigram_features", ":", "\n", "            ", "unigram_vocab", "=", "getTextVocabulary", "(", "train", ",", "preprocessed", ",", "options", ")", "\n", "unigram_vectorizer", "=", "CountVectorizer", "(", "vocabulary", "=", "unigram_vocab", ",", "binary", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "unigram_vectorizer", "=", "None", "\n", "\n", "", "training_features", ",", "training_labels", "=", "[", "]", ",", "[", "]", "\n", "for", "m", "in", "train", ":", "\n", "            ", "(", "feature_vector", ",", "label", ")", "=", "prepSample", "(", "\n", "m", ",", "\n", "preprocessed", ",", "\n", "preprocessed", ".", "per_fold_unigram_features", "[", "i", "]", ",", "\n", "options", "\n", ")", "\n", "if", "feature_vector", "is", "None", "or", "label", "is", "None", ":", "\n", "                ", "continue", "\n", "", "training_features", ".", "append", "(", "feature_vector", ")", "\n", "training_labels", ".", "append", "(", "label", ")", "\n", "\n", "", "test_features", ",", "test_labels", "=", "[", "]", ",", "[", "]", "\n", "for", "m", "in", "test", ":", "\n", "            ", "(", "feature_vector", ",", "label", ")", "=", "prepSample", "(", "\n", "m", ",", "\n", "preprocessed", ",", "\n", "preprocessed", ".", "per_fold_unigram_features", "[", "i", "]", ",", "\n", "options", "\n", ")", "\n", "if", "feature_vector", "is", "None", "or", "label", "is", "None", ":", "\n", "                ", "continue", "\n", "", "test_features", ".", "append", "(", "feature_vector", ")", "\n", "test_labels", ".", "append", "(", "label", ")", "\n", "\n", "", "log", ".", "writeln", "(", "'Number of training samples: {0:,}'", ".", "format", "(", "len", "(", "training_labels", ")", ")", ")", "\n", "log", ".", "writeln", "(", "'Number of test samples: {0:,}\\n'", ".", "format", "(", "len", "(", "test_labels", ")", ")", ")", "\n", "\n", "if", "len", "(", "test_labels", ")", "==", "0", ":", "\n", "            ", "log", ".", "writeln", "(", "'[WARNING] Test ids list is empty due to rounding in cross-validation splits, skipping...'", ")", "\n", "continue", "\n", "\n", "", "if", "len", "(", "set", "(", "training_labels", ")", ")", "==", "1", ":", "\n", "            ", "log", ".", "writeln", "(", "'[WARNING] Training samples for this subset have only one label class. Skipping...'", ")", "\n", "return", "None", "\n", "\n", "", "if", "options", ".", "unigram_features", ":", "\n", "            ", "training_features", "=", "scipy", ".", "sparse", ".", "vstack", "(", "training_features", ")", "\n", "test_features", "=", "scipy", ".", "sparse", ".", "vstack", "(", "test_features", ")", "\n", "\n", "", "scaler", "=", "StandardScaler", "(", "with_mean", "=", "False", ")", "\n", "if", "options", ".", "normalize_features", ":", "\n", "            ", "training_features", "=", "scaler", ".", "fit_transform", "(", "training_features", ")", "\n", "test_features", "=", "scaler", ".", "transform", "(", "test_features", ")", "\n", "\n", "", "if", "options", ".", "classifier", "==", "Classifier", ".", "SVM", ":", "\n", "            ", "t", "=", "log", ".", "startTimer", "(", "'Training SVM classifier...'", ")", "\n", "classifier", "=", "sklearn", ".", "svm", ".", "SVC", "(", "\n", "kernel", "=", "'linear'", ",", "\n", "random_state", "=", "options", ".", "random_seed", "+", "i", "\n", ")", "\n", "classifier", ".", "fit", "(", "training_features", ",", "training_labels", ")", "\n", "log", ".", "stopTimer", "(", "t", ",", "message", "=", "'Training complete in {0:.2f}s.\\n'", ")", "\n", "\n", "t", "=", "log", ".", "startTimer", "(", "'Running trained SVM on test set...'", ")", "\n", "predictions", "=", "classifier", ".", "predict", "(", "test_features", ")", "\n", "log", ".", "stopTimer", "(", "t", ",", "message", "=", "'Complete in {0:.2f}s.\\n'", ")", "\n", "\n", "", "elif", "options", ".", "classifier", "==", "Classifier", ".", "KNN", ":", "\n", "            ", "t", "=", "log", ".", "startTimer", "(", "'Training k-NN classifier...'", ")", "\n", "classifier", "=", "sklearn", ".", "neighbors", ".", "KNeighborsClassifier", "(", "\n", "n_neighbors", "=", "5", ",", "\n", "#random_state=options.random_seed+i", "\n", ")", "\n", "classifier", ".", "fit", "(", "training_features", ",", "training_labels", ")", "\n", "log", ".", "stopTimer", "(", "t", ",", "message", "=", "'Training complete in {0:.2f}s.\\n'", ")", "\n", "\n", "t", "=", "log", ".", "startTimer", "(", "'Running trained k-NN on test set...'", ")", "\n", "predictions", "=", "classifier", ".", "predict", "(", "test_features", ")", "\n", "log", ".", "stopTimer", "(", "t", ",", "message", "=", "'Complete in {0:.2f}s.\\n'", ")", "\n", "\n", "", "elif", "options", ".", "classifier", "==", "Classifier", ".", "MLP", ":", "\n", "            ", "t", "=", "log", ".", "startTimer", "(", "'Training MLP classifier...'", ")", "\n", "classifier", "=", "sklearn", ".", "neural_network", ".", "multilayer_perceptron", ".", "MLPClassifier", "(", "\n", "max_iter", "=", "1000", ",", "\n", "random_state", "=", "options", ".", "random_seed", "+", "i", "\n", ")", "\n", "classifier", ".", "fit", "(", "training_features", ",", "training_labels", ")", "\n", "log", ".", "stopTimer", "(", "t", ",", "message", "=", "'Training complete in {0:.2f}s.\\n'", ")", "\n", "\n", "t", "=", "log", ".", "startTimer", "(", "'Running trained MLP on test set...'", ")", "\n", "predictions", "=", "classifier", ".", "predict", "(", "test_features", ")", "\n", "log", ".", "stopTimer", "(", "t", ",", "message", "=", "'Complete in {0:.2f}s.\\n'", ")", "\n", "\n", "", "metrics", "=", "SimpleNamespace", "(", ")", "\n", "metrics", ".", "correct", "=", "0", "\n", "metrics", ".", "total", "=", "0", "\n", "\n", "for", "j", "in", "range", "(", "len", "(", "predictions", ")", ")", ":", "\n", "            ", "if", "predictions", "[", "j", "]", "==", "test_labels", "[", "j", "]", ":", "\n", "                ", "metrics", ".", "correct", "+=", "1", "\n", "", "metrics", ".", "total", "+=", "1", "\n", "\n", "if", "preds_stream", ":", "\n", "                ", "preds_stream", ".", "write", "(", "'Mention %d -- Pred: %d -> %s  Gold: %d -> %s\\n'", "%", "(", "\n", "test", "[", "j", "]", ".", "ID", ",", "\n", "predictions", "[", "j", "]", ",", "\n", "test", "[", "j", "]", ".", "candidates", "[", "predictions", "[", "j", "]", "]", ",", "\n", "test_labels", "[", "j", "]", ",", "\n", "test", "[", "j", "]", ".", "candidates", "[", "test_labels", "[", "j", "]", "]", "\n", ")", ")", "\n", "\n", "", "", "metrics", ".", "accuracy", "=", "float", "(", "metrics", ".", "correct", ")", "/", "metrics", ".", "total", "\n", "log", ".", "writeln", "(", "'Fold accuracy: {0:.2f} ({1:,}/{2:,})'", ".", "format", "(", "metrics", ".", "accuracy", ",", "metrics", ".", "correct", ",", "metrics", ".", "total", ")", ")", "\n", "\n", "cross_fold_metrics", ".", "append", "(", "metrics", ")", "\n", "\n", "", "overall_metrics", "=", "SimpleNamespace", "(", ")", "\n", "overall_metrics", ".", "correct", "=", "0", "\n", "overall_metrics", ".", "total", "=", "0", "\n", "\n", "log", ".", "writeln", "(", "'\\n\\n-- Cross-validation report --\\n'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "cross_fold_metrics", ")", ")", ":", "\n", "        ", "m", "=", "cross_fold_metrics", "[", "i", "]", "\n", "overall_metrics", ".", "correct", "+=", "m", ".", "correct", "\n", "overall_metrics", ".", "total", "+=", "m", ".", "total", "\n", "log", ".", "writeln", "(", "'  Fold %d -- Accuracy: %f (%d/%d)'", "%", "(", "i", "+", "1", ",", "m", ".", "accuracy", ",", "m", ".", "correct", ",", "m", ".", "total", ")", ")", "\n", "\n", "", "overall_metrics", ".", "accuracy", "=", "np", ".", "mean", "(", "[", "m", ".", "accuracy", "for", "m", "in", "cross_fold_metrics", "]", ")", "\n", "log", ".", "writeln", "(", "'\\nOverall cross-validation accuracy: %f'", "%", "overall_metrics", ".", "accuracy", ")", "\n", "\n", "return", "overall_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.experimentWrapper": [[506, 534], ["sklearn_classifiers.preprocessData", "hedgepig_logger.log.writeln", "sklearn_classifiers.filterMentions", "hedgepig_logger.log.writeln", "hedgepig_logger.log.writeln", "sklearn_classifiers.runCrossfoldExperiment", "len"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.candidate_selection.lesk_baseline.preprocessData", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.filterMentions", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.sklearn_classifiers.runCrossfoldExperiment"], ["", "def", "experimentWrapper", "(", "mentions", ",", "entity_embeds", ",", "ctx_embeds", ",", "options", ",", "preds_stream", ")", ":", "\n", "    ", "preprocessed", "=", "preprocessData", "(", "\n", "mentions", ",", "\n", "entity_embeds", ",", "\n", "ctx_embeds", ",", "\n", "options", "\n", ")", "\n", "\n", "log", ".", "writeln", "(", "'Filtering mentions for these embeddings...'", ")", "\n", "preprocessed", ".", "mentions", ",", "skipped", "=", "filterMentions", "(", "\n", "preprocessed", ",", "\n", "options", "\n", ")", "\n", "# re-calculate mentions_by_id to remove filtered sampled", "\n", "preprocessed", ".", "mentions_by_id", "=", "{", "\n", "m", ".", "ID", ":", "m", "\n", "for", "m", "in", "preprocessed", ".", "mentions", "\n", "}", "\n", "log", ".", "writeln", "(", "'  Removed {0:,} mentions with no valid features'", ".", "format", "(", "skipped", ")", ")", "\n", "log", ".", "writeln", "(", "'Filtered dataset size: {0:,} mentions\\n'", ".", "format", "(", "len", "(", "preprocessed", ".", "mentions", ")", ")", ")", "\n", "\n", "results", "=", "runCrossfoldExperiment", "(", "\n", "preprocessed", ",", "\n", "preds_stream", ",", "\n", "options", "\n", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.readSingleSplits": [[63, 70], ["codecs.open", "data.append", "s.strip", "id_cast", "line.split"], "function", ["None"], ["def", "readSingleSplits", "(", "f", ",", "id_cast", "=", "int", ")", ":", "\n", "    ", "data", "=", "[", "]", "\n", "with", "codecs", ".", "open", "(", "f", ",", "'r'", ",", "'utf-8'", ")", "as", "stream", ":", "\n", "        ", "for", "line", "in", "stream", ":", "\n", "            ", "(", "_id", ",", "lbl", ")", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "line", ".", "split", "(", "'\\t'", ")", "]", "\n", "data", ".", "append", "(", "id_cast", "(", "_id", ")", ")", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.readSplits": [[71, 81], ["range", "len", "cross_validation.readSingleSplits", "cross_validation.readSingleSplits", "cross_validation.readSingleSplits", "splits.append", "glob.glob"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.readSingleSplits", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.readSingleSplits", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.readSingleSplits"], ["", "def", "readSplits", "(", "f", ",", "n_folds", "=", "None", ",", "id_cast", "=", "int", ")", ":", "\n", "    ", "splits", "=", "[", "]", "\n", "if", "n_folds", "is", "None", ":", "\n", "        ", "n_folds", "=", "len", "(", "glob", ".", "glob", "(", "'%s.fold-*.train'", "%", "f", ")", ")", "\n", "", "for", "i", "in", "range", "(", "n_folds", ")", ":", "\n", "        ", "train", "=", "readSingleSplits", "(", "'%s.fold-%d.train'", "%", "(", "f", ",", "i", ")", ",", "id_cast", "=", "id_cast", ")", "\n", "dev", "=", "readSingleSplits", "(", "'%s.fold-%d.dev'", "%", "(", "f", ",", "i", ")", ",", "id_cast", "=", "id_cast", ")", "\n", "test", "=", "readSingleSplits", "(", "'%s.fold-%d.test'", "%", "(", "f", ",", "i", ")", ",", "id_cast", "=", "id_cast", ")", "\n", "splits", ".", "append", "(", "(", "train", ",", "dev", ",", "test", ")", ")", "\n", "", "return", "splits", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.writeSingleSplits": [[82, 86], ["codecs.open", "stream.write", "str", "str"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write"], ["", "def", "writeSingleSplits", "(", "data", ",", "f", ")", ":", "\n", "    ", "with", "codecs", ".", "open", "(", "f", ",", "'w'", ",", "'utf-8'", ")", "as", "stream", ":", "\n", "        ", "for", "(", "_id", ",", "lbl", ")", "in", "data", ":", "\n", "            ", "stream", ".", "write", "(", "'%s\\t%s\\n'", "%", "(", "str", "(", "_id", ")", ",", "str", "(", "lbl", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.writeSplits": [[87, 93], ["range", "len", "cross_validation.writeSingleSplits", "cross_validation.writeSingleSplits", "cross_validation.writeSingleSplits"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.writeSingleSplits", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.writeSingleSplits", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.writeSingleSplits"], ["", "", "", "def", "writeSplits", "(", "splits", ",", "f", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "len", "(", "splits", ")", ")", ":", "\n", "        ", "(", "train", ",", "dev", ",", "test", ")", "=", "splits", "[", "i", "]", "\n", "writeSingleSplits", "(", "train", ",", "'%s.fold-%d.train'", "%", "(", "f", ",", "i", ")", ")", "\n", "writeSingleSplits", "(", "dev", ",", "'%s.fold-%d.dev'", "%", "(", "f", ",", "i", ")", ")", "\n", "writeSingleSplits", "(", "test", ",", "'%s.fold-%d.test'", "%", "(", "f", ",", "i", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.stratifyByClass": [[94, 110], ["list", "list.sort", "type", "iter", "iter", "ids_by_class[].append", "ids_by_class.keys", "dataset.items"], "function", ["None"], ["", "", "def", "stratifyByClass", "(", "dataset", ")", ":", "\n", "# stratify the data by class", "\n", "    ", "ids_by_class", "=", "{", "}", "\n", "if", "type", "(", "dataset", ")", "is", "dict", ":", "\n", "        ", "item_iterator", "=", "iter", "(", "dataset", ".", "items", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "item_iterator", "=", "iter", "(", "dataset", ")", "\n", "", "for", "(", "_id", ",", "label", ")", "in", "item_iterator", ":", "\n", "        ", "if", "not", "label", "in", "ids_by_class", ":", "\n", "            ", "ids_by_class", "[", "label", "]", "=", "[", "]", "\n", "", "ids_by_class", "[", "label", "]", ".", "append", "(", "_id", ")", "\n", "\n", "", "classes", "=", "list", "(", "ids_by_class", ".", "keys", "(", ")", ")", "\n", "classes", ".", "sort", "(", ")", "\n", "\n", "return", "ids_by_class", ",", "classes", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.getFoldAndDevSizeByClass": [[111, 129], ["ids_by_class.items", "math.ceil", "len", "int", "len"], "function", ["None"], ["", "def", "getFoldAndDevSizeByClass", "(", "ids_by_class", ",", "n_folds", ",", "dev_size", ",", "no_test", "=", "False", ")", ":", "\n", "    ", "fold_size_by_class", ",", "dev_size_by_class", "=", "{", "}", ",", "{", "}", "\n", "\n", "dev_multiplier", "=", "n_folds", "\n", "\n", "for", "(", "_class", ",", "subset", ")", "in", "ids_by_class", ".", "items", "(", ")", ":", "\n", "# using ceil ensures a more balanced distribution", "\n", "# for everything other than the last fold", "\n", "        ", "fold_size_by_class", "[", "_class", "]", "=", "math", ".", "ceil", "(", "\n", "len", "(", "subset", ")", "/", "n_folds", "\n", ")", "\n", "if", "len", "(", "subset", ")", "<", "3", ":", "\n", "            ", "dev_size_by_class", "[", "_class", "]", "=", "0", "\n", "", "else", ":", "\n", "            ", "dev_size_by_class", "[", "_class", "]", "=", "int", "(", "\n", "fold_size_by_class", "[", "_class", "]", "*", "dev_size", "*", "dev_multiplier", "\n", ")", "\n", "", "", "return", "fold_size_by_class", ",", "dev_size_by_class", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.collapseFromByClass": [[130, 140], ["dct.items", "labeled_data.extend", "id_data.extend"], "function", ["None"], ["", "def", "collapseFromByClass", "(", "dct", ")", ":", "\n", "    ", "labeled_data", ",", "id_data", "=", "[", "]", ",", "[", "]", "\n", "for", "(", "k", ",", "v", ")", "in", "dct", ".", "items", "(", ")", ":", "\n", "        ", "labeled_data", ".", "extend", "(", "[", "\n", "(", "v_item", ",", "k", ")", "for", "v_item", "in", "v", "\n", "]", ")", "\n", "id_data", ".", "extend", "(", "[", "\n", "v_item", "for", "v_item", "in", "v", "\n", "]", ")", "\n", "", "return", "labeled_data", ",", "id_data", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.crossValidationSplits": [[141, 217], ["hedgepig_logger.log.writeln", "os.path.isfile", "hedgepig_logger.log.writeln", "cross_validation.readSplits", "hedgepig_logger.log.writeln", "numpy.random.seed", "cross_validation.stratifyByClass", "ids_by_class.items", "hedgepig_logger.log.writeln", "hedgepig_logger.log.writeln", "cross_validation.getFoldAndDevSizeByClass", "range", "len", "numpy.random.shuffle", "range", "cross_validation.collapseFromByClass", "cross_validation.collapseFromByClass", "cross_validation.collapseFromByClass", "labeled_splits.append", "id_splits.append", "hedgepig_logger.log.writeln", "hedgepig_logger.log.writeln", "cross_validation.writeSplits", "len", "fold_by_class.copy", "len", "len", "len", "fold_by_class.items", "fold_by_class.items", "train_by_class[].extend", "train_by_class[].extend"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.readSplits", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.stratifyByClass", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.getFoldAndDevSizeByClass", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.collapseFromByClass", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.collapseFromByClass", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.collapseFromByClass", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.cross_validation.writeSplits", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_file.EmbeddedMention.copy"], ["", "def", "crossValidationSplits", "(", "dataset", ",", "n_folds", ",", "dev_size", ",", "persistent_path", "=", "None", ",", "random_seed", "=", "1", ",", "log", "=", "log", ")", ":", "\n", "    ", "if", "persistent_path", "and", "os", ".", "path", ".", "isfile", "(", "'%s.fold-0.train'", "%", "persistent_path", ")", ":", "\n", "        ", "log", ".", "writeln", "(", "'Reading pre-existing cross validation splits from %s.'", "%", "persistent_path", ")", "\n", "splits", "=", "readSplits", "(", "persistent_path", ",", "n_folds", ",", "id_cast", "=", "int", ")", "\n", "", "else", ":", "\n", "        ", "log", ".", "writeln", "(", "'Generating cross-validation splits...'", ")", "\n", "np", ".", "random", ".", "seed", "(", "random_seed", ")", "\n", "\n", "ids_by_class", ",", "classes", "=", "stratifyByClass", "(", "dataset", ")", "\n", "\n", "total_size", "=", "0", "\n", "for", "(", "lbl", ",", "ids", ")", "in", "ids_by_class", ".", "items", "(", ")", ":", "\n", "            ", "total_size", "+=", "len", "(", "ids", ")", "\n", "", "log", ".", "writeln", "(", "'  Dataset size: {0:,}'", ".", "format", "(", "total_size", ")", ")", "\n", "log", ".", "writeln", "(", "'  Number of classes: {0:,}'", ".", "format", "(", "len", "(", "classes", ")", ")", ")", "\n", "\n", "# shuffle it", "\n", "for", "_class", "in", "classes", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "ids_by_class", "[", "_class", "]", ")", "\n", "\n", "# figure out how many points of each class per fold", "\n", "", "fold_size_by_class", ",", "dev_size_by_class", "=", "getFoldAndDevSizeByClass", "(", "\n", "ids_by_class", ",", "n_folds", ",", "dev_size", "\n", ")", "\n", "\n", "labeled_splits", ",", "id_splits", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "n_folds", ")", ":", "\n", "            ", "train_by_class", "=", "{", "}", "\n", "for", "_class", "in", "classes", ":", "\n", "                ", "train_by_class", "[", "_class", "]", "=", "[", "]", "\n", "\n", "", "for", "j", "in", "range", "(", "n_folds", ")", ":", "\n", "                ", "fold_by_class", "=", "{", "}", "\n", "for", "_class", "in", "classes", ":", "\n", "                    ", "fold_size", "=", "fold_size_by_class", "[", "_class", "]", "\n", "if", "j", "<", "(", "n_folds", "-", "1", ")", ":", "\n", "                        ", "fold_by_class", "[", "_class", "]", "=", "ids_by_class", "[", "_class", "]", "[", "j", "*", "fold_size", ":", "(", "j", "+", "1", ")", "*", "fold_size", "]", "\n", "", "else", ":", "\n", "                        ", "fold_by_class", "[", "_class", "]", "=", "ids_by_class", "[", "_class", "]", "[", "j", "*", "fold_size", ":", "]", "\n", "\n", "# pull test", "\n", "", "", "if", "j", "==", "i", ":", "\n", "                    ", "test_by_class", "=", "fold_by_class", ".", "copy", "(", ")", "\n", "# pull dev (portion)", "\n", "", "elif", "j", "==", "(", "(", "i", "+", "1", ")", "%", "n_folds", ")", ":", "\n", "                    ", "dev_by_class", "=", "{", "}", "\n", "for", "(", "_class", ",", "subset", ")", "in", "fold_by_class", ".", "items", "(", ")", ":", "\n", "                        ", "dev_by_class", "[", "_class", "]", "=", "subset", "[", ":", "dev_size_by_class", "[", "_class", "]", "]", "\n", "train_by_class", "[", "_class", "]", ".", "extend", "(", "\n", "subset", "[", "dev_size_by_class", "[", "_class", "]", ":", "]", "\n", ")", "\n", "# everything else goes to training", "\n", "", "", "else", ":", "\n", "                    ", "for", "(", "_class", ",", "subset", ")", "in", "fold_by_class", ".", "items", "(", ")", ":", "\n", "                        ", "train_by_class", "[", "_class", "]", ".", "extend", "(", "subset", ")", "\n", "\n", "# collapse train, dev, test to flat ID lists", "\n", "", "", "", "lbl_train", ",", "id_train", "=", "collapseFromByClass", "(", "train_by_class", ")", "\n", "lbl_dev", ",", "id_dev", "=", "collapseFromByClass", "(", "dev_by_class", ")", "\n", "lbl_test", ",", "id_test", "=", "collapseFromByClass", "(", "test_by_class", ")", "\n", "\n", "labeled_splits", ".", "append", "(", "(", "lbl_train", ",", "lbl_dev", ",", "lbl_test", ")", ")", "\n", "id_splits", ".", "append", "(", "(", "id_train", ",", "id_dev", ",", "id_test", ")", ")", "\n", "\n", "log", ".", "writeln", "(", "'  Fold {0} -- Train: {1:,}  Dev: {2:,}  Test: {3:,}'", ".", "format", "(", "\n", "i", "+", "1", ",", "len", "(", "id_train", ")", ",", "len", "(", "id_dev", ")", ",", "len", "(", "id_test", ")", "\n", ")", ")", "\n", "\n", "", "if", "persistent_path", ":", "\n", "            ", "log", ".", "writeln", "(", "'Writing cross validation splits to %s.'", "%", "persistent_path", ")", "\n", "writeSplits", "(", "labeled_splits", ",", "persistent_path", ")", "\n", "\n", "", "splits", "=", "id_splits", "\n", "", "log", ".", "writeln", "(", ")", "\n", "\n", "return", "splits", "\n", "", ""]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.generate_xval_splits.readFilterDocIDSet": [[58, 64], ["set", "open", "set.add", "line.strip"], "function", ["None"], ["def", "readFilterDocIDSet", "(", "f", ")", ":", "\n", "    ", "doc_IDs", "=", "set", "(", ")", "\n", "with", "open", "(", "f", ",", "'r'", ")", "as", "stream", ":", "\n", "        ", "for", "line", "in", "stream", ":", "\n", "            ", "doc_IDs", ".", "add", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "return", "doc_IDs", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.util.Indexer.__init__": [[61, 64], ["range", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ")", ":", "\n", "        ", "self", ".", "_vocab", "=", "vocab", "\n", "self", ".", "_indices", "=", "{", "vocab", "[", "i", "]", ":", "i", "for", "i", "in", "range", "(", "len", "(", "vocab", ")", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.util.Indexer.indexOf": [[65, 67], ["util.Indexer._indices.get"], "methods", ["None"], ["", "def", "indexOf", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_indices", ".", "get", "(", "key", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.util.Indexer.__getitem__": [[68, 70], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "_vocab", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.util.meanEmbeddings": [[72, 81], ["util.meanEmbeddingVectors", "s.strip", "context_string.lower().split", "word_embs.append", "context_string.lower"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.util.meanEmbeddingVectors"], ["", "", "def", "meanEmbeddings", "(", "strings", ",", "ctx_embeds", ")", ":", "\n", "    ", "word_embs", ",", "valid_ctx_embedding", "=", "[", "]", ",", "False", "\n", "for", "context_string", "in", "strings", ":", "\n", "        ", "words", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "context_string", ".", "lower", "(", ")", ".", "split", "(", ")", "]", "\n", "for", "w", "in", "words", ":", "\n", "            ", "if", "w", "in", "ctx_embeds", ":", "\n", "                ", "word_embs", ".", "append", "(", "ctx_embeds", "[", "w", "]", ")", "\n", "", "", "", "(", "ctx_embedding", ",", "valid_ctx_embedding", ")", "=", "meanEmbeddingVectors", "(", "word_embs", ",", "ctx_embeds", ".", "size", ")", "\n", "return", "ctx_embedding", ",", "valid_ctx_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.util.meanEmbeddingVectors": [[82, 90], ["len", "numpy.mean", "numpy.zeros"], "function", ["None"], ["", "def", "meanEmbeddingVectors", "(", "vectors", ",", "dim", ")", ":", "\n", "    ", "if", "len", "(", "vectors", ")", ">", "0", ":", "\n", "        ", "mean_vector", "=", "np", ".", "mean", "(", "vectors", ",", "axis", "=", "0", ")", "\n", "valid", "=", "True", "\n", "", "else", ":", "\n", "        ", "mean_vector", "=", "np", ".", "zeros", "(", "dim", ")", "\n", "valid", "=", "False", "\n", "", "return", "mean_vector", ",", "valid", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.util.readVocab": [[91, 97], ["set", "codecs.open", "set.add", "line.strip"], "function", ["None"], ["", "def", "readVocab", "(", "f", ")", ":", "\n", "    ", "vocab", "=", "set", "(", ")", "\n", "with", "codecs", ".", "open", "(", "f", ",", "'r'", ",", "'utf-8'", ")", "as", "stream", ":", "\n", "        ", "for", "line", "in", "stream", ":", "\n", "            ", "vocab", ".", "add", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.util.readPreferredStrings": [[98, 105], ["codecs.open", "s.strip", "line.split", "entity_id.lower"], "function", ["None"], ["", "def", "readPreferredStrings", "(", "f", ")", ":", "\n", "    ", "pref_strings", "=", "{", "}", "\n", "with", "codecs", ".", "open", "(", "f", ",", "'r'", ",", "'utf-8'", ")", "as", "stream", ":", "\n", "        ", "for", "line", "in", "stream", ":", "\n", "            ", "(", "entity_id", ",", "string", ")", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "line", ".", "split", "(", "'\\t'", ")", "]", "\n", "pref_strings", "[", "entity_id", ".", "lower", "(", ")", "]", "=", "string", "\n", "", "", "return", "pref_strings", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.util.readSubsetMap": [[106, 120], ["codecs.open", "_map[].append", "s.strip", "int", "line.split"], "function", ["None"], ["", "def", "readSubsetMap", "(", "f", ")", ":", "\n", "    ", "r'''Takes as input a tab-separated file of format\n      <mention ID> \\t <subset>\n    and returns a dictionary mapping\n      <subset> : [ <mention ID list> ]\n    '''", "\n", "_map", "=", "{", "}", "\n", "with", "codecs", ".", "open", "(", "f", ",", "'r'", ",", "'utf-8'", ")", "as", "stream", ":", "\n", "        ", "for", "line", "in", "stream", ":", "\n", "            ", "(", "mention_id", ",", "subset", ")", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "line", ".", "split", "(", "'\\t'", ")", "]", "\n", "if", "not", "subset", "in", "_map", ":", "\n", "                ", "_map", "[", "subset", "]", "=", "[", "]", "\n", "", "_map", "[", "subset", "]", ".", "append", "(", "int", "(", "mention_id", ")", ")", "\n", "", "", "return", "_map", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.util.finalPerSubsetReport": [[121, 135], ["log.writeln", "log.writeln", "log.writeln", "log.writeln", "log.writeln", "numpy.mean", "len", "float", "per_subset_results.values"], "function", ["None"], ["", "def", "finalPerSubsetReport", "(", "log", ",", "per_subset_results", ",", "subsets", ")", ":", "\n", "    ", "log", ".", "writeln", "(", "'\\n\\n{0}\\n  Final report\\n{0}'", ".", "format", "(", "'='", "*", "30", ")", ")", "\n", "micro_correct", ",", "micro_total", ",", "subsets_counted", "=", "0", ",", "0", ",", "0", "\n", "for", "subset", "in", "subsets", ":", "\n", "        ", "if", "subset", "in", "per_subset_results", ":", "\n", "            ", "subsets_counted", "+=", "1", "\n", "m", "=", "per_subset_results", "[", "subset", "]", "\n", "micro_correct", "+=", "m", ".", "correct", "\n", "micro_total", "+=", "m", ".", "total", "\n", "log", ".", "writeln", "(", "'  %s --> %f (%d/%d)'", "%", "(", "subset", ",", "m", ".", "accuracy", ",", "m", ".", "correct", ",", "m", ".", "total", ")", ")", "\n", "\n", "", "", "log", ".", "writeln", "(", "'\\nOverall micro accuracy: %f (%d/%d)'", "%", "(", "float", "(", "micro_correct", ")", "/", "micro_total", ",", "micro_correct", ",", "micro_total", ")", ")", "\n", "log", ".", "writeln", "(", "'Overall macro accuracy: %f'", "%", "np", ".", "mean", "(", "[", "m", ".", "accuracy", "for", "m", "in", "per_subset_results", ".", "values", "(", ")", "]", ")", ")", "\n", "log", ".", "writeln", "(", "'Subsets included in overall analysis: %d/%d'", "%", "(", "subsets_counted", ",", "len", "(", "subsets", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.experiments.util.writeDetailedOutcome": [[136, 178], ["range", "type", "stream.write", "len", "type", "stream.write", "stream.write", "entity_str.lower", "correct_candidate.lower"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write"], ["", "def", "writeDetailedOutcome", "(", "stream", ",", "mention", ",", "probs", ",", "batch_entity_masks", ",", "\n", "preferred_strings", ",", "correct_candidate", ",", "pred_ix", ",", "i", ",", "fold", "=", "None", ")", ":", "\n", "    ", "if", "type", "(", "mention", ")", "is", "mention_file", ".", "Mention", ":", "\n", "        ", "stream", ".", "write", "(", "\n", "'\\n-----------------------------------------------------\\n'", "\n", "'Mention %d %s\\n'", "\n", "'  Left context: %s\\n'", "\n", "'  Mention text: %s\\n'", "\n", "'  Right context: %s\\n'", "\n", "'  Candidates: [ %s ]\\n'", "\n", "'  Correct answer: %s\\n'", "\n", "'\\nPredictions\\n'", "%", "(", "\n", "mention", ".", "ID", ",", "\n", "(", "(", "' (Fold %d)'", "%", "i", ")", "if", "not", "fold", "is", "None", "else", "''", ")", ",", "\n", "mention", ".", "left_context", ",", "\n", "mention", ".", "mention_text", ",", "\n", "mention", ".", "right_context", ",", "\n", "', '", ".", "join", "(", "mention", ".", "candidates", ")", ",", "\n", "mention", ".", "CUI", "\n", ")", "\n", ")", "\n", "", "elif", "type", "(", "mention", ")", "is", "mention_file", ".", "EmbeddedMention", ":", "\n", "        ", "stream", ".", "write", "(", "\n", "'\\n-----------------------------------------------------\\n'", "\n", "'Mention %d %s - pre-embedded\\n'", "\n", "'  Candidates: [ %s ]\\n'", "\n", "'  Correct answer: %s\\n'", "\n", "'\\nPredictions\\n'", "%", "(", "\n", "mention", ".", "ID", ",", "\n", "(", "(", "' (Fold %d)'", "%", "i", ")", "if", "not", "fold", "is", "None", "else", "''", ")", ",", "\n", "', '", ".", "join", "(", "mention", ".", "candidates", ")", ",", "\n", "mention", ".", "CUI", "\n", ")", "\n", ")", "\n", "", "for", "j", "in", "range", "(", "len", "(", "probs", "[", "i", "]", ")", ")", ":", "\n", "        ", "if", "batch_entity_masks", "[", "i", "]", "[", "j", "]", "==", "1", ":", "\n", "            ", "entity_str", "=", "mention", ".", "candidates", "[", "j", "]", "\n", "stream", ".", "write", "(", "'  %s --> %f   Gold: %s  Pred: %s\\n'", "%", "(", "\n", "entity_str", ",", "\n", "probs", "[", "i", "]", "[", "j", "]", ",", "\n", "(", "'X'", "if", "entity_str", ".", "lower", "(", ")", "==", "correct_candidate", ".", "lower", "(", ")", "else", "' '", ")", ",", "\n", "(", "'X'", "if", "pred_ix", "==", "j", "else", "' '", ")", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.candidate_selection.lesk_baseline.preprocessData": [[79, 94], ["types.SimpleNamespace", "m.CUI.strip().lower", "m.CUI.strip"], "function", ["None"], ["def", "preprocessData", "(", "mentions", ",", "options", ")", ":", "\n", "    ", "preprocessed", "=", "SimpleNamespace", "(", ")", "\n", "\n", "preprocessed", ".", "mentions", "=", "mentions", "\n", "\n", "preprocessed", ".", "mentions_by_id", "=", "{", "\n", "m", ".", "ID", ":", "m", "\n", "for", "m", "in", "mentions", "\n", "}", "\n", "preprocessed", ".", "labels_by_id", "=", "{", "\n", "m", ".", "ID", ":", "m", ".", "CUI", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "for", "m", "in", "mentions", "\n", "}", "\n", "\n", "return", "preprocessed", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.candidate_selection.lesk_baseline.readCodeDefinitions": [[95, 108], ["open", "tokenizer.tokenize", "s.strip", "set", "line.split", "definitions[].add", "tok.lower", "stemmer.stem"], "function", ["None"], ["", "def", "readCodeDefinitions", "(", "f", ",", "main_only", "=", "False", ")", ":", "\n", "    ", "definitions", "=", "{", "}", "\n", "with", "open", "(", "f", ",", "'r'", ")", "as", "stream", ":", "\n", "        ", "for", "line", "in", "stream", ":", "\n", "            ", "(", "code", ",", "_type", ",", "defn", ")", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "line", ".", "split", "(", "'\\t'", ")", "]", "\n", "if", "main_only", "and", "_type", "!=", "'main'", ":", "\n", "                ", "continue", "\n", "", "if", "not", "code", "in", "definitions", ":", "\n", "                ", "definitions", "[", "code", "]", "=", "set", "(", ")", "\n", "", "for", "tok", "in", "tokenizer", ".", "tokenize", "(", "defn", ")", ":", "\n", "                ", "if", "not", "tok", ".", "lower", "(", ")", "in", "stopwords", ":", "\n", "                    ", "definitions", "[", "code", "]", ".", "add", "(", "stemmer", ".", "stem", "(", "tok", ")", ")", "\n", "", "", "", "", "return", "definitions", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.candidate_selection.lesk_baseline.getMostSimilar": [[109, 133], ["set", "mention.candidates.index", "string.split", "lesk_baseline.calculateSimilarity", "similarities.get", "max", "numpy.argmax", "definitions.items", "set.add", "tok.lower", "stemmer.stem"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.candidate_selection.lesk_baseline.calculateSimilarity"], ["", "def", "getMostSimilar", "(", "mention", ",", "definitions", ",", "default", ")", ":", "\n", "    ", "mention_toks", "=", "set", "(", ")", "\n", "for", "string", "in", "[", "mention", ".", "left_context", ",", "mention", ".", "right_context", ",", "mention", ".", "mention_text", "]", ":", "\n", "        ", "toks", "=", "string", ".", "split", "(", ")", "\n", "for", "tok", "in", "toks", ":", "\n", "            ", "if", "not", "tok", ".", "lower", "(", ")", "in", "stopwords", ":", "\n", "                ", "mention_toks", ".", "add", "(", "stemmer", ".", "stem", "(", "tok", ")", ")", "\n", "\n", "", "", "", "similarities", "=", "{", "\n", "code", ":", "calculateSimilarity", "(", "mention_toks", ",", "defn_toks", ")", "\n", "for", "(", "code", ",", "defn_toks", ")", "\n", "in", "definitions", ".", "items", "(", ")", "\n", "}", "\n", "\n", "default_ix", "=", "mention", ".", "candidates", ".", "index", "(", "default", ")", "\n", "ordered_similarities", "=", "[", "\n", "similarities", ".", "get", "(", "c", ",", "0.", ")", "\n", "for", "c", "in", "mention", ".", "candidates", "\n", "]", "\n", "\n", "if", "max", "(", "ordered_similarities", ")", "==", "0", ":", "\n", "        ", "return", "default_ix", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "argmax", "(", "ordered_similarities", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.candidate_selection.lesk_baseline.calculateSimilarity": [[134, 141], ["len", "mention_toks.intersection", "numpy.sqrt", "numpy.sqrt", "len", "len"], "function", ["None"], ["", "", "def", "calculateSimilarity", "(", "mention_toks", ",", "defn_toks", ")", ":", "\n", "    ", "numerator", "=", "len", "(", "mention_toks", ".", "intersection", "(", "defn_toks", ")", ")", "\n", "denominator", "=", "(", "\n", "np", ".", "sqrt", "(", "len", "(", "mention_toks", ")", ")", "\n", "*", "np", ".", "sqrt", "(", "len", "(", "defn_toks", ")", ")", "\n", ")", "\n", "return", "(", "numerator", "/", "denominator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.candidate_selection.lesk_baseline.runLeskExperiment": [[142, 172], ["hedgepig_logger.log.writeln", "types.SimpleNamespace", "range", "hedgepig_logger.log.writeln", "test_labels.append", "predictions.append", "len", "float", "m.CUI.lower", "lesk_baseline.getMostSimilar", "preds_stream.write", "m.candidates.index"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.candidate_selection.lesk_baseline.getMostSimilar", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write"], ["", "def", "runLeskExperiment", "(", "preprocessed", ",", "definitions", ",", "preds_stream", ",", "options", ")", ":", "\n", "    ", "log", ".", "writeln", "(", "(", "'\\n\\n{0}\\n  Starting experiment\\n{0}\\n'", ".", "format", "(", "'#'", "*", "80", ")", ")", ")", "\n", "\n", "test_labels", ",", "predictions", "=", "[", "]", ",", "[", "]", "\n", "for", "m", "in", "preprocessed", ".", "mentions", ":", "\n", "        ", "test_labels", ".", "append", "(", "m", ".", "CUI", ".", "lower", "(", ")", ")", "\n", "predictions", ".", "append", "(", "getMostSimilar", "(", "m", ",", "definitions", ",", "default", "=", "'d450'", ")", ")", "\n", "\n", "", "metrics", "=", "SimpleNamespace", "(", ")", "\n", "metrics", ".", "correct", "=", "0", "\n", "metrics", ".", "total", "=", "0", "\n", "\n", "for", "j", "in", "range", "(", "len", "(", "predictions", ")", ")", ":", "\n", "        ", "m", "=", "preprocessed", ".", "mentions", "[", "j", "]", "\n", "\n", "if", "m", ".", "candidates", "[", "predictions", "[", "j", "]", "]", "==", "test_labels", "[", "j", "]", ":", "\n", "            ", "metrics", ".", "correct", "+=", "1", "\n", "", "metrics", ".", "total", "+=", "1", "\n", "\n", "if", "preds_stream", ":", "\n", "            ", "preds_stream", ".", "write", "(", "'Mention %d -- Pred: %d -> %s  Gold: %d -> %s\\n'", "%", "(", "\n", "preprocessed", ".", "mentions", "[", "j", "]", ".", "ID", ",", "\n", "predictions", "[", "j", "]", ",", "\n", "m", ".", "candidates", "[", "predictions", "[", "j", "]", "]", ",", "\n", "m", ".", "candidates", ".", "index", "(", "test_labels", "[", "j", "]", ")", ",", "\n", "test_labels", "[", "j", "]", "\n", ")", ")", "\n", "\n", "", "", "metrics", ".", "accuracy", "=", "float", "(", "metrics", ".", "correct", ")", "/", "metrics", ".", "total", "\n", "log", ".", "writeln", "(", "'Accuracy: {0:.2f} ({1:,}/{2:,})'", ".", "format", "(", "metrics", ".", "accuracy", ",", "metrics", ".", "correct", ",", "metrics", ".", "total", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.candidate_selection.lesk_baseline.experimentWrapper": [[173, 187], ["lesk_baseline.preprocessData", "lesk_baseline.runLeskExperiment"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.candidate_selection.lesk_baseline.preprocessData", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.candidate_selection.lesk_baseline.runLeskExperiment"], ["", "def", "experimentWrapper", "(", "mentions", ",", "definitions", ",", "options", ",", "preds_stream", ")", ":", "\n", "    ", "preprocessed", "=", "preprocessData", "(", "\n", "mentions", ",", "\n", "options", "\n", ")", "\n", "\n", "results", "=", "runLeskExperiment", "(", "\n", "preprocessed", ",", "\n", "definitions", ",", "\n", "preds_stream", ",", "\n", "options", "\n", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_file.Mention.__init__": [[59, 66], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "CUI", ",", "mention_text", ",", "left_context", ",", "right_context", ",", "candidates", ",", "ID", "=", "None", ")", ":", "\n", "        ", "self", ".", "CUI", "=", "CUI", "\n", "self", ".", "mention_text", "=", "mention_text", "\n", "self", ".", "left_context", "=", "left_context", "\n", "self", ".", "right_context", "=", "right_context", "\n", "self", ".", "candidates", "=", "candidates", "\n", "self", ".", "ID", "=", "ID", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_file.Mention.copy": [[67, 75], ["mention_file.Mention", "str", "str", "str", "str", "mention_file.Mention.candidates.copy"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_file.EmbeddedMention.copy"], ["", "def", "copy", "(", "self", ")", ":", "\n", "        ", "return", "Mention", "(", "\n", "CUI", "=", "str", "(", "self", ".", "CUI", ")", ",", "\n", "mention_text", "=", "str", "(", "self", ".", "mention_text", ")", ",", "\n", "left_context", "=", "str", "(", "self", ".", "left_context", ")", ",", "\n", "right_context", "=", "str", "(", "self", ".", "right_context", ")", ",", "\n", "candidates", "=", "self", ".", "candidates", ".", "copy", "(", ")", ",", "\n", "ID", "=", "self", ".", "ID", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_file.EmbeddedMention.__init__": [[78, 84], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "CUI", ",", "mention_repr", ",", "context_repr", ",", "candidates", ",", "ID", "=", "None", ")", ":", "\n", "        ", "self", ".", "CUI", "=", "CUI", "\n", "self", ".", "mention_repr", "=", "mention_repr", "\n", "self", ".", "context_repr", "=", "context_repr", "\n", "self", ".", "candidates", "=", "candidates", "\n", "self", ".", "ID", "=", "ID", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_file.EmbeddedMention.copy": [[85, 92], ["mention_file.EmbeddedMention", "str", "mention_file.EmbeddedMention.candidates.copy"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_file.EmbeddedMention.copy"], ["", "def", "copy", "(", "self", ")", ":", "\n", "        ", "return", "EmbeddedMention", "(", "\n", "CUI", "=", "str", "(", "self", ".", "CUI", ")", ",", "\n", "mention_repr", "=", "self", ".", "mention_repr", ",", "\n", "context_repr", "=", "self", ".", "context_repr", ",", "\n", "candidates", "=", "self", ".", "candidates", ".", "copy", "(", ")", ",", "\n", "ID", "=", "self", ".", "ID", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_file.write": [[94, 129], ["type", "codecs.open", "stream.write", "type", "stream.write", "type", "stream.write", "Exception", "repr", "str", "type", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write"], ["", "", "def", "write", "(", "mentions", ",", "outf", ",", "encoding", "=", "'utf-8'", ")", ":", "\n", "    ", "max_ID", "=", "0", "\n", "for", "m", "in", "mentions", ":", "\n", "        ", "if", "not", "m", ".", "ID", "is", "None", "and", "m", ".", "ID", ">", "max_ID", ":", "\n", "            ", "max_ID", "=", "m", ".", "ID", "\n", "\n", "", "", "fmt_str", "=", "'TXT'", "\n", "if", "type", "(", "mentions", "[", "0", "]", ")", "is", "EmbeddedMention", ":", "\n", "        ", "fmt_str", "=", "'BIN'", "\n", "\n", "", "with", "codecs", ".", "open", "(", "outf", ",", "'w'", ",", "encoding", ")", "as", "stream", ":", "\n", "        ", "stream", ".", "write", "(", "'%s\\n'", "%", "fmt_str", ")", "\n", "for", "m", "in", "mentions", ":", "\n", "            ", "if", "m", ".", "ID", "is", "None", ":", "\n", "                ", "m", ".", "ID", "=", "max_ID", "\n", "max_ID", "+=", "1", "\n", "", "if", "type", "(", "m", ")", "is", "Mention", ":", "\n", "                ", "stream", ".", "write", "(", "'%s\\n'", "%", "'\\t'", ".", "join", "(", "[", "\n", "str", "(", "m", ".", "ID", ")", ",", "\n", "m", ".", "mention_text", ",", "\n", "m", ".", "left_context", ",", "\n", "m", ".", "right_context", ",", "\n", "m", ".", "CUI", ",", "\n", "'||'", ".", "join", "(", "m", ".", "candidates", ")", "\n", "]", ")", ")", "\n", "", "elif", "type", "(", "m", ")", "is", "EmbeddedMention", ":", "\n", "                ", "stream", ".", "write", "(", "'%s\\n'", "%", "'\\t'", ".", "join", "(", "[", "\n", "str", "(", "m", ".", "ID", ")", ",", "\n", "'None'", "if", "not", "m", ".", "mention_repr", "else", "(", "' '", ".", "join", "(", "[", "str", "(", "f", ")", "for", "f", "in", "m", ".", "mention_repr", "]", ")", ")", ",", "\n", "' '", ".", "join", "(", "[", "str", "(", "f", ")", "for", "f", "in", "m", ".", "context_repr", "]", ")", ",", "\n", "m", ".", "CUI", ",", "\n", "'||'", ".", "join", "(", "m", ".", "candidates", ")", "\n", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"Can't write mention of type '%s'!\"", "%", "repr", "(", "type", "(", "m", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_file.read": [[130, 177], ["codecs.open", "stream.read", "stream.seek", "print", "stream.readline", "s.strip", "chunks[].split.split", "mentions.append", "int", "chunks[].split", "mentions.append", "line.split", "len", "len", "mention_file.Mention", "float", "mention_file.EmbeddedMention", "len", "int", "len", "float", "chunks[].split", "len", "chunks[].split"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_file.read"], ["", "", "", "", "def", "read", "(", "mentionf", ",", "encoding", "=", "'utf-8'", ")", ":", "\n", "    ", "mentions", "=", "[", "]", "\n", "with", "codecs", ".", "open", "(", "mentionf", ",", "'r'", ",", "encoding", ")", "as", "stream", ":", "\n", "        ", "fmt", "=", "stream", ".", "read", "(", "3", ")", "\n", "stream", ".", "seek", "(", "0", ")", "\n", "if", "not", "fmt", "in", "[", "'BIN'", ",", "'TXT'", "]", ":", "\n", "            ", "fmt", "=", "'TXT'", "\n", "", "else", ":", "\n", "            ", "print", "(", "stream", ".", "readline", "(", ")", ")", "\n", "\n", "", "for", "line", "in", "stream", ":", "\n", "            ", "chunks", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "line", ".", "split", "(", "'\\t'", ")", "]", "\n", "if", "fmt", "==", "'TXT'", ":", "\n", "                ", "if", "len", "(", "chunks", ")", "==", "5", ":", "\n", "                    ", "ix", "=", "0", "\n", "_id", "=", "len", "(", "mentions", ")", "\n", "", "elif", "len", "(", "chunks", ")", "==", "6", ":", "\n", "                    ", "ix", "=", "1", "\n", "_id", "=", "int", "(", "chunks", "[", "0", "]", ")", "\n", "", "(", "\n", "mention_text", ",", "\n", "left_context", ",", "\n", "right_context", ",", "\n", "CUI", ",", "\n", "candidates", "\n", ")", "=", "chunks", "[", "ix", ":", "]", "\n", "candidates", "=", "candidates", ".", "split", "(", "'||'", ")", "\n", "if", "len", "(", "candidates", ")", "==", "1", "and", "candidates", "[", "0", "]", "==", "''", ":", "\n", "                    ", "candidates", "=", "[", "]", "\n", "", "mentions", ".", "append", "(", "Mention", "(", "\n", "CUI", ",", "mention_text", ",", "left_context", ",", "right_context", ",", "candidates", ",", "ID", "=", "_id", "\n", ")", ")", "\n", "", "else", ":", "\n", "                ", "_id", "=", "int", "(", "chunks", "[", "0", "]", ")", "\n", "if", "chunks", "[", "1", "]", "==", "'None'", ":", "\n", "                    ", "mention_repr", "=", "None", "\n", "", "else", ":", "\n", "                    ", "mention_repr", "=", "[", "float", "(", "f", ")", "for", "f", "in", "chunks", "[", "1", "]", ".", "split", "(", ")", "]", "\n", "", "context_repr", "=", "[", "float", "(", "f", ")", "for", "f", "in", "chunks", "[", "2", "]", ".", "split", "(", ")", "]", "\n", "CUI", "=", "chunks", "[", "3", "]", "\n", "candidates", "=", "chunks", "[", "4", "]", ".", "split", "(", "'||'", ")", "\n", "if", "len", "(", "candidates", ")", "==", "1", "and", "candidates", "[", "0", "]", "==", "''", ":", "\n", "                    ", "candidates", "=", "[", "]", "\n", "", "mentions", ".", "append", "(", "EmbeddedMention", "(", "\n", "CUI", ",", "mention_repr", ",", "context_repr", ",", "candidates", ",", "ID", "=", "_id", "\n", ")", ")", "\n", "", "", "", "return", "mentions", "\n", "", ""]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.tokenizer.Tokenizer.default": [[62, 65], ["None"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "default", "(", ")", ":", "\n", "        ", "return", "Tokenizer", ".", "SpaCy", "\n", "", "@", "staticmethod", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.tokenizer.Tokenizer.choices": [[65, 71], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "choices", "(", ")", ":", "\n", "        ", "return", "[", "\n", "Tokenizer", ".", "SpaCy", ",", "\n", "Tokenizer", ".", "PreTokenized", ",", "\n", "Tokenizer", ".", "BERT", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.tokenizer.Tokenizer.__init__": [[73, 87], ["spacy.load", "line.split", "tokenization.FullTokenizer", "spacy.load."], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.load"], ["", "def", "__init__", "(", "self", ",", "setting", ",", "bert_vocab_file", "=", "None", ")", ":", "\n", "        ", "if", "setting", "==", "Tokenizer", ".", "SpaCy", ":", "\n", "            ", "import", "spacy", "\n", "nlp", "=", "spacy", ".", "load", "(", "'en_core_web_sm'", ")", "\n", "self", ".", "tokenize", "=", "lambda", "line", ":", "[", "t", ".", "text", "for", "t", "in", "nlp", "(", "line", ")", "]", "\n", "", "elif", "setting", "==", "Tokenizer", ".", "PreTokenized", ":", "\n", "            ", "self", ".", "tokenize", "=", "lambda", "line", ":", "line", ".", "split", "(", ")", "\n", "", "elif", "setting", "==", "Tokenizer", ".", "BERT", ":", "\n", "            ", "from", "bert", "import", "tokenization", "\n", "tokenizer", "=", "tokenization", ".", "FullTokenizer", "(", "\n", "vocab_file", "=", "bert_vocab_file", ",", "\n", "do_lower_case", "=", "True", "\n", ")", "\n", "self", ".", "tokenize", "=", "tokenizer", ".", "tokenize", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.load": [[52, 59], ["open", "s.strip", "line.split", "int"], "function", ["None"], ["def", "load", "(", "f", ")", ":", "\n", "    ", "_map", "=", "{", "}", "\n", "with", "open", "(", "f", ",", "'r'", ")", "as", "stream", ":", "\n", "        ", "for", "line", "in", "stream", ":", "\n", "            ", "(", "m_ID", ",", "doc_ID", ")", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "line", ".", "split", "(", "'\\t'", ")", "]", "\n", "_map", "[", "int", "(", "m_ID", ")", "]", "=", "doc_ID", "\n", "", "", "return", "_map", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write": [[60, 64], ["open", "_map.items", "stream.write"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write"], ["", "def", "write", "(", "_map", ",", "f", ")", ":", "\n", "    ", "with", "open", "(", "f", ",", "'w'", ")", "as", "stream", ":", "\n", "        ", "for", "(", "m_ID", ",", "doc_ID", ")", "in", "_map", ".", "items", "(", ")", ":", "\n", "            ", "stream", ".", "write", "(", "'%d\\t%s\\n'", "%", "(", "m_ID", ",", "doc_ID", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.get_mentions.convertLinkedMention": [[77, 103], ["action.mobility.text[].replace().replace", "action.mobility.text[].replace().replace", "tokenizer.tokenize", "tokenizer.tokenize", "tokenizer.tokenize", "mention_file.Mention", "print", "input", "action.mobility.text[].replace", "action.mobility.text[].replace", "code.lower", "set", "code.lower"], "function", ["None"], ["def", "convertLinkedMention", "(", "action", ",", "tokenizer", ")", ":", "\n", "    ", "left_action_offset", "=", "action", ".", "start", "-", "action", ".", "mobility", ".", "start", "\n", "right_action_offset", "=", "action", ".", "end", "-", "action", ".", "mobility", ".", "start", "\n", "\n", "left_context", "=", "action", ".", "mobility", ".", "text", "[", ":", "left_action_offset", "]", ".", "replace", "(", "'\\t'", ",", "' '", ")", ".", "replace", "(", "'\\n'", ",", "' '", ")", "\n", "right_context", "=", "action", ".", "mobility", ".", "text", "[", "right_action_offset", ":", "]", ".", "replace", "(", "'\\t'", ",", "' '", ")", ".", "replace", "(", "'\\n'", ",", "' '", ")", "\n", "\n", "left_tokens", "=", "tokenizer", ".", "tokenize", "(", "left_context", ")", "\n", "right_tokens", "=", "tokenizer", ".", "tokenize", "(", "right_context", ")", "\n", "\n", "mention_tokens", "=", "tokenizer", ".", "tokenize", "(", "action", ".", "text", ")", "\n", "\n", "if", "action", ".", "code", "is", "None", ":", "\n", "        ", "code", "=", "'no_code'", "\n", "", "else", ":", "\n", "        ", "code", "=", "action", ".", "code", "\n", "", "if", "not", "code", ".", "lower", "(", ")", "in", "set", "(", "CANDIDATES", ")", ":", "\n", "        ", "print", "(", "'WHOA NELLY!  Action code \"%s\" is unmapped'", "%", "code", ")", "\n", "input", "(", ")", "\n", "\n", "", "return", "mention_file", ".", "Mention", "(", "\n", "mention_text", "=", "' '", ".", "join", "(", "mention_tokens", ")", ",", "\n", "left_context", "=", "' '", ".", "join", "(", "left_tokens", ")", ",", "\n", "right_context", "=", "' '", ".", "join", "(", "right_tokens", ")", ",", "\n", "candidates", "=", "CANDIDATES", ",", "\n", "CUI", "=", "code", ".", "lower", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.get_mentions.getAllMentions": [[105, 154], ["tokenizer.Tokenizer", "mobility_framework.entity_crosslinker.crosslinkEntities", "mobility_framework.csv_reader.extractAllEntities", "mobility_framework.xml_reader.extractAllEntities", "get_mentions.convertLinkedMention", "mentions.append", "config[].split", "config[].split"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.entity_crosslinker.crosslinkEntities", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.extractAllEntities", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.extractAllEntities", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.get_mentions.convertLinkedMention"], ["", "def", "getAllMentions", "(", "config", ",", "options", ",", "tokenizer", "=", "None", ",", "bert_vocab_file", "=", "None", ",", "log", "=", "log", ")", ":", "\n", "    ", "if", "tokenizer", "is", "None", ":", "\n", "        ", "tokenizer", "=", "config", "[", "'Tokenizer'", "]", "\n", "", "tokenizer", "=", "Tokenizer", "(", "tokenizer", ",", "bert_vocab_file", "=", "bert_vocab_file", ")", "\n", "\n", "if", "config", "[", "'ExtractionMode'", "]", "==", "'csv'", ":", "\n", "        ", "(", "\n", "mobilities", ",", "\n", "actions", ",", "\n", "assistances", ",", "\n", "quantifications", "\n", ")", "=", "mobility_framework", ".", "csv_reader", ".", "extractAllEntities", "(", "\n", "config", "[", "'DataDirectories'", "]", ".", "split", "(", "','", ")", ",", "\n", "config", "[", "'PlaintextDirectory'", "]", ",", "\n", "config", "[", "'CSVIdentifierPattern'", "]", ",", "\n", "config", "[", "'PlaintextIdentifierPattern'", "]", ",", "\n", "log", "=", "log", ",", "\n", "by_document", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "        ", "(", "\n", "mobilities", ",", "\n", "actions", ",", "\n", "assistances", ",", "\n", "quantifications", "\n", ")", "=", "mobility_framework", ".", "xml_reader", ".", "extractAllEntities", "(", "\n", "config", "[", "'DataDirectories'", "]", ".", "split", "(", "','", ")", ",", "\n", "log", "=", "log", "\n", ")", "\n", "\n", "", "mentions", ",", "mention_map", "=", "[", "]", ",", "{", "}", "\n", "\n", "mobility_framework", ".", "entity_crosslinker", ".", "crosslinkEntities", "(", "\n", "mobilities", ",", "actions", ",", "assistances", ",", "quantifications", ",", "\n", "log", "=", "log", "\n", ")", "\n", "\n", "cur_ID", "=", "0", "\n", "for", "action", "in", "actions", ":", "\n", "        ", "mention", "=", "convertLinkedMention", "(", "\n", "action", ",", "\n", "tokenizer", "\n", ")", "\n", "mention", ".", "ID", "=", "cur_ID", "\n", "mention_map", "[", "mention", ".", "ID", "]", "=", "action", ".", "file_ID", "\n", "mentions", ".", "append", "(", "mention", ")", "\n", "cur_ID", "+=", "1", "\n", "\n", "", "return", "mentions", ",", "mention_map", "\n", "", ""]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.models.Document.__init__": [[62, 72], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mobilities", "=", "None", ",", "actions", "=", "None", ",", "quantifications", "=", "None", ",", "\n", "assistances", "=", "None", ",", "full_text", "=", "None", ",", "file_path", "=", "None", ",", "ID", "=", "None", ")", ":", "\n", "        ", "self", ".", "mobilities", "=", "[", "]", "if", "mobilities", "is", "None", "else", "mobilities", "\n", "self", ".", "actions", "=", "[", "]", "if", "actions", "is", "None", "else", "actions", "\n", "self", ".", "assistances", "=", "[", "]", "if", "assistances", "is", "None", "else", "assistances", "\n", "self", ".", "quantifications", "=", "[", "]", "if", "quantifications", "is", "None", "else", "quantifications", "\n", "\n", "self", ".", "full_text", "=", "full_text", "\n", "self", ".", "file_path", "=", "file_path", "\n", "self", ".", "ID", "=", "ID", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.models.BaseMention.__init__": [[82, 85], ["kwargs.items"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "(", "k", ",", "v", ")", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "__dict__", "[", "k", "]", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.models.Mobility.__init__": [[95, 100], ["models.BaseMention.__init__"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.models.Mobility.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "action", "=", "[", "]", "\n", "self", ".", "assistance", "=", "[", "]", "\n", "self", ".", "quantification", "=", "[", "]", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.models.Mobility.__repr__": [[101, 105], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "'{Mobility: \"%s\" (%d-%d) History: %s Type: %s Subject: %s}'", "%", "(", "\n", "self", ".", "text", ",", "self", ".", "start", ",", "self", ".", "end", ",", "\n", "str", "(", "self", ".", "history", ")", ",", "self", ".", "type", ",", "self", ".", "subject", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.models.Action.__repr__": [[112, 115], ["str"], "methods", ["None"], ["def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "'{Action: \"%s\" (%d-%d) Code: %s Polarity: %s }'", "%", "(", "\n", "self", ".", "text", ",", "self", ".", "start", ",", "self", ".", "end", ",", "self", ".", "code", ",", "str", "(", "self", ".", "polarity", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.models.Quantification.__repr__": [[121, 124], ["None"], "methods", ["None"], ["def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "'{Quantification: \"%s\" (%d-%d) Type: %s}'", "%", "(", "\n", "self", ".", "text", ",", "self", ".", "start", ",", "self", ".", "end", ",", "self", ".", "type", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.models.Assistance.__repr__": [[131, 135], ["None"], "methods", ["None"], ["def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "'{Assistance: \"%s\" (%d-%d) Polarity: %s Source: %s}'", "%", "(", "\n", "self", ".", "text", ",", "self", ".", "start", ",", "self", ".", "end", ",", "\n", "self", ".", "polarity", ",", "self", ".", "source", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.csv_reader.matchAnnotationAndTextFiles": [[65, 92], ["re.compile", "csv_files.items", "os.listdir", "os.path.join", "os.path.isfile", "re.match", "txt_sub_pattern.format", "hedgepig_logger.log.writeln", "os.path.join", "re.match.groups"], "function", ["None"], ["def", "matchAnnotationAndTextFiles", "(", "data_directories", ",", "text_directory", ",", "csv_id_pattern", ",", "txt_sub_pattern", ",", "log", "=", "log", ")", ":", "\n", "    ", "csv_files", "=", "{", "}", "\n", "\n", "csv_id_getter", "=", "re", ".", "compile", "(", "csv_id_pattern", ")", "\n", "for", "csvdir", "in", "data_directories", ":", "\n", "        ", "for", "f", "in", "os", ".", "listdir", "(", "csvdir", ")", ":", "\n", "            ", "match", "=", "re", ".", "match", "(", "csv_id_getter", ",", "f", ")", "\n", "if", "match", ":", "\n", "                ", "_id", "=", "match", ".", "groups", "(", "1", ")", "[", "0", "]", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "csvdir", ",", "f", ")", "\n", "csv_files", "[", "_id", "]", "=", "fpath", "\n", "\n", "", "", "", "paired_files", "=", "{", "}", "\n", "for", "(", "_id", ",", "csv_path", ")", "in", "csv_files", ".", "items", "(", ")", ":", "\n", "        ", "txt_path", "=", "os", ".", "path", ".", "join", "(", "\n", "text_directory", ",", "\n", "txt_sub_pattern", ".", "format", "(", "_id", ")", "\n", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "txt_path", ")", ":", "\n", "            ", "paired_files", "[", "_id", "]", "=", "(", "\n", "csv_path", ",", "\n", "txt_path", "\n", ")", "\n", "", "else", ":", "\n", "            ", "log", ".", "writeln", "(", "'[WARNING] Could not find plaintext file for ID {0}'", ".", "format", "(", "_id", ")", ")", "\n", "\n", "", "", "return", "paired_files", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.csv_reader.extractAnnotationsFromFile": [[93, 128], ["codecs.open", "stream.read", "codecs.open", "csv.reader", "models.Document", "record[].lower", "mobilities.append", "csv_reader.parseMobility", "record[].lower", "actions.append", "csv_reader.parseAction", "record[].lower", "assistances.append", "csv_reader.parseAssistance", "record[].lower", "quantifications.append", "csv_reader.parseQuantification"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_file.read", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.parseMobility", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.parseAction", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.parseAssistance", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.parseQuantification"], ["", "def", "extractAnnotationsFromFile", "(", "csvf", ",", "txtf", ",", "as_document", "=", "False", ")", ":", "\n", "    ", "mobilities", "=", "[", "]", "\n", "actions", "=", "[", "]", "\n", "assistances", "=", "[", "]", "\n", "quantifications", "=", "[", "]", "\n", "\n", "with", "codecs", ".", "open", "(", "txtf", ",", "'r'", ",", "'utf-8'", ")", "as", "stream", ":", "\n", "        ", "full_text", "=", "stream", ".", "read", "(", ")", "\n", "\n", "", "with", "codecs", ".", "open", "(", "csvf", ",", "'r'", ",", "'utf-8-sig'", ")", "as", "stream", ":", "\n", "        ", "reader", "=", "csv", ".", "reader", "(", "stream", ",", "delimiter", "=", "'|'", ")", "\n", "for", "record", "in", "reader", ":", "\n", "            ", "if", "record", "[", "0", "]", ".", "lower", "(", ")", "==", "'mobility'", ":", "\n", "                ", "mobilities", ".", "append", "(", "parseMobility", "(", "record", ",", "txtf", ")", ")", "\n", "", "elif", "record", "[", "0", "]", ".", "lower", "(", ")", "==", "'action'", ":", "\n", "                ", "actions", ".", "append", "(", "parseAction", "(", "record", ",", "txtf", ")", ")", "\n", "", "elif", "record", "[", "0", "]", ".", "lower", "(", ")", "==", "'assistance'", ":", "\n", "                ", "assistances", ".", "append", "(", "parseAssistance", "(", "record", ",", "txtf", ")", ")", "\n", "", "elif", "record", "[", "0", "]", ".", "lower", "(", ")", "==", "'quantification'", ":", "\n", "                ", "quantifications", ".", "append", "(", "parseQuantification", "(", "record", ",", "txtf", ")", ")", "\n", "\n", "", "", "", "if", "as_document", ":", "\n", "        ", "return", "Document", "(", "\n", "mobilities", "=", "mobilities", ",", "\n", "actions", "=", "actions", ",", "\n", "assistances", "=", "assistances", ",", "\n", "quantifications", "=", "quantifications", ",", "\n", "full_text", "=", "full_text", "\n", ")", "\n", "", "else", ":", "\n", "        ", "return", "(", "\n", "mobilities", ",", "\n", "actions", ",", "\n", "assistances", ",", "\n", "quantifications", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.csv_reader.baseParse": [[130, 145], ["int", "int", "open", "stream.read", "hedgepig_logger.log.writeln"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_file.read"], ["", "", "def", "baseParse", "(", "record", ",", "txtf", ")", ":", "\n", "    ", "start_pos", "=", "int", "(", "record", "[", "1", "]", ")", "\n", "end_pos", "=", "int", "(", "record", "[", "2", "]", ")", "\n", "\n", "expected_text", "=", "record", "[", "3", "]", "\n", "with", "open", "(", "txtf", ",", "'r'", ")", "as", "stream", ":", "\n", "        ", "doc_text", "=", "stream", ".", "read", "(", ")", "\n", "", "actual_text", "=", "doc_text", "[", "start_pos", ":", "end_pos", "]", "\n", "\n", "if", "expected_text", "!=", "actual_text", ":", "\n", "        ", "log", ".", "writeln", "(", "'[WARNING] Mis-alignment on {0} mention -- Expected \"{1}\"  Found \"{2}\"'", ".", "format", "(", "\n", "record", "[", "0", "]", ",", "expected_text", ",", "actual_text", "\n", ")", ")", "\n", "\n", "", "return", "(", "start_pos", ",", "end_pos", ",", "expected_text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.csv_reader.parseAction": [[146, 162], ["csv_reader.baseParse", "models.Action", "len", "len", "int"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.baseParse"], ["", "def", "parseAction", "(", "record", ",", "txtf", ")", ":", "\n", "    ", "(", "start_pos", ",", "end_pos", ",", "text", ")", "=", "baseParse", "(", "record", ",", "txtf", ")", "\n", "\n", "code", "=", "None", "\n", "if", "len", "(", "record", "[", "4", "]", ")", ">", "0", ":", "\n", "        ", "code", "=", "record", "[", "4", "]", "\n", "", "polarity", "=", "None", "\n", "if", "len", "(", "record", "[", "5", "]", ")", ">", "0", ":", "\n", "        ", "polarity", "=", "int", "(", "record", "[", "5", "]", ")", "\n", "\n", "", "return", "Action", "(", "\n", "start", "=", "start_pos", ",", "\n", "end", "=", "end_pos", ",", "\n", "text", "=", "text", ",", "\n", "code", "=", "code", ",", "\n", "polarity", "=", "polarity", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.csv_reader.parseMobility": [[164, 183], ["csv_reader.baseParse", "models.Mobility", "len", "len", "len", "int"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.baseParse"], ["", "def", "parseMobility", "(", "record", ",", "txtf", ")", ":", "\n", "    ", "(", "start_pos", ",", "end_pos", ",", "text", ")", "=", "baseParse", "(", "record", ",", "txtf", ")", "\n", "\n", "_type", "=", "None", "\n", "if", "len", "(", "record", "[", "4", "]", ")", ">", "0", ":", "\n", "        ", "_type", "=", "record", "[", "4", "]", "\n", "", "subject", "=", "None", "\n", "if", "len", "(", "record", "[", "5", "]", ")", ">", "0", ":", "\n", "        ", "subject", "=", "record", "[", "5", "]", "\n", "", "history", "=", "None", "\n", "if", "len", "(", "record", "[", "6", "]", ")", ">", "0", ":", "\n", "        ", "history", "=", "int", "(", "record", "[", "6", "]", ")", "\n", "\n", "", "return", "Mobility", "(", "\n", "start", "=", "start_pos", ",", "\n", "end", "=", "end_pos", ",", "\n", "text", "=", "text", ",", "\n", "type", "=", "_type", ",", "\n", "history", "=", "history", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.csv_reader.parseQuantification": [[185, 198], ["csv_reader.baseParse", "models.Quantification", "len"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.baseParse"], ["", "def", "parseQuantification", "(", "record", ",", "txtf", ")", ":", "\n", "    ", "(", "start_pos", ",", "end_pos", ",", "text", ")", "=", "baseParse", "(", "record", ",", "txtf", ")", "\n", "\n", "_type", "=", "None", "\n", "\n", "if", "len", "(", "record", "[", "4", "]", ")", ">", "0", ":", "\n", "        ", "_type", "=", "record", "[", "4", "]", "\n", "\n", "", "return", "Quantification", "(", "\n", "start", "=", "start_pos", ",", "\n", "end", "=", "end_pos", ",", "\n", "text", "=", "text", ",", "\n", "type", "=", "_type", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.csv_reader.parseAssistance": [[200, 216], ["csv_reader.baseParse", "models.Assistance", "len", "len"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.baseParse"], ["", "def", "parseAssistance", "(", "record", ",", "txtf", ")", ":", "\n", "    ", "(", "start_pos", ",", "end_pos", ",", "text", ")", "=", "baseParse", "(", "record", ",", "txtf", ")", "\n", "\n", "polarity", "=", "None", "\n", "if", "len", "(", "record", "[", "4", "]", ")", ">", "0", ":", "\n", "        ", "polarity", "=", "record", "[", "4", "]", "\n", "", "source", "=", "None", "\n", "if", "len", "(", "record", "[", "5", "]", ")", ">", "0", ":", "\n", "        ", "source", "=", "record", "[", "5", "]", "\n", "\n", "", "return", "Assistance", "(", "\n", "start", "=", "start_pos", ",", "\n", "end", "=", "end_pos", ",", "\n", "text", "=", "text", ",", "\n", "polarity", "=", "polarity", ",", "\n", "source", "=", "source", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.csv_reader.extractAllEntities": [[218, 287], ["csv_reader.matchAnnotationAndTextFiles", "hedgepig_logger.log.track", "matchAnnotationAndTextFiles.items", "hedgepig_logger.log.flushTracker", "csv_reader.extractAnnotationsFromFile", "documents.append", "hedgepig_logger.log.tick", "len", "mobilities.append", "actions.append", "assistances.append", "quantifications.append", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.csv_reader.matchAnnotationAndTextFiles", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.csv_reader.extractAnnotationsFromFile"], ["", "def", "extractAllEntities", "(", "data_directories", ",", "text_directory", ",", "csv_id_pattern", ",", "txt_sub_pattern", ",", "log", "=", "log", ",", "\n", "with_full_text", "=", "False", ",", "by_document", "=", "True", ")", ":", "\n", "    ", "'''\n    Extract all Mobility, Action, Assistance, and Quantification entities from\n    CSV-formatted annotation files.\n\n    @parameters\n      data_directories :: list of directories containing .csv annotation files\n      text_directory   :: directory containing reference .txt files\n      csv_id_pattern   :: Python regex pattern for extracting file ID from a CSV file name\n                          (as first group); e.g. 'myfile_([0-9]*).csv' will extract\n                          '12345' as file ID from file myfile_12345.csv\n      txt_sub_pattern  :: Python string formatting pattern for matching to reference\n                          text files (ID substituted for {0}); e.g., 'mytext_{0}.txt'\n                          will look for mytext_12345.txt for file ID 12345\n      log              :: logging object to write to (defaults to dng_logger.log)\n\n    @returns\n      mobilities      :: list of Mobility objects\n      actions         :: list of Action objects\n      assistances     :: list of Assistance objects\n      quantifications :: list of Quantification objects\n    '''", "\n", "documents", "=", "[", "]", "\n", "\n", "mobilities", "=", "[", "]", "\n", "actions", "=", "[", "]", "\n", "assistances", "=", "[", "]", "\n", "quantifications", "=", "[", "]", "\n", "\n", "paired_files", "=", "matchAnnotationAndTextFiles", "(", "data_directories", ",", "text_directory", ",", "csv_id_pattern", ",", "txt_sub_pattern", ",", "log", "=", "log", ")", "\n", "\n", "log", ".", "track", "(", "message", "=", "'  >> Extracted entities from {0:,}/{1:,} files ({2:,} entities)'", ",", "writeInterval", "=", "1", ")", "\n", "for", "(", "_id", ",", "(", "csvf", ",", "txtf", ")", ")", "in", "paired_files", ".", "items", "(", ")", ":", "\n", "        ", "doc", "=", "extractAnnotationsFromFile", "(", "\n", "csvf", ",", "\n", "txtf", ",", "\n", "as_document", "=", "True", "\n", ")", "\n", "\n", "doc", ".", "file_path", "=", "txtf", "\n", "doc", ".", "ID", "=", "_id", "\n", "\n", "for", "m", "in", "doc", ".", "mobilities", ":", "\n", "            ", "m", ".", "file_ID", "=", "_id", "\n", "mobilities", ".", "append", "(", "m", ")", "\n", "", "for", "m", "in", "doc", ".", "actions", ":", "\n", "            ", "m", ".", "file_ID", "=", "_id", "\n", "actions", ".", "append", "(", "m", ")", "\n", "", "for", "m", "in", "doc", ".", "assistances", ":", "\n", "            ", "m", ".", "file_ID", "=", "_id", "\n", "assistances", ".", "append", "(", "m", ")", "\n", "", "for", "m", "in", "doc", ".", "quantifications", ":", "\n", "            ", "m", ".", "file_ID", "=", "_id", "\n", "quantifications", ".", "append", "(", "m", ")", "\n", "\n", "", "documents", ".", "append", "(", "doc", ")", "\n", "\n", "log", ".", "tick", "(", "len", "(", "paired_files", ")", ",", "len", "(", "mobilities", ")", "+", "len", "(", "actions", ")", "+", "len", "(", "assistances", ")", "+", "len", "(", "quantifications", ")", ")", "\n", "", "log", ".", "flushTracker", "(", "len", "(", "paired_files", ")", ",", "len", "(", "mobilities", ")", "+", "len", "(", "actions", ")", "+", "len", "(", "assistances", ")", "+", "len", "(", "quantifications", ")", ")", "\n", "\n", "if", "by_document", ":", "\n", "        ", "return", "documents", "\n", "", "else", ":", "\n", "        ", "return", "(", "\n", "mobilities", ",", "\n", "actions", ",", "\n", "assistances", ",", "\n", "quantifications", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.extractMentions": [[64, 151], ["bs4.BeautifulSoup", "bs4.BeautifulSoup.find_all", "str().replace().replace", "html.parser.HTMLParser", "html.parser.HTMLParser.unescape", "bs4.BeautifulSoup.find_all", "annot_set.find_all.find_all.find_all", "codecs.open", "stream.read", "len", "Exception", "html.parser.HTMLParser.unescape.index", "int", "models.Document", "str().replace", "str_text_with_nodes[].index", "len", "html.parser.HTMLParser.unescape.index", "annot[].lower", "mobilities.append", "node_txt.split", "xml_reader.XMLEntityExtractor.parseMobility", "annot[].lower", "actions.append", "str", "xml_reader.XMLEntityExtractor.parseAction", "annot[].lower", "assistances.append", "xml_reader.XMLEntityExtractor.parseAssistance", "annot[].lower", "quantifications.append", "xml_reader.XMLEntityExtractor.parseQuantification"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_file.read", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.parseMobility", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.parseAction", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.parseAssistance", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.parseQuantification"], ["    ", "def", "extractMentions", "(", "self", ",", "f", ",", "with_full_text", "=", "False", ",", "errors", "=", "'strict'", ",", "as_document", "=", "False", ",", "polarity_type", "=", "int", ")", ":", "\n", "        ", "self", ".", "_with_full_text", "=", "with_full_text", "\n", "self", ".", "_polarity_type", "=", "polarity_type", "\n", "\n", "with", "codecs", ".", "open", "(", "f", ",", "'r'", ",", "'utf-8'", ",", "errors", "=", "errors", ")", "as", "stream", ":", "\n", "            ", "contents", "=", "stream", ".", "read", "(", ")", "\n", "\n", "", "soup", "=", "BeautifulSoup", "(", "contents", ",", "'lxml'", ")", "\n", "\n", "text_with_nodes", "=", "soup", ".", "find_all", "(", "'textwithnodes'", ")", "\n", "if", "len", "(", "text_with_nodes", ")", "==", "0", ":", "\n", "            ", "raise", "Exception", "(", "\"Failed to find <TextWithNodes> elements in %s\"", "%", "f", ")", "\n", "", "text_with_nodes", "=", "text_with_nodes", "[", "0", "]", "\n", "str_text_with_nodes", "=", "str", "(", "text_with_nodes", ")", ".", "replace", "(", "'<textwithnodes>'", ",", "''", ")", ".", "replace", "(", "'</textwithnodes>'", ",", "''", ")", "\n", "\n", "# since we don't need to actually parse this as HTML, can unencode", "\n", "# HTML encodings to make string indices match up between", "\n", "# str(text_with_nodes) and text_with_nodes.text", "\n", "html_parser", "=", "html", ".", "parser", ".", "HTMLParser", "(", ")", "\n", "str_text_with_nodes", "=", "html_parser", ".", "unescape", "(", "str_text_with_nodes", ")", "\n", "\n", "self", ".", "_node_positions", "=", "{", "}", "\n", "\n", "cur_text_position", "=", "0", "\n", "try", ":", "ix", "=", "str_text_with_nodes", ".", "index", "(", "'<node'", ")", "\n", "except", ":", "ix", "=", "-", "1", "\n", "\n", "while", "ix", ">", "-", "1", ":", "\n", "            ", "node_end_ix", "=", "str_text_with_nodes", "[", "ix", ":", "]", ".", "index", "(", "'</node>'", ")", "+", "len", "(", "'</node>'", ")", "\n", "node_txt", "=", "str_text_with_nodes", "[", "ix", ":", "ix", "+", "node_end_ix", "]", "\n", "\n", "str_text_with_nodes", "=", "str_text_with_nodes", "[", "ix", "+", "node_end_ix", ":", "]", "\n", "cur_text_position", "+=", "ix", "\n", "\n", "node_id", "=", "int", "(", "node_txt", ".", "split", "(", "'\"'", ")", "[", "1", "]", ")", "\n", "self", ".", "_node_positions", "[", "node_id", "]", "=", "cur_text_position", "\n", "\n", "try", ":", "ix", "=", "str_text_with_nodes", ".", "index", "(", "'<node'", ")", "\n", "except", ":", "ix", "=", "-", "1", "\n", "\n", "", "self", ".", "_doc_text", "=", "text_with_nodes", ".", "text", "\n", "\n", "annot_sets", "=", "soup", ".", "find_all", "(", "'annotationset'", ")", "\n", "for", "annot_set", "in", "annot_sets", ":", "\n", "            ", "if", "'name'", "in", "annot_set", "and", "annot_set", "[", "'name'", "]", "==", "'ICF'", ":", "\n", "                ", "break", "\n", "\n", "", "", "annot_set", "=", "annot_set", ".", "find_all", "(", "'annotation'", ")", "\n", "mobilities", "=", "[", "]", "\n", "actions", "=", "[", "]", "\n", "assistances", "=", "[", "]", "\n", "quantifications", "=", "[", "]", "\n", "\n", "for", "annot", "in", "annot_set", ":", "\n", "            ", "if", "annot", "[", "'type'", "]", ".", "lower", "(", ")", "==", "'mobility'", ":", "\n", "                ", "mobilities", ".", "append", "(", "\n", "self", ".", "parseMobility", "(", "annot", ")", "\n", ")", "\n", "", "elif", "annot", "[", "'type'", "]", ".", "lower", "(", ")", "==", "'action'", ":", "\n", "                ", "actions", ".", "append", "(", "\n", "self", ".", "parseAction", "(", "annot", ")", "\n", ")", "\n", "", "elif", "annot", "[", "'type'", "]", ".", "lower", "(", ")", "==", "'assistance'", ":", "\n", "                ", "assistances", ".", "append", "(", "\n", "self", ".", "parseAssistance", "(", "annot", ")", "\n", ")", "\n", "", "elif", "annot", "[", "'type'", "]", ".", "lower", "(", ")", "==", "'quantification'", ":", "\n", "                ", "quantifications", ".", "append", "(", "\n", "self", ".", "parseQuantification", "(", "annot", ")", "\n", ")", "\n", "\n", "", "", "if", "as_document", ":", "\n", "            ", "return", "Document", "(", "\n", "mobilities", "=", "mobilities", ",", "\n", "actions", "=", "actions", ",", "\n", "assistances", "=", "assistances", ",", "\n", "quantifications", "=", "quantifications", ",", "\n", "full_text", "=", "self", ".", "_doc_text", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "\n", "mobilities", ",", "\n", "actions", ",", "\n", "assistances", ",", "\n", "quantifications", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.baseParse": [[153, 171], ["int", "int"], "methods", ["None"], ["", "", "def", "baseParse", "(", "self", ",", "xml", ")", ":", "\n", "        ", "start_node", "=", "int", "(", "xml", "[", "'startnode'", "]", ")", "\n", "end_node", "=", "int", "(", "xml", "[", "'endnode'", "]", ")", "\n", "\n", "start_pos", "=", "self", ".", "_node_positions", "[", "start_node", "]", "\n", "end_pos", "=", "self", ".", "_node_positions", "[", "end_node", "]", "\n", "\n", "text", "=", "self", ".", "_doc_text", "[", "start_pos", ":", "end_pos", "]", "\n", "\n", "base_args", "=", "{", "\n", "'start'", ":", "start_pos", ",", "\n", "'end'", ":", "end_pos", ",", "\n", "'text'", ":", "text", "\n", "}", "\n", "if", "self", ".", "_with_full_text", ":", "\n", "            ", "base_args", "[", "'full_text'", "]", "=", "self", ".", "_doc_text", "\n", "\n", "", "return", "base_args", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.parseAction": [[172, 189], ["xml_reader.XMLEntityExtractor.baseParse", "action_xml.find_all", "models.Action", "feature.find_all", "xml_reader.XMLEntityExtractor._polarity_type", "feature.find_all", "feature.find_all"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.baseParse"], ["", "def", "parseAction", "(", "self", ",", "action_xml", ")", ":", "\n", "        ", "args", "=", "self", ".", "baseParse", "(", "action_xml", ")", "\n", "\n", "code", "=", "None", "\n", "polarity", "=", "None", "\n", "\n", "features", "=", "action_xml", ".", "find_all", "(", "'feature'", ")", "\n", "for", "feature", "in", "features", ":", "\n", "            ", "name", "=", "feature", ".", "find_all", "(", "'name'", ")", "[", "0", "]", ".", "text", "\n", "if", "name", "==", "'Subdomain Code'", ":", "\n", "                ", "code", "=", "feature", ".", "find_all", "(", "'value'", ")", "[", "0", "]", ".", "text", "\n", "", "elif", "name", "==", "'Polarity'", ":", "\n", "                ", "polarity", "=", "self", ".", "_polarity_type", "(", "feature", ".", "find_all", "(", "'value'", ")", "[", "0", "]", ".", "text", ")", "\n", "\n", "", "", "args", "[", "'code'", "]", "=", "code", ",", "\n", "args", "[", "'polarity'", "]", "=", "polarity", "\n", "return", "Action", "(", "**", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.parseMobility": [[190, 212], ["xml_reader.XMLEntityExtractor.baseParse", "mobility_xml.find_all", "models.Mobility", "int", "feature.find_all", "feature.find_all", "feature.find_all", "feature.find_all"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.baseParse"], ["", "def", "parseMobility", "(", "self", ",", "mobility_xml", ")", ":", "\n", "        ", "args", "=", "self", ".", "baseParse", "(", "mobility_xml", ")", "\n", "\n", "history", "=", "None", "\n", "_type", "=", "None", "\n", "subject", "=", "None", "\n", "\n", "features", "=", "mobility_xml", ".", "find_all", "(", "'feature'", ")", "\n", "for", "feature", "in", "features", ":", "\n", "            ", "name", "=", "feature", ".", "find_all", "(", "'name'", ")", "[", "0", "]", ".", "text", "\n", "if", "name", "==", "'History'", ":", "\n", "                ", "history", "=", "int", "(", "feature", ".", "find_all", "(", "'value'", ")", "[", "0", "]", ".", "text", ")", "\n", "", "elif", "name", "==", "'Type'", ":", "\n", "                ", "_type", "=", "feature", ".", "find_all", "(", "'value'", ")", "[", "0", "]", ".", "text", "\n", "", "elif", "name", "==", "'Subject'", ":", "\n", "                ", "subject", "=", "feature", ".", "find_all", "(", "'value'", ")", "[", "0", "]", ".", "text", "\n", "\n", "", "", "args", "[", "'type'", "]", "=", "_type", "\n", "args", "[", "'history'", "]", "=", "history", ",", "\n", "args", "[", "'subject'", "]", "=", "subject", "\n", "\n", "return", "Mobility", "(", "**", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.parseQuantification": [[213, 227], ["xml_reader.XMLEntityExtractor.baseParse", "quant_xml.find_all", "models.Quantification", "feature.find_all", "feature.find_all"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.baseParse"], ["", "def", "parseQuantification", "(", "self", ",", "quant_xml", ")", ":", "\n", "        ", "args", "=", "self", ".", "baseParse", "(", "quant_xml", ")", "\n", "\n", "_type", "=", "None", "\n", "\n", "features", "=", "quant_xml", ".", "find_all", "(", "'feature'", ")", "\n", "for", "feature", "in", "features", ":", "\n", "            ", "name", "=", "feature", ".", "find_all", "(", "'name'", ")", "[", "0", "]", ".", "text", "\n", "if", "name", "==", "'Type'", ":", "\n", "                ", "_type", "=", "feature", ".", "find_all", "(", "'value'", ")", "[", "0", "]", ".", "text", "\n", "\n", "", "", "args", "[", "'type'", "]", "=", "_type", "\n", "\n", "return", "Quantification", "(", "**", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.parseAssistance": [[228, 246], ["xml_reader.XMLEntityExtractor.baseParse", "asst_xml.find_all", "models.Assistance", "feature.find_all", "feature.find_all", "feature.find_all"], "methods", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.baseParse"], ["", "def", "parseAssistance", "(", "self", ",", "asst_xml", ")", ":", "\n", "        ", "args", "=", "self", ".", "baseParse", "(", "asst_xml", ")", "\n", "\n", "polarity", "=", "None", "\n", "source", "=", "None", "\n", "\n", "features", "=", "asst_xml", ".", "find_all", "(", "'feature'", ")", "\n", "for", "feature", "in", "features", ":", "\n", "            ", "name", "=", "feature", ".", "find_all", "(", "'name'", ")", "[", "0", "]", ".", "text", "\n", "if", "name", "==", "'Polarity'", ":", "\n", "                ", "polarity", "=", "feature", ".", "find_all", "(", "'value'", ")", "[", "0", "]", ".", "text", "\n", "", "elif", "name", "==", "'Source'", ":", "\n", "                ", "source", "=", "feature", ".", "find_all", "(", "'value'", ")", "[", "0", "]", ".", "text", "\n", "\n", "", "", "args", "[", "'polarity'", "]", "=", "polarity", ",", "\n", "args", "[", "'source'", "]", "=", "source", "\n", "\n", "return", "Assistance", "(", "**", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.extractAllEntities": [[247, 318], ["xml_reader.XMLEntityExtractor", "os.listdir", "hedgepig_logger.log.writeln", "hedgepig_logger.log.track", "hedgepig_logger.log.flushTracker", "os.path.join", "xml_reader.XMLEntityExtractor.extractMentions", "documents.append", "hedgepig_logger.log.tick", "len", "mobilities.append", "actions.append", "assistances.append", "quantifications.append", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.xml_reader.XMLEntityExtractor.extractMentions"], ["", "", "def", "extractAllEntities", "(", "data_directories", ",", "log", "=", "log", ",", "with_full_text", "=", "False", ",", "\n", "errors", "=", "'strict'", ",", "by_document", "=", "False", ",", "polarity_type", "=", "int", ")", ":", "\n", "    ", "'''\n    Extract all Mobility, Action, Assistance, and Quantification entities from\n    XML-formatted annotation files.\n\n    @parameters\n      data_directories :: list of directories containing .xml annotation files\n      with_full_text   :: includes full document text in \"full_text\" field of each object\n      log              :: logging object to write to (defaults to dng_logger.log)\n\n    @returns\n      mobilities      :: list of Mobility objects\n      actions         :: list of Action objects\n      assistances     :: list of Assistance objects\n      quantifications :: list of Quantification objects\n    '''", "\n", "mobilities", "=", "[", "]", "\n", "actions", "=", "[", "]", "\n", "assistances", "=", "[", "]", "\n", "quantifications", "=", "[", "]", "\n", "\n", "documents", "=", "[", "]", "\n", "\n", "extractor", "=", "XMLEntityExtractor", "(", ")", "\n", "\n", "for", "dir_path", "in", "data_directories", ":", "\n", "        ", "files", "=", "os", ".", "listdir", "(", "dir_path", ")", "\n", "\n", "log", ".", "writeln", "(", "'Extracting data from %s...'", "%", "dir_path", ")", "\n", "log", ".", "track", "(", "message", "=", "'  >> Extracted entities from {0:,}/{1:,} files ({2:,} entities)'", ",", "writeInterval", "=", "1", ")", "\n", "\n", "for", "f", "in", "files", ":", "\n", "            ", "fpath", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "f", ")", "\n", "doc", "=", "extractor", ".", "extractMentions", "(", "\n", "fpath", ",", "\n", "with_full_text", "=", "with_full_text", ",", "\n", "errors", "=", "errors", ",", "\n", "polarity_type", "=", "polarity_type", ",", "\n", "as_document", "=", "True", "\n", ")", "\n", "\n", "doc", ".", "file_path", "=", "fpath", "\n", "doc", ".", "ID", "=", "f", "\n", "\n", "for", "m", "in", "doc", ".", "mobilities", ":", "\n", "                ", "m", ".", "file_ID", "=", "f", "\n", "mobilities", ".", "append", "(", "m", ")", "\n", "", "for", "m", "in", "doc", ".", "actions", ":", "\n", "                ", "m", ".", "file_ID", "=", "f", "\n", "actions", ".", "append", "(", "m", ")", "\n", "", "for", "m", "in", "doc", ".", "assistances", ":", "\n", "                ", "m", ".", "file_ID", "=", "f", "\n", "assistances", ".", "append", "(", "m", ")", "\n", "", "for", "m", "in", "doc", ".", "quantifications", ":", "\n", "                ", "m", ".", "file_ID", "=", "f", "\n", "quantifications", ".", "append", "(", "m", ")", "\n", "\n", "", "documents", ".", "append", "(", "doc", ")", "\n", "\n", "log", ".", "tick", "(", "len", "(", "files", ")", ",", "len", "(", "mobilities", ")", "+", "len", "(", "actions", ")", "+", "len", "(", "assistances", ")", "+", "len", "(", "quantifications", ")", ")", "\n", "", "log", ".", "flushTracker", "(", "len", "(", "files", ")", ",", "len", "(", "mobilities", ")", "+", "len", "(", "actions", ")", "+", "len", "(", "assistances", ")", "+", "len", "(", "quantifications", ")", ")", "\n", "\n", "", "if", "by_document", ":", "\n", "        ", "return", "documents", "\n", "", "else", ":", "\n", "        ", "return", "(", "\n", "mobilities", ",", "\n", "actions", ",", "\n", "assistances", ",", "\n", "quantifications", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.entity_crosslinker.crosslinkEntities": [[54, 90], ["set", "mobility_by_file_ID[].append", "set.add", "action_by_file_ID[].append", "set.add", "assistance_by_file_ID[].append", "set.add", "quantification_by_file_ID[].append", "set.add", "entity_crosslinker.crosslinkFileEntities", "mobility_by_file_ID.get", "action_by_file_ID.get", "assistance_by_file_ID.get", "quantification_by_file_ID.get"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.entity_crosslinker.crosslinkFileEntities"], ["def", "crosslinkEntities", "(", "mobilities", ",", "actions", ",", "assistances", ",", "quantifications", ",", "log", "=", "log", ")", ":", "\n", "    ", "mobility_by_file_ID", "=", "{", "}", "\n", "action_by_file_ID", "=", "{", "}", "\n", "assistance_by_file_ID", "=", "{", "}", "\n", "quantification_by_file_ID", "=", "{", "}", "\n", "\n", "file_IDs", "=", "set", "(", ")", "\n", "\n", "for", "mob", "in", "mobilities", ":", "\n", "        ", "if", "mob", ".", "file_ID", "not", "in", "mobility_by_file_ID", ":", "\n", "            ", "mobility_by_file_ID", "[", "mob", ".", "file_ID", "]", "=", "[", "]", "\n", "", "mobility_by_file_ID", "[", "mob", ".", "file_ID", "]", ".", "append", "(", "mob", ")", "\n", "file_IDs", ".", "add", "(", "mob", ".", "file_ID", ")", "\n", "", "for", "act", "in", "actions", ":", "\n", "        ", "if", "act", ".", "file_ID", "not", "in", "action_by_file_ID", ":", "\n", "            ", "action_by_file_ID", "[", "act", ".", "file_ID", "]", "=", "[", "]", "\n", "", "action_by_file_ID", "[", "act", ".", "file_ID", "]", ".", "append", "(", "act", ")", "\n", "file_IDs", ".", "add", "(", "act", ".", "file_ID", ")", "\n", "", "for", "ast", "in", "assistances", ":", "\n", "        ", "if", "ast", ".", "file_ID", "not", "in", "assistance_by_file_ID", ":", "\n", "            ", "assistance_by_file_ID", "[", "ast", ".", "file_ID", "]", "=", "[", "]", "\n", "", "assistance_by_file_ID", "[", "ast", ".", "file_ID", "]", ".", "append", "(", "ast", ")", "\n", "file_IDs", ".", "add", "(", "ast", ".", "file_ID", ")", "\n", "", "for", "qnt", "in", "quantifications", ":", "\n", "        ", "if", "qnt", ".", "file_ID", "not", "in", "quantification_by_file_ID", ":", "\n", "            ", "quantification_by_file_ID", "[", "qnt", ".", "file_ID", "]", "=", "[", "]", "\n", "", "quantification_by_file_ID", "[", "qnt", ".", "file_ID", "]", ".", "append", "(", "qnt", ")", "\n", "file_IDs", ".", "add", "(", "qnt", ".", "file_ID", ")", "\n", "\n", "", "for", "file_ID", "in", "file_IDs", ":", "\n", "        ", "crosslinkFileEntities", "(", "\n", "mobility_by_file_ID", ".", "get", "(", "file_ID", ",", "[", "]", ")", ",", "\n", "action_by_file_ID", ".", "get", "(", "file_ID", ",", "[", "]", ")", ",", "\n", "assistance_by_file_ID", ".", "get", "(", "file_ID", ",", "[", "]", ")", ",", "\n", "quantification_by_file_ID", ".", "get", "(", "file_ID", ",", "[", "]", ")", ",", "\n", "log", "=", "log", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.entity_crosslinker.crosslinkFileEntities": [[92, 113], ["entity_crosslinker.crosslinkSubentityType", "entity_crosslinker.crosslinkSubentityType", "entity_crosslinker.crosslinkSubentityType", "mob.action.append", "mob.assistance.append", "mob.quantification.append"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.entity_crosslinker.crosslinkSubentityType", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.entity_crosslinker.crosslinkSubentityType", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.entity_crosslinker.crosslinkSubentityType"], ["", "", "def", "crosslinkFileEntities", "(", "mobilities", ",", "actions", ",", "assistances", ",", "quantifications", ",", "log", "=", "log", ")", ":", "\n", "    ", "crosslinkSubentityType", "(", "\n", "mobilities", ",", "\n", "actions", ",", "\n", "lambda", "mob", ",", "act", ":", "mob", ".", "action", ".", "append", "(", "act", ")", ",", "\n", "'Action'", ",", "\n", "log", "=", "log", "\n", ")", "\n", "crosslinkSubentityType", "(", "\n", "mobilities", ",", "\n", "assistances", ",", "\n", "lambda", "mob", ",", "ast", ":", "mob", ".", "assistance", ".", "append", "(", "ast", ")", ",", "\n", "'Assistance'", ",", "\n", "log", "=", "log", "\n", ")", "\n", "crosslinkSubentityType", "(", "\n", "mobilities", ",", "\n", "quantifications", ",", "\n", "lambda", "mob", ",", "qnt", ":", "mob", ".", "quantification", ".", "append", "(", "qnt", ")", ",", "\n", "'Quantification'", ",", "\n", "log", "=", "log", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.mobility_framework.entity_crosslinker.crosslinkSubentityType": [[115, 142], ["sorted", "sorted", "hedgepig_logger.log.writeln", "len", "len", "hedgepig_logger.log.writeln", "child_op"], "function", ["None"], ["", "def", "crosslinkSubentityType", "(", "mobilities", ",", "subentities", ",", "child_op", ",", "_type", ",", "log", "=", "log", ")", ":", "\n", "# sort by starting, then ending positions", "\n", "    ", "sorted_mobilities", "=", "sorted", "(", "\n", "mobilities", ",", "\n", "key", "=", "lambda", "mob", ":", "(", "100", "*", "mob", ".", "start", ")", "+", "(", "0.00001", "*", "mob", ".", "end", ")", "\n", ")", "\n", "sorted_subentities", "=", "sorted", "(", "\n", "subentities", ",", "\n", "key", "=", "lambda", "act", ":", "(", "100", "*", "act", ".", "start", ")", "+", "(", "0.00001", "*", "act", ".", "end", ")", "\n", ")", "\n", "\n", "# for each action, find its containing mobility annotation", "\n", "for", "subent", "in", "sorted_subentities", ":", "\n", "        ", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "sorted_mobilities", ")", "and", "sorted_mobilities", "[", "i", "]", ".", "start", "<", "subent", ".", "start", ":", "\n", "            ", "i", "+=", "1", "\n", "", "if", "i", ">=", "len", "(", "sorted_mobilities", ")", "or", "sorted_mobilities", "[", "i", "]", ".", "start", ">", "subent", ".", "start", ":", "\n", "            ", "i", "-=", "1", "\n", "\n", "", "mob", "=", "sorted_mobilities", "[", "i", "]", "\n", "if", "(", "mob", ".", "start", ">", "subent", ".", "start", ")", "or", "(", "mob", ".", "end", "<", "subent", ".", "end", ")", ":", "\n", "            ", "log", ".", "writeln", "(", "'[WARNING] Failed to map {0} to Mobility, skipping'", ".", "format", "(", "_type", ")", ")", "\n", "", "elif", "(", "mob", ".", "text", "[", "subent", ".", "start", "-", "mob", ".", "start", ":", "subent", ".", "end", "-", "mob", ".", "start", "]", "!=", "subent", ".", "text", ")", ":", "\n", "            ", "log", ".", "writeln", "(", "'[WARNING] Text mismatch in entity crosslinking: Mobility has text \"{0}\", {1} has text \"{2}\"; skipping'", ".", "format", "(", "mob", ".", "text", "[", "subent", ".", "start", "-", "mob", ".", "start", ":", "subent", ".", "end", "-", "mob", ".", "start", "]", ",", "_type", ",", "subent", ".", "text", ")", ")", "\n", "", "else", ":", "\n", "            ", "subent", ".", "mobility", "=", "mob", "\n", "child_op", "(", "mob", ",", "subent", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.per_code_performance.readCUICodeMap": [[69, 76], ["codecs.open", "s.strip", "line.split", "cui.lower"], "function", ["None"], ["def", "readCUICodeMap", "(", "f", ")", ":", "\n", "    ", "_map", "=", "{", "}", "\n", "with", "codecs", ".", "open", "(", "f", ",", "'r'", ",", "'utf-8'", ")", "as", "stream", ":", "\n", "        ", "for", "line", "in", "stream", ":", "\n", "            ", "(", "code", ",", "cui", ")", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "line", ".", "split", "(", "'\\t'", ")", "]", "\n", "_map", "[", "cui", ".", "lower", "(", ")", "]", "=", "code", "\n", "", "", "return", "_map", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.per_code_performance.compileEvaluationSet": [[77, 85], ["set", "set", "eval_set.union.union"], "function", ["None"], ["", "def", "compileEvaluationSet", "(", "splits", ",", "eval_on_dev", ")", ":", "\n", "    ", "eval_set", "=", "set", "(", ")", "\n", "for", "(", "train", ",", "dev", ",", "test", ")", "in", "splits", ":", "\n", "        ", "these_evals", "=", "set", "(", "\n", "dev", "if", "eval_on_dev", "else", "test", "\n", ")", "\n", "eval_set", "=", "eval_set", ".", "union", "(", "these_evals", ")", "\n", "", "return", "eval_set", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.per_code_performance.remapIxesToCodes": [[86, 103], ["predictions.items", "candidates[].lower", "candidates[].lower"], "function", ["None"], ["", "def", "remapIxesToCodes", "(", "predictions", ",", "mentions", ")", ":", "\n", "    ", "mentions_by_id", "=", "{", "\n", "m", ".", "ID", ":", "m", "\n", "for", "m", "in", "mentions", "\n", "}", "\n", "\n", "remapped_predictions", "=", "{", "}", "\n", "for", "(", "mention_id", ",", "(", "scores", ",", "pred_ix", ",", "gold_ix", ",", "correct", ")", ")", "in", "predictions", ".", "items", "(", ")", ":", "\n", "        ", "candidates", "=", "mentions_by_id", "[", "mention_id", "]", ".", "candidates", "\n", "remapped_predictions", "[", "mention_id", "]", "=", "(", "\n", "scores", ",", "\n", "candidates", "[", "pred_ix", "]", ".", "lower", "(", ")", ",", "\n", "candidates", "[", "gold_ix", "]", ".", "lower", "(", ")", ",", "\n", "correct", "\n", ")", "\n", "\n", "", "return", "remapped_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.per_code_performance.sortCodesByGoldFrequency": [[104, 114], ["list", "list.sort", "list.items", "list.get"], "function", ["None"], ["", "def", "sortCodesByGoldFrequency", "(", "mentions", ",", "eval_set", ")", ":", "\n", "    ", "freqs", "=", "{", "}", "\n", "for", "m", "in", "mentions", ":", "\n", "        ", "if", "m", ".", "ID", "in", "eval_set", ":", "\n", "            ", "freqs", "[", "m", ".", "CUI", "]", "=", "freqs", ".", "get", "(", "m", ".", "CUI", ",", "0", ")", "+", "1", "\n", "\n", "", "", "freqs", "=", "list", "(", "freqs", ".", "items", "(", ")", ")", "\n", "freqs", ".", "sort", "(", "key", "=", "lambda", "k", ":", "k", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "return", "freqs", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.per_code_performance.calculateMetricsPerCode": [[115, 174], ["set", "metrics.items", "predictions.keys", "len", "hedgepig_logger.log.writeln", "input", "types.SimpleNamespace", "predictions.get", "mention.candidates.index", "len", "per_code_performance.calculateMetricsPerCode.initMetric"], "function", ["None"], ["", "def", "calculateMetricsPerCode", "(", "predictions", ",", "mentions_by_ID", ",", "eval_set", ")", ":", "\n", "    ", "preds_keys", "=", "set", "(", "predictions", ".", "keys", "(", ")", ")", "\n", "if", "len", "(", "preds_keys", "-", "eval_set", ")", ">", "0", ":", "\n", "        ", "log", ".", "writeln", "(", "'[WARNING] Predictions file includes outputs for {0} samples not included in reference evaluation set\\n'", ".", "format", "(", "len", "(", "preds_keys", "-", "eval_set", ")", ")", ")", "\n", "input", "(", "'[Enter] to continue'", ")", "\n", "\n", "", "def", "initMetric", "(", ")", ":", "\n", "        ", "obj", "=", "SimpleNamespace", "(", ")", "\n", "obj", ".", "tp", "=", "0", "\n", "obj", ".", "fp", "=", "0", "\n", "obj", ".", "fn", "=", "0", "\n", "return", "obj", "\n", "\n", "", "metrics", "=", "{", "}", "\n", "for", "mention_ID", "in", "eval_set", ":", "\n", "        ", "results", "=", "predictions", ".", "get", "(", "mention_ID", ",", "None", ")", "\n", "if", "results", "is", "None", ":", "\n", "            ", "mention", "=", "mentions_by_ID", "[", "mention_ID", "]", "\n", "gold_ix", "=", "mention", ".", "candidates", ".", "index", "(", "mention", ".", "CUI", ")", "\n", "if", "not", "gold_ix", "in", "metrics", ":", "\n", "                ", "metrics", "[", "gold_ix", "]", "=", "initMetric", "(", ")", "\n", "", "metrics", "[", "gold_ix", "]", ".", "fn", "+=", "1", "\n", "", "else", ":", "\n", "            ", "(", "scores", ",", "pred_ix", ",", "gold_ix", ",", "correct", ")", "=", "results", "\n", "if", "not", "pred_ix", "in", "metrics", ":", "\n", "                ", "metrics", "[", "pred_ix", "]", "=", "initMetric", "(", ")", "\n", "", "if", "not", "gold_ix", "in", "metrics", ":", "\n", "                ", "metrics", "[", "gold_ix", "]", "=", "initMetric", "(", ")", "\n", "\n", "", "if", "correct", ":", "\n", "                ", "metrics", "[", "gold_ix", "]", ".", "tp", "+=", "1", "\n", "", "else", ":", "\n", "                ", "metrics", "[", "pred_ix", "]", ".", "fp", "+=", "1", "\n", "metrics", "[", "gold_ix", "]", ".", "fn", "+=", "1", "\n", "\n", "", "", "", "for", "(", "ix", ",", "code_metrics", ")", "in", "metrics", ".", "items", "(", ")", ":", "\n", "        ", "if", "code_metrics", ".", "tp", "+", "code_metrics", ".", "fp", ">", "0", ":", "\n", "            ", "code_metrics", ".", "precision", "=", "(", "\n", "float", "(", "code_metrics", ".", "tp", ")", "/", "\n", "(", "code_metrics", ".", "tp", "+", "code_metrics", ".", "fp", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "code_metrics", ".", "precision", "=", "0", "\n", "", "if", "code_metrics", ".", "tp", "+", "code_metrics", ".", "fn", ">", "0", ":", "\n", "            ", "code_metrics", ".", "recall", "=", "(", "\n", "float", "(", "code_metrics", ".", "tp", ")", "/", "\n", "(", "code_metrics", ".", "tp", "+", "code_metrics", ".", "fn", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "code_metrics", ".", "recall", "=", "0", "\n", "", "if", "code_metrics", ".", "precision", "+", "code_metrics", ".", "recall", ">", "0", ":", "\n", "            ", "code_metrics", ".", "f1", "=", "(", "\n", "(", "2", "*", "code_metrics", ".", "precision", "*", "code_metrics", ".", "recall", ")", "/", "\n", "(", "code_metrics", ".", "precision", "+", "code_metrics", ".", "recall", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "code_metrics", ".", "f1", "=", "0", "\n", "\n", "", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.per_code_performance.calculateConfusionMatrix": [[175, 182], ["predictions.values", "matrix[].get"], "function", ["None"], ["", "def", "calculateConfusionMatrix", "(", "predictions", ")", ":", "\n", "    ", "matrix", "=", "{", "}", "\n", "for", "(", "_", ",", "pred_ix", ",", "gold_ix", ",", "_", ")", "in", "predictions", ".", "values", "(", ")", ":", "\n", "        ", "if", "not", "gold_ix", "in", "matrix", ":", "\n", "            ", "matrix", "[", "gold_ix", "]", "=", "{", "}", "\n", "", "matrix", "[", "gold_ix", "]", "[", "pred_ix", "]", "=", "matrix", "[", "gold_ix", "]", ".", "get", "(", "pred_ix", ",", "0", ")", "+", "1", "\n", "", "return", "matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.per_code_performance.printConfusionMatrix": [[183, 201], ["max", "hedgepig_logger.log.write", "hedgepig_logger.log.write", "hedgepig_logger.log.write", "hedgepig_logger.log.write", "hedgepig_logger.log.write", "hedgepig_logger.log.write", "hedgepig_logger.log.write", "len", "hedgepig_logger.log.write", "remap", "remap", "remap", "confusion_matrix.get().get", "confusion_matrix.get"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write", "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write"], ["", "def", "printConfusionMatrix", "(", "confusion_matrix", ",", "ordering", ",", "remap", "=", "None", ")", ":", "\n", "    ", "if", "remap", "is", "None", ":", "\n", "        ", "remap", "=", "lambda", "k", ":", "k", "\n", "\n", "", "column_width", "=", "max", "(", "[", "len", "(", "remap", "(", "item", ")", ")", "for", "item", "in", "ordering", "]", ")", "\n", "# headers", "\n", "log", ".", "write", "(", "' '", "*", "(", "column_width", "+", "1", ")", ")", "\n", "log", ".", "write", "(", "'|'", ")", "\n", "for", "item", "in", "ordering", ":", "\n", "        ", "log", ".", "write", "(", "(", "' %{0}s'", ".", "format", "(", "column_width", ")", ")", "%", "remap", "(", "item", ")", ")", "\n", "", "log", ".", "write", "(", "'\\n'", ")", "\n", "# rows", "\n", "for", "gold_item", "in", "ordering", ":", "\n", "        ", "log", ".", "write", "(", "(", "'%{0}s '", ".", "format", "(", "column_width", ")", ")", "%", "remap", "(", "gold_item", ")", ")", "\n", "log", ".", "write", "(", "'|'", ")", "\n", "for", "pred_item", "in", "ordering", ":", "\n", "            ", "log", ".", "write", "(", "(", "' %{0}d'", ".", "format", "(", "column_width", ")", ")", "%", "confusion_matrix", ".", "get", "(", "gold_item", ",", "{", "}", ")", ".", "get", "(", "pred_item", ",", "0", ")", ")", "\n", "", "log", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.per_code_performance.writeConfusionMatrixToCSV": [[202, 214], ["open", "csv.DictWriter", "csv.DictWriter.writeheader", "csv.DictWriter.writerow", "confusion_matrix.get().get", "confusion_matrix.get"], "function", ["None"], ["", "", "def", "writeConfusionMatrixToCSV", "(", "confusion_matrix", ",", "ordering", ",", "outf", ",", "remap", "=", "None", ")", ":", "\n", "    ", "if", "remap", "is", "None", ":", "\n", "        ", "remap", "=", "lambda", "k", ":", "k", "\n", "\n", "", "with", "open", "(", "outf", ",", "'w'", ")", "as", "stream", ":", "\n", "        ", "writer", "=", "csv", ".", "DictWriter", "(", "stream", ",", "fieldnames", "=", "[", "'Gold'", ",", "*", "ordering", "]", ")", "\n", "writer", ".", "writeheader", "(", ")", "\n", "for", "gold_item", "in", "ordering", ":", "\n", "            ", "row", "=", "{", "'Gold'", ":", "gold_item", "}", "\n", "for", "pred_item", "in", "ordering", ":", "\n", "                ", "row", "[", "pred_item", "]", "=", "confusion_matrix", ".", "get", "(", "gold_item", ",", "{", "}", ")", ".", "get", "(", "pred_item", ",", "0", ")", "\n", "", "writer", ".", "writerow", "(", "row", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.util.getLatestFile": [[59, 75], ["list", "glob.glob", "valid_logs.sort", "valid_logs.append", "os.path.splitext"], "function", ["None"], ["\n", "class", "Indexer", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "vocab", ")", ":", "\n", "        ", "self", ".", "_vocab", "=", "vocab", "\n", "self", ".", "_indices", "=", "{", "vocab", "[", "i", "]", ":", "i", "for", "i", "in", "range", "(", "len", "(", "vocab", ")", ")", "}", "\n", "\n", "", "def", "indexOf", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_indices", ".", "get", "(", "key", ",", "-", "1", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "_vocab", "[", "index", "]", "\n", "\n", "\n", "", "", "def", "meanEmbeddings", "(", "strings", ",", "ctx_embeds", ")", ":", "\n", "    ", "word_embs", ",", "valid_ctx_embedding", "=", "[", "]", ",", "False", "\n", "for", "context_string", "in", "strings", ":", "\n", "        ", "words", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "context_string", ".", "lower", "(", ")", ".", "split", "(", ")", "]", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.util.getLatestLog": [[76, 78], ["util.getLatestFile"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.util.getLatestFile"], ["for", "w", "in", "words", ":", "\n", "            ", "if", "w", "in", "ctx_embeds", ":", "\n", "                ", "word_embs", ".", "append", "(", "ctx_embeds", "[", "w", "]", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.util.getLatestWSDLog": [[79, 81], ["util.getLatestFile"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.util.getLatestFile"], ["", "", "", "(", "ctx_embedding", ",", "valid_ctx_embedding", ")", "=", "meanEmbeddingVectors", "(", "word_embs", ",", "ctx_embeds", ".", "size", ")", "\n", "return", "ctx_embedding", ",", "valid_ctx_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.util.getLatestPredictions": [[82, 84], ["util.getLatestFile"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.util.getLatestFile"], ["", "def", "meanEmbeddingVectors", "(", "vectors", ",", "dim", ")", ":", "\n", "    ", "if", "len", "(", "vectors", ")", ">", "0", ":", "\n", "        ", "mean_vector", "=", "np", ".", "mean", "(", "vectors", ",", "axis", "=", "0", ")", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.predictions_parser.parsePredictions": [[58, 99], ["codecs.open", "[].strip", "int", "int", "int", "[].strip", "[].strip", "tuple", "line.split", "line.split", "right.split", "info.extend", "line.split", "float", "left.split", "[].split", "[].split", "scores.split", "[].split", "right.split", "right.split", "right.split", "right.split"], "function", ["None"], ["def", "parsePredictions", "(", "f", ",", "get_candidate", "=", "False", ",", "no_scores", "=", "False", ")", ":", "\n", "    ", "predictions", "=", "{", "}", "\n", "with", "codecs", ".", "open", "(", "f", ",", "'r'", ",", "'utf-8'", ")", "as", "stream", ":", "\n", "        ", "for", "line", "in", "stream", ":", "\n", "            ", "first_word", "=", "line", ".", "split", "(", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "if", "first_word", "==", "'Mention'", ":", "\n", "                ", "if", "no_scores", ":", "\n", "                    ", "left", ",", "right", "=", "line", ".", "split", "(", "'--'", ",", "1", ")", "\n", "scores", "=", "None", "\n", "", "else", ":", "\n", "                    ", "left", ",", "right", "=", "line", ".", "split", "(", "'['", ",", "1", ")", "\n", "scores", ",", "right", "=", "right", ".", "split", "(", "']'", ",", "1", ")", "\n", "scores", "=", "[", "float", "(", "f", ")", "for", "f", "in", "scores", ".", "split", "(", ")", "]", "\n", "", "mention_id", "=", "int", "(", "left", ".", "split", "(", ")", "[", "1", "]", ")", "\n", "\n", "pred_ix", "=", "int", "(", "\n", "right", ".", "split", "(", "'->'", ")", "[", "0", "]", ".", "split", "(", "':'", ")", "[", "1", "]", "\n", ")", "\n", "gold_ix", "=", "int", "(", "\n", "right", ".", "split", "(", "'->'", ")", "[", "1", "]", ".", "split", "(", "':'", ")", "[", "-", "1", "]", "\n", ")", "\n", "\n", "pred_cand", "=", "right", ".", "split", "(", "'->'", ")", "[", "1", "]", ".", "split", "(", "'Gold'", ")", "[", "0", "]", ".", "strip", "(", ")", "\n", "gold_cand", "=", "right", ".", "split", "(", "'->'", ")", "[", "2", "]", ".", "strip", "(", ")", "\n", "\n", "info", "=", "[", "\n", "scores", ",", "\n", "pred_ix", ",", "\n", "gold_ix", ",", "\n", "pred_ix", "==", "gold_ix", "\n", "]", "\n", "if", "get_candidate", ":", "\n", "                    ", "info", ".", "extend", "(", "[", "\n", "pred_cand", ",", "\n", "gold_cand", "\n", "]", ")", "\n", "", "predictions", "[", "mention_id", "]", "=", "tuple", "(", "info", ")", "\n", "", "", "", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.analysis.predictions_parser.writePredictionsToStream": [[100, 111], ["stream.write", "str"], "function", ["home.repos.pwc.inspect_result.CC-RMD-EpiBio_automated-ICF-coding.dataset.mention_map_lib.write"], ["", "def", "writePredictionsToStream", "(", "stream", ",", "mention", ",", "scores", ",", "predicted_ix", ",", "correct_ix", ",", "\n", "correct_candidate", ",", "predicted_candidate", "=", "None", ")", ":", "\n", "    ", "if", "predicted_candidate", "is", "None", ":", "\n", "        ", "predicted_candidate", "=", "mention", ".", "candidates", "[", "predicted_ix", "]", "\n", "", "stream", ".", "write", "(", "'Mention %d -- Scores: [ %s ]  Pred: %d -> %s  Gold: %d -> %s\\n'", "%", "(", "\n", "mention", ".", "ID", ",", "\n", "' '", ".", "join", "(", "[", "str", "(", "s", ")", "for", "s", "in", "scores", "]", ")", ",", "\n", "predicted_ix", ",", "\n", "predicted_candidate", ",", "\n", "correct_ix", ",", "\n", "correct_candidate", "\n", ")", ")", "\n"]]}