{"home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.add_unseen_token_2_extra_vocabulary": [[14, 24], ["print", "random.random", "str", "open", "myfile.write", "range", "token.lower", "str"], "function", ["None"], ["def", "add_unseen_token_2_extra_vocabulary", "(", "token", ",", "extra_vocab_filename", ")", ":", "\n", "    ", "print", "(", "\"Adding unseen token: \"", ",", "token", ")", "\n", "random_vector", "=", "[", "random", ".", "random", "(", ")", "for", "_", "in", "range", "(", "0", ",", "300", ")", "]", "\n", "string_vector", "=", "[", "str", "(", "i", ")", "for", "i", "in", "random_vector", "]", "\n", "vector", "=", "[", "token", ".", "lower", "(", ")", "]", "+", "[", "\" \"", "]", "+", "string_vector", "\n", "with", "open", "(", "extra_vocab_filename", ",", "\"a\"", ")", "as", "myfile", ":", "\n", "        ", "str_vector", "=", "' '", ".", "join", "(", "str", "(", "e", ")", "for", "e", "in", "vector", ")", "#covert list to string", "\n", "str_vector", "=", "str_vector", "+", "\"\\n\"", "\n", "myfile", ".", "write", "(", "str_vector", ")", "\n", "", "return", "random_vector", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.tokenize_file_to_vectors": [[25, 38], ["open", "line.split", "print", "LM_RNN_GloVe.my_strip", "LM_RNN_GloVe.get_vector", "open", "myfile.write", "str"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.my_strip", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_vector"], ["", "def", "tokenize_file_to_vectors", "(", "vectors_file", ",", "file2tokenize", ",", "outputfile", ")", ":", "\n", "    ", "with", "open", "(", "file2tokenize", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "tokens", "=", "line", ".", "split", "(", ")", "\n", "for", "token", "in", "tokens", ":", "\n", "                ", "print", "(", "\"tokenizing: \"", ",", "token", ")", "\n", "token", "=", "my_strip", "(", "token", ")", "\n", "vector", "=", "get_vector", "(", "token", ",", "vectors_file", ")", "\n", "#vector = get_test_vector()", "\n", "with", "open", "(", "outputfile", ",", "\"a\"", ")", "as", "myfile", ":", "\n", "                    ", "str_vector", "=", "','", ".", "join", "(", "str", "(", "e", ")", "for", "e", "in", "vector", ")", "#covert list to string", "\n", "str_vector", "=", "str_vector", "+", "\"\\n\"", "\n", "myfile", ".", "write", "(", "str_vector", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.my_strip": [[39, 45], ["token.strip.strip", "token.strip.strip", "token.strip.strip", "token.strip.strip"], "function", ["None"], ["", "", "", "", "", "def", "my_strip", "(", "token", ")", ":", "\n", "    ", "token", "=", "token", ".", "strip", "(", "\",\"", ")", "\n", "token", "=", "token", ".", "strip", "(", "\".\"", ")", "\n", "token", "=", "token", ".", "strip", "(", "\"?\"", ")", "\n", "token", "=", "token", ".", "strip", "(", "\":\"", ")", "\n", "return", "token", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.get_test_vector": [[46, 48], ["list", "range"], "function", ["None"], ["", "def", "get_test_vector", "(", ")", ":", "\n", "    ", "return", "list", "(", "range", "(", "10", ",", "15", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.get_vector": [[50, 69], ["LM_RNN_GloVe.add_unseen_token_2_extra_vocabulary", "open", "open", "line.split", "line.split", "token.lower", "print", "token.lower"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.add_unseen_token_2_extra_vocabulary"], ["", "def", "get_vector", "(", "token", ",", "vectors_file", ",", "extra_vectors_file", "=", "\"/Users/macbook/Desktop/corpora/extra_vocab.txt\"", ")", ":", "\n", "\n", "    ", "with", "open", "(", "extra_vectors_file", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "tokens", "=", "line", ".", "split", "(", ")", "\n", "if", "tokens", "[", "0", "]", "==", "token", ".", "lower", "(", ")", ":", "\n", "                ", "vec", "=", "tokens", "[", "1", ":", "301", "]", "\n", "print", "(", "\"returning from extra: \"", ",", "token", ")", "\n", "return", "vec", "\n", "\n", "", "", "", "with", "open", "(", "vectors_file", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "tokens", "=", "line", ".", "split", "(", ")", "\n", "if", "tokens", "[", "0", "]", "==", "token", ".", "lower", "(", ")", ":", "\n", "                ", "vec", "=", "tokens", "[", "1", ":", "301", "]", "\n", "return", "vec", "\n", "\n", "", "", "", "vec", "=", "add_unseen_token_2_extra_vocabulary", "(", "token", ",", "extra_vectors_file", ")", "\n", "return", "vec", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.get_vector_by_number": [[70, 75], ["linecache.getline", "linecache.getline.split", "float"], "function", ["None"], ["", "def", "get_vector_by_number", "(", "token_number", ",", "vectors_filename", "=", "\"/Users/macbook/Desktop/corpora/glove.42B.300d.txt\"", ")", ":", "\n", "    ", "line", "=", "linecache", ".", "getline", "(", "vectors_filename", ",", "token_number", ")", "\n", "tokens", "=", "line", ".", "split", "(", ")", "\n", "vec", "=", "tokens", "[", "1", ":", "301", "]", "\n", "return", "[", "float", "(", "i", ")", "for", "i", "in", "vec", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.load_data": [[76, 93], ["pandas.read_csv", "range", "numpy.array", "numpy.array", "print", "print", "docX.append", "docY.append", "len", "pd.read_csv.iloc[].as_matrix", "pd.read_csv.iloc[].as_matrix"], "function", ["None"], ["", "def", "load_data", "(", "train_file_name", ",", "window_size", "=", "10", ")", ":", "\n", "\n", "#train = pd.read_csv(train_file_name, header=None, delim_whitespace=True)", "\n", "    ", "train", "=", "pd", ".", "read_csv", "(", "train_file_name", ")", "\n", "docX", ",", "docY", "=", "[", "]", ",", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "train", ")", "-", "window_size", ")", ":", "\n", "        ", "docX", ".", "append", "(", "train", ".", "iloc", "[", "i", ":", "i", "+", "window_size", "]", ".", "as_matrix", "(", ")", ")", "\n", "docY", ".", "append", "(", "train", ".", "iloc", "[", "i", "+", "window_size", "-", "1", "]", ".", "as_matrix", "(", ")", ")", "\n", "", "alsX", "=", "np", ".", "array", "(", "docX", ")", "\n", "alsY", "=", "np", ".", "array", "(", "docY", ")", "\n", "\n", "print", "(", "\"Shape x:\"", ",", "alsX", ".", "shape", ")", "\n", "print", "(", "\"Shape y:\"", ",", "alsY", ".", "shape", ")", "\n", "\n", "\n", "return", "alsX", ",", "alsY", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.run_experiment": [[94, 142], ["LM_RNN_GloVe.load_data", "print", "keras.models.Sequential", "print", "keras.models.Sequential.add", "print", "keras.models.Sequential.add", "print", "keras.models.Sequential.add", "print", "keras.models.Sequential.add", "print", "keras.models.Sequential.compile", "print", "int", "print", "keras.models.Sequential.fit", "print", "keras.models.Sequential.predict", "range", "LM_RNN_GloVe.calc_error_distribution", "keras.layers.recurrent.GRU", "keras.layers.core.Dropout", "keras.layers.core.Dense", "keras.layers.core.Activation", "random_results.append", "LM_RNN_GloVe.get_vector_by_number", "random.randint"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.load_data", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.calc_error_distribution", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.get_vector_by_number"], ["", "def", "run_experiment", "(", "tokenized_by_vectors_filename", ")", ":", "\n", "\n", "    ", "X", ",", "Y", "=", "load_data", "(", "tokenized_by_vectors_filename", ")", "\n", "\n", "in_out_neurons", "=", "300", "\n", "out_n", "=", "300", "\n", "hidden_neurons", "=", "30", "\n", "\n", "#create the model here", "\n", "print", "(", "\"Creating model...\"", ")", "\n", "model", "=", "Sequential", "(", ")", "\n", "print", "(", "\"Adding LSTM ...\"", ")", "\n", "model", ".", "add", "(", "GRU", "(", "hidden_neurons", ",", "input_dim", "=", "in_out_neurons", ",", "return_sequences", "=", "False", ")", ")", "\n", "\n", "print", "(", "\"Adding dropout ...\"", ")", "\n", "model", ".", "add", "(", "Dropout", "(", "0.8", ")", ")", "\n", "print", "(", "\"adding output layer...\"", ")", "\n", "model", ".", "add", "(", "Dense", "(", "out_n", ",", "input_dim", "=", "hidden_neurons", ")", ")", "\n", "print", "(", "\"adding activation...\"", ")", "\n", "model", ".", "add", "(", "Activation", "(", "\"linear\"", ")", ")", "\n", "print", "(", "\"compiling...\"", ")", "\n", "model", ".", "compile", "(", "loss", "=", "\"mean_squared_error\"", ",", "optimizer", "=", "\"rmsprop\"", ")", "\n", "print", "(", "\"compiled!\"", ")", "\n", "#split the data to train and test", "\n", "\n", "data_size", "=", "X", ".", "shape", "[", "0", "]", "\n", "train_size", "=", "int", "(", "data_size", "*", "0.7", ")", "\n", "\n", "X_train", "=", "X", "[", "0", ":", "train_size", ",", ":", "]", "\n", "Y_train", "=", "Y", "[", "0", ":", "train_size", "]", "\n", "Y_test", "=", "Y", "[", "train_size", "+", "1", ":", "data_size", "]", "\n", "X_test", "=", "X", "[", "train_size", "+", "1", ":", "data_size", ",", ":", "]", "\n", "\n", "print", "(", "\"start train!\"", ")", "\n", "\n", "model", ".", "fit", "(", "X_train", ",", "Y_train", ",", "batch_size", "=", "100", ",", "nb_epoch", "=", "300", ",", "validation_split", "=", "0.05", ")", "\n", "\n", "print", "(", "\"model is fit!\"", ")", "\n", "\n", "predicted_results", "=", "model", ".", "predict", "(", "X_test", ")", "\n", "\n", "\n", "#print (\"randome predicted shape: \", random_results.shape)", "\n", "random_results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "predicted_results", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "random_results", ".", "append", "(", "get_vector_by_number", "(", "randint", "(", "1", ",", "10000", ")", ")", ")", "\n", "\n", "", "calc_error_distribution", "(", "Y_test", ",", "predicted_results", ",", "random_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.calc_error_distribution": [[145, 169], ["matplotlib.hist", "matplotlib.hist", "matplotlib.legend", "matplotlib.show", "open", "range", "open", "range", "LM_RNN_GloVe.calc_distance", "predicted_dist.append", "LM_RNN_GloVe.calc_distance", "random_dist.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.calc_distance", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.calc_distance"], ["", "def", "calc_error_distribution", "(", "correct_values", ",", "predicted_values", ",", "random_values", ")", ":", "\n", "\n", "    ", "test_errors_file_name", "=", "\"/Users/macbook/Desktop/corpora/test_errors.txt\"", "\n", "test_random_errors_file_name", "=", "\"/Users/macbook/Desktop/corpora/test_random_errors.txt\"", "\n", "\n", "predicted_dist", "=", "[", "]", "\n", "random_dist", "=", "[", "]", "\n", "\n", "with", "open", "(", "test_errors_file_name", ",", "\"a\"", ")", "as", "myfile", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "correct_values", ")", "-", "1", ")", ":", "\n", "            ", "distance", "=", "calc_distance", "(", "correct_values", "[", "i", "]", ",", "predicted_values", "[", "i", "]", ")", "\n", "predicted_dist", ".", "append", "(", "distance", ")", "\n", "#   myfile.write(\" \" + str(distance))", "\n", "\n", "", "", "with", "open", "(", "test_random_errors_file_name", ",", "\"a\"", ")", "as", "myfile", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "correct_values", ")", "-", "1", ")", ":", "\n", "            ", "distance", "=", "calc_distance", "(", "correct_values", "[", "i", "]", ",", "random_values", "[", "i", "]", ")", "\n", "random_dist", ".", "append", "(", "distance", ")", "\n", "#  myfile.write(\" \" + str(distance))", "\n", "\n", "", "", "plt", ".", "hist", "(", "predicted_dist", ",", "fc", "=", "(", "0", ",", "0", ",", "1", ",", "0.5", ")", ",", "label", "=", "\"predicted\"", ")", "\n", "plt", ".", "hist", "(", "random_dist", ",", "fc", "=", "(", "1", ",", "0", ",", "0", ",", "0.5", ")", ",", "label", "=", "\"random\"", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'upper right'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.calc_distance": [[170, 172], ["scipy.spatial.distance.cosine"], "function", ["None"], ["", "def", "calc_distance", "(", "vec1", ",", "vec2", ")", ":", "\n", "    ", "return", "spatial", ".", "distance", ".", "cosine", "(", "vec1", ",", "vec2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.main": [[173, 190], ["LM_RNN_GloVe.tokenize_file_to_vectors", "print", "LM_RNN_GloVe.run_experiment"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.tokenize_file_to_vectors", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.LM_RNN_GloVe.run_experiment"], ["", "def", "main", "(", ")", ":", "\n", "\n", "\n", "\n", "    ", "file_2_tokenize_name", "=", "\"/Users/macbook/Desktop/corpora/text2tokenize.txt\"", "\n", "file_2_tokenize_name_test", "=", "\"/Users/macbook/Desktop/corpora/text2tokenize_test.txt\"", "\n", "tokenized_file_name", "=", "\"/Users/macbook/Desktop/corpora/tokenized2vectors.txt\"", "\n", "glove_vectors_file_name", "=", "\"/Users/macbook/Desktop/corpora/glove.42B.300d.txt\"", "\n", "vectors_test_file_name", "=", "\"/Users/macbook/Desktop/corpora/vectors_test.txt\"", "\n", "extra_vocab_filename", "=", "\"/Users/macbook/Desktop/corpora/extra_vocab.txt\"", "\n", "train_file_name", "=", "\"/Users/macbook/Desktop/corpora/tokenized_train.txt\"", "\n", "test_errors_file_name", "=", "\"/Users/macbook/Desktop/corpora/test_errors.txt\"", "\n", "test_random_errors_file_name", "=", "\"/Users/macbook/Desktop/corpora/test_random_errors.txt\"", "\n", "\n", "tokenize_file_to_vectors", "(", "glove_vectors_file_name", ",", "file_2_tokenize_name", ",", "tokenized_file_name", ")", "\n", "print", "(", "\"FINISHED TOKENIZING\"", ")", "\n", "run_experiment", "(", "tokenized_file_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.predictWordByContext": [[25, 27], ["None"], "function", ["None"], ["def", "predictWordByContext", "(", "context", ")", ":", "\n", "    ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.clean_text": [[29, 44], ["token.replace.replace", "token.replace.replace", "token.replace.replace", "token.replace.replace", "token.replace.replace", "token.replace.replace", "token.replace.replace", "token.replace.replace", "token.replace.replace", "token.replace.replace", "token.replace.replace", "token.replace.replace"], "function", ["None"], ["", "def", "clean_text", "(", "token", ")", ":", "\n", "\n", "    ", "token", "=", "token", ".", "replace", "(", "\",\"", ",", "\"\"", ")", "\n", "token", "=", "token", ".", "replace", "(", "\".\"", ",", "\"\"", ")", "\n", "token", "=", "token", ".", "replace", "(", "\"?\"", ",", "\"\"", ")", "\n", "token", "=", "token", ".", "replace", "(", "\":\"", ",", "\"\"", ")", "\n", "token", "=", "token", ".", "replace", "(", "\";\"", ",", "\"\"", ")", "\n", "token", "=", "token", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", "\n", "token", "=", "token", ".", "replace", "(", "\")\"", ",", "\"\"", ")", "\n", "token", "=", "token", ".", "replace", "(", "\"(\"", ",", "\"\"", ")", "\n", "token", "=", "token", ".", "replace", "(", "\"[\"", ",", "\"\"", ")", "\n", "token", "=", "token", ".", "replace", "(", "\"]\"", ",", "\"\"", ")", "\n", "token", "=", "token", ".", "replace", "(", "\"}\"", ",", "\"\"", ")", "\n", "token", "=", "token", ".", "replace", "(", "\"{\"", ",", "\"\"", ")", "\n", "return", "token", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.my_strip": [[46, 52], ["token.strip.strip", "token.strip.strip", "token.strip.strip", "token.strip.strip"], "function", ["None"], ["", "def", "my_strip", "(", "token", ")", ":", "\n", "    ", "token", "=", "token", ".", "strip", "(", "\",\"", ")", "\n", "token", "=", "token", ".", "strip", "(", "\".\"", ")", "\n", "token", "=", "token", ".", "strip", "(", "\"?\"", ")", "\n", "token", "=", "token", ".", "strip", "(", "\":\"", ")", "\n", "return", "token", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.tokenize_file_to_vectors": [[54, 65], ["open", "line.lower.lower", "line.lower.split", "len", "ProofSeerLM.find_ngrams", "ProofSeerLM.get_csv", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.find_ngrams", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_csv"], ["", "def", "tokenize_file_to_vectors", "(", "common_words_file", ",", "file2tokenize", ",", "outputfile", ")", ":", "\n", "    ", "with", "open", "(", "file2tokenize", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "lower", "(", ")", "\n", "tokens", "=", "line", ".", "split", "(", ")", "\n", "if", "(", "len", "(", "tokens", ")", ">", "4", ")", ":", "\n", "                ", "five_gramms", "=", "find_ngrams", "(", "line", ",", "5", ")", "\n", "for", "gramm", "in", "five_gramms", ":", "\n", "                    ", "str_gramm", "=", "get_csv", "(", "gramm", ")", "\n", "with", "open", "(", "outputfile", ",", "\"a\"", ")", "as", "myfile", ":", "\n", "                        ", "myfile", ".", "write", "(", "str_gramm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_tokenized_file_to_vectors2": [[67, 82], ["open", "line.lower.lower", "line.lower.split", "len", "ProofSeerLM.find_ngrams", "ProofSeerLM.get_csv"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.find_ngrams", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_csv"], ["", "", "", "", "", "", "def", "get_tokenized_file_to_vectors2", "(", "vocab", ",", "file2tokenize", ")", ":", "\n", "    ", "tokenized_file", "=", "\"\"", "\n", "with", "open", "(", "file2tokenize", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "lower", "(", ")", "\n", "tokens", "=", "line", ".", "split", "(", ")", "\n", "if", "len", "(", "tokens", ")", ">", "10", ":", "\n", "                ", "n_grams", "=", "find_ngrams", "(", "line", ",", "11", ")", "\n", "for", "gram", "in", "n_grams", ":", "\n", "                    ", "current_y", "=", "gram", "[", "5", "]", "\n", "# current_y = clean_text(current_y)", "\n", "if", "current_y", "in", "vocab", ":", "\n", "                        ", "str_gramm", "=", "get_csv", "(", "gram", ",", "vocab", ",", "5", ",", "11", ")", "\n", "tokenized_file", "=", "tokenized_file", "+", "str_gramm", "\n", "", "", "", "", "", "return", "tokenized_file", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_tokenized_file_to_vectors": [[84, 99], ["open", "line.lower.lower", "line.lower.split", "len", "ProofSeerLM.find_ngrams", "ProofSeerLM.clean_text", "ProofSeerLM.get_csv"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.find_ngrams", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.clean_text", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_csv"], ["", "def", "get_tokenized_file_to_vectors", "(", "vocab", ",", "file2tokenize", ")", ":", "\n", "    ", "tokenized_file", "=", "\"\"", "\n", "with", "open", "(", "file2tokenize", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "lower", "(", ")", "\n", "tokens", "=", "line", ".", "split", "(", ")", "\n", "if", "len", "(", "tokens", ")", ">", "4", ":", "\n", "                ", "five_gramms", "=", "find_ngrams", "(", "line", ",", "5", ")", "\n", "for", "gramm", "in", "five_gramms", ":", "\n", "                    ", "current_y", "=", "gramm", "[", "2", "]", "\n", "current_y", "=", "clean_text", "(", "current_y", ")", "\n", "if", "current_y", "in", "vocab", ":", "\n", "                        ", "str_gramm", "=", "get_csv", "(", "gramm", ",", "vocab", ",", "2", ",", "5", ")", "\n", "tokenized_file", "=", "tokenized_file", "+", "str_gramm", "\n", "", "", "", "", "", "return", "tokenized_file", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_csv": [[101, 106], ["ProofSeerLM.get_xs", "ProofSeerLM.get_ys"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_xs", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_ys"], ["", "def", "get_csv", "(", "gramm", ",", "vocab", ",", "target_index", ",", "n_gram_size", ")", ":", "#target index is the middle word in window. context-leaf and context-right are same length.", "\n", "    ", "xs", "=", "get_xs", "(", "gramm", ",", "target_index", ",", "vocab", ",", "n_gram_size", ")", "\n", "ys", "=", "get_ys", "(", "gramm", ",", "target_index", ",", "vocab", ")", "\n", "result", "=", "xs", "+", "\" , \"", "+", "ys", "+", "\"\\n\"", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_xs": [[108, 118], ["range", "ProofSeerLM.find_word_index_in_list", "str"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.find_word_index_in_list"], ["", "def", "get_xs", "(", "gramm", ",", "exclude_index", ",", "vocab", ",", "n_gram_size", ")", ":", "\n", "\n", "    ", "xs", "=", "[", "\"0\"", "]", "*", "10000", "\n", "for", "i", "in", "range", "(", "0", ",", "n_gram_size", ",", "1", ")", ":", "\n", "        ", "if", "i", "!=", "exclude_index", ":", "\n", "            ", "index", "=", "find_word_index_in_list", "(", "gramm", "[", "i", "]", ",", "vocab", ")", "\n", "if", "(", "index", "!=", "-", "1", ")", ":", "\n", "                ", "xs", "[", "index", "]", "=", "\"1\"", "\n", "# print(index)", "\n", "", "", "", "return", "','", ".", "join", "(", "str", "(", "e", ")", "for", "e", "in", "xs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_ys": [[120, 126], ["ProofSeerLM.find_word_index_in_list", "str"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.find_word_index_in_list"], ["", "def", "get_ys", "(", "gramm", ",", "label_index", ",", "vocab", ")", ":", "\n", "    ", "ys", "=", "[", "\"0\"", "]", "*", "10000", "\n", "index", "=", "find_word_index_in_list", "(", "gramm", "[", "label_index", "]", ",", "vocab", ")", "\n", "if", "(", "index", "!=", "-", "1", ")", ":", "\n", "        ", "ys", "[", "index", "]", "=", "\"1\"", "\n", "", "return", "','", ".", "join", "(", "str", "(", "e", ")", "for", "e", "in", "ys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.find_word_index": [[128, 143], ["len", "print", "open", "line.split"], "function", ["None"], ["", "def", "find_word_index", "(", "word", ",", "common_words_filename", ")", ":", "\n", "\n", "    ", "count", "=", "0", "\n", "if", "len", "(", "word", ")", ">", "0", ":", "\n", "        ", "with", "open", "(", "common_words_filename", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "tokens", "=", "line", ".", "split", "(", ")", "\n", "# print(str(len(tokens)))", "\n", "if", "tokens", "[", "0", "]", "==", "word", ":", "\n", "                    ", "return", "count", "\n", "", "count", "=", "count", "+", "1", "\n", "", "", "", "else", ":", "\n", "        ", "print", "(", "\"Empty token\"", ")", "\n", "#return -1 if the word was not found in the list of most common words", "\n", "", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.read_vocab_to_list": [[144, 146], ["open", "line.split"], "function", ["None"], ["", "def", "read_vocab_to_list", "(", "filename", ")", ":", "\n", "    ", "return", "[", "word", "for", "line", "in", "open", "(", "filename", ",", "'r'", ")", "for", "word", "in", "line", ".", "split", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.find_word_index_in_list": [[148, 152], ["word_list.index"], "function", ["None"], ["", "def", "find_word_index_in_list", "(", "word", ",", "word_list", ")", ":", "\n", "    ", "if", "word", "in", "word_list", ":", "\n", "        ", "return", "word_list", ".", "index", "(", "word", ")", "\n", "", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.write_common_files": [[154, 162], ["open", "open", "line.split", "range", "print", "myfile.write"], "function", ["None"], ["", "def", "write_common_files", "(", ")", ":", "\n", "    ", "with", "open", "(", "\"/Users/macbook/Desktop/corpora/magic.txt\"", ",", "\"a\"", ")", "as", "myfile", ":", "\n", "         ", "with", "open", "(", "\"/Users/macbook/Desktop/corpora/common_words_coca.txt\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "tokens", "=", "line", ".", "split", "(", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "4999", ",", "1", ")", ":", "\n", "                    ", "print", "(", "\"writing: \"", "+", "tokens", "[", "i", "]", "[", "3", ":", "]", ")", "\n", "myfile", ".", "write", "(", "tokens", "[", "i", "]", "[", "3", ":", "]", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.find_ngrams": [[167, 172], ["s.split", "range", "zip", "len", "ProofSeerLM.clean_text", "range"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.clean_text"], ["", "", "", "", "", "def", "find_ngrams", "(", "s", ",", "n", ")", ":", "\n", "    ", "input_list", "=", "s", ".", "split", "(", "\" \"", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "input_list", ")", ",", "1", ")", ":", "\n", "        ", "input_list", "[", "i", "]", "=", "clean_text", "(", "input_list", "[", "i", "]", ")", "\n", "", "return", "zip", "(", "*", "[", "input_list", "[", "i", ":", "]", "for", "i", "in", "range", "(", "n", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.create_online_dataset": [[174, 177], ["numpy.genfromtxt", "cStringIO.StringIO"], "function", ["None"], ["", "def", "create_online_dataset", "(", "filename", ")", ":", "\n", "\n", "    ", "np", ".", "genfromtxt", "(", "StringIO", "(", "filename", ")", ",", "delimiter", "=", "\",\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.train_model_from_dir": [[182, 221], ["time.time", "print", "keras.models.Sequential", "keras.models.Sequential.add", "keras.models.Sequential.add", "print", "keras.models.Sequential.compile", "print", "os.walk", "time.time", "print", "keras.models.Sequential.save", "keras.layers.core.Dense", "keras.layers.core.Dense", "os.path.join", "os.path.join.endswith", "print", "time.time", "ProofSeerLM.get_tokenized_file_to_vectors2", "numpy.genfromtxt", "time.time", "print", "cStringIO.StringIO", "numpy.array", "numpy.array", "keras.models.Sequential.fit", "ProofSeerLM.log_train_file", "ProofSeerLM.log_fail_file", "print", "keras.models.Sequential.save", "len"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_tokenized_file_to_vectors2", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.log_train_file", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.log_fail_file"], ["", "def", "train_model_from_dir", "(", "root", ",", "vocabulary_filename", ")", ":", "\n", "\n", "    ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Creating the model object\"", ")", "\n", "model", "=", "Sequential", "(", ")", "\n", "model", ".", "add", "(", "Dense", "(", "10", ",", "input_dim", "=", "10000", ",", "init", "=", "'uniform'", ",", "activation", "=", "'relu'", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "10000", ",", "init", "=", "'normal'", ",", "activation", "=", "'softmax'", ")", ")", "# can be also sigmoid (for a multiclass)", "\n", "print", "(", "\"compiling...\"", ")", "\n", "model", ".", "compile", "(", "loss", "=", "'categorical_crossentropy'", ",", "optimizer", "=", "'adam'", ",", "metrics", "=", "[", "'accuracy'", "]", ")", "\n", "print", "(", "\"compiled!\"", ")", "\n", "count", "=", "0", "\n", "for", "path", ",", "subdirs", ",", "files", "in", "os", ".", "walk", "(", "root", ")", ":", "\n", "        ", "for", "name", "in", "files", ":", "\n", "            ", "current_filename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "\n", "if", "current_filename", ".", "endswith", "(", "\"txt\"", ")", ":", "\n", "                ", "count", "=", "count", "+", "1", "\n", "print", "(", "\"file number\"", ",", "count", ")", "\n", "file_start", "=", "time", ".", "time", "(", ")", "\n", "data", "=", "get_tokenized_file_to_vectors2", "(", "vocabulary_filename", ",", "current_filename", ")", "\n", "#   print(\"read file:\", count)", "\n", "dataset", "=", "np", ".", "genfromtxt", "(", "StringIO", "(", "data", ")", ",", "delimiter", "=", "\",\"", ")", "\n", "#   print(\"shape\", dataset.shape)", "\n", "if", "(", "len", "(", "dataset", ".", "shape", ")", "==", "2", "and", "dataset", ".", "shape", "[", "1", "]", "==", "20000", ")", ":", "\n", "                    ", "X", "=", "dataset", "[", ":", ",", "0", ":", "10000", "]", "\n", "Y", "=", "dataset", "[", ":", ",", "10000", ":", "]", "\n", "arrX", "=", "np", ".", "array", "(", "X", ")", "\n", "arrY", "=", "np", ".", "array", "(", "Y", ")", "\n", "model", ".", "fit", "(", "arrX", ",", "arrY", ",", "nb_epoch", "=", "50", ",", "batch_size", "=", "dataset", ".", "shape", "[", "0", "]", ")", "#check the batch size", "\n", "log_train_file", "(", "current_filename", ",", "dataset", ".", "shape", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                    ", "log_fail_file", "(", "current_filename", ")", "\n", "", "file_end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"file time:\"", ",", "file_end", "-", "file_start", ")", "\n", "if", "count", "%", "10", "==", "0", ":", "\n", "                    ", "print", "(", "\"Saving model...\"", ",", "count", ")", "\n", "model", ".", "save", "(", "\"C:\\corpora\\\\model.h5\"", ")", "\n", "", "", "", "", "end_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"elapsed time\"", ",", "end_time", "-", "start_time", ")", "\n", "model", ".", "save", "(", "\"C:\\corpora\\\\model.h5\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.continue_train_model_from_dir": [[223, 259], ["time.time", "keras.models.load_model", "os.walk", "time.time", "print", "keras.models.load_model.save", "os.path.join", "os.path.join.endswith", "ProofSeerLM.find_word_index", "print", "print", "time.time", "ProofSeerLM.get_tokenized_file_to_vectors2", "numpy.genfromtxt", "print", "time.time", "print", "print", "cStringIO.StringIO", "len", "numpy.array", "numpy.array", "keras.models.load_model.fit", "ProofSeerLM.log_train_file", "ProofSeerLM.log_fail_file", "print", "keras.models.load_model.save", "len"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.find_word_index", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_tokenized_file_to_vectors2", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.log_train_file", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.log_fail_file"], ["", "def", "continue_train_model_from_dir", "(", "root", ",", "vocabulary_filename", ",", "model_filename", ")", ":", "\n", "\n", "    ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "model", "=", "load_model", "(", "model_filename", ")", "\n", "count", "=", "0", "\n", "for", "path", ",", "subdirs", ",", "files", "in", "os", ".", "walk", "(", "root", ")", ":", "\n", "        ", "for", "name", "in", "files", ":", "\n", "            ", "current_filename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "\n", "if", "current_filename", ".", "endswith", "(", "\"txt\"", ")", ":", "\n", "                ", "count", "=", "count", "+", "1", "\n", "if", "find_word_index", "(", "current_filename", ",", "\"C:\\corpora\\\\log.txt\"", ")", "==", "-", "1", ":", "\n", "                    ", "print", "(", "\"file number\"", ",", "count", ")", "\n", "print", "(", "\"filename\"", ",", "current_filename", ")", "\n", "file_start", "=", "time", ".", "time", "(", ")", "\n", "data", "=", "get_tokenized_file_to_vectors2", "(", "vocabulary_filename", ",", "current_filename", ")", "\n", "dataset", "=", "np", ".", "genfromtxt", "(", "StringIO", "(", "data", ")", ",", "delimiter", "=", "\",\"", ")", "\n", "print", "(", "\"shape dim:\"", ",", "len", "(", "dataset", ".", "shape", ")", ")", "\n", "if", "(", "len", "(", "dataset", ".", "shape", ")", "==", "2", "and", "dataset", ".", "shape", "[", "1", "]", "==", "20000", ")", ":", "\n", "                        ", "X", "=", "dataset", "[", ":", ",", "0", ":", "10000", "]", "\n", "Y", "=", "dataset", "[", ":", ",", "10000", ":", "]", "\n", "arrX", "=", "np", ".", "array", "(", "X", ")", "\n", "arrY", "=", "np", ".", "array", "(", "Y", ")", "\n", "model", ".", "fit", "(", "arrX", ",", "arrY", ",", "nb_epoch", "=", "50", ",", "batch_size", "=", "dataset", ".", "shape", "[", "0", "]", ")", "#check the batch size", "\n", "log_train_file", "(", "current_filename", ",", "dataset", ".", "shape", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                        ", "log_fail_file", "(", "current_filename", ")", "\n", "", "file_end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"file time:\"", ",", "file_end", "-", "file_start", ")", "\n", "if", "count", "%", "10", "==", "0", ":", "\n", "                        ", "print", "(", "\"Saving model...\"", ",", "count", ")", "\n", "model", ".", "save", "(", "\"C:\\corpora\\\\model.h5\"", ")", "\n", "", "", "else", ":", "\n", "                    ", "print", "(", "\"file already trained:\"", ",", "count", ",", "current_filename", ")", "\n", "", "", "", "", "end_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"elapsed time\"", ",", "end_time", "-", "start_time", ")", "\n", "model", ".", "save", "(", "\"C:\\corpora\\\\model.h5\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.log_train_file": [[261, 266], ["open", "myfile.write", "str"], "function", ["None"], ["", "def", "log_train_file", "(", "filename", ",", "tokens_num", ")", ":", "\n", "     ", "log_file", "=", "\"C:\\corpora\\\\log.txt\"", "\n", "logline", "=", "filename", "+", "\" \"", "+", "str", "(", "tokens_num", ")", "+", "\"\\n\"", "\n", "with", "open", "(", "log_file", ",", "\"a\"", ")", "as", "myfile", ":", "\n", "         ", "myfile", ".", "write", "(", "logline", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.log_fail_file": [[268, 273], ["open", "myfile.write"], "function", ["None"], ["", "", "def", "log_fail_file", "(", "filename", ")", ":", "\n", "    ", "log_file", "=", "\"C:\\corpora\\\\log_fail.txt\"", "\n", "logline", "=", "filename", "+", "\"\\n\"", "\n", "with", "open", "(", "log_file", ",", "\"a\"", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "logline", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.test_model_on_dir": [[274, 295], ["keras.models.load_model", "os.walk", "print", "name.endswith", "ProofSeerLM.get_tokenized_file_to_vectors2", "numpy.genfromtxt", "numpy.array", "numpy.array", "keras.models.load_model.predict", "ProofSeerLM.getMRR", "print", "os.path.join", "cStringIO.StringIO"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_tokenized_file_to_vectors2", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.getMRR"], ["", "", "def", "test_model_on_dir", "(", "model_filename", ",", "root", ",", "vocab", ")", ":", "\n", "    ", "model", "=", "load_model", "(", "model_filename", ")", "\n", "average", "=", "0", "\n", "files_num", "=", "0", "\n", "for", "path", ",", "subdirs", ",", "files", "in", "os", ".", "walk", "(", "root", ")", ":", "\n", "        ", "for", "name", "in", "files", ":", "\n", "#  print(\"file name\", os.path.join(path, name))", "\n", "            ", "if", "(", "name", ".", "endswith", "(", "\"txt\"", ")", ")", ":", "\n", "                ", "data", "=", "get_tokenized_file_to_vectors2", "(", "vocab", ",", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", ")", "\n", "dataset", "=", "np", ".", "genfromtxt", "(", "StringIO", "(", "data", ")", ",", "delimiter", "=", "\",\"", ")", "\n", "X", "=", "dataset", "[", ":", ",", "0", ":", "10000", "]", "\n", "Y", "=", "dataset", "[", ":", ",", "10000", ":", "]", "\n", "arrX", "=", "np", ".", "array", "(", "X", ")", "\n", "arrY", "=", "np", ".", "array", "(", "Y", ")", "\n", "predictions", "=", "model", ".", "predict", "(", "arrX", ")", "\n", "#  mrr = getMRR_after_sort(predictions, arrY, arrX, vocab)", "\n", "mrr", "=", "getMRR", "(", "predictions", ",", "arrY", ")", "\n", "average", "=", "average", "+", "mrr", "\n", "files_num", "=", "files_num", "+", "1", "\n", "print", "(", "name", ",", "\"MRR:\"", ",", "mrr", ")", "\n", "", "", "", "print", "(", "\"Average MRR:\"", ",", "average", "/", "files_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.getMRR": [[298, 311], ["range", "len", "numpy.argmax", "numpy.argmax", "float", "numpy.argmax", "len", "len", "len", "float"], "function", ["None"], ["", "def", "getMRR", "(", "predictions", ",", "labels", ")", ":", "\n", "    ", "sum", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "predictions", ")", ",", "1", ")", ":", "\n", "        ", "correct_index", "=", "np", ".", "argmax", "(", "labels", "[", "i", "]", ")", "\n", "predicted_index", "=", "np", ".", "argmax", "(", "predictions", "[", "i", "]", ")", "\n", "rank", "=", "1", "\n", "while", "predicted_index", "!=", "correct_index", "and", "rank", "<", "len", "(", "predictions", ")", ":", "\n", "            ", "predictions", "[", "i", "]", "[", "predicted_index", "]", "=", "-", "1", "\n", "predicted_index", "=", "np", ".", "argmax", "(", "predictions", "[", "i", "]", ")", "\n", "rank", "=", "rank", "+", "1", "\n", "", "if", "rank", "<", "len", "(", "predictions", ")", "-", "1", ":", "\n", "            ", "sum", "=", "sum", "+", "1", "/", "float", "(", "rank", ")", "\n", "", "", "return", "sum", "/", "float", "(", "len", "(", "predictions", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.getMRR_after_sort": [[313, 326], ["range", "len", "numpy.argmax", "ProofSeerLM.get_top_sorted_predictions_indexes", "float", "len", "len", "len", "float"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_top_sorted_predictions_indexes"], ["", "def", "getMRR_after_sort", "(", "predictions", ",", "labels", ",", "contexts", ",", "vocab", ")", ":", "\n", "    ", "sum", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "predictions", ")", ",", "1", ")", ":", "\n", "        ", "correct_index", "=", "np", ".", "argmax", "(", "labels", "[", "i", "]", ")", "\n", "sorted_predictions", "=", "get_top_sorted_predictions_indexes", "(", "predictions", "[", "i", "]", ",", "contexts", "[", "i", "]", ",", "vocab", ",", "correct_index", ")", "#sorted 1-dimensional array of suggestions", "\n", "rank", "=", "1", "\n", "predicted_index", "=", "sorted_predictions", "[", "0", "]", "\n", "while", "predicted_index", "!=", "correct_index", "and", "rank", "<", "len", "(", "sorted_predictions", ")", ":", "\n", "            ", "predicted_index", "=", "sorted_predictions", "[", "rank", "]", "\n", "rank", "=", "rank", "+", "1", "\n", "", "if", "rank", "<", "len", "(", "sorted_predictions", ")", ":", "\n", "            ", "sum", "=", "sum", "+", "1", "/", "float", "(", "rank", ")", "\n", "", "", "return", "sum", "/", "float", "(", "len", "(", "predictions", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_top_sorted_predictions_indexes": [[328, 377], ["range", "numpy.where", "ProofSeerLM.get_vector", "zip", "sorted", "zip", "numpy.argmax", "top_ten_words.append", "ProofSeerLM.get_vector", "top_ten_vectors.append", "context_words.append", "ProofSeerLM.get_vector", "context_vectors.append", "context_similarities.append", "list", "scipy.spatial.distance.cosine", "float", "scipy.spatial.distance.cosine", "float", "float", "float", "float", "float"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_vector", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_vector", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_vector"], ["", "def", "get_top_sorted_predictions_indexes", "(", "prediction", ",", "context", ",", "vocab", ",", "correct_index", ")", ":", "\n", "    ", "sorted_predictions", "=", "[", "0", "]", "*", "5", "\n", "top_ten_indices", "=", "[", "0", "]", "*", "5", "\n", "for", "i", "in", "range", "(", "0", ",", "5", ",", "1", ")", ":", "\n", "        ", "max_probability_index", "=", "np", ".", "argmax", "(", "prediction", ")", "\n", "top_ten_indices", "[", "i", "]", "=", "max_probability_index", "\n", "prediction", "[", "max_probability_index", "]", "=", "-", "1", "\n", "\n", "", "top_ten_words", "=", "[", "]", "\n", "for", "index", "in", "top_ten_indices", ":", "\n", "        ", "top_ten_words", ".", "append", "(", "vocab", "[", "index", "]", ")", "\n", "\n", "#  print(\"top ten words\", top_ten_words)", "\n", "", "top_ten_vectors", "=", "[", "]", "\n", "for", "word", "in", "top_ten_words", ":", "\n", "        ", "vector", "=", "get_vector", "(", "word", ")", "\n", "top_ten_vectors", ".", "append", "(", "vector", ")", "\n", "# print(\"top ten vec length\", len(top_ten_vectors))", "\n", "\n", "", "context_indexes", "=", "np", ".", "where", "(", "context", "==", "1", ")", "\n", "#   print (\"context indexes\", context_indexes)", "\n", "context_words", "=", "[", "]", "\n", "for", "index", "in", "context_indexes", "[", "0", "]", ":", "\n", "        ", "context_words", ".", "append", "(", "vocab", "[", "index", "]", ")", "\n", "#   print (\"Context words\", context_words)", "\n", "\n", "", "context_vectors", "=", "[", "]", "\n", "for", "word", "in", "context_words", ":", "\n", "        ", "vector", "=", "get_vector", "(", "word", ")", "\n", "context_vectors", ".", "append", "(", "vector", ")", "\n", "#   print(\"length context vectors\", len(context_vectors))", "\n", "\n", "", "correct_vector", "=", "get_vector", "(", "vocab", "[", "correct_index", "]", ")", "\n", "context_similarities", "=", "[", "]", "\n", "for", "vector", "in", "top_ten_vectors", ":", "\n", "        ", "vector_sim", "=", "0", "\n", "vector_sim", "=", "vector_sim", "+", "1", "-", "spatial", ".", "distance", ".", "cosine", "(", "[", "float", "(", "i", ")", "for", "i", "in", "vector", "]", ",", "[", "float", "(", "i", ")", "for", "i", "in", "correct_vector", "]", ")", "\n", "context_words_num", "=", "0", "\n", "for", "context_vec", "in", "context_vectors", ":", "\n", "            ", "vector_sim", "=", "vector_sim", "+", "1", "-", "spatial", ".", "distance", ".", "cosine", "(", "[", "float", "(", "i", ")", "for", "i", "in", "vector", "]", ",", "[", "float", "(", "i", ")", "for", "i", "in", "context_vec", "]", ")", "\n", "context_words_num", "=", "context_words_num", "+", "1", "\n", "", "grade", "=", "0", "\n", "grade", "=", "vector_sim", "/", "float", "(", "float", "(", "context_words_num", ")", "+", "1", ")", "\n", "context_similarities", ".", "append", "(", "grade", ")", "\n", "", "decorated", "=", "zip", "(", "top_ten_indices", ",", "context_similarities", ")", "\n", "list_of_lists", "=", "[", "list", "(", "elem", ")", "for", "elem", "in", "decorated", "]", "\n", "sorted_predictions", "=", "sorted", "(", "list_of_lists", ",", "key", "=", "lambda", "pair", ":", "pair", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "list1", ",", "list2", "=", "zip", "(", "*", "sorted_predictions", ")", "\n", "return", "list1", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_vector": [[379, 396], ["ProofSeerLM.RNNGloveConfig", "ProofSeerLM.add_unseen_token_2_extra_vocabulary", "open", "open", "line.split", "line.split", "token.lower", "token.lower"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.add_unseen_token_2_extra_vocabulary"], ["", "def", "get_vector", "(", "token", ",", "extra_vectors_file", "=", "\"/Users/macbook/Desktop/corpora/aux_files/extra_vocab.txt\"", ")", ":", "\n", "    ", "config", "=", "RNNGloveConfig", "(", ")", "\n", "with", "open", "(", "extra_vectors_file", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "tokens", "=", "line", ".", "split", "(", ")", "\n", "if", "tokens", "[", "0", "]", "==", "token", ".", "lower", "(", ")", ":", "\n", "                ", "vec", "=", "tokens", "[", "1", ":", "config", ".", "vector_dimension", "+", "1", "]", "\n", "#            print (\"returning from extra: \", token)", "\n", "return", "vec", "\n", "", "", "", "with", "open", "(", "config", ".", "glove_vectors", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "tokens", "=", "line", ".", "split", "(", ")", "\n", "if", "tokens", "[", "0", "]", "==", "token", ".", "lower", "(", ")", ":", "\n", "                ", "vec", "=", "tokens", "[", "1", ":", "config", ".", "vector_dimension", "+", "1", "]", "\n", "return", "vec", "\n", "", "", "", "vec", "=", "add_unseen_token_2_extra_vocabulary", "(", "token", ",", "extra_vectors_file", ")", "\n", "return", "vec", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.add_unseen_token_2_extra_vocabulary": [[398, 409], ["ProofSeerLM.RNNGloveConfig", "random.random", "str", "open", "myfile.write", "range", "token.lower", "str"], "function", ["None"], ["", "def", "add_unseen_token_2_extra_vocabulary", "(", "token", ",", "extra_vocab_filename", ")", ":", "\n", "    ", "config", "=", "RNNGloveConfig", "(", ")", "\n", "#   print(\"Adding unseen token: \", token)", "\n", "random_vector", "=", "[", "random", ".", "random", "(", ")", "for", "_", "in", "range", "(", "0", ",", "config", ".", "vector_dimension", ")", "]", "\n", "string_vector", "=", "[", "str", "(", "i", ")", "for", "i", "in", "random_vector", "]", "\n", "vector", "=", "[", "token", ".", "lower", "(", ")", "]", "+", "[", "\" \"", "]", "+", "string_vector", "\n", "with", "open", "(", "extra_vocab_filename", ",", "\"a\"", ")", "as", "myfile", ":", "\n", "        ", "str_vector", "=", "' '", ".", "join", "(", "str", "(", "e", ")", "for", "e", "in", "vector", ")", "#covert list to string", "\n", "str_vector", "=", "str_vector", "+", "\"\\n\"", "\n", "myfile", ".", "write", "(", "str_vector", ")", "\n", "", "return", "random_vector", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.get_context_words": [[411, 414], ["None"], "function", ["None"], ["", "def", "get_context_words", "(", "context", ")", ":", "\n", "    ", "words", "=", "[", "\"\"", "]", "*", "5", "\n", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.main": [[420, 434], ["print", "ProofSeerLM.read_vocab_to_list", "ProofSeerLM.test_model_on_dir"], "function", ["home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.read_vocab_to_list", "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.ProofSeerLM.test_model_on_dir"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "print", "(", "\"haha\"", ")", "\n", "\n", "common_words_filename", "=", "\"C:\\corpora\\\\clean_vocab10000.txt\"", "\n", "vocab", "=", "read_vocab_to_list", "(", "common_words_filename", ")", "\n", "corpus_path", "=", "\"C:\\corpora\\\\clean_corpus\"", "\n", "#   train_model_from_dir(corpus_path, vocab)", "\n", "#   dense_vectors_glove = \"/Users/macbook/Desktop/corpora/aux_files/glove.6B.50d.txt\"", "\n", "#   one_hot_train_data = \"/Users/macbook/Desktop/corpora/aux_files/one_hot_csv.txt\"", "\n", "#  continue_train_model_from_dir(corpus_path, vocab, \"C:\\corpora\\\\model.h5\")", "\n", "#    test_model_on_dir(\"C:\\\\corpora\\\\model.h5\", \"C:\\\\corpora\\\\alt_test\", vocab)", "\n", "#   test_model_on_dir(\"C:\\\\corpora\\\\model.h5\", \"C:\\\\corpora\\\\alt_test2\", vocab)", "\n", "test_model_on_dir", "(", "\"C:\\\\corpora\\\\model.h5\"", ",", "\"C:\\\\corpora\\\\triple_test_clean\"", ",", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.util.Vocab.__init__": [[5, 9], ["dict", "collections.defaultdict", "collections.defaultdict.iteritems", "itertools.count"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "w2i", "=", "None", ")", ":", "\n", "        ", "if", "w2i", "is", "None", ":", "w2i", "=", "defaultdict", "(", "count", "(", "0", ")", ".", "next", ")", "\n", "self", ".", "w2i", "=", "dict", "(", "w2i", ")", "\n", "self", ".", "i2w", "=", "{", "i", ":", "w", "for", "w", ",", "i", "in", "w2i", ".", "iteritems", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.util.Vocab.from_corpus": [[10, 16], ["collections.defaultdict", "util.Vocab", "itertools.count"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_corpus", "(", "cls", ",", "corpus", ")", ":", "\n", "        ", "w2i", "=", "defaultdict", "(", "count", "(", "0", ")", ".", "next", ")", "\n", "for", "sent", "in", "corpus", ":", "\n", "            ", "[", "w2i", "[", "word", "]", "for", "word", "in", "sent", "]", "\n", "", "return", "Vocab", "(", "w2i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.util.Vocab.size": [[17, 18], ["len", "util.Vocab.w2i.keys"], "methods", ["None"], ["", "def", "size", "(", "self", ")", ":", "return", "len", "(", "self", ".", "w2i", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.util.CorpusReader.__init__": [[20, 22], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "fname", ")", ":", "\n", "        ", "self", ".", "fname", "=", "fname", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.util.CorpusReader.__iter__": [[22, 30], ["file", "line.strip().split.strip().split.lower", "line.strip().split.strip().split.strip().split", "len", "line.strip().split.strip().split.strip"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "line", "in", "file", "(", "self", ".", "fname", ")", ":", "\n", "            ", "line", "=", "line", ".", "lower", "(", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "line", "=", "[", "\"<start>\"", "]", "+", "line", "+", "[", "\"<stop>\"", "]", "\n", "#line = [' ' if x == '' else x for x in line]", "\n", "if", "len", "(", "line", ")", ">", "1", ":", "\n", "                ", "yield", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.util.FastCorpusReader.__init__": [[33, 36], ["open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "fname", ")", ":", "\n", "        ", "self", ".", "fname", "=", "fname", "\n", "self", ".", "f", "=", "open", "(", "fname", ",", "'rb'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.util.FastCorpusReader.__iter__": [[37, 51], ["mmap.mmap", "mmap.mmap.readline", "util.FastCorpusReader.f.fileno", "mmap.mmap.readline", "line.strip().split.strip().split.lower", "line.strip().split.strip().split.strip().split", "line.strip().split.strip().split.strip", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "m", "=", "mmap", ".", "mmap", "(", "self", ".", "f", ".", "fileno", "(", ")", ",", "0", ",", "access", "=", "mmap", ".", "ACCESS_READ", ")", "\n", "data", "=", "m", ".", "readline", "(", ")", "\n", "count", "=", "0", "\n", "while", "data", ":", "\n", "            ", "line", "=", "data", "\n", "count", "=", "count", "+", "1", "\n", "data", "=", "m", ".", "readline", "(", ")", "\n", "line", "=", "line", ".", "lower", "(", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "line", "=", "[", "\"<start>\"", "]", "+", "line", "+", "[", "\"<stop>\"", "]", "\n", "if", "len", "(", "line", ")", ">", "1", "and", "count", "<=", "2800000", ":", "\n", "#line.reverse()", "\n", "                ", "yield", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.util.CharsCorpusReader.__init__": [[54, 57], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "fname", ",", "begin", "=", "None", ")", ":", "\n", "        ", "self", ".", "fname", "=", "fname", "\n", "self", ".", "begin", "=", "begin", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vicmak_ProofSeer.None.util.CharsCorpusReader.__iter__": [[57, 64], ["file", "list"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "begin", "=", "self", ".", "begin", "\n", "for", "line", "in", "file", "(", "self", ".", "fname", ")", ":", "\n", "            ", "line", "=", "list", "(", "line", ")", "\n", "if", "begin", ":", "\n", "                ", "line", "=", "[", "begin", "]", "+", "line", "\n", "", "yield", "line", "\n", "", "", "", ""]]}