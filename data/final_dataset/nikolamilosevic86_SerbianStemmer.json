{"home.repos.pwc.inspect_result.nikolamilosevic86_SerbianStemmer.None.StemmerByNikola.stem_arr": [[374, 394], ["str.replace.lower", "str.replace.replace", "str.replace.replace", "str.replace.replace", "str.replace.replace", "str.replace.replace", "nltk.tokenize.word_tokenize", "word.endswith", "len", "len", "len"], "function", ["None"], ["def", "stem_arr", "(", "str", ")", ":", "\n", "    ", "str", "=", "str", ".", "lower", "(", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u0161\"", ",", "\"sx\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u010d\"", ",", "\"cx\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u0107\"", ",", "\"cy\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u0111\"", ",", "\"dx\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u017e\"", ",", "\"zx\"", ")", "\n", "lam", "=", "word_tokenize", "(", "str", ")", "\n", "i", "=", "0", "\n", "for", "word", "in", "lam", ":", "\n", "        ", "for", "key", "in", "dictionary", ":", "\n", "            ", "if", "key", "==", "word", ":", "\n", "                ", "lam", "[", "i", "]", "=", "dictionary", "[", "key", "]", "\n", "break", "\n", "", "", "for", "key", "in", "rules", ":", "\n", "            ", "if", "(", "word", ".", "endswith", "(", "key", ")", "and", "len", "(", "word", ")", "-", "len", "(", "key", ")", ">", "2", ")", ":", "\n", "                ", "lam", "[", "i", "]", "=", "word", "[", ":", "-", "len", "(", "key", ")", "]", "+", "rules", "[", "key", "]", "\n", "break", "\n", "", "", "i", "=", "i", "+", "1", "\n", "", "return", "lam", "\n", "\n"]], "home.repos.pwc.inspect_result.nikolamilosevic86_SerbianStemmer.None.StemmerByNikola.stem_str": [[395, 431], ["str.replace.lower", "str.replace.replace", "str.replace.replace", "str.replace.replace", "str.replace.replace", "str.replace.replace", "str.replace.replace", "str.replace.replace", "str.replace.replace", "str.replace.replace", "str.replace.replace", "str.replace.replace", "str.replace.replace", "str.replace.replace", "str.replace.replace", "str.replace.replace", "str.replace.replace", "str.replace.replace", "nltk.tokenize.word_tokenize", "word.endswith", "len", "len", "len"], "function", ["None"], ["", "def", "stem_str", "(", "str", ")", ":", "\n", "    ", "str", "=", "str", ".", "lower", "(", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u0161\"", ",", "\"sx\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u010d\"", ",", "\"cx\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u0107\"", ",", "\"cy\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u0111\"", ",", "\"dx\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u017e\"", ",", "\"zx\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u0160\"", ",", "\"sx\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u010c\"", ",", "\"cx\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u0106\"", ",", "\"cy\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u0110\"", ",", "\"dx\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u017d\"", ",", "\"zx\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u201c\"", ",", "\"\\\"\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u201d\"", ",", "\"\\\"\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"'\"", ",", "\"\\\"\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u2019\"", ",", "\"\\\"\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u20ac\"", ",", "\"eur\"", ")", "\n", "str", "=", "str", ".", "replace", "(", "\"\u201e\"", ",", "\"\\\"\"", ")", "\n", "lam", "=", "word_tokenize", "(", "str", ")", "\n", "i", "=", "0", "\n", "for", "word", "in", "lam", ":", "\n", "        ", "for", "key", "in", "dictionary", ":", "\n", "            ", "if", "key", "==", "word", ":", "\n", "                ", "lam", "[", "i", "]", "=", "dictionary", "[", "key", "]", "\n", "break", "\n", "", "", "for", "key", "in", "rules", ":", "\n", "# Tokenize only words larger than 2 characters, apart from modal verbs", "\n", "            ", "if", "(", "word", ".", "endswith", "(", "key", ")", "and", "len", "(", "word", ")", "-", "len", "(", "key", ")", ">", "2", ")", ":", "\n", "                ", "lam", "[", "i", "]", "=", "word", "[", ":", "-", "len", "(", "key", ")", "]", "+", "rules", "[", "key", "]", "\n", "break", "\n", "", "", "i", "=", "i", "+", "1", "\n", "", "end_str", "=", "\"\"", "\n", "for", "word", "in", "lam", ":", "\n", "        ", "end_str", "=", "end_str", "+", "\" \"", "+", "word", "\n", "", "return", "end_str", "\n", "\n"]]}