{"home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.config.str2bool": [[5, 12], ["v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.config.path": [[14, 16], ["os.path.expanduser"], "function", ["None"], ["", "", "def", "path", "(", "p", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "expanduser", "(", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.train.run": [[19, 131], ["os.path.exists", "torch.nn.CrossEntropyLoss", "torch.optim.Adam", "model.DependencyBLSTM.zero_grad", "torch.optim.lr_scheduler.StepLR", "print", "utils.get_split_data", "utils.get_split_data", "print", "train.run.train"], "function", ["home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.get_split_data", "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.get_split_data"], ["def", "run", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "save_path", "=", "args", ".", "project_dir", "+", "'Models/'", "+", "args", ".", "sim_name", "+", "'/model.pt'", "\n", "\n", "with", "open", "(", "output_dir", "+", "'config'", ",", "'w'", ")", "as", "config_file", ":", "\n", "        ", "argss", "=", "(", "str", "(", "args", ")", ".", "split", "(", "'('", ")", "[", "1", "]", ".", "split", "(", "')'", ")", "[", "0", "]", ".", "split", "(", "','", ")", ")", "\n", "for", "a", "in", "argss", ":", "\n", "            ", "config_file", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "a", ")", ")", "\n", "", "", "if", "os", ".", "path", ".", "exists", "(", "save_path", ")", ":", "\n", "        ", "model", "=", "torch", ".", "load", "(", "save_path", ")", "\n", "model_loaded", "=", "True", "\n", "print", "(", "'Great!!! Pre-Trained Model Loaded !!!'", ")", "\n", "", "else", ":", "\n", "        ", "model_loaded", "=", "False", "\n", "print", "(", "'No pre-trained model '", ")", "\n", "model", "=", "DependencyBLSTM", "(", "num_words", "=", "utils", ".", "get_num_words", "(", ")", ",", "max_sen_length", "=", "97", ",", "max_doc_sent_length", "=", "326", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "'train_performance_log.csv'", ")", ":", "\n", "        ", "train_performance_log", "=", "open", "(", "output_dir", "+", "'train_performance_log.csv'", ",", "'w'", ")", "\n", "train_performance_log", ".", "write", "(", "'Step,Loss\\n'", ")", "\n", "", "else", ":", "\n", "        ", "train_performance_log", "=", "open", "(", "output_dir", "+", "'train_performance_log.csv'", ",", "'a'", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "'eval_performance_log.txt'", ")", ":", "\n", "        ", "eval_performance_log", "=", "open", "(", "output_dir", "+", "'eval_performance_log.txt'", ",", "'w'", ")", "\n", "", "else", ":", "\n", "        ", "eval_performance_log", "=", "open", "(", "output_dir", "+", "'eval_performance_log.txt'", ",", "'a'", ")", "\n", "\n", "", "if", "args", ".", "gpu", ">", "-", "1", ":", "\n", "        ", "model", ".", "cuda", "(", "device", "=", "int", "(", "args", ".", "gpu", ")", ")", "\n", "\n", "", "if", "not", "model_loaded", ":", "\n", "        ", "if", "args", ".", "fill_embedding", ":", "\n", "            ", "embed", "=", "utils", ".", "get_word_embeddings", "(", "source", "=", "'google'", ")", "\n", "if", "args", ".", "gpu", ">", "-", "1", ":", "\n", "                ", "model", ".", "word_embedding", ".", "weight", ".", "data", ".", "set_", "(", "torch", ".", "FloatTensor", "(", "(", "embed", ")", ")", ".", "cuda", "(", "int", "(", "args", ".", "gpu", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "word_embedding", ".", "weight", ".", "data", ".", "set_", "(", "torch", ".", "FloatTensor", "(", "(", "embed", ")", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "args", ".", "gpu", ">", "-", "1", ":", "\n", "                ", "model", ".", "word_embedding", ".", "weight", ".", "data", ".", "set_", "(", "\n", "torch", ".", "FloatTensor", "(", "(", "np", ".", "zeros", "(", "(", "utils", ".", "get_num_words", "(", ")", "+", "1", ",", "args", ".", "word_dim", ")", ")", ".", "astype", "(", ")", ")", ")", ".", "cuda", "(", "\n", "int", "(", "args", ".", "gpu", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "word_embedding", ".", "weight", ".", "data", ".", "set_", "(", "\n", "torch", ".", "FloatTensor", "(", "(", "np", ".", "zeros", "(", "(", "utils", ".", "get_num_words", "(", ")", "+", "1", ",", "args", ".", "word_dim", ")", ")", ")", ".", "astype", "(", "float", ")", ")", ")", "\n", "\n", "", "", "", "if", "args", ".", "train_embeddings", "==", "False", ":", "\n", "        ", "model", ".", "word_embedding", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n", "", "params", "=", "[", "p", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "params", "=", "params", ",", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "args", ".", "l2_coeff", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "scheduler", "=", "StepLR", "(", "optimizer", ",", "step_size", "=", "50", ",", "gamma", "=", "0.9", ")", "\n", "print", "(", "'Loading sets...'", ")", "\n", "dev_set", "=", "utils", ".", "get_split_data", "(", "split", "=", "'dev'", ")", "\n", "train_set", "=", "utils", ".", "get_split_data", "(", "split", "=", "'train'", ")", "\n", "train_set", "=", "train_set", "[", "0", ":", "int", "(", "len", "(", "train_set", ")", "/", "2", ")", "]", "\n", "print", "(", "'Train and dev sets loaded'", ")", "\n", "\n", "def", "train", "(", ")", ":", "\n", "        ", "prev_accuracy", "=", "0", "\n", "model", ".", "train", "(", ")", "\n", "for", "step", "in", "range", "(", "args", ".", "step_num", "+", "1", ")", ":", "\n", "            ", "random", ".", "shuffle", "(", "train_set", ")", "\n", "docs", "=", "train_set", "[", "0", ":", "args", ".", "batch_size", "]", "\n", "labels", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "d", "[", "'label'", "]", "for", "d", "in", "docs", "]", ")", ")", "\n", "doc_encodings", ",", "_", "=", "model", "(", "docs", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "doc_encodings", ".", "cpu", "(", ")", "\n", "loss", "=", "criterion", "(", "outputs", ",", "labels", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "print", "(", "\"Step {} Loss {}\"", ".", "format", "(", "step", ",", "loss", ".", "data", "[", "0", "]", ")", ")", "\n", "train_performance_log", ".", "write", "(", "\"{},{}\\n\"", ".", "format", "(", "step", ",", "loss", ".", "data", "[", "0", "]", ")", ")", "\n", "if", "step", "%", "20", "==", "0", "and", "step", ":", "\n", "                ", "accuracy", "=", "evaluation", "(", "step", ")", "\n", "if", "accuracy", ">=", "prev_accuracy", ":", "\n", "                    ", "torch", ".", "save", "(", "model", ",", "save_path", ")", "\n", "print", "(", "\"Best model saved in {} Accuracy {}\"", ".", "format", "(", "save_path", ",", "accuracy", ")", ")", "\n", "prev_accuracy", "=", "accuracy", "\n", "\n", "", "", "", "", "def", "evaluation", "(", "step", ")", ":", "\n", "        ", "print", "(", "'Start evaluation ...'", ")", "\n", "model", ".", "eval", "(", ")", "\n", "eval_labels", "=", "[", "d", "[", "'label'", "]", "for", "d", "in", "dev_set", "]", "\n", "labels", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "eval_labels", ")", ")", "\n", "doc_encodings", ",", "_", "=", "model", "(", "dev_set", ")", "\n", "outputs", "=", "doc_encodings", ".", "cpu", "(", ")", "\n", "loss", "=", "criterion", "(", "outputs", ",", "labels", ")", ".", "data", "[", "0", "]", "\n", "_", ",", "predictions", "=", "torch", ".", "max", "(", "outputs", ".", "data", ",", "1", ")", "\n", "predictions", "=", "predictions", ".", "numpy", "(", ")", "\n", "\n", "accuracy", "=", "accuracy_score", "(", "y_true", "=", "np", ".", "array", "(", "eval_labels", ")", ",", "y_pred", "=", "predictions", ")", "\n", "report", "=", "classification_report", "(", "y_true", "=", "np", ".", "array", "(", "eval_labels", ")", ",", "y_pred", "=", "predictions", ",", "target_names", "=", "[", "'Real'", ",", "'Fake'", "]", ")", "\n", "conf_matrix", "=", "confusion_matrix", "(", "y_true", "=", "np", ".", "array", "(", "eval_labels", ")", ",", "y_pred", "=", "predictions", ")", "\n", "eval_performance_log", ".", "write", "(", "\"Step {}, Loss {} Accuracy {} \\n\"", ".", "format", "(", "step", ",", "loss", ",", "accuracy", ")", ")", "\n", "eval_performance_log", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "report", ")", ")", "\n", "eval_performance_log", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "conf_matrix", ")", ")", "\n", "eval_performance_log", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "'='", "*", "50", ")", ")", "\n", "\n", "print", "(", "'************* Evaluation ****************'", ")", "\n", "print", "(", "\"Step {}, Loss {}  Accuracy {} \"", ".", "format", "(", "step", ",", "loss", ",", "accuracy", ")", ")", "\n", "print", "(", "report", ")", "\n", "print", "(", "conf_matrix", ")", "\n", "print", "(", "'*****************************************'", ")", "\n", "return", "accuracy", "\n", "\n", "", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.test.test": [[17, 85], ["os.path.exists", "torch.nn.CrossEntropyLoss", "utils.get_split_data", "print", "model.DependencyBLSTM.eval", "torch.autograd.Variable", "model.DependencyBLSTM.", "doc_encodings.cpu", "torch.max", "predictions.numpy.numpy", "sklearn.metrics.accuracy_score", "sklearn.metrics.classification_report", "sklearn.metrics.confusion_matrix", "open.write", "open.write", "open.write", "open.write", "print", "print", "print", "print", "print", "os.path.exists", "os.makedirs", "torch.load", "print", "print", "model.DependencyBLSTM", "os.path.exists", "open", "open", "model.DependencyBLSTM.cuda", "utils.get_word_embeddings", "torch.LongTensor", "len", "open", "pickle.dump", "model.DependencyBLSTM.word_embedding.weight.data.set_", "model.DependencyBLSTM.word_embedding.weight.data.set_", "model.DependencyBLSTM.word_embedding.weight.data.set_", "model.DependencyBLSTM.word_embedding.weight.data.set_", "nn.CrossEntropyLoss.", "numpy.array", "numpy.array", "numpy.array", "utils.get_num_words", "int", "torch.FloatTensor().cuda", "torch.FloatTensor", "torch.FloatTensor().cuda", "torch.FloatTensor", "int", "int", "numpy.zeros().astype", "torch.FloatTensor", "torch.FloatTensor", "numpy.zeros().astype", "numpy.zeros", "numpy.zeros", "utils.get_num_words", "utils.get_num_words"], "function", ["home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.get_split_data", "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.get_word_embeddings", "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.get_num_words", "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.get_num_words", "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.get_num_words"], ["def", "test", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "save_path", "=", "args", ".", "project_dir", "+", "'Models/'", "+", "args", ".", "sim_name", "+", "'/model.pt'", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "save_path", ")", ":", "\n", "        ", "model", "=", "torch", ".", "load", "(", "save_path", ")", "\n", "print", "(", "'Great!!! Pre-Trained Model Loaded !!!'", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'No pre-trained model '", ")", "\n", "model", "=", "DependencyBLSTM", "(", "num_words", "=", "utils", ".", "get_num_words", "(", ")", ",", "max_sen_length", "=", "97", ",", "max_doc_sent_length", "=", "326", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "'test_performance_log.txt'", ")", ":", "\n", "        ", "test_performance_log", "=", "open", "(", "output_dir", "+", "'test_performance_log.txt'", ",", "'w'", ")", "\n", "", "else", ":", "\n", "        ", "test_performance_log", "=", "open", "(", "output_dir", "+", "'test_performance_log.txt'", ",", "'a'", ")", "\n", "\n", "", "if", "args", ".", "gpu", ">", "-", "1", ":", "\n", "        ", "model", ".", "cuda", "(", "device", "=", "int", "(", "args", ".", "gpu", ")", ")", "\n", "", "if", "args", ".", "fill_embedding", ":", "\n", "        ", "embed", "=", "utils", ".", "get_word_embeddings", "(", "source", "=", "'google'", ")", "\n", "if", "args", ".", "gpu", ">", "-", "1", ":", "\n", "            ", "model", ".", "word_embedding", ".", "weight", ".", "data", ".", "set_", "(", "torch", ".", "FloatTensor", "(", "(", "embed", ")", ")", ".", "cuda", "(", "int", "(", "args", ".", "gpu", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "model", ".", "word_embedding", ".", "weight", ".", "data", ".", "set_", "(", "torch", ".", "FloatTensor", "(", "(", "embed", ")", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "args", ".", "gpu", ">", "-", "1", ":", "\n", "            ", "model", ".", "word_embedding", ".", "weight", ".", "data", ".", "set_", "(", "\n", "torch", ".", "FloatTensor", "(", "(", "np", ".", "zeros", "(", "(", "utils", ".", "get_num_words", "(", ")", "+", "1", ",", "args", ".", "word_dim", ")", ")", ".", "astype", "(", ")", ")", ")", ".", "cuda", "(", "int", "(", "args", ".", "gpu", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "model", ".", "word_embedding", ".", "weight", ".", "data", ".", "set_", "(", "\n", "torch", ".", "FloatTensor", "(", "(", "np", ".", "zeros", "(", "(", "utils", ".", "get_num_words", "(", ")", "+", "1", ",", "args", ".", "word_dim", ")", ")", ")", ".", "astype", "(", "float", ")", ")", ")", "\n", "\n", "", "", "if", "args", ".", "train_embeddings", "==", "False", ":", "\n", "        ", "model", ".", "word_embedding", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n", "", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "test_set", "=", "utils", ".", "get_split_data", "(", "split", "=", "'test'", ")", "\n", "print", "(", "'Start Test ...'", ")", "\n", "model", ".", "eval", "(", ")", "\n", "test_labels", "=", "[", "d", "[", "'label'", "]", "for", "d", "in", "test_set", "]", "\n", "labels", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "test_labels", ")", ")", "\n", "\n", "lengths", "=", "[", "len", "(", "doc", "[", "'word_indices'", "]", ")", "for", "doc", "in", "test_set", "]", "\n", "doc_encodings", ",", "all_doc_doc_dependency_tree_info", "=", "model", "(", "test_set", ")", "\n", "\n", "outputs", "=", "doc_encodings", ".", "cpu", "(", ")", "\n", "loss", "=", "criterion", "(", "outputs", ",", "labels", ")", ".", "data", "[", "0", "]", "\n", "_", ",", "predictions", "=", "torch", ".", "max", "(", "outputs", ".", "data", ",", "1", ")", "\n", "predictions", "=", "predictions", ".", "numpy", "(", ")", "\n", "\n", "with", "open", "(", "output_dir", "+", "\"matrix.pkl\"", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "[", "lengths", ",", "all_doc_doc_dependency_tree_info", ",", "test_labels", "]", ",", "f", ")", "\n", "\n", "", "accuracy", "=", "accuracy_score", "(", "y_true", "=", "np", ".", "array", "(", "test_labels", ")", ",", "y_pred", "=", "predictions", ")", "\n", "report", "=", "classification_report", "(", "y_true", "=", "np", ".", "array", "(", "test_labels", ")", ",", "y_pred", "=", "predictions", ",", "target_names", "=", "[", "'Real'", ",", "'Fake'", "]", ")", "\n", "conf_matrix", "=", "confusion_matrix", "(", "y_true", "=", "np", ".", "array", "(", "test_labels", ")", ",", "y_pred", "=", "predictions", ")", "\n", "test_performance_log", ".", "write", "(", "\" Loss {} Accuracy {} \\n\"", ".", "format", "(", "loss", ",", "accuracy", ")", ")", "\n", "test_performance_log", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "report", ")", ")", "\n", "test_performance_log", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "conf_matrix", ")", ")", "\n", "test_performance_log", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "'='", "*", "50", ")", ")", "\n", "\n", "print", "(", "'************* Test ****************'", ")", "\n", "print", "(", "\"Loss {}  Accuracy {} \"", ".", "format", "(", "loss", ",", "accuracy", ")", ")", "\n", "print", "(", "report", ")", "\n", "print", "(", "conf_matrix", ")", "\n", "print", "(", "'*****************************************'", ")", "\n", "return", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.model.DependencyBLSTM.__init__": [[8, 48], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Embedding", "torch.Embedding", "torch.Softmax", "torch.Softmax", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "utils.wrap_with_variable", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Dropout", "torch.Dropout", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Dropout", "torch.Dropout", "int", "int", "int", "int", "numpy.zeros", "int"], "methods", ["home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.myTree.__init__", "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.wrap_with_variable"], ["    ", "def", "__init__", "(", "self", ",", "num_words", ",", "max_sen_length", ",", "max_doc_sent_length", ")", ":", "\n", "        ", "super", "(", "DependencyBLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "max_sen_length", "=", "max_sen_length", "\n", "self", ".", "max_doc_sent_length", "=", "max_doc_sent_length", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "args", ".", "dropout", ")", "\n", "self", ".", "word_embedding", "=", "nn", ".", "Embedding", "(", "num_embeddings", "=", "num_words", ",", "embedding_dim", "=", "args", ".", "word_dim", ")", "\n", "self", ".", "Softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "0", ")", "\n", "############################# Sentence level Functions #######################################", "\n", "\n", "self", ".", "forwardLSTM_sent", "=", "nn", ".", "LSTM", "(", "num_layers", "=", "1", ",", "input_size", "=", "args", ".", "word_dim", ",", "\n", "dropout", "=", "args", ".", "dropout", ",", "\n", "hidden_size", "=", "int", "(", "args", ".", "blstm_hidden_unit_dim", ")", ",", "\n", "batch_first", "=", "True", ")", "\n", "self", ".", "backwardLSTM_sent", "=", "nn", ".", "LSTM", "(", "num_layers", "=", "1", ",", "input_size", "=", "args", ".", "word_dim", ",", "\n", "dropout", "=", "args", ".", "dropout", ",", "\n", "hidden_size", "=", "args", ".", "blstm_hidden_unit_dim", ",", "\n", "batch_first", "=", "True", ")", "\n", "self", ".", "sentence_encoder", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "args", ".", "word_dim", ",", "args", ".", "blstm_hidden_unit_dim", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", ")", ",", "nn", ".", "Dropout", "(", "p", "=", "args", ".", "dropout", ")", ")", "\n", "############################# Doc level Functions #######################################", "\n", "\n", "self", ".", "parent_encoder_doc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "args", ".", "blstm_hidden_unit_dim", ",", "int", "(", "args", ".", "blstm_hidden_unit_dim", ")", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", ")", ",", "nn", ".", "Dropout", "(", "p", "=", "args", ".", "dropout", ")", ")", "\n", "self", ".", "child_encoder_doc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "args", ".", "blstm_hidden_unit_dim", ",", "int", "(", "args", ".", "blstm_hidden_unit_dim", ")", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", ")", ",", "nn", ".", "Dropout", "(", "p", "=", "args", ".", "dropout", ")", ")", "\n", "\n", "\n", "self", ".", "root_score_encoder_doc", "=", "nn", ".", "Linear", "(", "args", ".", "blstm_hidden_unit_dim", ",", "1", ")", "\n", "self", ".", "root_embed_doc", "=", "utils", ".", "wrap_with_variable", "(", "torch", ".", "FloatTensor", "(", "np", ".", "zeros", "(", "shape", "=", "(", "args", ".", "blstm_hidden_unit_dim", ")", ")", ")", ",", "\n", "gpu", "=", "args", ".", "gpu", ",", "\n", "requires_grad", "=", "True", ")", "\n", "self", ".", "r_embeds_doc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "3", "*", "args", ".", "blstm_hidden_unit_dim", ",", "\n", "int", "(", "args", ".", "blstm_hidden_unit_dim", ")", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", ")", ",", "nn", ".", "Dropout", "(", "p", "=", "args", ".", "dropout", ")", ")", "\n", "\n", "self", ".", "final_binary_classifier", "=", "nn", ".", "Linear", "(", "int", "(", "args", ".", "blstm_hidden_unit_dim", ")", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.model.DependencyBLSTM.create_sentence_batches": [[49, 84], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "all_doc_batches.append", "all_doc_batches_inverse.append", "all_doc_seq_lengths.append", "utils.wrap_with_variable", "model.DependencyBLSTM.word_embedding", "model.DependencyBLSTM.dropout", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "utils.wrap_with_variable", "torch.stack.append", "torch.stack.append", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "model.DependencyBLSTM.data.index_select", "utils.wrap_with_variable", "torch.stack.append", "torch.stack.append", "seq_lengths.append", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "len", "numpy.array().astype", "len", "range", "len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "numpy.array", "model.DependencyBLSTM.data.size"], "methods", ["home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.wrap_with_variable", "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.wrap_with_variable", "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.wrap_with_variable"], ["", "def", "create_sentence_batches", "(", "self", ",", "docs", ")", ":", "\n", "        ", "all_doc_batches", "=", "[", "]", "\n", "all_doc_batches_inverse", "=", "[", "]", "\n", "all_doc_seq_lengths", "=", "[", "]", "\n", "for", "doc", "in", "docs", ":", "\n", "            ", "doc_sent_embed", ",", "doc_sent_embed_inverse", "=", "[", "]", ",", "[", "]", "\n", "seq_lengths", "=", "[", "]", "\n", "for", "sent_word_indices", "in", "doc", "[", "'word_indices'", "]", ":", "\n", "                ", "j", "=", "utils", ".", "wrap_with_variable", "(", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "sent_word_indices", ")", ".", "astype", "(", "int", ")", ")", ",", "gpu", "=", "args", ".", "gpu", ",", "requires_grad", "=", "False", ")", "\n", "\n", "word_embed", "=", "self", ".", "word_embedding", "(", "j", ")", "\n", "word_embed", "=", "self", ".", "dropout", "(", "word_embed", ")", "\n", "X", "=", "torch", ".", "zeros", "(", "self", ".", "max_sen_length", ",", "args", ".", "word_dim", ")", "\n", "X", "[", "0", ":", "len", "(", "sent_word_indices", ")", "]", "=", "word_embed", ".", "data", "\n", "X", "=", "utils", ".", "wrap_with_variable", "(", "X", ",", "gpu", "=", "args", ".", "gpu", ",", "requires_grad", "=", "True", ")", "\n", "doc_sent_embed", ".", "append", "(", "X", ")", "\n", "\n", "idx", "=", "[", "i", "for", "i", "in", "range", "(", "word_embed", ".", "data", ".", "size", "(", "0", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", "]", "\n", "if", "args", ".", "gpu", ">", "-", "1", ":", "\n", "                    ", "idx", "=", "torch", ".", "LongTensor", "(", "idx", ")", ".", "cuda", "(", "args", ".", "gpu", ")", "\n", "", "else", ":", "\n", "                    ", "idx", "=", "torch", ".", "LongTensor", "(", "idx", ")", "\n", "", "X_inverse", "=", "torch", ".", "zeros", "(", "self", ".", "max_sen_length", ",", "args", ".", "word_dim", ")", "\n", "X_inverse", "[", "0", ":", "len", "(", "sent_word_indices", ")", "]", "=", "word_embed", ".", "data", ".", "index_select", "(", "0", ",", "idx", ")", "\n", "X_inverse", "=", "utils", ".", "wrap_with_variable", "(", "X_inverse", ",", "gpu", "=", "args", ".", "gpu", ",", "requires_grad", "=", "True", ")", "\n", "doc_sent_embed_inverse", ".", "append", "(", "X_inverse", ")", "\n", "\n", "seq_lengths", ".", "append", "(", "len", "(", "sent_word_indices", ")", ")", "\n", "\n", "", "doc_sent_embed", "=", "torch", ".", "stack", "(", "doc_sent_embed", ")", "\n", "doc_sent_embed_inverse", "=", "torch", ".", "stack", "(", "doc_sent_embed_inverse", ")", "\n", "all_doc_batches", ".", "append", "(", "doc_sent_embed", ")", "\n", "all_doc_batches_inverse", ".", "append", "(", "doc_sent_embed_inverse", ")", "\n", "all_doc_seq_lengths", ".", "append", "(", "seq_lengths", ")", "\n", "", "return", "all_doc_batches", ",", "all_doc_batches_inverse", ",", "all_doc_seq_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.model.DependencyBLSTM.get_sentence_encodings": [[85, 107], ["zip", "model.DependencyBLSTM.forwardLSTM_sent", "model.DependencyBLSTM.backwardLSTM_sent", "zip", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "all_doc_sentence_encodings.append", "utils.wrap_with_variable", "model.DependencyBLSTM.sentence_encoder", "torch.stack.append", "torch.stack.append", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "sent_backward.data.index_select", "range", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.wrap_with_variable"], ["", "def", "get_sentence_encodings", "(", "self", ",", "all_doc_batches", ",", "all_doc_batches_inverse", ",", "all_doc_seq_lengths", ")", ":", "\n", "        ", "all_doc_sentence_encodings", "=", "[", "]", "\n", "for", "doc_batch", ",", "doc_batch_inverse", ",", "doc_seq_length", "in", "zip", "(", "all_doc_batches", ",", "all_doc_batches_inverse", ",", "\n", "all_doc_seq_lengths", ")", ":", "\n", "            ", "doc_sentence_encodings", "=", "[", "]", "\n", "\n", "fwrd_outputs", ",", "_", "=", "self", ".", "forwardLSTM_sent", "(", "doc_batch", ")", "\n", "bwrd_outputs", ",", "_", "=", "self", ".", "backwardLSTM_sent", "(", "doc_batch_inverse", ")", "\n", "for", "sent_forward", ",", "sent_backward", ",", "l", "in", "zip", "(", "doc_batch", ",", "doc_batch_inverse", ",", "doc_seq_length", ")", ":", "\n", "                ", "idx", "=", "[", "i", "for", "i", "in", "range", "(", "l", "-", "1", ",", "-", "1", ",", "-", "1", ")", "]", "\n", "if", "args", ".", "gpu", ">", "-", "1", ":", "\n", "                    ", "idx", "=", "torch", ".", "LongTensor", "(", "idx", ")", ".", "cuda", "(", "args", ".", "gpu", ")", "\n", "", "else", ":", "\n", "                    ", "idx", "=", "torch", ".", "LongTensor", "(", "idx", ")", "\n", "", "bwrd_outputs_inverse", "=", "utils", ".", "wrap_with_variable", "(", "sent_backward", ".", "data", ".", "index_select", "(", "0", ",", "idx", ")", ",", "gpu", "=", "args", ".", "gpu", ",", "\n", "requires_grad", "=", "True", ")", "\n", "\n", "h", "=", "self", ".", "sentence_encoder", "(", "0.5", "*", "(", "sent_forward", "[", "l", "-", "1", "]", "+", "bwrd_outputs_inverse", "[", "l", "-", "1", "]", ")", ")", "\n", "doc_sentence_encodings", ".", "append", "(", "h", ")", "\n", "", "doc_sentence_encodings", "=", "torch", ".", "stack", "(", "doc_sentence_encodings", ")", "\n", "all_doc_sentence_encodings", ".", "append", "(", "doc_sentence_encodings", ")", "\n", "", "return", "all_doc_sentence_encodings", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.model.DependencyBLSTM.forward": [[108, 153], ["model.DependencyBLSTM.create_sentence_batches", "model.DependencyBLSTM.get_sentence_encodings", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "model.DependencyBLSTM.final_binary_classifier", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "model.DependencyBLSTM.view", "model.DependencyBLSTM.Softmax", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "model.DependencyBLSTM.Softmax", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.stack.append", "torch.stack.append", "all_doc_doc_dependency_tree_info.append", "len", "model.DependencyBLSTM.append", "range", "len", "len", "len", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.stack.append", "torch.stack.append", "model.DependencyBLSTM.root_score_encoder_doc", "len", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "model.DependencyBLSTM.append", "len", "torch.sum.append", "torch.sum.append", "torch.sum.append", "torch.sum.append", "model.DependencyBLSTM.r_embeds_doc", "model.DependencyBLSTM.append", "model.DependencyBLSTM.parent_encoder_doc", "model.DependencyBLSTM.child_encoder_doc", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "utils.wrap_with_variable", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.model.DependencyBLSTM.create_sentence_batches", "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.model.DependencyBLSTM.get_sentence_encodings", "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.wrap_with_variable"], ["", "def", "forward", "(", "self", ",", "docs", ")", ":", "\n", "        ", "all_doc_batches", ",", "all_doc_batches_inverse", ",", "all_doc_seq_lengths", "=", "self", ".", "create_sentence_batches", "(", "docs", ")", "\n", "all_doc_sentence_encodings", "=", "self", ".", "get_sentence_encodings", "(", "all_doc_batches", ",", "all_doc_batches_inverse", ",", "\n", "all_doc_seq_lengths", ")", "\n", "all_doc_doc_dependency_tree_info", "=", "[", "]", "\n", "all_final_features", "=", "[", "]", "\n", "for", "sentence_encodings", "in", "all_doc_sentence_encodings", ":", "\n", "            ", "fri", "=", "[", "]", "\n", "Aij", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "sentence_encodings", ")", ")", ":", "\n", "                ", "fri", ".", "append", "(", "self", ".", "root_score_encoder_doc", "(", "sentence_encodings", "[", "i", "]", ")", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "sentence_encodings", ")", ")", ":", "\n", "                    ", "if", "i", "==", "j", ":", "\n", "                        ", "Aij", ".", "append", "(", "utils", ".", "wrap_with_variable", "(", "torch", ".", "tensor", "(", "-", "9999999.000", ")", ",", "gpu", "=", "args", ".", "gpu", ",", "requires_grad", "=", "True", ")", ")", "\n", "continue", "\n", "\n", "", "x", "=", "torch", ".", "dot", "(", "self", ".", "parent_encoder_doc", "(", "sentence_encodings", "[", "i", "]", ")", ",", "\n", "self", ".", "child_encoder_doc", "(", "sentence_encodings", "[", "j", "]", ")", ")", "\n", "Aij", ".", "append", "(", "x", ")", "\n", "", "", "Aij", "=", "torch", ".", "stack", "(", "Aij", ")", "\n", "Aij", "=", "Aij", ".", "view", "(", "len", "(", "sentence_encodings", ")", ",", "len", "(", "sentence_encodings", ")", ")", "\n", "Aij", "=", "self", ".", "Softmax", "(", "Aij", ")", "\n", "fri", "=", "torch", ".", "stack", "(", "fri", ")", "\n", "fri", "=", "self", ".", "Softmax", "(", "fri", ")", "\n", "ri", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "sentence_encodings", ")", ")", ":", "\n", "                ", "tmp", "=", "[", "]", "\n", "tmp3", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "len", "(", "sentence_encodings", ")", ")", ":", "\n", "                    ", "tmp", ".", "append", "(", "torch", ".", "mul", "(", "Aij", "[", "k", ",", "i", "]", ",", "sentence_encodings", "[", "k", "]", ")", ")", "\n", "tmp3", ".", "append", "(", "torch", ".", "mul", "(", "Aij", "[", "i", ",", "k", "]", ",", "sentence_encodings", "[", "i", "]", ")", ")", "\n", "", "tmp3", "=", "torch", ".", "stack", "(", "tmp3", ")", "\n", "tmp3", "=", "torch", ".", "sum", "(", "tmp3", ",", "0", ")", "\n", "tmp", "=", "torch", ".", "stack", "(", "tmp", ")", "\n", "tmp", "=", "torch", ".", "sum", "(", "tmp", ",", "0", ")", "\n", "tmp2", "=", "torch", ".", "mul", "(", "fri", "[", "i", "]", ",", "self", ".", "root_embed_doc", ")", "\n", "ri", ".", "append", "(", "self", ".", "r_embeds_doc", "(", "torch", ".", "cat", "(", "(", "sentence_encodings", "[", "i", "]", ",", "tmp", "+", "tmp2", ",", "tmp3", ")", ")", ")", ")", "\n", "", "ri", "=", "torch", ".", "stack", "(", "ri", ")", "\n", "final_feature", "=", "torch", ".", "mean", "(", "ri", ",", "0", ")", "\n", "all_final_features", ".", "append", "(", "final_feature", ")", "\n", "all_doc_doc_dependency_tree_info", ".", "append", "(", "[", "Aij", ".", "data", ",", "fri", ".", "data", "]", ")", "\n", "\n", "", "all_final_features", "=", "torch", ".", "stack", "(", "all_final_features", ")", "\n", "output", "=", "self", ".", "final_binary_classifier", "(", "all_final_features", ")", "\n", "return", "output", ",", "all_doc_doc_dependency_tree_info", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.myTree.__init__": [[14, 25], ["utils.myTree.add_child"], "methods", ["home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.myTree.add_child"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'Node'", ",", "children", "=", "None", ",", "data", "=", "None", ",", "parent", "=", "None", ")", ":", "\n", "        ", "self", ".", "parent", "=", "parent", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "index", "=", "-", "1", "\n", "self", ".", "children", "=", "[", "]", "\n", "self", ".", "data", "=", "data", "\n", "self", ".", "characters", "=", "[", "]", "\n", "self", ".", "parent_relation_index", "=", "-", "1", "\n", "if", "children", "is", "not", "None", ":", "\n", "            ", "for", "child", "in", "children", ":", "\n", "                ", "self", ".", "add_child", "(", "child", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.myTree.__repr__": [[26, 28], ["None"], "methods", ["None"], ["", "", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.myTree.add_child": [[29, 32], ["isinstance", "utils.myTree.children.append"], "methods", ["None"], ["", "def", "add_child", "(", "self", ",", "node", ")", ":", "\n", "        ", "assert", "isinstance", "(", "node", ",", "myTree", ")", "\n", "self", ".", "children", ".", "append", "(", "node", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.myTree.__str__": [[33, 39], ["len"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "children", ")", "==", "0", ":", "\n", "            ", "x", "=", "'NONE'", "\n", "", "else", ":", "\n", "            ", "x", "=", "[", "a", ".", "name", "for", "a", "in", "self", ".", "children", "]", "\n", "", "return", "\"{} Children:{}\"", ".", "format", "(", "self", ".", "name", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.myTree.__getitem__": [[40, 42], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "self", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.get_leaves": [[44, 52], ["len", "leaves.append", "leaves.extend", "utils.get_leaves"], "function", ["home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.get_leaves"], ["", "", "def", "get_leaves", "(", "node", ")", ":", "\n", "    ", "leaves", "=", "[", "]", "\n", "if", "len", "(", "node", ".", "children", ")", "==", "0", ":", "\n", "        ", "leaves", ".", "append", "(", "node", ")", "\n", "", "else", ":", "\n", "        ", "for", "child", "in", "node", ".", "children", ":", "\n", "            ", "leaves", ".", "extend", "(", "get_leaves", "(", "child", ")", ")", "\n", "", "", "return", "leaves", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.get_preorder": [[54, 60], ["X.append", "len", "X.append", "utils.get_preorder"], "function", ["home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.get_preorder"], ["", "def", "get_preorder", "(", "tree", ",", "X", ")", ":", "\n", "    ", "X", ".", "append", "(", "(", "tree", ".", "name", ")", ")", "\n", "if", "len", "(", "tree", ".", "children", ")", "==", "0", ":", "\n", "        ", "return", "\n", "", "for", "t", "in", "tree", ".", "children", ":", "\n", "        ", "X", ".", "append", "(", "get_preorder", "(", "t", ",", "X", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.wrap_with_variable": [[64, 69], ["torch.autograd.Variable", "torch.autograd.Variable", "tensor.cuda"], "function", ["None"], ["", "", "def", "wrap_with_variable", "(", "tensor", ",", "gpu", ",", "requires_grad", "=", "True", ")", ":", "\n", "    ", "if", "gpu", ">", "-", "1", ":", "\n", "        ", "return", "Variable", "(", "tensor", ".", "cuda", "(", "gpu", ")", ",", "requires_grad", "=", "requires_grad", ")", "\n", "", "else", ":", "\n", "        ", "return", "Variable", "(", "tensor", ",", "requires_grad", "=", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.get_word_embeddings": [[71, 75], ["open", "pickle.load"], "function", ["None"], ["", "", "def", "get_word_embeddings", "(", "source", "=", "'google'", ")", ":", "\n", "    ", "with", "open", "(", "args", ".", "project_dir", "+", "'Data/word_emb_'", "+", "source", "+", "'.pkl'", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "embed", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "return", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.creat_word_embedding": [[77, 99], ["os.path.exists", "print", "gensim.KeyedVectors.load_word2vec_format", "pandas.read_csv", "numpy.zeros", "print", "os.path.exists", "print", "exit", "numpy.random.rand", "open", "pickle.dump", "non_exist_words.append", "len", "numpy.random.rand", "len"], "function", ["None"], ["", "def", "creat_word_embedding", "(", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "project_dir", "+", "'Data/word_emb_google.pkl'", ")", ":", "\n", "        ", "return", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "project_dir", "+", "'GoogleNews-vectors-negative300.bin'", ")", ":", "\n", "        ", "print", "(", "\"Please download https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit and place it in\"", ".", "format", "(", "args", ".", "project_dir", ")", ")", "\n", "exit", "(", "-", "1", ")", "\n", "", "print", "(", "'Creating word embeddings ...'", ")", "\n", "model", "=", "word2vec", ".", "KeyedVectors", ".", "load_word2vec_format", "(", "args", ".", "project_dir", "+", "'GoogleNews-vectors-negative300.bin'", ",", "\n", "binary", "=", "True", ")", "\n", "all_words", "=", "pd", ".", "read_csv", "(", "args", ".", "project_dir", "+", "\"Data/words.csv\"", ",", "names", "=", "[", "'Index'", ",", "'Word'", ",", "'Freq'", "]", ")", "\n", "word_embeddings", "=", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "all_words", ")", "+", "1", ",", "args", ".", "word_dim", ")", ")", "\n", "non_exist_words", "=", "[", "]", "\n", "for", "w", "in", "all_words", ".", "values", ":", "\n", "        ", "if", "(", "w", "[", "1", "]", "in", "model", ")", ":", "\n", "            ", "word_embeddings", "[", "w", "[", "0", "]", "]", "=", "model", "[", "w", "[", "1", "]", "]", "\n", "", "else", ":", "\n", "            ", "word_embeddings", "[", "w", "[", "0", "]", "]", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "args", ".", "word_dim", ")", "[", "0", "]", "\n", "non_exist_words", ".", "append", "(", "w", "[", "1", "]", ")", "\n", "", "", "word_embeddings", "[", "len", "(", "all_words", ")", "]", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "args", ".", "word_dim", ")", "[", "0", "]", "\n", "with", "open", "(", "args", ".", "project_dir", "+", "'Data/word_emb_google.pkl'", ",", "'wb'", ")", "as", "pkl", ":", "\n", "        ", "pickle", ".", "dump", "(", "word_embeddings", ",", "pkl", ")", "\n", "", "print", "(", "'Word embedding file created and save in {}'", ".", "format", "(", "args", ".", "project_dir", "+", "'Data/word_emb_google.pkl'", ")", ")", "\n", "#print(non_exist_words, len(non_exist_words))", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.get_split_data": [[102, 118], ["open", "f.read().splitlines", "record.split", "open", "f.read().splitlines", "documents.append", "f.read", "w.split", "f.read", "record.split"], "function", ["None"], ["", "def", "get_split_data", "(", "split", "=", "'train'", ")", ":", "\n", "    ", "documents", "=", "[", "]", "\n", "with", "open", "(", "args", ".", "project_dir", "+", "'Splits/'", "+", "split", "+", "'.split.csv'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "records", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "", "for", "record", "in", "records", ":", "\n", "        ", "label", "=", "record", ".", "split", "(", "','", ")", "[", "-", "1", "]", "\n", "if", "label", "==", "'Fake'", ":", "\n", "            ", "l", "=", "1", "\n", "", "else", ":", "\n", "            ", "l", "=", "0", "\n", "", "with", "open", "(", "args", ".", "project_dir", "+", "'Data/'", "+", "record", ".", "split", "(", "','", ")", "[", "1", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "word_indices", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "word_indices", "=", "[", "w", ".", "split", "(", "','", ")", "for", "w", "in", "word_indices", "]", "\n", "documents", ".", "append", "(", "{", "\"word_indices\"", ":", "word_indices", ",", "'label'", ":", "l", "}", ")", "\n", "", "", "return", "documents", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.get_num_words": [[120, 123], ["pandas.read_csv", "len"], "function", ["None"], ["", "def", "get_num_words", "(", ")", ":", "\n", "    ", "all_words", "=", "pd", ".", "read_csv", "(", "args", ".", "project_dir", "+", "\"Data/words.csv\"", ",", "names", "=", "[", "'Index'", ",", "'Word'", ",", "'Freq'", "]", ")", "\n", "return", "len", "(", "all_words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.construct_dependecy_tree": [[125, 162], ["numpy.argmax", "utils.myTree", "trees.append", "current_nodes.append", "numpy.array", "enumerate", "utils.myTree", "numpy.abs", "trees[].add_child", "trees.append", "current_nodes.append", "numpy.array", "str", "numpy.argmax", "len", "len", "range", "str", "str", "int", "int", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.myTree.add_child"], ["", "def", "construct_dependecy_tree", "(", "matrixp", ",", "rootp", ")", ":", "\n", "    ", "trees", "=", "[", "]", "\n", "root_index", "=", "np", ".", "argmax", "(", "rootp", ")", "\n", "root", "=", "myTree", "(", "name", "=", "str", "(", "root_index", ")", ")", "\n", "trees", ".", "append", "(", "root", ")", "\n", "current_nodes", "=", "[", "]", "\n", "current_nodes", ".", "append", "(", "root_index", ")", "\n", "matrixp", "[", ":", ",", "root_index", "]", "=", "np", ".", "array", "(", "[", "-", "1", "for", "_", "in", "range", "(", "len", "(", "rootp", ")", ")", "]", ")", "\n", "flag", "=", "True", "\n", "child_parent_diff", "=", "0", "\n", "while", "flag", ":", "\n", "        ", "currmax", "=", "-", "99", "\n", "father", "=", "-", "1", "\n", "child", "=", "-", "1", "\n", "for", "c", "in", "current_nodes", ":", "\n", "            ", "m", "=", "np", ".", "argmax", "(", "matrixp", "[", "c", ",", ":", "]", ")", "\n", "if", "matrixp", "[", "c", ",", "m", "]", ">", "currmax", ":", "\n", "                ", "currmax", "=", "matrixp", "[", "c", ",", "m", "]", "\n", "father", "=", "c", "\n", "child", "=", "m", "\n", "\n", "", "", "father_index_in_the_list", "=", "-", "1", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "trees", ")", ":", "\n", "            ", "if", "t", ".", "name", "==", "str", "(", "father", ")", ":", "\n", "                ", "father_index_in_the_list", "=", "i", "\n", "break", "\n", "", "", "node", "=", "myTree", "(", "name", "=", "str", "(", "child", ")", ")", "\n", "child_parent_diff", "+=", "np", ".", "abs", "(", "int", "(", "child", ")", "-", "int", "(", "trees", "[", "father_index_in_the_list", "]", ".", "name", ")", ")", "\n", "node", ".", "parent", "=", "trees", "[", "father_index_in_the_list", "]", "\n", "trees", "[", "father_index_in_the_list", "]", ".", "add_child", "(", "node", ")", "\n", "trees", "[", "father_index_in_the_list", "]", ".", "data", "=", "currmax", "\n", "trees", ".", "append", "(", "node", ")", "\n", "current_nodes", ".", "append", "(", "child", ")", "\n", "matrixp", "[", ":", ",", "child", "]", "=", "np", ".", "array", "(", "[", "-", "1", "for", "_", "in", "range", "(", "len", "(", "rootp", ")", ")", "]", ")", "\n", "if", "len", "(", "current_nodes", ")", "==", "len", "(", "rootp", ")", ":", "\n", "            ", "flag", "=", "False", "\n", "", "", "return", "trees", "[", "0", "]", ",", "child_parent_diff", "\n", "\n"]], "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.dependecy_tree_stat": [[164, 196], ["enumerate", "numpy.array", "numpy.array", "open", "pickle.load", "zip", "utils.construct_dependecy_tree", "utils.get_preorder", "enumerate", "utils.get_leaves", "a[].numpy", "a[].numpy", "numpy.abs", "np.array.append", "np.array.append", "Y.append", "int", "len", "len", "len", "numpy.log10", "numpy.log10", "numpy.log10", "len", "numpy.log10", "numpy.log10", "numpy.log10", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.construct_dependecy_tree", "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.get_preorder", "home.repos.pwc.inspect_result.hamidkarimi_HDSF.None.utils.get_leaves"], ["", "def", "dependecy_tree_stat", "(", "dir", ")", ":", "\n", "    ", "with", "open", "(", "dir", "+", "'matrix.pkl'", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "x", "=", "pickle", ".", "load", "(", "f", ")", "\n", "lengths", ",", "all_doc_doc_dependency_tree_info", ",", "labels", "=", "x", "[", "0", "]", ",", "x", "[", "1", "]", ",", "x", "[", "2", "]", "\n", "pijs", "=", "[", "a", "[", "0", "]", ".", "numpy", "(", ")", "for", "a", "in", "all_doc_doc_dependency_tree_info", "]", "\n", "piroots", "=", "[", "a", "[", "1", "]", ".", "numpy", "(", ")", "for", "a", "in", "all_doc_doc_dependency_tree_info", "]", "\n", "", "fake_doc_stat", "=", "[", "]", "\n", "real_doc_stat", "=", "[", "]", "\n", "for", "index", ",", "(", "matrixp", ",", "rootp", ",", "label", ")", "in", "enumerate", "(", "zip", "(", "pijs", ",", "piroots", ",", "labels", ")", ")", ":", "\n", "        ", "tree", ",", "child_parent_diff", "=", "construct_dependecy_tree", "(", "matrixp", ",", "rootp", ")", "\n", "X", "=", "[", "]", "\n", "get_preorder", "(", "tree", ",", "X", ")", "\n", "Y", "=", "[", "]", "\n", "for", "ss", "in", "X", ":", "\n", "            ", "if", "ss", "is", "not", "None", ":", "\n", "                ", "Y", ".", "append", "(", "int", "(", "ss", ")", ")", "\n", "", "", "preorder_diff", "=", "0", "\n", "for", "i", ",", "n", "in", "enumerate", "(", "Y", ")", ":", "\n", "            ", "preorder_diff", "+=", "np", ".", "abs", "(", "i", "+", "1", "-", "n", ")", "\n", "", "leaves", "=", "get_leaves", "(", "tree", ")", "\n", "if", "label", "==", "1", ":", "\n", "            ", "fake_doc_stat", ".", "append", "(", "[", "label", ",", "len", "(", "matrixp", ")", ",", "len", "(", "leaves", ")", "/", "(", "np", ".", "log10", "(", "len", "(", "matrixp", ")", ")", ")", ",", "\n", "child_parent_diff", "/", "(", "np", ".", "log10", "(", "len", "(", "matrixp", ")", ")", ")", ",", "\n", "preorder_diff", "/", "(", "np", ".", "log10", "(", "len", "(", "matrixp", ")", ")", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "real_doc_stat", ".", "append", "(", "[", "label", ",", "len", "(", "matrixp", ")", ",", "len", "(", "leaves", ")", "/", "(", "np", ".", "log10", "(", "len", "(", "matrixp", ")", ")", ")", ",", "\n", "child_parent_diff", "/", "(", "np", ".", "log10", "(", "len", "(", "matrixp", ")", ")", ")", ",", "\n", "preorder_diff", "/", "(", "np", ".", "log10", "(", "len", "(", "matrixp", ")", ")", ")", "]", ")", "\n", "\n", "", "", "fake_doc_stat", "=", "np", ".", "array", "(", "fake_doc_stat", ")", "\n", "real_doc_stat", "=", "np", ".", "array", "(", "real_doc_stat", ")", "\n", "return", "fake_doc_stat", ",", "real_doc_stat", "\n", "\n"]]}