{"home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.Recipe1M.__init__": [[102, 151], ["os.path.join", "pickle.load", "pickle.load", "enumerate", "os.path.join", "open", "open", "lmdb.open", "data_loader.Recipe1M.ids.append", "data_loader.Recipe1M.ingrs_vocab.remove_eos", "numpy.array", "os.path.join", "os.path.join", "os.path.join", "len", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.Vocabulary.remove_eos"], ["    ", "def", "__init__", "(", "self", ",", "\n", "data_dir", ",", "\n", "split", ",", "\n", "maxnumims", ",", "\n", "transform", "=", "None", ",", "\n", "use_lmdb", "=", "False", ",", "\n", "suff", "=", "''", ",", "\n", "shuffle", "=", "False", ",", "\n", "perm", "=", "None", ",", "\n", "include_eos", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "aux_data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'preprocessed'", ")", "\n", "self", ".", "ingrs_vocab", "=", "pickle", ".", "load", "(", "\n", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "aux_data_dir", ",", "suff", "+", "'recipe1m_vocab_ingrs.pkl'", ")", ",", "'rb'", ")", ")", "\n", "\n", "self", ".", "dataset", "=", "pickle", ".", "load", "(", "\n", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "aux_data_dir", ",", "suff", "+", "'recipe1m_'", "+", "split", "+", "'.pkl'", ")", ",", "'rb'", ")", ")", "\n", "\n", "self", ".", "use_lmdb", "=", "use_lmdb", "\n", "if", "use_lmdb", ":", "\n", "            ", "self", ".", "image_file", "=", "lmdb", ".", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "aux_data_dir", ",", "'lmdb_'", "+", "split", ")", ",", "\n", "max_readers", "=", "1", ",", "\n", "readonly", "=", "True", ",", "\n", "lock", "=", "False", ",", "\n", "readahead", "=", "False", ",", "\n", "meminit", "=", "False", ")", "\n", "\n", "", "self", ".", "ids", "=", "[", "]", "\n", "self", ".", "split", "=", "split", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "self", ".", "dataset", ")", ":", "\n", "            ", "if", "len", "(", "entry", "[", "'images'", "]", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "self", ".", "ids", ".", "append", "(", "i", ")", "\n", "\n", "", "self", ".", "root", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'images'", ",", "split", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "maxnumims", "=", "maxnumims", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n", "self", ".", "include_eos", "=", "include_eos", "\n", "# remove eos from vocabulary list if not needed", "\n", "if", "not", "self", ".", "include_eos", ":", "\n", "            ", "self", ".", "ingrs_vocab", ".", "remove_eos", "(", ")", "\n", "\n", "", "if", "perm", "is", "not", "None", ":", "\n", "            ", "self", ".", "ids", "=", "np", ".", "array", "(", "self", ".", "ids", ")", "[", "perm", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "ids", "=", "np", ".", "array", "(", "self", ".", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.Recipe1M.__getitem__": [[153, 202], ["range", "list", "len", "list.append", "set", "numpy.random.shuffle", "list.append", "len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "os.path.join", "data_loader.Recipe1M.ingrs_vocab", "data_loader.Recipe1M.ingrs_vocab", "numpy.random.randint", "PIL.Image.open().convert", "data_loader.Recipe1M.transform", "len", "PIL.Image.fromarray", "data_loader.Recipe1M.image_file.begin", "txn.get", "numpy.fromstring", "numpy.reshape", "PIL.Image.open().convert.astype", "print", "PIL.Image.open().convert", "PIL.Image.open", "path.encode", "PIL.Image.open"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Returns one data pair (image and caption).\"\"\"", "\n", "\n", "sample", "=", "self", ".", "dataset", "[", "self", ".", "ids", "[", "index", "]", "]", "\n", "img_id", "=", "sample", "[", "'id'", "]", "\n", "paths", "=", "sample", "[", "'images'", "]", "[", "0", ":", "self", ".", "maxnumims", "]", "\n", "\n", "idx", "=", "index", "\n", "\n", "labels", "=", "self", ".", "dataset", "[", "self", ".", "ids", "[", "idx", "]", "]", "[", "'ingredients'", "]", "\n", "\n", "true_ingr_idxs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "            ", "true_ingr_idxs", ".", "append", "(", "self", ".", "ingrs_vocab", "(", "labels", "[", "i", "]", ")", ")", "\n", "", "true_ingr_idxs", "=", "list", "(", "set", "(", "true_ingr_idxs", ")", ")", "\n", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "true_ingr_idxs", ")", "\n", "\n", "", "if", "self", ".", "include_eos", ":", "\n", "            ", "true_ingr_idxs", ".", "append", "(", "self", ".", "ingrs_vocab", "(", "'<end>'", ")", ")", "\n", "\n", "", "if", "len", "(", "paths", ")", "==", "0", ":", "\n", "            ", "path", "=", "None", "\n", "image_input", "=", "torch", ".", "zeros", "(", "(", "3", ",", "224", ",", "224", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "split", "==", "'train'", ":", "\n", "                ", "img_idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "paths", ")", ")", "\n", "", "else", ":", "\n", "                ", "img_idx", "=", "0", "\n", "", "path", "=", "paths", "[", "img_idx", "]", "\n", "impath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "path", "[", "0", "]", ",", "path", "[", "1", "]", ",", "path", "[", "2", "]", ",", "path", "[", "3", "]", ",", "path", ")", "\n", "if", "self", ".", "use_lmdb", ":", "\n", "                ", "try", ":", "\n", "                    ", "with", "self", ".", "image_file", ".", "begin", "(", "write", "=", "False", ")", "as", "txn", ":", "\n", "                        ", "image", "=", "txn", ".", "get", "(", "path", ".", "encode", "(", ")", ")", "\n", "image", "=", "np", ".", "fromstring", "(", "image", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "image", "=", "np", ".", "reshape", "(", "image", ",", "(", "256", ",", "256", ",", "3", ")", ")", "\n", "", "image", "=", "Image", ".", "fromarray", "(", "image", ".", "astype", "(", "'uint8'", ")", ",", "'RGB'", ")", "\n", "", "except", ":", "\n", "                    ", "print", "(", "\"Image id not found in lmdb. Loading jpeg file...\"", ")", "\n", "image", "=", "Image", ".", "open", "(", "impath", ")", ".", "convert", "(", "'RGB'", ")", "\n", "", "", "else", ":", "\n", "                ", "image", "=", "Image", ".", "open", "(", "impath", ")", ".", "convert", "(", "'RGB'", ")", "\n", "", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "                ", "image", "=", "self", ".", "transform", "(", "image", ")", "\n", "", "image_input", "=", "image", "\n", "\n", "", "return", "image_input", ",", "true_ingr_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.Recipe1M.__len__": [[203, 205], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.Recipe1M.get_vocab": [[206, 210], ["min", "data_loader.Recipe1M.ingrs_vocab.idx2word.values", "isinstance"], "methods", ["None"], ["", "def", "get_vocab", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "min", "(", "w", ",", "key", "=", "len", ")", "if", "not", "isinstance", "(", "w", ",", "str", ")", "else", "w", "\n", "for", "w", "in", "self", ".", "ingrs_vocab", ".", "idx2word", ".", "values", "(", ")", "\n", "]", "# includes '<pad>' and eventually '<end>'", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.VOC.__init__": [[215, 260], ["utils.voc_utils.VOCDetection.__init__", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "root", "=", "''", ",", "\n", "year", "=", "'2007'", ",", "\n", "image_set", "=", "'train'", ",", "\n", "download", "=", "False", ",", "\n", "transform", "=", "None", ",", "\n", "target_transform", "=", "None", ",", "\n", "shuffle", "=", "True", ",", "\n", "perm", "=", "None", ",", "\n", "include_eos", "=", "False", ")", ":", "\n", "\n", "        ", "if", "image_set", "in", "[", "'train'", ",", "'val'", "]", ":", "\n", "            ", "set", "=", "'trainval'", "\n", "", "else", ":", "\n", "            ", "set", "=", "'test'", "\n", "\n", "", "VOCDetection", ".", "__init__", "(", "\n", "self", ",", "\n", "root", "=", "root", ",", "\n", "year", "=", "year", ",", "\n", "image_set", "=", "set", ",", "\n", "download", "=", "download", ",", "\n", "transform", "=", "transform", ",", "\n", "target_transform", "=", "target_transform", ")", "\n", "\n", "self", ".", "cats", "=", "[", "\n", "'eos'", ",", "'aeroplane'", ",", "'bicycle'", ",", "'bird'", ",", "'boat'", ",", "'bottle'", ",", "'bus'", ",", "'car'", ",", "'cat'", ",", "'chair'", ",", "\n", "'cow'", ",", "'diningtable'", ",", "'dog'", ",", "'horse'", ",", "'motorbike'", ",", "'person'", ",", "'pottedplant'", ",", "'sheep'", ",", "\n", "'sofa'", ",", "'train'", ",", "'tvmonitor'", ",", "'<pad>'", "\n", "]", "\n", "\n", "if", "perm", "is", "not", "None", ":", "\n", "            ", "self", ".", "images", "=", "np", ".", "array", "(", "self", ".", "images", ")", "[", "perm", "]", "\n", "self", ".", "annotations", "=", "np", ".", "array", "(", "self", ".", "annotations", ")", "[", "perm", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "images", "=", "np", ".", "array", "(", "self", ".", "images", ")", "\n", "self", ".", "annotations", "=", "np", ".", "array", "(", "self", ".", "annotations", ")", "\n", "\n", "", "self", ".", "include_eos", "=", "include_eos", "\n", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n", "# remove eos from category list if not needed", "\n", "if", "not", "self", ".", "include_eos", ":", "\n", "            ", "self", ".", "cats", "=", "self", ".", "cats", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.VOC.__getitem__": [[261, 297], ["PIL.Image.open().convert", "data_loader.VOC.parse_voc_xml", "list", "utils.voc_utils.ET.parse().getroot", "data_loader.VOC.transform", "type", "range", "numpy.random.shuffle", "data_loader.VOC.cats.index", "target_list.append", "PIL.Image.open", "len", "target_list.append", "utils.voc_utils.ET.parse"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.voc_utils.VOCDetection.parse_voc_xml"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is a dictionary of the XML tree.\n        \"\"\"", "\n", "\n", "img", "=", "Image", ".", "open", "(", "self", ".", "images", "[", "index", "]", ")", ".", "convert", "(", "'RGB'", ")", "\n", "target", "=", "self", ".", "parse_voc_xml", "(", "ET", ".", "parse", "(", "self", ".", "annotations", "[", "index", "]", ")", ".", "getroot", "(", ")", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "target", "=", "target", "[", "'annotation'", "]", "[", "'object'", "]", "\n", "# handle 1-object case", "\n", "if", "type", "(", "target", ")", "is", "dict", ":", "\n", "            ", "target", "=", "[", "target", "]", "\n", "\n", "", "idxs", "=", "list", "(", "range", "(", "len", "(", "target", ")", ")", ")", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "idxs", ")", "\n", "\n", "# build target", "\n", "", "target_list", "=", "[", "]", "\n", "for", "t", "in", "idxs", ":", "\n", "            ", "category_name", "=", "target", "[", "t", "]", "[", "'name'", "]", "\n", "category_id", "=", "self", ".", "cats", ".", "index", "(", "category_name", ")", "\n", "if", "category_id", "not", "in", "target_list", ":", "\n", "                ", "target_list", ".", "append", "(", "category_id", ")", "\n", "\n", "# eos", "\n", "", "", "if", "self", ".", "include_eos", ":", "\n", "            ", "target_list", ".", "append", "(", "0", ")", "\n", "\n", "", "return", "img", ",", "target_list", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.VOC.get_vocab": [[298, 300], ["None"], "methods", ["None"], ["", "def", "get_vocab", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cats", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.VOC.get_sample_list": [[301, 303], ["None"], "methods", ["None"], ["", "def", "get_sample_list", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.NUSWIDE.__init__": [[307, 345], ["os.path.join", "list", "open", "data_loader.NUSWIDE.load_tags", "list", "data_loader.NUSWIDE.load_tags", "list", "numpy.array", "numpy.array", "x.rstrip", "open", "open", "numpy.array", "numpy.array", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.NUSWIDE.load_tags", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.NUSWIDE.load_tags"], ["    ", "def", "__init__", "(", "self", ",", "\n", "root", ",", "\n", "split", ",", "\n", "transform", "=", "None", ",", "\n", "shuffle", "=", "False", ",", "\n", "perm", "=", "None", ",", "\n", "include_eos", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "root", "=", "root", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "include_eos", "=", "include_eos", "\n", "\n", "labels_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'Concepts81.txt'", ")", "\n", "\n", "lines", "=", "list", "(", "open", "(", "labels_dir", ",", "'r'", ")", ")", "\n", "\n", "self", ".", "category_list", "=", "[", "'eos'", "]", "+", "lines", "+", "[", "'<pad>'", "]", "\n", "\n", "# remove eos from category list if not needed", "\n", "if", "not", "self", ".", "include_eos", ":", "\n", "            ", "self", ".", "category_list", "=", "self", ".", "category_list", "[", "1", ":", "]", "\n", "\n", "", "if", "split", "==", "'train'", "or", "split", "==", "'val'", ":", "\n", "            ", "self", ".", "tags", "=", "self", ".", "load_tags", "(", "'train'", ")", "\n", "self", ".", "ids", "=", "list", "(", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'ImageList'", ",", "'TrainImagelist.txt'", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tags", "=", "self", ".", "load_tags", "(", "'test'", ")", "\n", "self", ".", "ids", "=", "list", "(", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'ImageList'", ",", "'TestImagelist.txt'", ")", ")", ")", "\n", "\n", "", "if", "perm", "is", "not", "None", ":", "\n", "            ", "self", ".", "tags", "=", "np", ".", "array", "(", "self", ".", "tags", ")", "[", "perm", "]", "\n", "self", ".", "ids", "=", "np", ".", "array", "(", "self", ".", "ids", ")", "[", "perm", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "tags", "=", "np", ".", "array", "(", "self", ".", "tags", ")", "\n", "self", ".", "ids", "=", "np", ".", "array", "(", "self", ".", "ids", ")", "\n", "\n", "", "self", ".", "category_list", "=", "[", "x", ".", "rstrip", "(", ")", "for", "x", "in", "self", ".", "category_list", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.NUSWIDE.load_tags": [[347, 363], ["list", "open", "len", "range", "os.path.join", "len", "split.capitalize", "cat.rstrip"], "methods", ["None"], ["", "def", "load_tags", "(", "self", ",", "split", ")", ":", "\n", "\n", "        ", "anns", "=", "[", "]", "\n", "for", "cat", "in", "self", ".", "category_list", "[", "1", "if", "self", ".", "include_eos", "else", "0", ":", "-", "1", "]", ":", "\n", "\n", "            ", "c_anns", "=", "list", "(", "\n", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'TrainTestLabels'", ",", "\n", "'Labels_'", "+", "cat", ".", "rstrip", "(", ")", "+", "'_'", "+", "split", ".", "capitalize", "(", ")", "+", "'.txt'", ")", ")", ")", "\n", "\n", "if", "len", "(", "anns", ")", "==", "0", ":", "\n", "                ", "anns", "=", "c_anns", "\n", "", "else", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "c_anns", ")", ")", ":", "\n", "                    ", "anns", "[", "i", "]", "+=", "' '", "+", "c_anns", "[", "i", "]", "\n", "", "", "", "return", "anns", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.NUSWIDE.__getitem__": [[364, 396], ["data_loader.NUSWIDE.ids[].rstrip", "os.path.join", "PIL.Image.open().convert", "numpy.asarray", "list", "data_loader.NUSWIDE.split", "data_loader.NUSWIDE.transform", "numpy.asarray.rstrip().split", "numpy.where", "range", "numpy.random.shuffle", "target_list.append", "PIL.Image.open", "len", "target_list.append", "numpy.asarray.rstrip"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "\n", "        ", "path", "=", "self", ".", "ids", "[", "item", "]", ".", "rstrip", "(", ")", "\n", "data", "=", "self", ".", "tags", "[", "item", "]", "\n", "\n", "path", "=", "'/'", ".", "join", "(", "path", ".", "split", "(", "'\\\\'", ")", ")", "\n", "impath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'Flickr'", ",", "path", ")", "\n", "img", "=", "Image", ".", "open", "(", "impath", ")", ".", "convert", "(", "'RGB'", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "# data = data.rstrip().split(' ')", "\n", "# data = np.array([int(i.rstrip()) for i in data])", "\n", "", "data", "=", "np", ".", "asarray", "(", "data", ".", "rstrip", "(", ")", ".", "split", "(", "'\\n '", ")", ",", "dtype", "=", "'uint8'", ")", "\n", "target", "=", "np", ".", "where", "(", "data", "==", "1", ")", "[", "0", "]", "\n", "\n", "idxs", "=", "list", "(", "range", "(", "len", "(", "target", ")", ")", ")", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "idxs", ")", "\n", "\n", "# build target", "\n", "", "target_list", "=", "[", "]", "\n", "for", "t", "in", "idxs", ":", "\n", "            ", "category_id", "=", "target", "[", "t", "]", "+", "1", "if", "self", ".", "include_eos", "else", "target", "[", "t", "]", "\n", "if", "category_id", "not", "in", "target_list", ":", "\n", "                ", "target_list", ".", "append", "(", "category_id", ")", "\n", "\n", "# eos", "\n", "", "", "if", "self", ".", "include_eos", ":", "\n", "            ", "target_list", ".", "append", "(", "0", ")", "\n", "\n", "", "return", "img", ",", "target_list", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.NUSWIDE.__len__": [[397, 399], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.NUSWIDE.get_vocab": [[400, 402], ["None"], "methods", ["None"], ["", "def", "get_vocab", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "category_list", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.NUSWIDE.get_sample_list": [[403, 405], ["None"], "methods", ["None"], ["", "def", "get_sample_list", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.COCO.__init__": [[409, 448], ["data_loader.COCO", "list", "data_loader.COCO.category_list.append", "data_loader.COCO.coco.imgs.keys", "[].tolist", "numpy.array"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "root", ",", "\n", "annFile", ",", "\n", "transform", "=", "None", ",", "\n", "shuffle", "=", "False", ",", "\n", "perm", "=", "None", ",", "\n", "include_eos", "=", "False", ",", ")", ":", "\n", "        ", "from", "pycocotools", ".", "coco", "import", "COCO", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "coco", "=", "COCO", "(", "annFile", ")", "\n", "self", ".", "ids", "=", "list", "(", "self", ".", "coco", ".", "imgs", ".", "keys", "(", ")", ")", "\n", "\n", "if", "perm", "is", "not", "None", ":", "\n", "            ", "self", ".", "ids", "=", "np", ".", "array", "(", "self", ".", "ids", ")", "[", "perm", "]", ".", "tolist", "(", ")", "\n", "\n", "", "self", ".", "transform", "=", "transform", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n", "self", ".", "category_list", "=", "[", "\n", "'eos'", ",", "'person'", ",", "'bicycle'", ",", "'car'", ",", "'motorcycle'", ",", "'airplane'", ",", "'bus'", ",", "'train'", ",", "'truck'", ",", "\n", "'boat'", ",", "'traffic light'", ",", "'fire hydrant'", ",", "'stop sign'", ",", "'parking meter'", ",", "'bench'", ",", "'bird'", ",", "\n", "'cat'", ",", "'dog'", ",", "'horse'", ",", "'sheep'", ",", "'cow'", ",", "'elephant'", ",", "'bear'", ",", "'zebra'", ",", "'giraffe'", ",", "\n", "'backpack'", ",", "'umbrella'", ",", "'handbag'", ",", "'tie'", ",", "'suitcase'", ",", "'frisbee'", ",", "'skis'", ",", "'snowboard'", ",", "\n", "'sports ball'", ",", "'kite'", ",", "'baseball bat'", ",", "'baseball glove'", ",", "'skateboard'", ",", "'surfboard'", ",", "\n", "'tennis racket'", ",", "'bottle'", ",", "'wine glass'", ",", "'cup'", ",", "'fork'", ",", "'knife'", ",", "'spoon'", ",", "'bowl'", ",", "\n", "'banana'", ",", "'apple'", ",", "'sandwich'", ",", "'orange'", ",", "'broccoli'", ",", "'carrot'", ",", "'hot dog'", ",", "'pizza'", ",", "\n", "'donut'", ",", "'cake'", ",", "'chair'", ",", "'couch'", ",", "'potted plant'", ",", "'bed'", ",", "'dining table'", ",", "'toilet'", ",", "\n", "'tv'", ",", "'laptop'", ",", "'mouse'", ",", "'remote'", ",", "'keyboard'", ",", "'cell phone'", ",", "'microwave'", ",", "'oven'", ",", "\n", "'toaster'", ",", "'sink'", ",", "'refrigerator'", ",", "'book'", ",", "'clock'", ",", "'vase'", ",", "'scissors'", ",", "'teddy bear'", ",", "\n", "'hair drier'", ",", "'toothbrush'", "\n", "]", "\n", "\n", "self", ".", "category_list", ".", "append", "(", "'<pad>'", ")", "\n", "\n", "self", ".", "include_eos", "=", "include_eos", "\n", "\n", "# remove eos from category list if not needed", "\n", "if", "not", "self", ".", "include_eos", ":", "\n", "            ", "self", ".", "category_list", "=", "self", ".", "category_list", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.COCO.__getitem__": [[449, 479], ["coco.getAnnIds", "coco.loadAnns", "os.path.join", "PIL.Image.open().convert", "list", "data_loader.COCO.transform", "range", "numpy.random.shuffle", "data_loader.COCO.category_list.index", "target_list.append", "coco.loadImgs", "PIL.Image.open", "len", "target_list.append"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "coco", "=", "self", ".", "coco", "\n", "img_id", "=", "self", ".", "ids", "[", "index", "]", "\n", "ann_ids", "=", "coco", ".", "getAnnIds", "(", "imgIds", "=", "img_id", ")", "\n", "target", "=", "coco", ".", "loadAnns", "(", "ann_ids", ")", "\n", "\n", "path", "=", "coco", ".", "loadImgs", "(", "img_id", ")", "[", "0", "]", "[", "'file_name'", "]", "\n", "impath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "path", ")", "\n", "img", "=", "Image", ".", "open", "(", "impath", ")", ".", "convert", "(", "'RGB'", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "idxs", "=", "list", "(", "range", "(", "len", "(", "target", ")", ")", ")", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "idxs", ")", "\n", "\n", "# build target", "\n", "", "target_list", "=", "[", "]", "\n", "for", "t", "in", "idxs", ":", "\n", "            ", "category_id", "=", "target", "[", "t", "]", "[", "'category_id'", "]", "\n", "category_name", "=", "category_map", "[", "category_id", "]", "\n", "category_id", "=", "self", ".", "category_list", ".", "index", "(", "category_name", ")", "\n", "if", "category_id", "not", "in", "target_list", ":", "\n", "                ", "target_list", ".", "append", "(", "category_id", ")", "\n", "\n", "# eos", "\n", "", "", "if", "self", ".", "include_eos", ":", "\n", "            ", "target_list", ".", "append", "(", "0", ")", "\n", "\n", "", "return", "img", ",", "target_list", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.COCO.__len__": [[480, 482], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.COCO.get_vocab": [[483, 485], ["None"], "methods", ["None"], ["", "def", "get_vocab", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "category_list", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.COCO.get_sample_list": [[486, 488], ["None"], "methods", ["None"], ["", "def", "get_sample_list", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.ADE20K.__init__": [[492, 526], ["os.path.join", "os.path.join", "list", "os.path.join", "list", "numpy.array", "[].rstrip", "open", "open", "numpy.array", "open().readlines", "[].split", "open", "x.split"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "root", ",", "\n", "split", ",", "\n", "transform", "=", "None", ",", "\n", "shuffle", "=", "False", ",", "\n", "perm", "=", "None", ",", "\n", "include_eos", "=", "False", ")", ":", "\n", "\n", "        ", "labels_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'objectInfo150.txt'", ")", "\n", "lines", "=", "[", "x", ".", "split", "(", "'\\t'", ")", "[", "-", "1", "]", ".", "split", "(", "','", ")", "[", "0", "]", ".", "rstrip", "(", ")", "for", "x", "in", "open", "(", "labels_dir", ")", ".", "readlines", "(", ")", "]", "[", "1", ":", "]", "\n", "\n", "self", ".", "category_list", "=", "[", "'eos'", "]", "+", "lines", "+", "[", "'<pad>'", "]", "\n", "\n", "self", ".", "root", "=", "root", "\n", "if", "split", "==", "'train'", "or", "split", "==", "'val'", ":", "\n", "            ", "samples_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'ADE20K_object150_train.txt'", ")", "\n", "self", ".", "ids", "=", "list", "(", "open", "(", "samples_dir", ",", "'r'", ")", ")", "\n", "", "else", ":", "\n", "            ", "samples_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'ADE20K_object150_val.txt'", ")", "\n", "self", ".", "ids", "=", "list", "(", "open", "(", "samples_dir", ",", "'r'", ")", ")", "\n", "\n", "", "if", "perm", "is", "not", "None", ":", "\n", "            ", "self", ".", "ids", "=", "np", ".", "array", "(", "self", ".", "ids", ")", "[", "perm", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "ids", "=", "np", ".", "array", "(", "self", ".", "ids", ")", "\n", "\n", "", "self", ".", "transform", "=", "transform", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n", "self", ".", "include_eos", "=", "include_eos", "\n", "\n", "# remove eos from category list if not needed", "\n", "if", "not", "self", ".", "include_eos", ":", "\n", "            ", "self", ".", "category_list", "=", "self", ".", "category_list", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.ADE20K.__getitem__": [[527, 562], ["data_loader.ADE20K.ids[].rstrip", "os.path.join", "os.path.join", "PIL.Image.open().convert", "PIL.Image.open", "numpy.unique", "numpy.delete", "data_loader.ADE20K.transform", "numpy.where", "numpy.random.shuffle", "target_list.append", "data_loader.ADE20K.split", "PIL.Image.open", "target_list.append"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "\n", "        ", "sample_name", "=", "self", ".", "ids", "[", "item", "]", ".", "rstrip", "(", ")", "\n", "impath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'images'", ",", "sample_name", ")", "\n", "\n", "maskname", "=", "sample_name", ".", "split", "(", "'.jpg'", ")", "[", "0", "]", "+", "'.png'", "\n", "maskpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'annotations'", ",", "maskname", ")", "\n", "\n", "img", "=", "Image", ".", "open", "(", "impath", ")", ".", "convert", "(", "'RGB'", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "mask", "=", "Image", ".", "open", "(", "maskpath", ")", "\n", "\n", "idxs", "=", "np", ".", "unique", "(", "mask", ")", "\n", "# the 0 idx refers to \"other objects\"", "\n", "idxs", "=", "np", ".", "delete", "(", "idxs", ",", "np", ".", "where", "(", "idxs", "==", "0", ")", ")", "\n", "\n", "if", "not", "self", ".", "include_eos", ":", "\n", "            ", "idxs", "=", "[", "i", "-", "1", "for", "i", "in", "idxs", "]", "\n", "\n", "", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "idxs", ")", "\n", "\n", "", "target_list", "=", "[", "]", "\n", "for", "t", "in", "idxs", ":", "\n", "            ", "category_id", "=", "t", "\n", "if", "category_id", "not", "in", "target_list", ":", "\n", "                ", "target_list", ".", "append", "(", "category_id", ")", "\n", "\n", "# eos", "\n", "", "", "if", "self", ".", "include_eos", ":", "\n", "            ", "target_list", ".", "append", "(", "0", ")", "\n", "\n", "", "return", "img", ",", "target_list", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.ADE20K.__len__": [[563, 565], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.ADE20K.get_vocab": [[566, 568], ["None"], "methods", ["None"], ["", "def", "get_vocab", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "category_list", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.ADE20K.get_sample_list": [[569, 571], ["None"], "methods", ["None"], ["", "def", "get_sample_list", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.RandomSamplerWithStateIterator.__init__": [[586, 594], ["torch.Generator", "torch.Generator", "torch.Generator", "torch.Generator", "torch.Generator.manual_seed", "torch.Generator.manual_seed", "torch.randperm().tolist", "torch.randperm().tolist", "torch.randperm().tolist", "torch.randperm().tolist", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_source", ",", "seed", ")", ":", "\n", "        ", "self", ".", "data_source", "=", "data_source", "\n", "self", ".", "seed", "=", "seed", "\n", "g", "=", "torch", ".", "Generator", "(", ")", "\n", "g", ".", "manual_seed", "(", "seed", ")", "\n", "self", ".", "indices", "=", "torch", ".", "randperm", "(", "len", "(", "self", ".", "data_source", ")", ",", "generator", "=", "g", ")", ".", "tolist", "(", ")", "\n", "self", ".", "epoch", "=", "0", "\n", "self", ".", "index", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.RandomSamplerWithStateIterator.__iter__": [[595, 597], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.RandomSamplerWithStateIterator.__next__": [[598, 604], ["len"], "methods", ["None"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "index", "==", "len", "(", "self", ".", "data_source", ")", ":", "\n", "            ", "raise", "StopIteration", "\n", "", "item", "=", "self", ".", "indices", "[", "self", ".", "index", "]", "\n", "self", ".", "index", "+=", "1", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.RandomSamplerWithStateIterator.set_epoch": [[605, 611], ["torch.Generator", "torch.Generator", "torch.Generator", "torch.Generator", "torch.Generator.manual_seed", "torch.Generator.manual_seed", "torch.randperm().tolist", "torch.randperm().tolist", "torch.randperm().tolist", "torch.randperm().tolist", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "len"], "methods", ["None"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "g", "=", "torch", ".", "Generator", "(", ")", "\n", "g", ".", "manual_seed", "(", "self", ".", "seed", "+", "epoch", ")", "\n", "self", ".", "epoch", "=", "epoch", "\n", "self", ".", "indices", "=", "torch", ".", "randperm", "(", "len", "(", "self", ".", "data_source", ")", ",", "generator", "=", "g", ")", ".", "tolist", "(", ")", "\n", "self", ".", "index", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.RandomSamplerWithStateIterator.increase_epoch": [[612, 614], ["data_loader.RandomSamplerWithStateIterator.set_epoch"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.RandomSamplerWithStateIterator.set_epoch"], ["", "def", "increase_epoch", "(", "self", ")", ":", "\n", "        ", "self", ".", "set_epoch", "(", "self", ".", "epoch", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.RandomSamplerWithState.__init__": [[618, 621], ["data_loader.RandomSamplerWithStateIterator"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_source", ",", "batch_size", ",", "seed", ")", ":", "\n", "        ", "self", ".", "iterator", "=", "RandomSamplerWithStateIterator", "(", "data_source", ",", "seed", ")", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.RandomSamplerWithState.__iter__": [[622, 624], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "iterator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.RandomSamplerWithState.__len__": [[625, 627], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "iterator", ".", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.RandomSamplerWithState.set_state": [[628, 631], ["data_loader.RandomSamplerWithState.iterator.set_epoch"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.RandomSamplerWithStateIterator.set_epoch"], ["", "def", "set_state", "(", "self", ",", "epoch", ",", "step", ")", ":", "\n", "        ", "self", ".", "iterator", ".", "set_epoch", "(", "epoch", ")", "\n", "self", ".", "iterator", ".", "index", "=", "step", "*", "self", ".", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.collate_fn": [[573, 582], ["zip", "torch.stack", "torch.stack"], "function", ["None"], ["", "", "def", "collate_fn", "(", "data", ")", ":", "\n", "\n", "    ", "img", ",", "target", "=", "zip", "(", "*", "data", ")", "\n", "\n", "# Merge images (from tuple of 3D tensor to 4D tensor)", "\n", "# We keep targets as list of lists (each image may contain different number of labels)", "\n", "img", "=", "torch", ".", "stack", "(", "img", ",", "0", ")", "\n", "\n", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.get_loader": [[633, 732], ["os.path.join", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "open", "numpy.array", "data_loader.COCO", "numpy.random.seed", "data_loader.RandomSamplerWithState", "torch.utils.data.sampler.SequentialSampler", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "data_loader.VOC", "torch.utils.data.sampler.SequentialSampler.set_state", "int", "data_loader.NUSWIDE", "line.rstrip", "data_loader.ADE20K", "data_loader.Recipe1M"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.RandomSamplerWithState.set_state"], ["", "", "def", "get_loader", "(", "dataset", ",", "\n", "dataset_root", ",", "\n", "split", ",", "\n", "transform", ",", "\n", "batch_size", ",", "\n", "shuffle", ",", "\n", "num_workers", ",", "\n", "include_eos", ",", "\n", "drop_last", "=", "False", ",", "\n", "shuffle_labels", "=", "False", ",", "\n", "seed", "=", "1234", ",", "\n", "checkpoint", "=", "None", ")", ":", "\n", "\n", "# reads the file with ids to use for this split", "\n", "    ", "perm_file", "=", "os", ".", "path", ".", "join", "(", "'../data/splits/'", ",", "dataset", ",", "split", "+", "'.txt'", ")", "\n", "with", "open", "(", "perm_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "perm", "=", "np", ".", "array", "(", "[", "int", "(", "line", ".", "rstrip", "(", "'\\n'", ")", ")", "for", "line", "in", "f", "]", ")", "\n", "\n", "", "if", "dataset", "==", "'coco'", ":", "\n", "        ", "if", "split", "==", "'train'", "or", "split", "==", "'val'", ":", "\n", "            ", "annFile", "=", "os", ".", "path", ".", "join", "(", "dataset_root", ",", "'annotations'", ",", "'instances_train2014.json'", ")", "\n", "impath", "=", "os", ".", "path", ".", "join", "(", "dataset_root", ",", "'train2014'", ")", "\n", "", "else", ":", "\n", "            ", "annFile", "=", "os", ".", "path", ".", "join", "(", "dataset_root", ",", "'annotations'", ",", "'instances_val2014.json'", ")", "\n", "impath", "=", "os", ".", "path", ".", "join", "(", "dataset_root", ",", "'val2014'", ")", "\n", "\n", "", "dataset", "=", "COCO", "(", "\n", "root", "=", "impath", ",", "\n", "annFile", "=", "annFile", ",", "\n", "transform", "=", "transform", ",", "\n", "shuffle", "=", "shuffle_labels", ",", "\n", "perm", "=", "perm", ",", "\n", "include_eos", "=", "include_eos", ")", "\n", "\n", "", "elif", "dataset", "==", "'voc'", ":", "\n", "        ", "dataset", "=", "VOC", "(", "\n", "root", "=", "dataset_root", ",", "\n", "year", "=", "'2007'", ",", "\n", "image_set", "=", "split", ",", "\n", "download", "=", "False", ",", "\n", "transform", "=", "transform", ",", "\n", "shuffle", "=", "shuffle_labels", ",", "\n", "perm", "=", "perm", ",", "\n", "include_eos", "=", "include_eos", ")", "\n", "\n", "", "elif", "dataset", "==", "'nuswide'", ":", "\n", "        ", "dataset", "=", "NUSWIDE", "(", "\n", "dataset_root", ",", "\n", "split", ",", "\n", "transform", "=", "transform", ",", "\n", "shuffle", "=", "shuffle_labels", ",", "\n", "perm", "=", "perm", ",", "\n", "include_eos", "=", "include_eos", ")", "\n", "\n", "", "elif", "dataset", "==", "'ade20k'", ":", "\n", "        ", "dataset", "=", "ADE20K", "(", "\n", "dataset_root", ",", "\n", "split", ",", "\n", "transform", "=", "transform", ",", "\n", "shuffle", "=", "shuffle_labels", ",", "\n", "perm", "=", "perm", ",", "\n", "include_eos", "=", "include_eos", ")", "\n", "\n", "", "elif", "dataset", "==", "'recipe1m'", ":", "\n", "        ", "dataset", "=", "Recipe1M", "(", "\n", "dataset_root", ",", "\n", "split", ",", "\n", "maxnumims", "=", "5", ",", "\n", "shuffle", "=", "shuffle_labels", ",", "\n", "transform", "=", "transform", ",", "\n", "use_lmdb", "=", "False", ",", "\n", "suff", "=", "'final_'", ",", "\n", "perm", "=", "perm", ",", "\n", "include_eos", "=", "include_eos", ")", "\n", "\n", "", "def", "worker_init_fn", "(", "worker_id", ")", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "", "if", "shuffle", ":", "\n", "# for training", "\n", "        ", "sampler", "=", "RandomSamplerWithState", "(", "dataset", ",", "batch_size", ",", "seed", ")", "\n", "if", "checkpoint", "is", "not", "None", ":", "\n", "            ", "sampler", ".", "set_state", "(", "checkpoint", "[", "'args'", "]", ".", "current_epoch", ",", "checkpoint", "[", "'current_step'", "]", ")", "\n", "", "", "else", ":", "\n", "# for validation and test", "\n", "        ", "sampler", "=", "SequentialSampler", "(", "dataset", ")", "\n", "\n", "", "data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "drop_last", "=", "drop_last", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "worker_init_fn", "=", "worker_init_fn", ",", "\n", "sampler", "=", "sampler", ")", "\n", "\n", "return", "data_loader", ",", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.increase_loader_epoch": [[734, 736], ["data_loader.sampler.iterator.increase_epoch"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.RandomSamplerWithStateIterator.increase_epoch"], ["", "def", "increase_loader_epoch", "(", "data_loader", ")", ":", "\n", "    ", "data_loader", ".", "sampler", ".", "iterator", ".", "increase_epoch", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.eval.main": [[27, 160], ["glob.glob", "numpy.zeros", "numpy.zeros", "numpy.zeros", "print", "enumerate", "print", "pandas.DataFrame", "pd.DataFrame.to_csv", "os.path.exists", "os.makedirs", "print", "print", "torch.load", "transforms_list.append", "transforms_list.append", "transforms_list.append", "transforms_list.append", "torchvision.transforms.Compose", "json.load", "data_loader.get_loader", "len", "print", "print", "model.get_model", "model.to.load_state_dict", "model.to.eval", "model.to.to", "len", "print", "tqdm.tqdm", "utils.metrics.compute_metrics", "numpy.mean", "print", "os.path.join", "len", "len", "len", "re.split", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "open", "dataset.get_vocab", "enumerate", "img_inputs.to.to", "len", "torch.no_grad", "model.to.", "model.label2_k_hots", "model.label2_k_hots", "utils.metrics.update_error_counts", "range", "model.label2_k_hots.size", "utils.metrics.update_error_counts", "utils.metrics.compute_metrics", "f1s_image.append", "pred_k_hots[].unsqueeze", "target_k_hots[].unsqueeze"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.get_loader", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.model.get_model", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.compute_metrics", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.ADE20K.get_vocab", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.model.label2_k_hots", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.model.label2_k_hots", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.update_error_counts", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.update_error_counts", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.compute_metrics"], ["def", "main", "(", "args", ")", ":", "\n", "\n", "# Get models to test from models_path", "\n", "    ", "models_to_test", "=", "glob", ".", "glob", "(", "args", ".", "models_path", "+", "'/*.ckpt'", ")", "\n", "\n", "# To store results", "\n", "mat_f1", "=", "np", ".", "zeros", "(", "(", "len", "(", "models_to_test", ")", ",", ")", ")", "\n", "mat_f1_c", "=", "np", ".", "zeros", "(", "(", "len", "(", "models_to_test", ")", ",", ")", ")", "\n", "mat_f1_i", "=", "np", ".", "zeros", "(", "(", "len", "(", "models_to_test", ")", ",", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "save_results_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "save_results_path", ")", "\n", "\n", "", "print", "(", "'Results will be saved here: '", "+", "args", ".", "save_results_path", ")", "\n", "\n", "# Extract model names", "\n", "models_to_test", "=", "[", "m", "for", "m", "in", "models_to_test", "if", "args", ".", "dataset", "in", "m", "]", "\n", "model_names", "=", "[", "re", ".", "split", "(", "r'[/]'", ",", "m", ")", "[", "-", "1", "]", "for", "m", "in", "models_to_test", "]", "\n", "\n", "# Iterate over models to test", "\n", "for", "k", ",", "m", "in", "enumerate", "(", "models_to_test", ")", ":", "\n", "        ", "print", "(", "'---------------------------------------------'", ")", "\n", "print", "(", "'Evaluating '", "+", "model_names", "[", "k", "]", ")", "\n", "\n", "# Load model", "\n", "checkpoint", "=", "torch", ".", "load", "(", "m", ",", "map_location", "=", "map_loc", ")", "\n", "model_args", "=", "checkpoint", "[", "'args'", "]", "\n", "\n", "# Image pre-processing", "\n", "transforms_list", "=", "[", "]", "\n", "transforms_list", ".", "append", "(", "transforms", ".", "Resize", "(", "model_args", ".", "image_size", ")", ")", "\n", "transforms_list", ".", "append", "(", "transforms", ".", "CenterCrop", "(", "model_args", ".", "crop_size", ")", ")", "\n", "transforms_list", ".", "append", "(", "transforms", ".", "ToTensor", "(", ")", ")", "\n", "transforms_list", ".", "append", "(", "\n", "transforms", ".", "Normalize", "(", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "(", "0.229", ",", "0.224", ",", "0.225", ")", ")", ")", "\n", "transform", "=", "transforms", ".", "Compose", "(", "transforms_list", ")", "\n", "\n", "# Load data", "\n", "datapaths", "=", "json", ".", "load", "(", "open", "(", "'../configs/datapaths.json'", ")", ")", "\n", "dataset_root", "=", "datapaths", "[", "model_args", ".", "dataset", "]", "\n", "data_loader", ",", "dataset", "=", "get_loader", "(", "\n", "dataset", "=", "model_args", ".", "dataset", ",", "\n", "dataset_root", "=", "dataset_root", ",", "\n", "split", "=", "args", ".", "eval_split", ",", "\n", "transform", "=", "transform", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "include_eos", "=", "(", "model_args", ".", "decoder", "!=", "'ff'", ")", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "8", ",", "\n", "drop_last", "=", "False", ",", "\n", "shuffle_labels", "=", "False", ")", "\n", "\n", "vocab_size", "=", "len", "(", "dataset", ".", "get_vocab", "(", ")", ")", "\n", "print", "(", "'Vocabulary size is {}'", ".", "format", "(", "vocab_size", ")", ")", "\n", "print", "(", "'Dataset {} split contains {} images'", ".", "format", "(", "args", ".", "eval_split", ",", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "# Load model", "\n", "model", "=", "get_model", "(", "model_args", ",", "vocab_size", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "\n", "# Eval", "\n", "model", ".", "eval", "(", ")", "\n", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "total_step", "=", "len", "(", "data_loader", ")", "\n", "print", "(", "'Number of iterations is {}'", ".", "format", "(", "total_step", ")", ")", "\n", "\n", "overall_error_counts", "=", "{", "\n", "'tp_c'", ":", "0", ",", "\n", "'fp_c'", ":", "0", ",", "\n", "'fn_c'", ":", "0", ",", "\n", "'tn_c'", ":", "0", ",", "\n", "'tp_all'", ":", "0", ",", "\n", "'fp_all'", ":", "0", ",", "\n", "'fn_all'", ":", "0", "\n", "}", "\n", "error_counts_per_card", "=", "{", "}", "\n", "f1s_image_per_card", "=", "{", "}", "\n", "card_l1_err", "=", "[", "]", "\n", "f1s_image", "=", "[", "]", "\n", "card_accs", "=", "[", "]", "\n", "\n", "for", "l", ",", "(", "img_inputs", ",", "target", ")", "in", "tqdm", "(", "enumerate", "(", "data_loader", ")", ")", ":", "\n", "\n", "            ", "img_inputs", "=", "img_inputs", ".", "to", "(", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# get model predictions", "\n", "# predictions format can either be a matrix of size batch_size x maxnumlabels, where", "\n", "# each row contains the integer labels of an image, followed by pad_value", "\n", "# or a list of sublists, where each sublist contains the integer labels of an image", "\n", "# and len(list) = batch_size and len(sublist) is variable", "\n", "                ", "_", ",", "predictions", "=", "model", "(", "\n", "img_inputs", ",", "maxnumlabels", "=", "model_args", ".", "maxnumlabels", ",", "compute_predictions", "=", "True", ")", "\n", "# convert model predictions and targets to k-hots", "\n", "pred_k_hots", "=", "label2_k_hots", "(", "\n", "predictions", ",", "vocab_size", "-", "1", ",", "remove_eos", "=", "(", "model_args", ".", "decoder", "!=", "'ff'", ")", ")", "\n", "target_k_hots", "=", "label2_k_hots", "(", "\n", "target", ",", "vocab_size", "-", "1", ",", "remove_eos", "=", "(", "model_args", ".", "decoder", "!=", "'ff'", ")", ")", "\n", "# update overall and per class error counts", "\n", "update_error_counts", "(", "overall_error_counts", ",", "pred_k_hots", ",", "target_k_hots", ")", "\n", "\n", "# get per-image error counts", "\n", "for", "i", "in", "range", "(", "pred_k_hots", ".", "size", "(", "0", ")", ")", ":", "\n", "# compute per image metrics", "\n", "                    ", "image_error_counts", "=", "{", "\n", "'tp_c'", ":", "0", ",", "\n", "'fp_c'", ":", "0", ",", "\n", "'fn_c'", ":", "0", ",", "\n", "'tn_c'", ":", "0", ",", "\n", "'tp_all'", ":", "0", ",", "\n", "'fp_all'", ":", "0", ",", "\n", "'fn_all'", ":", "0", "\n", "}", "\n", "update_error_counts", "(", "image_error_counts", ",", "pred_k_hots", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "\n", "target_k_hots", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "image_metrics", "=", "compute_metrics", "(", "image_error_counts", ",", "which_metrics", "=", "[", "'f1'", "]", ")", "\n", "f1s_image", ".", "append", "(", "image_metrics", "[", "'f1'", "]", ")", "\n", "\n", "# compute overall and per class metrics", "\n", "", "", "", "overall_metrics", "=", "compute_metrics", "(", "overall_error_counts", ",", "[", "'f1'", ",", "'c_f1'", "]", ",", "weights", "=", "None", ")", "\n", "overall_metrics", "[", "'f1_i'", "]", "=", "np", ".", "mean", "(", "f1s_image", ")", "\n", "print", "(", "overall_metrics", ")", "\n", "\n", "# save results", "\n", "mat_f1", "[", "k", "]", "=", "overall_metrics", "[", "'f1'", "]", "\n", "mat_f1_c", "[", "k", "]", "=", "overall_metrics", "[", "'c_f1'", "]", "\n", "mat_f1_i", "[", "k", "]", "=", "overall_metrics", "[", "'f1_i'", "]", "\n", "\n", "", "print", "(", "'Saving results...'", ")", "\n", "data", "=", "{", "'Model'", ":", "model_names", ",", "'f1'", ":", "mat_f1", ",", "'f1_c'", ":", "mat_f1_c", ",", "'f1_i'", ":", "mat_f1_i", "}", "\n", "df", "=", "pd", ".", "DataFrame", "(", "data", ")", "\n", "df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_results_path", ",", "'results.csv'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.StreamToLogger.__init__": [[41, 45], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "logger", ",", "log_level", "=", "logging", ".", "INFO", ")", ":", "\n", "        ", "self", ".", "logger", "=", "logger", "\n", "self", ".", "log_level", "=", "log_level", "\n", "self", ".", "linebuf", "=", "''", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.StreamToLogger.write": [[46, 49], ["buf.rstrip().splitlines", "train.StreamToLogger.logger.log", "buf.rstrip", "line.rstrip"], "methods", ["None"], ["", "def", "write", "(", "self", ",", "buf", ")", ":", "\n", "        ", "for", "line", "in", "buf", ".", "rstrip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "self", ".", "logger", ".", "log", "(", "self", ".", "log_level", ",", "line", ".", "rstrip", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.StreamToLogger.flush": [[50, 52], ["None"], "methods", ["None"], ["", "", "def", "flush", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.save_checkpoint": [[54, 73], ["optimizer.state_dict", "print", "torch.save", "torch.save", "torch.save", "os.path.isfile", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "model.module.state_dict", "model.state_dict", "print", "os.rename"], "function", ["None"], ["", "", "def", "save_checkpoint", "(", "model", ",", "optimizer", ",", "args", ",", "es_best", ",", "epoch_best", ",", "current_step", ",", "current_pat", ",", "\n", "checkpoint_filename", ")", ":", "\n", "    ", "checkpoint", "=", "{", "}", "\n", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "        ", "checkpoint", "[", "'state_dict'", "]", "=", "model", ".", "module", ".", "state_dict", "(", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint", "[", "'state_dict'", "]", "=", "model", ".", "state_dict", "(", ")", "\n", "", "checkpoint", "[", "'optimizer'", "]", "=", "optimizer", ".", "state_dict", "(", ")", "\n", "checkpoint", "[", "'es_best'", "]", "=", "es_best", "\n", "checkpoint", "[", "'epoch_best'", "]", "=", "epoch_best", "\n", "checkpoint", "[", "'args'", "]", "=", "args", "\n", "checkpoint", "[", "'current_step'", "]", "=", "current_step", "\n", "checkpoint", "[", "'current_pat'", "]", "=", "current_pat", "\n", "\n", "print", "(", "'saving tmp checkpoint'", ",", "CHECKPOINT_tempfile", ",", "flush", "=", "True", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "CHECKPOINT_tempfile", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "CHECKPOINT_tempfile", ")", ":", "\n", "        ", "print", "(", "'file was saved correctly. renaming now'", ",", "flush", "=", "True", ")", "\n", "os", ".", "rename", "(", "CHECKPOINT_tempfile", ",", "checkpoint_filename", "+", "'.ckpt'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.count_parameters": [[75, 77], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["", "", "def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.set_lr": [[79, 82], ["None"], "function", ["None"], ["", "def", "set_lr", "(", "optimizer", ",", "decay_factor", ")", ":", "\n", "    ", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "group", "[", "'lr'", "]", "=", "group", "[", "'lr'", "]", "*", "decay_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.make_dir": [[84, 87], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "def", "make_dir", "(", "d", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "d", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.main": [[89, 508], ["os.path.join", "os.path.join", "os.path.join", "print", "os.path.join", "os.path.join", "train.make_dir", "train.make_dir", "train.make_dir", "train.make_dir", "logging.getLogger", "logging.getLogger.setLevel", "logging.Formatter", "logging.FileHandler", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "logging.getLogger", "logging.FileHandler", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler", "train.StreamToLogger", "os.path.join", "os.path.isfile", "os.path.isfile", "len", "logging.getLogger.info", "model.get_model", "list", "sum", "sum", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.info", "nn.DataParallel.to", "range", "open", "es_best.keys", "open.close", "os.path.join", "os.path.join", "os.remove", "os.remove", "utils.tb_visualizer.Visualizer", "os.path.isfile", "transforms_list.append", "transforms_list.append", "torchvision.transforms.Compose", "json.load", "data_loader.get_loader", "logging.getLogger.info", "datasets[].get_vocab", "list", "nn.DataParallel.image_encoder.pretrained_net.parameters", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "logging.getLogger.info", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "logging.getLogger.info", "torch.optim.Adam.load_state_dict", "torch.optim.Adam.state.values", "nn.DataParallel.load_state_dict", "torch.DataParallel", "hasattr", "train.save_checkpoint", "logging.getLogger.info", "open.write", "utils.tb_visualizer.Visualizer.close", "str", "str", "torch.load", "torch.load", "torch.load", "torchvision.transforms.Resize", "transforms_list.append", "transforms_list.append", "transforms_list.append", "transforms_list.append", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "open", "list", "list", "nn.DataParallel.decoder.parameters", "p.numel", "p.numel", "state.items", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "utils.tb_visualizer.Visualizer.reset", "logging.getLogger.info", "train.set_lr", "logging.getLogger.info", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "len", "iter", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "time.time", "numpy.mean", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.RandomAffine", "torchvision.transforms.RandomCrop", "torchvision.transforms.CenterCrop", "len", "nn.DataParallel.decoder.parameters", "nn.DataParallel.image_encoder.last_module.parameters", "isinstance", "nn.DataParallel.train", "nn.DataParallel.eval", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "img_inputs.to.to", "gt.to.to", "loss_dict.keys", "data_loader.increase_loader_epoch", "utils.metrics.compute_metrics", "train.save_checkpoint", "numpy.mean", "v.to", "nn.DataParallel.", "label_loss.mean.mean", "label_loss.mean.item", "loss.item", "nn.DataParallel.zero_grad", "loss.backward", "torch.optim.Adam.step", "total_loss_dict[].append", "total_loss_dict.keys", "logging.getLogger.info", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "time.time", "utils.tb_visualizer.Visualizer.scalar_summary", "train.save_checkpoint", "torch.no_grad", "torch.no_grad", "torch.no_grad", "nn.DataParallel.", "model.label2_k_hots", "model.label2_k_hots", "utils.metrics.update_error_counts", "range", "numpy.mean", "cardinality_loss.mean.mean", "cardinality_loss.mean.item", "eos_loss.mean.mean", "eos_loss.mean.item", "time.time", "utils.tb_visualizer.Visualizer.scalar_summary", "model.label2_k_hots.size", "utils.metrics.update_error_counts", "utils.metrics.compute_metrics", "i_f1s.append", "len", "len", "pred_k_hots[].unsqueeze", "target_k_hots[].unsqueeze", "numpy.mean", "numpy.mean", "numpy.mean", "total_loss_dict.items", "total_loss_dict.items"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.make_dir", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.make_dir", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.make_dir", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.make_dir", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.model.get_model", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.tb_visualizer.Visualizer.close", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.get_loader", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.ADE20K.get_vocab", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.save_checkpoint", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.StreamToLogger.write", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.tb_visualizer.Visualizer.close", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.tb_visualizer.Visualizer.reset", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.set_lr", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.data_loader.increase_loader_epoch", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.compute_metrics", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.save_checkpoint", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.item", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.item", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.tb_visualizer.Visualizer.scalar_summary", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.train.save_checkpoint", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.model.label2_k_hots", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.model.label2_k_hots", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.update_error_counts", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.item", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.item", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.tb_visualizer.Visualizer.scalar_summary", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.update_error_counts", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.compute_metrics"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "global", "HALT_filename", ",", "CHECKPOINT_tempfile", "\n", "\n", "# Create model directory & other aux folders for logging", "\n", "where_to_save", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "args", ".", "dataset", ",", "args", ".", "model_name", ",", "args", ".", "image_model", ",", "args", ".", "experiment_name", ")", "\n", "checkpoints_dir", "=", "os", ".", "path", ".", "join", "(", "where_to_save", ",", "'checkpoints'", ")", "\n", "suffix", "=", "'_'", ".", "join", "(", "[", "args", ".", "dataset", ",", "args", ".", "model_name", ",", "str", "(", "args", ".", "seed", ")", "]", ")", "\n", "checkpoint_filename", "=", "os", ".", "path", ".", "join", "(", "checkpoints_dir", ",", "'_'", ".", "join", "(", "[", "suffix", ",", "'checkpoint'", "]", ")", ")", "\n", "print", "(", "checkpoint_filename", ")", "\n", "logs_dir", "=", "os", ".", "path", ".", "join", "(", "where_to_save", ",", "'logs'", ")", "\n", "tb_logs", "=", "os", ".", "path", ".", "join", "(", "where_to_save", ",", "'tb_logs'", ",", "args", ".", "dataset", ",", "\n", "args", ".", "model_name", "+", "'_'", "+", "str", "(", "args", ".", "seed", ")", ")", "\n", "make_dir", "(", "where_to_save", ")", "\n", "make_dir", "(", "logs_dir", ")", "\n", "make_dir", "(", "checkpoints_dir", ")", "\n", "make_dir", "(", "tb_logs", ")", "\n", "\n", "# Create loggers", "\n", "# stdout logger", "\n", "stdout_logger", "=", "logging", ".", "getLogger", "(", "'STDOUT'", ")", "\n", "stdout_logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s - %(threadName)s - %(levelname)s: %(message)s'", ")", "\n", "fh_out", "=", "logging", ".", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "logs_dir", ",", "'train_{}.log'", ".", "format", "(", "suffix", ")", ")", ")", "\n", "fh_out", ".", "setFormatter", "(", "formatter", ")", "\n", "stdout_logger", ".", "addHandler", "(", "fh_out", ")", "\n", "ch", "=", "logging", ".", "StreamHandler", "(", "stream", "=", "sys", ".", "stdout", ")", "\n", "ch", ".", "setFormatter", "(", "formatter", ")", "\n", "stdout_logger", ".", "addHandler", "(", "ch", ")", "\n", "# stderr logger", "\n", "stderr_logger", "=", "logging", ".", "getLogger", "(", "'STDERR'", ")", "\n", "fh_err", "=", "logging", ".", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "logs_dir", ",", "'train_{}.err'", ".", "format", "(", "suffix", ")", ")", ",", "mode", "=", "'w'", ")", "\n", "fh_err", ".", "setFormatter", "(", "formatter", ")", "\n", "stderr_logger", ".", "addHandler", "(", "fh_err", ")", "\n", "sl_stderr", "=", "StreamToLogger", "(", "stderr_logger", ",", "logging", ".", "ERROR", ")", "\n", "sys", ".", "stderr", "=", "sl_stderr", "\n", "\n", "# HALT file is used as a sign of job completion.", "\n", "# Check if no HALT file left from previous runs.", "\n", "HALT_filename", "=", "os", ".", "path", ".", "join", "(", "where_to_save", ",", "'HALT_{}'", ".", "format", "(", "suffix", ")", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "HALT_filename", ")", ":", "\n", "        ", "os", ".", "remove", "(", "HALT_filename", ")", "\n", "\n", "# Remove CHECKPOINT_tempfile", "\n", "", "CHECKPOINT_tempfile", "=", "checkpoint_filename", "+", "'.tmp.ckpt'", "\n", "if", "os", ".", "path", ".", "isfile", "(", "CHECKPOINT_tempfile", ")", ":", "\n", "        ", "os", ".", "remove", "(", "CHECKPOINT_tempfile", ")", "\n", "\n", "# Create tensorboard visualizer", "\n", "", "if", "args", ".", "tensorboard", ":", "\n", "        ", "logger", "=", "Visualizer", "(", "tb_logs", ",", "name", "=", "'visual_results'", ",", "resume", "=", "args", ".", "resume", ")", "\n", "\n", "# Check if we want to resume from last checkpoint of current model", "\n", "", "checkpoint", "=", "None", "\n", "if", "args", ".", "resume", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "checkpoint_filename", "+", "'.ckpt'", ")", ":", "\n", "            ", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_filename", "+", "'.ckpt'", ",", "map_location", "=", "map_loc", ")", "\n", "num_epochs", "=", "args", ".", "num_epochs", "\n", "args", "=", "checkpoint", "[", "'args'", "]", "\n", "args", ".", "num_epochs", "=", "num_epochs", "\n", "\n", "# Build data loader", "\n", "", "", "data_loaders", "=", "{", "}", "\n", "datasets", "=", "{", "}", "\n", "for", "split", "in", "[", "'train'", ",", "'val'", "]", ":", "\n", "\n", "        ", "transforms_list", "=", "[", "transforms", ".", "Resize", "(", "args", ".", "image_size", ")", "]", "\n", "\n", "# Image pre-processing", "\n", "if", "split", "==", "'train'", ":", "\n", "            ", "transforms_list", ".", "append", "(", "transforms", ".", "RandomHorizontalFlip", "(", ")", ")", "\n", "transforms_list", ".", "append", "(", "transforms", ".", "RandomAffine", "(", "degrees", "=", "10", ",", "translate", "=", "(", "0.1", ",", "0.1", ")", ")", ")", "\n", "transforms_list", ".", "append", "(", "transforms", ".", "RandomCrop", "(", "args", ".", "crop_size", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "transforms_list", ".", "append", "(", "transforms", ".", "CenterCrop", "(", "args", ".", "crop_size", ")", ")", "\n", "", "transforms_list", ".", "append", "(", "transforms", ".", "ToTensor", "(", ")", ")", "\n", "transforms_list", ".", "append", "(", "transforms", ".", "Normalize", "(", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "(", "0.229", ",", "0.224", ",", "0.225", ")", ")", ")", "\n", "transform", "=", "transforms", ".", "Compose", "(", "transforms_list", ")", "\n", "\n", "# Load dataset path", "\n", "datapaths", "=", "json", ".", "load", "(", "open", "(", "'../configs/datapaths.json'", ")", ")", "\n", "dataset_root", "=", "datapaths", "[", "args", ".", "dataset", "]", "\n", "data_loaders", "[", "split", "]", ",", "datasets", "[", "split", "]", "=", "get_loader", "(", "\n", "dataset", "=", "args", ".", "dataset", ",", "\n", "dataset_root", "=", "dataset_root", ",", "\n", "split", "=", "split", ",", "\n", "transform", "=", "transform", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "include_eos", "=", "(", "args", ".", "decoder", "!=", "'ff'", ")", ",", "\n", "shuffle", "=", "(", "split", "==", "'train'", ")", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "drop_last", "=", "(", "split", "==", "'train'", ")", ",", "\n", "shuffle_labels", "=", "args", ".", "shuffle_labels", ",", "\n", "seed", "=", "args", ".", "seed", ",", "\n", "checkpoint", "=", "checkpoint", ")", "\n", "stdout_logger", ".", "info", "(", "'Dataset {} split contains {} images'", ".", "format", "(", "\n", "split", ",", "len", "(", "datasets", "[", "split", "]", ")", ")", ")", "\n", "\n", "", "vocab_size", "=", "len", "(", "datasets", "[", "split", "]", ".", "get_vocab", "(", ")", ")", "\n", "stdout_logger", ".", "info", "(", "'Vocabulary size is {}'", ".", "format", "(", "vocab_size", ")", ")", "\n", "\n", "# Build the model", "\n", "model", "=", "get_model", "(", "args", ",", "vocab_size", ")", "\n", "\n", "# add model parameters", "\n", "if", "model", ".", "image_encoder", ".", "last_module", "is", "not", "None", ":", "\n", "        ", "params", "=", "list", "(", "model", ".", "decoder", ".", "parameters", "(", ")", ")", "+", "list", "(", "\n", "model", ".", "image_encoder", ".", "last_module", ".", "parameters", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "params", "=", "list", "(", "model", ".", "decoder", ".", "parameters", "(", ")", ")", "\n", "", "params_cnn", "=", "list", "(", "model", ".", "image_encoder", ".", "pretrained_net", ".", "parameters", "(", ")", ")", "\n", "\n", "n_p_cnn", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "params_cnn", "if", "p", ".", "requires_grad", ")", "\n", "n_p", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "params", "if", "p", ".", "requires_grad", ")", "\n", "total", "=", "n_p", "+", "n_p_cnn", "\n", "stdout_logger", ".", "info", "(", "\"CNN params: {}\"", ".", "format", "(", "n_p_cnn", ")", ")", "\n", "stdout_logger", ".", "info", "(", "\"decoder params: {}\"", ".", "format", "(", "n_p", ")", ")", "\n", "stdout_logger", ".", "info", "(", "\"total params: {}\"", ".", "format", "(", "total", ")", ")", "\n", "\n", "# encoder and decoder optimizers", "\n", "if", "params_cnn", "is", "not", "None", "and", "args", ".", "finetune_after", "==", "0", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "[", "{", "\n", "'params'", ":", "params", "\n", "}", ",", "{", "\n", "'params'", ":", "params_cnn", ",", "\n", "'lr'", ":", "args", ".", "learning_rate", "*", "args", ".", "scale_learning_rate_cnn", "\n", "}", "]", ",", "\n", "lr", "=", "args", ".", "learning_rate", ",", "\n", "weight_decay", "=", "args", ".", "weight_decay", ")", "\n", "keep_cnn_gradients", "=", "True", "\n", "stdout_logger", ".", "info", "(", "\"Fine tuning image encoder\"", ")", "\n", "", "else", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "params", ",", "lr", "=", "args", ".", "learning_rate", ")", "\n", "keep_cnn_gradients", "=", "False", "\n", "stdout_logger", ".", "info", "(", "\"Freezing image encoder\"", ")", "\n", "\n", "# early stopping and checkpoint", "\n", "", "es_best", "=", "{", "'o_f1'", ":", "0", ",", "'c_f1'", ":", "0", ",", "'i_f1'", ":", "0", ",", "'average'", ":", "0", "}", "\n", "epoch_best", "=", "{", "'o_f1'", ":", "-", "1", ",", "'c_f1'", ":", "-", "1", ",", "'i_f1'", ":", "-", "1", ",", "'average'", ":", "-", "1", "}", "\n", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "for", "state", "in", "optimizer", ".", "state", ".", "values", "(", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                    ", "state", "[", "k", "]", "=", "v", ".", "to", "(", "device", ")", "\n", "", "", "", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "es_best", "=", "checkpoint", "[", "'es_best'", "]", "\n", "epoch_best", "=", "checkpoint", "[", "'epoch_best'", "]", "\n", "\n", "", "if", "device", "!=", "'cpu'", "and", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "        ", "model", "=", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "if", "not", "hasattr", "(", "args", ",", "'current_epoch'", ")", ":", "\n", "        ", "args", ".", "current_epoch", "=", "0", "\n", "\n", "# Train the model", "\n", "", "decay_factor", "=", "1.0", "\n", "start_step", "=", "0", "if", "checkpoint", "is", "None", "else", "checkpoint", "[", "'current_step'", "]", "\n", "curr_pat", "=", "0", "if", "checkpoint", "is", "None", "else", "checkpoint", "[", "'current_pat'", "]", "\n", "for", "epoch", "in", "range", "(", "args", ".", "current_epoch", ",", "args", ".", "num_epochs", ")", ":", "\n", "\n", "# save current epoch for resuming", "\n", "        ", "if", "args", ".", "tensorboard", ":", "\n", "            ", "logger", ".", "reset", "(", ")", "\n", "\n", "# increase / decrease values for moving params", "\n", "", "if", "args", ".", "decay_lr", ":", "\n", "            ", "frac", "=", "epoch", "//", "args", ".", "lr_decay_every", "\n", "decay_factor", "=", "args", ".", "lr_decay_rate", "**", "frac", "\n", "new_lr", "=", "args", ".", "learning_rate", "*", "decay_factor", "\n", "stdout_logger", ".", "info", "(", "'Epoch %d. lr: %.5f'", "%", "(", "epoch", ",", "new_lr", ")", ")", "\n", "set_lr", "(", "optimizer", ",", "decay_factor", ")", "\n", "\n", "", "if", "args", ".", "finetune_after", "!=", "-", "1", "and", "args", ".", "finetune_after", "<", "epoch", "and", "not", "keep_cnn_gradients", "and", "params_cnn", "is", "not", "None", ":", "\n", "\n", "            ", "stdout_logger", ".", "info", "(", "\"Starting to fine tune CNN\"", ")", "\n", "# start with learning rates as they were (if decayed during training)", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "[", "{", "\n", "'params'", ":", "params", "\n", "}", ",", "{", "\n", "'params'", ":", "params_cnn", ",", "\n", "'lr'", ":", "decay_factor", "*", "args", ".", "learning_rate", "*", "args", ".", "scale_learning_rate_cnn", "\n", "}", "]", ",", "\n", "lr", "=", "decay_factor", "*", "args", ".", "learning_rate", ")", "\n", "keep_cnn_gradients", "=", "True", "\n", "\n", "", "for", "split", "in", "[", "'train'", ",", "'val'", "]", ":", "\n", "\n", "            ", "if", "split", "==", "'train'", ":", "\n", "                ", "model", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "eval", "(", ")", "\n", "", "total_step", "=", "len", "(", "data_loaders", "[", "split", "]", ")", "\n", "loader", "=", "iter", "(", "data_loaders", "[", "split", "]", ")", "\n", "\n", "total_loss_dict", "=", "{", "\n", "'label_loss'", ":", "[", "]", ",", "\n", "'eos_loss'", ":", "[", "]", ",", "\n", "'cardinality_loss'", ":", "[", "]", ",", "\n", "'loss'", ":", "[", "]", ",", "\n", "'o_f1'", ":", "[", "]", ",", "\n", "'c_f1'", ":", "[", "]", ",", "\n", "'i_f1'", ":", "[", "]", ",", "\n", "}", "\n", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "overall_error_counts", "=", "{", "\n", "'tp_c'", ":", "0", ",", "\n", "'fp_c'", ":", "0", ",", "\n", "'fn_c'", ":", "0", ",", "\n", "'tn_c'", ":", "0", ",", "\n", "'tp_all'", ":", "0", ",", "\n", "'fp_all'", ":", "0", ",", "\n", "'fn_all'", ":", "0", "\n", "}", "\n", "\n", "i", "=", "0", "if", "split", "==", "'val'", "else", "start_step", "\n", "for", "info", "in", "loader", ":", "\n", "                ", "img_inputs", ",", "gt", "=", "info", "\n", "\n", "# adapt gts by adding pad_value to match maxnumlabel length", "\n", "gt", "=", "[", "\n", "sublist", "+", "[", "vocab_size", "-", "1", "]", "*", "(", "args", ".", "maxnumlabels", "-", "len", "(", "sublist", ")", ")", "\n", "for", "sublist", "in", "gt", "\n", "]", "\n", "gt", "=", "torch", ".", "LongTensor", "(", "gt", ")", "\n", "\n", "# move to device", "\n", "img_inputs", "=", "img_inputs", ".", "to", "(", "device", ")", "\n", "gt", "=", "gt", ".", "to", "(", "device", ")", "\n", "\n", "loss_dict", "=", "{", "}", "\n", "\n", "if", "split", "==", "'val'", ":", "\n", "                    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# get losses and label predictions", "\n", "                        ", "_", ",", "predictions", "=", "model", "(", "\n", "img_inputs", ",", "\n", "maxnumlabels", "=", "args", ".", "maxnumlabels", ",", "\n", "compute_losses", "=", "False", ",", "\n", "compute_predictions", "=", "True", ")", "\n", "\n", "# convert model predictions and targets to k-hots", "\n", "pred_k_hots", "=", "label2_k_hots", "(", "\n", "predictions", ",", "vocab_size", "-", "1", ",", "remove_eos", "=", "(", "args", ".", "decoder", "!=", "'ff'", ")", ")", "\n", "target_k_hots", "=", "label2_k_hots", "(", "\n", "gt", ",", "vocab_size", "-", "1", ",", "remove_eos", "=", "(", "args", ".", "decoder", "!=", "'ff'", ")", ")", "\n", "\n", "# update overall and per class error types", "\n", "update_error_counts", "(", "overall_error_counts", ",", "pred_k_hots", ",", "target_k_hots", ")", "\n", "\n", "# update per image error types", "\n", "i_f1s", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "pred_k_hots", ".", "size", "(", "0", ")", ")", ":", "\n", "                            ", "image_error_counts", "=", "{", "\n", "'tp_c'", ":", "0", ",", "\n", "'fp_c'", ":", "0", ",", "\n", "'fn_c'", ":", "0", ",", "\n", "'tn_c'", ":", "0", ",", "\n", "'tp_all'", ":", "0", ",", "\n", "'fp_all'", ":", "0", ",", "\n", "'fn_all'", ":", "0", "\n", "}", "\n", "update_error_counts", "(", "image_error_counts", ",", "pred_k_hots", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "\n", "target_k_hots", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "image_metrics", "=", "compute_metrics", "(", "\n", "image_error_counts", ",", "which_metrics", "=", "[", "'f1'", "]", ")", "\n", "i_f1s", ".", "append", "(", "image_metrics", "[", "'f1'", "]", ")", "\n", "\n", "", "loss_dict", "[", "'i_f1'", "]", "=", "np", ".", "mean", "(", "i_f1s", ")", "\n", "del", "predictions", ",", "pred_k_hots", ",", "target_k_hots", ",", "image_metrics", "\n", "\n", "", "", "else", ":", "\n", "                    ", "losses", ",", "_", "=", "model", "(", "\n", "img_inputs", ",", "\n", "gt", ",", "\n", "maxnumlabels", "=", "args", ".", "maxnumlabels", ",", "\n", "keep_cnn_gradients", "=", "keep_cnn_gradients", ",", "\n", "compute_losses", "=", "True", ")", "\n", "\n", "# label loss", "\n", "label_loss", "=", "losses", "[", "'label_loss'", "]", "\n", "label_loss", "=", "label_loss", ".", "mean", "(", ")", "\n", "loss_dict", "[", "'label_loss'", "]", "=", "label_loss", ".", "item", "(", ")", "\n", "\n", "# cardinality loss", "\n", "if", "args", ".", "pred_cardinality", "!=", "'none'", ":", "\n", "                        ", "cardinality_loss", "=", "losses", "[", "'cardinality_loss'", "]", "\n", "cardinality_loss", "=", "cardinality_loss", ".", "mean", "(", ")", "\n", "loss_dict", "[", "'cardinality_loss'", "]", "=", "cardinality_loss", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "                        ", "cardinality_loss", "=", "0", "\n", "\n", "# eos loss", "\n", "", "if", "args", ".", "perminv", ":", "\n", "                        ", "eos_loss", "=", "losses", "[", "'eos_loss'", "]", "\n", "eos_loss", "=", "eos_loss", ".", "mean", "(", ")", "\n", "loss_dict", "[", "'eos_loss'", "]", "=", "eos_loss", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "                        ", "eos_loss", "=", "0", "\n", "\n", "# total loss", "\n", "", "loss", "=", "args", ".", "loss_weight", "[", "0", "]", "*", "label_loss", "+", "args", ".", "loss_weight", "[", "1", "]", "*", "cardinality_loss", "+", "args", ".", "loss_weight", "[", "2", "]", "*", "eos_loss", "\n", "loss_dict", "[", "'loss'", "]", "=", "loss", ".", "item", "(", ")", "\n", "\n", "# optimizer step", "\n", "model", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "del", "loss", ",", "losses", "\n", "", "del", "img_inputs", "\n", "\n", "for", "key", "in", "loss_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "total_loss_dict", "[", "key", "]", ".", "append", "(", "loss_dict", "[", "key", "]", ")", "\n", "\n", "# Print log info", "\n", "", "if", "args", ".", "log_step", "!=", "-", "1", "and", "i", "%", "args", ".", "log_step", "==", "0", ":", "\n", "                    ", "elapsed_time", "=", "time", ".", "time", "(", ")", "-", "start", "\n", "lossesstr", "=", "\"\"", "\n", "for", "k", "in", "total_loss_dict", ".", "keys", "(", ")", ":", "\n", "                        ", "if", "len", "(", "total_loss_dict", "[", "k", "]", ")", "==", "0", ":", "\n", "                            ", "continue", "\n", "", "this_one", "=", "\"%s: %.4f\"", "%", "(", "k", ",", "np", ".", "mean", "(", "total_loss_dict", "[", "k", "]", "[", "-", "args", ".", "log_step", ":", "]", ")", ")", "\n", "lossesstr", "+=", "this_one", "+", "', '", "\n", "# this only displays nll loss on captions, the rest of losses will", "\n", "# be in tensorboard logs", "\n", "", "strtoprint", "=", "'Split: %s, Epoch [%d/%d], Step [%d/%d], Losses: %sTime: %.4f'", "%", "(", "\n", "split", ",", "epoch", ",", "args", ".", "num_epochs", ",", "i", ",", "total_step", ",", "lossesstr", ",", "elapsed_time", ")", "\n", "stdout_logger", ".", "info", "(", "strtoprint", ")", "\n", "if", "args", ".", "tensorboard", "and", "split", "==", "'train'", ":", "\n", "                        ", "logger", ".", "scalar_summary", "(", "\n", "mode", "=", "split", "+", "'_iter'", ",", "\n", "epoch", "=", "total_step", "*", "epoch", "+", "i", ",", "\n", "**", "{", "\n", "k", ":", "np", ".", "mean", "(", "v", "[", "-", "args", ".", "log_step", ":", "]", ")", "\n", "for", "k", ",", "v", "in", "total_loss_dict", ".", "items", "(", ")", "\n", "if", "v", "\n", "}", ")", "\n", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "i", "+=", "1", "\n", "\n", "", "if", "split", "==", "'train'", ":", "\n", "                ", "increase_loader_epoch", "(", "data_loaders", "[", "'train'", "]", ")", "\n", "start_step", "=", "0", "\n", "\n", "", "if", "split", "==", "'val'", ":", "\n", "                ", "overal_metrics", "=", "compute_metrics", "(", "overall_error_counts", ",", "[", "'f1'", ",", "'c_f1'", "]", ",", "weights", "=", "None", ")", "\n", "\n", "total_loss_dict", "[", "'o_f1'", "]", "=", "overal_metrics", "[", "'f1'", "]", "\n", "total_loss_dict", "[", "'c_f1'", "]", "=", "overal_metrics", "[", "'c_f1'", "]", "\n", "\n", "if", "args", ".", "tensorboard", ":", "\n", "# 1. Log scalar values (scalar summary)", "\n", "                    ", "logger", ".", "scalar_summary", "(", "\n", "mode", "=", "split", ",", "\n", "epoch", "=", "epoch", ",", "\n", "**", "{", "k", ":", "np", ".", "mean", "(", "v", ")", "\n", "for", "k", ",", "v", "in", "total_loss_dict", ".", "items", "(", ")", "\n", "if", "v", "}", ")", "\n", "\n", "# early stopping", "\n", "", "", "", "metric_average", "=", "0", "\n", "best_at_checkpoint_metric", "=", "False", "\n", "if", "args", ".", "metric_to_checkpoint", "!=", "'average'", ":", "\n", "            ", "es_value", "=", "np", ".", "mean", "(", "total_loss_dict", "[", "args", ".", "metric_to_checkpoint", "]", ")", "\n", "if", "es_value", ">", "es_best", "[", "args", ".", "metric_to_checkpoint", "]", ":", "\n", "                ", "es_best", "[", "args", ".", "metric_to_checkpoint", "]", "=", "es_value", "\n", "epoch_best", "[", "args", ".", "metric_to_checkpoint", "]", "=", "epoch", "\n", "best_at_checkpoint_metric", "=", "True", "\n", "save_checkpoint", "(", "model", ",", "optimizer", ",", "args", ",", "es_best", ",", "epoch_best", ",", "0", ",", "0", ",", "\n", "'{}.best.{}'", ".", "format", "(", "checkpoint_filename", ",", "args", ".", "metric_to_checkpoint", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "metric", "in", "[", "'o_f1'", ",", "'c_f1'", ",", "'i_f1'", "]", ":", "\n", "                ", "es_value", "=", "np", ".", "mean", "(", "total_loss_dict", "[", "metric", "]", ")", "\n", "metric_average", "+=", "es_value", "\n", "", "metric_average", "/=", "3", "\n", "if", "metric_average", ">", "es_best", "[", "'average'", "]", ":", "\n", "                ", "es_best", "[", "'average'", "]", "=", "metric_average", "\n", "epoch_best", "[", "'average'", "]", "=", "epoch", "\n", "if", "'average'", "==", "args", ".", "metric_to_checkpoint", ":", "\n", "                    ", "best_at_checkpoint_metric", "=", "True", "\n", "save_checkpoint", "(", "model", ",", "optimizer", ",", "args", ",", "es_best", ",", "epoch_best", ",", "0", ",", "0", ",", "\n", "'{}.best.average'", ".", "format", "(", "checkpoint_filename", ")", ")", "\n", "\n", "", "", "", "if", "best_at_checkpoint_metric", ":", "\n", "            ", "curr_pat", "=", "0", "\n", "", "else", ":", "\n", "            ", "curr_pat", "+=", "1", "\n", "\n", "", "args", ".", "current_epoch", "=", "epoch", "+", "1", "# Save the epoch at which the model needs to start", "\n", "save_checkpoint", "(", "model", ",", "optimizer", ",", "args", ",", "es_best", ",", "epoch_best", ",", "0", ",", "curr_pat", ",", "\n", "checkpoint_filename", ")", "\n", "stdout_logger", ".", "info", "(", "'Saved checkpoint for epoch {}.'", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "if", "curr_pat", ">", "args", ".", "patience", ":", "\n", "            ", "break", "\n", "\n", "# Mark job as finished", "\n", "", "", "f", "=", "open", "(", "HALT_filename", ",", "'w'", ")", "\n", "for", "metric", "in", "es_best", ".", "keys", "(", ")", ":", "\n", "        ", "f", ".", "write", "(", "'{}:{}\\n'", ".", "format", "(", "metric", ",", "es_best", "[", "metric", "]", ")", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "\n", "if", "args", ".", "tensorboard", ":", "\n", "        ", "logger", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.model.SetPred.__init__": [[240, 277], ["torch.Module.__init__", "math.log"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "decoder", ",", "\n", "image_encoder", ",", "\n", "maxnumlabels", ",", "\n", "crit", "=", "None", ",", "\n", "crit_eos", "=", "None", ",", "\n", "crit_cardinality", "=", "None", ",", "\n", "pad_value", "=", "0", ",", "\n", "perminv", "=", "True", ",", "\n", "decoder_ff", "=", "False", ",", "\n", "th", "=", "0.5", ",", "\n", "loss_label", "=", "'bce'", ",", "\n", "replacement", "=", "False", ",", "\n", "card_type", "=", "'none'", ",", "\n", "dataset", "=", "'voc'", ",", "\n", "U", "=", "2.36", ",", "\n", "use_empty_set", "=", "False", ",", "\n", "eps", "=", "1e-8", ")", ":", "\n", "\n", "        ", "super", "(", "SetPred", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "image_encoder", "=", "image_encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "decoder_ff", "=", "decoder_ff", "\n", "self", ".", "maxnumlabels", "=", "maxnumlabels", "\n", "self", ".", "crit", "=", "crit", "\n", "self", ".", "th", "=", "th", "\n", "self", ".", "perminv", "=", "perminv", "\n", "self", ".", "pad_value", "=", "pad_value", "\n", "self", ".", "crit_eos", "=", "crit_eos", "\n", "self", ".", "crit_cardinality", "=", "crit_cardinality", "\n", "self", ".", "loss_label", "=", "loss_label", "\n", "self", ".", "replacement", "=", "replacement", "\n", "self", ".", "card_type", "=", "card_type", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "u_term", "=", "math", ".", "log", "(", "U", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "use_empty_set", "=", "use_empty_set", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.model.SetPred.forward": [[278, 413], ["model.SetPred.image_encoder", "model.SetPred.decoder", "model.SetPred.decoder.sample", "model.label2_k_hots", "label2_k_hots.sum().unsqueeze", "model.SetPred.crit", "model.predictions_to_idxs", "model.mask_from_eos", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "model.SetPred.crit_cardinality", "torch.log", "torch.log", "torch.log", "torch.log", "torch.from_numpy().to().unsqueeze().float", "torch.from_numpy().to().unsqueeze().float", "torch.from_numpy().to().unsqueeze().float", "torch.from_numpy().to().unsqueeze().float", "torch.functional.softmax", "torch.functional.softmax", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "label_target.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.max", "torch.max", "torch.max", "torch.max", "model.label2_k_hots", "model.SetPred.crit", "model.SetPred.crit_eos", "model.SetPred.decoder", "label_logits.view", "label_target.view", "model.SetPred.crit", "label2_k_hots.sum", "utils.metrics.DC", "numpy.array", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "eos_head.float().unsqueeze", "eos_target.float", "list", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.zeros.unsqueeze().to().long", "torch.zeros.unsqueeze().to().long", "label_logits.size", "label_logits.size", "range", "eos_head.float", "eos_head.float().sum", "label2_k_hots.sum().unsqueeze.squeeze", "torch.nn.functional.log_softmax.size", "torch.nn.functional.log_softmax.size", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.zeros.unsqueeze().to", "torch.zeros.unsqueeze().to", "eos_pos.float", "eos_head.float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.zeros.unsqueeze", "torch.zeros.unsqueeze", "eos_head.float"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.DecoderTransformer.sample", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.model.label2_k_hots", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.model.predictions_to_idxs", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.model.mask_from_eos", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.model.label2_k_hots", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.DC"], ["", "def", "forward", "(", "self", ",", "img_inputs", ",", "label_target", "=", "None", ",", "maxnumlabels", "=", "0", ",", "keep_cnn_gradients", "=", "False", ",", "compute_losses", "=", "False", ",", "compute_predictions", "=", "False", ")", ":", "\n", "\n", "        ", "losses", "=", "{", "}", "\n", "predictions", "=", "None", "\n", "\n", "assert", "(", "label_target", "is", "not", "None", "and", "compute_losses", ")", "or", "(", "label_target", "is", "None", "and", "not", "compute_losses", ")", "\n", "\n", "if", "not", "compute_losses", "and", "not", "compute_predictions", ":", "\n", "            ", "return", "losses", ",", "predictions", "\n", "\n", "# encode image", "\n", "", "img_features", "=", "self", ".", "image_encoder", "(", "img_inputs", ",", "keep_cnn_gradients", ")", "\n", "\n", "if", "self", ".", "decoder_ff", ":", "\n", "# use ff decoder to predict set of labels and cardinality", "\n", "            ", "label_logits", ",", "cardinality_logits", "=", "self", ".", "decoder", "(", "img_features", ")", "\n", "\n", "if", "compute_losses", ":", "\n", "# label target to k_hot", "\n", "                ", "target_k_hot", "=", "label2_k_hots", "(", "label_target", ",", "self", ".", "pad_value", ")", "\n", "# cardinality target", "\n", "cardinality_target", "=", "target_k_hot", ".", "sum", "(", "dim", "=", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# compute labels loss", "\n", "losses", "[", "'label_loss'", "]", "=", "self", ".", "crit", "(", "label_logits", ",", "target_k_hot", ")", "\n", "\n", "# compute cardinality loss if needed", "\n", "if", "self", ".", "crit_cardinality", "is", "not", "None", ":", "\n", "# subtract 1 from num_target to match class idxs (1st label corresponds to class 0) only", "\n", "# 1st label corresponds to 0 only if use_empty_set is false", "\n", "# otherwise, 1st label corresponds to 1", "\n", "                    ", "offset", "=", "0", "if", "self", ".", "use_empty_set", "else", "1", "\n", "losses", "[", "'cardinality_loss'", "]", "=", "self", ".", "crit_cardinality", "(", "\n", "cardinality_logits", ",", "(", "cardinality_target", ".", "squeeze", "(", ")", "-", "offset", ")", ".", "long", "(", ")", ")", "\n", "\n", "", "", "if", "compute_predictions", ":", "\n", "# consider cardinality", "\n", "                ", "if", "self", ".", "card_type", "==", "'dc'", "and", "self", ".", "loss_label", "==", "'bce'", ":", "\n", "                    ", "offset", "=", "0", "if", "self", ".", "use_empty_set", "else", "1", "\n", "cardinality", "=", "torch", ".", "log", "(", "DC", "(", "cardinality_logits", ",", "dataset", "=", "self", ".", "dataset", ")", ")", "\n", "u_term", "=", "np", ".", "array", "(", "list", "(", "range", "(", "cardinality", ".", "size", "(", "-", "1", ")", ")", ")", ")", "+", "offset", "\n", "u_term", "=", "u_term", "*", "self", ".", "u_term", "\n", "u_term", "=", "torch", ".", "from_numpy", "(", "u_term", ")", ".", "to", "(", "device", ")", ".", "unsqueeze", "(", "0", ")", ".", "float", "(", ")", "\n", "cardinality", "=", "cardinality", "+", "u_term", "\n", "", "elif", "self", ".", "card_type", "==", "'cat'", ":", "\n", "                    ", "cardinality", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "cardinality_logits", "+", "self", ".", "eps", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                    ", "cardinality", "=", "None", "\n", "\n", "# apply nonlinearity to label logits", "\n", "", "if", "self", ".", "loss_label", "==", "'td'", ":", "\n", "                    ", "label_probs", "=", "nn", ".", "functional", ".", "softmax", "(", "label_logits", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                    ", "label_probs", "=", "torch", ".", "sigmoid", "(", "label_logits", ")", "\n", "\n", "# get label ids", "\n", "", "predictions", "=", "predictions_to_idxs", "(", "\n", "label_probs", ",", "\n", "maxnumlabels", ",", "\n", "self", ".", "pad_value", ",", "\n", "th", "=", "self", ".", "th", ",", "\n", "cardinality_prediction", "=", "cardinality", ",", "\n", "which_loss", "=", "self", ".", "loss_label", ",", "\n", "accumulate_probs", "=", "self", ".", "card_type", "==", "'dc'", "and", "self", ".", "loss_label", "==", "'bce'", ",", "\n", "use_empty_set", "=", "self", ".", "use_empty_set", ")", "\n", "\n", "", "", "else", ":", "# auto-regressive models", "\n", "\n", "# use auto-regressive decoder to predict labels (sample function)", "\n", "# output label_logits is only used to compute losses in case of self.perminv (no teacher forcing)", "\n", "# predictions output is used for all auto-regressive models", "\n", "            ", "predictions", ",", "label_logits", "=", "self", ".", "decoder", ".", "sample", "(", "\n", "img_features", ",", "\n", "None", ",", "\n", "first_token_value", "=", "0", ",", "\n", "replacement", "=", "self", ".", "replacement", ")", "\n", "\n", "if", "compute_predictions", ":", "\n", "# mask labels after finding eos (cardinality)", "\n", "                ", "sample_mask", "=", "mask_from_eos", "(", "predictions", ",", "eos_value", "=", "0", ",", "mult_before", "=", "False", ")", "\n", "predictions", "[", "sample_mask", "==", "0", "]", "=", "self", ".", "pad_value", "\n", "", "else", ":", "\n", "                ", "predictions", "=", "None", "\n", "\n", "", "if", "compute_losses", ":", "\n", "# add dummy first word to sequence and remove last", "\n", "                ", "first_word", "=", "torch", ".", "zeros", "(", "label_target", ".", "size", "(", "0", ")", ")", "\n", "shift_target", "=", "torch", ".", "cat", "(", "[", "first_word", ".", "unsqueeze", "(", "-", "1", ")", ".", "to", "(", "device", ")", ".", "long", "(", ")", ",", "label_target", "]", ",", "\n", "-", "1", ")", "[", ":", ",", ":", "-", "1", "]", "\n", "if", "self", ".", "perminv", ":", "\n", "# autoregressive mode for decoder when training with permutation invariant objective", "\n", "# e.g. lstmset and tfset", "\n", "\n", "# apply softmax nonlinearity before pooling across timesteps", "\n", "                    ", "label_probs", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "label_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# find idxs for eos label", "\n", "# eos probability is the one assigned to the first position of the softmax", "\n", "# this is used with bce loss only", "\n", "eos", "=", "label_probs", "[", ":", ",", ":", ",", "0", "]", "\n", "eos_pos", "=", "(", "label_target", "==", "0", ")", "# all zeros except position where eos is in the gt", "\n", "eos_head", "=", "(", "(", "label_target", "!=", "self", ".", "pad_value", ")", "&", "(", "label_target", "!=", "0", ")", ")", "# 1s for gt label positions, 0s starting from eos position in the gt", "\n", "eos_target", "=", "~", "eos_head", "# 0s for gt label positions, 1s starting from eos position in the gt", "\n", "\n", "# select transformer steps to pool (steps corresponding to set elements, i.e. labels)", "\n", "label_probs", "=", "label_probs", "*", "eos_head", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "# pool", "\n", "label_probs", ",", "_", "=", "torch", ".", "max", "(", "label_probs", ",", "dim", "=", "1", ")", "\n", "\n", "# compute label loss", "\n", "target_k_hot", "=", "label2_k_hots", "(", "label_target", ",", "self", ".", "pad_value", ",", "remove_eos", "=", "True", ")", "\n", "loss", "=", "self", ".", "crit", "(", "label_probs", "[", ":", ",", "1", ":", "]", ",", "target_k_hot", ")", "\n", "losses", "[", "'label_loss'", "]", "=", "loss", "\n", "\n", "# compute eos loss", "\n", "eos_loss", "=", "self", ".", "crit_eos", "(", "eos", ",", "eos_target", ".", "float", "(", ")", ")", "\n", "# eos loss is computed for all timesteps <= eos in gt and", "\n", "# equally penalizes the head (all 0s) and the true eos position (1)", "\n", "losses", "[", "'eos_loss'", "]", "=", "0.5", "*", "(", "eos_loss", "*", "eos_pos", ".", "float", "(", ")", ")", ".", "sum", "(", "1", ")", "+", "0.5", "*", "(", "eos_loss", "*", "eos_head", ".", "float", "(", ")", ")", ".", "sum", "(", "1", ")", "/", "(", "\n", "eos_head", ".", "float", "(", ")", ".", "sum", "(", "1", ")", "+", "self", ".", "eps", ")", "\n", "\n", "", "else", ":", "\n", "# other autoregressive models", "\n", "# we need to recompute logits using teacher forcing (forward pass)", "\n", "                    ", "label_logits", ",", "_", "=", "self", ".", "decoder", "(", "img_features", ",", "None", ",", "shift_target", ")", "\n", "label_logits_v", "=", "label_logits", ".", "view", "(", "label_logits", ".", "size", "(", "0", ")", "*", "label_logits", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "\n", "# compute label loss", "\n", "label_target_v", "=", "label_target", ".", "view", "(", "-", "1", ")", "\n", "loss", "=", "self", ".", "crit", "(", "label_logits_v", ",", "label_target_v", ")", "\n", "losses", "[", "'label_loss'", "]", "=", "loss", "\n", "\n", "", "", "", "return", "losses", ",", "predictions", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.model.label2_k_hots": [[18, 40], ["torch.unsqueeze", "torch.unsqueeze", "torch.FloatTensor().zero_().to", "torch.FloatTensor().zero_().to", "torch.FloatTensor().zero_().to.scatter_", "torch.FloatTensor().zero_().to.max", "type", "numpy.array", "torch.from_numpy().to", "torch.from_numpy().to", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.from_numpy", "torch.from_numpy", "torch.FloatTensor", "torch.FloatTensor", "torch.from_numpy().to.size", "torch.from_numpy().to.size", "len", "len", "max"], "function", ["None"], ["def", "label2_k_hots", "(", "labels", ",", "pad_value", ",", "remove_eos", "=", "False", ")", ":", "\n", "# labels is a list of (possibly variable length) lists.", "\n", "# labels are numpy array", "\n", "    ", "if", "type", "(", "labels", ")", "==", "list", ":", "\n", "        ", "tmp", "=", "np", ".", "array", "(", "[", "i", "+", "[", "pad_value", "]", "*", "(", "len", "(", "max", "(", "labels", ",", "key", "=", "len", ")", ")", "-", "len", "(", "i", ")", ")", "for", "i", "in", "labels", "]", ")", "\n", "labels", "=", "torch", ".", "from_numpy", "(", "tmp", ")", ".", "to", "(", "device", ")", "\n", "\n", "# input labels to one hot vector", "\n", "", "inp_", "=", "torch", ".", "unsqueeze", "(", "labels", ",", "2", ")", "\n", "k_hots", "=", "torch", ".", "FloatTensor", "(", "labels", ".", "size", "(", "0", ")", ",", "labels", ".", "size", "(", "1", ")", ",", "pad_value", "+", "1", ")", ".", "zero_", "(", ")", ".", "to", "(", "device", ")", "\n", "k_hots", ".", "scatter_", "(", "2", ",", "inp_", ",", "1", ")", "\n", "k_hots", ",", "_", "=", "k_hots", ".", "max", "(", "dim", "=", "1", ")", "\n", "\n", "# remove pad position", "\n", "k_hots", "=", "k_hots", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "# handle eos", "\n", "if", "remove_eos", ":", "\n", "# this is used by tfset/lstmset when computing losses and", "\n", "# by all auto-regressive models when computing f1 metrics", "\n", "        ", "k_hots", "=", "k_hots", "[", ":", ",", "1", ":", "]", "\n", "", "return", "k_hots", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.model.mask_from_eos": [[42, 59], ["torch.ones().to().byte", "torch.ones().to().byte", "torch.ones().to().byte", "torch.ones().to().byte", "range", "prediction.size", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "prediction.size", "prediction.size"], "function", ["None"], ["", "def", "mask_from_eos", "(", "prediction", ",", "eos_value", ",", "mult_before", "=", "True", ")", ":", "\n", "    ", "mask", "=", "torch", ".", "ones", "(", "prediction", ".", "size", "(", ")", ")", ".", "to", "(", "device", ")", ".", "byte", "(", ")", "\n", "mask_aux", "=", "torch", ".", "ones", "(", "prediction", ".", "size", "(", "0", ")", ")", ".", "to", "(", "device", ")", ".", "byte", "(", ")", "\n", "\n", "# find eos in label prediction", "\n", "for", "idx", "in", "range", "(", "prediction", ".", "size", "(", "1", ")", ")", ":", "\n", "# force mask to have 1s in the first position to avoid division", "\n", "# by 0 when predictions start with eos", "\n", "        ", "if", "idx", "==", "0", ":", "\n", "            ", "continue", "\n", "", "if", "mult_before", ":", "\n", "            ", "mask", "[", ":", ",", "idx", "]", "=", "mask", "[", ":", ",", "idx", "]", "*", "mask_aux", "\n", "mask_aux", "=", "mask_aux", "*", "(", "prediction", "[", ":", ",", "idx", "]", "!=", "eos_value", ")", "\n", "", "else", ":", "\n", "            ", "mask_aux", "=", "mask_aux", "*", "(", "prediction", "[", ":", ",", "idx", "]", "!=", "eos_value", ")", "\n", "mask", "[", ":", ",", "idx", "]", "=", "mask", "[", ":", ",", "idx", "]", "*", "mask_aux", "\n", "", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.model.predictions_to_idxs": [[61, 125], ["torch.topk", "torch.topk", "idxs.clone", "torch.ones().to().byte", "torch.ones().to().byte", "range", "torch.max", "torch.max", "torch.ones().to().byte", "torch.ones().to().byte", "torch.ones().to().byte", "torch.ones().to().byte", "range", "probs.size", "range", "torch.ones().to().byte.size", "torch.ones().to", "torch.ones().to", "torch.sum", "torch.sum", "cardinality_prediction.size", "torch.sum", "torch.sum", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.log", "torch.log", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "probs.size", "probs.size", "torch.ones().to().byte.size"], "function", ["None"], ["", "def", "predictions_to_idxs", "(", "label_logits", ",", "\n", "maxnumlabels", ",", "\n", "pad_value", ",", "\n", "th", "=", "1", ",", "\n", "cardinality_prediction", "=", "None", ",", "\n", "which_loss", "=", "'bce'", ",", "\n", "accumulate_probs", "=", "False", ",", "\n", "use_empty_set", "=", "False", ")", ":", "\n", "\n", "    ", "assert", "th", ">", "0", "and", "th", "<=", "1", "\n", "\n", "\n", "card_offset", "=", "0", "if", "use_empty_set", "else", "1", "\n", "\n", "# select topk elements", "\n", "probs", ",", "idxs", "=", "torch", ".", "topk", "(", "label_logits", ",", "k", "=", "maxnumlabels", ",", "dim", "=", "1", ",", "largest", "=", "True", ",", "sorted", "=", "True", ")", "\n", "idxs_clone", "=", "idxs", ".", "clone", "(", ")", "\n", "\n", "# mask to identify elements within the top-maxnumlabel ones which satisfy the threshold th", "\n", "if", "which_loss", "==", "'td'", ":", "\n", "# cumulative threshold", "\n", "        ", "mask", "=", "torch", ".", "ones", "(", "probs", ".", "size", "(", ")", ")", ".", "to", "(", "device", ")", ".", "byte", "(", ")", "\n", "for", "idx", "in", "range", "(", "probs", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "mask_step", "=", "torch", ".", "sum", "(", "probs", "[", ":", ",", "0", ":", "idx", "]", ",", "dim", "=", "-", "1", ")", "<", "th", "\n", "mask", "[", ":", ",", "idx", "]", "=", "mask", "[", ":", ",", "idx", "]", "*", "mask_step", "\n", "", "", "else", ":", "\n", "# probility threshold", "\n", "        ", "mask", "=", "(", "probs", ">", "th", ")", ".", "byte", "(", ")", "\n", "\n", "# if the model has cardinality prediction", "\n", "", "if", "cardinality_prediction", "is", "not", "None", ":", "\n", "\n", "# get the argmax for each element in the batch to get the cardinality", "\n", "# (note that the output is N - 1, e.g. argmax = 0 means that there's 1 element)", "\n", "# unless we are in the empty set case, e.g. argmax = 0 means there there are 0 elements", "\n", "\n", "        ", "if", "accumulate_probs", ":", "\n", "            ", "for", "c", "in", "range", "(", "cardinality_prediction", ".", "size", "(", "-", "1", ")", ")", ":", "\n", "                ", "value", "=", "torch", ".", "sum", "(", "torch", ".", "log", "(", "probs", "[", ":", ",", "0", ":", "c", "+", "1", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "cardinality_prediction", "[", ":", ",", "c", "]", "+=", "value", "\n", "\n", "# select cardinality", "\n", "", "", "_", ",", "card_idx", "=", "torch", ".", "max", "(", "cardinality_prediction", ",", "dim", "=", "-", "1", ")", "\n", "\n", "mask", "=", "torch", ".", "ones", "(", "probs", ".", "size", "(", ")", ")", ".", "to", "(", "device", ")", ".", "byte", "(", ")", "\n", "aux_mask", "=", "torch", ".", "ones", "(", "mask", ".", "size", "(", "0", ")", ")", ".", "to", "(", "device", ")", ".", "byte", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "mask", ".", "size", "(", "-", "1", ")", ")", ":", "\n", "# If the cardinality prediction is higher than i, it means that from this point", "\n", "# on the mask must be 0. Predicting 0 cardinality means 0 objects when", "\n", "# use_empty_set=True and 1 object when use_empty_set=False", "\n", "# real cardinality value is", "\n", "            ", "above_cardinality", "=", "(", "i", "<", "card_idx", "+", "card_offset", ")", "\n", "# multiply the auxiliar mask with this condition", "\n", "# (once you multiply by 0, the following entries will also be 0)", "\n", "aux_mask", "=", "aux_mask", "*", "above_cardinality", "\n", "mask", "[", ":", ",", "i", "]", "=", "aux_mask", "\n", "", "", "else", ":", "\n", "        ", "if", "not", "use_empty_set", ":", "\n", "            ", "mask", "[", ":", ",", "0", "]", "=", "1", "\n", "\n", "", "", "idxs_clone", "[", "mask", "==", "0", "]", "=", "pad_value", "\n", "\n", "return", "idxs_clone", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.model.get_model": [[127, 236], ["modules.encoder.EncoderCNN", "print", "model.SetPred", "print", "modules.ff_decoder.FFDecoder", "utils.metrics.softIoULoss", "utils.metrics.targetDistLoss", "print", "utils.metrics.DCLoss", "print", "modules.rnn_decoder.DecoderRNN", "torch.BCEWithLogitsLoss", "torch.BCELoss", "torch.BCELoss", "torch.CrossEntropyLoss", "print", "torch.CrossEntropyLoss", "print", "print", "modules.transformer_decoder.DecoderTransformer"], "function", ["None"], ["", "def", "get_model", "(", "args", ",", "vocab_size", ")", ":", "\n", "\n", "# build image encoder", "\n", "    ", "encoder_image", "=", "EncoderCNN", "(", "args", ".", "embed_size", ",", "args", ".", "dropout_encoder", ",", "\n", "args", ".", "image_model", ")", "\n", "\n", "use_empty_set", "=", "(", "True", "if", "args", ".", "dataset", "in", "[", "'coco'", ",", "'nuswide'", "]", "else", "False", ")", "\n", "\n", "# build set predictor", "\n", "if", "args", ".", "decoder", "==", "'ff'", ":", "\n", "        ", "print", "(", "\n", "'Building feed-forward decoder. Embed size {} / Dropout {} / '", "\n", "'Cardinality Prediction {} / Max. Num. Labels {} / Num. Layers {}'", ".", "format", "(", "\n", "args", ".", "embed_size", ",", "args", ".", "dropout_decoder", ",", "args", ".", "pred_cardinality", ",", "args", ".", "maxnumlabels", ",", "\n", "args", ".", "ff_layers", ")", ",", "\n", "flush", "=", "True", ")", "\n", "\n", "decoder", "=", "FFDecoder", "(", "\n", "args", ".", "embed_size", ",", "\n", "vocab_size", ",", "\n", "args", ".", "embed_size", ",", "\n", "dropout", "=", "args", ".", "dropout_decoder", ",", "\n", "pred_cardinality", "=", "args", ".", "pred_cardinality", ",", "\n", "nobjects", "=", "args", ".", "maxnumlabels", ",", "\n", "n_layers", "=", "args", ".", "ff_layers", ",", "\n", "use_empty_set", "=", "use_empty_set", ")", "\n", "\n", "", "elif", "args", ".", "decoder", "==", "'lstm'", ":", "\n", "        ", "print", "(", "\n", "'Building LSTM decoder. Embed size {} / Dropout {} / Max. Num. Labels {}. '", ".", "format", "(", "\n", "args", ".", "embed_size", ",", "args", ".", "dropout_decoder", ",", "args", ".", "maxnumlabels", ")", ",", "\n", "flush", "=", "True", ")", "\n", "\n", "decoder", "=", "DecoderRNN", "(", "\n", "args", ".", "embed_size", ",", "\n", "args", ".", "embed_size", ",", "\n", "vocab_size", ",", "\n", "dropout", "=", "args", ".", "dropout_decoder", ",", "\n", "seq_length", "=", "args", ".", "maxnumlabels", ",", "\n", "num_instrs", "=", "1", ")", "\n", "\n", "", "elif", "args", ".", "decoder", "==", "'tf'", ":", "\n", "        ", "print", "(", "\n", "'Building Transformer decoder. Embed size {} / Dropout {} / Max. Num. Labels {} / '", "\n", "'Num. Attention Heads {} / Num. Layers {}.'", ".", "format", "(", "\n", "args", ".", "embed_size", ",", "args", ".", "dropout_decoder", ",", "args", ".", "maxnumlabels", ",", "args", ".", "n_att", ",", "\n", "args", ".", "tf_layers", ")", ",", "\n", "flush", "=", "True", ")", "\n", "\n", "decoder", "=", "DecoderTransformer", "(", "\n", "args", ".", "embed_size", ",", "\n", "vocab_size", ",", "\n", "dropout", "=", "args", ".", "dropout_decoder", ",", "\n", "seq_length", "=", "args", ".", "maxnumlabels", ",", "\n", "num_instrs", "=", "1", ",", "\n", "attention_nheads", "=", "args", ".", "n_att", ",", "\n", "pos_embeddings", "=", "False", ",", "\n", "num_layers", "=", "args", ".", "tf_layers", ",", "\n", "learned", "=", "False", ",", "\n", "normalize_before", "=", "True", ")", "\n", "\n", "# label and eos loss", "\n", "", "label_losses", "=", "{", "\n", "'bce'", ":", "nn", ".", "BCEWithLogitsLoss", "(", "reduction", "=", "'mean'", ")", "if", "args", ".", "decoder", "==", "'ff'", "else", "nn", ".", "BCELoss", "(", "reduction", "=", "'mean'", ")", ",", "\n", "'iou'", ":", "softIoULoss", "(", "reduction", "=", "'mean'", ")", ",", "\n", "'td'", ":", "targetDistLoss", "(", "reduction", "=", "'mean'", ")", ",", "\n", "}", "\n", "pad_value", "=", "vocab_size", "-", "1", "\n", "print", "(", "'Using {} loss.'", ".", "format", "(", "args", ".", "label_loss", ")", ",", "flush", "=", "True", ")", "\n", "if", "args", ".", "decoder", "==", "'ff'", ":", "\n", "        ", "label_loss", "=", "label_losses", "[", "args", ".", "label_loss", "]", "\n", "eos_loss", "=", "None", "\n", "", "elif", "args", ".", "decoder", "in", "[", "'tf'", ",", "'lstm'", "]", "and", "args", ".", "perminv", ":", "\n", "        ", "label_loss", "=", "label_losses", "[", "args", ".", "label_loss", "]", "\n", "eos_loss", "=", "nn", ".", "BCELoss", "(", "reduction", "=", "'mean'", ")", "\n", "", "else", ":", "\n", "        ", "label_loss", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "pad_value", ",", "reduction", "=", "'mean'", ")", "\n", "eos_loss", "=", "None", "\n", "\n", "# cardinality loss", "\n", "", "if", "args", ".", "pred_cardinality", "==", "'dc'", ":", "\n", "        ", "print", "(", "'Using Dirichlet-Categorical cardinality loss.'", ",", "flush", "=", "True", ")", "\n", "cardinality_loss", "=", "DCLoss", "(", "U", "=", "args", ".", "U", ",", "dataset", "=", "args", ".", "dataset", ",", "reduction", "=", "'mean'", ")", "\n", "", "elif", "args", ".", "pred_cardinality", "==", "'cat'", ":", "\n", "        ", "print", "(", "'Using categorical cardinality loss.'", ",", "flush", "=", "True", ")", "\n", "cardinality_loss", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'mean'", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Using no cardinality loss.'", ",", "flush", "=", "True", ")", "\n", "cardinality_loss", "=", "None", "\n", "\n", "", "model", "=", "SetPred", "(", "\n", "decoder", ",", "\n", "encoder_image", ",", "\n", "args", ".", "maxnumlabels", ",", "\n", "crit", "=", "label_loss", ",", "\n", "crit_eos", "=", "eos_loss", ",", "\n", "crit_cardinality", "=", "cardinality_loss", ",", "\n", "pad_value", "=", "pad_value", ",", "\n", "perminv", "=", "args", ".", "perminv", ",", "\n", "decoder_ff", "=", "True", "if", "args", ".", "decoder", "==", "'ff'", "else", "False", ",", "\n", "th", "=", "args", ".", "th", ",", "\n", "loss_label", "=", "args", ".", "label_loss", ",", "\n", "replacement", "=", "args", ".", "replacement", ",", "\n", "card_type", "=", "args", ".", "pred_cardinality", ",", "\n", "dataset", "=", "args", ".", "dataset", ",", "\n", "U", "=", "args", ".", "U", ",", "\n", "use_empty_set", "=", "use_empty_set", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.args.get_args_from_json": [[10, 19], ["print", "json.load", "json.load.items", "open", "print", "hasattr", "isinstance", "setattr", "type", "getattr"], "function", ["None"], ["def", "get_args_from_json", "(", "args", ",", "filename", ")", ":", "\n", "    ", "print", "(", "'Loading args from {}:'", ".", "format", "(", "filename", ")", ")", "\n", "config", "=", "json", ".", "load", "(", "open", "(", "filename", ")", ")", "\n", "for", "key", ",", "val", "in", "config", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "key", ",", "flush", "=", "True", ")", "\n", "assert", "hasattr", "(", "args", ",", "key", ")", "\n", "assert", "isinstance", "(", "val", ",", "type", "(", "getattr", "(", "args", ",", "key", ")", ")", ")", "\n", "setattr", "(", "args", ",", "key", ",", "val", ")", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.args.set_default_model_flags": [[21, 29], ["setattr", "setattr", "setattr", "setattr", "setattr", "setattr"], "function", ["None"], ["", "def", "set_default_model_flags", "(", "args", ")", ":", "\n", "    ", "setattr", "(", "args", ",", "'label_loss'", ",", "'cross-entropy'", ")", "\n", "setattr", "(", "args", ",", "'pred_cardinality'", ",", "'none'", ")", "\n", "setattr", "(", "args", ",", "'decoder'", ",", "'tf'", ")", "\n", "setattr", "(", "args", ",", "'perminv'", ",", "False", ")", "\n", "setattr", "(", "args", ",", "'shuffle_labels'", ",", "False", ")", "\n", "setattr", "(", "args", ",", "'replacement'", ",", "False", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.args.set_flags_for_model": [[31, 50], ["args.set_default_model_flags", "setattr", "set_default_model_flags.model_name.split", "print", "setattr", "setattr", "len", "setattr", "setattr", "setattr", "setattr"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.args.set_default_model_flags"], ["", "def", "set_flags_for_model", "(", "args", ")", ":", "\n", "    ", "args", "=", "set_default_model_flags", "(", "args", ")", "\n", "if", "'ff_'", "in", "args", ".", "model_name", ":", "\n", "        ", "setattr", "(", "args", ",", "'decoder'", ",", "'ff'", ")", "\n", "tokens", "=", "args", ".", "model_name", ".", "split", "(", "'_'", ")", "\n", "print", "(", "tokens", ")", "\n", "assert", "tokens", "[", "1", "]", "in", "[", "'bce'", ",", "'iou'", ",", "'td'", "]", "\n", "setattr", "(", "args", ",", "'label_loss'", ",", "tokens", "[", "1", "]", ")", "\n", "if", "len", "(", "tokens", ")", "==", "3", ":", "\n", "            ", "assert", "tokens", "[", "2", "]", "in", "[", "'dc'", ",", "'cat'", "]", "\n", "setattr", "(", "args", ",", "'pred_cardinality'", ",", "tokens", "[", "2", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "setattr", "(", "args", ",", "'decoder'", ",", "'tf'", "if", "'tf'", "in", "args", ".", "model_name", "else", "'lstm'", ")", "\n", "if", "'set'", "in", "args", ".", "model_name", ":", "\n", "            ", "setattr", "(", "args", ",", "'perminv'", ",", "True", ")", "\n", "setattr", "(", "args", ",", "'label_loss'", ",", "'bce'", ")", "\n", "", "else", ":", "\n", "            ", "setattr", "(", "args", ",", "'shuffle_labels'", ",", "True", "if", "'shuffle'", "in", "args", ".", "model_name", "else", "False", ")", "\n", "", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.args.get_parser": [[52, 138], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.parse_args", "args.set_flags_for_model", "os.path.join", "args.get_args_from_json"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.args.set_flags_for_model", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.src.args.get_args_from_json"], ["", "def", "get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--save_dir'", ",", "type", "=", "str", ",", "default", "=", "'checkpoints'", ",", "help", "=", "'Directory for saving the models'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--experiment_name'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'experiment'", ",", "\n", "help", "=", "'Specifies the sub directory for saving the models. The full path will be '", "\n", "'<save_dir>/<dataset>/<model_name>/<experiment_name>.'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--dataset'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'voc'", ",", "\n", "choices", "=", "[", "'coco'", ",", "'voc'", ",", "'nuswide'", ",", "'ade20k'", ",", "'recipe1m'", "]", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--model_name'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'ff_bce'", ",", "\n", "choices", "=", "[", "\n", "'ff_bce'", ",", "'ff_iou'", ",", "'ff_td'", ",", "'ff_bce_dc'", ",", "'ff_bce_cat'", ",", "'ff_iou_cat'", ",", "'ff_td_cat'", ",", "'tf'", ",", "\n", "'tf_shuffle'", ",", "'tfset'", ",", "'lstm'", ",", "'lstm_shuffle'", ",", "'lstmset'", "\n", "]", ")", "\n", "\n", "# Model parameters", "\n", "parser", ".", "add_argument", "(", "\n", "'--image_model'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'resnet50'", ",", "\n", "choices", "=", "[", "'resnet50'", ",", "'resnet101'", ",", "'resnext101_32x8d'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--embed_size'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "parser", ".", "add_argument", "(", "'--n_att'", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "'--tf_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--ff_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--crop_size'", ",", "type", "=", "int", ",", "default", "=", "448", ",", "help", "=", "'size for randomly cropping images'", ")", "\n", "parser", ".", "add_argument", "(", "'--image_size'", ",", "type", "=", "int", ",", "default", "=", "448", ")", "\n", "parser", ".", "add_argument", "(", "'--log_step'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "'step size for printing log info'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.001", ")", "\n", "parser", ".", "add_argument", "(", "'--scale_learning_rate_cnn'", ",", "type", "=", "float", ",", "default", "=", "0.01", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_decay_rate'", ",", "type", "=", "float", ",", "default", "=", "0.99", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_decay_every'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "type", "=", "float", ",", "default", "=", "0.", ")", "\n", "parser", ".", "add_argument", "(", "'--U'", ",", "type", "=", "float", ",", "default", "=", "2.36", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "1235", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--dropout_encoder'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout_decoder'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--num_epochs'", ",", "type", "=", "int", ",", "default", "=", "400", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "'--num_workers'", ",", "type", "=", "int", ",", "default", "=", "8", ")", "\n", "parser", ".", "add_argument", "(", "'--patience'", ",", "type", "=", "int", ",", "default", "=", "50", ")", "\n", "parser", ".", "add_argument", "(", "'--maxnumlabels'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "'--finetune_after'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--loss_weight'", ",", "nargs", "=", "'+'", ",", "type", "=", "float", ",", "default", "=", "[", "1.0", ",", "1.0", ",", "0.0", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--th'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--metric_to_checkpoint'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'o_f1'", ",", "\n", "choices", "=", "[", "'o_f1'", ",", "'c_f1'", ",", "'i_f1'", ",", "'average'", "]", ")", "\n", "\n", "# Flags", "\n", "parser", ".", "add_argument", "(", "'--notensorboard'", ",", "dest", "=", "'tensorboard'", ",", "action", "=", "'store_false'", ")", "\n", "parser", ".", "set_defaults", "(", "tensorboard", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--resume'", ",", "dest", "=", "'resume'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "set_defaults", "(", "resume", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--nodecay_lr'", ",", "dest", "=", "'decay_lr'", ",", "action", "=", "'store_false'", ")", "\n", "parser", ".", "set_defaults", "(", "decay_lr", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--use_json_config'", ",", "dest", "=", "'use_json_config'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "set_defaults", "(", "use_json_config", "=", "False", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# If we are using configuration file, overwrite command line arguments", "\n", "if", "args", ".", "use_json_config", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "'../configs/'", ",", "args", ".", "dataset", ",", "args", ".", "image_model", "+", "'_'", "+", "args", ".", "model_name", "+", "'.json'", ")", "\n", "args", "=", "get_args_from_json", "(", "args", ",", "filename", ")", "\n", "\n", "", "args", "=", "set_flags_for_model", "(", "args", ")", "\n", "\n", "return", "args", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.DCLoss.__init__": [[67, 75], ["torch.Module.__init__", "math.log"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__"], ["    ", "def", "__init__", "(", "self", ",", "U", ",", "dataset", ",", "reduction", "=", "'none'", ",", "e", "=", "1e-8", ")", ":", "\n", "        ", "super", "(", "DCLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "reduction", "in", "[", "'none'", ",", "'mean'", "]", "\n", "self", ".", "U", "=", "math", ".", "log", "(", "U", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "offset", "=", "0", "if", "self", ".", "dataset", "in", "[", "'coco'", ",", "'nuswide'", "]", "else", "1", "\n", "self", ".", "reduction", "=", "reduction", "\n", "self", ".", "e", "=", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.DCLoss.forward": [[76, 84], ["loss.mean.mean.mean", "torch.NLLLoss", "torch.NLLLoss", "torch.NLLLoss", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "metrics.DC"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.DC"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "loss", "=", "nn", ".", "NLLLoss", "(", "reduction", "=", "'none'", ")", "(", "\n", "torch", ".", "log", "(", "DC", "(", "input", ",", "dataset", "=", "self", ".", "dataset", ")", "+", "self", ".", "e", ")", ",", "\n", "target", ")", "-", "(", "(", "target", "+", "self", ".", "offset", ")", "*", "self", ".", "U", ")", ".", "float", "(", ")", "\n", "\n", "if", "self", ".", "reduction", "==", "'mean'", ":", "\n", "            ", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.softIoULoss.__init__": [[99, 104], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__"], ["    ", "def", "__init__", "(", "self", ",", "reduction", "=", "'none'", ",", "e", "=", "1e-8", ")", ":", "\n", "        ", "super", "(", "softIoULoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "reduction", "in", "[", "'none'", ",", "'mean'", "]", "\n", "self", ".", "reduction", "=", "reduction", "\n", "self", ".", "e", "=", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.softIoULoss.forward": [[105, 112], ["metrics.softIoU", "loss.mean.mean.mean"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.softIoU"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "targets", ")", ":", "\n", "        ", "loss", "=", "1.0", "-", "softIoU", "(", "inputs", ",", "targets", ",", "e", "=", "self", ".", "e", ")", "\n", "\n", "if", "self", ".", "reduction", "==", "'mean'", ":", "\n", "            ", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.targetDistLoss.__init__": [[116, 121], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__"], ["    ", "def", "__init__", "(", "self", ",", "reduction", "=", "'none'", ",", "e", "=", "1e-8", ")", ":", "\n", "        ", "super", "(", "targetDistLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "reduction", "in", "[", "'none'", ",", "'mean'", "]", "\n", "self", ".", "reduction", "=", "reduction", "\n", "self", ".", "e", "=", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.targetDistLoss.forward": [[122, 145], ["label_target.sum().unsqueeze", "torch.FloatTensor().to().unsqueeze().unsqueeze", "torch.FloatTensor().to().unsqueeze().unsqueeze", "torch.FloatTensor().to().unsqueeze().unsqueeze", "torch.FloatTensor().to().unsqueeze().unsqueeze", "torch.FloatTensor().to().unsqueeze().unsqueeze", "torch.FloatTensor().to().unsqueeze().unsqueeze", "torch.FloatTensor().to().unsqueeze().unsqueeze", "torch.FloatTensor().to().unsqueeze().unsqueeze", "torch.FloatTensor().to().unsqueeze().unsqueeze", "label_target.size", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "loss.mean.mean.mean", "label_target.sum", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "label_target.float", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.array"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "label_prediction", ",", "label_target", ")", ":", "\n", "# create target distribution", "\n", "# check if the target is all 0s", "\n", "        ", "cardinality_target", "=", "label_target", ".", "sum", "(", "dim", "=", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "is_empty", "=", "(", "cardinality_target", "==", "0", ")", ".", "float", "(", ")", "\n", "\n", "# create flat distribution", "\n", "flat_target", "=", "1", "/", "label_target", ".", "size", "(", "-", "1", ")", "\n", "flat_target", "=", "torch", ".", "FloatTensor", "(", "\n", "np", ".", "array", "(", "flat_target", ")", ")", ".", "to", "(", "device", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "# divide target by number of elements and add equal prob to all elements for the empty sets", "\n", "target_distribution", "=", "label_target", ".", "float", "(", ")", "/", "(", "\n", "cardinality_target", "+", "self", ".", "e", ")", "+", "is_empty", "*", "flat_target", "\n", "\n", "# loss", "\n", "loss", "=", "target_distribution", "*", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "label_prediction", ",", "dim", "=", "-", "1", ")", "\n", "loss", "=", "-", "torch", ".", "sum", "(", "loss", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "self", ".", "reduction", "==", "'mean'", ":", "\n", "            ", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.DC": [[18, 63], ["sum", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "np.array.unsqueeze().to().float", "numpy.array", "numpy.array", "alphas.size", "np.array.unsqueeze().to", "numpy.array", "torch.sum", "torch.sum", "torch.sum", "numpy.array", "numpy.array", "np.array.unsqueeze"], "function", ["None"], ["def", "DC", "(", "alphas", ",", "dataset", "=", "'coco'", ")", ":", "\n", "\n", "    ", "if", "dataset", "==", "'coco'", ":", "\n", "        ", "cms", "=", "np", ".", "array", "(", "[", "\n", "703", ",", "15100.", ",", "22519.", ",", "15179.", ",", "8853.", ",", "5334.", ",", "3025.", ",", "1803.", ",", "971.", ",", "541.", ",", "280.", ",", "145", ",", "69", ",", "32", ",", "11", ",", "\n", "7", ",", "2", ",", "0", ",", "1", ",", "0", ",", "0", "\n", "]", ")", "\n", "\n", "", "elif", "dataset", "==", "'voc'", ":", "\n", "        ", "cms", "=", "np", ".", "array", "(", "\n", "[", "2538.", ",", "1479.", ",", "386.", ",", "91.", ",", "10.", ",", "4.", ",", "1.", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "\n", "", "elif", "dataset", "==", "'ade20k'", ":", "\n", "        ", "cms", "=", "np", ".", "array", "(", "[", "\n", "104.", ",", "507.", ",", "1177.", ",", "1747.", ",", "1909.", ",", "1926.", ",", "1765.", ",", "1646.", ",", "1468.", ",", "1289.", ",", "1111", ",", "874", ",", "624", ",", "579", ",", "\n", "416", ",", "258", ",", "226", ",", "159", ",", "113", ",", "95", ",", "64", ",", "48", ",", "27", ",", "21", ",", "8", ",", "9", ",", "4", ",", "1", ",", "0", ",", "0", ",", "1", "\n", "]", ")", "\n", "\n", "", "elif", "dataset", "==", "'recipe1m'", ":", "\n", "        ", "cms", "=", "np", ".", "array", "(", "[", "\n", "0.0000e+00", ",", "1.1570e+04", ",", "2.7383e+04", ",", "4.5583e+04", ",", "6.2422e+04", ",", "7.2228e+04", ",", "7.6909e+04", ",", "\n", "7.6319e+04", ",", "7.0102e+04", ",", "5.9216e+04", ",", "4.6648e+04", ",", "3.4192e+04", ",", "2.3283e+04", ",", "1.5590e+04", ",", "\n", "1.0079e+04", ",", "6.2400e+03", ",", "3.7690e+03", ",", "2.2110e+03", ",", "1.3430e+03", ",", "2.7000e+01", "\n", "]", ")", "\n", "\n", "", "else", ":", "\n", "        ", "cms", "=", "np", ".", "array", "(", "[", "\n", "36340", ",", "42824.", ",", "28406.", ",", "17843.", ",", "11093.", ",", "6550.", ",", "3564.", ",", "1768.", ",", "647.", ",", "164.", ",", "40.", ",", "3", ",", "2", ",", "0", ",", "0", ",", "0", ",", "0", ",", "\n", "0", ",", "0", ",", "0", ",", "0", "\n", "]", ")", "\n", "\n", "", "cms", "=", "cms", "[", "0", ":", "alphas", ".", "size", "(", "-", "1", ")", "]", "\n", "c", "=", "sum", "(", "cms", ")", "\n", "\n", "cms", "=", "torch", ".", "from_numpy", "(", "cms", ")", "\n", "\n", "cms", "=", "cms", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "device", ")", ".", "float", "(", ")", "\n", "\n", "num", "=", "alphas", "+", "cms", "\n", "\n", "den", "=", "(", "torch", ".", "sum", "(", "alphas", ",", "dim", "=", "-", "1", ")", "+", "c", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "dc_alphas", "=", "num", "/", "den", "\n", "\n", "return", "dc_alphas", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.softIoU": [[86, 95], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "function", ["None"], ["", "", "def", "softIoU", "(", "out", ",", "target", ",", "sum_axis", "=", "1", ",", "e", "=", "1e-8", ")", ":", "\n", "# logits to probs", "\n", "    ", "out", "=", "torch", ".", "sigmoid", "(", "out", ")", "\n", "# loss", "\n", "num", "=", "(", "out", "*", "target", ")", ".", "sum", "(", "sum_axis", ",", "True", ")", "+", "e", "\n", "den", "=", "(", "out", "+", "target", "-", "out", "*", "target", ")", ".", "sum", "(", "sum_axis", ",", "True", ")", "+", "e", "\n", "iou", "=", "num", "/", "den", "\n", "\n", "return", "iou", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.update_error_counts": [[147, 157], ["None"], "function", ["None"], ["", "", "def", "update_error_counts", "(", "error_counts", ",", "y_pred", ",", "y_true", ")", ":", "\n", "\n", "    ", "error_counts", "[", "'tp_c'", "]", "+=", "(", "y_pred", "*", "y_true", ")", ".", "sum", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "error_counts", "[", "'fp_c'", "]", "+=", "(", "y_pred", "*", "(", "1", "-", "y_true", ")", ")", ".", "sum", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "error_counts", "[", "'fn_c'", "]", "+=", "(", "(", "1", "-", "y_pred", ")", "*", "y_true", ")", ".", "sum", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "error_counts", "[", "'tn_c'", "]", "+=", "(", "(", "1", "-", "y_pred", ")", "*", "(", "1", "-", "y_true", ")", ")", ".", "sum", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "\n", "error_counts", "[", "'tp_all'", "]", "+=", "(", "y_pred", "*", "y_true", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "error_counts", "[", "'fp_all'", "]", "+=", "(", "y_pred", "*", "(", "1", "-", "y_true", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "error_counts", "[", "'fn_all'", "]", "+=", "(", "(", "1", "-", "y_pred", ")", "*", "y_true", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.metrics.compute_metrics": [[159, 180], ["numpy.average"], "function", ["None"], ["", "def", "compute_metrics", "(", "error_counts", ",", "which_metrics", ",", "eps", "=", "1e-8", ",", "weights", "=", "None", ")", ":", "\n", "\n", "    ", "ret_metrics", "=", "{", "}", "\n", "\n", "if", "'f1'", "in", "which_metrics", ":", "\n", "        ", "pre", "=", "(", "error_counts", "[", "'tp_all'", "]", "+", "eps", ")", "/", "(", "error_counts", "[", "'tp_all'", "]", "+", "error_counts", "[", "'fp_all'", "]", "+", "eps", ")", "\n", "rec", "=", "(", "error_counts", "[", "'tp_all'", "]", "+", "eps", ")", "/", "(", "error_counts", "[", "'tp_all'", "]", "+", "error_counts", "[", "'fn_all'", "]", "+", "eps", ")", "\n", "\n", "f1", "=", "2", "*", "(", "pre", "*", "rec", ")", "/", "(", "pre", "+", "rec", ")", "\n", "ret_metrics", "[", "'f1'", "]", "=", "f1", "\n", "\n", "", "if", "'c_f1'", "in", "which_metrics", ":", "\n", "        ", "pre", "=", "(", "error_counts", "[", "'tp_c'", "]", "+", "eps", ")", "/", "(", "error_counts", "[", "'tp_c'", "]", "+", "error_counts", "[", "'fp_c'", "]", "+", "eps", ")", "\n", "rec", "=", "(", "error_counts", "[", "'tp_c'", "]", "+", "eps", ")", "/", "(", "error_counts", "[", "'tp_c'", "]", "+", "error_counts", "[", "'fn_c'", "]", "+", "eps", ")", "\n", "\n", "f1_perclass", "=", "2", "*", "(", "pre", "*", "rec", ")", "/", "(", "pre", "+", "rec", ")", "\n", "f1_perclass_avg", "=", "np", ".", "average", "(", "f1_perclass", ",", "weights", "=", "weights", ")", "\n", "ret_metrics", "[", "'c_f1'", "]", "=", "f1_perclass_avg", "\n", "\n", "\n", "", "return", "ret_metrics", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.Vocabulary.__init__": [[20, 24], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "word2idx", "=", "{", "}", "\n", "self", ".", "idx2word", "=", "{", "}", "\n", "self", ".", "idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.Vocabulary.add_word": [[25, 41], ["recipe1m_utils.Vocabulary.idx2word.keys", "recipe1m_utils.Vocabulary.idx2word[].append"], "methods", ["None"], ["", "def", "add_word", "(", "self", ",", "word", ",", "idx", "=", "None", ")", ":", "\n", "        ", "if", "idx", "is", "None", ":", "\n", "            ", "if", "not", "word", "in", "self", ".", "word2idx", ":", "\n", "                ", "self", ".", "word2idx", "[", "word", "]", "=", "self", ".", "idx", "\n", "self", ".", "idx2word", "[", "self", ".", "idx", "]", "=", "word", "\n", "self", ".", "idx", "+=", "1", "\n", "", "return", "self", ".", "idx", "\n", "", "else", ":", "\n", "            ", "if", "not", "word", "in", "self", ".", "word2idx", ":", "\n", "                ", "self", ".", "word2idx", "[", "word", "]", "=", "idx", "\n", "if", "idx", "in", "self", ".", "idx2word", ".", "keys", "(", ")", ":", "\n", "                    ", "self", ".", "idx2word", "[", "idx", "]", ".", "append", "(", "word", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "idx2word", "[", "idx", "]", "=", "[", "word", "]", "\n", "\n", "", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.Vocabulary.remove_eos": [[42, 58], ["range", "isinstance", "len"], "methods", ["None"], ["", "", "", "def", "remove_eos", "(", "self", ")", ":", "\n", "# get word id to remove", "\n", "        ", "id_to_remove", "=", "self", ".", "word2idx", "[", "'<end>'", "]", "\n", "\n", "# remove word and shift all subsequent ids", "\n", "for", "i", "in", "range", "(", "id_to_remove", ",", "len", "(", "self", ".", "idx2word", ")", "-", "1", ")", ":", "\n", "            ", "word_aux", "=", "self", ".", "idx2word", "[", "i", "+", "1", "]", "\n", "if", "isinstance", "(", "word_aux", ",", "list", ")", ":", "\n", "                ", "for", "el", "in", "word_aux", ":", "\n", "                    ", "self", ".", "word2idx", "[", "el", "]", "=", "i", "\n", "", "", "self", ".", "idx2word", "[", "i", "]", "=", "word_aux", "\n", "\n", "# remove last idx", "\n", "", "del", "self", ".", "idx2word", "[", "i", "+", "1", "]", "\n", "# remove eos word", "\n", "del", "self", ".", "word2idx", "[", "'<end>'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.Vocabulary.__call__": [[59, 63], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "not", "word", "in", "self", ".", "word2idx", ":", "\n", "            ", "return", "self", ".", "word2idx", "[", "'<pad>'", "]", "\n", "", "return", "self", ".", "word2idx", "[", "word", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.Vocabulary.__len__": [[64, 66], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idx2word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.get_ingredient": [[68, 80], ["det_ingr[].lower", "replace_dict.items", "det_ingr_undrs.replace.strip", "det_ingr_undrs.replace.replace", "det_ingr_undrs.replace.replace", "i.isdigit"], "function", ["None"], ["", "", "def", "get_ingredient", "(", "det_ingr", ",", "replace_dict", ")", ":", "\n", "    ", "det_ingr_undrs", "=", "det_ingr", "[", "'text'", "]", ".", "lower", "(", ")", "\n", "det_ingr_undrs", "=", "''", ".", "join", "(", "i", "for", "i", "in", "det_ingr_undrs", "if", "not", "i", ".", "isdigit", "(", ")", ")", "\n", "\n", "for", "rep", ",", "char_list", "in", "replace_dict", ".", "items", "(", ")", ":", "\n", "        ", "for", "c_", "in", "char_list", ":", "\n", "            ", "if", "c_", "in", "det_ingr_undrs", ":", "\n", "                ", "det_ingr_undrs", "=", "det_ingr_undrs", ".", "replace", "(", "c_", ",", "rep", ")", "\n", "", "", "", "det_ingr_undrs", "=", "det_ingr_undrs", ".", "strip", "(", ")", "\n", "det_ingr_undrs", "=", "det_ingr_undrs", ".", "replace", "(", "' '", ",", "'_'", ")", "\n", "\n", "return", "det_ingr_undrs", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.get_instruction": [[81, 93], ["instruction.replace.lower", "replace_dict.items", "instruction.replace.strip", "instruction[].isdigit", "len", "instruction.replace.replace"], "function", ["None"], ["", "def", "get_instruction", "(", "instruction", ",", "replace_dict", ",", "instruction_mode", "=", "True", ")", ":", "\n", "    ", "instruction", "=", "instruction", ".", "lower", "(", ")", "\n", "\n", "for", "rep", ",", "char_list", "in", "replace_dict", ".", "items", "(", ")", ":", "\n", "        ", "for", "c_", "in", "char_list", ":", "\n", "            ", "if", "c_", "in", "instruction", ":", "\n", "                ", "instruction", "=", "instruction", ".", "replace", "(", "c_", ",", "rep", ")", "\n", "", "", "instruction", "=", "instruction", ".", "strip", "(", ")", "\n", "# remove sentences starting with \"1.\", \"2.\", ... from the targets", "\n", "", "if", "len", "(", "instruction", ")", ">", "0", "and", "instruction", "[", "0", "]", ".", "isdigit", "(", ")", "and", "instruction_mode", ":", "\n", "        ", "instruction", "=", "''", "\n", "", "return", "instruction", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.remove_plurals": [[95, 121], ["counter_ingrs.items", "len", "del_ingrs.append", "counter_ingrs.keys", "ingr_clusters[].extend", "del_ingrs.append", "counter_ingrs.keys", "ingr_clusters[].extend", "del_ingrs.append"], "function", ["None"], ["", "def", "remove_plurals", "(", "counter_ingrs", ",", "ingr_clusters", ")", ":", "\n", "    ", "del_ingrs", "=", "[", "]", "\n", "\n", "for", "k", ",", "v", "in", "counter_ingrs", ".", "items", "(", ")", ":", "\n", "\n", "        ", "if", "len", "(", "k", ")", "==", "0", ":", "\n", "            ", "del_ingrs", ".", "append", "(", "k", ")", "\n", "continue", "\n", "\n", "", "gotit", "=", "0", "\n", "if", "k", "[", "-", "2", ":", "]", "==", "'es'", ":", "\n", "            ", "if", "k", "[", ":", "-", "2", "]", "in", "counter_ingrs", ".", "keys", "(", ")", ":", "\n", "                ", "counter_ingrs", "[", "k", "[", ":", "-", "2", "]", "]", "+=", "v", "\n", "ingr_clusters", "[", "k", "[", ":", "-", "2", "]", "]", ".", "extend", "(", "ingr_clusters", "[", "k", "]", ")", "\n", "del_ingrs", ".", "append", "(", "k", ")", "\n", "gotit", "=", "1", "\n", "\n", "", "", "if", "k", "[", "-", "1", "]", "==", "'s'", "and", "gotit", "==", "0", ":", "\n", "            ", "if", "k", "[", ":", "-", "1", "]", "in", "counter_ingrs", ".", "keys", "(", ")", ":", "\n", "                ", "counter_ingrs", "[", "k", "[", ":", "-", "1", "]", "]", "+=", "v", "\n", "ingr_clusters", "[", "k", "[", ":", "-", "1", "]", "]", ".", "extend", "(", "ingr_clusters", "[", "k", "]", ")", "\n", "del_ingrs", ".", "append", "(", "k", ")", "\n", "", "", "", "for", "item", "in", "del_ingrs", ":", "\n", "        ", "del", "counter_ingrs", "[", "item", "]", "\n", "del", "ingr_clusters", "[", "item", "]", "\n", "", "return", "counter_ingrs", ",", "ingr_clusters", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.cluster_ingredients": [[123, 161], ["dict", "dict", "counter_ingrs.items", "k.split", "k.split", "len", "k.split", "counter_ingrs.keys", "w.split", "k.split", "k.split", "len", "dict.keys", "mydict_ingrs[].append", "k.split", "k.split", "counter_ingrs.keys", "counter_ingrs.keys"], "function", ["None"], ["", "def", "cluster_ingredients", "(", "counter_ingrs", ")", ":", "\n", "    ", "mydict", "=", "dict", "(", ")", "\n", "mydict_ingrs", "=", "dict", "(", ")", "\n", "\n", "for", "k", ",", "v", "in", "counter_ingrs", ".", "items", "(", ")", ":", "\n", "\n", "        ", "w1", "=", "k", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "\n", "w2", "=", "k", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "lw", "=", "[", "w1", ",", "w2", "]", "\n", "if", "len", "(", "k", ".", "split", "(", "'_'", ")", ")", ">", "1", ":", "\n", "            ", "w3", "=", "k", ".", "split", "(", "'_'", ")", "[", "0", "]", "+", "'_'", "+", "k", ".", "split", "(", "'_'", ")", "[", "1", "]", "\n", "w4", "=", "k", ".", "split", "(", "'_'", ")", "[", "-", "2", "]", "+", "'_'", "+", "k", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "\n", "\n", "lw", "=", "[", "w1", ",", "w2", ",", "w4", ",", "w3", "]", "\n", "\n", "", "gotit", "=", "0", "\n", "for", "w", "in", "lw", ":", "\n", "            ", "if", "w", "in", "counter_ingrs", ".", "keys", "(", ")", ":", "\n", "# check if its parts are", "\n", "                ", "parts", "=", "w", ".", "split", "(", "'_'", ")", "\n", "if", "len", "(", "parts", ")", ">", "0", ":", "\n", "                    ", "if", "parts", "[", "0", "]", "in", "counter_ingrs", ".", "keys", "(", ")", ":", "\n", "                        ", "w", "=", "parts", "[", "0", "]", "\n", "", "elif", "parts", "[", "1", "]", "in", "counter_ingrs", ".", "keys", "(", ")", ":", "\n", "                        ", "w", "=", "parts", "[", "1", "]", "\n", "", "", "if", "w", "in", "mydict", ".", "keys", "(", ")", ":", "\n", "                    ", "mydict", "[", "w", "]", "+=", "v", "\n", "mydict_ingrs", "[", "w", "]", ".", "append", "(", "k", ")", "\n", "", "else", ":", "\n", "                    ", "mydict", "[", "w", "]", "=", "v", "\n", "mydict_ingrs", "[", "w", "]", "=", "[", "k", "]", "\n", "", "gotit", "=", "1", "\n", "break", "\n", "", "", "if", "gotit", "==", "0", ":", "\n", "            ", "mydict", "[", "k", "]", "=", "v", "\n", "mydict_ingrs", "[", "k", "]", "=", "[", "k", "]", "\n", "\n", "", "", "return", "mydict", ",", "mydict_ingrs", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.update_counter": [[163, 168], ["nltk.tokenize.word_tokenize", "counter_toks.update"], "function", ["None"], ["", "def", "update_counter", "(", "list_", ",", "counter_toks", ",", "istrain", "=", "False", ")", ":", "\n", "    ", "for", "sentence", "in", "list_", ":", "\n", "        ", "tokens", "=", "nltk", ".", "tokenize", ".", "word_tokenize", "(", "sentence", ")", "\n", "if", "istrain", ":", "\n", "            ", "counter_toks", ".", "update", "(", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.build_vocab_recipe1m": [[170, 350], ["print", "os.path.join", "json.load", "json.load", "json.load", "enumerate", "print", "print", "enumerate", "recipe1m_utils.cluster_ingredients", "recipe1m_utils.remove_plurals", "recipe1m_utils.Vocabulary", "recipe1m_utils.Vocabulary.add_word", "ingrs.items", "recipe1m_utils.Vocabulary.add_word", "print", "tqdm", "print", "dataset.keys", "os.path.exists", "os.mkdir", "open", "open", "open", "os.path.exists", "print", "pickle.load", "collections.Counter", "tqdm", "pickle.dump", "enumerate", "enumerate", "dataset[].append", "print", "os.path.join", "os.path.join", "os.path.join", "len", "open", "enumerate", "enumerate", "open", "collections.Counter.keys", "collections.Counter.items", "recipe1m_utils.Vocabulary.add_word", "len", "recipe1m_utils.get_instruction", "id2im.keys", "len", "recipe1m_utils.get_instruction", "collections.Counter.update", "recipe1m_utils.get_ingredient", "ingrs_list.append", "Vocabulary.", "len", "len", "instrs_list.append", "len", "len", "len", "len", "images_list.append", "recipe1m_utils.get_ingredient", "det_ingrs_filtered.append", "ingrs_list.append", "len", "instrs_list.append", "len", "len", "len", "len", "len", "len", "labels.append", "len", "Vocabulary."], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.cluster_ingredients", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.remove_plurals", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.Vocabulary.add_word", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.Vocabulary.add_word", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.Vocabulary.add_word", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.get_instruction", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.get_instruction", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.get_ingredient", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.get_ingredient"], ["", "", "", "def", "build_vocab_recipe1m", "(", "args", ")", ":", "\n", "    ", "print", "(", "\"Loading data...\"", ")", "\n", "\n", "args", ".", "save_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "recipe1m_path", ",", "'preprocessed'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "save_path", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "args", ".", "save_path", ")", "\n", "\n", "", "dets", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "recipe1m_path", ",", "'det_ingrs.json'", ")", ",", "'r'", ")", ")", "\n", "layer1", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "recipe1m_path", ",", "'layer1.json'", ")", ",", "'r'", ")", ")", "\n", "layer2", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "recipe1m_path", ",", "'layer2.json'", ")", ",", "'r'", ")", ")", "\n", "\n", "id2im", "=", "{", "}", "\n", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "layer2", ")", ":", "\n", "        ", "id2im", "[", "entry", "[", "'id'", "]", "]", "=", "i", "\n", "\n", "", "print", "(", "\"Loaded data.\"", ")", "\n", "print", "(", "\"Found %d recipes in the dataset.\"", "%", "(", "len", "(", "layer1", ")", ")", ")", "\n", "replace_dict_ingrs", "=", "{", "'and'", ":", "[", "'&'", ",", "\"'n\"", "]", ",", "''", ":", "[", "'%'", ",", "','", ",", "'.'", ",", "'#'", ",", "'['", ",", "']'", ",", "'!'", ",", "'?'", "]", "}", "\n", "replace_dict_instrs", "=", "{", "'and'", ":", "[", "'&'", ",", "\"'n\"", "]", ",", "''", ":", "[", "'#'", ",", "'['", ",", "']'", "]", "}", "\n", "\n", "idx2ind", "=", "{", "}", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "dets", ")", ":", "\n", "        ", "idx2ind", "[", "entry", "[", "'id'", "]", "]", "=", "i", "\n", "\n", "", "ingrs_file", "=", "args", ".", "save_path", "+", "'allingrs_count.pkl'", "\n", "#####", "\n", "# 1. Count words in dataset and clean", "\n", "#####", "\n", "if", "os", ".", "path", ".", "exists", "(", "ingrs_file", ")", "and", "not", "args", ".", "forcegen", ":", "\n", "        ", "print", "(", "\"loading pre-extracted word counters\"", ")", "\n", "counter_ingrs", "=", "pickle", ".", "load", "(", "open", "(", "args", ".", "save_path", "+", "'allingrs_count.pkl'", ",", "'rb'", ")", ")", "\n", "", "else", ":", "\n", "        ", "counter_ingrs", "=", "Counter", "(", ")", "\n", "\n", "for", "i", ",", "entry", "in", "tqdm", "(", "enumerate", "(", "layer1", ")", ")", ":", "\n", "\n", "# get all instructions for this recipe", "\n", "            ", "instrs", "=", "entry", "[", "'instructions'", "]", "\n", "\n", "instrs_list", "=", "[", "]", "\n", "ingrs_list", "=", "[", "]", "\n", "\n", "# retrieve pre-detected ingredients for this entry", "\n", "det_ingrs", "=", "dets", "[", "idx2ind", "[", "entry", "[", "'id'", "]", "]", "]", "[", "'ingredients'", "]", "\n", "\n", "valid", "=", "dets", "[", "idx2ind", "[", "entry", "[", "'id'", "]", "]", "]", "[", "'valid'", "]", "\n", "det_ingrs_filtered", "=", "[", "]", "\n", "\n", "for", "j", ",", "det_ingr", "in", "enumerate", "(", "det_ingrs", ")", ":", "\n", "                ", "if", "len", "(", "det_ingr", ")", ">", "0", "and", "valid", "[", "j", "]", ":", "\n", "                    ", "det_ingr_undrs", "=", "get_ingredient", "(", "det_ingr", ",", "replace_dict_ingrs", ")", "\n", "det_ingrs_filtered", ".", "append", "(", "det_ingr_undrs", ")", "\n", "ingrs_list", ".", "append", "(", "det_ingr_undrs", ")", "\n", "\n", "# get raw text for instructions of this entry", "\n", "", "", "acc_len", "=", "0", "\n", "for", "instr", "in", "instrs", ":", "\n", "                ", "instr", "=", "instr", "[", "'text'", "]", "\n", "instr", "=", "get_instruction", "(", "instr", ",", "replace_dict_instrs", ")", "\n", "if", "len", "(", "instr", ")", ">", "0", ":", "\n", "                    ", "instrs_list", ".", "append", "(", "instr", ")", "\n", "acc_len", "+=", "len", "(", "instr", ")", "\n", "\n", "# discard recipes with too few or too many ingredients or instruction words", "\n", "", "", "if", "len", "(", "ingrs_list", ")", "<", "args", ".", "minnumingrs", "or", "len", "(", "instrs_list", ")", "<", "args", ".", "minnuminstrs", "or", "len", "(", "instrs_list", ")", ">=", "args", ".", "maxnuminstrs", "or", "len", "(", "ingrs_list", ")", ">=", "args", ".", "maxnumingrs", "or", "acc_len", "<", "args", ".", "minnumwords", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "entry", "[", "'partition'", "]", "==", "'train'", ":", "\n", "                ", "counter_ingrs", ".", "update", "(", "ingrs_list", ")", "\n", "\n", "", "", "pickle", ".", "dump", "(", "counter_ingrs", ",", "open", "(", "args", ".", "save_path", "+", "'allingrs_count.pkl'", ",", "'wb'", ")", ")", "\n", "\n", "# manually add missing entries for better clustering", "\n", "", "base_words", "=", "[", "\n", "'peppers'", ",", "'tomato'", ",", "'spinach_leaves'", ",", "'turkey_breast'", ",", "'lettuce_leaf'", ",", "'chicken_thighs'", ",", "\n", "'milk_powder'", ",", "'bread_crumbs'", ",", "'onion_flakes'", ",", "'red_pepper'", ",", "'pepper_flakes'", ",", "\n", "'juice_concentrate'", ",", "'cracker_crumbs'", ",", "'hot_chili'", ",", "'seasoning_mix'", ",", "'dill_weed'", ",", "\n", "'pepper_sauce'", ",", "'sprouts'", ",", "'cooking_spray'", ",", "'cheese_blend'", ",", "'basil_leaves'", ",", "\n", "'pineapple_chunks'", ",", "'marshmallow'", ",", "'chile_powder'", ",", "'cheese_blend'", ",", "'corn_kernels'", ",", "\n", "'tomato_sauce'", ",", "'chickens'", ",", "'cracker_crust'", ",", "'lemonade_concentrate'", ",", "'red_chili'", ",", "\n", "'mushroom_caps'", ",", "'mushroom_cap'", ",", "'breaded_chicken'", ",", "'frozen_pineapple'", ",", "'pineapple_chunks'", ",", "\n", "'seasoning_mix'", ",", "'seaweed'", ",", "'onion_flakes'", ",", "'bouillon_granules'", ",", "'lettuce_leaf'", ",", "\n", "'stuffing_mix'", ",", "'parsley_flakes'", ",", "'chicken_breast'", ",", "'basil_leaves'", ",", "'baguettes'", ",", "\n", "'green_tea'", ",", "'peanut_butter'", ",", "'green_onion'", ",", "'fresh_cilantro'", ",", "'breaded_chicken'", ",", "\n", "'hot_pepper'", ",", "'dried_lavender'", ",", "'white_chocolate'", ",", "'dill_weed'", ",", "'cake_mix'", ",", "'cheese_spread'", ",", "\n", "'turkey_breast'", ",", "'chucken_thighs'", ",", "'basil_leaves'", ",", "'mandarin_orange'", ",", "'laurel'", ",", "\n", "'cabbage_head'", ",", "'pistachio'", ",", "'cheese_dip'", ",", "'thyme_leave'", ",", "'boneless_pork'", ",", "'red_pepper'", ",", "\n", "'onion_dip'", ",", "'skinless_chicken'", ",", "'dark_chocolate'", ",", "'canned_corn'", ",", "'muffin'", ",", "'cracker_crust'", ",", "\n", "'bread_crumbs'", ",", "'frozen_broccoli'", ",", "'philadelphia'", ",", "'cracker_crust'", ",", "'chicken_breast'", "\n", "]", "\n", "\n", "for", "base_word", "in", "base_words", ":", "\n", "\n", "        ", "if", "base_word", "not", "in", "counter_ingrs", ".", "keys", "(", ")", ":", "\n", "            ", "counter_ingrs", "[", "base_word", "]", "=", "1", "\n", "\n", "", "", "counter_ingrs", ",", "cluster_ingrs", "=", "cluster_ingredients", "(", "counter_ingrs", ")", "\n", "counter_ingrs", ",", "cluster_ingrs", "=", "remove_plurals", "(", "counter_ingrs", ",", "cluster_ingrs", ")", "\n", "\n", "# If the ingredient frequency is less than 'threshold', then the ingredient is discarded.", "\n", "ingrs", "=", "{", "word", ":", "cnt", "for", "word", ",", "cnt", "in", "counter_ingrs", ".", "items", "(", ")", "if", "cnt", ">=", "args", ".", "threshold_ingrs", "}", "\n", "\n", "# Ingredient vocab", "\n", "# Create a vocab wrapper for ingredients", "\n", "vocab_ingrs", "=", "Vocabulary", "(", ")", "\n", "idx", "=", "vocab_ingrs", ".", "add_word", "(", "'<end>'", ")", "\n", "# this returns the next idx to add words to", "\n", "# Add the ingredients to the vocabulary.", "\n", "for", "k", ",", "_", "in", "ingrs", ".", "items", "(", ")", ":", "\n", "        ", "for", "ingr", "in", "cluster_ingrs", "[", "k", "]", ":", "\n", "            ", "idx", "=", "vocab_ingrs", ".", "add_word", "(", "ingr", ",", "idx", ")", "\n", "", "idx", "+=", "1", "\n", "", "_", "=", "vocab_ingrs", ".", "add_word", "(", "'<pad>'", ",", "idx", ")", "\n", "\n", "print", "(", "\"Total ingr vocabulary size: {}\"", ".", "format", "(", "len", "(", "vocab_ingrs", ")", ")", ")", "\n", "\n", "dataset", "=", "{", "'train'", ":", "[", "]", ",", "'val'", ":", "[", "]", ",", "'test'", ":", "[", "]", "}", "\n", "\n", "######", "\n", "# 2. Tokenize and build dataset based on vocabularies.", "\n", "######", "\n", "for", "i", ",", "entry", "in", "tqdm", "(", "enumerate", "(", "layer1", ")", ")", ":", "\n", "\n", "# get all instructions for this recipe", "\n", "        ", "instrs", "=", "entry", "[", "'instructions'", "]", "\n", "\n", "instrs_list", "=", "[", "]", "\n", "ingrs_list", "=", "[", "]", "\n", "images_list", "=", "[", "]", "\n", "\n", "# retrieve pre-detected ingredients for this entry", "\n", "det_ingrs", "=", "dets", "[", "idx2ind", "[", "entry", "[", "'id'", "]", "]", "]", "[", "'ingredients'", "]", "\n", "valid", "=", "dets", "[", "idx2ind", "[", "entry", "[", "'id'", "]", "]", "]", "[", "'valid'", "]", "\n", "labels", "=", "[", "]", "\n", "\n", "for", "j", ",", "det_ingr", "in", "enumerate", "(", "det_ingrs", ")", ":", "\n", "            ", "if", "len", "(", "det_ingr", ")", ">", "0", "and", "valid", "[", "j", "]", ":", "\n", "                ", "det_ingr_undrs", "=", "get_ingredient", "(", "det_ingr", ",", "replace_dict_ingrs", ")", "\n", "ingrs_list", ".", "append", "(", "det_ingr_undrs", ")", "\n", "label_idx", "=", "vocab_ingrs", "(", "det_ingr_undrs", ")", "\n", "if", "label_idx", "is", "not", "vocab_ingrs", "(", "'<pad>'", ")", "and", "label_idx", "not", "in", "labels", ":", "\n", "                    ", "labels", ".", "append", "(", "label_idx", ")", "\n", "\n", "# get raw text for instructions of this entry", "\n", "", "", "", "acc_len", "=", "0", "\n", "for", "instr", "in", "instrs", ":", "\n", "            ", "instr", "=", "instr", "[", "'text'", "]", "\n", "instr", "=", "get_instruction", "(", "instr", ",", "replace_dict_instrs", ")", "\n", "if", "len", "(", "instr", ")", ">", "0", ":", "\n", "                ", "acc_len", "+=", "len", "(", "instr", ")", "\n", "instrs_list", ".", "append", "(", "instr", ")", "\n", "\n", "# we discard recipes with too many or too few ingredients or instruction words", "\n", "", "", "if", "len", "(", "labels", ")", "<", "args", ".", "minnumingrs", "or", "len", "(", "instrs_list", ")", "<", "args", ".", "minnuminstrs", "or", "len", "(", "instrs_list", ")", ">=", "args", ".", "maxnuminstrs", "or", "len", "(", "labels", ")", ">=", "args", ".", "maxnumingrs", "or", "acc_len", "<", "args", ".", "minnumwords", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "entry", "[", "'id'", "]", "in", "id2im", ".", "keys", "(", ")", ":", "\n", "            ", "ims", "=", "layer2", "[", "id2im", "[", "entry", "[", "'id'", "]", "]", "]", "\n", "\n", "# copy image paths for this recipe", "\n", "for", "im", "in", "ims", "[", "'images'", "]", ":", "\n", "                ", "images_list", ".", "append", "(", "im", "[", "'id'", "]", ")", "\n", "\n", "", "", "newentry", "=", "{", "\n", "'id'", ":", "entry", "[", "'id'", "]", ",", "\n", "'ingredients'", ":", "ingrs_list", ",", "\n", "'images'", ":", "images_list", ",", "\n", "}", "\n", "dataset", "[", "entry", "[", "'partition'", "]", "]", ".", "append", "(", "newentry", ")", "\n", "\n", "", "print", "(", "'Dataset size:'", ")", "\n", "for", "split", "in", "dataset", ".", "keys", "(", ")", ":", "\n", "        ", "print", "(", "split", ",", "':'", ",", "len", "(", "dataset", "[", "split", "]", ")", ")", "\n", "\n", "", "return", "vocab_ingrs", ",", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.main": [[352, 363], ["recipe1m_utils.build_vocab_recipe1m", "dataset.keys", "open", "pickle.dump", "os.path.join", "open", "pickle.dump", "os.path.join"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.recipe1m_utils.build_vocab_recipe1m"], ["", "def", "main", "(", "args", ")", ":", "\n", "\n", "    ", "vocab_ingrs", ",", "dataset", "=", "build_vocab_recipe1m", "(", "args", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "args", ".", "suff", "+", "'recipe1m_vocab_ingrs.pkl'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "vocab_ingrs", ",", "f", ")", "\n", "\n", "", "for", "split", "in", "dataset", ".", "keys", "(", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "args", ".", "suff", "+", "'recipe1m_'", "+", "split", "+", "'.pkl'", ")", ",", "\n", "'wb'", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "dataset", "[", "split", "]", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.tb_visualizer.Visualizer.__init__": [[15, 27], ["tensorboardX.SummaryWriter", "glob.glob", "os.remove"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "checkpoints_dir", ",", "name", ",", "resume", "=", "False", ")", ":", "\n", "        ", "self", ".", "win_size", "=", "256", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "saved", "=", "False", "\n", "self", ".", "checkpoints_dir", "=", "checkpoints_dir", "\n", "self", ".", "ncols", "=", "4", "\n", "\n", "# remove existing", "\n", "if", "not", "resume", ":", "\n", "            ", "for", "filename", "in", "glob", ".", "glob", "(", "self", ".", "checkpoints_dir", "+", "\"/events*\"", ")", ":", "\n", "                ", "os", ".", "remove", "(", "filename", ")", "\n", "", "", "self", ".", "writer", "=", "SummaryWriter", "(", "checkpoints_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.tb_visualizer.Visualizer.reset": [[28, 30], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "saved", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.tb_visualizer.Visualizer.image_summary": [[32, 35], ["torchvision.make_grid", "tb_visualizer.Visualizer.writer.add_image"], "methods", ["None"], ["", "def", "image_summary", "(", "self", ",", "mode", ",", "epoch", ",", "images", ")", ":", "\n", "        ", "images", "=", "vutils", ".", "make_grid", "(", "images", ",", "normalize", "=", "True", ",", "scale_each", "=", "True", ")", "\n", "self", ".", "writer", ".", "add_image", "(", "'{}/Image'", ".", "format", "(", "mode", ")", ",", "images", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.tb_visualizer.Visualizer.text_summary": [[37, 55], ["enumerate", "operator.itemgetter", "len", "tb_visualizer.Visualizer.writer.add_text", "tb_visualizer.Visualizer.writer.add_text", "el.nonzero().squeeze", "filter", "len", "el.nonzero"], "methods", ["None"], ["", "def", "text_summary", "(", "self", ",", "mode", ",", "epoch", ",", "type", ",", "text", ",", "vocabulary", ",", "gt", "=", "True", ",", "max_length", "=", "20", ")", ":", "\n", "        ", "for", "i", ",", "el", "in", "enumerate", "(", "text", ")", ":", "# text_list", "\n", "            ", "if", "not", "gt", ":", "# we are printing a sample", "\n", "                ", "idx", "=", "el", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "+", "1", "\n", "", "else", ":", "\n", "                ", "idx", "=", "el", "# we are printing the ground truth", "\n", "\n", "", "words_list", "=", "itemgetter", "(", "*", "idx", ")", "(", "vocabulary", ")", "\n", "\n", "if", "len", "(", "words_list", ")", "<=", "max_length", ":", "\n", "                ", "self", ".", "writer", ".", "add_text", "(", "'{}/{}_{}_{}'", ".", "format", "(", "mode", ",", "type", ",", "i", ",", "'gt'", "\n", "if", "gt", "else", "'prediction'", ")", ",", "\n", "', '", ".", "join", "(", "filter", "(", "lambda", "x", ":", "x", "!=", "'<pad>'", ",", "words_list", ")", ")", ",", "epoch", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "writer", ".", "add_text", "(", "'{}/{}_{}_{}'", ".", "format", "(", "mode", ",", "type", ",", "i", ",", "'gt'", "\n", "if", "gt", "else", "'prediction'", ")", ",", "\n", "'Number of sampled ingredients is too big: {}'", ".", "format", "(", "\n", "len", "(", "words_list", ")", ")", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.tb_visualizer.Visualizer.scalar_summary": [[57, 63], ["args.items", "tb_visualizer.Visualizer.writer.export_scalars_to_json", "tb_visualizer.Visualizer.writer.add_scalar"], "methods", ["None"], ["", "", "", "def", "scalar_summary", "(", "self", ",", "mode", ",", "epoch", ",", "**", "args", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "writer", ".", "add_scalar", "(", "'{}/{}'", ".", "format", "(", "mode", ",", "k", ")", ",", "v", ",", "epoch", ")", "\n", "\n", "", "self", ".", "writer", ".", "export_scalars_to_json", "(", "\"{}/tensorboard_all_scalars.json\"", ".", "format", "(", "\n", "self", ".", "checkpoints_dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.tb_visualizer.Visualizer.histo_summary": [[64, 69], ["model.named_parameters", "tb_visualizer.Visualizer.writer.add_histogram"], "methods", ["None"], ["", "def", "histo_summary", "(", "self", ",", "model", ",", "step", ")", ":", "\n", "        ", "\"\"\"Log a histogram of the tensor of values.\"\"\"", "\n", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "self", ".", "writer", ".", "add_histogram", "(", "name", ",", "param", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.tb_visualizer.Visualizer.close": [[70, 72], ["tb_visualizer.Visualizer.writer.close"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.tb_visualizer.Visualizer.close"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "writer", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.voc_utils.VOCDetection.__init__": [[79, 121], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "voc_utils.download_extract", "os.path.isdir", "RuntimeError", "os.path.exists", "ValueError", "open", "os.path.join", "os.path.join", "len", "len", "image_set.rstrip", "os.path.join", "x.strip", "f.readlines"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.voc_utils.download_extract"], ["def", "__init__", "(", "self", ",", "\n", "root", ",", "\n", "year", "=", "'2012'", ",", "\n", "image_set", "=", "'train'", ",", "\n", "download", "=", "False", ",", "\n", "transform", "=", "None", ",", "\n", "target_transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "root", "=", "root", "\n", "self", ".", "year", "=", "year", "\n", "self", ".", "url", "=", "DATASET_YEAR_DICT", "[", "year", "]", "[", "'url'", "]", "\n", "self", ".", "filename", "=", "DATASET_YEAR_DICT", "[", "year", "]", "[", "'filename'", "]", "\n", "self", ".", "md5", "=", "DATASET_YEAR_DICT", "[", "year", "]", "[", "'md5'", "]", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "image_set", "=", "image_set", "\n", "\n", "voc_root", "=", "self", ".", "root", "\n", "image_dir", "=", "os", ".", "path", ".", "join", "(", "voc_root", ",", "'JPEGImages'", ")", "\n", "annotation_dir", "=", "os", ".", "path", ".", "join", "(", "voc_root", ",", "'Annotations'", ")", "\n", "\n", "if", "download", ":", "\n", "            ", "download_extract", "(", "self", ".", "url", ",", "self", ".", "root", ",", "self", ".", "filename", ",", "self", ".", "md5", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "voc_root", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "'Dataset not found or corrupted.'", "+", "' You can use download=True to download it'", ")", "\n", "\n", "", "splits_dir", "=", "os", ".", "path", ".", "join", "(", "voc_root", ",", "'ImageSets/Main'", ")", "\n", "\n", "split_f", "=", "os", ".", "path", ".", "join", "(", "splits_dir", ",", "image_set", ".", "rstrip", "(", "'\\n'", ")", "+", "'.txt'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "split_f", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Wrong image_set entered! Please use image_set=\"train\" '", "\n", "'or image_set=\"trainval\" or image_set=\"val\" or a valid'", "\n", "'image_set from the VOC ImageSets/Main folder.'", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "split_f", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "file_names", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "self", ".", "images", "=", "[", "os", ".", "path", ".", "join", "(", "image_dir", ",", "x", "+", "\".jpg\"", ")", "for", "x", "in", "file_names", "]", "\n", "self", ".", "annotations", "=", "[", "os", ".", "path", ".", "join", "(", "annotation_dir", ",", "x", "+", "\".xml\"", ")", "for", "x", "in", "file_names", "]", "\n", "assert", "(", "len", "(", "self", ".", "images", ")", "==", "len", "(", "self", ".", "annotations", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.voc_utils.VOCDetection.__getitem__": [[122, 139], ["PIL.Image.open().convert", "voc_utils.VOCDetection.parse_voc_xml", "ET.parse().getroot", "voc_utils.VOCDetection.transform", "voc_utils.VOCDetection.target_transform", "PIL.Image.open", "ET.parse"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.voc_utils.VOCDetection.parse_voc_xml"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is a dictionary of the XML tree.\n        \"\"\"", "\n", "img", "=", "Image", ".", "open", "(", "self", ".", "images", "[", "index", "]", ")", ".", "convert", "(", "'RGB'", ")", "\n", "target", "=", "self", ".", "parse_voc_xml", "(", "ET", ".", "parse", "(", "self", ".", "annotations", "[", "index", "]", ")", ".", "getroot", "(", ")", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.voc_utils.VOCDetection.__len__": [[140, 142], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.voc_utils.VOCDetection.parse_voc_xml": [[143, 157], ["list", "collections.defaultdict", "map", "node.text.strip", "dc.items", "def_dic[].append", "collections.defaultdict.items", "len"], "methods", ["None"], ["", "def", "parse_voc_xml", "(", "self", ",", "node", ")", ":", "\n", "        ", "voc_dict", "=", "{", "}", "\n", "children", "=", "list", "(", "node", ")", "\n", "if", "children", ":", "\n", "            ", "def_dic", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "dc", "in", "map", "(", "self", ".", "parse_voc_xml", ",", "children", ")", ":", "\n", "                ", "for", "ind", ",", "v", "in", "dc", ".", "items", "(", ")", ":", "\n", "                    ", "def_dic", "[", "ind", "]", ".", "append", "(", "v", ")", "\n", "", "", "voc_dict", "=", "{", "node", ".", "tag", ":", "{", "ind", ":", "v", "[", "0", "]", "if", "len", "(", "v", ")", "==", "1", "else", "v", "for", "ind", ",", "v", "in", "def_dic", ".", "items", "(", ")", "}", "}", "\n", "", "if", "node", ".", "text", ":", "\n", "            ", "text", "=", "node", ".", "text", ".", "strip", "(", ")", "\n", "if", "not", "children", ":", "\n", "                ", "voc_dict", "[", "node", ".", "tag", "]", "=", "text", "\n", "", "", "return", "voc_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.utils.voc_utils.download_extract": [[159, 163], ["torchvision.datasets.utils.download_url", "tarfile.open", "tar.extractall", "os.path.join"], "function", ["None"], ["", "", "def", "download_extract", "(", "url", ",", "root", ",", "filename", ",", "md5", ")", ":", "\n", "    ", "download_url", "(", "url", ",", "root", ",", "filename", ",", "md5", ")", "\n", "with", "tarfile", ".", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ")", ",", "\"r\"", ")", "as", "tar", ":", "\n", "        ", "tar", ".", "extractall", "(", "path", "=", "root", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.encoder.EncoderCNN.__init__": [[14, 34], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "ValueError", "torch.Sequential", "torch.Sequential", "globals", "list", "torch.Conv2d", "torch.Conv2d", "torch.Dropout", "torch.Dropout", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "pretrained_net.children"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embed_size", ",", "dropout", "=", "0.5", ",", "image_model", "=", "'resnet50'", ",", "pretrained", "=", "True", ")", ":", "\n", "        ", "\"\"\"Load the pretrained model and replace top fc layer.\"\"\"", "\n", "super", "(", "EncoderCNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "pretrained_net", "=", "globals", "(", ")", "[", "image_model", "]", "(", "pretrained", "=", "pretrained", ")", "\n", "\n", "if", "'resnet'", "in", "image_model", "or", "'resnext'", "in", "image_model", ":", "\n", "            ", "modules", "=", "list", "(", "pretrained_net", ".", "children", "(", ")", ")", "[", ":", "-", "2", "]", "# delete avg pooling and last fc layer", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid image_model {}'", ".", "format", "(", "image_model", ")", ")", "\n", "\n", "", "self", ".", "pretrained_net", "=", "nn", ".", "Sequential", "(", "*", "modules", ")", "\n", "in_dim", "=", "pretrained_net", ".", "fc", ".", "in_features", "\n", "\n", "if", "in_dim", "==", "embed_size", ":", "\n", "            ", "self", ".", "last_module", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "last_module", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_dim", ",", "embed_size", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "nn", ".", "BatchNorm2d", "(", "embed_size", ",", "momentum", "=", "0.01", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.encoder.EncoderCNN.forward": [[35, 58], ["encoder.EncoderCNN.view", "encoder.EncoderCNN.pretrained_net", "encoder.EncoderCNN.last_module", "encoder.EncoderCNN.size", "encoder.EncoderCNN.size", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "encoder.EncoderCNN.pretrained_net"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "images", ",", "keep_cnn_gradients", "=", "False", ")", ":", "\n", "        ", "\"\"\"Extract feature vectors from input images.\"\"\"", "\n", "\n", "if", "images", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "# Get encoder output", "\n", "", "if", "keep_cnn_gradients", ":", "\n", "            ", "raw_conv_feats", "=", "self", ".", "pretrained_net", "(", "images", ")", "\n", "", "else", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "raw_conv_feats", "=", "self", ".", "pretrained_net", "(", "images", ")", "\n", "\n", "# Apply last_module to change the number of channels in the encoder output", "\n", "", "", "if", "self", ".", "last_module", "is", "not", "None", ":", "\n", "            ", "features", "=", "self", ".", "last_module", "(", "raw_conv_feats", ")", "\n", "", "else", ":", "\n", "            ", "features", "=", "raw_conv_feats", "\n", "\n", "# Reshape features", "\n", "", "features", "=", "features", ".", "view", "(", "features", ".", "size", "(", "0", ")", ",", "features", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "\n", "return", "features", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.ff_decoder.FFDecoder.__init__": [[11, 48], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "fc_layers.extend", "len", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear"], ["    ", "def", "__init__", "(", "self", ",", "\n", "embed_size", ",", "\n", "vocab_size", ",", "\n", "hidden_size", ",", "\n", "dropout", "=", "0.0", ",", "\n", "pred_cardinality", "=", "'none'", ",", "\n", "nobjects", "=", "10", ",", "\n", "n_layers", "=", "1", ",", "\n", "use_empty_set", "=", "False", ")", ":", "\n", "        ", "super", "(", "FFDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "in_dim", "=", "embed_size", "\n", "\n", "# Add fully connected layers", "\n", "fc_layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "fc_layers", ".", "extend", "(", "[", "\n", "nn", ".", "Linear", "(", "in_dim", ",", "hidden_size", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "hidden_size", ",", "momentum", "=", "0.01", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", "]", ")", "\n", "in_dim", "=", "hidden_size", "\n", "\n", "", "if", "len", "(", "fc_layers", ")", "!=", "0", ":", "\n", "            ", "self", ".", "fc_layers", "=", "nn", ".", "Sequential", "(", "*", "fc_layers", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "fc_layers", "=", "None", "\n", "\n", "", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "hidden_size", ",", "vocab_size", "-", "1", ")", ")", "\n", "\n", "self", ".", "pred_cardinality", "=", "pred_cardinality", "\n", "if", "self", ".", "pred_cardinality", "!=", "'none'", ":", "\n", "            ", "if", "use_empty_set", ":", "\n", "# This is to account for 0 when using cardinality prediction and dealing with datasets with empty sets", "\n", "                ", "nobjects", "+=", "1", "\n", "", "self", ".", "fc_cardinality", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "hidden_size", ",", "nobjects", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.ff_decoder.FFDecoder.forward": [[49, 68], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "ff_decoder.FFDecoder.classifier", "ff_decoder.FFDecoder.fc_layers", "torch.ReLU", "torch.ReLU", "ff_decoder.FFDecoder.fc_cardinality", "ff_decoder.FFDecoder.fc_cardinality"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "img_features", ")", ":", "\n", "\n", "# Apply global average pooling", "\n", "        ", "feat", "=", "torch", ".", "mean", "(", "img_features", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Apply fully connected layers", "\n", "if", "self", ".", "fc_layers", "is", "not", "None", ":", "\n", "            ", "feat", "=", "self", ".", "fc_layers", "(", "feat", ")", "\n", "\n", "# Apply classifier", "\n", "", "logits", "=", "self", ".", "classifier", "(", "feat", ")", "\n", "\n", "# Apply cardinality layer", "\n", "if", "self", ".", "pred_cardinality", "==", "'dc'", ":", "\n", "            ", "return", "logits", ",", "nn", ".", "ReLU", "(", ")", "(", "self", ".", "fc_cardinality", "(", "feat", ")", ")", "\n", "", "elif", "self", ".", "pred_cardinality", "!=", "'none'", ":", "\n", "            ", "return", "logits", ",", "self", ".", "fc_cardinality", "(", "feat", ")", "\n", "", "else", ":", "\n", "            ", "return", "logits", ",", "None", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.__init__": [[22, 40], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "multihead_attention.MultiheadAttention.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.Parameter", "torch.nn.Parameter", "multihead_attention.MultiheadAttention.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.reset_parameters"], ["def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "dropout", "=", "0.", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "self", ".", "_mask", "=", "None", "\n", "\n", "self", ".", "in_proj_weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ",", "embed_dim", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "in_proj_bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'in_proj_bias'", ",", "None", ")", "\n", "", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.reset_parameters": [[41, 47], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "in_proj_weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "out_proj", ".", "weight", ")", "\n", "if", "self", ".", "in_proj_bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "in_proj_bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.forward": [[48, 155], ["query.size", "multihead_attention.MultiheadAttention.new.size", "multihead_attention.MultiheadAttention.contiguous().view().transpose", "multihead_attention.MultiheadAttention.new.contiguous().view().transpose", "multihead_attention.MultiheadAttention.new.contiguous().view().transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax().type_as", "torch.softmax().type_as", "torch.dropout", "torch.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "multihead_attention.MultiheadAttention.transpose().contiguous().view", "multihead_attention.MultiheadAttention.out_proj", "query.data_ptr", "key.data_ptr", "value.data_ptr", "key.data_ptr", "value.data_ptr", "list", "key.size", "value.size", "multihead_attention.MultiheadAttention._get_input_buffer", "multihead_attention.MultiheadAttention.in_proj_qkv", "multihead_attention.MultiheadAttention._set_input_buffer", "multihead_attention.MultiheadAttention.new.transpose", "list", "multihead_attention.MultiheadAttention.buffered_mask().unsqueeze", "attn_weights.view.view.view", "attn_weights.view.view.float().masked_fill().type_as", "attn_weights.view.view.view", "list", "attn_weights.view.view.view", "query.size", "multihead_attention.MultiheadAttention.in_proj_q", "multihead_attention.MultiheadAttention.in_proj_q", "multihead_attention.MultiheadAttention.in_proj_k", "multihead_attention.MultiheadAttention.in_proj_v", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "key_padding_mask.size", "key_padding_mask.size", "multihead_attention.MultiheadAttention.contiguous().view", "multihead_attention.MultiheadAttention.new.contiguous().view", "multihead_attention.MultiheadAttention.new.contiguous().view", "attn_weights.view.view.size", "query.size", "key.size", "torch.softmax", "torch.softmax", "multihead_attention.MultiheadAttention.size", "multihead_attention.MultiheadAttention.transpose().contiguous", "attn_weights.view.view.sum", "multihead_attention.MultiheadAttention.new", "multihead_attention.MultiheadAttention.in_proj_kv", "multihead_attention.MultiheadAttention.buffered_mask", "attn_weights.view.view.float().masked_fill", "attn_weights.view.view.float", "multihead_attention.MultiheadAttention.contiguous", "multihead_attention.MultiheadAttention.new.contiguous", "multihead_attention.MultiheadAttention.new.contiguous", "key_padding_mask.unsqueeze().unsqueeze", "float", "multihead_attention.MultiheadAttention.transpose", "attn_weights.view.view.float", "key_padding_mask.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution._get_input_buffer", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.in_proj_qkv", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution._set_input_buffer", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.in_proj_k", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.in_proj_v", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.in_proj_kv", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.buffered_mask"], ["", "", "def", "forward", "(", "self", ",", "\n", "query", ",", "\n", "key", ",", "\n", "value", ",", "\n", "mask_future_timesteps", "=", "False", ",", "\n", "key_padding_mask", "=", "None", ",", "\n", "incremental_state", "=", "None", ",", "\n", "need_weights", "=", "True", ",", "\n", "static_kv", "=", "False", ")", ":", "\n", "        ", "\"\"\"Input shape: Time x Batch x Channel\n        Self-attention can be implemented by passing in the same arguments for\n        query, key and value. Future timesteps can be masked with the\n        `mask_future_timesteps` argument. Padding elements can be excluded from\n        the key by passing a binary ByteTensor (`key_padding_mask`) with shape:\n        batch x src_len, where padding elements are indicated by 1s.\n        \"\"\"", "\n", "\n", "qkv_same", "=", "query", ".", "data_ptr", "(", ")", "==", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "kv_same", "=", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "\n", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "embed_dim", "==", "self", ".", "embed_dim", "\n", "assert", "list", "(", "query", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "bsz", ",", "embed_dim", "]", "\n", "assert", "key", ".", "size", "(", ")", "==", "value", ".", "size", "(", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "saved_state", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "'prev_key'", "in", "saved_state", ":", "\n", "# previous time steps are cached - no need to recompute", "\n", "# key and value if they are static", "\n", "                ", "if", "static_kv", ":", "\n", "                    ", "assert", "kv_same", "and", "not", "qkv_same", "\n", "key", "=", "value", "=", "None", "\n", "", "", "", "else", ":", "\n", "            ", "saved_state", "=", "None", "\n", "\n", "", "if", "qkv_same", ":", "\n", "# self-attention", "\n", "            ", "q", ",", "k", ",", "v", "=", "self", ".", "in_proj_qkv", "(", "query", ")", "\n", "", "elif", "kv_same", ":", "\n", "# encoder-decoder attention", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "if", "key", "is", "None", ":", "\n", "                ", "assert", "value", "is", "None", "\n", "# this will allow us to concat it with previous value and get", "\n", "# just get the previous value", "\n", "k", "=", "v", "=", "q", ".", "new", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "k", ",", "v", "=", "self", ".", "in_proj_kv", "(", "key", ")", "\n", "", "", "else", ":", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "k", "=", "self", ".", "in_proj_k", "(", "key", ")", "\n", "v", "=", "self", ".", "in_proj_v", "(", "value", ")", "\n", "", "q", "*=", "self", ".", "scaling", "\n", "\n", "if", "saved_state", "is", "not", "None", ":", "\n", "            ", "if", "'prev_key'", "in", "saved_state", ":", "\n", "                ", "k", "=", "torch", ".", "cat", "(", "(", "saved_state", "[", "'prev_key'", "]", ",", "k", ")", ",", "dim", "=", "0", ")", "\n", "", "if", "'prev_value'", "in", "saved_state", ":", "\n", "                ", "v", "=", "torch", ".", "cat", "(", "(", "saved_state", "[", "'prev_value'", "]", ",", "v", ")", ",", "dim", "=", "0", ")", "\n", "", "saved_state", "[", "'prev_key'", "]", "=", "k", "\n", "saved_state", "[", "'prev_value'", "]", "=", "v", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "\n", "", "src_len", "=", "k", ".", "size", "(", "0", ")", "\n", "\n", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "assert", "key_padding_mask", ".", "size", "(", "0", ")", "==", "bsz", "\n", "assert", "key_padding_mask", ".", "size", "(", "1", ")", "==", "src_len", "\n", "\n", "", "q", "=", "q", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "k", "=", "k", ".", "contiguous", "(", ")", ".", "view", "(", "src_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "v", "=", "v", ".", "contiguous", "(", ")", ".", "view", "(", "src_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "assert", "list", "(", "attn_weights", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "]", "\n", "\n", "# only apply masking at training time (when incremental state is None)", "\n", "if", "mask_future_timesteps", "and", "incremental_state", "is", "None", ":", "\n", "            ", "assert", "query", ".", "size", "(", ")", "==", "key", ".", "size", "(", ")", ",", "'mask_future_timesteps only applies to self-attention'", "\n", "attn_weights", "+=", "self", ".", "buffered_mask", "(", "attn_weights", ")", ".", "unsqueeze", "(", "0", ")", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# don't attend to padding symbols", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_weights", "=", "attn_weights", ".", "float", "(", ")", ".", "masked_fill", "(", "\n", "key_padding_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "\n", "float", "(", "'-inf'", ")", ",", "\n", ")", ".", "type_as", "(", "attn_weights", ")", "# FP16 support: cast to float and back", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "attn_weights", "=", "F", ".", "softmax", "(", "attn_weights", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "type_as", "(", "attn_weights", ")", "\n", "attn_weights", "=", "F", ".", "dropout", "(", "attn_weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "attn", "=", "torch", ".", "bmm", "(", "attn_weights", ",", "v", ")", "\n", "assert", "list", "(", "attn", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", "]", "\n", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "attn", "=", "self", ".", "out_proj", "(", "attn", ")", "\n", "\n", "if", "need_weights", ":", "\n", "# average attention weights over heads", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_weights", "=", "attn_weights", ".", "sum", "(", "dim", "=", "1", ")", "/", "self", ".", "num_heads", "\n", "", "else", ":", "\n", "            ", "attn_weights", "=", "None", "\n", "\n", "", "return", "attn", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.in_proj_qkv": [[156, 158], ["multihead_attention.MultiheadAttention._in_proj().chunk", "multihead_attention.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention._in_proj"], ["", "def", "in_proj_qkv", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ")", ".", "chunk", "(", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.in_proj_kv": [[159, 161], ["multihead_attention.MultiheadAttention._in_proj().chunk", "multihead_attention.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention._in_proj"], ["", "def", "in_proj_kv", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.in_proj_q": [[162, 164], ["multihead_attention.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention._in_proj"], ["", "def", "in_proj_q", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ",", "end", "=", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.in_proj_k": [[165, 167], ["multihead_attention.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention._in_proj"], ["", "def", "in_proj_k", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ",", "end", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.in_proj_v": [[168, 170], ["multihead_attention.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention._in_proj"], ["", "def", "in_proj_v", "(", "self", ",", "value", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "value", ",", "start", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention._in_proj": [[171, 183], ["torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "_in_proj", "(", "self", ",", "input", ",", "start", "=", "None", ",", "end", "=", "None", ")", ":", "\n", "        ", "weight", "=", "self", ".", "in_proj_weight", "\n", "bias", "=", "self", ".", "in_proj_bias", "\n", "if", "end", "is", "not", "None", ":", "\n", "            ", "weight", "=", "weight", "[", ":", "end", ",", ":", "]", "\n", "if", "bias", "is", "not", "None", ":", "\n", "                ", "bias", "=", "bias", "[", ":", "end", "]", "\n", "", "", "if", "start", "is", "not", "None", ":", "\n", "            ", "weight", "=", "weight", "[", "start", ":", ",", ":", "]", "\n", "if", "bias", "is", "not", "None", ":", "\n", "                ", "bias", "=", "bias", "[", "start", ":", "]", "\n", "", "", "return", "F", ".", "linear", "(", "input", ",", "weight", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.buffered_mask": [[184, 191], ["tensor.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "multihead_attention.MultiheadAttention._mask.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "modules.utils.fill_with_neg_inf", "modules.utils.fill_with_neg_inf", "tensor.new", "multihead_attention.MultiheadAttention._mask.resize_"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.fill_with_neg_inf", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.fill_with_neg_inf"], ["", "def", "buffered_mask", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "dim", "=", "tensor", ".", "size", "(", "-", "1", ")", "\n", "if", "self", ".", "_mask", "is", "None", ":", "\n", "            ", "self", ".", "_mask", "=", "torch", ".", "triu", "(", "fill_with_neg_inf", "(", "tensor", ".", "new", "(", "dim", ",", "dim", ")", ")", ",", "1", ")", "\n", "", "if", "self", ".", "_mask", ".", "size", "(", "0", ")", "<", "dim", ":", "\n", "            ", "self", ".", "_mask", "=", "torch", ".", "triu", "(", "fill_with_neg_inf", "(", "self", ".", "_mask", ".", "resize_", "(", "dim", ",", "dim", ")", ")", ",", "1", ")", "\n", "", "return", "self", ".", "_mask", "[", ":", "dim", ",", ":", "dim", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention.reorder_incremental_state": [[192, 199], ["multihead_attention.MultiheadAttention._get_input_buffer", "multihead_attention.MultiheadAttention.keys", "multihead_attention.MultiheadAttention._set_input_buffer", "input_buffer[].index_select"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution._get_input_buffer", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution._set_input_buffer"], ["", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"Reorder buffered internal state (for incremental generation).\"\"\"", "\n", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "for", "k", "in", "input_buffer", ".", "keys", "(", ")", ":", "\n", "                ", "input_buffer", "[", "k", "]", "=", "input_buffer", "[", "k", "]", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention._get_input_buffer": [[200, 206], ["modules.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.get_incremental_state"], ["", "", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "return", "get_incremental_state", "(", "\n", "self", ",", "\n", "incremental_state", ",", "\n", "'attn_state'", ",", "\n", ")", "or", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.multihead_attention.MultiheadAttention._set_input_buffer": [[207, 213], ["modules.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.set_incremental_state"], ["", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ",", "buffer", ")", ":", "\n", "        ", "set_incremental_state", "(", "\n", "self", ",", "\n", "incremental_state", ",", "\n", "'attn_state'", ",", "\n", "buffer", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.rnn_decoder.AttentionLayer.__init__": [[17, 29], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv1d", "torch.Conv1d", "torch.Sequential", "torch.Sequential", "torch.Conv1d", "torch.Conv1d", "torch.ReLU", "torch.ReLU", "torch.Conv1d", "torch.Conv1d", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear"], ["    ", "def", "__init__", "(", "self", ",", "embed_size", ",", "hidden_size", ")", ":", "\n", "        ", "super", "(", "AttentionLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "linear_feats", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "embed_size", ",", "hidden_size", ",", "kernel_size", "=", "1", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "self", ".", "embed_feats", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv1d", "(", "hidden_size", ",", "hidden_size", ",", "kernel_size", "=", "1", ")", ")", "\n", "\n", "self", ".", "linear_hidden", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", ",", "nn", ".", "Tanh", "(", ")", ")", "\n", "self", ".", "embed_hidden", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", ")", "\n", "\n", "self", ".", "att_coeffs", "=", "nn", ".", "Conv1d", "(", "hidden_size", ",", "1", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "linear_out", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", ",", "nn", ".", "Tanh", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.rnn_decoder.AttentionLayer.forward": [[30, 53], ["rnn_decoder.AttentionLayer.linear_feats", "rnn_decoder.AttentionLayer.embed_feats", "rnn_decoder.AttentionLayer.linear_hidden", "rnn_decoder.AttentionLayer.embed_hidden", "rnn_decoder.AttentionLayer.unsqueeze", "hidden_repeat.expand.expand.expand", "rnn_decoder.AttentionLayer.att_coeffs", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax.expand", "torch.nn.functional.softmax.expand", "rnn_decoder.AttentionLayer.linear_out", "rnn_decoder.AttentionLayer.size", "torch.Tanh", "torch.Tanh", "rnn_decoder.AttentionLayer.size", "v.sum", "torch.nn.functional.softmax.squeeze", "torch.nn.functional.softmax.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "hidden", ")", ":", "\n", "\n", "        ", "features", "=", "self", ".", "linear_feats", "(", "features", ")", "\n", "features_embed", "=", "self", ".", "embed_feats", "(", "features", ")", "\n", "\n", "hidden", "=", "self", ".", "linear_hidden", "(", "hidden", ")", "\n", "hidden_embed", "=", "self", ".", "embed_hidden", "(", "hidden", ")", "\n", "\n", "hidden_repeat", "=", "hidden_embed", ".", "unsqueeze", "(", "2", ")", "\n", "hidden_repeat", "=", "hidden_repeat", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "features_embed", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "merged", "=", "nn", ".", "Tanh", "(", ")", "(", "features_embed", "+", "hidden_repeat", ")", "\n", "att_coeffs", "=", "self", ".", "att_coeffs", "(", "merged", ")", "\n", "att_coeffs", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "att_coeffs", ",", "dim", "=", "2", ")", "\n", "\n", "att_coeffs_exp", "=", "att_coeffs", ".", "expand", "(", "-", "1", ",", "features", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "\n", "v", "=", "att_coeffs_exp", "*", "features", "\n", "\n", "v", "=", "v", ".", "sum", "(", "dim", "=", "-", "1", ")", "+", "hidden", "\n", "out", "=", "self", ".", "linear_out", "(", "v", ")", "\n", "\n", "return", "out", ",", "att_coeffs", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.rnn_decoder.LSTMAtt.__init__": [[57, 66], ["torch.Module.__init__", "torch.LSTMCell", "torch.LSTMCell", "rnn_decoder.AttentionLayer"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embed_size", ",", "hidden_size", ")", ":", "\n", "        ", "\"\"\"Set the hyper-parameters and build the layers.\"\"\"", "\n", "super", "(", "LSTMAtt", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "lstmcell", "=", "nn", ".", "LSTMCell", "(", "embed_size", "*", "2", ",", "hidden_size", ")", "\n", "\n", "self", ".", "attention", "=", "AttentionLayer", "(", "embed_size", ",", "hidden_size", ")", "\n", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.rnn_decoder.LSTMAtt.forward": [[67, 79], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "rnn_decoder.LSTMAtt.lstmcell", "rnn_decoder.LSTMAtt.attention", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "input_feat.size", "input_feat.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_feat", ",", "features", ",", "prev_word", ",", "states", ")", ":", "\n", "\n", "        ", "if", "states", "is", "None", ":", "\n", "            ", "states", "=", "(", "torch", ".", "zeros", "(", "input_feat", ".", "size", "(", "0", ")", ",", "self", ".", "hidden_size", ")", ".", "cuda", "(", ")", ",", "\n", "torch", ".", "zeros", "(", "input_feat", ".", "size", "(", "0", ")", ",", "self", ".", "hidden_size", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "", "input", "=", "torch", ".", "cat", "(", "(", "input_feat", ",", "prev_word", ")", ",", "1", ")", "\n", "states", "=", "self", ".", "lstmcell", "(", "input", ",", "states", ")", "\n", "\n", "v", ",", "att_coeffs", "=", "self", ".", "attention", "(", "features", ",", "states", "[", "0", "]", ")", "\n", "\n", "return", "v", ",", "states", ",", "att_coeffs", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.rnn_decoder.DecoderRNN.__init__": [[83, 99], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "rnn_decoder.LSTMAtt"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Embedding", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Embedding", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear"], ["    ", "def", "__init__", "(", "self", ",", "\n", "embed_size", ",", "\n", "hidden_size", ",", "\n", "vocab_size", ",", "\n", "dropout", "=", "0.5", ",", "\n", "seq_length", "=", "20", ",", "\n", "num_instrs", "=", "15", ")", ":", "\n", "\n", "        ", "super", "(", "DecoderRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embed_size", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "vocab_size", "-", "1", ")", "\n", "self", ".", "core", "=", "LSTMAtt", "(", "embed_size", ",", "hidden_size", ")", "\n", "\n", "self", ".", "seq_length", "=", "seq_length", "*", "num_instrs", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "embed_size", "=", "embed_size", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.rnn_decoder.DecoderRNN.forward": [[100, 126], ["rnn_decoder.DecoderRNN.embed", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "rnn_decoder.DecoderRNN.size", "rnn_decoder.DecoderRNN.core", "torch.nn.functional.dropout", "torch.nn.functional.dropout", "torch.nn.functional.dropout", "torch.nn.functional.dropout", "rnn_decoder.DecoderRNN.linear", "rnn_decoder.DecoderRNN.max", "sampled_ids.append", "outputs.append", "rnn_decoder.DecoderRNN.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "mask", ",", "captions", ")", ":", "\n", "\n", "        ", "embeddings", "=", "self", ".", "embed", "(", "captions", ")", "\n", "\n", "avg_feats", "=", "torch", ".", "mean", "(", "features", ",", "dim", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "[", "]", "\n", "states", "=", "None", "\n", "sampled_ids", "=", "[", "]", "\n", "\n", "input_feat", "=", "avg_feats", "\n", "for", "i", "in", "range", "(", "embeddings", ".", "size", "(", "1", ")", ")", ":", "\n", "\n", "            ", "v", ",", "states", ",", "atts", "=", "self", ".", "core", "(", "input_feat", ",", "features", ",", "embeddings", "[", ":", ",", "i", "]", ",", "states", ")", "\n", "input_feat", "=", "v", "\n", "v", "=", "torch", ".", "nn", ".", "functional", ".", "dropout", "(", "v", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "o", "=", "self", ".", "linear", "(", "v", ")", "\n", "\n", "_", ",", "predicted", "=", "o", ".", "max", "(", "1", ")", "\n", "sampled_ids", ".", "append", "(", "predicted", ")", "\n", "\n", "outputs", ".", "append", "(", "o", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n", "", "outs", "=", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "\n", "return", "outs", ",", "sampled_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.rnn_decoder.DecoderRNN.sample": [[127, 182], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "features.size", "rnn_decoder.DecoderRNN.embed().squeeze", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.ones().cuda().long", "torch.ones().cuda().long", "torch.ones().cuda().long", "torch.ones().cuda().long", "rnn_decoder.DecoderRNN.core", "rnn_decoder.DecoderRNN.linear", "outputs.squeeze.squeeze.squeeze", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "rnn_decoder.DecoderRNN.embed", "rnn_decoder.DecoderRNN.embed", "outputs.squeeze.squeeze.max", "[].detach.detach", "torch.div", "torch.div", "torch.div", "torch.div", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "[].detach", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.zeros().float().to", "torch.zeros().float().to", "torch.zeros().float().to", "torch.zeros().float().to", "float", "outputs.squeeze.squeeze.squeeze", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "range", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "\n", "features", ",", "\n", "mask", ",", "\n", "greedy", "=", "True", ",", "\n", "temperature", "=", "1.0", ",", "\n", "first_token_value", "=", "0", ",", "\n", "replacement", "=", "True", ")", ":", "\n", "        ", "\"\"\"Generate captions for given image features.\"\"\"", "\n", "logits", "=", "[", "]", "\n", "avg_feats", "=", "torch", ".", "mean", "(", "features", ",", "dim", "=", "-", "1", ")", "\n", "\n", "inputs", "=", "avg_feats", "\n", "states", "=", "None", "\n", "fs", "=", "features", ".", "size", "(", "0", ")", "\n", "prev_word", "=", "torch", ".", "ones", "(", "fs", ",", "1", ")", ".", "cuda", "(", ")", ".", "long", "(", ")", "*", "first_token_value", "\n", "sampled_ids", "=", "[", "prev_word", "]", "\n", "prev_word", "=", "self", ".", "embed", "(", "prev_word", ")", ".", "squeeze", "(", "1", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "seq_length", ")", ":", "\n", "            ", "v", ",", "states", ",", "att_coeffs", "=", "self", ".", "core", "(", "inputs", ",", "features", ",", "prev_word", ",", "states", ")", "\n", "inputs", "=", "v", "\n", "outputs", "=", "self", ".", "linear", "(", "v", ")", "\n", "\n", "outputs", "=", "outputs", ".", "squeeze", "(", "1", ")", "\n", "if", "not", "replacement", ":", "\n", "# predicted mask", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "predicted_mask", "=", "torch", ".", "zeros", "(", "outputs", ".", "shape", ")", ".", "float", "(", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "                    ", "batch_ind", "=", "[", "j", "for", "j", "in", "range", "(", "fs", ")", "if", "sampled_ids", "[", "i", "]", "[", "j", "]", "!=", "0", "]", "\n", "sampled_ids_new", "=", "sampled_ids", "[", "i", "]", "[", "batch_ind", "]", "\n", "predicted_mask", "[", "batch_ind", ",", "sampled_ids_new", "]", "=", "float", "(", "'-inf'", ")", "\n", "\n", "# mask previously selected ids", "\n", "", "outputs", "+=", "predicted_mask", "\n", "\n", "", "logits", ".", "append", "(", "outputs", ")", "\n", "# outputs = torch.nn.functional.log_softmax(outputs, dim=1)", "\n", "if", "greedy", ":", "\n", "                ", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "predicted", "=", "predicted", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "                ", "k", "=", "10", "\n", "prob_prev", "=", "torch", ".", "div", "(", "outputs", ".", "squeeze", "(", "1", ")", ",", "temperature", ")", "\n", "prob_prev", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "prob_prev", ",", "dim", "=", "-", "1", ")", ".", "data", "\n", "# top k random sampling", "\n", "prob_prev_topk", ",", "indices", "=", "torch", ".", "topk", "(", "prob_prev", ",", "k", "=", "k", ",", "dim", "=", "1", ")", "\n", "predicted", "=", "torch", ".", "multinomial", "(", "prob_prev_topk", ",", "1", ")", ".", "view", "(", "-", "1", ")", "\n", "predicted", "=", "torch", ".", "index_select", "(", "indices", ",", "dim", "=", "1", ",", "index", "=", "predicted", ")", "[", ":", ",", "0", "]", ".", "detach", "(", ")", "\n", "", "sampled_ids", ".", "append", "(", "predicted", ")", "\n", "prev_word", "=", "self", ".", "embed", "(", "predicted", ")", "\n", "\n", "", "logits", "=", "torch", ".", "stack", "(", "logits", ",", "1", ")", "\n", "sampled_ids", "=", "torch", ".", "stack", "(", "sampled_ids", "[", "1", ":", "]", ",", "1", ")", "\n", "\n", "return", "sampled_ids", ",", "logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.SinusoidalPositionalEmbedding.__init__": [[28, 39], ["torch.Module.__init__", "transformer_decoder.SinusoidalPositionalEmbedding.get_embedding", "transformer_decoder.SinusoidalPositionalEmbedding.register_buffer", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.SinusoidalPositionalEmbedding.get_embedding"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "padding_idx", ",", "left_pad", ",", "init_size", "=", "1024", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "left_pad", "=", "left_pad", "\n", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "init_size", ",", "\n", "embedding_dim", ",", "\n", "padding_idx", ",", "\n", ")", "\n", "self", ".", "register_buffer", "(", "'_float_tensor'", ",", "torch", ".", "FloatTensor", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.SinusoidalPositionalEmbedding.get_embedding": [[40, 57], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "math.log", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "None", ")", ":", "\n", "        ", "\"\"\"Build sinusoidal embeddings.\n        This matches the implementation in tensor2tensor, but differs slightly\n        from the description in Section 3.5 of \"Attention Is All You Need\".\n        \"\"\"", "\n", "half_dim", "=", "embedding_dim", "//", "2", "\n", "emb", "=", "math", ".", "log", "(", "10000", ")", "/", "(", "half_dim", "-", "1", ")", "\n", "emb", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "half_dim", ",", "dtype", "=", "torch", ".", "float", ")", "*", "-", "emb", ")", "\n", "emb", "=", "torch", ".", "arange", "(", "num_embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "1", ")", "*", "emb", ".", "unsqueeze", "(", "0", ")", "\n", "emb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "emb", ")", ",", "torch", ".", "cos", "(", "emb", ")", "]", ",", "dim", "=", "1", ")", ".", "view", "(", "num_embeddings", ",", "-", "1", ")", "\n", "if", "embedding_dim", "%", "2", "==", "1", ":", "\n", "# zero pad", "\n", "            ", "emb", "=", "torch", ".", "cat", "(", "[", "emb", ",", "torch", ".", "zeros", "(", "num_embeddings", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "emb", "[", "padding_idx", ",", ":", "]", "=", "0", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.SinusoidalPositionalEmbedding.forward": [[58, 77], ["input.size", "transformer_decoder.SinusoidalPositionalEmbedding.weights.type_as", "modules.layers.make_positions", "transformer_decoder.SinusoidalPositionalEmbedding.weights.index_select().view().detach", "transformer_decoder.SinusoidalPositionalEmbedding.get_embedding", "transformer_decoder.SinusoidalPositionalEmbedding.weights[].expand", "transformer_decoder.SinusoidalPositionalEmbedding.weights.size", "transformer_decoder.SinusoidalPositionalEmbedding.weights.index_select().view", "transformer_decoder.SinusoidalPositionalEmbedding.weights.index_select", "modules.layers.make_positions.view"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.make_positions", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.SinusoidalPositionalEmbedding.get_embedding"], ["", "def", "forward", "(", "self", ",", "input", ",", "incremental_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"", "\n", "# recompute/expand embeddings if needed", "\n", "bsz", ",", "seq_len", "=", "input", ".", "size", "(", ")", "\n", "max_pos", "=", "self", ".", "padding_idx", "+", "1", "+", "seq_len", "\n", "if", "self", ".", "weights", "is", "None", "or", "max_pos", ">", "self", ".", "weights", ".", "size", "(", "0", ")", ":", "\n", "            ", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "max_pos", ",", "\n", "self", ".", "embedding_dim", ",", "\n", "self", ".", "padding_idx", ",", "\n", ")", "\n", "", "self", ".", "weights", "=", "self", ".", "weights", ".", "type_as", "(", "self", ".", "_float_tensor", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "# positions is the same for every token when decoding a single step", "\n", "            ", "return", "self", ".", "weights", "[", "self", ".", "padding_idx", "+", "seq_len", ",", ":", "]", ".", "expand", "(", "bsz", ",", "1", ",", "-", "1", ")", "\n", "\n", "", "positions", "=", "make_positions", "(", "input", ".", "data", ",", "self", ".", "padding_idx", ",", "self", ".", "left_pad", ")", "\n", "return", "self", ".", "weights", ".", "index_select", "(", "0", ",", "positions", ".", "view", "(", "-", "1", ")", ")", ".", "view", "(", "bsz", ",", "seq_len", ",", "-", "1", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.SinusoidalPositionalEmbedding.max_positions": [[78, 81], ["int"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum number of supported positions.\"\"\"", "\n", "return", "int", "(", "1e5", ")", "# an arbitrary large number", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.TransformerDecoderLayer.__init__": [[86, 111], ["torch.Module.__init__", "modules.multihead_attention.MultiheadAttention", "modules.multihead_attention.MultiheadAttention", "transformer_decoder.Linear", "transformer_decoder.Linear", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "transformer_decoder.LayerNorm", "range"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.LayerNorm"], ["def", "__init__", "(", "self", ",", "embed_dim", ",", "n_att", ",", "dropout", "=", "0.5", ",", "normalize_before", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "relu_dropout", "=", "dropout", "\n", "self", ".", "normalize_before", "=", "normalize_before", "\n", "num_layer_norm", "=", "3", "\n", "\n", "# self-attention on generated recipe", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "\n", "self", ".", "embed_dim", ",", "\n", "n_att", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "\n", "self", ".", "encoder_attn", "=", "MultiheadAttention", "(", "\n", "self", ".", "embed_dim", ",", "\n", "n_att", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "\n", "self", ".", "fc1", "=", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "fc2", "=", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "layer_norms", "=", "nn", ".", "ModuleList", "(", "[", "LayerNorm", "(", "self", ".", "embed_dim", ")", "for", "i", "in", "range", "(", "num_layer_norm", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.TransformerDecoderLayer.forward": [[112, 154], ["transformer_decoder.TransformerDecoderLayer.maybe_layer_norm", "transformer_decoder.TransformerDecoderLayer.self_attn", "torch.dropout", "torch.dropout", "torch.dropout", "transformer_decoder.TransformerDecoderLayer.maybe_layer_norm", "transformer_decoder.TransformerDecoderLayer.maybe_layer_norm", "transformer_decoder.TransformerDecoderLayer.encoder_attn", "torch.dropout", "torch.dropout", "torch.dropout", "transformer_decoder.TransformerDecoderLayer.maybe_layer_norm", "transformer_decoder.TransformerDecoderLayer.maybe_layer_norm", "torch.relu", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "torch.dropout", "transformer_decoder.TransformerDecoderLayer.fc2", "torch.dropout", "torch.dropout", "torch.dropout", "transformer_decoder.TransformerDecoderLayer.maybe_layer_norm", "transformer_decoder.TransformerDecoderLayer.fc1"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.TransformerDecoderLayer.maybe_layer_norm"], ["", "def", "forward", "(", "self", ",", "x", ",", "encoder_out", ",", "encoder_padding_mask", ",", "incremental_state", ")", ":", "\n", "\n", "# self attention", "\n", "        ", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "0", ",", "x", ",", "before", "=", "True", ")", "\n", "x", ",", "_", "=", "self", ".", "self_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "x", ",", "\n", "value", "=", "x", ",", "\n", "mask_future_timesteps", "=", "True", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", "need_weights", "=", "False", ",", "\n", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "0", ",", "x", ",", "after", "=", "True", ")", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "1", ",", "x", ",", "before", "=", "True", ")", "\n", "\n", "x", ",", "attn", "=", "self", ".", "encoder_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "encoder_out", ",", "\n", "value", "=", "encoder_out", ",", "\n", "key_padding_mask", "=", "encoder_padding_mask", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", "static_kv", "=", "True", ",", "\n", ")", "\n", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "1", ",", "x", ",", "after", "=", "True", ")", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "-", "1", ",", "x", ",", "before", "=", "True", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "relu_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "-", "1", ",", "x", ",", "after", "=", "True", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.TransformerDecoderLayer.maybe_layer_norm": [[155, 161], ["None"], "methods", ["None"], ["", "def", "maybe_layer_norm", "(", "self", ",", "i", ",", "x", ",", "before", "=", "False", ",", "after", "=", "False", ")", ":", "\n", "        ", "assert", "before", "^", "after", "\n", "if", "after", "^", "self", ".", "normalize_before", ":", "\n", "            ", "return", "self", ".", "layer_norms", "[", "i", "]", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.DecoderTransformer.__init__": [[166, 199], ["torch.Module.__init__", "transformer_decoder.Embedding", "math.sqrt", "transformer_decoder.LayerNorm", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "transformer_decoder.DecoderTransformer.layers.extend", "transformer_decoder.Linear", "transformer_decoder.PositionalEmbedding", "transformer_decoder.TransformerDecoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Embedding", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.LayerNorm", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.PositionalEmbedding"], ["def", "__init__", "(", "self", ",", "\n", "embed_size", ",", "\n", "vocab_size", ",", "\n", "dropout", "=", "0.5", ",", "\n", "seq_length", "=", "20", ",", "\n", "num_instrs", "=", "15", ",", "\n", "attention_nheads", "=", "16", ",", "\n", "pos_embeddings", "=", "True", ",", "\n", "num_layers", "=", "8", ",", "\n", "learned", "=", "True", ",", "\n", "normalize_before", "=", "True", ")", ":", "\n", "        ", "super", "(", "DecoderTransformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "seq_length", "=", "seq_length", "*", "num_instrs", "\n", "self", ".", "embed_tokens", "=", "Embedding", "(", "vocab_size", ",", "embed_size", ",", "padding_idx", "=", "vocab_size", "-", "1", ")", "\n", "if", "pos_embeddings", ":", "\n", "            ", "self", ".", "embed_positions", "=", "PositionalEmbedding", "(", "\n", "1024", ",", "embed_size", ",", "0", ",", "left_pad", "=", "False", ",", "learned", "=", "learned", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embed_positions", "=", "None", "\n", "\n", "", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "embed_size", ")", "\n", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "embed_size", ")", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "layers", ".", "extend", "(", "[", "\n", "TransformerDecoderLayer", "(", "\n", "embed_size", ",", "attention_nheads", ",", "dropout", "=", "dropout", ",", "normalize_before", "=", "normalize_before", ")", "\n", "for", "i", "in", "range", "(", "num_layers", ")", "\n", "]", ")", "\n", "\n", "self", ".", "linear", "=", "Linear", "(", "embed_size", ",", "vocab_size", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.DecoderTransformer.forward": [[200, 241], ["torch.dropout", "torch.dropout", "torch.dropout", "layer.transpose", "layer.transpose", "transformer_decoder.DecoderTransformer.linear", "layer.max", "transformer_decoder.DecoderTransformer.permute", "transformer_decoder.DecoderTransformer.transpose", "transformer_decoder.DecoderTransformer.layer_norm", "transformer_decoder.DecoderTransformer.embed_positions", "transformer_decoder.DecoderTransformer.embed_tokens", "layer", "mask.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "mask", ",", "captions", ",", "incremental_state", "=", "None", ")", ":", "\n", "\n", "        ", "if", "features", "is", "not", "None", ":", "\n", "            ", "features", "=", "features", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "features", "=", "features", ".", "transpose", "(", "0", ",", "1", ")", "\n", "features", "=", "self", ".", "layer_norm", "(", "features", ")", "\n", "\n", "", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "(", "1", "-", "mask", ".", "squeeze", "(", "1", ")", ")", ".", "byte", "(", ")", "\n", "\n", "# embed positions", "\n", "", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "positions", "=", "self", ".", "embed_positions", "(", "captions", ",", "incremental_state", "=", "incremental_state", ")", "\n", "", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "                ", "positions", "=", "positions", "[", ":", ",", "-", "1", ":", "]", "\n", "", "captions", "=", "captions", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "# embed tokens and positions", "\n", "", "x", "=", "self", ".", "embed_scale", "*", "self", ".", "embed_tokens", "(", "captions", ")", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "positions", "\n", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# decoder layers", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ",", "features", ",", "mask", ",", "incremental_state", ")", "\n", "# T x B x C -> B x T x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "x", "=", "self", ".", "linear", "(", "x", ")", "\n", "_", ",", "predicted", "=", "x", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "\n", "if", "incremental_state", "is", "None", ":", "\n", "            ", "return", "x", ",", "predicted", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.DecoderTransformer.sample": [[242, 295], ["features.size", "first_word.to().long.to().long.to().long", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "transformer_decoder.DecoderTransformer.forward", "outputs.squeeze.squeeze.squeeze", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "first_word.to().long.to().long.to", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "outputs.squeeze.squeeze.max", "[].detach.detach", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "[].detach", "torch.zeros().float().to", "torch.zeros().float().to", "torch.zeros().float().to", "torch.zeros().float().to", "torch.zeros().float().to", "torch.zeros().float().to", "torch.zeros().float().to", "torch.zeros().float().to", "torch.zeros().float().to", "float", "outputs.squeeze.squeeze.squeeze", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "range", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.forward"], ["", "", "def", "sample", "(", "self", ",", "\n", "features", ",", "\n", "mask", ",", "\n", "greedy", "=", "True", ",", "\n", "temperature", "=", "1.0", ",", "\n", "first_token_value", "=", "0", ",", "\n", "replacement", "=", "True", ")", ":", "\n", "\n", "        ", "incremental_state", "=", "{", "}", "\n", "\n", "# create dummy previous word", "\n", "fs", "=", "features", ".", "size", "(", "0", ")", "\n", "first_word", "=", "torch", ".", "ones", "(", "fs", ")", "*", "first_token_value", "\n", "\n", "first_word", "=", "first_word", ".", "to", "(", "device", ")", ".", "long", "(", ")", "\n", "sampled_ids", "=", "[", "first_word", "]", "\n", "logits", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "seq_length", ")", ":", "\n", "# forward", "\n", "            ", "outputs", "=", "self", ".", "forward", "(", "features", ",", "mask", ",", "torch", ".", "stack", "(", "sampled_ids", ",", "1", ")", ",", "incremental_state", ")", "\n", "outputs", "=", "outputs", ".", "squeeze", "(", "1", ")", "\n", "if", "not", "replacement", ":", "\n", "# predicted mask", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "predicted_mask", "=", "torch", ".", "zeros", "(", "outputs", ".", "shape", ")", ".", "float", "(", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "                    ", "batch_ind", "=", "[", "j", "for", "j", "in", "range", "(", "fs", ")", "if", "sampled_ids", "[", "i", "]", "[", "j", "]", "!=", "0", "]", "\n", "sampled_ids_new", "=", "sampled_ids", "[", "i", "]", "[", "batch_ind", "]", "\n", "predicted_mask", "[", "batch_ind", ",", "sampled_ids_new", "]", "=", "float", "(", "'-inf'", ")", "\n", "\n", "# mask previously selected ids", "\n", "", "outputs", "+=", "predicted_mask", "\n", "\n", "# add outputs to list", "\n", "", "logits", ".", "append", "(", "outputs", ")", "\n", "\n", "if", "greedy", ":", "\n", "                ", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "predicted", "=", "predicted", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "                ", "k", "=", "10", "\n", "prob_prev", "=", "torch", ".", "div", "(", "outputs", ".", "squeeze", "(", "1", ")", ",", "temperature", ")", "\n", "prob_prev", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "prob_prev", ",", "dim", "=", "-", "1", ")", ".", "data", "\n", "\n", "# top k random sampling", "\n", "prob_prev_topk", ",", "indices", "=", "torch", ".", "topk", "(", "prob_prev", ",", "k", "=", "k", ",", "dim", "=", "1", ")", "\n", "predicted", "=", "torch", ".", "multinomial", "(", "prob_prev_topk", ",", "1", ")", ".", "view", "(", "-", "1", ")", "\n", "predicted", "=", "torch", ".", "index_select", "(", "indices", ",", "dim", "=", "1", ",", "index", "=", "predicted", ")", "[", ":", ",", "0", "]", ".", "detach", "(", ")", "\n", "\n", "", "sampled_ids", ".", "append", "(", "predicted", ")", "\n", "", "sampled_ids", "=", "torch", ".", "stack", "(", "sampled_ids", "[", "1", ":", "]", ",", "1", ")", "\n", "logits", "=", "torch", ".", "stack", "(", "logits", ",", "1", ")", "\n", "return", "sampled_ids", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.DecoderTransformer.max_positions": [[296, 299], ["transformer_decoder.DecoderTransformer.embed_positions.max_positions"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LearnedPositionalEmbedding.max_positions"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the decoder.\"\"\"", "\n", "return", "self", ".", "embed_positions", ".", "max_positions", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.DecoderTransformer.upgrade_state_dict": [[300, 307], ["isinstance", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["None"], ["", "def", "upgrade_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "embed_positions", ",", "SinusoidalPositionalEmbedding", ")", ":", "\n", "            ", "if", "'decoder.embed_positions.weights'", "in", "state_dict", ":", "\n", "                ", "del", "state_dict", "[", "'decoder.embed_positions.weights'", "]", "\n", "", "if", "'decoder.embed_positions._float_tensor'", "not", "in", "state_dict", ":", "\n", "                ", "state_dict", "[", "'decoder.embed_positions._float_tensor'", "]", "=", "torch", ".", "FloatTensor", "(", ")", "\n", "", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.Embedding": [[309, 313], ["torch.Embedding", "torch.init.normal_"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.LayerNorm": [[315, 318], ["torch.LayerNorm"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.LayerNorm"], ["", "def", "LayerNorm", "(", "embedding_dim", ")", ":", "\n", "    ", "m", "=", "nn", ".", "LayerNorm", "(", "embedding_dim", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.Linear": [[320, 325], ["torch.Linear", "torch.init.xavier_uniform_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.PositionalEmbedding": [[327, 335], ["modules.layers.LearnedPositionalEmbedding", "torch.init.normal_", "torch.init.constant_", "transformer_decoder.SinusoidalPositionalEmbedding"], "function", ["None"], ["", "def", "PositionalEmbedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ",", "left_pad", ",", "learned", "=", "False", ")", ":", "\n", "    ", "if", "learned", ":", "\n", "        ", "m", "=", "LearnedPositionalEmbedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ",", "left_pad", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "        ", "m", "=", "SinusoidalPositionalEmbedding", "(", "embedding_dim", ",", "padding_idx", ",", "left_pad", ",", "num_embeddings", ")", "\n", "", "return", "m", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LearnedPositionalEmbedding.__init__": [[88, 91], ["torch.Embedding.__init__"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__"], ["def", "__init__", "(", "self", ",", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ",", "left_pad", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", "\n", "self", ".", "left_pad", "=", "left_pad", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LearnedPositionalEmbedding.forward": [[92, 102], ["super().forward", "input.data.new().fill_", "layers.make_positions", "input.data.new", "input.size"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.forward", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.make_positions"], ["", "def", "forward", "(", "self", ",", "input", ",", "incremental_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "# positions is the same for every token when decoding a single step", "\n", "\n", "            ", "positions", "=", "input", ".", "data", ".", "new", "(", "1", ",", "1", ")", ".", "fill_", "(", "self", ".", "padding_idx", "+", "input", ".", "size", "(", "1", ")", ")", "\n", "", "else", ":", "\n", "\n", "            ", "positions", "=", "make_positions", "(", "input", ".", "data", ",", "self", ".", "padding_idx", ",", "self", ".", "left_pad", ")", "\n", "", "return", "super", "(", ")", ".", "forward", "(", "positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LearnedPositionalEmbedding.max_positions": [[103, 106], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum number of supported positions.\"\"\"", "\n", "return", "self", ".", "num_embeddings", "-", "self", ".", "padding_idx", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.ConvTBC.__init__": [[114, 124], ["super().__init__", "torch.nn.modules.utils._single", "torch.nn.modules.utils._single", "torch.nn.modules.utils._single", "torch.nn.modules.utils._single", "torch.nn.modules.utils._single", "torch.nn.modules.utils._single", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "padding", "=", "0", ")", ":", "\n", "        ", "super", "(", "ConvTBC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "_single", "(", "kernel_size", ")", "\n", "self", ".", "padding", "=", "_single", "(", "padding", ")", "\n", "\n", "self", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "self", ".", "kernel_size", "[", "0", "]", ",", "in_channels", ",", "out_channels", ")", ")", "\n", "self", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.ConvTBC.forward": [[125, 127], ["input.contiguous().conv_tbc", "input.contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "input", ".", "contiguous", "(", ")", ".", "conv_tbc", "(", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "padding", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.ConvTBC.__repr__": [[128, 135], ["s.format"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "(", "'{name}({in_channels}, {out_channels}, kernel_size={kernel_size}'", "\n", "', padding={padding}'", ")", "\n", "if", "self", ".", "bias", "is", "None", ":", "\n", "            ", "s", "+=", "', bias=False'", "\n", "", "s", "+=", "')'", "\n", "return", "s", ".", "format", "(", "name", "=", "self", ".", "__class__", ".", "__name__", ",", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__": [[145, 149], ["layers.ConvTBC.__init__", "layers.LinearizedConvolution.register_backward_hook"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", "\n", "self", ".", "_linearized_weight", "=", "None", "\n", "self", ".", "register_backward_hook", "(", "self", ".", "_clear_linearized_weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.forward": [[150, 187], ["layers.LinearizedConvolution._get_linearized_weight", "input.size", "torch.linear.view", "layers.ConvTBC.forward", "layers.LinearizedConvolution._get_input_buffer", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.linear", "torch.linear", "torch.linear", "input.new().zero_", "layers.LinearizedConvolution._set_input_buffer", "input_buffer[].clone", "input.view", "input.new", "input.size"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution._get_linearized_weight", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.forward", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution._get_input_buffer", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution._set_input_buffer"], ["", "def", "forward", "(", "self", ",", "input", ",", "incremental_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Input:\n            Time x Batch x Channel during training\n            Batch x Time x Channel during inference\n        Args:\n            incremental_state: Used to buffer signal; if not None, then input is\n                expected to contain a single frame. If the input order changes\n                between time steps, call reorder_incremental_state.\n        \"\"\"", "\n", "if", "incremental_state", "is", "None", ":", "\n", "            ", "output", "=", "super", "(", ")", ".", "forward", "(", "input", ")", "\n", "if", "self", ".", "kernel_size", "[", "0", "]", ">", "1", "and", "self", ".", "padding", "[", "0", "]", ">", "0", ":", "\n", "# remove future timesteps added by padding", "\n", "                ", "output", "=", "output", "[", ":", "-", "self", ".", "padding", "[", "0", "]", ",", ":", ",", ":", "]", "\n", "", "return", "output", "\n", "\n", "# reshape weight", "\n", "", "weight", "=", "self", ".", "_get_linearized_weight", "(", ")", "\n", "kw", "=", "self", ".", "kernel_size", "[", "0", "]", "\n", "\n", "bsz", "=", "input", ".", "size", "(", "0", ")", "# input: bsz x len x dim", "\n", "if", "kw", ">", "1", ":", "\n", "            ", "input", "=", "input", ".", "data", "\n", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "None", ":", "\n", "                ", "input_buffer", "=", "input", ".", "new", "(", "bsz", ",", "kw", ",", "input", ".", "size", "(", "2", ")", ")", ".", "zero_", "(", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "", "else", ":", "\n", "# shift buffer", "\n", "                ", "input_buffer", "[", ":", ",", ":", "-", "1", ",", ":", "]", "=", "input_buffer", "[", ":", ",", "1", ":", ",", ":", "]", ".", "clone", "(", ")", "\n", "# append next input", "\n", "", "input_buffer", "[", ":", ",", "-", "1", ",", ":", "]", "=", "input", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "input", "=", "input_buffer", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "output", "=", "F", ".", "linear", "(", "input", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "weight", ",", "self", ".", "bias", ")", "\n", "", "return", "output", ".", "view", "(", "bsz", ",", "1", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution.reorder_incremental_state": [[188, 193], ["layers.LinearizedConvolution._get_input_buffer", "input_buffer.index_select.index_select.index_select", "layers.LinearizedConvolution._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution._get_input_buffer", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution._set_input_buffer"], ["", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "input_buffer", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution._get_input_buffer": [[194, 196], ["modules.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.get_incremental_state"], ["", "", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "return", "utils", ".", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "'input_buffer'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution._set_input_buffer": [[197, 199], ["modules.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.set_incremental_state"], ["", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ",", "new_buffer", ")", ":", "\n", "        ", "return", "utils", ".", "set_incremental_state", "(", "self", ",", "incremental_state", ",", "'input_buffer'", ",", "new_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution._get_linearized_weight": [[200, 207], ["layers.LinearizedConvolution.weight.transpose().transpose().contiguous", "layers.LinearizedConvolution.view", "layers.LinearizedConvolution.size", "layers.LinearizedConvolution.weight.transpose().transpose", "layers.LinearizedConvolution.weight.transpose"], "methods", ["None"], ["", "def", "_get_linearized_weight", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_linearized_weight", "is", "None", ":", "\n", "            ", "kw", "=", "self", ".", "kernel_size", "[", "0", "]", "\n", "weight", "=", "self", ".", "weight", ".", "transpose", "(", "2", ",", "1", ")", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "assert", "weight", ".", "size", "(", ")", "==", "(", "self", ".", "out_channels", ",", "kw", ",", "self", ".", "in_channels", ")", "\n", "self", ".", "_linearized_weight", "=", "weight", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "", "return", "self", ".", "_linearized_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConvolution._clear_linearized_weight": [[208, 210], ["None"], "methods", ["None"], ["", "def", "_clear_linearized_weight", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "_linearized_weight", "=", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Embedding": [[17, 22], ["torch.Embedding", "torch.init.normal_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Embedding"], ["def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "0", ",", "0.1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.PositionalEmbedding": [[24, 29], ["layers.LearnedPositionalEmbedding", "torch.init.normal_", "torch.init.constant_"], "function", ["None"], ["", "def", "PositionalEmbedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ",", "left_pad", ")", ":", "\n", "    ", "m", "=", "LearnedPositionalEmbedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ",", "left_pad", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "0", ",", "0.1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear": [[31, 37], ["torch.Linear", "torch.init.normal_", "torch.init.constant_", "torch.utils.weight_norm", "math.sqrt"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "dropout", "=", "0", ")", ":", "\n", "    ", "\"\"\"Weight-normalized Linear layer (input: N x T x C)\"\"\"", "\n", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "math", ".", "sqrt", "(", "(", "1", "-", "dropout", ")", "/", "in_features", ")", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "return", "nn", ".", "utils", ".", "weight_norm", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.LinearizedConv1d": [[39, 46], ["layers.LinearizedConvolution", "math.sqrt", "torch.init.normal_", "torch.init.constant_", "torch.utils.weight_norm"], "function", ["None"], ["", "def", "LinearizedConv1d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "dropout", "=", "0", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Weight-normalized Conv1d layer optimized for decoding\"\"\"", "\n", "m", "=", "LinearizedConvolution", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", "\n", "std", "=", "math", ".", "sqrt", "(", "(", "4", "*", "(", "1.0", "-", "dropout", ")", ")", "/", "(", "m", ".", "kernel_size", "[", "0", "]", "*", "in_channels", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "return", "nn", ".", "utils", ".", "weight_norm", "(", "m", ",", "dim", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.ConvTBC": [[48, 56], ["layers.ConvTBC", "math.sqrt", "torch.init.normal_", "torch.init.constant_", "torch.utils.weight_norm"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.ConvTBC"], ["", "def", "ConvTBC", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "dropout", "=", "0", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Weight-normalized Conv1d layer\"\"\"", "\n", "from", "fairseq", ".", "modules", "import", "ConvTBC", "\n", "m", "=", "ConvTBC", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", "\n", "std", "=", "math", ".", "sqrt", "(", "(", "4", "*", "(", "1.0", "-", "dropout", ")", ")", "/", "(", "m", ".", "kernel_size", "[", "0", "]", "*", "in_channels", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "return", "nn", ".", "utils", ".", "weight_norm", "(", "m", ",", "dim", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.layers.make_positions": [[58, 80], ["tensor.new", "tensor.ne", "range_buf[].expand_as", "tensor.clone", "out.masked_scatter_.masked_scatter_", "tensor.size", "tensor.new.numel", "torch.arange", "torch.arange", "torch.arange", "tensor.ne.long().sum().unsqueeze", "tensor.ne.size", "tensor.size", "tensor.ne.long().sum", "tensor.ne.long"], "function", ["None"], ["", "def", "make_positions", "(", "tensor", ",", "padding_idx", ",", "left_pad", ")", ":", "\n", "    ", "\"\"\"Replace non-padding symbols with their position numbers.\n    Position numbers begin at padding_idx+1.\n    Padding symbols are ignored, but it is necessary to specify whether padding\n    is added on the left side (left_pad=True) or right side (left_pad=False).\n    \"\"\"", "\n", "\n", "# creates tensor from scratch - to avoid multigpu issues", "\n", "max_pos", "=", "padding_idx", "+", "1", "+", "tensor", ".", "size", "(", "1", ")", "\n", "#if not hasattr(make_positions, 'range_buf'):", "\n", "range_buf", "=", "tensor", ".", "new", "(", ")", "\n", "#make_positions.range_buf = make_positions.range_buf.type_as(tensor)", "\n", "if", "range_buf", ".", "numel", "(", ")", "<", "max_pos", ":", "\n", "        ", "torch", ".", "arange", "(", "padding_idx", "+", "1", ",", "max_pos", ",", "out", "=", "range_buf", ")", "\n", "", "mask", "=", "tensor", ".", "ne", "(", "padding_idx", ")", "\n", "positions", "=", "range_buf", "[", ":", "tensor", ".", "size", "(", "1", ")", "]", ".", "expand_as", "(", "tensor", ")", "\n", "if", "left_pad", ":", "\n", "        ", "positions", "=", "positions", "-", "mask", ".", "size", "(", "1", ")", "+", "mask", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "out", "=", "tensor", ".", "clone", "(", ")", "\n", "out", "=", "out", ".", "masked_scatter_", "(", "mask", ",", "positions", "[", "mask", "]", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.torch_persistent_save": [[20, 27], ["range", "torch.save", "logging.error", "traceback.format_exc"], "function", ["None"], ["def", "torch_persistent_save", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "torch", ".", "save", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "Exception", ":", "\n", "            ", "if", "i", "==", "2", ":", "\n", "                ", "logging", ".", "error", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.convert_state_dict_type": [[29, 41], ["isinstance", "collections.OrderedDict", "state_dict.items", "isinstance", "utils.convert_state_dict_type", "torch.is_tensor", "utils.convert_state_dict_type", "state_dict.type"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.convert_state_dict_type", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.convert_state_dict_type"], ["", "", "", "", "def", "convert_state_dict_type", "(", "state_dict", ",", "ttype", "=", "torch", ".", "FloatTensor", ")", ":", "\n", "    ", "if", "isinstance", "(", "state_dict", ",", "dict", ")", ":", "\n", "        ", "cpu_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "cpu_dict", "[", "k", "]", "=", "convert_state_dict_type", "(", "v", ")", "\n", "", "return", "cpu_dict", "\n", "", "elif", "isinstance", "(", "state_dict", ",", "list", ")", ":", "\n", "        ", "return", "[", "convert_state_dict_type", "(", "v", ")", "for", "v", "in", "state_dict", "]", "\n", "", "elif", "torch", ".", "is_tensor", "(", "state_dict", ")", ":", "\n", "        ", "return", "state_dict", ".", "type", "(", "ttype", ")", "\n", "", "else", ":", "\n", "        ", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.save_state": [[43, 74], ["utils.torch_persistent_save", "utils.convert_state_dict_type", "utils.convert_state_dict_type", "model.state_dict", "optimizer.state_dict", "lr_scheduler.state_dict"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.torch_persistent_save", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.convert_state_dict_type", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.convert_state_dict_type"], ["", "", "def", "save_state", "(", "filename", ",", "\n", "args", ",", "\n", "model", ",", "\n", "criterion", ",", "\n", "optimizer", ",", "\n", "lr_scheduler", ",", "\n", "num_updates", ",", "\n", "optim_history", "=", "None", ",", "\n", "extra_state", "=", "None", ")", ":", "\n", "    ", "if", "optim_history", "is", "None", ":", "\n", "        ", "optim_history", "=", "[", "]", "\n", "", "if", "extra_state", "is", "None", ":", "\n", "        ", "extra_state", "=", "{", "}", "\n", "", "state_dict", "=", "{", "\n", "'args'", ":", "\n", "args", ",", "\n", "'model'", ":", "\n", "convert_state_dict_type", "(", "model", ".", "state_dict", "(", ")", ")", ",", "\n", "'optimizer_history'", ":", "\n", "optim_history", "+", "[", "{", "\n", "'criterion_name'", ":", "criterion", ".", "__class__", ".", "__name__", ",", "\n", "'optimizer_name'", ":", "optimizer", ".", "__class__", ".", "__name__", ",", "\n", "'lr_scheduler_state'", ":", "lr_scheduler", ".", "state_dict", "(", ")", ",", "\n", "'num_updates'", ":", "num_updates", ",", "\n", "}", "]", ",", "\n", "'last_optimizer_state'", ":", "\n", "convert_state_dict_type", "(", "optimizer", ".", "state_dict", "(", ")", ")", ",", "\n", "'extra_state'", ":", "\n", "extra_state", ",", "\n", "}", "\n", "torch_persistent_save", "(", "state_dict", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.load_model_state": [[76, 91], ["torch.load", "utils._upgrade_state_dict", "model.upgrade_state_dict", "os.path.exists", "model.load_state_dict", "Exception", "torch.serialization.default_restore_location"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils._upgrade_state_dict", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.DecoderTransformer.upgrade_state_dict"], ["", "def", "load_model_state", "(", "filename", ",", "model", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "        ", "return", "None", ",", "[", "]", ",", "None", "\n", "", "state", "=", "torch", ".", "load", "(", "filename", ",", "map_location", "=", "lambda", "s", ",", "l", ":", "default_restore_location", "(", "s", ",", "'cpu'", ")", ")", "\n", "state", "=", "_upgrade_state_dict", "(", "state", ")", "\n", "model", ".", "upgrade_state_dict", "(", "state", "[", "'model'", "]", ")", "\n", "\n", "# load model parameters", "\n", "try", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "state", "[", "'model'", "]", ",", "strict", "=", "True", ")", "\n", "", "except", "Exception", ":", "\n", "        ", "raise", "Exception", "(", "'Cannot load model parameters from checkpoint, '", "\n", "'please ensure that the architectures match'", ")", "\n", "\n", "", "return", "state", "[", "'extra_state'", "]", ",", "state", "[", "'optimizer_history'", "]", ",", "state", "[", "'last_optimizer_state'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils._upgrade_state_dict": [[93, 145], ["hasattr", "hasattr"], "function", ["None"], ["", "def", "_upgrade_state_dict", "(", "state", ")", ":", "\n", "    ", "\"\"\"Helper for upgrading old model checkpoints.\"\"\"", "\n", "# add optimizer_history", "\n", "if", "'optimizer_history'", "not", "in", "state", ":", "\n", "        ", "state", "[", "'optimizer_history'", "]", "=", "[", "\n", "{", "\n", "'criterion_name'", ":", "'CrossEntropyCriterion'", ",", "\n", "'best_loss'", ":", "state", "[", "'best_loss'", "]", ",", "\n", "}", ",", "\n", "]", "\n", "state", "[", "'last_optimizer_state'", "]", "=", "state", "[", "'optimizer'", "]", "\n", "del", "state", "[", "'optimizer'", "]", "\n", "del", "state", "[", "'best_loss'", "]", "\n", "# move extra_state into sub-dictionary", "\n", "", "if", "'epoch'", "in", "state", "and", "'extra_state'", "not", "in", "state", ":", "\n", "        ", "state", "[", "'extra_state'", "]", "=", "{", "\n", "'epoch'", ":", "state", "[", "'epoch'", "]", ",", "\n", "'batch_offset'", ":", "state", "[", "'batch_offset'", "]", ",", "\n", "'val_loss'", ":", "state", "[", "'val_loss'", "]", ",", "\n", "}", "\n", "del", "state", "[", "'epoch'", "]", "\n", "del", "state", "[", "'batch_offset'", "]", "\n", "del", "state", "[", "'val_loss'", "]", "\n", "# reduce optimizer history's memory usage (only keep the last state)", "\n", "", "if", "'optimizer'", "in", "state", "[", "'optimizer_history'", "]", "[", "-", "1", "]", ":", "\n", "        ", "state", "[", "'last_optimizer_state'", "]", "=", "state", "[", "'optimizer_history'", "]", "[", "-", "1", "]", "[", "'optimizer'", "]", "\n", "for", "optim_hist", "in", "state", "[", "'optimizer_history'", "]", ":", "\n", "            ", "del", "optim_hist", "[", "'optimizer'", "]", "\n", "# record the optimizer class name", "\n", "", "", "if", "'optimizer_name'", "not", "in", "state", "[", "'optimizer_history'", "]", "[", "-", "1", "]", ":", "\n", "        ", "state", "[", "'optimizer_history'", "]", "[", "-", "1", "]", "[", "'optimizer_name'", "]", "=", "'FairseqNAG'", "\n", "# move best_loss into lr_scheduler_state", "\n", "", "if", "'lr_scheduler_state'", "not", "in", "state", "[", "'optimizer_history'", "]", "[", "-", "1", "]", ":", "\n", "        ", "state", "[", "'optimizer_history'", "]", "[", "-", "1", "]", "[", "'lr_scheduler_state'", "]", "=", "{", "\n", "'best'", ":", "state", "[", "'optimizer_history'", "]", "[", "-", "1", "]", "[", "'best_loss'", "]", ",", "\n", "}", "\n", "del", "state", "[", "'optimizer_history'", "]", "[", "-", "1", "]", "[", "'best_loss'", "]", "\n", "# keep track of number of updates", "\n", "", "if", "'num_updates'", "not", "in", "state", "[", "'optimizer_history'", "]", "[", "-", "1", "]", ":", "\n", "        ", "state", "[", "'optimizer_history'", "]", "[", "-", "1", "]", "[", "'num_updates'", "]", "=", "0", "\n", "# old model checkpoints may not have separate source/target positions", "\n", "", "if", "hasattr", "(", "state", "[", "'args'", "]", ",", "\n", "'max_positions'", ")", "and", "not", "hasattr", "(", "state", "[", "'args'", "]", ",", "'max_source_positions'", ")", ":", "\n", "        ", "state", "[", "'args'", "]", ".", "max_source_positions", "=", "state", "[", "'args'", "]", ".", "max_positions", "\n", "state", "[", "'args'", "]", ".", "max_target_positions", "=", "state", "[", "'args'", "]", ".", "max_positions", "\n", "# use stateful training data iterator", "\n", "", "if", "'train_iterator'", "not", "in", "state", "[", "'extra_state'", "]", ":", "\n", "        ", "state", "[", "'extra_state'", "]", "[", "'train_iterator'", "]", "=", "{", "\n", "'epoch'", ":", "state", "[", "'extra_state'", "]", "[", "'epoch'", "]", ",", "\n", "'iterations_in_epoch'", ":", "0", ",", "\n", "}", "\n", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.load_ensemble_for_inference": [[147, 173], ["torch.load", "utils._upgrade_state_dict", "states.append", "utils._override_model_args", "task.build_model", "task.build_model.upgrade_state_dict", "task.build_model.load_state_dict", "ensemble.append", "os.path.exists", "IOError", "torch.serialization.default_restore_location"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils._upgrade_state_dict", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils._override_model_args", "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.transformer_decoder.DecoderTransformer.upgrade_state_dict"], ["", "def", "load_ensemble_for_inference", "(", "filenames", ",", "task", ",", "model_arg_overrides", "=", "None", ")", ":", "\n", "    ", "\"\"\"Load an ensemble of models for inference.\n    model_arg_overrides allows you to pass a dictionary model_arg_overrides --\n    {'arg_name': arg} -- to override model args that were used during model\n    training\n    \"\"\"", "\n", "# load model architectures and weights", "\n", "states", "=", "[", "]", "\n", "for", "filename", "in", "filenames", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "            ", "raise", "IOError", "(", "'Model file not found: {}'", ".", "format", "(", "filename", ")", ")", "\n", "", "state", "=", "torch", ".", "load", "(", "filename", ",", "map_location", "=", "lambda", "s", ",", "l", ":", "default_restore_location", "(", "s", ",", "'cpu'", ")", ")", "\n", "state", "=", "_upgrade_state_dict", "(", "state", ")", "\n", "states", ".", "append", "(", "state", ")", "\n", "", "args", "=", "states", "[", "0", "]", "[", "'args'", "]", "\n", "if", "model_arg_overrides", "is", "not", "None", ":", "\n", "        ", "args", "=", "_override_model_args", "(", "args", ",", "model_arg_overrides", ")", "\n", "\n", "# build ensemble", "\n", "", "ensemble", "=", "[", "]", "\n", "for", "state", "in", "states", ":", "\n", "        ", "model", "=", "task", ".", "build_model", "(", "args", ")", "\n", "model", ".", "upgrade_state_dict", "(", "state", "[", "'model'", "]", ")", "\n", "model", ".", "load_state_dict", "(", "state", "[", "'model'", "]", ",", "strict", "=", "True", ")", "\n", "ensemble", ".", "append", "(", "model", ")", "\n", "", "return", "ensemble", ",", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils._override_model_args": [[175, 180], ["model_arg_overrides.items", "setattr"], "function", ["None"], ["", "def", "_override_model_args", "(", "args", ",", "model_arg_overrides", ")", ":", "\n", "# Uses model_arg_overrides {'arg_name': arg} to override model args", "\n", "    ", "for", "arg_name", ",", "arg_val", "in", "model_arg_overrides", ".", "items", "(", ")", ":", "\n", "        ", "setattr", "(", "args", ",", "arg_name", ",", "arg_val", ")", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.move_to_cuda": [[182, 197], ["utils.move_to_cuda._move_to_cuda"], "function", ["None"], ["", "def", "move_to_cuda", "(", "sample", ")", ":", "\n", "    ", "if", "len", "(", "sample", ")", "==", "0", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "def", "_move_to_cuda", "(", "maybe_tensor", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "maybe_tensor", ")", ":", "\n", "            ", "return", "maybe_tensor", ".", "cuda", "(", ")", "\n", "", "elif", "isinstance", "(", "maybe_tensor", ",", "dict", ")", ":", "\n", "            ", "return", "{", "key", ":", "_move_to_cuda", "(", "value", ")", "for", "key", ",", "value", "in", "maybe_tensor", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "maybe_tensor", ",", "list", ")", ":", "\n", "            ", "return", "[", "_move_to_cuda", "(", "x", ")", "for", "x", "in", "maybe_tensor", "]", "\n", "", "else", ":", "\n", "            ", "return", "maybe_tensor", "\n", "\n", "", "", "return", "_move_to_cuda", "(", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils._get_full_incremental_state_key": [[202, 212], ["hasattr"], "function", ["None"], ["def", "_get_full_incremental_state_key", "(", "module_instance", ",", "key", ")", ":", "\n", "    ", "module_name", "=", "module_instance", ".", "__class__", ".", "__name__", "\n", "\n", "# assign a unique ID to each module instance, so that incremental state is", "\n", "# not shared across module instances", "\n", "if", "not", "hasattr", "(", "module_instance", ",", "'_fairseq_instance_id'", ")", ":", "\n", "        ", "INCREMENTAL_STATE_INSTANCE_ID", "[", "module_name", "]", "+=", "1", "\n", "module_instance", ".", "_fairseq_instance_id", "=", "INCREMENTAL_STATE_INSTANCE_ID", "[", "module_name", "]", "\n", "\n", "", "return", "'{}.{}.{}'", ".", "format", "(", "module_name", ",", "module_instance", ".", "_fairseq_instance_id", ",", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.get_incremental_state": [[214, 220], ["utils._get_full_incremental_state_key"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils._get_full_incremental_state_key"], ["", "def", "get_incremental_state", "(", "module", ",", "incremental_state", ",", "key", ")", ":", "\n", "    ", "\"\"\"Helper for getting incremental state for an nn.Module.\"\"\"", "\n", "full_key", "=", "_get_full_incremental_state_key", "(", "module", ",", "key", ")", "\n", "if", "incremental_state", "is", "None", "or", "full_key", "not", "in", "incremental_state", ":", "\n", "        ", "return", "None", "\n", "", "return", "incremental_state", "[", "full_key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.set_incremental_state": [[222, 227], ["utils._get_full_incremental_state_key"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils._get_full_incremental_state_key"], ["", "def", "set_incremental_state", "(", "module", ",", "incremental_state", ",", "key", ",", "value", ")", ":", "\n", "    ", "\"\"\"Helper for setting incremental state for an nn.Module.\"\"\"", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "        ", "full_key", "=", "_get_full_incremental_state_key", "(", "module", ",", "key", ")", "\n", "incremental_state", "[", "full_key", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.load_align_dict": [[229, 244], ["isinstance", "open", "line.split"], "function", ["None"], ["", "", "def", "load_align_dict", "(", "replace_unk", ")", ":", "\n", "    ", "if", "replace_unk", "is", "None", ":", "\n", "        ", "align_dict", "=", "None", "\n", "", "elif", "isinstance", "(", "replace_unk", ",", "str", ")", ":", "\n", "# Load alignment dictionary for unknown word replacement if it was passed as an argument.", "\n", "        ", "align_dict", "=", "{", "}", "\n", "with", "open", "(", "replace_unk", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "cols", "=", "line", ".", "split", "(", ")", "\n", "align_dict", "[", "cols", "[", "0", "]", "]", "=", "cols", "[", "1", "]", "\n", "", "", "", "else", ":", "\n", "# No alignment dictionary provided but we still want to perform unknown word", "\n", "# replacement by copying the original source word.", "\n", "        ", "align_dict", "=", "{", "}", "\n", "", "return", "align_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.print_embed_overlap": [[246, 251], ["set", "set", "len", "print", "embed_dict.keys", "len"], "function", ["None"], ["", "def", "print_embed_overlap", "(", "embed_dict", ",", "vocab_dict", ")", ":", "\n", "    ", "embed_keys", "=", "set", "(", "embed_dict", ".", "keys", "(", ")", ")", "\n", "vocab_keys", "=", "set", "(", "vocab_dict", ".", "symbols", ")", "\n", "overlap", "=", "len", "(", "embed_keys", "&", "vocab_keys", ")", "\n", "print", "(", "\"| Found {}/{} types in embedding file.\"", ".", "format", "(", "overlap", ",", "len", "(", "vocab_dict", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.parse_embedding": [[253, 269], ["open", "next", "line.rstrip().split", "torch.Tensor", "line.rstrip", "float"], "function", ["None"], ["", "def", "parse_embedding", "(", "embed_path", ")", ":", "\n", "    ", "\"\"\"Parse embedding text file into a dictionary of word and embedding tensors.\n    The first line can have vocabulary size and dimension. The following lines\n    should contain word and embedding separated by spaces.\n    Example:\n        2 5\n        the -0.0230 -0.0264  0.0287  0.0171  0.1403\n        at -0.0395 -0.1286  0.0275  0.0254 -0.0932\n    \"\"\"", "\n", "embed_dict", "=", "{", "}", "\n", "with", "open", "(", "embed_path", ")", "as", "f_embed", ":", "\n", "        ", "next", "(", "f_embed", ")", "# skip header", "\n", "for", "line", "in", "f_embed", ":", "\n", "            ", "pieces", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "embed_dict", "[", "pieces", "[", "0", "]", "]", "=", "torch", ".", "Tensor", "(", "[", "float", "(", "weight", ")", "for", "weight", "in", "pieces", "[", "1", ":", "]", "]", ")", "\n", "", "", "return", "embed_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.load_embedding": [[271, 277], ["range", "len"], "function", ["None"], ["", "def", "load_embedding", "(", "embed_dict", ",", "vocab", ",", "embedding", ")", ":", "\n", "    ", "for", "idx", "in", "range", "(", "len", "(", "vocab", ")", ")", ":", "\n", "        ", "token", "=", "vocab", "[", "idx", "]", "\n", "if", "token", "in", "embed_dict", ":", "\n", "            ", "embedding", ".", "weight", ".", "data", "[", "idx", "]", "=", "embed_dict", "[", "token", "]", "\n", "", "", "return", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.replace_unk": [[279, 292], ["tokenizer.tokenize_line", "enumerate", "tokenizer.tokenize_line", "align_dict.get"], "function", ["None"], ["", "def", "replace_unk", "(", "hypo_str", ",", "src_str", ",", "alignment", ",", "align_dict", ",", "unk", ")", ":", "\n", "    ", "from", "fairseq", "import", "tokenizer", "\n", "# Tokens are strings here", "\n", "hypo_tokens", "=", "tokenizer", ".", "tokenize_line", "(", "hypo_str", ")", "\n", "# TODO: Very rare cases where the replacement is '<eos>' should be handled gracefully", "\n", "src_tokens", "=", "tokenizer", ".", "tokenize_line", "(", "src_str", ")", "+", "[", "'<eos>'", "]", "\n", "for", "i", ",", "ht", "in", "enumerate", "(", "hypo_tokens", ")", ":", "\n", "        ", "if", "ht", "==", "unk", ":", "\n", "            ", "src_token", "=", "src_tokens", "[", "alignment", "[", "i", "]", "]", "\n", "# Either take the corresponding value in the aligned dictionary", "\n", "# or just copy the original value.", "\n", "hypo_tokens", "[", "i", "]", "=", "align_dict", ".", "get", "(", "src_token", ",", "src_token", ")", "\n", "", "", "return", "' '", ".", "join", "(", "hypo_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.post_process_prediction": [[294, 304], ["tgt_dict.string", "utils.replace_unk", "tokenizer.Tokenizer.tokenize", "tgt_dict.unk_string"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.replace_unk"], ["", "def", "post_process_prediction", "(", "hypo_tokens", ",", "src_str", ",", "alignment", ",", "align_dict", ",", "tgt_dict", ",", "remove_bpe", ")", ":", "\n", "    ", "from", "fairseq", "import", "tokenizer", "\n", "hypo_str", "=", "tgt_dict", ".", "string", "(", "hypo_tokens", ",", "remove_bpe", ")", "\n", "if", "align_dict", "is", "not", "None", ":", "\n", "        ", "hypo_str", "=", "replace_unk", "(", "hypo_str", ",", "src_str", ",", "alignment", ",", "align_dict", ",", "tgt_dict", ".", "unk_string", "(", ")", ")", "\n", "", "if", "align_dict", "is", "not", "None", "or", "remove_bpe", "is", "not", "None", ":", "\n", "# Convert back to tokens for evaluating with unk replacement or without BPE", "\n", "# Note that the dictionary can be modified inside the method.", "\n", "        ", "hypo_tokens", "=", "tokenizer", ".", "Tokenizer", ".", "tokenize", "(", "hypo_str", ",", "tgt_dict", ",", "add_if_not_exist", "=", "True", ")", "\n", "", "return", "hypo_tokens", ",", "hypo_str", ",", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.make_positions": [[306, 323], ["make_positions.range_buf.type_as", "tensor.ne", "make_positions.range_buf[].expand_as", "tensor.clone().masked_scatter_", "tensor.size", "hasattr", "tensor.new", "make_positions.range_buf.numel", "torch.arange", "tensor.ne.long().sum().unsqueeze", "tensor.clone", "tensor.ne.size", "tensor.size", "tensor.ne.long().sum", "tensor.ne.long"], "function", ["None"], ["", "def", "make_positions", "(", "tensor", ",", "padding_idx", ",", "left_pad", ")", ":", "\n", "    ", "\"\"\"Replace non-padding symbols with their position numbers.\n    Position numbers begin at padding_idx+1.\n    Padding symbols are ignored, but it is necessary to specify whether padding\n    is added on the left side (left_pad=True) or right side (left_pad=False).\n    \"\"\"", "\n", "max_pos", "=", "padding_idx", "+", "1", "+", "tensor", ".", "size", "(", "1", ")", "\n", "if", "not", "hasattr", "(", "make_positions", ",", "'range_buf'", ")", ":", "\n", "        ", "make_positions", ".", "range_buf", "=", "tensor", ".", "new", "(", ")", "\n", "", "make_positions", ".", "range_buf", "=", "make_positions", ".", "range_buf", ".", "type_as", "(", "tensor", ")", "\n", "if", "make_positions", ".", "range_buf", ".", "numel", "(", ")", "<", "max_pos", ":", "\n", "        ", "torch", ".", "arange", "(", "padding_idx", "+", "1", ",", "max_pos", ",", "out", "=", "make_positions", ".", "range_buf", ")", "\n", "", "mask", "=", "tensor", ".", "ne", "(", "padding_idx", ")", "\n", "positions", "=", "make_positions", ".", "range_buf", "[", ":", "tensor", ".", "size", "(", "1", ")", "]", ".", "expand_as", "(", "tensor", ")", "\n", "if", "left_pad", ":", "\n", "        ", "positions", "=", "positions", "-", "mask", ".", "size", "(", "1", ")", "+", "mask", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "", "return", "tensor", ".", "clone", "(", ")", ".", "masked_scatter_", "(", "mask", ",", "positions", "[", "mask", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.strip_pad": [[325, 327], ["tensor.ne"], "function", ["None"], ["", "def", "strip_pad", "(", "tensor", ",", "pad", ")", ":", "\n", "    ", "return", "tensor", "[", "tensor", ".", "ne", "(", "pad", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.buffered_arange": [[329, 335], ["hasattr", "torch.LongTensor", "buffered_arange.buf.numel", "torch.arange"], "function", ["None"], ["", "def", "buffered_arange", "(", "max", ")", ":", "\n", "    ", "if", "not", "hasattr", "(", "buffered_arange", ",", "'buf'", ")", ":", "\n", "        ", "buffered_arange", ".", "buf", "=", "torch", ".", "LongTensor", "(", ")", "\n", "", "if", "max", ">", "buffered_arange", ".", "buf", ".", "numel", "(", ")", ":", "\n", "        ", "torch", ".", "arange", "(", "max", ",", "out", "=", "buffered_arange", ".", "buf", ")", "\n", "", "return", "buffered_arange", ".", "buf", "[", ":", "max", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.convert_padding_direction": [[337, 357], ["src_tokens.eq", "src_tokens.size", "buffered_arange().type_as().expand_as", "src_tokens.eq.long().sum", "src_tokens.gather", "src_tokens.eq.any", "torch.remainder", "torch.remainder", "pad_mask[].any", "pad_mask[].any", "buffered_arange().type_as", "src_tokens.eq.long", "utils.buffered_arange"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.buffered_arange"], ["", "def", "convert_padding_direction", "(", "src_tokens", ",", "padding_idx", ",", "right_to_left", "=", "False", ",", "left_to_right", "=", "False", ")", ":", "\n", "    ", "assert", "right_to_left", "^", "left_to_right", "\n", "pad_mask", "=", "src_tokens", ".", "eq", "(", "padding_idx", ")", "\n", "if", "not", "pad_mask", ".", "any", "(", ")", ":", "\n", "# no padding, return early", "\n", "        ", "return", "src_tokens", "\n", "", "if", "left_to_right", "and", "not", "pad_mask", "[", ":", ",", "0", "]", ".", "any", "(", ")", ":", "\n", "# already right padded", "\n", "        ", "return", "src_tokens", "\n", "", "if", "right_to_left", "and", "not", "pad_mask", "[", ":", ",", "-", "1", "]", ".", "any", "(", ")", ":", "\n", "# already left padded", "\n", "        ", "return", "src_tokens", "\n", "", "max_len", "=", "src_tokens", ".", "size", "(", "1", ")", "\n", "range", "=", "buffered_arange", "(", "max_len", ")", ".", "type_as", "(", "src_tokens", ")", ".", "expand_as", "(", "src_tokens", ")", "\n", "num_pads", "=", "pad_mask", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "right_to_left", ":", "\n", "        ", "index", "=", "torch", ".", "remainder", "(", "range", "-", "num_pads", ",", "max_len", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "torch", ".", "remainder", "(", "range", "+", "num_pads", ",", "max_len", ")", "\n", "", "return", "src_tokens", ".", "gather", "(", "1", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.item": [[359, 365], ["hasattr", "hasattr", "tensor.item"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.item"], ["", "def", "item", "(", "tensor", ")", ":", "\n", "    ", "if", "hasattr", "(", "tensor", ",", "'item'", ")", ":", "\n", "        ", "return", "tensor", ".", "item", "(", ")", "\n", "", "if", "hasattr", "(", "tensor", ",", "'__getitem__'", ")", ":", "\n", "        ", "return", "tensor", "[", "0", "]", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.clip_grad_norm_": [[367, 373], ["utils.item", "torch.norm", "tensor.mul_"], "function", ["home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.item"], ["", "def", "clip_grad_norm_", "(", "tensor", ",", "max_norm", ")", ":", "\n", "    ", "grad_norm", "=", "item", "(", "torch", ".", "norm", "(", "tensor", ")", ")", "\n", "if", "grad_norm", ">", "max_norm", ">", "0", ":", "\n", "        ", "clip_coef", "=", "max_norm", "/", "(", "grad_norm", "+", "1e-6", ")", "\n", "tensor", ".", "mul_", "(", "clip_coef", ")", "\n", "", "return", "grad_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.fill_with_neg_inf": [[375, 378], ["t.float().fill_().type_as", "t.float().fill_", "float", "t.float"], "function", ["None"], ["", "def", "fill_with_neg_inf", "(", "t", ")", ":", "\n", "    ", "\"\"\"FP16-compatible function that fills a tensor with -inf.\"\"\"", "\n", "return", "t", ".", "float", "(", ")", ".", "fill_", "(", "float", "(", "'-inf'", ")", ")", ".", "type_as", "(", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_image-to-set.modules.utils.checkpoint_paths": [[380, 396], ["re.compile", "os.listdir", "enumerate", "re.compile.fullmatch", "os.path.join", "entries.append", "sorted", "int", "len", "pt_regexp.fullmatch.group", "pt_regexp.fullmatch.group", "pt_regexp.fullmatch.groups"], "function", ["None"], ["", "def", "checkpoint_paths", "(", "path", ",", "pattern", "=", "r'checkpoint(\\d+)\\.pt'", ")", ":", "\n", "    ", "\"\"\"Retrieves all checkpoints found in `path` directory.\n    Checkpoints are identified by matching filename to the specified pattern. If\n    the pattern contains groups, the result will be sorted by the first group in\n    descending order.\n    \"\"\"", "\n", "pt_regexp", "=", "re", ".", "compile", "(", "pattern", ")", "\n", "files", "=", "os", ".", "listdir", "(", "path", ")", "\n", "\n", "entries", "=", "[", "]", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "files", ")", ":", "\n", "        ", "m", "=", "pt_regexp", ".", "fullmatch", "(", "f", ")", "\n", "if", "m", "is", "not", "None", ":", "\n", "            ", "idx", "=", "int", "(", "m", ".", "group", "(", "1", ")", ")", "if", "len", "(", "m", ".", "groups", "(", ")", ")", ">", "0", "else", "i", "\n", "entries", ".", "append", "(", "(", "idx", ",", "m", ".", "group", "(", "0", ")", ")", ")", "\n", "", "", "return", "[", "os", ".", "path", ".", "join", "(", "path", ",", "x", "[", "1", "]", ")", "for", "x", "in", "sorted", "(", "entries", ",", "reverse", "=", "True", ")", "]", "\n", "", ""]]}