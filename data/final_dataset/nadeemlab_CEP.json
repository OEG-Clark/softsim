{"home.repos.pwc.inspect_result.nadeemlab_CEP.util.html.HTML.__init__": [[14, 34], ["os.path.join", "dominate.document", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "dominate.tags.meta", "str"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "web_dir", ",", "title", ",", "refresh", "=", "0", ")", ":", "\n", "        ", "\"\"\"Initialize the HTML classes\n\n        Parameters:\n            web_dir (str) -- a directory that stores the webpage. HTML file will be created at <web_dir>/index.html; images will be saved at <web_dir/images/\n            title (str)   -- the webpage name\n            refresh (int) -- how often the website refresh itself; if 0; no refreshing\n        \"\"\"", "\n", "self", ".", "title", "=", "title", "\n", "self", ".", "web_dir", "=", "web_dir", "\n", "self", ".", "img_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "web_dir", ",", "'images'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "web_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "web_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "img_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "img_dir", ")", "\n", "\n", "", "self", ".", "doc", "=", "dominate", ".", "document", "(", "title", "=", "title", ")", "\n", "if", "refresh", ">", "0", ":", "\n", "            ", "with", "self", ".", "doc", ".", "head", ":", "\n", "                ", "meta", "(", "http_equiv", "=", "\"refresh\"", ",", "content", "=", "str", "(", "refresh", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.html.HTML.get_image_dir": [[35, 38], ["None"], "methods", ["None"], ["", "", "", "def", "get_image_dir", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the directory that stores images\"\"\"", "\n", "return", "self", ".", "img_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.html.HTML.add_header": [[39, 47], ["dominate.tags.h3"], "methods", ["None"], ["", "def", "add_header", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Insert a header to the HTML file\n\n        Parameters:\n            text (str) -- the header text\n        \"\"\"", "\n", "with", "self", ".", "doc", ":", "\n", "            ", "h3", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.html.HTML.add_images": [[48, 67], ["dominate.tags.table", "html.HTML.doc.add", "dominate.tags.tr", "zip", "dominate.tags.td", "dominate.tags.p", "dominate.tags.br", "dominate.tags.p", "dominate.tags.a", "dominate.tags.img", "os.path.join", "os.path.join"], "methods", ["None"], ["", "", "def", "add_images", "(", "self", ",", "ims", ",", "txts", ",", "links", ",", "width", "=", "400", ")", ":", "\n", "        ", "\"\"\"add images to the HTML file\n\n        Parameters:\n            ims (str list)   -- a list of image paths\n            txts (str list)  -- a list of image names shown on the website\n            links (str list) --  a list of hyperref links; when you click an image, it will redirect you to a new page\n        \"\"\"", "\n", "self", ".", "t", "=", "table", "(", "border", "=", "1", ",", "style", "=", "\"table-layout: fixed;\"", ")", "# Insert a table", "\n", "self", ".", "doc", ".", "add", "(", "self", ".", "t", ")", "\n", "with", "self", ".", "t", ":", "\n", "            ", "with", "tr", "(", ")", ":", "\n", "                ", "for", "im", ",", "txt", ",", "link", "in", "zip", "(", "ims", ",", "txts", ",", "links", ")", ":", "\n", "                    ", "with", "td", "(", "style", "=", "\"word-wrap: break-word;\"", ",", "halign", "=", "\"center\"", ",", "valign", "=", "\"top\"", ")", ":", "\n", "                        ", "with", "p", "(", ")", ":", "\n", "                            ", "with", "a", "(", "href", "=", "os", ".", "path", ".", "join", "(", "'images'", ",", "link", ")", ")", ":", "\n", "                                ", "img", "(", "style", "=", "\"width:%dpx\"", "%", "width", ",", "src", "=", "os", ".", "path", ".", "join", "(", "'images'", ",", "im", ")", ")", "\n", "", "br", "(", ")", "\n", "p", "(", "txt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.html.HTML.save": [[68, 74], ["open", "open.write", "open.close", "html.HTML.doc.render"], "methods", ["None"], ["", "", "", "", "", "", "def", "save", "(", "self", ")", ":", "\n", "        ", "\"\"\"save the current content to the HMTL file\"\"\"", "\n", "html_file", "=", "'%s/index.html'", "%", "self", ".", "web_dir", "\n", "f", "=", "open", "(", "html_file", ",", "'wt'", ")", "\n", "f", ".", "write", "(", "self", ".", "doc", ".", "render", "(", ")", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.image_pool.ImagePool.__init__": [[12, 22], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "pool_size", ")", ":", "\n", "        ", "\"\"\"Initialize the ImagePool class\n\n        Parameters:\n            pool_size (int) -- the size of image buffer, if pool_size=0, no buffer will be created\n        \"\"\"", "\n", "self", ".", "pool_size", "=", "pool_size", "\n", "if", "self", ".", "pool_size", ">", "0", ":", "# create an empty pool", "\n", "            ", "self", ".", "num_imgs", "=", "0", "\n", "self", ".", "images", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.image_pool.ImagePool.query": [[23, 55], ["torch.cat", "torch.unsqueeze", "image_pool.ImagePool.images.append", "torch.cat.append", "random.uniform", "random.randint", "image_pool.ImagePool.images[].clone", "torch.cat.append", "torch.cat.append"], "methods", ["None"], ["", "", "def", "query", "(", "self", ",", "images", ")", ":", "\n", "        ", "\"\"\"Return an image from the pool.\n\n        Parameters:\n            images: the latest generated images from the generator\n\n        Returns images from the buffer.\n\n        By 50/100, the buffer will return input images.\n        By 50/100, the buffer will return images previously stored in the buffer,\n        and insert the current images to the buffer.\n        \"\"\"", "\n", "if", "self", ".", "pool_size", "==", "0", ":", "# if the buffer size is 0, do nothing", "\n", "            ", "return", "images", "\n", "", "return_images", "=", "[", "]", "\n", "for", "image", "in", "images", ":", "\n", "            ", "image", "=", "torch", ".", "unsqueeze", "(", "image", ".", "data", ",", "0", ")", "\n", "if", "self", ".", "num_imgs", "<", "self", ".", "pool_size", ":", "# if the buffer is not full; keep inserting current images to the buffer", "\n", "                ", "self", ".", "num_imgs", "=", "self", ".", "num_imgs", "+", "1", "\n", "self", ".", "images", ".", "append", "(", "image", ")", "\n", "return_images", ".", "append", "(", "image", ")", "\n", "", "else", ":", "\n", "                ", "p", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "p", ">", "0.5", ":", "# by 50% chance, the buffer will return a previously stored image, and insert the current image into the buffer", "\n", "                    ", "random_id", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "pool_size", "-", "1", ")", "# randint is inclusive", "\n", "tmp", "=", "self", ".", "images", "[", "random_id", "]", ".", "clone", "(", ")", "\n", "self", ".", "images", "[", "random_id", "]", "=", "image", "\n", "return_images", ".", "append", "(", "tmp", ")", "\n", "", "else", ":", "# by another 50% chance, the buffer will return the current image", "\n", "                    ", "return_images", ".", "append", "(", "image", ")", "\n", "", "", "", "return_images", "=", "torch", ".", "cat", "(", "return_images", ",", "0", ")", "# collect all the images and return", "\n", "return", "return_images", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.visualizer.Visualizer.__init__": [[58, 92], ["os.path.join", "visdom.Visdom", "os.path.join", "os.path.join", "print", "util.mkdirs", "open", "time.strftime", "log_file.write", "visualizer.Visualizer.vis.check_connection", "visualizer.Visualizer.create_visdom_connections"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.mkdirs", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.visualizer.Visualizer.create_visdom_connections"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the Visualizer class\n\n        Parameters:\n            opt -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        Step 1: Cache the training/test options\n        Step 2: connect to a visdom server\n        Step 3: create an HTML object for saveing HTML filters\n        Step 4: create a logging file to store training losses\n        \"\"\"", "\n", "self", ".", "opt", "=", "opt", "# cache the option", "\n", "self", ".", "display_id", "=", "opt", ".", "display_id", "\n", "self", ".", "use_html", "=", "opt", ".", "isTrain", "and", "not", "opt", ".", "no_html", "\n", "self", ".", "win_size", "=", "opt", ".", "display_winsize", "\n", "self", ".", "name", "=", "opt", ".", "name", "\n", "self", ".", "port", "=", "opt", ".", "display_port", "\n", "self", ".", "saved", "=", "False", "\n", "if", "self", ".", "display_id", ">", "0", ":", "# connect to a visdom server given <display_port> and <display_server>", "\n", "            ", "import", "visdom", "\n", "self", ".", "ncols", "=", "opt", ".", "display_ncols", "\n", "self", ".", "vis", "=", "visdom", ".", "Visdom", "(", "server", "=", "opt", ".", "display_server", ",", "port", "=", "opt", ".", "display_port", ",", "env", "=", "opt", ".", "display_env", ")", "\n", "if", "not", "self", ".", "vis", ".", "check_connection", "(", ")", ":", "\n", "                ", "self", ".", "create_visdom_connections", "(", ")", "\n", "\n", "", "", "if", "self", ".", "use_html", ":", "# create an HTML object at <checkpoints_dir>/web/; images will be saved under <checkpoints_dir>/web/images/", "\n", "            ", "self", ".", "web_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ",", "'web'", ")", "\n", "self", ".", "img_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "web_dir", ",", "'images'", ")", "\n", "print", "(", "'create web directory %s...'", "%", "self", ".", "web_dir", ")", "\n", "util", ".", "mkdirs", "(", "[", "self", ".", "web_dir", ",", "self", ".", "img_dir", "]", ")", "\n", "# create a logging file to store training losses", "\n", "", "self", ".", "log_name", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ",", "'loss_log.txt'", ")", "\n", "with", "open", "(", "self", ".", "log_name", ",", "\"a\"", ")", "as", "log_file", ":", "\n", "            ", "now", "=", "time", ".", "strftime", "(", "\"%c\"", ")", "\n", "log_file", ".", "write", "(", "'================ Training Loss (%s) ================\\n'", "%", "now", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.visualizer.Visualizer.reset": [[93, 96], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset the self.saved status\"\"\"", "\n", "self", ".", "saved", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.visualizer.Visualizer.create_visdom_connections": [[97, 103], ["print", "print", "subprocess.Popen"], "methods", ["None"], ["", "def", "create_visdom_connections", "(", "self", ")", ":", "\n", "        ", "\"\"\"If the program could not connect to Visdom server, this function will start a new server at port < self.port > \"\"\"", "\n", "cmd", "=", "sys", ".", "executable", "+", "' -m visdom.server -p %d &>/dev/null &'", "%", "self", ".", "port", "\n", "print", "(", "'\\n\\nCould not connect to Visdom server. \\n Trying to start a server....'", ")", "\n", "print", "(", "'Command: %s'", "%", "cmd", ")", "\n", "Popen", "(", "cmd", ",", "shell", "=", "True", ",", "stdout", "=", "PIPE", ",", "stderr", "=", "PIPE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.visualizer.Visualizer.display_current_results": [[104, 184], ["visuals.items", "html.HTML", "range", "html.HTML.save", "min", "visuals.items", "util.tensor2im", "os.path.join", "util.save_image", "html.HTML.add_header", "visuals.items", "html.HTML.add_images", "len", "util.tensor2im", "images.append", "numpy.ones_like", "images.append", "visualizer.Visualizer.vis.images", "visualizer.Visualizer.vis.text", "visuals.items", "util.tensor2im", "ims.append", "txts.append", "links.append", "next", "util.tensor2im.transpose", "util.tensor2im.transpose", "visualizer.Visualizer.create_visdom_connections", "util.tensor2im", "visualizer.Visualizer.vis.image", "visualizer.Visualizer.create_visdom_connections", "iter", "dict", "dict", "util.tensor2im.transpose", "visuals.values", "dict"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.util.html.HTML.save", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.tensor2im", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.save_image", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.html.HTML.add_header", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.html.HTML.add_images", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.tensor2im", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.tensor2im", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.visualizer.Visualizer.create_visdom_connections", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.tensor2im", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.visualizer.Visualizer.create_visdom_connections"], ["", "def", "display_current_results", "(", "self", ",", "visuals", ",", "epoch", ",", "save_result", ")", ":", "\n", "        ", "\"\"\"Display current results on visdom; save current results to an HTML file.\n\n        Parameters:\n            visuals (OrderedDict) - - dictionary of images to display or save\n            epoch (int) - - the current epoch\n            save_result (bool) - - if save the current results to an HTML file\n        \"\"\"", "\n", "if", "self", ".", "display_id", ">", "0", ":", "# show images in the browser using visdom", "\n", "            ", "ncols", "=", "self", ".", "ncols", "\n", "if", "ncols", ">", "0", ":", "# show all the images in one visdom panel", "\n", "                ", "ncols", "=", "min", "(", "ncols", ",", "len", "(", "visuals", ")", ")", "\n", "h", ",", "w", "=", "next", "(", "iter", "(", "visuals", ".", "values", "(", ")", ")", ")", ".", "shape", "[", ":", "2", "]", "\n", "table_css", "=", "\"\"\"<style>\n                        table {border-collapse: separate; border-spacing: 4px; white-space: nowrap; text-align: center}\n                        table td {width: % dpx; height: % dpx; padding: 4px; outline: 4px solid black}\n                        </style>\"\"\"", "%", "(", "w", ",", "h", ")", "# create a table css", "\n", "# create a table of images.", "\n", "title", "=", "self", ".", "name", "\n", "label_html", "=", "''", "\n", "label_html_row", "=", "''", "\n", "images", "=", "[", "]", "\n", "idx", "=", "0", "\n", "for", "label", ",", "image", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                    ", "image_numpy", "=", "util", ".", "tensor2im", "(", "image", ")", "\n", "label_html_row", "+=", "'<td>%s</td>'", "%", "label", "\n", "images", ".", "append", "(", "image_numpy", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ")", "\n", "idx", "+=", "1", "\n", "if", "idx", "%", "ncols", "==", "0", ":", "\n", "                        ", "label_html", "+=", "'<tr>%s</tr>'", "%", "label_html_row", "\n", "label_html_row", "=", "''", "\n", "", "", "white_image", "=", "np", ".", "ones_like", "(", "image_numpy", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ")", "*", "255", "\n", "while", "idx", "%", "ncols", "!=", "0", ":", "\n", "                    ", "images", ".", "append", "(", "white_image", ")", "\n", "label_html_row", "+=", "'<td></td>'", "\n", "idx", "+=", "1", "\n", "", "if", "label_html_row", "!=", "''", ":", "\n", "                    ", "label_html", "+=", "'<tr>%s</tr>'", "%", "label_html_row", "\n", "", "try", ":", "\n", "                    ", "self", ".", "vis", ".", "images", "(", "images", ",", "nrow", "=", "ncols", ",", "win", "=", "self", ".", "display_id", "+", "1", ",", "\n", "padding", "=", "2", ",", "opts", "=", "dict", "(", "title", "=", "title", "+", "' images'", ")", ")", "\n", "label_html", "=", "'<table>%s</table>'", "%", "label_html", "\n", "self", ".", "vis", ".", "text", "(", "table_css", "+", "label_html", ",", "win", "=", "self", ".", "display_id", "+", "2", ",", "\n", "opts", "=", "dict", "(", "title", "=", "title", "+", "' labels'", ")", ")", "\n", "", "except", "VisdomExceptionBase", ":", "\n", "                    ", "self", ".", "create_visdom_connections", "(", ")", "\n", "\n", "", "", "else", ":", "# show each image in a separate visdom panel;", "\n", "                ", "idx", "=", "1", "\n", "try", ":", "\n", "                    ", "for", "label", ",", "image", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                        ", "image_numpy", "=", "util", ".", "tensor2im", "(", "image", ")", "\n", "self", ".", "vis", ".", "image", "(", "image_numpy", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ",", "opts", "=", "dict", "(", "title", "=", "label", ")", ",", "\n", "win", "=", "self", ".", "display_id", "+", "idx", ")", "\n", "idx", "+=", "1", "\n", "", "", "except", "VisdomExceptionBase", ":", "\n", "                    ", "self", ".", "create_visdom_connections", "(", ")", "\n", "\n", "", "", "", "if", "self", ".", "use_html", "and", "(", "save_result", "or", "not", "self", ".", "saved", ")", ":", "# save images to an HTML file if they haven't been saved.", "\n", "            ", "self", ".", "saved", "=", "True", "\n", "# save images to the disk", "\n", "for", "label", ",", "image", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                ", "image_numpy", "=", "util", ".", "tensor2im", "(", "image", ")", "\n", "img_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "img_dir", ",", "'epoch%.3d_%s.png'", "%", "(", "epoch", ",", "label", ")", ")", "\n", "util", ".", "save_image", "(", "image_numpy", ",", "img_path", ")", "\n", "\n", "# update website", "\n", "", "webpage", "=", "html", ".", "HTML", "(", "self", ".", "web_dir", ",", "'Experiment name = %s'", "%", "self", ".", "name", ",", "refresh", "=", "1", ")", "\n", "for", "n", "in", "range", "(", "epoch", ",", "0", ",", "-", "1", ")", ":", "\n", "                ", "webpage", ".", "add_header", "(", "'epoch [%d]'", "%", "n", ")", "\n", "ims", ",", "txts", ",", "links", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "label", ",", "image_numpy", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                    ", "image_numpy", "=", "util", ".", "tensor2im", "(", "image", ")", "\n", "img_path", "=", "'epoch%.3d_%s.png'", "%", "(", "n", ",", "label", ")", "\n", "ims", ".", "append", "(", "img_path", ")", "\n", "txts", ".", "append", "(", "label", ")", "\n", "links", ".", "append", "(", "img_path", ")", "\n", "", "webpage", ".", "add_images", "(", "ims", ",", "txts", ",", "links", ",", "width", "=", "self", ".", "win_size", ")", "\n", "", "webpage", ".", "save", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.visualizer.Visualizer.plot_current_losses": [[185, 209], ["visualizer.Visualizer.plot_data[].append", "visualizer.Visualizer.plot_data[].append", "hasattr", "visualizer.Visualizer.vis.line", "list", "visualizer.Visualizer.create_visdom_connections", "losses.keys", "numpy.stack", "numpy.array", "len", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.util.visualizer.Visualizer.create_visdom_connections"], ["", "", "def", "plot_current_losses", "(", "self", ",", "epoch", ",", "counter_ratio", ",", "losses", ")", ":", "\n", "        ", "\"\"\"display the current losses on visdom display: dictionary of error labels and values\n\n        Parameters:\n            epoch (int)           -- current epoch\n            counter_ratio (float) -- progress (percentage) in the current epoch, between 0 to 1\n            losses (OrderedDict)  -- training losses stored in the format of (name, float) pairs\n        \"\"\"", "\n", "if", "not", "hasattr", "(", "self", ",", "'plot_data'", ")", ":", "\n", "            ", "self", ".", "plot_data", "=", "{", "'X'", ":", "[", "]", ",", "'Y'", ":", "[", "]", ",", "'legend'", ":", "list", "(", "losses", ".", "keys", "(", ")", ")", "}", "\n", "", "self", ".", "plot_data", "[", "'X'", "]", ".", "append", "(", "epoch", "+", "counter_ratio", ")", "\n", "self", ".", "plot_data", "[", "'Y'", "]", ".", "append", "(", "[", "losses", "[", "k", "]", "for", "k", "in", "self", ".", "plot_data", "[", "'legend'", "]", "]", ")", "\n", "try", ":", "\n", "            ", "self", ".", "vis", ".", "line", "(", "\n", "X", "=", "np", ".", "stack", "(", "[", "np", ".", "array", "(", "self", ".", "plot_data", "[", "'X'", "]", ")", "]", "*", "len", "(", "self", ".", "plot_data", "[", "'legend'", "]", ")", ",", "1", ")", ",", "\n", "Y", "=", "np", ".", "array", "(", "self", ".", "plot_data", "[", "'Y'", "]", ")", ",", "\n", "opts", "=", "{", "\n", "'title'", ":", "self", ".", "name", "+", "' loss over time'", ",", "\n", "'legend'", ":", "self", ".", "plot_data", "[", "'legend'", "]", ",", "\n", "'xlabel'", ":", "'epoch'", ",", "\n", "'ylabel'", ":", "'loss'", "}", ",", "\n", "win", "=", "self", ".", "display_id", ")", "\n", "", "except", "VisdomExceptionBase", ":", "\n", "            ", "self", ".", "create_visdom_connections", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.visualizer.Visualizer.print_current_losses": [[211, 228], ["losses.items", "print", "open", "log_file.write"], "methods", ["None"], ["", "", "def", "print_current_losses", "(", "self", ",", "epoch", ",", "iters", ",", "losses", ",", "t_comp", ",", "t_data", ")", ":", "\n", "        ", "\"\"\"print current losses on console; also save the losses to the disk\n\n        Parameters:\n            epoch (int) -- current epoch\n            iters (int) -- current training iteration during this epoch (reset to 0 at the end of every epoch)\n            losses (OrderedDict) -- training losses stored in the format of (name, float) pairs\n            t_comp (float) -- computational time per data point (normalized by batch_size)\n            t_data (float) -- data loading time per data point (normalized by batch_size)\n        \"\"\"", "\n", "message", "=", "'(epoch: %d, iters: %d, time: %.3f, data: %.3f) '", "%", "(", "epoch", ",", "iters", ",", "t_comp", ",", "t_data", ")", "\n", "for", "k", ",", "v", "in", "losses", ".", "items", "(", ")", ":", "\n", "            ", "message", "+=", "'%s: %.3f '", "%", "(", "k", ",", "v", ")", "\n", "\n", "", "print", "(", "message", ")", "# print the message", "\n", "with", "open", "(", "self", ".", "log_name", ",", "\"a\"", ")", "as", "log_file", ":", "\n", "            ", "log_file", ".", "write", "(", "'%s\\n'", "%", "message", ")", "# save the message", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.visualizer.save_images": [[16, 50], ["webpage.get_image_dir", "ntpath.basename", "webpage.add_header", "visuals.items", "webpage.add_images", "os.path.splitext", "util.tensor2im", "os.path.join", "util.save_image", "ims.append", "txts.append", "links.append", "numpy.array", "numpy.array", "Image.fromarray().resize", "Image.fromarray().resize", "Image.fromarray", "int", "Image.fromarray", "int"], "function", ["home.repos.pwc.inspect_result.nadeemlab_CEP.util.html.HTML.get_image_dir", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.html.HTML.add_header", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.html.HTML.add_images", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.tensor2im", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.save_image"], ["", "def", "save_images", "(", "webpage", ",", "visuals", ",", "image_path", ",", "aspect_ratio", "=", "1.0", ",", "width", "=", "256", ")", ":", "\n", "    ", "\"\"\"Save images to the disk.\n\n    Parameters:\n        webpage (the HTML class) -- the HTML webpage class that stores these imaegs (see html.py for more details)\n        visuals (OrderedDict)    -- an ordered dictionary that stores (name, images (either tensor or numpy) ) pairs\n        image_path (str)         -- the string is used to create image paths\n        aspect_ratio (float)     -- the aspect ratio of saved images\n        width (int)              -- the images will be resized to width x width\n\n    This function will save images stored in 'visuals' to the HTML file specified by 'webpage'.\n    \"\"\"", "\n", "image_dir", "=", "webpage", ".", "get_image_dir", "(", ")", "\n", "short_path", "=", "ntpath", ".", "basename", "(", "image_path", "[", "0", "]", ")", "\n", "name", "=", "os", ".", "path", ".", "splitext", "(", "short_path", ")", "[", "0", "]", "\n", "\n", "webpage", ".", "add_header", "(", "name", ")", "\n", "ims", ",", "txts", ",", "links", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "label", ",", "im_data", "in", "visuals", ".", "items", "(", ")", ":", "\n", "        ", "im", "=", "util", ".", "tensor2im", "(", "im_data", ")", "\n", "image_name", "=", "'%s_%s.png'", "%", "(", "name", ",", "label", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "image_name", ")", "\n", "h", ",", "w", ",", "_", "=", "im", ".", "shape", "\n", "if", "aspect_ratio", ">", "1.0", ":", "\n", "            ", "im", "=", "np", ".", "array", "(", "Image", ".", "fromarray", "(", "im", ")", ".", "resize", "(", "(", "h", ",", "int", "(", "w", "*", "aspect_ratio", ")", ")", ")", ")", "\n", "", "if", "aspect_ratio", "<", "1.0", ":", "\n", "            ", "im", "=", "np", ".", "array", "(", "Image", ".", "fromarray", "(", "im", ")", ".", "resize", "(", "(", "im", ",", "(", "int", "(", "h", "/", "aspect_ratio", ")", ",", "w", ")", ")", ")", ")", "\n", "", "util", ".", "save_image", "(", "im", ",", "save_path", ")", "\n", "\n", "ims", ".", "append", "(", "image_name", ")", "\n", "txts", ".", "append", "(", "label", ")", "\n", "links", ".", "append", "(", "image_name", ")", "\n", "", "webpage", ".", "add_images", "(", "ims", ",", "txts", ",", "links", ",", "width", "=", "width", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.get_data.GetData.__init__": [[27, 34], ["url_dict.get", "technique.lower"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.util.get_data.GetData.get"], ["def", "__init__", "(", "self", ",", "technique", "=", "'cyclegan'", ",", "verbose", "=", "True", ")", ":", "\n", "        ", "url_dict", "=", "{", "\n", "'pix2pix'", ":", "'http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/'", ",", "\n", "'cyclegan'", ":", "'https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets'", "\n", "}", "\n", "self", ".", "url", "=", "url_dict", ".", "get", "(", "technique", ".", "lower", "(", ")", ")", "\n", "self", ".", "_verbose", "=", "verbose", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.get_data.GetData._print": [[35, 38], ["print"], "methods", ["None"], ["", "def", "_print", "(", "self", ",", "text", ")", ":", "\n", "        ", "if", "self", ".", "_verbose", ":", "\n", "            ", "print", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.get_data.GetData._get_options": [[39, 45], ["bs4.BeautifulSoup", "bs4.BeautifulSoup.find_all", "h.text.endswith"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_get_options", "(", "r", ")", ":", "\n", "        ", "soup", "=", "BeautifulSoup", "(", "r", ".", "text", ",", "'lxml'", ")", "\n", "options", "=", "[", "h", ".", "text", "for", "h", "in", "soup", ".", "find_all", "(", "'a'", ",", "href", "=", "True", ")", "\n", "if", "h", ".", "text", ".", "endswith", "(", "(", "'.zip'", ",", "'tar.gz'", ")", ")", "]", "\n", "return", "options", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.get_data.GetData._present_options": [[46, 55], ["requests.get", "get_data.GetData._get_options", "print", "enumerate", "input", "print", "int"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.util.get_data.GetData.get", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.get_data.GetData._get_options"], ["", "def", "_present_options", "(", "self", ")", ":", "\n", "        ", "r", "=", "requests", ".", "get", "(", "self", ".", "url", ")", "\n", "options", "=", "self", ".", "_get_options", "(", "r", ")", "\n", "print", "(", "'Options:\\n'", ")", "\n", "for", "i", ",", "o", "in", "enumerate", "(", "options", ")", ":", "\n", "            ", "print", "(", "\"{0}: {1}\"", ".", "format", "(", "i", ",", "o", ")", ")", "\n", "", "choice", "=", "input", "(", "\"\\nPlease enter the number of the \"", "\n", "\"dataset above you wish to download:\"", ")", "\n", "return", "options", "[", "int", "(", "choice", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.get_data.GetData._download_data": [[56, 78], ["os.path.basename", "os.path.join", "os.path.basename.endswith", "get_data.GetData._print", "zipfile.ZipFile.extractall", "zipfile.ZipFile.close", "os.remove", "os.path.isdir", "os.makedirs", "open", "requests.get", "f.write", "tarfile.open", "os.path.basename.endswith", "zipfile.ZipFile", "ValueError"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.util.get_data.GetData._print", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.get_data.GetData.get"], ["", "def", "_download_data", "(", "self", ",", "dataset_url", ",", "save_path", ")", ":", "\n", "        ", "if", "not", "isdir", "(", "save_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_path", ")", "\n", "\n", "", "base", "=", "basename", "(", "dataset_url", ")", "\n", "temp_save_path", "=", "join", "(", "save_path", ",", "base", ")", "\n", "\n", "with", "open", "(", "temp_save_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "r", "=", "requests", ".", "get", "(", "dataset_url", ")", "\n", "f", ".", "write", "(", "r", ".", "content", ")", "\n", "\n", "", "if", "base", ".", "endswith", "(", "'.tar.gz'", ")", ":", "\n", "            ", "obj", "=", "tarfile", ".", "open", "(", "temp_save_path", ")", "\n", "", "elif", "base", ".", "endswith", "(", "'.zip'", ")", ":", "\n", "            ", "obj", "=", "ZipFile", "(", "temp_save_path", ",", "'r'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown File Type: {0}.\"", ".", "format", "(", "base", ")", ")", "\n", "\n", "", "self", ".", "_print", "(", "\"Unpacking Data...\"", ")", "\n", "obj", ".", "extractall", "(", "save_path", ")", "\n", "obj", ".", "close", "(", ")", "\n", "os", ".", "remove", "(", "temp_save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.get_data.GetData.get": [[79, 111], ["os.path.join", "os.path.isdir", "os.path.abspath", "get_data.GetData._present_options", "warnings.warn", "get_data.GetData._print", "get_data.GetData._download_data", "get_data.GetData.split"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.util.get_data.GetData._present_options", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.get_data.GetData._print", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.get_data.GetData._download_data"], ["", "def", "get", "(", "self", ",", "save_path", ",", "dataset", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Download a dataset.\n\n        Parameters:\n            save_path (str) -- A directory to save the data to.\n            dataset (str)   -- (optional). A specific dataset to download.\n                            Note: this must include the file extension.\n                            If None, options will be presented for you\n                            to choose from.\n\n        Returns:\n            save_path_full (str) -- the absolute path to the downloaded data.\n\n        \"\"\"", "\n", "if", "dataset", "is", "None", ":", "\n", "            ", "selected_dataset", "=", "self", ".", "_present_options", "(", ")", "\n", "", "else", ":", "\n", "            ", "selected_dataset", "=", "dataset", "\n", "\n", "", "save_path_full", "=", "join", "(", "save_path", ",", "selected_dataset", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "\n", "\n", "if", "isdir", "(", "save_path_full", ")", ":", "\n", "            ", "warn", "(", "\"\\n'{0}' already exists. Voiding Download.\"", ".", "format", "(", "\n", "save_path_full", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_print", "(", "'Downloading Data...'", ")", "\n", "url", "=", "\"{0}/{1}\"", ".", "format", "(", "self", ".", "url", ",", "selected_dataset", ")", "\n", "self", ".", "_download_data", "(", "url", ",", "save_path", "=", "save_path", ")", "\n", "\n", "", "return", "abspath", "(", "save_path_full", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.tensor2im": [[9, 28], ["np.tile.astype", "isinstance", "isinstance", "image_tensor[].cpu().float().numpy", "numpy.tile", "image_tensor[].cpu().float", "numpy.transpose", "image_tensor[].cpu"], "function", ["None"], ["def", "tensor2im", "(", "input_image", ",", "imtype", "=", "np", ".", "uint8", ")", ":", "\n", "    ", "\"\"\"\"Converts a Tensor array into a numpy image array.\n\n    Parameters:\n        input_image (tensor) --  the input image tensor array\n        imtype (type)        --  the desired type of the converted numpy array\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "input_image", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "if", "isinstance", "(", "input_image", ",", "torch", ".", "Tensor", ")", ":", "# get the data from a variable", "\n", "            ", "image_tensor", "=", "input_image", ".", "data", "\n", "", "else", ":", "\n", "            ", "return", "input_image", "\n", "", "image_numpy", "=", "image_tensor", "[", "0", "]", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "# convert it into a numpy array", "\n", "if", "image_numpy", ".", "shape", "[", "0", "]", "==", "1", ":", "# grayscale to RGB", "\n", "            ", "image_numpy", "=", "np", ".", "tile", "(", "image_numpy", ",", "(", "3", ",", "1", ",", "1", ")", ")", "\n", "", "image_numpy", "=", "(", "np", ".", "transpose", "(", "image_numpy", ",", "(", "1", ",", "2", ",", "0", ")", ")", "+", "1", ")", "/", "2.0", "*", "255.0", "# post-processing: tranpose and scaling", "\n", "", "else", ":", "# if it is a numpy array, do nothing", "\n", "        ", "image_numpy", "=", "input_image", "\n", "", "return", "image_numpy", ".", "astype", "(", "imtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.diagnose_network": [[30, 47], ["net.parameters", "print", "print", "torch.mean", "torch.abs"], "function", ["None"], ["", "def", "diagnose_network", "(", "net", ",", "name", "=", "'network'", ")", ":", "\n", "    ", "\"\"\"Calculate and print the mean of average absolute(gradients)\n\n    Parameters:\n        net (torch network) -- Torch network\n        name (str) -- the name of the network\n    \"\"\"", "\n", "mean", "=", "0.0", "\n", "count", "=", "0", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "        ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "            ", "mean", "+=", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "param", ".", "grad", ".", "data", ")", ")", "\n", "count", "+=", "1", "\n", "", "", "if", "count", ">", "0", ":", "\n", "        ", "mean", "=", "mean", "/", "count", "\n", "", "print", "(", "name", ")", "\n", "print", "(", "mean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.save_image": [[49, 58], ["PIL.Image.fromarray", "Image.fromarray.save"], "function", ["home.repos.pwc.inspect_result.nadeemlab_CEP.util.html.HTML.save"], ["", "def", "save_image", "(", "image_numpy", ",", "image_path", ")", ":", "\n", "    ", "\"\"\"Save a numpy image to the disk\n\n    Parameters:\n        image_numpy (numpy array) -- input numpy array\n        image_path (str)          -- the path of the image\n    \"\"\"", "\n", "image_pil", "=", "Image", ".", "fromarray", "(", "image_numpy", ")", "\n", "image_pil", ".", "save", "(", "image_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.print_numpy": [[60, 74], ["x.flatten.astype", "print", "x.flatten.flatten", "print", "numpy.mean", "numpy.min", "numpy.max", "numpy.median", "numpy.std"], "function", ["None"], ["", "def", "print_numpy", "(", "x", ",", "val", "=", "True", ",", "shp", "=", "False", ")", ":", "\n", "    ", "\"\"\"Print the mean, min, max, median, std, and size of a numpy array\n\n    Parameters:\n        val (bool) -- if print the values of the numpy array\n        shp (bool) -- if print the shape of the numpy array\n    \"\"\"", "\n", "x", "=", "x", ".", "astype", "(", "np", ".", "float64", ")", "\n", "if", "shp", ":", "\n", "        ", "print", "(", "'shape,'", ",", "x", ".", "shape", ")", "\n", "", "if", "val", ":", "\n", "        ", "x", "=", "x", ".", "flatten", "(", ")", "\n", "print", "(", "'mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f'", "%", "(", "\n", "np", ".", "mean", "(", "x", ")", ",", "np", ".", "min", "(", "x", ")", ",", "np", ".", "max", "(", "x", ")", ",", "np", ".", "median", "(", "x", ")", ",", "np", ".", "std", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.mkdirs": [[76, 87], ["isinstance", "util.mkdir", "isinstance", "util.mkdir"], "function", ["home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.mkdir", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.mkdir"], ["", "", "def", "mkdirs", "(", "paths", ")", ":", "\n", "    ", "\"\"\"create empty directories if they don't exist\n\n    Parameters:\n        paths (str list) -- a list of directory paths\n    \"\"\"", "\n", "if", "isinstance", "(", "paths", ",", "list", ")", "and", "not", "isinstance", "(", "paths", ",", "str", ")", ":", "\n", "        ", "for", "path", "in", "paths", ":", "\n", "            ", "mkdir", "(", "path", ")", "\n", "", "", "else", ":", "\n", "        ", "mkdir", "(", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.mkdir": [[89, 97], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "def", "mkdir", "(", "path", ")", ":", "\n", "    ", "\"\"\"create a single empty directory if it didn't exist\n\n    Parameters:\n        path (str) -- a single directory path\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.GANLoss.__init__": [[210, 233], ["torch.Module.__init__", "networks.GANLoss.register_buffer", "networks.GANLoss.register_buffer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.MSELoss", "torch.MSELoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "gan_mode", ",", "target_real_label", "=", "1.0", ",", "target_fake_label", "=", "0.0", ")", ":", "\n", "        ", "\"\"\" Initialize the GANLoss class.\n\n        Parameters:\n            gan_mode (str) - - the type of GAN objective. It currently supports vanilla, lsgan, and wgangp.\n            target_real_label (bool) - - label for a real image\n            target_fake_label (bool) - - label of a fake image\n\n        Note: Do not use sigmoid as the last layer of Discriminator.\n        LSGAN needs no sigmoid. vanilla GANs will handle it with BCEWithLogitsLoss.\n        \"\"\"", "\n", "super", "(", "GANLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "'real_label'", ",", "torch", ".", "tensor", "(", "target_real_label", ")", ")", "\n", "self", ".", "register_buffer", "(", "'fake_label'", ",", "torch", ".", "tensor", "(", "target_fake_label", ")", ")", "\n", "self", ".", "gan_mode", "=", "gan_mode", "\n", "if", "gan_mode", "==", "'lsgan'", ":", "\n", "            ", "self", ".", "loss", "=", "nn", ".", "MSELoss", "(", ")", "\n", "", "elif", "gan_mode", "==", "'vanilla'", ":", "\n", "            ", "self", ".", "loss", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "", "elif", "gan_mode", "in", "[", "'wgangp'", "]", ":", "\n", "            ", "self", ".", "loss", "=", "None", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'gan mode %s not implemented'", "%", "gan_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.GANLoss.get_target_tensor": [[234, 250], ["target_tensor.expand_as"], "methods", ["None"], ["", "", "def", "get_target_tensor", "(", "self", ",", "prediction", ",", "target_is_real", ")", ":", "\n", "        ", "\"\"\"Create label tensors with the same size as the input.\n\n        Parameters:\n            prediction (tensor) - - tpyically the prediction from a discriminator\n            target_is_real (bool) - - if the ground truth label is for real images or fake images\n\n        Returns:\n            A label tensor filled with ground truth label, and with the size of the input\n        \"\"\"", "\n", "\n", "if", "target_is_real", ":", "\n", "            ", "target_tensor", "=", "self", ".", "real_label", "\n", "", "else", ":", "\n", "            ", "target_tensor", "=", "self", ".", "fake_label", "\n", "", "return", "target_tensor", ".", "expand_as", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.GANLoss.__call__": [[251, 270], ["networks.GANLoss.get_target_tensor", "networks.GANLoss.loss", "prediction.mean", "prediction.mean"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.GANLoss.get_target_tensor"], ["", "def", "__call__", "(", "self", ",", "prediction", ",", "target_is_real", ")", ":", "\n", "        ", "\"\"\"Calculate loss given Discriminator's output and grount truth labels.\n\n        Parameters:\n            prediction (tensor) - - tpyically the prediction output from a discriminator\n            target_is_real (bool) - - if the ground truth label is for real images or fake images\n\n        Returns:\n            the calculated loss.\n        \"\"\"", "\n", "if", "self", ".", "gan_mode", "in", "[", "'lsgan'", ",", "'vanilla'", "]", ":", "\n", "            ", "target_tensor", "=", "self", ".", "get_target_tensor", "(", "prediction", ",", "target_is_real", ")", "\n", "loss", "=", "self", ".", "loss", "(", "prediction", ",", "target_tensor", ")", "\n", "", "elif", "self", ".", "gan_mode", "==", "'wgangp'", ":", "\n", "            ", "if", "target_is_real", ":", "\n", "                ", "loss", "=", "-", "prediction", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "prediction", ".", "mean", "(", ")", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.ResnetGenerator.__init__": [[316, 365], ["torch.Module.__init__", "range", "range", "range", "torch.Sequential", "torch.Sequential", "type", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Tanh", "torch.Tanh", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "networks.ResnetBlock", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "norm_layer", "torch.ReLU", "torch.ReLU", "int", "int"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ",", "n_blocks", "=", "6", ",", "padding_type", "=", "'reflect'", ")", ":", "\n", "        ", "\"\"\"Construct a Resnet-based generator\n\n        Parameters:\n            input_nc (int)      -- the number of channels in input images\n            output_nc (int)     -- the number of channels in output images\n            ngf (int)           -- the number of filters in the last conv layer\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers\n            n_blocks (int)      -- the number of ResNet blocks\n            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n        \"\"\"", "\n", "assert", "(", "n_blocks", ">=", "0", ")", "\n", "super", "(", "ResnetGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "model", "=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", ",", "\n", "nn", ".", "Conv2d", "(", "input_nc", ",", "ngf", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "n_downsampling", "=", "2", "\n", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add downsampling layers", "\n", "            ", "mult", "=", "2", "**", "i", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", "*", "mult", ",", "ngf", "*", "mult", "*", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", "*", "mult", "*", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "", "mult", "=", "2", "**", "n_downsampling", "\n", "for", "i", "in", "range", "(", "n_blocks", ")", ":", "# add ResNet blocks", "\n", "\n", "            ", "model", "+=", "[", "ResnetBlock", "(", "ngf", "*", "mult", ",", "padding_type", "=", "padding_type", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "use_bias", "=", "use_bias", ")", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add upsampling layers", "\n", "            ", "mult", "=", "2", "**", "(", "n_downsampling", "-", "i", ")", "\n", "model", "+=", "[", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "mult", ",", "int", "(", "ngf", "*", "mult", "/", "2", ")", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "output_padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "int", "(", "ngf", "*", "mult", "/", "2", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "", "model", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", "]", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", ",", "output_nc", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ")", "]", "\n", "model", "+=", "[", "nn", ".", "Tanh", "(", ")", "]", "\n", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.ResnetGenerator.forward": [[366, 369], ["networks.ResnetGenerator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward\"\"\"", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.ResnetBlock.__init__": [[374, 384], ["torch.Module.__init__", "networks.ResnetBlock.build_conv_block"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.ResnetBlock.build_conv_block"], ["def", "__init__", "(", "self", ",", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", ":", "\n", "        ", "\"\"\"Initialize the Resnet block\n\n        A resnet block is a conv block with skip connections\n        We construct a conv block with build_conv_block function,\n        and implement skip connections in <forward> function.\n        Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n        \"\"\"", "\n", "super", "(", "ResnetBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_block", "=", "self", ".", "build_conv_block", "(", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.ResnetBlock.build_conv_block": [[385, 424], ["torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Dropout", "torch.Dropout", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "NotImplementedError", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "NotImplementedError"], "methods", ["None"], ["", "def", "build_conv_block", "(", "self", ",", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", ":", "\n", "        ", "\"\"\"Construct a convolutional block.\n\n        Parameters:\n            dim (int)           -- the number of channels in the conv layer.\n            padding_type (str)  -- the name of padding layer: reflect | replicate | zero\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers.\n            use_bias (bool)     -- if the conv layer uses bias or not\n\n        Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU))\n        \"\"\"", "\n", "conv_block", "=", "[", "]", "\n", "p", "=", "0", "\n", "if", "padding_type", "==", "'reflect'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'replicate'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReplicationPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'zero'", ":", "\n", "            ", "p", "=", "1", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'padding [%s] is not implemented'", "%", "padding_type", ")", "\n", "\n", "", "conv_block", "+=", "[", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "3", ",", "padding", "=", "p", ",", "bias", "=", "use_bias", ")", ",", "norm_layer", "(", "dim", ")", ",", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "if", "use_dropout", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "Dropout", "(", "0.5", ")", "]", "\n", "\n", "", "p", "=", "0", "\n", "if", "padding_type", "==", "'reflect'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'replicate'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReplicationPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'zero'", ":", "\n", "            ", "p", "=", "1", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'padding [%s] is not implemented'", "%", "padding_type", ")", "\n", "", "conv_block", "+=", "[", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "3", ",", "padding", "=", "p", ",", "bias", "=", "use_bias", ")", ",", "norm_layer", "(", "dim", ")", "]", "\n", "\n", "return", "nn", ".", "Sequential", "(", "*", "conv_block", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.ResnetBlock.forward": [[425, 429], ["networks.ResnetBlock.conv_block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward function (with skip connections)\"\"\"", "\n", "out", "=", "x", "+", "self", ".", "conv_block", "(", "x", ")", "# add skip connections", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.UnetGenerator.__init__": [[434, 457], ["torch.Module.__init__", "networks.UnetSkipConnectionBlock", "range", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "num_downs", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Unet generator\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            output_nc (int) -- the number of channels in output images\n            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n                                image of size 128x128 will become of size 1x1 # at the bottleneck\n            ngf (int)       -- the number of filters in the last conv layer\n            norm_layer      -- normalization layer\n\n        We construct the U-Net from the innermost layer to the outermost layer.\n        It is a recursive process.\n        \"\"\"", "\n", "super", "(", "UnetGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# construct unet structure", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "8", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "None", ",", "norm_layer", "=", "norm_layer", ",", "innermost", "=", "True", ")", "# add the innermost layer", "\n", "for", "i", "in", "range", "(", "num_downs", "-", "5", ")", ":", "# add intermediate layers with ngf * 8 filters", "\n", "            ", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "8", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ")", "\n", "# gradually reduce the number of filters from ngf * 8 to ngf", "\n", "", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "4", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ")", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "2", ",", "ngf", "*", "4", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ")", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", ",", "ngf", "*", "2", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "model", "=", "UnetSkipConnectionBlock", "(", "output_nc", ",", "ngf", ",", "input_nc", "=", "input_nc", ",", "submodule", "=", "unet_block", ",", "outermost", "=", "True", ",", "norm_layer", "=", "norm_layer", ")", "# add the outermost layer", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.UnetGenerator.forward": [[458, 461], ["networks.UnetGenerator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward\"\"\"", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.UnetSkipConnectionBlock.__init__": [[469, 525], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "norm_layer", "torch.ReLU", "torch.ReLU", "norm_layer", "torch.Sequential", "torch.Sequential", "type", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Tanh", "torch.Tanh", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "outer_nc", ",", "inner_nc", ",", "input_nc", "=", "None", ",", "\n", "submodule", "=", "None", ",", "outermost", "=", "False", ",", "innermost", "=", "False", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Unet submodule with skip connections.\n\n        Parameters:\n            outer_nc (int) -- the number of filters in the outer conv layer\n            inner_nc (int) -- the number of filters in the inner conv layer\n            input_nc (int) -- the number of channels in input images/features\n            submodule (UnetSkipConnectionBlock) -- previously defined submodules\n            outermost (bool)    -- if this module is the outermost module\n            innermost (bool)    -- if this module is the innermost module\n            norm_layer          -- normalization layer\n            user_dropout (bool) -- if use dropout layers.\n        \"\"\"", "\n", "super", "(", "UnetSkipConnectionBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "outermost", "=", "outermost", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "", "if", "input_nc", "is", "None", ":", "\n", "            ", "input_nc", "=", "outer_nc", "\n", "", "downconv", "=", "nn", ".", "Conv2d", "(", "input_nc", ",", "inner_nc", ",", "kernel_size", "=", "4", ",", "\n", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "downrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "downnorm", "=", "norm_layer", "(", "inner_nc", ")", "\n", "uprelu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "upnorm", "=", "norm_layer", "(", "outer_nc", ")", "\n", "\n", "if", "outermost", ":", "\n", "            ", "upconv", "=", "nn", ".", "ConvTranspose2d", "(", "inner_nc", "*", "2", ",", "outer_nc", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ")", "\n", "down", "=", "[", "downconv", "]", "\n", "up", "=", "[", "uprelu", ",", "upconv", ",", "nn", ".", "Tanh", "(", ")", "]", "\n", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "\n", "", "elif", "innermost", ":", "\n", "            ", "upconv", "=", "nn", ".", "ConvTranspose2d", "(", "inner_nc", ",", "outer_nc", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "down", "=", "[", "downrelu", ",", "downconv", "]", "\n", "up", "=", "[", "uprelu", ",", "upconv", ",", "upnorm", "]", "\n", "model", "=", "down", "+", "up", "\n", "", "else", ":", "\n", "            ", "upconv", "=", "nn", ".", "ConvTranspose2d", "(", "inner_nc", "*", "2", ",", "outer_nc", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "down", "=", "[", "downrelu", ",", "downconv", ",", "downnorm", "]", "\n", "up", "=", "[", "uprelu", ",", "upconv", ",", "upnorm", "]", "\n", "\n", "if", "use_dropout", ":", "\n", "                ", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "+", "[", "nn", ".", "Dropout", "(", "0.5", ")", "]", "\n", "", "else", ":", "\n", "                ", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "\n", "\n", "", "", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.UnetSkipConnectionBlock.forward": [[526, 531], ["networks.UnetSkipConnectionBlock.model", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks.UnetSkipConnectionBlock.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "outermost", ":", "\n", "            ", "return", "self", ".", "model", "(", "x", ")", "\n", "", "else", ":", "# add skip connections", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "x", ",", "self", ".", "model", "(", "x", ")", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.NLayerDiscriminator.__init__": [[536, 575], ["torch.Module.__init__", "range", "min", "torch.Sequential", "torch.Sequential", "type", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "min", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "ndf", "=", "64", ",", "n_layers", "=", "3", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "\"\"\"Construct a PatchGAN discriminator\n\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            ndf (int)       -- the number of filters in the last conv layer\n            n_layers (int)  -- the number of conv layers in the discriminator\n            norm_layer      -- normalization layer\n        \"\"\"", "\n", "super", "(", "NLayerDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "# no need to use bias as BatchNorm2d has affine parameters", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "!=", "nn", ".", "BatchNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "!=", "nn", ".", "BatchNorm2d", "\n", "\n", "", "kw", "=", "4", "\n", "padw", "=", "1", "\n", "sequence", "=", "[", "nn", ".", "Conv2d", "(", "input_nc", ",", "ndf", ",", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ")", ",", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "]", "\n", "nf_mult", "=", "1", "\n", "nf_mult_prev", "=", "1", "\n", "for", "n", "in", "range", "(", "1", ",", "n_layers", ")", ":", "# gradually increase the number of filters", "\n", "            ", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "nf_mult", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n_layers", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "nf_mult", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "sequence", "+=", "[", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult", ",", "1", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ")", "]", "# output 1 channel prediction map", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.NLayerDiscriminator.forward": [[576, 579], ["networks.NLayerDiscriminator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward.\"\"\"", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.PixelDiscriminator.__init__": [[584, 607], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "type", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "ndf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "\"\"\"Construct a 1x1 PatchGAN discriminator\n\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            ndf (int)       -- the number of filters in the last conv layer\n            norm_layer      -- normalization layer\n        \"\"\"", "\n", "super", "(", "PixelDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "# no need to use bias as BatchNorm2d has affine parameters", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "!=", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "!=", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "self", ".", "net", "=", "[", "\n", "nn", ".", "Conv2d", "(", "input_nc", ",", "ndf", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ndf", ",", "ndf", "*", "2", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "2", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "2", ",", "1", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", "]", "\n", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "net", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.PixelDiscriminator.forward": [[608, 611], ["networks.PixelDiscriminator.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward.\"\"\"", "\n", "return", "self", ".", "net", "(", "input", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.get_norm_layer": [[12, 30], ["functools.partial", "functools.partial", "NotImplementedError"], "function", ["None"], ["def", "get_norm_layer", "(", "norm_type", "=", "'instance'", ")", ":", "\n", "    ", "\"\"\"Return a normalization layer\n\n    Parameters:\n        norm_type (str) -- the name of the normalization layer: batch | instance | none\n\n    For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n    For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics.\n    \"\"\"", "\n", "if", "norm_type", "==", "'batch'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "BatchNorm2d", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "", "elif", "norm_type", "==", "'instance'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "InstanceNorm2d", ",", "affine", "=", "False", ",", "track_running_stats", "=", "False", ")", "\n", "", "elif", "norm_type", "==", "'none'", ":", "\n", "        ", "norm_layer", "=", "None", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'normalization layer [%s] is not found'", "%", "norm_type", ")", "\n", "", "return", "norm_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.get_scheduler": [[32, 59], ["torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.ReduceLROnPlateau", "max", "float", "torch.optim.lr_scheduler.CosineAnnealingLR", "NotImplementedError"], "function", ["None"], ["", "def", "get_scheduler", "(", "optimizer", ",", "opt", ")", ":", "\n", "    ", "\"\"\"Return a learning rate scheduler\n\n    Parameters:\n        optimizer          -- the optimizer of the network\n        opt (option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\uff0e\u3000\n                              opt.lr_policy is the name of learning rate policy: linear | step | plateau | cosine\n\n    For 'linear', we keep the same learning rate for the first <opt.niter> epochs\n    and linearly decay the rate to zero over the next <opt.niter_decay> epochs.\n    For other schedulers (step, plateau, and cosine), we use the default PyTorch schedulers.\n    See https://pytorch.org/docs/stable/optim.html for more details.\n    \"\"\"", "\n", "if", "opt", ".", "lr_policy", "==", "'linear'", ":", "\n", "        ", "def", "lambda_rule", "(", "epoch", ")", ":", "\n", "            ", "lr_l", "=", "1.0", "-", "max", "(", "0", ",", "epoch", "+", "opt", ".", "epoch_count", "-", "opt", ".", "niter", ")", "/", "float", "(", "opt", ".", "niter_decay", "+", "1", ")", "\n", "return", "lr_l", "\n", "", "scheduler", "=", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lambda_rule", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'step'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "step_size", "=", "opt", ".", "lr_decay_iters", ",", "gamma", "=", "0.1", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'plateau'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "factor", "=", "0.2", ",", "threshold", "=", "0.01", ",", "patience", "=", "5", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'cosine'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "CosineAnnealingLR", "(", "optimizer", ",", "T_max", "=", "opt", ".", "niter", ",", "eta_min", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "return", "NotImplementedError", "(", "'learning rate policy [%s] is not implemented'", ",", "opt", ".", "lr_policy", ")", "\n", "", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.init_weights": [[61, 93], ["print", "net.apply", "hasattr", "torch.nn.init.normal_", "hasattr", "torch.nn.init.constant_", "classname.find", "torch.nn.init.normal_", "torch.nn.init.constant_", "classname.find", "classname.find", "torch.nn.init.xavier_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.orthogonal_", "NotImplementedError"], "function", ["None"], ["", "def", "init_weights", "(", "net", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ")", ":", "\n", "    ", "\"\"\"Initialize network weights.\n\n    Parameters:\n        net (network)   -- network to be initialized\n        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n\n    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n    work better for some applications. Feel free to try yourself.\n    \"\"\"", "\n", "def", "init_func", "(", "m", ")", ":", "# define the initialization function", "\n", "        ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "(", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", "or", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ")", ":", "\n", "            ", "if", "init_type", "==", "'normal'", ":", "\n", "                ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "0.0", ",", "init_gain", ")", "\n", "", "elif", "init_type", "==", "'xavier'", ":", "\n", "                ", "init", ".", "xavier_normal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "init_gain", ")", "\n", "", "elif", "init_type", "==", "'kaiming'", ":", "\n", "                ", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ".", "data", ",", "a", "=", "0", ",", "mode", "=", "'fan_in'", ")", "\n", "", "elif", "init_type", "==", "'orthogonal'", ":", "\n", "                ", "init", ".", "orthogonal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "init_gain", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'initialization method [%s] is not implemented'", "%", "init_type", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'BatchNorm2d'", ")", "!=", "-", "1", ":", "# BatchNorm Layer's weight is not a matrix; only normal distribution applies.", "\n", "            ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "1.0", ",", "init_gain", ")", "\n", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "\n", "", "", "print", "(", "'initialize network with %s'", "%", "init_type", ")", "\n", "net", ".", "apply", "(", "init_func", ")", "# apply the initialization function <init_func>", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.init_net": [[95, 111], ["networks.init_weights", "len", "torch.cuda.is_available", "torch.cuda.is_available", "torch.nn.DataParallel.to", "torch.nn.DataParallel", "torch.nn.DataParallel"], "function", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.init_weights"], ["", "def", "init_net", "(", "net", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n    Parameters:\n        net (network)      -- the network to be initialized\n        init_type (str)    -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n        gain (float)       -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n\n    Return an initialized network.\n    \"\"\"", "\n", "if", "len", "(", "gpu_ids", ")", ">", "0", ":", "\n", "        ", "assert", "(", "torch", ".", "cuda", ".", "is_available", "(", ")", ")", "\n", "net", ".", "to", "(", "gpu_ids", "[", "0", "]", ")", "\n", "net", "=", "torch", ".", "nn", ".", "DataParallel", "(", "net", ",", "gpu_ids", ")", "# multi-GPUs", "\n", "", "init_weights", "(", "net", ",", "init_type", ",", "init_gain", "=", "init_gain", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.define_G": [[113, 154], ["networks.get_norm_layer", "networks.init_net", "networks.ResnetGenerator", "networks.ResnetGenerator", "networks.UnetGenerator", "networks.UnetGenerator", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.init_net"], ["", "def", "define_G", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "netG", ",", "norm", "=", "'batch'", ",", "use_dropout", "=", "False", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Create a generator\n\n    Parameters:\n        input_nc (int) -- the number of channels in input images\n        output_nc (int) -- the number of channels in output images\n        ngf (int) -- the number of filters in the last conv layer\n        netG (str) -- the architecture's name: resnet_9blocks | resnet_6blocks | unet_256 | unet_128\n        norm (str) -- the name of normalization layers used in the network: batch | instance | none\n        use_dropout (bool) -- if use dropout layers.\n        init_type (str)    -- the name of our initialization method.\n        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n\n    Returns a generator\n\n    Our current implementation provides two types of generators:\n        U-Net: [unet_128] (for 128x128 input images) and [unet_256] (for 256x256 input images)\n        The original U-Net paper: https://arxiv.org/abs/1505.04597\n\n        Resnet-based generator: [resnet_6blocks] (with 6 Resnet blocks) and [resnet_9blocks] (with 9 Resnet blocks)\n        Resnet-based generator consists of several Resnet blocks between a few downsampling/upsampling operations.\n        We adapt Torch code from Justin Johnson's neural style transfer project (https://github.com/jcjohnson/fast-neural-style).\n\n\n    The generator has been initialized by <init_net>. It uses RELU for non-linearity.\n    \"\"\"", "\n", "net", "=", "None", "\n", "norm_layer", "=", "get_norm_layer", "(", "norm_type", "=", "norm", ")", "\n", "\n", "if", "netG", "==", "'resnet_9blocks'", ":", "\n", "        ", "net", "=", "ResnetGenerator", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "n_blocks", "=", "9", ")", "\n", "", "elif", "netG", "==", "'resnet_6blocks'", ":", "\n", "        ", "net", "=", "ResnetGenerator", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "n_blocks", "=", "6", ")", "\n", "", "elif", "netG", "==", "'unet_128'", ":", "\n", "        ", "net", "=", "UnetGenerator", "(", "input_nc", ",", "output_nc", ",", "7", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ")", "\n", "", "elif", "netG", "==", "'unet_256'", ":", "\n", "        ", "net", "=", "UnetGenerator", "(", "input_nc", ",", "output_nc", ",", "8", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Generator model name [%s] is not recognized'", "%", "netG", ")", "\n", "", "return", "init_net", "(", "net", ",", "init_type", ",", "init_gain", ",", "gpu_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.define_D": [[156, 198], ["networks.get_norm_layer", "networks.init_net", "networks.NLayerDiscriminator", "networks.NLayerDiscriminator", "networks.PixelDiscriminator", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.init_net"], ["", "def", "define_D", "(", "input_nc", ",", "ndf", ",", "netD", ",", "n_layers_D", "=", "3", ",", "norm", "=", "'batch'", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Create a discriminator\n\n    Parameters:\n        input_nc (int)     -- the number of channels in input images\n        ndf (int)          -- the number of filters in the first conv layer\n        netD (str)         -- the architecture's name: basic | n_layers | pixel\n        n_layers_D (int)   -- the number of conv layers in the discriminator; effective when netD=='n_layers'\n        norm (str)         -- the type of normalization layers used in the network.\n        init_type (str)    -- the name of the initialization method.\n        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n\n    Returns a discriminator\n\n    Our current implementation provides three types of discriminators:\n        [basic]: 'PatchGAN' classifier described in the original pix2pix paper.\n        It can classify whether 70\u00d770 overlapping patches are real or fake.\n        Such a patch-level discriminator architecture has fewer parameters\n        than a full-image discriminator and can work on arbitrarily-sized images\n        in a fully convolutional fashion.\n\n        [n_layers]: With this mode, you cna specify the number of conv layers in the discriminator\n        with the parameter <n_layers_D> (default=3 as used in [basic] (PatchGAN).)\n\n        [pixel]: 1x1 PixelGAN discriminator can classify whether a pixel is real or not.\n        It encourages greater color diversity but has no effect on spatial statistics.\n\n    The discriminator has been initialized by <init_net>. It uses Leakly RELU for non-linearity.\n    \"\"\"", "\n", "net", "=", "None", "\n", "norm_layer", "=", "get_norm_layer", "(", "norm_type", "=", "norm", ")", "\n", "\n", "if", "netD", "==", "'basic'", ":", "# default PatchGAN classifier", "\n", "        ", "net", "=", "NLayerDiscriminator", "(", "input_nc", ",", "ndf", ",", "n_layers", "=", "3", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "elif", "netD", "==", "'n_layers'", ":", "# more options", "\n", "        ", "net", "=", "NLayerDiscriminator", "(", "input_nc", ",", "ndf", ",", "n_layers_D", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "elif", "netD", "==", "'pixel'", ":", "# classify if each pixel is real or fake", "\n", "        ", "net", "=", "PixelDiscriminator", "(", "input_nc", ",", "ndf", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Discriminator model name [%s] is not recognized'", "%", "net", ")", "\n", "", "return", "init_net", "(", "net", ",", "init_type", ",", "init_gain", ",", "gpu_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.cal_gradient_penalty": [[272, 308], ["interpolatesv.requires_grad_", "netD", "torch.autograd.grad", "torch.autograd.grad", "gradients[].view", "real_data.size", "torch.ones().to", "torch.ones().to", "torch.rand", "torch.rand", "alpha.to.expand().contiguous().view", "alpha.to.to", "NotImplementedError", "torch.ones", "torch.ones", "alpha.to.expand().contiguous", "netD.size", "alpha.to.expand", "real_data.nelement"], "function", ["None"], ["", "", "def", "cal_gradient_penalty", "(", "netD", ",", "real_data", ",", "fake_data", ",", "device", ",", "type", "=", "'mixed'", ",", "constant", "=", "1.0", ",", "lambda_gp", "=", "10.0", ")", ":", "\n", "    ", "\"\"\"Calculate the gradient penalty loss, used in WGAN-GP paper https://arxiv.org/abs/1704.00028\n\n    Arguments:\n        netD (network)              -- discriminator network\n        real_data (tensor array)    -- real images\n        fake_data (tensor array)    -- generated images from the generator\n        device (str)                -- GPU / CPU: from torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')\n        type (str)                  -- if we mix real and fake data or not [real | fake | mixed].\n        constant (float)            -- the constant used in formula ( | |gradient||_2 - constant)^2\n        lambda_gp (float)           -- weight for this loss\n\n    Returns the gradient penalty loss\n    \"\"\"", "\n", "if", "lambda_gp", ">", "0.0", ":", "\n", "        ", "if", "type", "==", "'real'", ":", "# either use real images, fake images, or a linear interpolation of two.", "\n", "            ", "interpolatesv", "=", "real_data", "\n", "", "elif", "type", "==", "'fake'", ":", "\n", "            ", "interpolatesv", "=", "fake_data", "\n", "", "elif", "type", "==", "'mixed'", ":", "\n", "            ", "alpha", "=", "torch", ".", "rand", "(", "real_data", ".", "shape", "[", "0", "]", ",", "1", ")", "\n", "alpha", "=", "alpha", ".", "expand", "(", "real_data", ".", "shape", "[", "0", "]", ",", "real_data", ".", "nelement", "(", ")", "//", "real_data", ".", "shape", "[", "0", "]", ")", ".", "contiguous", "(", ")", ".", "view", "(", "*", "real_data", ".", "shape", ")", "\n", "alpha", "=", "alpha", ".", "to", "(", "device", ")", "\n", "interpolatesv", "=", "alpha", "*", "real_data", "+", "(", "(", "1", "-", "alpha", ")", "*", "fake_data", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'{} not implemented'", ".", "format", "(", "type", ")", ")", "\n", "", "interpolatesv", ".", "requires_grad_", "(", "True", ")", "\n", "disc_interpolates", "=", "netD", "(", "interpolatesv", ")", "\n", "gradients", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "disc_interpolates", ",", "inputs", "=", "interpolatesv", ",", "\n", "grad_outputs", "=", "torch", ".", "ones", "(", "disc_interpolates", ".", "size", "(", ")", ")", ".", "to", "(", "device", ")", ",", "\n", "create_graph", "=", "True", ",", "retain_graph", "=", "True", ",", "only_inputs", "=", "True", ")", "\n", "gradients", "=", "gradients", "[", "0", "]", ".", "view", "(", "real_data", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# flat the data", "\n", "gradient_penalty", "=", "(", "(", "(", "gradients", "+", "1e-16", ")", ".", "norm", "(", "2", ",", "dim", "=", "1", ")", "-", "constant", ")", "**", "2", ")", ".", "mean", "(", ")", "*", "lambda_gp", "# added eps", "\n", "return", "gradient_penalty", ",", "gradients", "\n", "", "else", ":", "\n", "        ", "return", "0.0", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.test_model.TestModel.modify_commandline_options": [[11, 30], ["parser.set_defaults", "parser.add_argument"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", "=", "True", ")", ":", "\n", "        ", "\"\"\"Add new dataset-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n\n        The model can only be used during test time. It requires '--dataset_mode single'.\n        You need to specify the network using the option '--model_suffix'.\n        \"\"\"", "\n", "assert", "not", "is_train", ",", "'TestModel cannot be used during training time'", "\n", "parser", ".", "set_defaults", "(", "dataset_mode", "=", "'single'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_suffix'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'In checkpoints_dir, [epoch]_net_G[model_suffix].pth will be loaded as the generator.'", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.test_model.TestModel.__init__": [[31, 52], ["base_model.BaseModel.__init__", "networks.define_G", "setattr"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.define_G"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the pix2pix class.\n\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "assert", "(", "not", "opt", ".", "isTrain", ")", "\n", "BaseModel", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "# specify the training losses you want to print out. The training/test scripts  will call <BaseModel.get_current_losses>", "\n", "self", ".", "loss_names", "=", "[", "]", "\n", "# specify the images you want to save/display. The training/test scripts  will call <BaseModel.get_current_visuals>", "\n", "#self.visual_names = ['real_A', 'fake_B']", "\n", "self", ".", "visual_names", "=", "[", "'fake_B'", "]", "\n", "# specify the models you want to save to the disk. The training/test scripts will call <BaseModel.save_networks> and <BaseModel.load_networks>", "\n", "self", ".", "model_names", "=", "[", "'G'", "+", "opt", ".", "model_suffix", "]", "# only generator is needed.", "\n", "self", ".", "netG", "=", "networks", ".", "define_G", "(", "opt", ".", "input_nc", ",", "opt", ".", "output_nc", ",", "opt", ".", "ngf", ",", "opt", ".", "netG", ",", "\n", "opt", ".", "norm", ",", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "\n", "# assigns the model to self.netG_[suffix] so that it can be loaded", "\n", "# please see <BaseModel.load_networks>", "\n", "setattr", "(", "self", ",", "'netG'", "+", "opt", ".", "model_suffix", ",", "self", ".", "netG", ")", "# store netG in self.", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.test_model.TestModel.set_input": [[53, 63], ["input[].to"], "methods", ["None"], ["", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n\n        Parameters:\n            input: a dictionary that contains the data itself and its metadata information.\n\n        We need to use 'single_dataset' dataset mode. It only load images from one domain.\n        \"\"\"", "\n", "self", ".", "real_A", "=", "input", "[", "'A'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "image_paths", "=", "input", "[", "'A_paths'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.test_model.TestModel.forward": [[64, 67], ["test_model.TestModel.netG"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run forward pass.\"\"\"", "\n", "self", ".", "fake_B", "=", "self", ".", "netG", "(", "self", ".", "real_A", ")", "# G(A)", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.test_model.TestModel.optimize_parameters": [[68, 71], ["None"], "methods", ["None"], ["", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"No optimization for test model.\"\"\"", "\n", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.xdcyclegan_model.XDCycleGANModel.modify_commandline_options": [[14, 34], ["parser.set_defaults", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", "=", "True", ")", ":", "\n", "        ", "\"\"\"Add new dataset-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n\n        \"\"\"", "\n", "parser", ".", "set_defaults", "(", "no_dropout", "=", "True", ")", "# default CycleGAN did not use dropout", "\n", "if", "is_train", ":", "\n", "            ", "parser", ".", "add_argument", "(", "'--lambda_A'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for cycle loss (A -> B -> A)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_B'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for cycle loss (B -> A -> B)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_extend'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for adversarial loss on reconstructed image G_A(G_B(B))'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_identity'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'use identity mapping. Setting lambda_identity other than 0 has an effect of scaling the weight of the identity mapping loss. For example, if the weight of the identity loss should be 10 times smaller than the weight of the reconstruction loss, please set lambda_identity = 0.1'", ")", "\n", "\n", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.xdcyclegan_model.XDCycleGANModel.__init__": [[35, 97], ["base_model.BaseModel.__init__", "networks.define_G", "networks.define_G", "visual_names_A.append", "visual_names_B.append", "networks.define_D", "networks.define_D", "util.image_pool.ImagePool", "util.image_pool.ImagePool", "util.image_pool.ImagePool", "util.image_pool.ImagePool", "util.image_pool.ImagePool", "util.image_pool.ImagePool", "networks.GANLoss().to", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.optim.Adam", "torch.optim.Adam", "xdcyclegan_model.XDCycleGANModel.optimizers.append", "xdcyclegan_model.XDCycleGANModel.optimizers.append", "itertools.chain", "itertools.chain", "networks.GANLoss", "xdcyclegan_model.XDCycleGANModel.netG_A.parameters", "xdcyclegan_model.XDCycleGANModel.netG_B.parameters", "xdcyclegan_model.XDCycleGANModel.netD_B.parameters", "xdcyclegan_model.XDCycleGANModel.netD.parameters"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.define_G", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.define_G", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.define_D", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.define_D"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the XDCycleGAN class.\n\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "BaseModel", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "# specify the training losses you want to print out. The training/test scripts will call <BaseModel.get_current_losses>", "\n", "self", ".", "loss_names", "=", "[", "'G_A'", ",", "'cycle_A'", ",", "'idt_A'", ",", "'D_B'", ",", "'G_B'", ",", "'cycle_B'", ",", "\"D\"", ",", "\"extend_A\"", "]", "\n", "\n", "# specify the images you want to save/display. The training/test scripts will call <BaseModel.get_current_visuals>", "\n", "visual_names_A", "=", "[", "'real_A'", ",", "'fake_B'", ",", "'rec_A'", ",", "'ex_fake_B'", "]", "\n", "visual_names_B", "=", "[", "'real_B'", ",", "'fake_A'", ",", "'rec_B'", "]", "\n", "\n", "if", "self", ".", "isTrain", "and", "self", ".", "opt", ".", "lambda_identity", ">", "0.0", ":", "# if identity loss is used, we also visualize idt_B=G_A(B) ad idt_A=G_A(B)", "\n", "            ", "visual_names_A", ".", "append", "(", "'idt_B'", ")", "\n", "visual_names_B", ".", "append", "(", "'idt_A'", ")", "\n", "", "self", ".", "visual_names", "=", "visual_names_A", "+", "visual_names_B", "# combine visualizations for A and B", "\n", "\n", "# specify the models you want to save to the disk. The training/test scripts will call <BaseModel.save_networks> and <BaseModel.load_networks>.", "\n", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "model_names", "=", "[", "'G_A'", ",", "'G_B'", ",", "'D'", ",", "'D_B'", "]", "\n", "", "else", ":", "# during test time, only load Gs", "\n", "            ", "self", ".", "model_names", "=", "[", "'G_A'", ",", "'G_B'", "]", "\n", "\n", "# define networks (both Generators and discriminators)", "\n", "", "self", ".", "netG_A", "=", "networks", ".", "define_G", "(", "opt", ".", "input_nc", ",", "opt", ".", "output_nc", ",", "opt", ".", "ngf", ",", "opt", ".", "netG", ",", "opt", ".", "norm", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "self", ".", "netG_B", "=", "networks", ".", "define_G", "(", "opt", ".", "output_nc", ",", "opt", ".", "input_nc", ",", "opt", ".", "ngf", ",", "opt", ".", "netG", ",", "opt", ".", "norm", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "\n", "if", "self", ".", "isTrain", ":", "# define discriminators", "\n", "            ", "self", ".", "netD", "=", "networks", ".", "define_D", "(", "opt", ".", "output_nc", "*", "2", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "opt", ".", "n_layers_D", ",", "opt", ".", "norm", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "\n", "self", ".", "netD_B", "=", "networks", ".", "define_D", "(", "opt", ".", "input_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "opt", ".", "n_layers_D", ",", "opt", ".", "norm", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "\n", "", "if", "self", ".", "isTrain", ":", "\n", "            ", "if", "opt", ".", "lambda_identity", ">", "0.0", ":", "# only works when input and output images have the same number of channels", "\n", "                ", "assert", "(", "opt", ".", "input_nc", "==", "opt", ".", "output_nc", ")", "\n", "\n", "# create image buffer to store previously generated images", "\n", "", "self", ".", "fake_A_pool", "=", "ImagePool", "(", "opt", ".", "pool_size", ")", "\n", "self", ".", "fake_B_pool", "=", "ImagePool", "(", "opt", ".", "pool_size", ")", "\n", "self", ".", "rec_A_pool", "=", "ImagePool", "(", "opt", ".", "pool_size", ")", "\n", "self", ".", "AtoB_pool", "=", "ImagePool", "(", "opt", ".", "pool_size", ")", "\n", "self", ".", "BtoA_pool", "=", "ImagePool", "(", "opt", ".", "pool_size", ")", "\n", "self", ".", "real_pool", "=", "ImagePool", "(", "opt", ".", "pool_size", ")", "\n", "\n", "\n", "# define loss functions", "\n", "self", ".", "criterionGAN", "=", "networks", ".", "GANLoss", "(", "opt", ".", "gan_mode", ")", ".", "to", "(", "self", ".", "device", ")", "# define GAN loss.", "\n", "self", ".", "criterionCycle", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "\n", "self", ".", "criterionIdt", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "\n", "\n", "# initialize optimizers; schedulers will be automatically created by function <BaseModel.setup>.", "\n", "self", ".", "optimizer_G", "=", "torch", ".", "optim", ".", "Adam", "(", "itertools", ".", "chain", "(", "self", ".", "netG_A", ".", "parameters", "(", ")", ",", "self", ".", "netG_B", ".", "parameters", "(", ")", ")", ",", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "self", ".", "optimizer_D", "=", "torch", ".", "optim", ".", "Adam", "(", "itertools", ".", "chain", "(", "self", ".", "netD_B", ".", "parameters", "(", ")", ",", "self", ".", "netD", ".", "parameters", "(", ")", ")", ",", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_G", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_D", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.xdcyclegan_model.XDCycleGANModel.set_input": [[98, 110], ["input[].to", "input[].to"], "methods", ["None"], ["", "", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n\n        Parameters:\n            input (dict): include the data itself and its metadata information.\n\n        The option 'direction' can be used to swap domain A and domain B.\n        \"\"\"", "\n", "AtoB", "=", "self", ".", "opt", ".", "direction", "==", "'AtoB'", "\n", "self", ".", "real_A", "=", "input", "[", "'A'", "if", "AtoB", "else", "'B'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "real_B", "=", "input", "[", "'B'", "if", "AtoB", "else", "'A'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "image_paths", "=", "input", "[", "'A_paths'", "if", "AtoB", "else", "'B_paths'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.xdcyclegan_model.XDCycleGANModel.forward": [[111, 120], ["xdcyclegan_model.XDCycleGANModel.netG_A", "xdcyclegan_model.XDCycleGANModel.netG_B", "xdcyclegan_model.XDCycleGANModel.netG_B", "xdcyclegan_model.XDCycleGANModel.netG_A", "xdcyclegan_model.XDCycleGANModel.netG_A", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"", "\n", "self", ".", "fake_B", "=", "self", ".", "netG_A", "(", "self", ".", "real_A", ")", "# G_A(A)", "\n", "self", ".", "rec_A", "=", "self", ".", "netG_B", "(", "self", ".", "fake_B", ")", "# G_B(G_A(A))", "\n", "self", ".", "fake_A", "=", "self", ".", "netG_B", "(", "self", ".", "real_B", ")", "# G_B(B)", "\n", "self", ".", "rec_B", "=", "self", ".", "netG_A", "(", "self", ".", "fake_A", ")", "# G_A(G_B(B))", "\n", "self", ".", "ex_fake_B", "=", "self", ".", "netG_A", "(", "self", ".", "rec_A", ")", "#G_A(G_B(G_A(A)))", "\n", "self", ".", "AtoB", "=", "torch", ".", "cat", "(", "(", "self", ".", "real_A", ",", "self", ".", "fake_B", ")", ",", "1", ")", "\n", "self", ".", "BtoA", "=", "torch", ".", "cat", "(", "(", "self", ".", "fake_A", ",", "self", ".", "real_B", ")", ",", "1", ")", "\n", "#print(self.real_A.shape,self.AtoB.shape)", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.xdcyclegan_model.XDCycleGANModel.backward_D_basic": [[122, 143], ["netD", "xdcyclegan_model.XDCycleGANModel.criterionGAN", "netD", "xdcyclegan_model.XDCycleGANModel.criterionGAN", "loss_D.backward", "fake.detach"], "methods", ["None"], ["", "def", "backward_D_basic", "(", "self", ",", "netD", ",", "real", ",", "fake", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for the discriminator\n\n        Parameters:\n            netD (network)      -- the discriminator D\n            real (tensor array) -- real images\n            fake (tensor array) -- images generated by a generator\n\n        Return the discriminator loss.\n        We also call loss_D.backward() to calculate the gradients.\n        \"\"\"", "\n", "# Real", "\n", "pred_real", "=", "netD", "(", "real", ")", "\n", "loss_D_real", "=", "self", ".", "criterionGAN", "(", "pred_real", ",", "True", ")", "\n", "# Fake", "\n", "pred_fake", "=", "netD", "(", "fake", ".", "detach", "(", ")", ")", "\n", "loss_D_fake", "=", "self", ".", "criterionGAN", "(", "pred_fake", ",", "False", ")", "\n", "# Combined loss and calculate gradients", "\n", "loss_D", "=", "(", "loss_D_real", "+", "loss_D_fake", ")", "*", "0.5", "\n", "loss_D", ".", "backward", "(", ")", "\n", "return", "loss_D", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.xdcyclegan_model.XDCycleGANModel.backward_D_B": [[144, 153], ["xdcyclegan_model.XDCycleGANModel.rec_A_pool.query", "xdcyclegan_model.XDCycleGANModel.backward_D_basic", "xdcyclegan_model.XDCycleGANModel.fake_A_pool.query", "xdcyclegan_model.XDCycleGANModel.real_pool.query", "xdcyclegan_model.XDCycleGANModel.backward_D_basic", "xdcyclegan_model.XDCycleGANModel.rec_A.detach", "xdcyclegan_model.XDCycleGANModel.fake_A.detach", "xdcyclegan_model.XDCycleGANModel.real_A.detach"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.util.image_pool.ImagePool.query", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_basic", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.image_pool.ImagePool.query", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.image_pool.ImagePool.query", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_basic"], ["", "def", "backward_D_B", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for discriminator D_B\"\"\"", "\n", "\n", "rec_A", "=", "self", ".", "rec_A_pool", ".", "query", "(", "self", ".", "rec_A", ".", "detach", "(", ")", ")", "\n", "self", ".", "loss_D_B", "=", "self", ".", "backward_D_basic", "(", "self", ".", "netD_B", ",", "self", ".", "real_A", ",", "rec_A", ")", "\n", "\n", "fake_A", "=", "self", ".", "fake_A_pool", ".", "query", "(", "self", ".", "fake_A", ".", "detach", "(", ")", ")", "\n", "real_A", "=", "self", ".", "real_pool", ".", "query", "(", "self", ".", "real_A", ".", "detach", "(", ")", ")", "\n", "self", ".", "loss_D_B", "+=", "self", ".", "backward_D_basic", "(", "self", ".", "netD_B", ",", "real_A", ",", "fake_A", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.xdcyclegan_model.XDCycleGANModel.backward_D": [[154, 160], ["torch.cat", "torch.cat", "xdcyclegan_model.XDCycleGANModel.backward_D_basic", "torch.cat.detach", "torch.cat.detach"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_basic"], ["", "def", "backward_D", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for discriminator D\"\"\"", "\n", "\n", "AB", "=", "torch", ".", "cat", "(", "(", "self", ".", "real_A", ",", "self", ".", "fake_B", ")", ",", "1", ")", "\n", "BA", "=", "torch", ".", "cat", "(", "(", "self", ".", "fake_A", ",", "self", ".", "real_B", ")", ",", "1", ")", "\n", "self", ".", "loss_D", "=", "self", ".", "backward_D_basic", "(", "self", ".", "netD", ",", "AB", ".", "detach", "(", ")", ",", "BA", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.xdcyclegan_model.XDCycleGANModel.backward_G": [[163, 198], ["xdcyclegan_model.XDCycleGANModel.criterionGAN", "xdcyclegan_model.XDCycleGANModel.criterionGAN", "xdcyclegan_model.XDCycleGANModel.loss_G.backward", "xdcyclegan_model.XDCycleGANModel.netG_A", "xdcyclegan_model.XDCycleGANModel.netG_B", "xdcyclegan_model.XDCycleGANModel.netD", "xdcyclegan_model.XDCycleGANModel.netD", "xdcyclegan_model.XDCycleGANModel.criterionCycle", "xdcyclegan_model.XDCycleGANModel.criterionCycle", "xdcyclegan_model.XDCycleGANModel.criterionGAN", "xdcyclegan_model.XDCycleGANModel.fake_B.detach", "xdcyclegan_model.XDCycleGANModel.netD_B", "xdcyclegan_model.XDCycleGANModel.criterionIdt"], "methods", ["None"], ["", "def", "backward_G", "(", "self", ")", ":", "\n", "\n", "        ", "\"\"\"Calculate the loss for generators G_A and G_B\"\"\"", "\n", "lambda_idt", "=", "self", ".", "opt", ".", "lambda_identity", "\n", "lambda_A", "=", "self", ".", "opt", ".", "lambda_A", "\n", "lambda_B", "=", "self", ".", "opt", ".", "lambda_B", "\n", "lambda_E", "=", "self", ".", "opt", ".", "lambda_extend", "\n", "\n", "# Identity loss", "\n", "if", "lambda_idt", ">", "0", ":", "\n", "# G_A should be identity if real_B is fed: ||G_A(B) - B||", "\n", "            ", "self", ".", "idt_A", "=", "self", ".", "netG_A", "(", "self", ".", "real_B", ")", "\n", "self", ".", "loss_idt_A", "=", "self", ".", "criterionIdt", "(", "self", ".", "idt_A", ",", "self", ".", "real_B", ")", "*", "lambda_B", "*", "lambda_idt", "\n", "self", ".", "idt_B", "=", "self", ".", "netG_B", "(", "self", ".", "real_A", ")", "\n", "self", ".", "loss_idt_B", "=", "0", "\n", "", "else", ":", "\n", "            ", "self", ".", "loss_idt_A", "=", "0", "\n", "self", ".", "loss_idt_B", "=", "0", "\n", "\n", "# GAN loss D_A(G_A(A))", "\n", "", "self", ".", "loss_G_A", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD", "(", "self", ".", "AtoB", ")", ",", "False", ")", "\n", "# GAN loss D_B(G_B(B))", "\n", "self", ".", "loss_G_B", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD", "(", "self", ".", "BtoA", ")", ",", "True", ")", "\n", "\n", "#Extended Cycle loss", "\n", "self", ".", "loss_cycle_A", "=", "self", ".", "criterionCycle", "(", "self", ".", "ex_fake_B", ",", "self", ".", "fake_B", ".", "detach", "(", ")", ")", "*", "lambda_A", "\n", "# Backward cycle loss ", "\n", "self", ".", "loss_cycle_B", "=", "self", ".", "criterionCycle", "(", "self", ".", "rec_B", ",", "self", ".", "real_B", ")", "*", "lambda_B", "\n", "\n", "#Extended cycle discrmininator", "\n", "self", ".", "loss_extend_A", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD_B", "(", "self", ".", "rec_A", ")", ",", "True", ")", "*", "lambda_E", "\n", "\n", "# combined loss and calculate gradients", "\n", "self", ".", "loss_G", "=", "self", ".", "loss_G_A", "+", "self", ".", "loss_G_B", "+", "self", ".", "loss_cycle_A", "+", "self", ".", "loss_cycle_B", "+", "self", ".", "loss_idt_A", "+", "self", ".", "loss_idt_B", "+", "self", ".", "loss_extend_A", "\n", "self", ".", "loss_G", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.xdcyclegan_model.XDCycleGANModel.optimize_parameters": [[201, 216], ["xdcyclegan_model.XDCycleGANModel.forward", "xdcyclegan_model.XDCycleGANModel.set_requires_grad", "xdcyclegan_model.XDCycleGANModel.optimizer_G.zero_grad", "xdcyclegan_model.XDCycleGANModel.backward_G", "xdcyclegan_model.XDCycleGANModel.optimizer_G.step", "xdcyclegan_model.XDCycleGANModel.set_requires_grad", "xdcyclegan_model.XDCycleGANModel.optimizer_D.zero_grad", "xdcyclegan_model.XDCycleGANModel.backward_D", "xdcyclegan_model.XDCycleGANModel.backward_D_B", "xdcyclegan_model.XDCycleGANModel.optimizer_D.step"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.forward", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_G", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.xdcyclegan_model.XDCycleGANModel.backward_D", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_B"], ["", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"", "\n", "# forward", "\n", "self", ".", "forward", "(", ")", "# compute fake images and reconstruction images.", "\n", "# G_A and G_B", "\n", "self", ".", "set_requires_grad", "(", "[", "self", ".", "netD_B", ",", "self", ".", "netD", "]", ",", "False", ")", "# Ds require no gradients when optimizing Gs", "\n", "self", ".", "optimizer_G", ".", "zero_grad", "(", ")", "# set G_A and G_B's gradients to zero", "\n", "self", ".", "backward_G", "(", ")", "# calculate gradients for G_A and G_B", "\n", "self", ".", "optimizer_G", ".", "step", "(", ")", "# update G_A and G_B's weights", "\n", "# D and D_B", "\n", "self", ".", "set_requires_grad", "(", "[", "self", ".", "netD_B", ",", "self", ".", "netD", "]", ",", "True", ")", "\n", "self", ".", "optimizer_D", ".", "zero_grad", "(", ")", "# set D_A and D_B's gradients to zero", "\n", "self", ".", "backward_D", "(", ")", "# calculate gradients for D_A", "\n", "self", ".", "backward_D_B", "(", ")", "# calculate graidents for D_B", "\n", "self", ".", "optimizer_D", ".", "step", "(", ")", "# update D_A and D_B's weights", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.modify_commandline_options": [[15, 38], ["parser.set_defaults", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["@", "staticmethod", "\n", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", "=", "True", ")", ":", "\n", "        ", "\"\"\"Add new dataset-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser\n        \"\"\"", "\n", "parser", ".", "set_defaults", "(", "no_dropout", "=", "True", ")", "\n", "\n", "if", "is_train", ":", "\n", "            ", "parser", ".", "add_argument", "(", "'--lambda_adv'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'weight for adversarial portion'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_T'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for transitve loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_GT'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for ground truth loss'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--lambda_identity'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'use identity mapping. Setting lambda_identity other than 0 has an effect of scaling the weight of the identity mapping loss. For example, if the weight of the identity loss should be 10 times smaller than the weight of the reconstruction loss, please set lambda_identity = 0.1'", ")", "\n", "\n", "\n", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.__init__": [[41, 117], ["base_model.BaseModel.__init__", "networks.define_G", "networks.define_G", "networks.define_G", "networks.define_G", "networks.define_D", "networks.define_D", "networks.define_D", "networks.define_D", "networks.GANLoss().to", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.optim.Adam", "torch.optim.Adam", "foldit_model.FoldItModel.optimizers.append", "foldit_model.FoldItModel.optimizers.append", "itertools.chain", "itertools.chain", "networks.GANLoss", "foldit_model.FoldItModel.netG_A.parameters", "foldit_model.FoldItModel.netG_B.parameters", "foldit_model.FoldItModel.netG_AC.parameters", "foldit_model.FoldItModel.netG_BC.parameters", "foldit_model.FoldItModel.netD_A.parameters", "foldit_model.FoldItModel.netD_B.parameters", "foldit_model.FoldItModel.netD_BC.parameters", "foldit_model.FoldItModel.netD_AC.parameters"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.define_G", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.define_G", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.define_G", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.define_G", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.define_D", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.define_D", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.define_D", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.define_D"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the FoldIt class.\n\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "BaseModel", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "# specify the training losses you want to print out. The training/test scripts will call <BaseModel.get_current_losses>", "\n", "self", ".", "loss_names", "=", "[", "'G_A'", ",", "'G_B'", ",", "'G_AC'", ",", "'G_BC'", ",", "'D_A'", ",", "'D_B'", ",", "'D_AC'", ",", "'D_BC'", ",", "'T_AC'", ",", "'T_BC'", ",", "'GT'", ",", "'idt_AC'", ",", "'idt_BC'", ",", "]", "#'G_big','D_big']", "\n", "\n", "\n", "\n", "# specify the images you want to save/display. The training/test scripts will call <BaseModel.get_current_visuals>", "\n", "visual_names_A", "=", "[", "'real_A'", ",", "'fake_B'", ",", "'rec_AC'", ",", "'fake_AC'", "]", "\n", "visual_names_B", "=", "[", "'real_B'", ",", "'fake_A'", ",", "'rec_BC'", ",", "'fake_BC'", "]", "\n", "visual_names_C", "=", "[", "'real_C'", ",", "'idt_AC'", ",", "'idt_BC'", "]", "\n", "\n", "\n", "\n", "self", ".", "visual_names", "=", "visual_names_A", "+", "visual_names_B", "+", "visual_names_C", "# combine visualizations for A and B and C", "\n", "\n", "# specify the models you want to save to the disk. The training/test scripts will call <BaseModel.save_networks> and <BaseModel.load_networks>.", "\n", "if", "self", ".", "isTrain", ":", "\n", "\n", "            ", "self", ".", "model_names", "=", "[", "'G_A'", ",", "'G_B'", ",", "'G_AC'", ",", "'G_BC'", ",", "'D_A'", ",", "'D_B'", ",", "'D_BC'", ",", "'D_AC'", "]", "\n", "\n", "", "else", ":", "# during test time, only load Gs", "\n", "            ", "self", ".", "model_names", "=", "[", "'G_A'", ",", "'G_B'", ",", "'G_AC'", ",", "'G_BC'", "]", "\n", "\n", "# define networks (both Generators and discriminators)", "\n", "# The naming is different from those used in the paper.", "\n", "\n", "", "self", ".", "netG_A", "=", "networks", ".", "define_G", "(", "opt", ".", "input_nc", ",", "opt", ".", "output_nc", ",", "opt", ".", "ngf", ",", "opt", ".", "netG", ",", "opt", ".", "norm", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "self", ".", "netG_B", "=", "networks", ".", "define_G", "(", "opt", ".", "output_nc", ",", "opt", ".", "input_nc", ",", "opt", ".", "ngf", ",", "opt", ".", "netG", ",", "opt", ".", "norm", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "self", ".", "netG_AC", "=", "networks", ".", "define_G", "(", "opt", ".", "output_nc", ",", "opt", ".", "input_nc", ",", "opt", ".", "ngf", ",", "opt", ".", "netG", ",", "opt", ".", "norm", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "self", ".", "netG_BC", "=", "networks", ".", "define_G", "(", "opt", ".", "output_nc", ",", "opt", ".", "input_nc", ",", "opt", ".", "ngf", ",", "opt", ".", "netG", ",", "opt", ".", "norm", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "\n", "\n", "\n", "\n", "if", "self", ".", "isTrain", ":", "# define discriminators", "\n", "\n", "            ", "self", ".", "netD_A", "=", "networks", ".", "define_D", "(", "opt", ".", "output_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "opt", ".", "n_layers_D", ",", "opt", ".", "norm", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "\n", "self", ".", "netD_B", "=", "networks", ".", "define_D", "(", "opt", ".", "output_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "opt", ".", "n_layers_D", ",", "opt", ".", "norm", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "\n", "self", ".", "netD_BC", "=", "networks", ".", "define_D", "(", "opt", ".", "input_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "opt", ".", "n_layers_D", ",", "opt", ".", "norm", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "self", ".", "netD_AC", "=", "networks", ".", "define_D", "(", "opt", ".", "input_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "opt", ".", "n_layers_D", ",", "opt", ".", "norm", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "\n", "\n", "\n", "\n", "", "if", "self", ".", "isTrain", ":", "\n", "            ", "if", "opt", ".", "lambda_identity", ">", "0.0", ":", "# only works when input and output images have the same number of channels", "\n", "                ", "assert", "(", "opt", ".", "input_nc", "==", "opt", ".", "output_nc", ")", "\n", "\n", "\n", "# define loss functions", "\n", "", "self", ".", "criterionGAN", "=", "networks", ".", "GANLoss", "(", "opt", ".", "gan_mode", ")", ".", "to", "(", "self", ".", "device", ")", "# define GAN loss.", "\n", "self", ".", "criterionCycle", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "\n", "self", ".", "criterionIdt", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "\n", "self", ".", "L1Loss", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "\n", "# initialize optimizers; schedulers will be automatically created by function <BaseModel.setup>.", "\n", "self", ".", "optimizer_G", "=", "torch", ".", "optim", ".", "Adam", "(", "itertools", ".", "chain", "(", "self", ".", "netG_A", ".", "parameters", "(", ")", ",", "self", ".", "netG_B", ".", "parameters", "(", ")", ",", "self", ".", "netG_AC", ".", "parameters", "(", ")", ",", "self", ".", "netG_BC", ".", "parameters", "(", ")", ")", ",", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "self", ".", "optimizer_D", "=", "torch", ".", "optim", ".", "Adam", "(", "itertools", ".", "chain", "(", "self", ".", "netD_A", ".", "parameters", "(", ")", ",", "self", ".", "netD_B", ".", "parameters", "(", ")", ",", "self", ".", "netD_BC", ".", "parameters", "(", ")", ",", "self", ".", "netD_AC", ".", "parameters", "(", ")", ")", ",", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_G", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_D", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.set_input": [[118, 131], ["input[].to", "input[].to", "input[].to"], "methods", ["None"], ["", "", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n\n        Parameters:\n            input (dict): include the data itself and its metadata information.\n\n        The option 'direction' can be used to swap domain A and domain B.\n        \"\"\"", "\n", "AtoB", "=", "self", ".", "opt", ".", "direction", "==", "'AtoB'", "\n", "self", ".", "real_A", "=", "input", "[", "'A'", "if", "AtoB", "else", "'B'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "real_B", "=", "input", "[", "'B'", "if", "AtoB", "else", "'A'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "real_C", "=", "input", "[", "'C'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "image_paths", "=", "input", "[", "'A_paths'", "if", "AtoB", "else", "'B_paths'", "]", "\n", "# print(input['B_paths'],input['C_paths'])", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.forward": [[133, 146], ["foldit_model.FoldItModel.netG_A", "foldit_model.FoldItModel.netG_BC", "foldit_model.FoldItModel.netG_AC", "foldit_model.FoldItModel.netG_B", "foldit_model.FoldItModel.netG_AC", "foldit_model.FoldItModel.netG_BC", "foldit_model.FoldItModel.netG_AC", "foldit_model.FoldItModel.netG_BC"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"", "\n", "self", ".", "fake_B", "=", "self", ".", "netG_A", "(", "self", ".", "real_A", ")", "# G_A(A)", "\n", "self", ".", "rec_AC", "=", "self", ".", "netG_BC", "(", "self", ".", "fake_B", ")", "# G_BC(G_A(A))", "\n", "self", ".", "fake_AC", "=", "self", ".", "netG_AC", "(", "self", ".", "real_A", ")", "# G_AC(A)", "\n", "\n", "\n", "self", ".", "fake_A", "=", "self", ".", "netG_B", "(", "self", ".", "real_B", ")", "# G_B(B)", "\n", "self", ".", "rec_BC", "=", "self", ".", "netG_AC", "(", "self", ".", "fake_A", ")", "# G_AC(G_B(B))", "\n", "self", ".", "fake_BC", "=", "self", ".", "netG_BC", "(", "self", ".", "real_B", ")", "# G_BC(B)", "\n", "\n", "self", ".", "idt_AC", "=", "self", ".", "netG_AC", "(", "self", ".", "real_C", ")", "# G_AC(C)", "\n", "self", ".", "idt_BC", "=", "self", ".", "netG_BC", "(", "self", ".", "real_C", ")", "# G_BC(C)", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_basic": [[149, 170], ["netD", "foldit_model.FoldItModel.criterionGAN", "netD", "foldit_model.FoldItModel.criterionGAN", "loss_D.backward", "fake.detach"], "methods", ["None"], ["", "def", "backward_D_basic", "(", "self", ",", "netD", ",", "real", ",", "fake", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for the discriminator\n\n        Parameters:\n            netD (network)      -- the discriminator D\n            real (tensor array) -- real images\n            fake (tensor array) -- images generated by a generator\n\n        Return the discriminator loss.\n        We also call loss_D.backward() to calculate the gradients.\n        \"\"\"", "\n", "# Real", "\n", "pred_real", "=", "netD", "(", "real", ")", "\n", "loss_D_real", "=", "self", ".", "criterionGAN", "(", "pred_real", ",", "True", ")", "\n", "# Fake", "\n", "pred_fake", "=", "netD", "(", "fake", ".", "detach", "(", ")", ")", "\n", "loss_D_fake", "=", "self", ".", "criterionGAN", "(", "pred_fake", ",", "False", ")", "\n", "# Combined loss and calculate gradients", "\n", "loss_D", "=", "(", "loss_D_real", "+", "loss_D_fake", ")", "*", "0.5", "\n", "loss_D", ".", "backward", "(", ")", "\n", "return", "loss_D", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_A": [[171, 176], ["foldit_model.FoldItModel.backward_D_basic"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_basic"], ["", "def", "backward_D_A", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for discriminator D_A\"\"\"", "\n", "\n", "# fake_B = self.fake_B_pool.query(self.fake_B)", "\n", "self", ".", "loss_D_A", "=", "self", ".", "backward_D_basic", "(", "self", ".", "netD_A", ",", "self", ".", "real_B", ",", "self", ".", "fake_B", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_B": [[177, 182], ["foldit_model.FoldItModel.backward_D_basic"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_basic"], ["", "def", "backward_D_B", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for discriminator D_A\"\"\"", "\n", "\n", "# fake_A = self.fake_A_pool.query(self.fake_A)", "\n", "self", ".", "loss_D_B", "=", "self", ".", "backward_D_basic", "(", "self", ".", "netD_B", ",", "self", ".", "real_A", ",", "self", ".", "fake_A", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_AC": [[185, 188], ["foldit_model.FoldItModel.backward_D_basic", "foldit_model.FoldItModel.fake_AC.detach"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_basic"], ["", "def", "backward_D_AC", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for discriminator D_A\"\"\"", "\n", "self", ".", "loss_D_AC", "=", "self", ".", "backward_D_basic", "(", "self", ".", "netD_AC", ",", "self", ".", "real_C", ",", "self", ".", "fake_AC", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_BC": [[190, 193], ["foldit_model.FoldItModel.backward_D_basic", "foldit_model.FoldItModel.fake_BC.detach"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_basic"], ["", "def", "backward_D_BC", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for discriminator D_BC\"\"\"", "\n", "self", ".", "loss_D_BC", "=", "self", ".", "backward_D_basic", "(", "self", ".", "netD_BC", ",", "self", ".", "real_C", ",", "self", ".", "fake_BC", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_G": [[205, 270], ["foldit_model.FoldItModel.loss_G.backward", "foldit_model.FoldItModel.criterionGAN", "foldit_model.FoldItModel.criterionGAN", "foldit_model.FoldItModel.criterionGAN", "foldit_model.FoldItModel.criterionGAN", "foldit_model.FoldItModel.criterionCycle", "foldit_model.FoldItModel.criterionCycle", "foldit_model.FoldItModel.L1Loss", "foldit_model.FoldItModel.criterionIdt", "foldit_model.FoldItModel.criterionIdt", "foldit_model.FoldItModel.netD_A", "foldit_model.FoldItModel.netD_AC", "foldit_model.FoldItModel.netD_B", "foldit_model.FoldItModel.netD_BC"], "methods", ["None"], ["", "def", "backward_G", "(", "self", ")", ":", "\n", "\n", "\n", "        ", "\"\"\"Calculate the loss for generators G_A and G_B\"\"\"", "\n", "\n", "#get weights", "\n", "lambda_idt", "=", "self", ".", "opt", ".", "lambda_identity", "\n", "lambda_T", "=", "self", ".", "opt", ".", "lambda_T", "\n", "lambda_GT", "=", "self", ".", "opt", ".", "lambda_GT", "\n", "lambda_adv", "=", "self", ".", "opt", ".", "lambda_adv", "\n", "\n", "#______________________________________________________", "\n", "#Adversarial Losses", "\n", "#______________________________________________________", "\n", "\n", "# GAN loss D_A(G_A(A))", "\n", "self", ".", "loss_G_A", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD_A", "(", "self", ".", "fake_B", ")", ",", "True", ")", "*", "lambda_adv", "\n", "\n", "# GAN loss D_AC(G_AC(A))", "\n", "self", ".", "loss_G_AC", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD_AC", "(", "self", ".", "fake_AC", ")", ",", "True", ")", "*", "lambda_adv", "\n", "\n", "# GAN loss D_B(G_B(B))", "\n", "self", ".", "loss_G_B", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD_B", "(", "self", ".", "fake_A", ")", ",", "True", ")", "*", "lambda_adv", "\n", "\n", "# GAN loss D_BC(G_BC(B))", "\n", "self", ".", "loss_G_BC", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD_BC", "(", "self", ".", "fake_BC", ")", ",", "True", ")", "*", "lambda_adv", "\n", "\n", "\n", "#sum adversarial losses", "\n", "self", ".", "loss_G", "=", "self", ".", "loss_G_B", "+", "self", ".", "loss_G_BC", "+", "self", ".", "loss_G_A", "+", "self", ".", "loss_G_AC", "\n", "\n", "\n", "#______________________________________________________", "\n", "#Transitive Losses", "\n", "#______________________________________________________", "\n", "\n", "self", ".", "loss_T_BC", "=", "self", ".", "criterionCycle", "(", "self", ".", "fake_BC", ",", "self", ".", "rec_BC", ")", "*", "lambda_T", "\n", "\n", "self", ".", "loss_T_AC", "=", "self", ".", "criterionCycle", "(", "self", ".", "fake_AC", ",", "self", ".", "rec_AC", ")", "*", "lambda_T", "\n", "\n", "#add transitive loss", "\n", "self", ".", "loss_G", "+=", "self", ".", "loss_T_BC", "+", "self", ".", "loss_T_AC", "\n", "\n", "\n", "#______________________________________________________", "\n", "#Ground Truth Losses", "\n", "#______________________________________________________", "\n", "\n", "self", ".", "loss_GT", "=", "self", ".", "L1Loss", "(", "self", ".", "fake_BC", ",", "self", ".", "real_C", ")", "*", "lambda_GT", "\n", "\n", "#add ground truth loss", "\n", "self", ".", "loss_G", "+=", "self", ".", "loss_GT", "\n", "\n", "#______________________________________________________", "\n", "#Identity Losses", "\n", "#______________________________________________________", "\n", "self", ".", "loss_idt_BC", "=", "self", ".", "criterionIdt", "(", "self", ".", "idt_BC", ",", "self", ".", "real_C", ")", "*", "lambda_idt", "\n", "\n", "self", ".", "loss_idt_AC", "=", "self", ".", "criterionIdt", "(", "self", ".", "idt_AC", ",", "self", ".", "real_C", ")", "*", "lambda_idt", "\n", "\n", "#add identity loss", "\n", "self", ".", "loss_G", "+=", "self", ".", "loss_idt_BC", "+", "self", ".", "loss_idt_AC", "\n", "\n", "#apply backwards operation", "\n", "self", ".", "loss_G", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.optimize_parameters": [[272, 295], ["foldit_model.FoldItModel.forward", "foldit_model.FoldItModel.set_requires_grad", "foldit_model.FoldItModel.optimizer_G.zero_grad", "foldit_model.FoldItModel.backward_G", "foldit_model.FoldItModel.optimizer_G.step", "foldit_model.FoldItModel.set_requires_grad", "foldit_model.FoldItModel.optimizer_D.zero_grad", "foldit_model.FoldItModel.backward_D_BC", "foldit_model.FoldItModel.backward_D_AC", "foldit_model.FoldItModel.backward_D_A", "foldit_model.FoldItModel.backward_D_B", "foldit_model.FoldItModel.optimizer_D.step"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.forward", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_G", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_BC", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_AC", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_A", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.foldit_model.FoldItModel.backward_D_B"], ["", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"", "\n", "# forward", "\n", "\n", "\n", "self", ".", "forward", "(", ")", "# compute fake images and reconstruction images.", "\n", "# G_A and G_B", "\n", "self", ".", "set_requires_grad", "(", "[", "self", ".", "netD_A", ",", "self", ".", "netD_B", ",", "self", ".", "netD_BC", ",", "self", ".", "netD_AC", "]", ",", "False", ")", "# Ds require no gradients when optimizing Gs", "\n", "self", ".", "optimizer_G", ".", "zero_grad", "(", ")", "# set G_A and G_B's gradients to zero", "\n", "self", ".", "backward_G", "(", ")", "# calculate gradients for G_A and G_B", "\n", "self", ".", "optimizer_G", ".", "step", "(", ")", "# update G_A and G_B's weights", "\n", "\n", "\n", "self", ".", "set_requires_grad", "(", "[", "self", ".", "netD_A", ",", "self", ".", "netD_B", ",", "self", ".", "netD_BC", ",", "self", ".", "netD_AC", "]", ",", "True", ")", "\n", "\n", "self", ".", "optimizer_D", ".", "zero_grad", "(", ")", "# set D_A and D_B's gradients to zero", "\n", "self", ".", "backward_D_BC", "(", ")", "\n", "self", ".", "backward_D_AC", "(", ")", "\n", "\n", "# self.backward_D()      # calculate gradients for D_A", "\n", "self", ".", "backward_D_A", "(", ")", "# calculate gradients for D_A", "\n", "self", ".", "backward_D_B", "(", ")", "# calculate graidents for D_B", "\n", "self", ".", "optimizer_D", ".", "step", "(", ")", "# update D_A and D_B's weights", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.__init__.find_model_using_name": [[25, 46], ["importlib.import_module", "importlib.import_module.__dict__.items", "model_name.replace", "print", "exit", "issubclass", "name.lower", "target_model_name.lower"], "function", ["None"], []], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.__init__.get_option_setter": [[48, 52], ["__init__.find_model_using_name"], "function", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.__init__.find_model_using_name"], []], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.__init__.create_model": [[54, 68], ["__init__.find_model_using_name", "find_model_using_name.", "print", "type"], "function", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.__init__.find_model_using_name"], []], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.__init__": [[18, 45], ["os.path.join", "torch.device", "torch.device"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the BaseModel class.\n\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n\n        When creating your custom class, you need to implement your own initialization.\n        In this fucntion, you should first call <BaseModel.__init__(self, opt)>\n        Then, you need to define four lists:\n            -- self.loss_names (str list):          specify the training losses that you want to plot and save.\n            -- self.model_names (str list):         specify the images that you want to display and save.\n            -- self.visual_names (str list):        define networks used in our training.\n            -- self.optimizers (optimizer list):    define and initialize optimizers. You can define one optimizer for each network. If two networks are updated at the same time, you can use itertools.chain to group them. See cycle_gan_model.py for an example.\n        \"\"\"", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "gpu_ids", "=", "opt", ".", "gpu_ids", "\n", "self", ".", "isTrain", "=", "opt", ".", "isTrain", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:{}'", ".", "format", "(", "self", ".", "gpu_ids", "[", "0", "]", ")", ")", "if", "self", ".", "gpu_ids", "else", "torch", ".", "device", "(", "'cpu'", ")", "# get device name: CPU or GPU", "\n", "self", ".", "save_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "# save all the checkpoints to save_dir", "\n", "if", "opt", ".", "preprocess", "!=", "'scale_width'", ":", "# with [scale_width], input images might have different sizes, which hurts the performance of cudnn.benchmark.", "\n", "            ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "", "self", ".", "loss_names", "=", "[", "]", "\n", "self", ".", "model_names", "=", "[", "]", "\n", "self", ".", "visual_names", "=", "[", "]", "\n", "self", ".", "optimizers", "=", "[", "]", "\n", "self", ".", "image_paths", "=", "[", "]", "\n", "self", ".", "metric", "=", "0", "# used for learning rate policy 'plateau'", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.modify_commandline_options": [[46, 58], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"Add new model-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n        \"\"\"", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.set_input": [[59, 67], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n\n        Parameters:\n            input (dict): includes the data itself and its metadata information.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.forward": [[68, 72], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "forward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.optimize_parameters": [[73, 77], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.setup": [[78, 90], ["base_model.BaseModel.print_networks", "base_model.BaseModel.load_networks", "networks.get_scheduler"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.print_networks", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.load_networks", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.networks.get_scheduler"], ["", "def", "setup", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Load and print networks; create schedulers\n\n        Parameters:\n            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "schedulers", "=", "[", "networks", ".", "get_scheduler", "(", "optimizer", ",", "opt", ")", "for", "optimizer", "in", "self", ".", "optimizers", "]", "\n", "", "if", "not", "self", ".", "isTrain", "or", "opt", ".", "continue_train", ":", "\n", "            ", "load_suffix", "=", "'iter_%d'", "%", "opt", ".", "load_iter", "if", "opt", ".", "load_iter", ">", "0", "else", "opt", ".", "epoch", "\n", "self", ".", "load_networks", "(", "load_suffix", ")", "\n", "", "self", ".", "print_networks", "(", "opt", ".", "verbose", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.eval": [[91, 97], ["isinstance", "getattr", "getattr.eval"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.eval"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make models eval mode during test time\"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "net", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.test": [[98, 107], ["torch.no_grad", "base_model.BaseModel.forward", "base_model.BaseModel.compute_visuals"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.forward", "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.compute_visuals"], ["", "", "", "def", "test", "(", "self", ")", ":", "\n", "        ", "\"\"\"Forward function used in test time.\n\n        This function wraps <forward> function in no_grad() so we don't save intermediate steps for backprop\n        It also calls <compute_visuals> to produce additional visualization results\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "forward", "(", ")", "\n", "self", ".", "compute_visuals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.compute_visuals": [[108, 111], ["None"], "methods", ["None"], ["", "", "def", "compute_visuals", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate additional output images for visdom and HTML visualization\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.get_image_paths": [[112, 115], ["None"], "methods", ["None"], ["", "def", "get_image_paths", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return image paths that are used to load current data\"\"\"", "\n", "return", "self", ".", "image_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.update_learning_rate": [[116, 126], ["print", "scheduler.step", "scheduler.step"], "methods", ["None"], ["", "def", "update_learning_rate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Update learning rates for all the networks; called at the end of every epoch\"\"\"", "\n", "for", "scheduler", "in", "self", ".", "schedulers", ":", "\n", "            ", "if", "self", ".", "opt", ".", "lr_policy", "==", "'plateau'", ":", "\n", "                ", "scheduler", ".", "step", "(", "self", ".", "metric", ")", "\n", "", "else", ":", "\n", "                ", "scheduler", ".", "step", "(", ")", "\n", "\n", "", "", "lr", "=", "self", ".", "optimizers", "[", "0", "]", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "print", "(", "'learning rate = %.7f'", "%", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.get_current_visuals": [[127, 134], ["collections.OrderedDict", "isinstance", "getattr"], "methods", ["None"], ["", "def", "get_current_visuals", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return visualization images. train.py will display these images with visdom, and save the images to a HTML\"\"\"", "\n", "visual_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "visual_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "visual_ret", "[", "name", "]", "=", "getattr", "(", "self", ",", "name", ")", "\n", "", "", "return", "visual_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.get_current_losses": [[135, 142], ["collections.OrderedDict", "isinstance", "float", "getattr"], "methods", ["None"], ["", "def", "get_current_losses", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return traning losses / errors. train.py will print out these errors on console, and save them to a file\"\"\"", "\n", "errors_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "loss_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "errors_ret", "[", "name", "]", "=", "float", "(", "getattr", "(", "self", ",", "'loss_'", "+", "name", ")", ")", "# float(...) works for both scalar tensor and float number", "\n", "", "", "return", "errors_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.save_networks": [[143, 160], ["isinstance", "os.path.join", "getattr", "torch.cuda.is_available", "torch.save", "getattr.cuda", "torch.save", "len", "getattr.module.cpu().state_dict", "getattr.cpu().state_dict", "getattr.module.cpu", "getattr.cpu"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.util.html.HTML.save", "home.repos.pwc.inspect_result.nadeemlab_CEP.util.html.HTML.save"], ["", "def", "save_networks", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Save all the networks to the disk.\n\n        Parameters:\n            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n        \"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "save_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch", ",", "name", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "save_filename", ")", "\n", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "\n", "if", "len", "(", "self", ".", "gpu_ids", ")", ">", "0", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "torch", ".", "save", "(", "net", ".", "module", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "net", ".", "cuda", "(", "self", ".", "gpu_ids", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "save", "(", "net", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.__patch_instance_norm_state_dict": [[161, 174], ["len", "base_model.BaseModel.__patch_instance_norm_state_dict", "module.__class__.__name__.startswith", "module.__class__.__name__.startswith", "state_dict.pop", "getattr", "getattr", "state_dict.pop"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.__patch_instance_norm_state_dict"], ["", "", "", "", "def", "__patch_instance_norm_state_dict", "(", "self", ",", "state_dict", ",", "module", ",", "keys", ",", "i", "=", "0", ")", ":", "\n", "        ", "\"\"\"Fix InstanceNorm checkpoints incompatibility (prior to 0.4)\"\"\"", "\n", "key", "=", "keys", "[", "i", "]", "\n", "if", "i", "+", "1", "==", "len", "(", "keys", ")", ":", "# at the end, pointing to a parameter/buffer", "\n", "            ", "if", "module", ".", "__class__", ".", "__name__", ".", "startswith", "(", "'InstanceNorm'", ")", "and", "(", "key", "==", "'running_mean'", "or", "key", "==", "'running_var'", ")", ":", "\n", "                ", "if", "getattr", "(", "module", ",", "key", ")", "is", "None", ":", "\n", "                    ", "state_dict", ".", "pop", "(", "'.'", ".", "join", "(", "keys", ")", ")", "\n", "", "", "if", "module", ".", "__class__", ".", "__name__", ".", "startswith", "(", "'InstanceNorm'", ")", "and", "(", "key", "==", "'num_batches_tracked'", ")", ":", "\n", "                ", "state_dict", ".", "pop", "(", "'.'", ".", "join", "(", "keys", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "__patch_instance_norm_state_dict", "(", "state_dict", ",", "getattr", "(", "module", ",", "key", ")", ",", "keys", ",", "i", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.load_networks": [[175, 199], ["isinstance", "os.path.join", "getattr", "isinstance", "print", "torch.load", "hasattr", "list", "getattr.load_state_dict", "torch.load.keys", "base_model.BaseModel.__patch_instance_norm_state_dict", "str", "key.split"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.__patch_instance_norm_state_dict"], ["", "", "def", "load_networks", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Load all the networks from the disk.\n\n        Parameters:\n            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n        \"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "load_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch", ",", "name", ")", "\n", "load_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "load_filename", ")", "\n", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "if", "isinstance", "(", "net", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "                    ", "net", "=", "net", ".", "module", "\n", "", "print", "(", "'loading the model from %s'", "%", "load_path", ")", "\n", "# if you are using PyTorch newer than 0.4 (e.g., built from", "\n", "# GitHub source), you can remove str() on self.device", "\n", "state_dict", "=", "torch", ".", "load", "(", "load_path", ",", "map_location", "=", "str", "(", "self", ".", "device", ")", ")", "\n", "if", "hasattr", "(", "state_dict", ",", "'_metadata'", ")", ":", "\n", "                    ", "del", "state_dict", ".", "_metadata", "\n", "\n", "# patch InstanceNorm checkpoints prior to 0.4", "\n", "", "for", "key", "in", "list", "(", "state_dict", ".", "keys", "(", ")", ")", ":", "# need to copy keys here because we mutate in loop", "\n", "                    ", "self", ".", "__patch_instance_norm_state_dict", "(", "state_dict", ",", "net", ",", "key", ".", "split", "(", "'.'", ")", ")", "\n", "", "net", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.print_networks": [[200, 217], ["print", "print", "isinstance", "getattr", "getattr.parameters", "print", "param.numel", "print"], "methods", ["None"], ["", "", "", "def", "print_networks", "(", "self", ",", "verbose", ")", ":", "\n", "        ", "\"\"\"Print the total number of parameters in the network and (if verbose) network architecture\n\n        Parameters:\n            verbose (bool) -- if verbose: print the network architecture\n        \"\"\"", "\n", "print", "(", "'---------- Networks initialized -------------'", ")", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "num_params", "=", "0", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "                    ", "num_params", "+=", "param", ".", "numel", "(", ")", "\n", "", "if", "verbose", ":", "\n", "                    ", "print", "(", "net", ")", "\n", "", "print", "(", "'[Network %s] Total number of parameters : %.3f M'", "%", "(", "name", ",", "num_params", "/", "1e6", ")", ")", "\n", "", "", "print", "(", "'-----------------------------------------------'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.models.base_model.BaseModel.set_requires_grad": [[218, 230], ["isinstance", "net.parameters"], "methods", ["None"], ["", "def", "set_requires_grad", "(", "self", ",", "nets", ",", "requires_grad", "=", "False", ")", ":", "\n", "        ", "\"\"\"Set requies_grad=Fasle for all the networks to avoid unnecessary computations\n        Parameters:\n            nets (network list)   -- a list of networks\n            requires_grad (bool)  -- whether the networks require gradients or not\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "nets", ",", "list", ")", ":", "\n", "            ", "nets", "=", "[", "nets", "]", "\n", "", "for", "net", "in", "nets", ":", "\n", "            ", "if", "net", "is", "not", "None", ":", "\n", "                ", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.aligned_dataset.AlignedDataset.__init__": [[16, 28], ["data.base_dataset.BaseDataset.__init__", "os.path.join", "sorted", "data.image_folder.make_dataset"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.image_folder.make_dataset"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize this dataset class.\n\n        Parameters:\n            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "BaseDataset", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "self", ".", "dir_AB", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "dataroot", ",", "opt", ".", "phase", ")", "# get the image directory", "\n", "self", ".", "AB_paths", "=", "sorted", "(", "make_dataset", "(", "self", ".", "dir_AB", ",", "opt", ".", "max_dataset_size", ")", ")", "# get image paths", "\n", "assert", "(", "self", ".", "opt", ".", "load_size", ">=", "self", ".", "opt", ".", "crop_size", ")", "# crop_size should be smaller than the size of loaded image", "\n", "self", ".", "input_nc", "=", "self", ".", "opt", ".", "output_nc", "if", "self", ".", "opt", ".", "direction", "==", "'BtoA'", "else", "self", ".", "opt", ".", "input_nc", "\n", "self", ".", "output_nc", "=", "self", ".", "opt", ".", "input_nc", "if", "self", ".", "opt", ".", "direction", "==", "'BtoA'", "else", "self", ".", "opt", ".", "output_nc", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.aligned_dataset.AlignedDataset.__getitem__": [[29, 59], ["PIL.Image.open().convert", "int", "PIL.Image.open().convert.crop", "PIL.Image.open().convert.crop", "data.base_dataset.get_params", "data.base_dataset.get_transform", "data.base_dataset.get_transform", "data.base_dataset.get_transform.", "data.base_dataset.get_transform.", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.get_params", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.get_transform", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.get_transform"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return a data point and its metadata information.\n\n        Parameters:\n            index - - a random integer for data indexing\n\n        Returns a dictionary that contains A, B, A_paths and B_paths\n            A (tensor) - - an image in the input domain\n            B (tensor) - - its corresponding image in the target domain\n            A_paths (str) - - image paths\n            B_paths (str) - - image paths (same as A_paths)\n        \"\"\"", "\n", "# read a image given a random integer index", "\n", "AB_path", "=", "self", ".", "AB_paths", "[", "index", "]", "\n", "AB", "=", "Image", ".", "open", "(", "AB_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "# split AB image into A and B", "\n", "w", ",", "h", "=", "AB", ".", "size", "\n", "w2", "=", "int", "(", "w", "/", "2", ")", "\n", "A", "=", "AB", ".", "crop", "(", "(", "0", ",", "0", ",", "w2", ",", "h", ")", ")", "\n", "B", "=", "AB", ".", "crop", "(", "(", "w2", ",", "0", ",", "w", ",", "h", ")", ")", "\n", "\n", "# apply the same transform to both A and B", "\n", "transform_params", "=", "get_params", "(", "self", ".", "opt", ",", "A", ".", "size", ")", "\n", "A_transform", "=", "get_transform", "(", "self", ".", "opt", ",", "transform_params", ",", "grayscale", "=", "(", "self", ".", "input_nc", "==", "1", ")", ")", "\n", "B_transform", "=", "get_transform", "(", "self", ".", "opt", ",", "transform_params", ",", "grayscale", "=", "(", "self", ".", "output_nc", "==", "1", ")", ")", "\n", "\n", "A", "=", "A_transform", "(", "A", ")", "\n", "B", "=", "B_transform", "(", "B", ")", "\n", "\n", "return", "{", "'A'", ":", "A", ",", "'B'", ":", "B", ",", "'A_paths'", ":", "AB_path", ",", "'B_paths'", ":", "AB_path", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.aligned_dataset.AlignedDataset.__len__": [[60, 63], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the total number of images in the dataset.\"\"\"", "\n", "return", "len", "(", "self", ".", "AB_paths", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.colorization_dataset.ColorizationDataset.modify_commandline_options": [[15, 31], ["parser.set_defaults"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"Add new dataset-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n\n        By default, the number of channels for input image  is 1 (L) and\n        the nubmer of channels for output image is 2 (ab). The direction is from A to B\n        \"\"\"", "\n", "parser", ".", "set_defaults", "(", "input_nc", "=", "1", ",", "output_nc", "=", "2", ",", "direction", "=", "'AtoB'", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.colorization_dataset.ColorizationDataset.__init__": [[32, 43], ["data.base_dataset.BaseDataset.__init__", "os.path.join", "sorted", "data.base_dataset.get_transform", "data.image_folder.make_dataset"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.get_transform", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.image_folder.make_dataset"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize this dataset class.\n\n        Parameters:\n            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "BaseDataset", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "self", ".", "dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "dataroot", ")", "\n", "self", ".", "AB_paths", "=", "sorted", "(", "make_dataset", "(", "self", ".", "dir", ",", "opt", ".", "max_dataset_size", ")", ")", "\n", "assert", "(", "opt", ".", "input_nc", "==", "1", "and", "opt", ".", "output_nc", "==", "2", "and", "opt", ".", "direction", "==", "'AtoB'", ")", "\n", "self", ".", "transform", "=", "get_transform", "(", "self", ".", "opt", ",", "convert", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.colorization_dataset.ColorizationDataset.__getitem__": [[44, 65], ["PIL.Image.open().convert", "colorization_dataset.ColorizationDataset.transform", "numpy.array", "skimage.color.rgb2lab().astype", "torchvision.ToTensor", "PIL.Image.open", "skimage.color.rgb2lab"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return a data point and its metadata information.\n\n        Parameters:\n            index - - a random integer for data indexing\n\n        Returns a dictionary that contains A, B, A_paths and B_paths\n            A (tensor) - - the L channel of an image\n            B (tensor) - - the ab channels of the same image\n            A_paths (str) - - image paths\n            B_paths (str) - - image paths (same as A_paths)\n        \"\"\"", "\n", "path", "=", "self", ".", "AB_paths", "[", "index", "]", "\n", "im", "=", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "im", "=", "self", ".", "transform", "(", "im", ")", "\n", "im", "=", "np", ".", "array", "(", "im", ")", "\n", "lab", "=", "color", ".", "rgb2lab", "(", "im", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "lab_t", "=", "transforms", ".", "ToTensor", "(", ")", "(", "lab", ")", "\n", "A", "=", "lab_t", "[", "[", "0", "]", ",", "...", "]", "/", "50.0", "-", "1.0", "\n", "B", "=", "lab_t", "[", "[", "1", ",", "2", "]", ",", "...", "]", "/", "110.0", "\n", "return", "{", "'A'", ":", "A", ",", "'B'", ":", "B", ",", "'A_paths'", ":", "path", ",", "'B_paths'", ":", "path", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.colorization_dataset.ColorizationDataset.__len__": [[66, 69], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the total number of images in the dataset.\"\"\"", "\n", "return", "len", "(", "self", ".", "AB_paths", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.BaseDataset.__init__": [[23, 31], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the class; save the options in the class\n\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "root", "=", "opt", ".", "dataroot", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.BaseDataset.modify_commandline_options": [[32, 44], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"Add new dataset-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n        \"\"\"", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.BaseDataset.__len__": [[45, 49], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the total number of images in the dataset.\"\"\"", "\n", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.BaseDataset.__getitem__": [[50, 61], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return a data point and its metadata information.\n\n        Parameters:\n            index - - a random integer for data indexing\n\n        Returns:\n            a dictionary of data with their names. It ususally contains the data itself and its metadata information.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.get_params": [[63, 79], ["random.randint", "random.randint", "numpy.maximum", "numpy.maximum", "random.random"], "function", ["None"], ["", "", "def", "get_params", "(", "opt", ",", "size", ")", ":", "\n", "    ", "w", ",", "h", "=", "size", "\n", "new_h", "=", "h", "\n", "new_w", "=", "w", "\n", "if", "opt", ".", "preprocess", "==", "'resize_and_crop'", ":", "\n", "        ", "new_h", "=", "new_w", "=", "opt", ".", "load_size", "\n", "", "elif", "opt", ".", "preprocess", "==", "'scale_width_and_crop'", ":", "\n", "        ", "new_w", "=", "opt", ".", "load_size", "\n", "new_h", "=", "opt", ".", "load_size", "*", "h", "//", "w", "\n", "\n", "", "x", "=", "random", ".", "randint", "(", "0", ",", "np", ".", "maximum", "(", "0", ",", "new_w", "-", "opt", ".", "crop_size", ")", ")", "\n", "y", "=", "random", ".", "randint", "(", "0", ",", "np", ".", "maximum", "(", "0", ",", "new_h", "-", "opt", ".", "crop_size", ")", ")", "\n", "\n", "flip", "=", "random", ".", "random", "(", ")", ">", "0.5", "\n", "\n", "return", "{", "'crop_pos'", ":", "(", "x", ",", "y", ")", ",", "'flip'", ":", "flip", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.get_transform": [[81, 111], ["torchvision.Compose", "transform_list.append", "transform_list.append", "transform_list.append", "torchvision.Grayscale", "torchvision.Resize", "transform_list.append", "transform_list.append", "transform_list.append", "torchvision.Lambda", "transform_list.append", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Lambda", "torchvision.RandomCrop", "torchvision.Lambda", "torchvision.RandomHorizontalFlip", "transform_list.append", "base_dataset.__make_power_2", "torchvision.Lambda", "base_dataset.__scale_width", "base_dataset.__crop", "base_dataset.__flip"], "function", ["home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.__make_power_2", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.__scale_width", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.__crop", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.__flip"], ["", "def", "get_transform", "(", "opt", ",", "params", "=", "None", ",", "grayscale", "=", "False", ",", "method", "=", "Image", ".", "BICUBIC", ",", "convert", "=", "True", ")", ":", "\n", "    ", "transform_list", "=", "[", "]", "\n", "if", "grayscale", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Grayscale", "(", "1", ")", ")", "\n", "", "if", "'resize'", "in", "opt", ".", "preprocess", ":", "\n", "        ", "osize", "=", "[", "opt", ".", "load_size", ",", "opt", ".", "load_size", "]", "\n", "transform_list", ".", "append", "(", "transforms", ".", "Resize", "(", "osize", ",", "method", ")", ")", "\n", "", "elif", "'scale_width'", "in", "opt", ".", "preprocess", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__scale_width", "(", "img", ",", "opt", ".", "load_size", ",", "method", ")", ")", ")", "\n", "\n", "", "if", "'crop'", "in", "opt", ".", "preprocess", ":", "\n", "        ", "if", "params", "is", "None", ":", "\n", "            ", "transform_list", ".", "append", "(", "transforms", ".", "RandomCrop", "(", "opt", ".", "crop_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__crop", "(", "img", ",", "params", "[", "'crop_pos'", "]", ",", "opt", ".", "crop_size", ")", ")", ")", "\n", "\n", "", "", "if", "opt", ".", "preprocess", "==", "'none'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__make_power_2", "(", "img", ",", "base", "=", "4", ",", "method", "=", "method", ")", ")", ")", "\n", "\n", "", "if", "not", "opt", ".", "no_flip", ":", "\n", "        ", "if", "params", "is", "None", ":", "\n", "            ", "transform_list", ".", "append", "(", "transforms", ".", "RandomHorizontalFlip", "(", ")", ")", "\n", "", "elif", "params", "[", "'flip'", "]", ":", "\n", "            ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__flip", "(", "img", ",", "params", "[", "'flip'", "]", ")", ")", ")", "\n", "\n", "", "", "if", "convert", ":", "\n", "        ", "transform_list", "+=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "\n", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "]", "\n", "", "return", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.__make_power_2": [[113, 122], ["int", "int", "base_dataset.__print_size_warning", "img.resize", "round", "round"], "function", ["home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.__print_size_warning"], ["", "def", "__make_power_2", "(", "img", ",", "base", ",", "method", "=", "Image", ".", "BICUBIC", ")", ":", "\n", "    ", "ow", ",", "oh", "=", "img", ".", "size", "\n", "h", "=", "int", "(", "round", "(", "oh", "/", "base", ")", "*", "base", ")", "\n", "w", "=", "int", "(", "round", "(", "ow", "/", "base", ")", "*", "base", ")", "\n", "if", "(", "h", "==", "oh", ")", "and", "(", "w", "==", "ow", ")", ":", "\n", "        ", "return", "img", "\n", "\n", "", "__print_size_warning", "(", "ow", ",", "oh", ",", "w", ",", "h", ")", "\n", "return", "img", ".", "resize", "(", "(", "w", ",", "h", ")", ",", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.__scale_width": [[124, 131], ["int", "img.resize"], "function", ["None"], ["", "def", "__scale_width", "(", "img", ",", "target_width", ",", "method", "=", "Image", ".", "BICUBIC", ")", ":", "\n", "    ", "ow", ",", "oh", "=", "img", ".", "size", "\n", "if", "(", "ow", "==", "target_width", ")", ":", "\n", "        ", "return", "img", "\n", "", "w", "=", "target_width", "\n", "h", "=", "int", "(", "target_width", "*", "oh", "/", "ow", ")", "\n", "return", "img", ".", "resize", "(", "(", "w", ",", "h", ")", ",", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.__crop": [[133, 140], ["img.crop"], "function", ["None"], ["", "def", "__crop", "(", "img", ",", "pos", ",", "size", ")", ":", "\n", "    ", "ow", ",", "oh", "=", "img", ".", "size", "\n", "x1", ",", "y1", "=", "pos", "\n", "tw", "=", "th", "=", "size", "\n", "if", "(", "ow", ">", "tw", "or", "oh", ">", "th", ")", ":", "\n", "        ", "return", "img", ".", "crop", "(", "(", "x1", ",", "y1", ",", "x1", "+", "tw", ",", "y1", "+", "th", ")", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.__flip": [[142, 146], ["img.transpose"], "function", ["None"], ["", "def", "__flip", "(", "img", ",", "flip", ")", ":", "\n", "    ", "if", "flip", ":", "\n", "        ", "return", "img", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.__print_size_warning": [[148, 156], ["hasattr", "print"], "function", ["None"], ["", "def", "__print_size_warning", "(", "ow", ",", "oh", ",", "w", ",", "h", ")", ":", "\n", "    ", "\"\"\"Print warning information about image size(only print once)\"\"\"", "\n", "if", "not", "hasattr", "(", "__print_size_warning", ",", "'has_printed'", ")", ":", "\n", "        ", "print", "(", "\"The image size needs to be a multiple of 4. \"", "\n", "\"The loaded image size was (%d, %d), so it was adjusted to \"", "\n", "\"(%d, %d). This adjustment will be done to all images \"", "\n", "\"whose sizes are not multiples of 4\"", "%", "(", "ow", ",", "oh", ",", "w", ",", "h", ")", ")", "\n", "__print_size_warning", ".", "has_printed", "=", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.single_dataset.SingleDataset.__init__": [[12, 22], ["data.base_dataset.BaseDataset.__init__", "sorted", "data.base_dataset.get_transform", "data.image_folder.make_dataset"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.get_transform", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.image_folder.make_dataset"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize this dataset class.\n\n        Parameters:\n            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "BaseDataset", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "self", ".", "A_paths", "=", "sorted", "(", "make_dataset", "(", "opt", ".", "dataroot", ",", "opt", ".", "max_dataset_size", ")", ")", "\n", "input_nc", "=", "self", ".", "opt", ".", "output_nc", "if", "self", ".", "opt", ".", "direction", "==", "'BtoA'", "else", "self", ".", "opt", ".", "input_nc", "\n", "self", ".", "transform", "=", "get_transform", "(", "opt", ",", "grayscale", "=", "(", "input_nc", "==", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.single_dataset.SingleDataset.__getitem__": [[23, 37], ["PIL.Image.open().convert", "single_dataset.SingleDataset.transform", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return a data point and its metadata information.\n\n        Parameters:\n            index - - a random integer for data indexing\n\n        Returns a dictionary that contains A and A_paths\n            A(tensor) - - an image in one domain\n            A_paths(str) - - the path of the image\n        \"\"\"", "\n", "A_path", "=", "self", ".", "A_paths", "[", "index", "]", "\n", "A_img", "=", "Image", ".", "open", "(", "A_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "A", "=", "self", ".", "transform", "(", "A_img", ")", "\n", "return", "{", "'A'", ":", "A", ",", "'A_paths'", ":", "A_path", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.single_dataset.SingleDataset.__len__": [[38, 41], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the total number of images in the dataset.\"\"\"", "\n", "return", "len", "(", "self", ".", "A_paths", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.template_dataset.TemplateDataset.modify_commandline_options": [[21, 35], ["parser.add_argument", "parser.set_defaults"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"Add new dataset-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n        \"\"\"", "\n", "parser", ".", "add_argument", "(", "'--new_dataset_option'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'new dataset option'", ")", "\n", "parser", ".", "set_defaults", "(", "max_dataset_size", "=", "10", ",", "new_dataset_option", "=", "2.0", ")", "# specify dataset-specific default values", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.template_dataset.TemplateDataset.__init__": [[36, 53], ["data.base_dataset.BaseDataset.__init__", "data.base_dataset.get_transform"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.get_transform"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize this dataset class.\n\n        Parameters:\n            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n\n        A few things can be done here.\n        - save the options (have been done in BaseDataset)\n        - get image paths and meta information of the dataset.\n        - define the image transformation.\n        \"\"\"", "\n", "# save the option and dataset root", "\n", "BaseDataset", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "# get the image paths of your dataset;", "\n", "self", ".", "image_paths", "=", "[", "]", "# You can call sorted(make_dataset(self.root, opt.max_dataset_size)) to get all the image paths under the directory self.root", "\n", "# define the default transform function. You can use <base_dataset.get_transform>; You can also define your custom transform function", "\n", "self", ".", "transform", "=", "get_transform", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.template_dataset.TemplateDataset.__getitem__": [[54, 72], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return a data point and its metadata information.\n\n        Parameters:\n            index -- a random integer for data indexing\n\n        Returns:\n            a dictionary of data with their names. It usually contains the data itself and its metadata information.\n\n        Step 1: get a random image path: e.g., path = self.image_paths[index]\n        Step 2: load your data from the disk: e.g., image = Image.open(path).convert('RGB').\n        Step 3: convert your data to a PyTorch tensor. You can use helpder functions such as self.transform. e.g., data = self.transform(image)\n        Step 4: return a data point as a dictionary.\n        \"\"\"", "\n", "path", "=", "'temp'", "# needs to be a string", "\n", "data_A", "=", "None", "# needs to be a tensor", "\n", "data_B", "=", "None", "# needs to be a tensor", "\n", "return", "{", "'data_A'", ":", "data_A", ",", "'data_B'", ":", "data_B", ",", "'path'", ":", "path", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.template_dataset.TemplateDataset.__len__": [[73, 76], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the total number of images.\"\"\"", "\n", "return", "len", "(", "self", ".", "image_paths", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.image_folder.ImageFolder.__init__": [[41, 54], ["image_folder.make_dataset", "len", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.data.image_folder.make_dataset"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "transform", "=", "None", ",", "return_paths", "=", "False", ",", "\n", "loader", "=", "default_loader", ")", ":", "\n", "        ", "imgs", "=", "make_dataset", "(", "root", ")", "\n", "if", "len", "(", "imgs", ")", "==", "0", ":", "\n", "            ", "raise", "(", "RuntimeError", "(", "\"Found 0 images in: \"", "+", "root", "+", "\"\\n\"", "\n", "\"Supported image extensions are: \"", "+", "\n", "\",\"", ".", "join", "(", "IMG_EXTENSIONS", ")", ")", ")", "\n", "\n", "", "self", ".", "root", "=", "root", "\n", "self", ".", "imgs", "=", "imgs", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "return_paths", "=", "return_paths", "\n", "self", ".", "loader", "=", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.image_folder.ImageFolder.__getitem__": [[55, 64], ["image_folder.ImageFolder.loader", "image_folder.ImageFolder.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "imgs", "[", "index", "]", "\n", "img", "=", "self", ".", "loader", "(", "path", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "if", "self", ".", "return_paths", ":", "\n", "            ", "return", "img", ",", "path", "\n", "", "else", ":", "\n", "            ", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.image_folder.ImageFolder.__len__": [[65, 67], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "imgs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.image_folder.is_image_file": [[19, 21], ["any", "filename.endswith"], "function", ["None"], ["def", "is_image_file", "(", "filename", ")", ":", "\n", "    ", "return", "any", "(", "filename", ".", "endswith", "(", "extension", ")", "for", "extension", "in", "IMG_EXTENSIONS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.image_folder.make_dataset": [[23, 33], ["float", "os.path.isdir", "os.path.isdir", "sorted", "os.walk", "os.walk", "image_folder.is_image_file", "min", "os.path.join", "os.path.join", "images.append", "len"], "function", ["home.repos.pwc.inspect_result.nadeemlab_CEP.data.image_folder.is_image_file"], ["", "def", "make_dataset", "(", "dir", ",", "max_dataset_size", "=", "float", "(", "\"inf\"", ")", ")", ":", "\n", "    ", "images", "=", "[", "]", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "dir", ")", ",", "'%s is not a valid directory'", "%", "dir", "\n", "\n", "for", "root", ",", "_", ",", "fnames", "in", "sorted", "(", "os", ".", "walk", "(", "dir", ")", ")", ":", "\n", "        ", "for", "fname", "in", "fnames", ":", "\n", "            ", "if", "is_image_file", "(", "fname", ")", ":", "\n", "                ", "path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "fname", ")", "\n", "images", ".", "append", "(", "path", ")", "\n", "", "", "", "return", "images", "[", ":", "min", "(", "max_dataset_size", ",", "len", "(", "images", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.image_folder.default_loader": [[35, 37], ["PIL.Image.open().convert", "PIL.Image.open"], "function", ["None"], ["", "def", "default_loader", "(", "path", ")", ":", "\n", "    ", "return", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.__init__.CustomDatasetDataLoader.__init__": [[65, 80], ["__init__.find_dataset_using_name", "find_dataset_using_name.", "print", "torch.utils.data.DataLoader", "int", "type"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.data.__init__.find_dataset_using_name"], []], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.__init__.CustomDatasetDataLoader.load_data": [[81, 83], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.__init__.CustomDatasetDataLoader.__len__": [[84, 87], ["min", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.__init__.CustomDatasetDataLoader.__iter__": [[88, 94], ["enumerate"], "methods", ["None"], []], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.__init__.find_dataset_using_name": [[18, 39], ["importlib.import_module", "importlib.import_module.__dict__.items", "dataset_name.replace", "NotImplementedError", "issubclass", "name.lower", "target_dataset_name.lower"], "function", ["None"], []], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.__init__.get_option_setter": [[41, 45], ["__init__.find_dataset_using_name"], "function", ["home.repos.pwc.inspect_result.nadeemlab_CEP.data.__init__.find_dataset_using_name"], []], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.__init__.create_dataset": [[47, 60], ["__init__.CustomDatasetDataLoader", "__init__.CustomDatasetDataLoader.load_data"], "function", ["home.repos.pwc.inspect_result.nadeemlab_CEP.data.__init__.CustomDatasetDataLoader.load_data"], []], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.unaligned_dataset.UnalignedDataset.__init__": [[21, 46], ["data.base_dataset.BaseDataset.__init__", "os.path.join", "os.path.join", "sorted", "sorted", "len", "len", "data.base_dataset.get_transform", "data.image_folder.make_dataset", "data.image_folder.make_dataset", "os.path.join", "sorted", "len", "data.image_folder.make_dataset"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.get_transform", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.image_folder.make_dataset", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.image_folder.make_dataset", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.image_folder.make_dataset"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize this dataset class.\n\n        Parameters:\n            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "BaseDataset", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "self", ".", "dir_A", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "dataroot", ",", "opt", ".", "phase", "+", "'A'", ")", "# create a path '/path/to/data/trainA'", "\n", "self", ".", "dir_B", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "dataroot", ",", "opt", ".", "phase", "+", "'B'", ")", "# create a path '/path/to/data/trainB'", "\n", "\n", "self", ".", "A_paths", "=", "sorted", "(", "make_dataset", "(", "self", ".", "dir_A", ",", "opt", ".", "max_dataset_size", ")", ")", "# load images from '/path/to/data/trainA'", "\n", "self", ".", "B_paths", "=", "sorted", "(", "make_dataset", "(", "self", ".", "dir_B", ",", "opt", ".", "max_dataset_size", ")", ")", "# load images from '/path/to/data/trainB'", "\n", "self", ".", "A_size", "=", "len", "(", "self", ".", "A_paths", ")", "# get the size of dataset A", "\n", "self", ".", "B_size", "=", "len", "(", "self", ".", "B_paths", ")", "# get the size of dataset B", "\n", "btoA", "=", "self", ".", "opt", ".", "direction", "==", "'BtoA'", "\n", "input_nc", "=", "self", ".", "opt", ".", "output_nc", "if", "btoA", "else", "self", ".", "opt", ".", "input_nc", "# get the number of channels of input image", "\n", "output_nc", "=", "self", ".", "opt", ".", "input_nc", "if", "btoA", "else", "self", ".", "opt", ".", "output_nc", "# get the number of channels of output image", "\n", "self", ".", "transform_A", "=", "get_transform", "(", "self", ".", "opt", ",", "grayscale", "=", "(", "input_nc", "==", "1", ")", ")", "\n", "\n", "self", ".", "C_size", "=", "0", "\n", "if", "self", ".", "opt", ".", "model", "==", "'foldit'", ":", "\n", "#add dataset C", "\n", "            ", "self", ".", "dir_C", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "dataroot", ",", "opt", ".", "phase", "+", "'C'", ")", "# create a path '/path/to/data/trainC'", "\n", "self", ".", "C_paths", "=", "sorted", "(", "make_dataset", "(", "self", ".", "dir_C", ",", "opt", ".", "max_dataset_size", ")", ")", "# load images from '/path/to/data/trainC'", "\n", "self", ".", "C_size", "=", "len", "(", "self", ".", "C_paths", ")", "# get the size of dataset C", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.unaligned_dataset.UnalignedDataset.__getitem__": [[49, 94], ["PIL.Image.open().convert", "PIL.Image.open().convert", "data.base_dataset.get_params", "unaligned_dataset.UnalignedDataset.transform_A", "data.base_dataset.get_params", "data.base_dataset.get_transform", "data.base_dataset.get_transform.", "random.randint", "PIL.Image.open().convert", "data.base_dataset.get_transform", "data.base_dataset.get_transform.", "data.base_dataset.get_transform.", "PIL.Image.open", "PIL.Image.open", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.get_params", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.get_params", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.get_transform", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.base_dataset.get_transform"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return a data point and its metadata information.\n\n        Parameters:\n            index (int)      -- a random integer for data indexing\n\n        Returns a dictionary that contains A, B, A_paths and B_paths\n            A (tensor)       -- an image in the input domain\n            B (tensor)       -- its corresponding image in the target domain\n            A_paths (str)    -- image paths\n            B_paths (str)    -- image paths\n        \"\"\"", "\n", "A_path", "=", "self", ".", "A_paths", "[", "index", "%", "self", ".", "A_size", "]", "# make sure index is within then range", "\n", "if", "self", ".", "opt", ".", "serial_batches", ":", "# make sure index is within then range", "\n", "            ", "index_B", "=", "index", "%", "self", ".", "B_size", "\n", "", "else", ":", "# randomize the index for domain B to avoid fixed pairs.", "\n", "            ", "index_B", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "B_size", "-", "1", ")", "\n", "\n", "", "B_path", "=", "self", ".", "B_paths", "[", "index_B", "]", "\n", "A_img", "=", "Image", ".", "open", "(", "A_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "B_img", "=", "Image", ".", "open", "(", "B_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n", "transform_params", "=", "get_params", "(", "self", ".", "opt", ",", "A_img", ".", "size", ")", "\n", "# apply image transformation", "\n", "A", "=", "self", ".", "transform_A", "(", "A_img", ")", "\n", "\n", "transform_params", "=", "get_params", "(", "self", ".", "opt", ",", "B_img", ".", "size", ")", "\n", "transform_B", "=", "get_transform", "(", "self", ".", "opt", ",", "transform_params", ",", "grayscale", "=", "False", ")", "\n", "B", "=", "transform_B", "(", "B_img", ")", "\n", "\n", "if", "self", ".", "opt", ".", "model", "==", "'foldit'", ":", "\n", "            ", "C_path", "=", "self", ".", "C_paths", "[", "index_B", "]", "\n", "C_img", "=", "Image", ".", "open", "(", "C_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n", "#apply the same transforms for img B anc C", "\n", "transform_C", "=", "get_transform", "(", "self", ".", "opt", ",", "transform_params", ",", "grayscale", "=", "False", ")", "\n", "\n", "B", "=", "transform_B", "(", "B_img", ")", "\n", "C", "=", "transform_C", "(", "C_img", ")", "\n", "\n", "\n", "return", "{", "'A'", ":", "A", ",", "'B'", ":", "B", ",", "'C'", ":", "C", ",", "'A_paths'", ":", "A_path", ",", "'B_paths'", ":", "B_path", ",", "'C_paths'", ":", "C_path", "}", "\n", "", "else", ":", "\n", "# B = self.transform_B(B_img)", "\n", "            ", "return", "{", "'A'", ":", "A", ",", "'B'", ":", "B", ",", "'A_paths'", ":", "A_path", ",", "'B_paths'", ":", "B_path", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.data.unaligned_dataset.UnalignedDataset.__len__": [[98, 105], ["max"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the total number of images in the dataset.\n\n        As we have two datasets with potentially different number of images,\n        we take a maximum of\n        \"\"\"", "\n", "return", "max", "(", "self", ".", "A_size", ",", "self", ".", "B_size", ",", "self", ".", "C_size", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.options.test_options.TestOptions.initialize": [[10, 25], ["base_options.BaseOptions.initialize", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.set_defaults", "base_options.BaseOptions.initialize.set_defaults", "float", "base_options.BaseOptions.initialize.get_default"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.initialize"], ["def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "parser", "=", "BaseOptions", ".", "initialize", "(", "self", ",", "parser", ")", "# define shared options", "\n", "parser", ".", "add_argument", "(", "'--ntest'", ",", "type", "=", "int", ",", "default", "=", "float", "(", "\"inf\"", ")", ",", "help", "=", "'# of test examples.'", ")", "\n", "parser", ".", "add_argument", "(", "'--results_dir'", ",", "type", "=", "str", ",", "default", "=", "'./results/'", ",", "help", "=", "'saves results here.'", ")", "\n", "parser", ".", "add_argument", "(", "'--aspect_ratio'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'aspect ratio of result images'", ")", "\n", "parser", ".", "add_argument", "(", "'--phase'", ",", "type", "=", "str", ",", "default", "=", "'test'", ",", "help", "=", "'train, val, test, etc'", ")", "\n", "# Dropout and Batchnorm has different behavioir during training and test.", "\n", "parser", ".", "add_argument", "(", "'--eval'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use eval mode during test time.'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_test'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'how many test images to run'", ")", "\n", "# rewrite devalue values", "\n", "parser", ".", "set_defaults", "(", "model", "=", "'test'", ")", "\n", "# To avoid cropping, the load_size should be the same as crop_size", "\n", "parser", ".", "set_defaults", "(", "load_size", "=", "parser", ".", "get_default", "(", "'crop_size'", ")", ")", "\n", "self", ".", "isTrain", "=", "False", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.options.train_options.TrainOptions.initialize": [[10, 41], ["base_options.BaseOptions.initialize", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.initialize"], ["def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "parser", "=", "BaseOptions", ".", "initialize", "(", "self", ",", "parser", ")", "\n", "# visdom and HTML visualization parameters", "\n", "parser", ".", "add_argument", "(", "'--display_freq'", ",", "type", "=", "int", ",", "default", "=", "400", ",", "help", "=", "'frequency of showing training results on screen'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_ncols'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'if positive, display all images in a single visdom web panel with certain number of images per row.'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_id'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'window id of the web display'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_server'", ",", "type", "=", "str", ",", "default", "=", "\"http://localhost\"", ",", "help", "=", "'visdom server of the web display'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_env'", ",", "type", "=", "str", ",", "default", "=", "'main'", ",", "help", "=", "'visdom display environment name (default is \"main\")'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_port'", ",", "type", "=", "int", ",", "default", "=", "8097", ",", "help", "=", "'visdom port of the web display'", ")", "\n", "parser", ".", "add_argument", "(", "'--update_html_freq'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'frequency of saving training results to html'", ")", "\n", "parser", ".", "add_argument", "(", "'--print_freq'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'frequency of showing training results on console'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_html'", ",", "action", "=", "'store_true'", ",", "help", "=", "'do not save intermediate training results to [opt.checkpoints_dir]/[opt.name]/web/'", ")", "\n", "# network saving and loading parameters", "\n", "parser", ".", "add_argument", "(", "'--save_latest_freq'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "help", "=", "'frequency of saving the latest results'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_epoch_freq'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'frequency of saving checkpoints at the end of epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_by_iter'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether saves model by iteration'", ")", "\n", "parser", ".", "add_argument", "(", "'--continue_train'", ",", "action", "=", "'store_true'", ",", "help", "=", "'continue training: load the latest model'", ")", "\n", "parser", ".", "add_argument", "(", "'--epoch_count'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'the starting epoch count, we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>, ...'", ")", "\n", "parser", ".", "add_argument", "(", "'--phase'", ",", "type", "=", "str", ",", "default", "=", "'train'", ",", "help", "=", "'train, val, test, etc'", ")", "\n", "# training parameters", "\n", "parser", ".", "add_argument", "(", "'--niter'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'# of iter at starting learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--niter_decay'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'# of iter to linearly decay learning rate to zero'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta1'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'momentum term of adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.0002", ",", "help", "=", "'initial learning rate for adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--gan_mode'", ",", "type", "=", "str", ",", "default", "=", "'lsgan'", ",", "help", "=", "'the type of GAN objective. [vanilla| lsgan | wgangp]. vanilla GAN loss is the cross-entropy objective used in the original GAN paper.'", ")", "\n", "parser", ".", "add_argument", "(", "'--pool_size'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'the size of image buffer that stores previously generated images'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_policy'", ",", "type", "=", "str", ",", "default", "=", "'linear'", ",", "help", "=", "'learning rate policy. [linear | step | plateau | cosine]'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_decay_iters'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'multiply by a gamma every lr_decay_iters iterations'", ")", "\n", "\n", "self", ".", "isTrain", "=", "True", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.__init__": [[16, 19], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset the class; indicates the class hasn't been initailized\"\"\"", "\n", "self", ".", "initialized", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.initialize": [[20, 59], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "float"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "\"\"\"Define the common options that are used in both training and test.\"\"\"", "\n", "# basic parameters", "\n", "parser", ".", "add_argument", "(", "'--dataroot'", ",", "required", "=", "True", ",", "help", "=", "'path to images (should have subfolders trainA, trainB, valA, valB, etc)'", ")", "\n", "parser", ".", "add_argument", "(", "'--name'", ",", "type", "=", "str", ",", "default", "=", "'experiment_name'", ",", "help", "=", "'name of the experiment. It decides where to store samples and models'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_ids'", ",", "type", "=", "str", ",", "default", "=", "'0'", ",", "help", "=", "'gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoints_dir'", ",", "type", "=", "str", ",", "default", "=", "'./checkpoints'", ",", "help", "=", "'models are saved here'", ")", "\n", "# model parameters", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "'foldit'", ",", "help", "=", "'chooses which model to use. [foldit]'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_nc'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'# of input image channels: 3 for RGB and 1 for grayscale'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_nc'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'# of output image channels: 3 for RGB and 1 for grayscale'", ")", "\n", "parser", ".", "add_argument", "(", "'--ngf'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'# of gen filters in the last conv layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--ndf'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'# of discrim filters in the first conv layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--netD'", ",", "type", "=", "str", ",", "default", "=", "'basic'", ",", "help", "=", "'specify discriminator architecture [basic | n_layers | pixel]. The basic model is a 70x70 PatchGAN. n_layers allows you to specify the layers in the discriminator'", ")", "\n", "parser", ".", "add_argument", "(", "'--netG'", ",", "type", "=", "str", ",", "default", "=", "'resnet_9blocks'", ",", "help", "=", "'specify generator architecture [resnet_9blocks | resnet_6blocks | unet_256 | unet_128]'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_layers_D'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'only used if netD==n_layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--norm'", ",", "type", "=", "str", ",", "default", "=", "'instance'", ",", "help", "=", "'instance normalization or batch normalization [instance | batch | none]'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_type'", ",", "type", "=", "str", ",", "default", "=", "'normal'", ",", "help", "=", "'network initialization [normal | xavier | kaiming | orthogonal]'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_gain'", ",", "type", "=", "float", ",", "default", "=", "0.02", ",", "help", "=", "'scaling factor for normal, xavier and orthogonal.'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_dropout'", ",", "action", "=", "'store_true'", ",", "help", "=", "'no dropout for the generator'", ")", "\n", "# dataset parameters", "\n", "parser", ".", "add_argument", "(", "'--dataset_mode'", ",", "type", "=", "str", ",", "default", "=", "'unaligned'", ",", "help", "=", "'chooses how datasets are loaded. [unaligned | aligned | single | colorization]'", ")", "\n", "parser", ".", "add_argument", "(", "'--direction'", ",", "type", "=", "str", ",", "default", "=", "'AtoB'", ",", "help", "=", "'AtoB or BtoA'", ")", "\n", "parser", ".", "add_argument", "(", "'--serial_batches'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if true, takes images in order to make batches, otherwise takes them randomly'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_threads'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "'# threads for loading data'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'input batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_size'", ",", "type", "=", "int", ",", "default", "=", "286", ",", "help", "=", "'scale images to this size'", ")", "\n", "parser", ".", "add_argument", "(", "'--crop_size'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'then crop to this size'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_dataset_size'", ",", "type", "=", "int", ",", "default", "=", "float", "(", "\"inf\"", ")", ",", "help", "=", "'Maximum number of samples allowed per dataset. If the dataset directory contains more than max_dataset_size, only a subset is loaded.'", ")", "\n", "parser", ".", "add_argument", "(", "'--preprocess'", ",", "type", "=", "str", ",", "default", "=", "'resize_and_crop'", ",", "help", "=", "'scaling and cropping of images at load time [resize_and_crop | crop | scale_width | scale_width_and_crop | none]'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_flip'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, do not flip the images for data augmentation'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_winsize'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'display window size for both visdom and HTML'", ")", "\n", "# additional parameters", "\n", "parser", ".", "add_argument", "(", "'--epoch'", ",", "type", "=", "str", ",", "default", "=", "'latest'", ",", "help", "=", "'which epoch to load? set to latest to use latest cached model'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_iter'", ",", "type", "=", "int", ",", "default", "=", "'0'", ",", "help", "=", "'which iteration to load? if load_iter > 0, the code will load models by iter_[load_iter]; otherwise, the code will load models by [epoch]'", ")", "\n", "parser", ".", "add_argument", "(", "'--verbose'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, print more debugging information'", ")", "\n", "parser", ".", "add_argument", "(", "'--suffix'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "help", "=", "'customized suffix: opt.name = opt.name + suffix: e.g., {model}_{netG}_size{load_size}'", ")", "\n", "self", ".", "initialized", "=", "True", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.gather_options": [[60, 87], ["base_options.BaseOptions.parse_known_args", "models.get_option_setter", "models.get_option_setter.", "base_options.BaseOptions.parse_known_args", "data.get_option_setter", "data.get_option_setter.", "base_options.BaseOptions.parse_args", "argparse.ArgumentParser", "base_options.BaseOptions.initialize"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.data.__init__.get_option_setter", "home.repos.pwc.inspect_result.nadeemlab_CEP.data.__init__.get_option_setter", "home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.initialize"], ["", "def", "gather_options", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize our parser with basic options(only once).\n        Add additional model-specific and dataset-specific options.\n        These options are defined in the <modify_commandline_options> function\n        in model and dataset classes.\n        \"\"\"", "\n", "if", "not", "self", ".", "initialized", ":", "# check if it has been initialized", "\n", "            ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", "=", "self", ".", "initialize", "(", "parser", ")", "\n", "\n", "# get the basic options", "\n", "", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "\n", "# modify model-related parser options", "\n", "model_name", "=", "opt", ".", "model", "\n", "model_option_setter", "=", "models", ".", "get_option_setter", "(", "model_name", ")", "\n", "parser", "=", "model_option_setter", "(", "parser", ",", "self", ".", "isTrain", ")", "\n", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "# parse again with new defaults", "\n", "\n", "# modify dataset-related parser options", "\n", "dataset_name", "=", "opt", ".", "dataset_mode", "\n", "dataset_option_setter", "=", "data", ".", "get_option_setter", "(", "dataset_name", ")", "\n", "parser", "=", "dataset_option_setter", "(", "parser", ",", "self", ".", "isTrain", ")", "\n", "\n", "# save and return the parser", "\n", "self", ".", "parser", "=", "parser", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.print_options": [[88, 112], ["sorted", "print", "os.path.join", "util.util.util.mkdirs", "os.path.join", "vars().items", "base_options.BaseOptions.parser.get_default", "open", "opt_file.write", "opt_file.write", "str", "str", "vars", "str"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.util.util.mkdirs"], ["", "def", "print_options", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Print and save options\n\n        It will print both current options and default values(if different).\n        It will save options into a text file / [checkpoints_dir] / opt.txt\n        \"\"\"", "\n", "message", "=", "''", "\n", "message", "+=", "'----------------- Options ---------------\\n'", "\n", "for", "k", ",", "v", "in", "sorted", "(", "vars", "(", "opt", ")", ".", "items", "(", ")", ")", ":", "\n", "            ", "comment", "=", "''", "\n", "default", "=", "self", ".", "parser", ".", "get_default", "(", "k", ")", "\n", "if", "v", "!=", "default", ":", "\n", "                ", "comment", "=", "'\\t[default: %s]'", "%", "str", "(", "default", ")", "\n", "", "message", "+=", "'{:>25}: {:<30}{}\\n'", ".", "format", "(", "str", "(", "k", ")", ",", "str", "(", "v", ")", ",", "comment", ")", "\n", "", "message", "+=", "'----------------- End -------------------'", "\n", "print", "(", "message", ")", "\n", "\n", "# save to the disk", "\n", "expr_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "\n", "util", ".", "mkdirs", "(", "expr_dir", ")", "\n", "file_name", "=", "os", ".", "path", ".", "join", "(", "expr_dir", ",", "'opt.txt'", ")", "\n", "with", "open", "(", "file_name", ",", "'wt'", ")", "as", "opt_file", ":", "\n", "            ", "opt_file", ".", "write", "(", "message", ")", "\n", "opt_file", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.parse": [[113, 137], ["base_options.BaseOptions.gather_options", "base_options.BaseOptions.print_options", "base_options.BaseOptions.gpu_ids.split", "int", "len", "torch.cuda.set_device", "base_options.BaseOptions.gpu_ids.append", "base_options.BaseOptions.suffix.format", "vars"], "methods", ["home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.gather_options", "home.repos.pwc.inspect_result.nadeemlab_CEP.options.base_options.BaseOptions.print_options"], ["", "", "def", "parse", "(", "self", ")", ":", "\n", "        ", "\"\"\"Parse our options, create checkpoints directory suffix, and set up gpu device.\"\"\"", "\n", "opt", "=", "self", ".", "gather_options", "(", ")", "\n", "opt", ".", "isTrain", "=", "self", ".", "isTrain", "# train or test", "\n", "\n", "# process opt.suffix", "\n", "if", "opt", ".", "suffix", ":", "\n", "            ", "suffix", "=", "(", "'_'", "+", "opt", ".", "suffix", ".", "format", "(", "**", "vars", "(", "opt", ")", ")", ")", "if", "opt", ".", "suffix", "!=", "''", "else", "''", "\n", "opt", ".", "name", "=", "opt", ".", "name", "+", "suffix", "\n", "\n", "", "self", ".", "print_options", "(", "opt", ")", "\n", "\n", "# set gpu ids", "\n", "str_ids", "=", "opt", ".", "gpu_ids", ".", "split", "(", "','", ")", "\n", "opt", ".", "gpu_ids", "=", "[", "]", "\n", "for", "str_id", "in", "str_ids", ":", "\n", "            ", "id", "=", "int", "(", "str_id", ")", "\n", "if", "id", ">=", "0", ":", "\n", "                ", "opt", ".", "gpu_ids", ".", "append", "(", "id", ")", "\n", "", "", "if", "len", "(", "opt", ".", "gpu_ids", ")", ">", "0", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu_ids", "[", "0", "]", ")", "\n", "\n", "", "self", ".", "opt", "=", "opt", "\n", "return", "self", ".", "opt", "\n", "", "", ""]]}