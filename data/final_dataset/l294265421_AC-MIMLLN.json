{"home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.create_graph.create_dependency_graph": [[25, 37], ["stanford_nlp.dependency_parse", "len", "numpy.zeros", "range"], "function", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.dependency_parse"], ["def", "create_dependency_graph", "(", "sentence", ":", "str", ",", "stanford_nlp", ")", ":", "\n", "    ", "arcs", ",", "words", "=", "stanford_nlp", ".", "dependency_parse", "(", "sentence", ",", "True", ")", "\n", "word_num", "=", "len", "(", "words", ")", "\n", "word_relation_graph", "=", "np", ".", "zeros", "(", "(", "word_num", ",", "word_num", ")", ")", "\n", "for", "i", "in", "range", "(", "word_num", ")", ":", "\n", "        ", "word_relation_graph", "[", "i", "]", "[", "i", "]", "=", "1", "\n", "", "for", "word_relation", "in", "arcs", "[", "1", ":", "]", ":", "\n", "        ", "head", "=", "word_relation", "[", "2", "]", "-", "1", "\n", "dependency", "=", "word_relation", "[", "1", "]", "-", "1", "\n", "word_relation_graph", "[", "head", "]", "[", "dependency", "]", "=", "1", "\n", "word_relation_graph", "[", "dependency", "]", "[", "head", "]", "=", "1", "\n", "", "return", "word_relation_graph", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.create_graph.get_coref_edges": [[39, 65], ["stanford_nlp.coref", "range", "len", "sentence_start_indices.append", "len", "range", "all_words.append", "len", "range", "len", "range", "range", "edges.append", "edges.append"], "function", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.coref"], ["", "def", "get_coref_edges", "(", "text", ":", "str", ",", "stanford_nlp", ")", ":", "\n", "    ", "all_words", "=", "[", "]", "\n", "edges", "=", "[", "]", "\n", "if", "stanford_nlp", "is", "None", ":", "\n", "        ", "return", "edges", ",", "all_words", "\n", "", "coref_relations", ",", "sentence_words", "=", "stanford_nlp", ".", "coref", "(", "text", ",", "return_words", "=", "True", ")", "\n", "sentence_start_indices", "=", "[", "]", "\n", "word_num", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "sentence_words", ")", ")", ":", "\n", "        ", "sentence_word", "=", "sentence_words", "[", "i", "]", "\n", "sentence_start_indices", ".", "append", "(", "word_num", ")", "\n", "word_num", "+=", "len", "(", "sentence_word", ")", "\n", "for", "word", "in", "sentence_word", ":", "\n", "            ", "all_words", ".", "append", "(", "word", "[", "'word'", "]", ")", "\n", "", "", "for", "coref_relation", "in", "coref_relations", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "coref_relation", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "coref_relation", ")", ")", ":", "\n", "                ", "first_word", "=", "coref_relation", "[", "i", "]", "\n", "second_word", "=", "coref_relation", "[", "j", "]", "\n", "for", "k", "in", "range", "(", "first_word", "[", "1", "]", ",", "first_word", "[", "2", "]", ")", ":", "\n", "                    ", "first_index", "=", "sentence_start_indices", "[", "first_word", "[", "0", "]", "-", "1", "]", "+", "k", "-", "1", "\n", "for", "l", "in", "range", "(", "second_word", "[", "1", "]", ",", "second_word", "[", "2", "]", ")", ":", "\n", "                        ", "second_index", "=", "sentence_start_indices", "[", "second_word", "[", "0", "]", "-", "1", "]", "+", "l", "-", "1", "\n", "edges", ".", "append", "(", "[", "first_index", ",", "second_index", ",", "'coref'", "]", ")", "\n", "edges", ".", "append", "(", "[", "second_index", ",", "first_index", ",", "'coref'", "]", ")", "\n", "", "", "", "", "", "return", "edges", ",", "all_words", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.create_graph.create_dependency_graph_by_spacy": [[67, 82], ["spacy_nlp", "len", "numpy.zeros().astype", "numpy.zeros"], "function", ["None"], ["", "def", "create_dependency_graph_by_spacy", "(", "sentence", ":", "str", ",", "spacy_nlp", ")", ":", "\n", "# https://spacy.io/docs/usage/processing-text", "\n", "    ", "document", "=", "spacy_nlp", "(", "sentence", ")", "\n", "seq_len", "=", "len", "(", "[", "token", "for", "token", "in", "document", "]", ")", "\n", "matrix", "=", "np", ".", "zeros", "(", "(", "seq_len", ",", "seq_len", ")", ")", ".", "astype", "(", "'float32'", ")", "\n", "\n", "for", "token", "in", "document", ":", "\n", "        ", "if", "token", ".", "i", "<", "seq_len", ":", "\n", "            ", "matrix", "[", "token", ".", "i", "]", "[", "token", ".", "i", "]", "=", "1", "\n", "# https://spacy.io/docs/api/token", "\n", "for", "child", "in", "token", ".", "children", ":", "\n", "                ", "if", "child", ".", "i", "<", "seq_len", ":", "\n", "                    ", "matrix", "[", "token", ".", "i", "]", "[", "child", ".", "i", "]", "=", "1", "\n", "matrix", "[", "child", ".", "i", "]", "[", "token", ".", "i", "]", "=", "1", "\n", "", "", "", "", "return", "matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.create_graph.create_dependency_graph_for_dgl": [[84, 112], ["spacy_nlp", "len", "dgl.DGLGraph", "dgl.DGLGraph.add_nodes", "create_graph.get_coref_edges", "list", "dgl.DGLGraph.add_edges", "dgl.DGLGraph.edata.update", "edge_list.extend", "zip", "spacy_dependencies.index", "edge_list.append", "len", "len", "torch.tensor", "edge_list.append", "edge_list.append", "edge_list.append"], "function", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.create_graph.get_coref_edges"], ["", "def", "create_dependency_graph_for_dgl", "(", "sentence", ":", "str", ",", "spacy_nlp", ",", "stanford_nlp", "=", "None", ")", ":", "\n", "# https://spacy.io/docs/usage/processing-text", "\n", "    ", "document", "=", "spacy_nlp", "(", "sentence", ")", "\n", "seq_len", "=", "len", "(", "[", "token", "for", "token", "in", "document", "]", ")", "\n", "g", "=", "dgl", ".", "DGLGraph", "(", ")", "\n", "g", ".", "add_nodes", "(", "seq_len", ")", "\n", "edge_list", "=", "[", "]", "\n", "for", "token", "in", "document", ":", "\n", "        ", "if", "token", ".", "i", "<", "seq_len", ":", "\n", "            ", "edge_list", ".", "append", "(", "(", "token", ".", "i", ",", "token", ".", "i", ",", "'self_loop'", ")", ")", "\n", "if", "token", ".", "i", "+", "1", "<", "seq_len", ":", "\n", "                ", "edge_list", ".", "append", "(", "(", "token", ".", "i", ",", "token", ".", "i", "+", "1", ",", "'next'", ")", ")", "\n", "# https://spacy.io/docs/api/token", "\n", "", "for", "child", "in", "token", ".", "children", ":", "\n", "                ", "if", "child", ".", "i", "<", "seq_len", ":", "\n", "                    ", "if", "not", "child", ".", "dep_", ":", "\n", "                        ", "continue", "\n", "", "edge_list", ".", "append", "(", "(", "token", ".", "i", ",", "child", ".", "i", ",", "child", ".", "dep_", ")", ")", "\n", "edge_list", ".", "append", "(", "(", "child", ".", "i", ",", "token", ".", "i", ",", "child", ".", "dep_", ")", ")", "\n", "\n", "", "", "", "", "coref_edges", ",", "coref_words", "=", "get_coref_edges", "(", "sentence", ",", "stanford_nlp", ")", "\n", "if", "len", "(", "coref_words", ")", "==", "seq_len", "and", "len", "(", "coref_edges", ")", "!=", "0", ":", "\n", "        ", "edge_list", ".", "extend", "(", "coref_edges", ")", "\n", "", "src", ",", "dst", ",", "rtype", "=", "list", "(", "zip", "(", "*", "edge_list", ")", ")", "\n", "rtype_index", "=", "[", "spacy_dependencies", ".", "index", "(", "r", ")", "for", "r", "in", "rtype", "]", "\n", "g", ".", "add_edges", "(", "src", ",", "dst", ")", "\n", "g", ".", "edata", ".", "update", "(", "{", "'rel_type'", ":", "torch", ".", "tensor", "(", "rtype_index", ")", "}", ")", "\n", "return", "g", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.create_graph.create_aspect_term_dependency_graph": [[114, 140], ["dgl.DGLGraph", "dgl.DGLGraph.add_nodes", "range", "range", "list", "dgl.DGLGraph.add_edges", "dgl.DGLGraph.edata.update", "len", "len", "edge_list.append", "len", "zip", "all_dependencies.index", "range", "torch.tensor", "len", "range", "edge_list.append", "edge_list.append"], "function", ["None"], ["", "def", "create_aspect_term_dependency_graph", "(", "aspect_term_indices", ",", "polarity_indices", ",", "words", ")", ":", "\n", "    ", "connective_and_relation_pair", "=", "{", "\n", "'other than'", ":", "''", ",", "# Food other than sushi is also very nice.", "\n", "\n", "}", "\n", "all_dependencies", "=", "[", "'self-loop'", ",", "'inter'", "]", "\n", "g", "=", "dgl", ".", "DGLGraph", "(", ")", "\n", "g", ".", "add_nodes", "(", "len", "(", "words", ")", ")", "\n", "edge_list", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "len", "(", "words", ")", ")", ":", "\n", "        ", "edge_list", ".", "append", "(", "(", "k", ",", "k", ",", "'self-loop'", ")", ")", "\n", "", "for", "k", "in", "range", "(", "len", "(", "aspect_term_indices", ")", ")", ":", "\n", "        ", "polarity_index", "=", "polarity_indices", "[", "k", "]", "\n", "aspect_term_index", "=", "aspect_term_indices", "[", "k", "]", "\n", "if", "polarity_index", "==", "-", "100", ":", "\n", "            ", "continue", "\n", "", "if", "k", "+", "1", "<", "len", "(", "aspect_term_indices", ")", "and", "polarity_indices", "[", "k", "+", "1", "]", "!=", "-", "100", ":", "\n", "            ", "for", "i", "in", "range", "(", "aspect_term_index", "[", "0", "]", ",", "aspect_term_index", "[", "1", "]", "+", "1", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "aspect_term_indices", "[", "k", "+", "1", "]", "[", "0", "]", ",", "aspect_term_indices", "[", "k", "+", "1", "]", "[", "1", "]", "+", "1", ")", ":", "\n", "                    ", "edge_list", ".", "append", "(", "(", "i", ",", "j", ",", "'inter'", ")", ")", "\n", "edge_list", ".", "append", "(", "(", "j", ",", "i", ",", "'inter'", ")", ")", "\n", "", "", "", "", "src", ",", "dst", ",", "rtype", "=", "list", "(", "zip", "(", "*", "edge_list", ")", ")", "\n", "rtype_index", "=", "[", "all_dependencies", ".", "index", "(", "r", ")", "for", "r", "in", "rtype", "]", "\n", "g", ".", "add_edges", "(", "src", ",", "dst", ")", "\n", "g", ".", "edata", ".", "update", "(", "{", "'rel_type'", ":", "torch", ".", "tensor", "(", "rtype_index", ")", "}", ")", "\n", "return", "g", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.create_graph.plot_dgl_graph": [[146, 152], ["graph.to_networkx", "networkx.kamada_kawai_layout", "networkx.draw", "matplotlib.show"], "function", ["None"], ["", "def", "plot_dgl_graph", "(", "graph", ")", ":", "\n", "    ", "nx_G", "=", "graph", ".", "to_networkx", "(", ")", "\n", "# Kamada-Kawaii layout usually looks pretty for arbitrary graphs", "\n", "pos", "=", "nx", ".", "kamada_kawai_layout", "(", "nx_G", ")", "\n", "nx", ".", "draw", "(", "nx_G", ",", "pos", ",", "with_labels", "=", "True", ",", "node_color", "=", "[", "[", ".7", ",", ".7", ",", ".7", "]", "]", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.create_graph.create_coref_graph": [[154, 179], ["stanford_nlp.coref", "range", "numpy.zeros", "len", "sentence_start_indices.append", "len", "range", "all_words.append", "len", "range", "len", "range", "range", "print"], "function", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.coref"], ["", "def", "create_coref_graph", "(", "text", ":", "str", ",", "stanford_nlp", ")", ":", "\n", "    ", "coref_relations", ",", "sentence_words", "=", "stanford_nlp", ".", "coref", "(", "text", ",", "return_words", "=", "True", ")", "\n", "all_words", "=", "[", "]", "\n", "sentence_start_indices", "=", "[", "]", "\n", "word_num", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "sentence_words", ")", ")", ":", "\n", "        ", "sentence_word", "=", "sentence_words", "[", "i", "]", "\n", "sentence_start_indices", ".", "append", "(", "word_num", ")", "\n", "word_num", "+=", "len", "(", "sentence_word", ")", "\n", "for", "word", "in", "sentence_word", ":", "\n", "            ", "all_words", ".", "append", "(", "word", "[", "'word'", "]", ")", "\n", "", "", "word_relation_graph", "=", "np", ".", "zeros", "(", "(", "word_num", ",", "word_num", ")", ")", "\n", "for", "coref_relation", "in", "coref_relations", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "coref_relation", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "coref_relation", ")", ")", ":", "\n", "                ", "first_word", "=", "coref_relation", "[", "i", "]", "\n", "second_word", "=", "coref_relation", "[", "j", "]", "\n", "for", "k", "in", "range", "(", "first_word", "[", "1", "]", ",", "first_word", "[", "2", "]", ")", ":", "\n", "                    ", "first_index", "=", "sentence_start_indices", "[", "first_word", "[", "0", "]", "-", "1", "]", "+", "k", "-", "1", "\n", "for", "l", "in", "range", "(", "second_word", "[", "1", "]", ",", "second_word", "[", "2", "]", ")", ":", "\n", "                        ", "second_index", "=", "sentence_start_indices", "[", "second_word", "[", "0", "]", "-", "1", "]", "+", "l", "-", "1", "\n", "print", "(", "'first_word: %s second_word: %s'", "%", "(", "all_words", "[", "first_index", "]", ",", "all_words", "[", "second_index", "]", ")", ")", "\n", "word_relation_graph", "[", "first_index", "]", "[", "second_index", "]", "=", "1", "\n", "word_relation_graph", "[", "second_index", "]", "[", "first_index", "]", "=", "1", "\n", "", "", "", "", "", "return", "word_relation_graph", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.annotation_utils.split_sentence": [[5, 18], ["len", "result.append"], "function", ["None"], ["def", "split_sentence", "(", "sentence", ":", "str", ",", "length", ":", "int", "=", "100", ")", ":", "\n", "    ", "\"\"\"\n    :param sentence:\n    :param length:\n    :return:\n    \"\"\"", "\n", "\n", "result", "=", "[", "]", "\n", "start", "=", "0", "\n", "while", "start", "<", "len", "(", "sentence", ")", ":", "\n", "        ", "result", ".", "append", "(", "sentence", "[", "start", ":", "start", "+", "length", "]", ")", "\n", "start", "+=", "length", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.text_utils.to_english_like_sentence": [[7, 14], ["nlp_tasks.utils.tokenizers.JiebaTokenizer", "tokenizer"], "function", ["None"], ["def", "to_english_like_sentence", "(", "sentence", ":", "str", ",", "tokenizer", "=", "tokenizers", ".", "JiebaTokenizer", "(", ")", ")", ":", "\n", "    ", "\"\"\"\n\n    :param sentence:\n    :return:\n    \"\"\"", "\n", "return", "' '", ".", "join", "(", "tokenizer", "(", "sentence", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.event_extractor.get_event_representation_by_constituency_tree": [[7, 38], ["target_node.parent.value.startswith", "nlp_tasks.utils.stanfordnlp_sentence_constituency_parser.TreeNode.get_np_ancestor", "target_node.parent.value.startswith", "len"], "function", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.TreeNode.get_np_ancestor"], ["def", "get_event_representation_by_constituency_tree", "(", "target_node", ":", "constip", ".", "TreeNode", ",", "constituency_tree", ":", "constip", ".", "TreeNode", ")", ":", "\n", "    ", "\"\"\"\n    :param target_node:\n    :param original_index:\n    :param constituency_tree:\n    :return:\n    \"\"\"", "\n", "if", "target_node", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "# if successful_rule == 'rule5' and cause_or_effect == 'effect':", "\n", "#     result = constip.TreeNode.get_ancestor(target_node, constituency_tree, 'IP')", "\n", "#     return result", "\n", "\n", "", "if", "target_node", ".", "parent", "is", "not", "None", "and", "target_node", ".", "parent", ".", "value", ".", "startswith", "(", "'N'", ")", ":", "\n", "        ", "result", "=", "constip", ".", "TreeNode", ".", "get_np_ancestor", "(", "target_node", ",", "constituency_tree", ")", "\n", "return", "result", "if", "result", "!=", "constituency_tree", "else", "None", "\n", "\n", "", "if", "target_node", ".", "parent", "is", "not", "None", "and", "target_node", ".", "parent", ".", "value", "==", "'VV'", "and", "target_node", ".", "parent", ".", "parent", "is", "not", "None", "and", "target_node", ".", "parent", ".", "parent", ".", "value", "==", "'VP'", "and", "len", "(", "target_node", ".", "parent", ".", "parent", ".", "children", ")", "==", "2", "and", "'NP'", "in", "[", "child", ".", "value", "for", "child", "in", "target_node", ".", "parent", ".", "parent", ".", "children", "]", ":", "\n", "        ", "result", "=", "target_node", ".", "parent", ".", "parent", "\n", "return", "result", "if", "result", "!=", "constituency_tree", "else", "None", "\n", "\n", "", "if", "target_node", ".", "parent", "is", "not", "None", "and", "target_node", ".", "parent", ".", "value", ".", "startswith", "(", "'V'", ")", "and", "target_node", ".", "parent", ".", "parent", "is", "not", "None", "and", "target_node", ".", "parent", ".", "parent", ".", "value", "==", "'VP'", "and", "target_node", ".", "parent", ".", "parent", ".", "parent", "is", "not", "None", "and", "target_node", ".", "parent", ".", "parent", ".", "parent", ".", "value", "in", "(", "'IP'", ",", "'VP'", ")", ":", "\n", "        ", "result", "=", "target_node", ".", "parent", ".", "parent", ".", "parent", "\n", "return", "result", "if", "result", "!=", "constituency_tree", "else", "None", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.event_extractor.get_ccomp_event_representation_by_constituency_tree": [[40, 52], ["nlp_tasks.utils.stanfordnlp_sentence_constituency_parser.TreeNode.get_ancestor"], "function", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.TreeNode.get_ancestor"], ["", "def", "get_ccomp_event_representation_by_constituency_tree", "(", "target_node", ":", "constip", ".", "TreeNode", ",", "constituency_tree", ":", "constip", ".", "TreeNode", ")", ":", "\n", "    ", "\"\"\"\n    :param target_node:\n    :param original_index:\n    :param constituency_tree:\n    :return:\n    \"\"\"", "\n", "if", "target_node", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "result", "=", "constip", ".", "TreeNode", ".", "get_ancestor", "(", "target_node", ",", "constituency_tree", ",", "'IP'", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.event_extractor.get_noun_event_representation_by_constituency_tree": [[54, 69], ["target_node.parent.value.startswith", "nlp_tasks.utils.stanfordnlp_sentence_constituency_parser.TreeNode.get_np_ancestor"], "function", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.TreeNode.get_np_ancestor"], ["", "def", "get_noun_event_representation_by_constituency_tree", "(", "target_node", ":", "constip", ".", "TreeNode", ",", "\n", "constituency_tree", ":", "constip", ".", "TreeNode", ")", ":", "\n", "    ", "\"\"\"\n    :param target_node:\n    :param original_index:\n    :param constituency_tree:\n    :return:\n    \"\"\"", "\n", "if", "target_node", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "if", "target_node", ".", "parent", "is", "not", "None", "and", "target_node", ".", "parent", ".", "value", ".", "startswith", "(", "'N'", ")", ":", "\n", "        ", "result", "=", "constip", ".", "TreeNode", ".", "get_np_ancestor", "(", "target_node", ",", "constituency_tree", ")", "\n", "return", "result", "if", "result", "!=", "constituency_tree", "else", "None", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.event_extractor.get_verb_event_representation_by_constituency_tree": [[71, 88], ["target_node.parent.value.startswith"], "function", ["None"], ["", "def", "get_verb_event_representation_by_constituency_tree", "(", "target_node", ":", "constip", ".", "TreeNode", ",", "\n", "constituency_tree", ":", "constip", ".", "TreeNode", ")", ":", "\n", "    ", "\"\"\"\n    :param target_node:\n    :param original_index:\n    :param constituency_tree:\n    :return:\n    \"\"\"", "\n", "if", "target_node", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "if", "target_node", ".", "parent", "is", "not", "None", "and", "target_node", ".", "parent", ".", "value", ".", "startswith", "(", "'V'", ")", "and", "target_node", ".", "parent", ".", "parent", "is", "not", "None", "and", "target_node", ".", "parent", ".", "parent", ".", "value", "==", "'VP'", "and", "target_node", ".", "parent", ".", "parent", ".", "parent", "is", "not", "None", "and", "target_node", ".", "parent", ".", "parent", ".", "parent", ".", "value", "==", "'IP'", ":", "\n", "        ", "result", "=", "target_node", ".", "parent", ".", "parent", ".", "parent", "\n", "return", "result", "if", "result", "!=", "constituency_tree", "else", "None", "\n", "", "return", "None", "\n", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.write_lines": [[4, 15], ["open", "out_file.write"], "function", ["None"], ["def", "write_lines", "(", "lines", ",", "file_path", ",", "mode", "=", "'w'", ")", ":", "\n", "    ", "\"\"\"\n\n    :param lines:\n    :param file_path:\n    :param mode:\n    :return:\n    \"\"\"", "\n", "with", "open", "(", "file_path", ",", "mode", "=", "mode", ",", "encoding", "=", "'utf-8'", ")", "as", "out_file", ":", "\n", "        ", "for", "line", "in", "lines", ":", "\n", "            ", "out_file", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.append_line": [[17, 20], ["open", "out_file.write"], "function", ["None"], ["", "", "", "def", "append_line", "(", "line", ",", "file_path", ",", "mode", "=", "'a'", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "mode", "=", "mode", ",", "encoding", "=", "'utf-8'", ")", "as", "out_file", ":", "\n", "        ", "out_file", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.read_all_lines": [[22, 33], ["open", "lines.append", "line.strip", "lines.append", "lines.append", "line.strip"], "function", ["None"], ["", "", "def", "read_all_lines", "(", "file_path", ",", "encoding", "=", "'utf-8'", ",", "strip_type", "=", "'all'", ")", ":", "\n", "    ", "lines", "=", "[", "]", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "encoding", ")", "as", "in_file", ":", "\n", "        ", "for", "line", "in", "in_file", ":", "\n", "            ", "if", "strip_type", "==", "'all'", ":", "\n", "                ", "lines", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "elif", "strip_type", "==", "'line_separator'", ":", "\n", "                ", "lines", ".", "append", "(", "line", ".", "strip", "(", "'\\r\\n'", ")", ")", "\n", "", "else", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.read_all_lines_generator": [[35, 39], ["open"], "function", ["None"], ["", "def", "read_all_lines_generator", "(", "file_path", ",", "encoding", "=", "'utf-8'", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "encoding", "=", "encoding", ")", "as", "in_file", ":", "\n", "        ", "for", "line", "in", "in_file", ":", "\n", "            ", "yield", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.read_all_content": [[41, 53], ["open", "in_file.read"], "function", ["None"], ["", "", "", "def", "read_all_content", "(", "filepath", ",", "encoding", "=", "'utf-8'", ",", "keep_line_separator", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n\n    :param filepath:\n    :param encoding:\n    :return:\n    \"\"\"", "\n", "new_line", "=", "None", "\n", "if", "keep_line_separator", ":", "\n", "        ", "new_line", "=", "''", "\n", "", "with", "open", "(", "filepath", ",", "encoding", "=", "encoding", ",", "newline", "=", "new_line", ")", "as", "in_file", ":", "\n", "        ", "return", "in_file", ".", "read", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.rm_r": [[55, 66], ["os.walk", "os.remove", "os.rmdir", "os.path.join", "os.path.join"], "function", ["None"], ["", "", "def", "rm_r", "(", "file_path", ")", ":", "\n", "    ", "\"\"\"\n    remove file recursively\n    :param file_path:\n    :return:\n    \"\"\"", "\n", "for", "root", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "file_path", ",", "topdown", "=", "False", ")", ":", "\n", "        ", "for", "name", "in", "files", ":", "\n", "            ", "os", ".", "remove", "(", "os", ".", "path", ".", "join", "(", "root", ",", "name", ")", ")", "\n", "", "for", "name", "in", "dirs", ":", "\n", "            ", "os", ".", "rmdir", "(", "os", ".", "path", ".", "join", "(", "root", ",", "name", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizer_wrappers.TokenizerWithCustomWordSegmenter.__init__": [[15, 30], ["keras.preprocessing.text.Tokenizer.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "word_segmenter", ",", "num_words", "=", "None", ",", "\n", "filters", "=", "'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'", ",", "\n", "lower", "=", "True", ",", "\n", "split", "=", "' '", ",", "\n", "char_level", "=", "False", ",", "\n", "oov_token", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_words", "=", "num_words", ",", "\n", "filters", "=", "filters", ",", "\n", "lower", "=", "lower", ",", "\n", "split", "=", "split", ",", "\n", "char_level", "=", "char_level", ",", "\n", "oov_token", "=", "oov_token", ",", "\n", "**", "kwargs", ")", "\n", "self", ".", "word_segmenter", "=", "word_segmenter", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizer_wrappers.TokenizerWithCustomWordSegmenter.text_to_word_sequence": [[31, 38], ["tokenizer_wrappers.TokenizerWithCustomWordSegmenter.word_segmenter"], "methods", ["None"], ["", "def", "text_to_word_sequence", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"\n\n        :param text:\n        :return:\n        \"\"\"", "\n", "return", "self", ".", "word_segmenter", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizer_wrappers.TokenizerWithCustomWordSegmenter.fit_on_texts": [[39, 89], ["list", "list.sort", "sorted_voc.extend", "dict", "dict", "list", "set", "tokenizer_wrappers.TokenizerWithCustomWordSegmenter.word_counts.items", "list", "tokenizer_wrappers.TokenizerWithCustomWordSegmenter.word_docs.items", "isinstance", "tokenizer_wrappers.TokenizerWithCustomWordSegmenter.text_to_word_sequence", "zip", "isinstance", "list", "tokenizer_wrappers.TokenizerWithCustomWordSegmenter.word_index.items", "text.lower.lower.lower", "range", "text_elem.lower", "len"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizer_wrappers.TokenizerWithCustomWordSegmenter.text_to_word_sequence"], ["", "def", "fit_on_texts", "(", "self", ",", "texts", ")", ":", "\n", "        ", "\"\"\"Updates internal vocabulary based on a list of texts.\n\n        In the case where texts contains lists,\n        we assume each entry of the lists to be a token.\n\n        Required before using `texts_to_sequences` or `texts_to_matrix`.\n\n        # Arguments\n            texts: can be a list of strings,\n                a generator of strings (for memory-efficiency),\n                or a list of list of strings.\n        \"\"\"", "\n", "for", "text", "in", "texts", ":", "\n", "            ", "self", ".", "document_count", "+=", "1", "\n", "if", "self", ".", "char_level", "or", "isinstance", "(", "text", ",", "list", ")", ":", "\n", "                ", "if", "self", ".", "lower", ":", "\n", "                    ", "if", "isinstance", "(", "text", ",", "list", ")", ":", "\n", "                        ", "text", "=", "[", "text_elem", ".", "lower", "(", ")", "for", "text_elem", "in", "text", "]", "\n", "", "else", ":", "\n", "                        ", "text", "=", "text", ".", "lower", "(", ")", "\n", "", "", "seq", "=", "text", "\n", "", "else", ":", "\n", "                ", "seq", "=", "self", ".", "text_to_word_sequence", "(", "text", ")", "\n", "", "for", "w", "in", "seq", ":", "\n", "                ", "if", "w", "in", "self", ".", "word_counts", ":", "\n", "                    ", "self", ".", "word_counts", "[", "w", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "self", ".", "word_counts", "[", "w", "]", "=", "1", "\n", "", "", "for", "w", "in", "set", "(", "seq", ")", ":", "\n", "# In how many documents each word occurs", "\n", "                ", "self", ".", "word_docs", "[", "w", "]", "+=", "1", "\n", "\n", "", "", "wcounts", "=", "list", "(", "self", ".", "word_counts", ".", "items", "(", ")", ")", "\n", "wcounts", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "# forcing the oov_token to index 1 if it exists", "\n", "if", "self", ".", "oov_token", "is", "None", ":", "\n", "            ", "sorted_voc", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "sorted_voc", "=", "[", "self", ".", "oov_token", "]", "\n", "", "sorted_voc", ".", "extend", "(", "wc", "[", "0", "]", "for", "wc", "in", "wcounts", ")", "\n", "\n", "# note that index 0 is reserved, never assigned to an existing word", "\n", "self", ".", "word_index", "=", "dict", "(", "\n", "list", "(", "zip", "(", "sorted_voc", ",", "list", "(", "range", "(", "1", ",", "len", "(", "sorted_voc", ")", "+", "1", ")", ")", ")", ")", ")", "\n", "\n", "self", ".", "index_word", "=", "dict", "(", "(", "c", ",", "w", ")", "for", "w", ",", "c", "in", "self", ".", "word_index", ".", "items", "(", ")", ")", "\n", "\n", "for", "w", ",", "c", "in", "list", "(", "self", ".", "word_docs", ".", "items", "(", ")", ")", ":", "\n", "            ", "self", ".", "index_docs", "[", "self", ".", "word_index", "[", "w", "]", "]", "=", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizer_wrappers.TokenizerWithCustomWordSegmenter.text_to_sequence": [[90, 93], ["tokenizer_wrappers.TokenizerWithCustomWordSegmenter.texts_to_sequences"], "methods", ["None"], ["", "", "def", "text_to_sequence", "(", "self", ",", "text", ")", ":", "\n", "        ", "sequences", "=", "self", ".", "texts_to_sequences", "(", "[", "text", "]", ")", "\n", "return", "sequences", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizer_wrappers.TokenizerWithCustomWordSegmenter.texts_to_sequences_generator": [[94, 133], ["tokenizer_wrappers.TokenizerWithCustomWordSegmenter.word_index.get", "isinstance", "tokenizer_wrappers.TokenizerWithCustomWordSegmenter.text_to_word_sequence", "tokenizer_wrappers.TokenizerWithCustomWordSegmenter.word_index.get", "isinstance", "text.lower.lower.lower", "vect.append", "vect.append", "text_elem.lower", "vect.append"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizer_wrappers.TokenizerWithCustomWordSegmenter.text_to_word_sequence"], ["", "def", "texts_to_sequences_generator", "(", "self", ",", "texts", ")", ":", "\n", "        ", "\"\"\"Transforms each text in `texts` to a sequence of integers.\n\n        Each item in texts can also be a list,\n        in which case we assume each item of that list to be a token.\n\n        Only top \"num_words\" most frequent words will be taken into account.\n        Only words known by the tokenizer will be taken into account.\n\n        # Arguments\n            texts: A list of texts (strings).\n\n        # Yields\n            Yields individual sequences.\n        \"\"\"", "\n", "num_words", "=", "self", ".", "num_words", "\n", "oov_token_index", "=", "self", ".", "word_index", ".", "get", "(", "self", ".", "oov_token", ")", "\n", "for", "text", "in", "texts", ":", "\n", "            ", "if", "self", ".", "char_level", "or", "isinstance", "(", "text", ",", "list", ")", ":", "\n", "                ", "if", "self", ".", "lower", ":", "\n", "                    ", "if", "isinstance", "(", "text", ",", "list", ")", ":", "\n", "                        ", "text", "=", "[", "text_elem", ".", "lower", "(", ")", "for", "text_elem", "in", "text", "]", "\n", "", "else", ":", "\n", "                        ", "text", "=", "text", ".", "lower", "(", ")", "\n", "", "", "seq", "=", "text", "\n", "", "else", ":", "\n", "                ", "seq", "=", "self", ".", "text_to_word_sequence", "(", "text", ")", "\n", "", "vect", "=", "[", "]", "\n", "for", "w", "in", "seq", ":", "\n", "                ", "i", "=", "self", ".", "word_index", ".", "get", "(", "w", ")", "\n", "if", "i", "is", "not", "None", ":", "\n", "                    ", "if", "num_words", "and", "i", ">=", "num_words", ":", "\n", "                        ", "if", "oov_token_index", "is", "not", "None", ":", "\n", "                            ", "vect", ".", "append", "(", "oov_token_index", ")", "\n", "", "", "else", ":", "\n", "                        ", "vect", ".", "append", "(", "i", ")", "\n", "", "", "elif", "self", ".", "oov_token", "is", "not", "None", ":", "\n", "                    ", "vect", ".", "append", "(", "oov_token_index", ")", "\n", "", "", "yield", "vect", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.__init__": [[27, 121], ["logging.basicConfig", "my_corenlp.StanfordCoreNLP._check_args", "path_or_host.startswith", "socket.socket", "time.sleep", "socket.socket.connect_ex", "logging.info", "logging.info", "logging.info", "logging.info", "urlparse", "logging.info", "time.sleep", "str", "RuntimeError", "os.path.isdir", "IOError", "os.path.normpath", "len", "IOError", "range", "IOError", "str", "open", "subprocess.Popen", "logging.info", "str", "subprocess.call", "glob.glob", "str", "psutil.net_connections", "switcher.get", "str", "jars.get", "psutil.net_connections"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP._check_args"], ["    ", "def", "__init__", "(", "self", ",", "path_or_host", ",", "port", "=", "None", ",", "memory", "=", "'4g'", ",", "lang", "=", "'en'", ",", "timeout", "=", "1500", ",", "quiet", "=", "True", ",", "\n", "logging_level", "=", "logging", ".", "WARNING", ")", ":", "\n", "        ", "self", ".", "path_or_host", "=", "path_or_host", "\n", "self", ".", "port", "=", "port", "\n", "self", ".", "memory", "=", "memory", "\n", "self", ".", "lang", "=", "lang", "\n", "self", ".", "timeout", "=", "timeout", "\n", "self", ".", "quiet", "=", "quiet", "\n", "self", ".", "logging_level", "=", "logging_level", "\n", "\n", "logging", ".", "basicConfig", "(", "level", "=", "self", ".", "logging_level", ")", "\n", "\n", "# Check args", "\n", "self", ".", "_check_args", "(", ")", "\n", "\n", "if", "path_or_host", ".", "startswith", "(", "'http'", ")", ":", "\n", "            ", "self", ".", "url", "=", "path_or_host", "+", "':'", "+", "str", "(", "port", ")", "\n", "logging", ".", "info", "(", "'Using an existing server {}'", ".", "format", "(", "self", ".", "url", ")", ")", "\n", "", "else", ":", "\n", "\n", "# Check Java", "\n", "            ", "if", "not", "subprocess", ".", "call", "(", "[", "'java'", ",", "'-version'", "]", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "stderr", "=", "subprocess", ".", "STDOUT", ")", "==", "0", ":", "\n", "                ", "raise", "RuntimeError", "(", "'Java not found.'", ")", "\n", "\n", "# Check if the dir exists", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "path_or_host", ")", ":", "\n", "                ", "raise", "IOError", "(", "str", "(", "self", ".", "path_or_host", ")", "+", "' is not a directory.'", ")", "\n", "", "directory", "=", "os", ".", "path", ".", "normpath", "(", "self", ".", "path_or_host", ")", "+", "os", ".", "sep", "\n", "self", ".", "class_path_dir", "=", "directory", "\n", "\n", "# Check if the language specific model file exists", "\n", "switcher", "=", "{", "\n", "'en'", ":", "'stanford-corenlp-[0-9].[0-9].[0-9]-models.jar'", ",", "\n", "'zh'", ":", "'stanford-chinese-corenlp-[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]-models.jar'", ",", "\n", "'ar'", ":", "'stanford-arabic-corenlp-[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]-models.jar'", ",", "\n", "'fr'", ":", "'stanford-french-corenlp-[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]-models.jar'", ",", "\n", "'de'", ":", "'stanford-german-corenlp-[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]-models.jar'", ",", "\n", "'es'", ":", "'stanford-spanish-corenlp-[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]-models.jar'", "\n", "}", "\n", "jars", "=", "{", "\n", "'en'", ":", "'stanford-corenlp-x.x.x-models.jar'", ",", "\n", "'zh'", ":", "'stanford-chinese-corenlp-yyyy-MM-dd-models.jar'", ",", "\n", "'ar'", ":", "'stanford-arabic-corenlp-yyyy-MM-dd-models.jar'", ",", "\n", "'fr'", ":", "'stanford-french-corenlp-yyyy-MM-dd-models.jar'", ",", "\n", "'de'", ":", "'stanford-german-corenlp-yyyy-MM-dd-models.jar'", ",", "\n", "'es'", ":", "'stanford-spanish-corenlp-yyyy-MM-dd-models.jar'", "\n", "}", "\n", "if", "len", "(", "glob", ".", "glob", "(", "directory", "+", "switcher", ".", "get", "(", "self", ".", "lang", ")", ")", ")", "<=", "0", ":", "\n", "                ", "raise", "IOError", "(", "jars", ".", "get", "(", "\n", "self", ".", "lang", ")", "+", "' not exists. You should download and place it in the '", "+", "directory", "+", "' first.'", ")", "\n", "\n", "# If port not set, auto select", "\n", "", "if", "self", ".", "port", "is", "None", ":", "\n", "                ", "for", "port_candidate", "in", "range", "(", "9000", ",", "65535", ")", ":", "\n", "                    ", "if", "port_candidate", "not", "in", "[", "conn", ".", "laddr", "[", "1", "]", "for", "conn", "in", "psutil", ".", "net_connections", "(", ")", "]", ":", "\n", "                        ", "self", ".", "port", "=", "port_candidate", "\n", "break", "\n", "\n", "# Check if the port is in use", "\n", "", "", "", "if", "self", ".", "port", "in", "[", "conn", ".", "laddr", "[", "1", "]", "for", "conn", "in", "psutil", ".", "net_connections", "(", ")", "]", ":", "\n", "                ", "raise", "IOError", "(", "'Port '", "+", "str", "(", "self", ".", "port", ")", "+", "' is already in use.'", ")", "\n", "\n", "# Start native server", "\n", "", "logging", ".", "info", "(", "'Initializing native server...'", ")", "\n", "cmd", "=", "\"java\"", "\n", "java_args", "=", "\"-Xmx{}\"", ".", "format", "(", "self", ".", "memory", ")", "\n", "java_class", "=", "\"edu.stanford.nlp.pipeline.StanfordCoreNLPServer\"", "\n", "class_path", "=", "'\"{}*\"'", ".", "format", "(", "directory", ")", "\n", "\n", "args", "=", "[", "cmd", ",", "java_args", ",", "'-cp'", ",", "class_path", ",", "java_class", ",", "'-port'", ",", "str", "(", "self", ".", "port", ")", "]", "\n", "\n", "args", "=", "' '", ".", "join", "(", "args", ")", "\n", "\n", "logging", ".", "info", "(", "args", ")", "\n", "\n", "# Silence", "\n", "with", "open", "(", "os", ".", "devnull", ",", "'w'", ")", "as", "null_file", ":", "\n", "                ", "out_file", "=", "None", "\n", "if", "self", ".", "quiet", ":", "\n", "                    ", "out_file", "=", "null_file", "\n", "\n", "", "self", ".", "p", "=", "subprocess", ".", "Popen", "(", "args", ",", "shell", "=", "True", ",", "stdout", "=", "out_file", ",", "stderr", "=", "subprocess", ".", "STDOUT", ")", "\n", "logging", ".", "info", "(", "'Server shell PID: {}'", ".", "format", "(", "self", ".", "p", ".", "pid", ")", ")", "\n", "\n", "", "self", ".", "url", "=", "'http://localhost:'", "+", "str", "(", "self", ".", "port", ")", "\n", "\n", "# Wait until server starts", "\n", "", "sock", "=", "socket", ".", "socket", "(", "socket", ".", "AF_INET", ",", "socket", ".", "SOCK_STREAM", ")", "\n", "host_name", "=", "urlparse", "(", "self", ".", "url", ")", ".", "hostname", "\n", "time", ".", "sleep", "(", "1", ")", "# OSX, not tested", "\n", "while", "sock", ".", "connect_ex", "(", "(", "host_name", ",", "self", ".", "port", ")", ")", ":", "\n", "            ", "logging", ".", "info", "(", "'Waiting until the server is available.'", ")", "\n", "time", ".", "sleep", "(", "1", ")", "\n", "", "logging", ".", "info", "(", "'The server is available.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.close_process": [[122, 139], ["psutil.Process.children", "logging.info", "psutil.Process.kill", "psutil.Process", "logging.info", "process.kill", "logging.info", "psutil.Process.cmdline", "process.cmdline"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "close_process", "(", "pid", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "parent", "=", "psutil", ".", "Process", "(", "pid", ")", "\n", "", "except", "psutil", ".", "NoSuchProcess", ":", "\n", "            ", "logging", ".", "info", "(", "'No process: {}'", ".", "format", "(", "pid", ")", ")", "\n", "return", "\n", "\n", "", "children", "=", "parent", ".", "children", "(", "recursive", "=", "True", ")", "\n", "for", "process", "in", "children", ":", "\n", "            ", "logging", ".", "info", "(", "'Killing pid: {}, cmdline: {}'", ".", "format", "(", "process", ".", "pid", ",", "process", ".", "cmdline", "(", ")", ")", ")", "\n", "# process.send_signal(signal.SIGTERM)", "\n", "process", ".", "kill", "(", ")", "\n", "\n", "", "logging", ".", "info", "(", "'Killing shell pid: {}, cmdline: {}'", ".", "format", "(", "parent", ".", "pid", ",", "parent", ".", "cmdline", "(", ")", ")", ")", "\n", "# parent.send_signal(signal.SIGTERM)", "\n", "parent", ".", "kill", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.close": [[140, 144], ["logging.info", "hasattr", "StanfordCoreNLP.close_procecess"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "logging", ".", "info", "(", "'Cleanup...'", ")", "\n", "if", "hasattr", "(", "self", ",", "'p'", ")", ":", "\n", "            ", "StanfordCoreNLP", ".", "close_procecess", "(", "self", ".", "p", ".", "pid", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.__enter__": [[145, 147], ["None"], "methods", ["None"], ["", "", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.__exit__": [[148, 150], ["my_corenlp.StanfordCoreNLP.close"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.close"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_val", ",", "exc_tb", ")", ":", "\n", "        ", "self", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.annotate": [[151, 158], ["requests.post", "text.encode.encode.encode", "str"], "methods", ["None"], ["", "def", "annotate", "(", "self", ",", "text", ",", "properties", "=", "None", ")", ":", "\n", "        ", "if", "sys", ".", "version_info", ".", "major", ">=", "3", ":", "\n", "            ", "text", "=", "text", ".", "encode", "(", "'utf-8'", ")", "\n", "\n", "", "r", "=", "requests", ".", "post", "(", "self", ".", "url", ",", "params", "=", "{", "'properties'", ":", "str", "(", "properties", ")", "}", ",", "data", "=", "text", ",", "\n", "headers", "=", "{", "'Connection'", ":", "'close'", "}", ")", "\n", "return", "r", ".", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.tregex": [[159, 163], ["my_corenlp.StanfordCoreNLP._request"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP._request"], ["", "def", "tregex", "(", "self", ",", "sentence", ",", "pattern", ")", ":", "\n", "        ", "tregex_url", "=", "self", ".", "url", "+", "'/tregex'", "\n", "r_dict", "=", "self", ".", "_request", "(", "tregex_url", ",", "pattern", ",", "\"tokenize,ssplit,depparse,parse\"", ",", "sentence", ")", "\n", "return", "r_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.tokensregex": [[164, 168], ["my_corenlp.StanfordCoreNLP._request"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP._request"], ["", "def", "tokensregex", "(", "self", ",", "sentence", ",", "pattern", ")", ":", "\n", "        ", "tokensregex_url", "=", "self", ".", "url", "+", "'/tokensregex'", "\n", "r_dict", "=", "self", ".", "_request", "(", "tokensregex_url", ",", "pattern", ",", "\"tokenize,ssplit,depparse\"", ",", "sentence", ")", "\n", "return", "r_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.semgrex": [[169, 173], ["my_corenlp.StanfordCoreNLP._request"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP._request"], ["", "def", "semgrex", "(", "self", ",", "sentence", ",", "pattern", ")", ":", "\n", "        ", "semgrex_url", "=", "self", ".", "url", "+", "'/semgrex'", "\n", "r_dict", "=", "self", ".", "_request", "(", "semgrex_url", ",", "pattern", ",", "\"tokenize,ssplit,depparse\"", ",", "sentence", ")", "\n", "return", "r_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.word_tokenize": [[174, 185], ["my_corenlp.StanfordCoreNLP._request"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP._request"], ["", "def", "word_tokenize", "(", "self", ",", "sentence", ",", "span", "=", "False", ")", ":", "\n", "        ", "r_dict", "=", "self", ".", "_request", "(", "'ssplit,tokenize'", ",", "sentence", ")", "\n", "tokens", "=", "[", "token", "[", "'originalText'", "]", "for", "s", "in", "r_dict", "[", "'sentences'", "]", "for", "token", "in", "s", "[", "'tokens'", "]", "]", "\n", "\n", "# Whether return token span", "\n", "if", "span", ":", "\n", "            ", "spans", "=", "[", "(", "token", "[", "'characterOffsetBegin'", "]", ",", "token", "[", "'characterOffsetEnd'", "]", ")", "for", "s", "in", "r_dict", "[", "'sentences'", "]", "for", "token", "\n", "in", "s", "[", "'tokens'", "]", "]", "\n", "return", "tokens", ",", "spans", "\n", "", "else", ":", "\n", "            ", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.pos_tag": [[186, 195], ["my_corenlp.StanfordCoreNLP._request", "list", "zip", "words.append", "tags.append"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP._request"], ["", "", "def", "pos_tag", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "r_dict", "=", "self", ".", "_request", "(", "'pos'", ",", "sentence", ")", "\n", "words", "=", "[", "]", "\n", "tags", "=", "[", "]", "\n", "for", "s", "in", "r_dict", "[", "'sentences'", "]", ":", "\n", "            ", "for", "token", "in", "s", "[", "'tokens'", "]", ":", "\n", "                ", "words", ".", "append", "(", "token", "[", "'originalText'", "]", ")", "\n", "tags", ".", "append", "(", "token", "[", "'pos'", "]", ")", "\n", "", "", "return", "list", "(", "zip", "(", "words", ",", "tags", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.ner": [[196, 205], ["my_corenlp.StanfordCoreNLP._request", "list", "zip", "words.append", "ner_tags.append"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP._request"], ["", "def", "ner", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "r_dict", "=", "self", ".", "_request", "(", "'ner'", ",", "sentence", ")", "\n", "words", "=", "[", "]", "\n", "ner_tags", "=", "[", "]", "\n", "for", "s", "in", "r_dict", "[", "'sentences'", "]", ":", "\n", "            ", "for", "token", "in", "s", "[", "'tokens'", "]", ":", "\n", "                ", "words", ".", "append", "(", "token", "[", "'originalText'", "]", ")", "\n", "ner_tags", ".", "append", "(", "token", "[", "'ner'", "]", ")", "\n", "", "", "return", "list", "(", "zip", "(", "words", ",", "ner_tags", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.parse": [[206, 209], ["my_corenlp.StanfordCoreNLP._request"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP._request"], ["", "def", "parse", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "r_dict", "=", "self", ".", "_request", "(", "'pos,parse'", ",", "sentence", ")", "\n", "return", "[", "s", "[", "'parse'", "]", "for", "s", "in", "r_dict", "[", "'sentences'", "]", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.dependency_parse": [[210, 220], ["my_corenlp.StanfordCoreNLP._request"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP._request"], ["", "def", "dependency_parse", "(", "self", ",", "sentence", ",", "return_words", "=", "False", ")", ":", "\n", "        ", "r_dict", "=", "self", ".", "_request", "(", "'depparse'", ",", "sentence", ")", "\n", "dependencies", "=", "[", "(", "dep", "[", "'dep'", "]", ",", "dep", "[", "'governor'", "]", ",", "dep", "[", "'dependent'", "]", ")", "for", "s", "in", "r_dict", "[", "'sentences'", "]", "for", "dep", "in", "\n", "s", "[", "'enhancedPlusPlusDependencies'", "]", "]", "\n", "if", "not", "return_words", ":", "\n", "            ", "return", "dependencies", "\n", "", "else", ":", "\n", "            ", "words", "=", "[", "token", "[", "'word'", "]", "for", "s", "in", "r_dict", "[", "'sentences'", "]", "for", "token", "in", "\n", "s", "[", "'tokens'", "]", "]", "\n", "return", "dependencies", ",", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.coref": [[221, 234], ["my_corenlp.StanfordCoreNLP._request", "r_dict[].items", "corefs.append", "simplified_mentions.append"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP._request"], ["", "", "def", "coref", "(", "self", ",", "text", ",", "return_words", "=", "False", ")", ":", "\n", "        ", "r_dict", "=", "self", ".", "_request", "(", "'tokenize,ssplit,coref'", ",", "text", ")", "\n", "\n", "corefs", "=", "[", "]", "\n", "for", "k", ",", "mentions", "in", "r_dict", "[", "'corefs'", "]", ".", "items", "(", ")", ":", "\n", "            ", "simplified_mentions", "=", "[", "]", "\n", "for", "m", "in", "mentions", ":", "\n", "                ", "simplified_mentions", ".", "append", "(", "(", "m", "[", "'sentNum'", "]", ",", "m", "[", "'startIndex'", "]", ",", "m", "[", "'endIndex'", "]", ",", "m", "[", "'text'", "]", ")", ")", "\n", "", "corefs", ".", "append", "(", "simplified_mentions", ")", "\n", "", "if", "return_words", ":", "\n", "            ", "return", "corefs", ",", "[", "sentence", "[", "'tokens'", "]", "for", "sentence", "in", "r_dict", "[", "'sentences'", "]", "]", "\n", "", "else", ":", "\n", "            ", "return", "corefs", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.switch_language": [[235, 238], ["my_corenlp.StanfordCoreNLP._check_language"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP._check_language"], ["", "", "def", "switch_language", "(", "self", ",", "language", "=", "\"en\"", ")", ":", "\n", "        ", "self", ".", "_check_language", "(", "language", ")", "\n", "self", ".", "lang", "=", "language", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP._request": [[239, 253], ["logging.info", "requests.post", "json.loads", "data.encode.encode.encode", "str", "str"], "methods", ["None"], ["", "def", "_request", "(", "self", ",", "annotators", "=", "None", ",", "data", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "sys", ".", "version_info", ".", "major", ">=", "3", ":", "\n", "            ", "data", "=", "data", ".", "encode", "(", "'utf-8'", ")", "\n", "\n", "", "properties", "=", "{", "'annotators'", ":", "annotators", ",", "'outputFormat'", ":", "'json'", "}", "\n", "params", "=", "{", "'properties'", ":", "str", "(", "properties", ")", ",", "'pipelineLanguage'", ":", "self", ".", "lang", "}", "\n", "if", "'pattern'", "in", "kwargs", ":", "\n", "            ", "params", "=", "{", "\"pattern\"", ":", "kwargs", "[", "'pattern'", "]", ",", "'properties'", ":", "str", "(", "properties", ")", ",", "'pipelineLanguage'", ":", "self", ".", "lang", "}", "\n", "\n", "", "logging", ".", "info", "(", "params", ")", "\n", "r", "=", "requests", ".", "post", "(", "self", ".", "url", ",", "params", "=", "params", ",", "data", "=", "data", ",", "headers", "=", "{", "'Connection'", ":", "'close'", "}", ")", "\n", "r_dict", "=", "json", ".", "loads", "(", "r", ".", "text", ")", "\n", "\n", "return", "r_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP._check_args": [[254, 258], ["my_corenlp.StanfordCoreNLP._check_language", "re.match", "ValueError"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP._check_language"], ["", "def", "_check_args", "(", "self", ")", ":", "\n", "        ", "self", ".", "_check_language", "(", "self", ".", "lang", ")", "\n", "if", "not", "re", ".", "match", "(", "'\\dg'", ",", "self", ".", "memory", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'memory='", "+", "self", ".", "memory", "+", "' not supported. Use 4g, 6g, 8g and etc. '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP._check_language": [[259, 262], ["ValueError"], "methods", ["None"], ["", "", "def", "_check_language", "(", "self", ",", "lang", ")", ":", "\n", "        ", "if", "lang", "not", "in", "[", "'en'", ",", "'zh'", ",", "'ar'", ",", "'fr'", ",", "'de'", ",", "'es'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "'lang='", "+", "self", ".", "lang", "+", "' not supported. Use English(en), Chinese(zh), Arabic(ar), '", "\n", "'French(fr), German(de), Spanish(es).'", ")", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.vector_utils.get_trained_count_and_tfidf_model": [[8, 24], ["sklearn.feature_extraction.text.CountVectorizer", "sklearn_text.CountVectorizer.fit", "sklearn_text.CountVectorizer.transform", "sklearn.feature_extraction.text.TfidfTransformer", "sklearn_text.TfidfTransformer.fit", "nlp_tasks.utils.tokenizers.BaseTokenizer", "tokenizer"], "function", ["None"], ["def", "get_trained_count_and_tfidf_model", "(", "texts", ":", "list", ",", "tokenizer", ":", "tokenizers", ".", "BaseTokenizer", "(", ")", ")", ":", "\n", "    ", "\"\"\"\n\n    :param texts:\n    :param tokenizer:\n    :return:\n    \"\"\"", "\n", "texts_tokenized", "=", "[", "' '", ".", "join", "(", "tokenizer", "(", "text", ")", ")", "for", "text", "in", "texts", "]", "\n", "count_model", "=", "sklearn_text", ".", "CountVectorizer", "(", ")", "\n", "count_model", ".", "fit", "(", "texts_tokenized", ")", "\n", "freq_word_matrix", "=", "count_model", ".", "transform", "(", "texts_tokenized", ")", "\n", "\n", "tfidf_model", "=", "sklearn_text", ".", "TfidfTransformer", "(", ")", "\n", "tfidf_model", ".", "fit", "(", "freq_word_matrix", ")", "\n", "\n", "return", "count_model", ",", "tfidf_model", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.vector_utils.to_tfidf_vectors3": [[26, 38], ["count_model.transform", "tfidf_model.transform"], "function", ["None"], ["", "def", "to_tfidf_vectors3", "(", "texts", ":", "list", ",", "count_model", ",", "tfidf_model", ")", ":", "\n", "    ", "\"\"\"\n\n    :param texts:\n    :param tokenizer:\n    :param count_model:\n    :param tfidf_model:\n    :return:\n    \"\"\"", "\n", "count", "=", "count_model", ".", "transform", "(", "texts", ")", "\n", "result", "=", "tfidf_model", ".", "transform", "(", "count", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.vector_utils.to_tfidf_vectors2": [[40, 51], ["vector_utils.to_tfidf_vectors3", "nlp_tasks.utils.tokenizers.BaseTokenizer", "tokenizer"], "function", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.vector_utils.to_tfidf_vectors3"], ["", "def", "to_tfidf_vectors2", "(", "texts", ":", "list", ",", "tokenizer", ":", "tokenizers", ".", "BaseTokenizer", "(", ")", ",", "count_model", ",", "tfidf_model", ")", ":", "\n", "    ", "\"\"\"\n\n    :param texts:\n    :param tokenizer:\n    :param count_model:\n    :param tfidf_model:\n    :return:\n    \"\"\"", "\n", "texts_tokenized", "=", "[", "' '", ".", "join", "(", "tokenizer", "(", "text", ")", ")", "for", "text", "in", "texts", "]", "\n", "return", "to_tfidf_vectors3", "(", "texts_tokenized", ",", "count_model", ",", "tfidf_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.vector_utils.to_tfidf_vectors": [[53, 69], ["sklearn.feature_extraction.text.CountVectorizer", "sklearn_text.CountVectorizer.fit_transform", "sklearn.feature_extraction.text.TfidfTransformer", "sklearn_text.TfidfTransformer.fit_transform", "transformer.fit_transform.toarray", "nlp_tasks.utils.tokenizers.BaseTokenizer", "tokenizer"], "function", ["None"], ["", "def", "to_tfidf_vectors", "(", "texts", ":", "list", ",", "tokenizer", ":", "tokenizers", ".", "BaseTokenizer", "(", ")", ")", ":", "\n", "    ", "\"\"\"\n\n    :param texts: list of str\n    :param tokenizer:\n    :return:\n    \"\"\"", "\n", "texts_tokenized", "=", "[", "' '", ".", "join", "(", "tokenizer", "(", "text", ")", ")", "for", "text", "in", "texts", "]", "\n", "vectorizer", "=", "sklearn_text", ".", "CountVectorizer", "(", ")", "\n", "freq_word_matrix", "=", "vectorizer", ".", "fit_transform", "(", "texts_tokenized", ")", "\n", "\n", "transformer", "=", "sklearn_text", ".", "TfidfTransformer", "(", ")", "\n", "tfidf_matrix", "=", "transformer", ".", "fit_transform", "(", "freq_word_matrix", ")", "\n", "\n", "X", "=", "tfidf_matrix", ".", "toarray", "(", ")", "\n", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.argument_utils.my_bool": [[7, 14], ["argparse.ArgumentTypeError"], "function", ["None"], ["def", "my_bool", "(", "val", ")", ":", "\n", "    ", "if", "val", "==", "'True'", ":", "\n", "        ", "return", "True", "\n", "", "elif", "val", "==", "'False'", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Unsupported value encountered.'", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.corenlp_factory.create_corenlp_server": [[12, 18], ["nlp_tasks.utils.my_corenlp.StanfordCoreNLP"], "function", ["None"], ["def", "create_corenlp_server", "(", "start_new_server", "=", "False", ",", "lang", "=", "'en'", ")", ":", "\n", "    ", "path_or_host", "=", "MODEL_DIR", "\n", "if", "not", "start_new_server", ":", "\n", "        ", "path_or_host", "=", "'http://localhost'", "\n", "", "return", "my_corenlp", ".", "StanfordCoreNLP", "(", "path_or_host", ",", "lang", "=", "lang", ",", "quiet", "=", "False", ",", "logging_level", "=", "logging", ".", "INFO", ",", "memory", "=", "'4g'", ",", "\n", "port", "=", "8081", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.BaseTokenizer.__init__": [[18, 20], ["nlp_tasks.utils.word_processor.BaseWordProcessor"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "word_processor", "=", "word_processor", ".", "BaseWordProcessor", "(", ")", ")", ":", "\n", "        ", "self", ".", "word_processor", "=", "word_processor", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.BaseTokenizer.is_valid_text": [[21, 25], ["None"], "methods", ["None"], ["", "def", "is_valid_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "if", "text", "is", "None", ":", "\n", "            ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.BaseTokenizer._inner_segment": [[26, 34], ["text.split"], "methods", ["None"], ["", "def", "_inner_segment", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"\n\n        :param text:\n        :return:\n        \"\"\"", "\n", "words", "=", "text", ".", "split", "(", "' '", ")", "\n", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.BaseTokenizer._segment": [[35, 43], ["tokenizers.BaseTokenizer._inner_segment", "tokenizers.BaseTokenizer.word_processor.process", "result.append"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.SpacyTokenizer._inner_segment", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.word_processor.BaseWordProcessor.process"], ["", "def", "_segment", "(", "self", ",", "text", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "words", "=", "self", ".", "_inner_segment", "(", "text", ")", "\n", "for", "word", "in", "words", ":", "\n", "            ", "word", "=", "self", ".", "word_processor", ".", "process", "(", "word", ")", "\n", "if", "word", "is", "not", "None", ":", "\n", "                ", "result", ".", "append", "(", "word", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.BaseTokenizer.__call__": [[44, 49], ["tokenizers.BaseTokenizer.is_valid_text", "tokenizers.BaseTokenizer._segment"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.BaseTokenizer.is_valid_text", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.BaseTokenizer._segment"], ["", "def", "__call__", "(", "self", ",", "text", ":", "str", ")", "->", "list", ":", "\n", "        ", "if", "not", "self", ".", "is_valid_text", "(", "text", ")", ":", "\n", "            ", "return", "[", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_segment", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.JiebaTokenizer.__init__": [[55, 57], ["nlp_tasks.utils.word_processor.BaseWordProcessor", "tokenizers.BaseTokenizer.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "word_processor", "=", "word_processor", ".", "BaseWordProcessor", "(", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "word_processor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.JiebaTokenizer._inner_segment": [[58, 62], ["list", "tokenizers.JiebaTokenizer.is_valid_text", "jieba.cut"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.BaseTokenizer.is_valid_text"], ["", "def", "_inner_segment", "(", "self", ",", "text", ")", ":", "\n", "        ", "if", "not", "self", ".", "is_valid_text", "(", "text", ")", ":", "\n", "            ", "return", "[", "]", "\n", "", "return", "list", "(", "jieba", ".", "cut", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.NltkTokenizer.__init__": [[69, 71], ["nlp_tasks.utils.word_processor.BaseWordProcessor", "tokenizers.BaseTokenizer.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "word_processor", "=", "word_processor", ".", "BaseWordProcessor", "(", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "word_processor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.NltkTokenizer._inner_segment": [[72, 76], ["nltk.tokenize.word_tokenize", "tokenizers.NltkTokenizer.is_valid_text"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.word_tokenize", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.BaseTokenizer.is_valid_text"], ["", "def", "_inner_segment", "(", "self", ",", "text", ")", ":", "\n", "        ", "if", "not", "self", ".", "is_valid_text", "(", "text", ")", ":", "\n", "            ", "return", "[", "]", "\n", "", "return", "tokenize", ".", "word_tokenize", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.StanfordTokenizer.__init__": [[83, 86], ["nlp_tasks.utils.word_processor.BaseWordProcessor", "tokenizers.BaseTokenizer.__init__", "nlp_tasks.utils.corenlp_factory.create_corenlp_server"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.corenlp_factory.create_corenlp_server"], ["def", "__init__", "(", "self", ",", "word_processor", "=", "word_processor", ".", "BaseWordProcessor", "(", ")", ",", "lang", "=", "'en'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "word_processor", ")", "\n", "self", ".", "stanford_nlp", "=", "corenlp_factory", ".", "create_corenlp_server", "(", "lang", "=", "lang", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.StanfordTokenizer._inner_segment": [[87, 92], ["tokenizers.StanfordTokenizer.stanford_nlp.word_tokenize", "tokenizers.StanfordTokenizer.is_valid_text"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.word_tokenize", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.BaseTokenizer.is_valid_text"], ["", "def", "_inner_segment", "(", "self", ",", "text", ")", ":", "\n", "        ", "if", "not", "self", ".", "is_valid_text", "(", "text", ")", ":", "\n", "            ", "return", "[", "]", "\n", "", "words", "=", "self", ".", "stanford_nlp", ".", "word_tokenize", "(", "text", ")", "\n", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.SpacyTokenizer.__init__": [[99, 102], ["nlp_tasks.utils.word_processor.BaseWordProcessor", "tokenizers.BaseTokenizer.__init__", "spacy.load"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "word_processor", "=", "word_processor", ".", "BaseWordProcessor", "(", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "word_processor", ")", "\n", "self", ".", "spacy_nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.SpacyTokenizer._inner_segment": [[103, 109], ["tokenizers.SpacyTokenizer.spacy_nlp", "tokenizers.SpacyTokenizer.is_valid_text"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizers.BaseTokenizer.is_valid_text"], ["", "def", "_inner_segment", "(", "self", ",", "text", ")", ":", "\n", "        ", "if", "not", "self", ".", "is_valid_text", "(", "text", ")", ":", "\n", "            ", "return", "[", "]", "\n", "", "doc", "=", "self", ".", "spacy_nlp", "(", "text", ",", "disable", "=", "[", "\"parser\"", "]", ")", "\n", "words", "=", "[", "token", ".", "text", "for", "token", "in", "doc", "]", "\n", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.word_processor.WordProcessorInterface.process": [[15, 18], ["None"], "methods", ["None"], ["@", "abc", ".", "abstractmethod", "\n", "def", "process", "(", "self", ",", "word", ":", "str", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.word_processor.WordProcessorInterface.get_description": [[19, 22], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "get_description", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.word_processor.BaseWordProcessor.__init__": [[29, 31], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "other_processor", ":", "WordProcessorInterface", "=", "None", ")", ":", "\n", "        ", "self", ".", "other_processor", "=", "other_processor", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.word_processor.BaseWordProcessor.get_description": [[32, 42], ["word_processor.BaseWordProcessor.other_processor.get_description"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.word_processor.BaseWordProcessor.get_description"], ["", "def", "get_description", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n\n        :return:\n        \"\"\"", "\n", "result", "=", "''", "\n", "if", "not", "self", ".", "other_processor", "is", "None", ":", "\n", "            ", "result", "+=", "self", ".", "other_processor", ".", "get_description", "(", ")", "\n", "result", "+", "'->'", "\n", "", "return", "result", "+", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.word_processor.BaseWordProcessor._inner_process": [[43, 49], ["None"], "methods", ["None"], ["", "def", "_inner_process", "(", "self", ",", "word", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n\n        :return:\n        \"\"\"", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.word_processor.BaseWordProcessor.process": [[50, 61], ["word_processor.BaseWordProcessor._inner_process", "word_processor.BaseWordProcessor.other_processor.process"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.word_processor.StopWordProcessor._inner_process", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.word_processor.BaseWordProcessor.process"], ["", "def", "process", "(", "self", ",", "word", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n\n        :param word:\n        :return:\n        \"\"\"", "\n", "if", "word", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "if", "self", ".", "other_processor", "is", "not", "None", ":", "\n", "            ", "word", "=", "self", ".", "other_processor", ".", "process", "(", "word", ")", "\n", "", "return", "self", ".", "_inner_process", "(", "word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.word_processor.LowerProcessor.__init__": [[68, 70], ["word_processor.BaseWordProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "other_processor", ":", "WordProcessorInterface", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "other_processor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.word_processor.LowerProcessor._inner_process": [[71, 78], ["word.lower"], "methods", ["None"], ["", "def", "_inner_process", "(", "self", ",", "word", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n\n        :param word:\n        :return:\n        \"\"\"", "\n", "return", "word", ".", "lower", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.word_processor.StemProcessor.__init__": [[85, 87], ["word_processor.BaseWordProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "other_processor", ":", "WordProcessorInterface", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "other_processor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.word_processor.StemProcessor._inner_process": [[88, 95], ["stemmer.stem"], "methods", ["None"], ["", "def", "_inner_process", "(", "self", ",", "word", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n\n        :param word:\n        :return:\n        \"\"\"", "\n", "return", "stemmer", ".", "stem", "(", "word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.word_processor.StopWordProcessor.__init__": [[102, 104], ["word_processor.BaseWordProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "other_processor", ":", "WordProcessorInterface", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "other_processor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.word_processor.StopWordProcessor._inner_process": [[105, 115], ["None"], "methods", ["None"], ["", "def", "_inner_process", "(", "self", ",", "word", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n\n        :param word:\n        :return:\n        \"\"\"", "\n", "if", "word", "in", "english_stop_words", ":", "\n", "            ", "return", "None", "\n", "", "else", ":", "\n", "            ", "return", "word", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.attention_visualizer.plot_attention": [[8, 26], ["range", "pandas.DataFrame", "matplotlib.subplots", "seaborn.heatmap", "matplotlib.show", "len", "len"], "function", ["None"], ["def", "plot_attention", "(", "words", ",", "attention", ")", ":", "\n", "    ", "\"\"\"\n\n    :param words:\n    :param attention:\n    :return:\n    \"\"\"", "\n", "data", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "words", ")", ")", ":", "\n", "        ", "data", "[", "words", "[", "i", "]", "]", "=", "{", "'attention'", ":", "attention", "[", "i", "]", "}", "\n", "", "d1", "=", "pd", ".", "DataFrame", "(", "data", ",", "columns", "=", "words", ")", "\n", "\n", "f", ",", "(", "ax1", ")", "=", "plt", ".", "subplots", "(", "figsize", "=", "(", "len", "(", "words", ")", ",", "3", ")", ",", "nrows", "=", "1", ")", "\n", "# sns.heatmap(d1, annot=True, ax=ax1)", "\n", "\n", "sns", ".", "heatmap", "(", "d1", ",", "annot", "=", "True", ",", "ax", "=", "ax1", ",", "linewidths", "=", "1", ",", "vmax", "=", "1", ",", "fmt", "=", "'.2f'", ",", "vmin", "=", "0", ",", "center", "=", "0.3", ",", "\n", "cmap", "=", "'Reds'", ")", "# YlGnBu,YlOrRd,YlGn,Reds", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.attention_visualizer.plot_attentions": [[28, 70], ["range", "len", "matplotlib.subplots", "axes[].set_title", "enumerate", "matplotlib.show", "len", "columns.append", "range", "axis.get_xticklabels", "matplotlib.setp", "seaborn.heatmap", "sns.heatmap.tick_params", "sns.heatmap.figure.colorbar", "sns_plot.figure.colorbar.ax.tick_params", "matplotlib.tight_layout", "matplotlib.subplots_adjust", "len", "pandas.DataFrame", "datas.append", "len", "len"], "function", ["None"], ["", "def", "plot_attentions", "(", "words", ",", "attentions", ",", "labels", ",", "title", ")", ":", "\n", "    ", "\"\"\"\n\n    :param words:\n    :param attention:\n    :return:\n    \"\"\"", "\n", "datas", "=", "[", "]", "\n", "data", "=", "{", "}", "\n", "columns", "=", "[", "]", "\n", "max_word_num_per_subplot", "=", "30", "\n", "for", "i", "in", "range", "(", "len", "(", "words", ")", ")", ":", "\n", "        ", "columns", ".", "append", "(", "words", "[", "i", "]", ")", "\n", "data", "[", "words", "[", "i", "]", "]", "=", "{", "}", "\n", "for", "j", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "            ", "data", "[", "words", "[", "i", "]", "]", "[", "labels", "[", "j", "]", "]", "=", "attentions", "[", "j", "]", "[", "i", "]", "\n", "", "if", "(", "i", ">", "0", "and", "i", "%", "max_word_num_per_subplot", "==", "0", ")", "or", "i", "==", "len", "(", "words", ")", "-", "1", ":", "\n", "            ", "d", "=", "pd", ".", "DataFrame", "(", "data", ",", "columns", "=", "columns", ")", "\n", "datas", ".", "append", "(", "d", ")", "\n", "data", "=", "{", "}", "\n", "columns", "=", "[", "]", "\n", "\n", "", "", "nrows", "=", "len", "(", "datas", ")", "\n", "f", ",", "axes", "=", "plt", ".", "subplots", "(", "nrows", "=", "nrows", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "80", ",", "len", "(", "labels", ")", "+", "5", ")", ")", "\n", "if", "nrows", "==", "1", ":", "\n", "        ", "axes", "=", "[", "axes", "]", "\n", "# sns.heatmap(d1, annot=True, ax=ax1)", "\n", "# https://blog.csdn.net/ChenHaoUESTC/article/details/79132602", "\n", "", "axes", "[", "0", "]", ".", "set_title", "(", "title", ")", "\n", "for", "i", ",", "axis", "in", "enumerate", "(", "axes", ")", ":", "\n", "# axis.legend(fontsize=4)", "\n", "        ", "label_x", "=", "axis", ".", "get_xticklabels", "(", ")", "\n", "rotation", "=", "30", "\n", "plt", ".", "setp", "(", "label_x", ",", "rotation", "=", "rotation", ")", "\n", "sns_plot", "=", "sns", ".", "heatmap", "(", "datas", "[", "i", "]", ",", "annot", "=", "True", ",", "ax", "=", "axis", ",", "linewidths", "=", "1", ",", "vmax", "=", "1", ",", "fmt", "=", "'.2f'", ",", "vmin", "=", "0", ",", "center", "=", "0.3", ",", "\n", "cmap", "=", "'Reds'", ",", "annot_kws", "=", "{", "'size'", ":", "5", "}", ",", "cbar", "=", "False", ")", "\n", "sns_plot", ".", "tick_params", "(", "labelsize", "=", "5", ")", "\n", "cb", "=", "sns_plot", ".", "figure", ".", "colorbar", "(", "sns_plot", ".", "collections", "[", "0", "]", ",", "shrink", "=", "1", ")", "\n", "cb", ".", "ax", ".", "tick_params", "(", "labelsize", "=", "5", ")", "\n", "plt", ".", "tight_layout", "(", "pad", "=", "5", ")", "\n", "plt", ".", "subplots_adjust", "(", "left", "=", "0.03", ",", "right", "=", "1", ",", "top", "=", "0.7", ",", "bottom", "=", "0.35", ")", "\n", "", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.attention_visualizer.plot_attentions_pakdd": [[72, 113], ["range", "len", "matplotlib.subplots", "axes[].set_title", "enumerate", "matplotlib.show", "len", "columns.append", "range", "seaborn.heatmap", "len", "pandas.DataFrame", "datas.append", "len", "len"], "function", ["None"], ["", "def", "plot_attentions_pakdd", "(", "words", ",", "attentions", ",", "labels", ",", "title", ")", ":", "\n", "    ", "\"\"\"\n\n    :param words:\n    :param attention:\n    :return:\n    \"\"\"", "\n", "datas", "=", "[", "]", "\n", "data", "=", "{", "}", "\n", "columns", "=", "[", "]", "\n", "max_word_num_per_subplot", "=", "30", "\n", "for", "i", "in", "range", "(", "len", "(", "words", ")", ")", ":", "\n", "        ", "columns", ".", "append", "(", "words", "[", "i", "]", ")", "\n", "data", "[", "words", "[", "i", "]", "]", "=", "{", "}", "\n", "for", "j", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "            ", "data", "[", "words", "[", "i", "]", "]", "[", "labels", "[", "j", "]", "]", "=", "attentions", "[", "j", "]", "[", "i", "]", "\n", "", "if", "(", "i", ">", "0", "and", "i", "%", "max_word_num_per_subplot", "==", "0", ")", "or", "i", "==", "len", "(", "words", ")", "-", "1", ":", "\n", "            ", "d", "=", "pd", ".", "DataFrame", "(", "data", ",", "columns", "=", "columns", ")", "\n", "datas", ".", "append", "(", "d", ")", "\n", "data", "=", "{", "}", "\n", "columns", "=", "[", "]", "\n", "\n", "", "", "nrows", "=", "len", "(", "datas", ")", "\n", "f", ",", "axes", "=", "plt", ".", "subplots", "(", "nrows", "=", "nrows", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "80", ",", "len", "(", "labels", ")", "+", "5", ")", ")", "\n", "if", "nrows", "==", "1", ":", "\n", "        ", "axes", "=", "[", "axes", "]", "\n", "# sns.heatmap(d1, annot=True, ax=ax1)", "\n", "# https://blog.csdn.net/ChenHaoUESTC/article/details/79132602", "\n", "", "axes", "[", "0", "]", ".", "set_title", "(", "title", ")", "\n", "for", "i", ",", "axis", "in", "enumerate", "(", "axes", ")", ":", "\n", "# axis.legend(fontsize=4)", "\n", "# label_x = axis.get_xticklabels()", "\n", "# x_rotation = 0", "\n", "# plt.setp(label_x, rotation=x_rotation)", "\n", "# label_y = axis.get_yticklabels()", "\n", "# y_rotation = 190", "\n", "# plt.setp(label_y, rotation=y_rotation)", "\n", "        ", "sns_plot", "=", "sns", ".", "heatmap", "(", "datas", "[", "i", "]", ",", "annot", "=", "True", ",", "ax", "=", "axis", ",", "linewidths", "=", "1", ",", "vmax", "=", "1", ",", "fmt", "=", "'.2f'", ",", "vmin", "=", "0", ",", "center", "=", "0.3", ",", "\n", "cmap", "=", "'Reds'", ",", "annot_kws", "=", "{", "'size'", ":", "5", "}", ",", "cbar", "=", "True", ",", "cbar_kws", "=", "{", "\n", "'shrink'", ":", "1", "}", ")", "\n", "", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.attention_visualizer.plot_multi_attentions_of_sentence": [[115, 155], ["range", "len", "matplotlib.subplots", "enumerate", "len", "range", "range", "pandas.DataFrame", "datas.append", "axis.set_title", "axis.get_xticklabels", "matplotlib.setp", "seaborn.heatmap", "sns.heatmap.tick_params", "matplotlib.tight_layout", "matplotlib.subplots_adjust", "matplotlib.savefig", "matplotlib.show", "len", "len", "len", "range", "len", "str", "str", "len"], "function", ["None"], ["", "def", "plot_multi_attentions_of_sentence", "(", "words", ",", "attentions_list", ",", "labels", ",", "titles", ",", "savefig_filepath", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n\n    :param words:\n    :param attention:\n    :return:\n    \"\"\"", "\n", "datas", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "titles", ")", ")", ":", "\n", "        ", "data", "=", "{", "}", "\n", "columns", "=", "range", "(", "len", "(", "words", ")", ")", "\n", "if", "i", "==", "len", "(", "titles", ")", "-", "1", ":", "\n", "            ", "columns", "=", "[", "'%s-%s'", "%", "(", "str", "(", "words", "[", "k", "]", ")", ",", "str", "(", "k", ")", ")", "for", "k", "in", "range", "(", "len", "(", "words", ")", ")", "]", "\n", "", "for", "j", "in", "range", "(", "len", "(", "words", ")", ")", ":", "\n", "            ", "column_name", "=", "columns", "[", "j", "]", "\n", "data", "[", "column_name", "]", "=", "{", "labels", "[", "i", "]", ":", "attentions_list", "[", "i", "]", "[", "j", "]", "}", "\n", "", "data", "=", "pd", ".", "DataFrame", "(", "data", ",", "columns", "=", "columns", ")", "\n", "datas", ".", "append", "(", "data", ")", "\n", "\n", "", "nrows", "=", "len", "(", "datas", ")", "\n", "f", ",", "axes", "=", "plt", ".", "subplots", "(", "nrows", "=", "nrows", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "80", ",", "len", "(", "labels", ")", "+", "5", ")", ")", "\n", "if", "nrows", "==", "1", ":", "\n", "        ", "axes", "=", "[", "axes", "]", "\n", "# sns.heatmap(d1, annot=True, ax=ax1)", "\n", "# https://blog.csdn.net/ChenHaoUESTC/article/details/79132602", "\n", "\n", "", "for", "i", ",", "axis", "in", "enumerate", "(", "axes", ")", ":", "\n", "        ", "axis", ".", "set_title", "(", "titles", "[", "i", "]", ",", "fontsize", "=", "15", ")", "\n", "label_x", "=", "axis", ".", "get_xticklabels", "(", ")", "\n", "rotation", "=", "30", "\n", "plt", ".", "setp", "(", "label_x", ",", "rotation", "=", "rotation", ")", "\n", "sns_plot", "=", "sns", ".", "heatmap", "(", "datas", "[", "i", "]", ",", "annot", "=", "True", ",", "ax", "=", "axis", ",", "linewidths", "=", "1", ",", "vmax", "=", "1", ",", "fmt", "=", "'.2f'", ",", "vmin", "=", "0", ",", "center", "=", "0.3", ",", "\n", "cmap", "=", "'Reds'", ",", "annot_kws", "=", "{", "'size'", ":", "15", "}", ",", "cbar", "=", "True", ",", "cbar_kws", "=", "{", "'shrink'", ":", "1", "}", ")", "\n", "sns_plot", ".", "tick_params", "(", "labelsize", "=", "15", ")", "\n", "plt", ".", "tight_layout", "(", "pad", "=", "5", ")", "\n", "plt", ".", "subplots_adjust", "(", "left", "=", "0.05", ",", "right", "=", "0.95", ",", "top", "=", "0.90", ",", "bottom", "=", "0.09", ")", "\n", "", "if", "savefig_filepath", ":", "\n", "        ", "plt", ".", "savefig", "(", "savefig_filepath", ",", "format", "=", "'svg'", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.attention_visualizer.plot_multi_attentions_of_sentence_backup": [[157, 197], ["range", "len", "matplotlib.subplots", "enumerate", "len", "range", "range", "pandas.DataFrame", "datas.append", "axis.set_title", "axis.get_xticklabels", "matplotlib.setp", "seaborn.heatmap", "sns.heatmap.tick_params", "matplotlib.tight_layout", "matplotlib.subplots_adjust", "matplotlib.savefig", "matplotlib.show", "len", "len", "len", "range", "len", "str", "str", "len"], "function", ["None"], ["", "", "def", "plot_multi_attentions_of_sentence_backup", "(", "words", ",", "attentions_list", ",", "labels", ",", "titles", ",", "savefig_filepath", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n\n    :param words:\n    :param attention:\n    :return:\n    \"\"\"", "\n", "datas", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "titles", ")", ")", ":", "\n", "        ", "data", "=", "{", "}", "\n", "columns", "=", "range", "(", "len", "(", "words", ")", ")", "\n", "if", "i", "==", "len", "(", "titles", ")", "-", "1", ":", "\n", "            ", "columns", "=", "[", "'%s-%s'", "%", "(", "str", "(", "words", "[", "k", "]", ")", ",", "str", "(", "k", ")", ")", "for", "k", "in", "range", "(", "len", "(", "words", ")", ")", "]", "\n", "", "for", "j", "in", "range", "(", "len", "(", "words", ")", ")", ":", "\n", "            ", "column_name", "=", "columns", "[", "j", "]", "\n", "data", "[", "column_name", "]", "=", "{", "labels", "[", "i", "]", ":", "attentions_list", "[", "i", "]", "[", "j", "]", "}", "\n", "", "data", "=", "pd", ".", "DataFrame", "(", "data", ",", "columns", "=", "columns", ")", "\n", "datas", ".", "append", "(", "data", ")", "\n", "\n", "", "nrows", "=", "len", "(", "datas", ")", "\n", "f", ",", "axes", "=", "plt", ".", "subplots", "(", "nrows", "=", "nrows", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "80", ",", "len", "(", "labels", ")", "+", "5", ")", ")", "\n", "if", "nrows", "==", "1", ":", "\n", "        ", "axes", "=", "[", "axes", "]", "\n", "# sns.heatmap(d1, annot=True, ax=ax1)", "\n", "# https://blog.csdn.net/ChenHaoUESTC/article/details/79132602", "\n", "\n", "", "for", "i", ",", "axis", "in", "enumerate", "(", "axes", ")", ":", "\n", "        ", "axis", ".", "set_title", "(", "titles", "[", "i", "]", ")", "\n", "label_x", "=", "axis", ".", "get_xticklabels", "(", ")", "\n", "rotation", "=", "30", "\n", "plt", ".", "setp", "(", "label_x", ",", "rotation", "=", "rotation", ")", "\n", "sns_plot", "=", "sns", ".", "heatmap", "(", "datas", "[", "i", "]", ",", "annot", "=", "True", ",", "ax", "=", "axis", ",", "linewidths", "=", "1", ",", "vmax", "=", "1", ",", "fmt", "=", "'.2f'", ",", "vmin", "=", "0", ",", "center", "=", "0.3", ",", "\n", "cmap", "=", "'Reds'", ",", "annot_kws", "=", "{", "'size'", ":", "5", "}", ",", "cbar", "=", "True", ",", "cbar_kws", "=", "{", "'shrink'", ":", "1", "}", ")", "\n", "sns_plot", ".", "tick_params", "(", "labelsize", "=", "5", ")", "\n", "plt", ".", "tight_layout", "(", "pad", "=", "5", ")", "\n", "plt", ".", "subplots_adjust", "(", "left", "=", "0.05", ",", "right", "=", "0.95", ",", "top", "=", "0.90", ",", "bottom", "=", "0.09", ")", "\n", "", "if", "savefig_filepath", ":", "\n", "        ", "plt", ".", "savefig", "(", "savefig_filepath", ",", "format", "=", "'svg'", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.attention_visualizer.extract_numbers": [[199, 208], ["re.findall", "float"], "function", ["None"], ["", "", "def", "extract_numbers", "(", "text", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    I(0.00) go(0.00) -> 0.00 0.00\n    :param text:\n    :return:\n    \"\"\"", "\n", "nums", "=", "re", ".", "findall", "(", "'[0-9]\\.[0-9]+'", ",", "text", ")", "\n", "result", "=", "[", "float", "(", "num", ")", "for", "num", "in", "nums", "]", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.text_segmentation.ZhSplitStentence.__init__": [[12, 19], ["re.compile"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "cal_offset", ":", "bool", "=", "False", ",", "\n", "pattern", ":", "str", "=", "\"[\u3002\uff1f?\uff01!]\"", ")", ":", "\n", "\n", "        ", "self", ".", "_cal_offset", "=", "cal_offset", "\n", "self", ".", "_pattern", "=", "pattern", "\n", "self", ".", "_complie_pattern", "=", "re", ".", "compile", "(", "self", ".", "_pattern", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.text_segmentation.ZhSplitStentence.__call__": [[20, 38], ["text_segmentation.ZhSplitStentence._complie_pattern.findall", "list", "text.index", "text[].strip", "list.append", "len", "list.append"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "text", ":", "str", ")", ":", "\n", "\n", "        ", "end_tags", "=", "self", ".", "_complie_pattern", ".", "findall", "(", "text", ")", "\n", "\n", "sentences", "=", "list", "(", ")", "\n", "\n", "start", "=", "0", "\n", "for", "end_tag", "in", "end_tags", ":", "\n", "            ", "index", "=", "text", ".", "index", "(", "end_tag", ",", "start", ")", "\n", "\n", "sentence", "=", "text", "[", "start", ":", "index", "+", "1", "]", ".", "strip", "(", ")", "\n", "\n", "if", "len", "(", "sentence", ")", ">", "0", ":", "\n", "                ", "sentences", ".", "append", "(", "sentence", ")", "\n", "", "start", "=", "index", "+", "1", "\n", "", "if", "not", "sentences", ":", "\n", "            ", "sentences", ".", "append", "(", "text", ")", "\n", "", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.text_segmentation.ZhSplitParagraph.__init__": [[45, 52], ["re.compile"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "cal_offset", ":", "bool", "=", "False", ",", "\n", "pattern", ":", "str", "=", "\"\\r\\n\"", ")", ":", "\n", "\n", "        ", "self", ".", "_cal_offset", "=", "cal_offset", "\n", "self", ".", "_pattern", "=", "pattern", "\n", "self", ".", "_complie_pattern", "=", "re", ".", "compile", "(", "self", ".", "_pattern", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.text_segmentation.ZhSplitParagraph.__call__": [[53, 72], ["text_segmentation.ZhSplitParagraph._complie_pattern.findall", "list", "text.endswith", "text.index", "text[].strip", "list.append", "len", "list.append"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "text", ":", "str", ")", ":", "\n", "        ", "if", "not", "text", ".", "endswith", "(", "'\\r\\n'", ")", ":", "\n", "            ", "text", "+=", "'\\r\\n'", "\n", "", "end_tags", "=", "self", ".", "_complie_pattern", ".", "findall", "(", "text", ")", "\n", "\n", "sentences", "=", "list", "(", ")", "\n", "\n", "start", "=", "0", "\n", "for", "end_tag", "in", "end_tags", ":", "\n", "            ", "index", "=", "text", ".", "index", "(", "end_tag", ",", "start", ")", "\n", "\n", "sentence", "=", "text", "[", "start", ":", "index", "+", "1", "]", ".", "strip", "(", ")", "\n", "\n", "if", "len", "(", "sentence", ")", ">", "0", ":", "\n", "                ", "sentences", ".", "append", "(", "sentence", ")", "\n", "", "start", "=", "index", "+", "1", "\n", "", "if", "not", "sentences", ":", "\n", "            ", "sentences", ".", "append", "(", "text", ")", "\n", "", "return", "sentences", "\n", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.corenlp_sentence_parser.CorenlpParser.__init__": [[9, 11], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "nlp", ":", "my_corenlp", ".", "StanfordCoreNLP", ")", ":", "\n", "        ", "self", ".", "nlp", "=", "nlp", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.corenlp_sentence_parser.CorenlpParser.build_parse_child_dict": [[12, 34], ["[].append", "range", "range", "len", "len"], "methods", ["None"], ["", "def", "build_parse_child_dict", "(", "self", ",", "postags", ",", "arcs", ")", ":", "\n", "        ", "\"\"\"\n\n        \"\"\"", "\n", "format_parse_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "postags", ")", ")", "]", "\n", "child_dict_list", "=", "[", "{", "}", "for", "_", "in", "range", "(", "len", "(", "postags", ")", ")", "]", "\n", "for", "element", "in", "arcs", ":", "\n", "            ", "relation", ",", "start_index", ",", "end_index", "=", "element", "\n", "start_index", "-=", "1", "\n", "end_index", "-=", "1", "\n", "current_word", "=", "postags", "[", "end_index", "]", "[", "0", "]", "\n", "current_word_pos", "=", "postags", "[", "end_index", "]", "[", "1", "]", "\n", "head_word", "=", "postags", "[", "start_index", "]", "[", "0", "]", "if", "start_index", "!=", "-", "1", "else", "'ROOT'", "\n", "head_word_pos", "=", "postags", "[", "start_index", "]", "[", "1", "]", "if", "start_index", "!=", "-", "1", "else", "''", "\n", "format_parse_list", "[", "end_index", "]", "=", "[", "relation", ",", "current_word", ",", "end_index", ",", "current_word_pos", ",", "\n", "head_word", ",", "start_index", ",", "head_word_pos", "]", "\n", "if", "start_index", "==", "-", "1", ":", "\n", "                ", "continue", "\n", "", "if", "relation", "not", "in", "child_dict_list", "[", "start_index", "]", ":", "\n", "                ", "child_dict_list", "[", "start_index", "]", "[", "relation", "]", "=", "[", "]", "\n", "", "child_dict_list", "[", "start_index", "]", "[", "relation", "]", ".", "append", "(", "end_index", ")", "\n", "", "return", "child_dict_list", ",", "format_parse_list", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.corenlp_sentence_parser.CorenlpParser.parser_main": [[35, 46], ["corenlp_sentence_parser.CorenlpParser.nlp.word_tokenize", "corenlp_sentence_parser.CorenlpParser.nlp.pos_tag", "corenlp_sentence_parser.CorenlpParser.nlp.dependency_parse", "corenlp_sentence_parser.CorenlpParser.build_parse_child_dict"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.word_tokenize", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.pos_tag", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.dependency_parse", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.corenlp_sentence_parser.CorenlpParser.build_parse_child_dict"], ["", "def", "parser_main", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "\"\"\"\n\n        :param sentence:\n        :return:\n        \"\"\"", "\n", "words", "=", "self", ".", "nlp", ".", "word_tokenize", "(", "sentence", ")", "\n", "postags", "=", "self", ".", "nlp", ".", "pos_tag", "(", "sentence", ")", "\n", "arcs", "=", "self", ".", "nlp", ".", "dependency_parse", "(", "sentence", ")", "\n", "child_dict_list", ",", "format_parse_list", "=", "self", ".", "build_parse_child_dict", "(", "postags", ",", "arcs", ")", "\n", "return", "words", ",", "postags", ",", "arcs", ",", "child_dict_list", ",", "format_parse_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.TreeNode.__init__": [[18, 22], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "value", "=", "value", "\n", "self", ".", "parent", "=", "None", "\n", "self", ".", "children", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.TreeNode.__str__": [[23, 25], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.TreeNode.__repr__": [[26, 28], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.TreeNode.to_string": [[29, 44], ["stanfordnlp_sentence_constituency_parser.TreeNode.get_all_leaves"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.TreeNode.get_all_leaves"], ["", "@", "staticmethod", "\n", "def", "to_string", "(", "node", ",", "recursive", "=", "False", ",", "filter_node", ":", "list", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        :param node:\n        :param recursive:\n        :param filter_pos:\n        :return:\n        \"\"\"", "\n", "if", "node", "is", "None", ":", "\n", "            ", "return", "''", "\n", "", "if", "recursive", ":", "\n", "            ", "leaves", "=", "TreeNode", ".", "get_all_leaves", "(", "node", ",", "filter_node", "=", "filter_node", ")", "\n", "values_of_leaves", "=", "[", "leaf", ".", "value", "for", "leaf", "in", "leaves", "]", "\n", "return", "''", ".", "join", "(", "values_of_leaves", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.TreeNode.get_all_leaves": [[45, 65], ["len", "result.extend", "stanfordnlp_sentence_constituency_parser.TreeNode.get_all_leaves"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.TreeNode.get_all_leaves"], ["", "", "@", "staticmethod", "\n", "def", "get_all_leaves", "(", "root", ",", "filter_node", ":", "list", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        :param root:\n        :param filter_node:\n        :return:\n        \"\"\"", "\n", "if", "root", "is", "None", ":", "\n", "            ", "return", "[", "]", "\n", "", "if", "filter_node", "is", "None", ":", "\n", "            ", "filter_node", "=", "[", "]", "\n", "", "if", "len", "(", "root", ".", "children", ")", "==", "0", ":", "\n", "            ", "return", "[", "root", "]", "\n", "", "else", ":", "\n", "            ", "result", "=", "[", "]", "\n", "for", "child", "in", "root", ".", "children", ":", "\n", "                ", "if", "child", ".", "value", "not", "in", "filter_node", ":", "\n", "                    ", "result", ".", "extend", "(", "TreeNode", ".", "get_all_leaves", "(", "child", ",", "filter_node", "=", "filter_node", ")", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.TreeNode.get_np_ancestor": [[66, 82], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "get_np_ancestor", "(", "node", ",", "root", ")", ":", "\n", "        ", "\"\"\"\n        :param node:\n        :param root:\n        :return:\n        \"\"\"", "\n", "result", "=", "None", "\n", "if", "node", "is", "None", ":", "\n", "            ", "return", "result", "\n", "", "cursor", "=", "node", "\n", "while", "cursor", ".", "parent", "is", "not", "None", "and", "cursor", ".", "parent", "!=", "root", ":", "\n", "            ", "cursor", "=", "cursor", ".", "parent", "\n", "if", "cursor", ".", "value", "==", "'NP'", ":", "\n", "                ", "result", "=", "cursor", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.TreeNode.get_ancestor": [[83, 98], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_ancestor", "(", "node", ",", "root", ",", "target_ancestor_value", ",", "is_top", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "result", "=", "None", "\n", "if", "node", "is", "None", "or", "root", "is", "None", "or", "target_ancestor_value", "is", "None", ":", "\n", "            ", "return", "result", "\n", "", "cursor", "=", "node", "\n", "while", "cursor", ".", "parent", "is", "not", "None", "and", "cursor", ".", "parent", "!=", "root", ":", "\n", "            ", "cursor", "=", "cursor", ".", "parent", "\n", "if", "cursor", ".", "value", "==", "target_ancestor_value", ":", "\n", "                ", "result", "=", "cursor", "\n", "if", "not", "is_top", ":", "\n", "                    ", "break", "\n", "", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.TreeNode.is_sub_tree": [[99, 112], ["stanfordnlp_sentence_constituency_parser.TreeNode.is_sub_tree"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.TreeNode.is_sub_tree"], ["", "@", "staticmethod", "\n", "def", "is_sub_tree", "(", "tree_candidate", ",", "sub_tree_candidate", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "if", "tree_candidate", "is", "None", "or", "sub_tree_candidate", "is", "None", ":", "\n", "            ", "return", "False", "\n", "", "result", "=", "tree_candidate", "==", "sub_tree_candidate", "\n", "if", "result", ":", "\n", "            ", "return", "result", "\n", "", "else", ":", "\n", "            ", "for", "child", "in", "tree_candidate", ".", "children", ":", "\n", "                ", "result", "=", "result", "or", "TreeNode", ".", "is_sub_tree", "(", "child", ",", "sub_tree_candidate", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.TreeNode.find_corresponding_node": [[113, 126], ["stanfordnlp_sentence_constituency_parser.TreeNode.get_all_leaves", "len", "logging.error", "traceback.format_exc", "str"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.TreeNode.get_all_leaves"], ["", "", "@", "staticmethod", "\n", "def", "find_corresponding_node", "(", "root", ",", "value", ",", "original_index", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "leaves", "=", "TreeNode", ".", "get_all_leaves", "(", "root", ")", "\n", "if", "len", "(", "leaves", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "", "try", ":", "\n", "            ", "result", "=", "leaves", "[", "original_index", "]", "\n", "", "except", ":", "\n", "            ", "logging", ".", "error", "(", "'%s-%s'", "%", "(", "traceback", ".", "format_exc", "(", ")", ",", "str", "(", "original_index", ")", ")", ")", "\n", "result", "=", "None", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.sub_constituency_parser_result_generator": [[127, 148], ["enumerate", "constituency_parser_result.startswith", "result.append", "stack.append", "stack.pop", "len", "result.append"], "function", ["None"], ["", "", "def", "sub_constituency_parser_result_generator", "(", "constituency_parser_result", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "result", "=", "[", "]", "\n", "if", "not", "constituency_parser_result", ".", "startswith", "(", "'('", ")", ":", "\n", "        ", "result", ".", "append", "(", "constituency_parser_result", ")", "\n", "return", "result", "\n", "\n", "", "stack", "=", "[", "]", "\n", "start_index", "=", "-", "1", "\n", "for", "i", ",", "c", "in", "enumerate", "(", "constituency_parser_result", ")", ":", "\n", "        ", "if", "c", "==", "'('", ":", "\n", "            ", "stack", ".", "append", "(", "'('", ")", "\n", "if", "start_index", "==", "-", "1", ":", "\n", "                ", "start_index", "=", "i", "\n", "", "", "elif", "c", "==", "')'", ":", "\n", "            ", "stack", ".", "pop", "(", ")", "\n", "if", "len", "(", "stack", ")", "==", "0", ":", "\n", "                ", "result", ".", "append", "(", "constituency_parser_result", "[", "start_index", ":", "i", "+", "1", "]", ")", "\n", "start_index", "=", "-", "1", "\n", "", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.parse_corenlp_parse_result": [[150, 175], ["re.sub", "re.sub.startswith", "stanfordnlp_sentence_constituency_parser.TreeNode", "re.sub.index", "stanfordnlp_sentence_constituency_parser.TreeNode", "stanfordnlp_sentence_constituency_parser.sub_constituency_parser_result_generator", "stanfordnlp_sentence_constituency_parser.parse_corenlp_parse_result", "children.append"], "function", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.sub_constituency_parser_result_generator", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.stanfordnlp_sentence_constituency_parser.parse_corenlp_parse_result"], ["", "def", "parse_corenlp_parse_result", "(", "constituency_parser_result", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n\n    \"\"\"", "\n", "if", "constituency_parser_result", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "constituency_parser_result", "=", "re", ".", "sub", "(", "'\\\\s+'", ",", "' '", ",", "constituency_parser_result", ")", "\n", "if", "not", "constituency_parser_result", ".", "startswith", "(", "'('", ")", ":", "\n", "        ", "leaf_node", "=", "TreeNode", "(", "constituency_parser_result", ")", "\n", "return", "leaf_node", "\n", "", "else", ":", "\n", "        ", "constituency_parser_result", "=", "constituency_parser_result", "[", "1", ":", "-", "1", "]", "\n", "first_whitespace_index", "=", "constituency_parser_result", ".", "index", "(", "' '", ")", "\n", "value", "=", "constituency_parser_result", "[", ":", "first_whitespace_index", "]", "\n", "parent_node", "=", "TreeNode", "(", "value", ")", "\n", "constituency_parser_result", "=", "constituency_parser_result", "[", "first_whitespace_index", "+", "1", ":", "]", "\n", "sub_constituency_parser_results", "=", "sub_constituency_parser_result_generator", "(", "constituency_parser_result", ")", "\n", "children", "=", "[", "]", "\n", "for", "sub_constituency_parser_result", "in", "sub_constituency_parser_results", ":", "\n", "            ", "parse_result", "=", "parse_corenlp_parse_result", "(", "sub_constituency_parser_result", ")", "\n", "children", ".", "append", "(", "parse_result", ")", "\n", "", "for", "child", "in", "children", ":", "\n", "            ", "child", ".", "parent", "=", "parent_node", "\n", "", "parent_node", ".", "children", "=", "children", "\n", "return", "parent_node", "\n", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.cnn_encoder_seq2seq.CnnEncoder.__init__": [[54, 75], ["allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder.__init__", "enumerate", "torch.nn.Conv1d", "cnn_encoder_seq2seq.CnnEncoder.add_module", "len", "allennlp.nn.Activation.by_name"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "\n", "embedding_dim", ":", "int", ",", "\n", "num_filters", ":", "int", ",", "\n", "ngram_filter_sizes", ":", "Tuple", "[", "int", ",", "...", "]", "=", "(", "2", ",", "3", ",", "4", ",", "5", ")", ",", "# pylint: disable=bad-whitespace", "\n", "conv_layer_activation", ":", "Activation", "=", "None", ",", "\n", "output_dim", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "CnnEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_embedding_dim", "=", "embedding_dim", "\n", "self", ".", "_num_filters", "=", "num_filters", "\n", "self", ".", "_ngram_filter_sizes", "=", "ngram_filter_sizes", "\n", "self", ".", "_activation", "=", "conv_layer_activation", "or", "Activation", ".", "by_name", "(", "'relu'", ")", "(", ")", "\n", "self", ".", "_output_dim", "=", "output_dim", "\n", "\n", "self", ".", "_convolution_layers", "=", "[", "Conv1d", "(", "in_channels", "=", "self", ".", "_embedding_dim", ",", "\n", "out_channels", "=", "self", ".", "_num_filters", ",", "\n", "kernel_size", "=", "ngram_size", ")", "\n", "for", "ngram_size", "in", "self", ".", "_ngram_filter_sizes", "]", "\n", "for", "i", ",", "conv_layer", "in", "enumerate", "(", "self", ".", "_convolution_layers", ")", ":", "\n", "            ", "self", ".", "add_module", "(", "'conv_layer_%d'", "%", "i", ",", "conv_layer", ")", "\n", "\n", "", "self", ".", "_output_dim", "=", "self", ".", "_num_filters", "*", "len", "(", "self", ".", "_ngram_filter_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.cnn_encoder_seq2seq.CnnEncoder.get_input_dim": [[76, 79], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_input_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_embedding_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.cnn_encoder_seq2seq.CnnEncoder.get_output_dim": [[80, 83], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_output_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.cnn_encoder_seq2seq.CnnEncoder.forward": [[84, 112], ["torch.transpose", "range", "torch.cat", "len", "torch.nn.ConstantPad1d", "torch.nn.ConstantPad1d.", "getattr", "filter_outputs.append", "torch.transpose", "mask.unsqueeze().float", "cnn_encoder_seq2seq.CnnEncoder._activation", "getattr.", "mask.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tokens", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ")", ":", "# pylint: disable=arguments-differ", "\n", "        ", "if", "mask", "is", "not", "None", ":", "\n", "            ", "tokens", "=", "tokens", "*", "mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "float", "(", ")", "\n", "\n", "# Our input is expected to have shape `(batch_size, num_tokens, embedding_dim)`.  The", "\n", "# convolution layers expect input of shape `(batch_size, in_channels, sequence_length)`,", "\n", "# where the conv layer `in_channels` is our `embedding_dim`.  We thus need to transpose the", "\n", "# tensor first.", "\n", "", "tokens", "=", "torch", ".", "transpose", "(", "tokens", ",", "1", ",", "2", ")", "\n", "# Each convolution layer returns output of size `(batch_size, num_filters, pool_length)`,", "\n", "# where `pool_length = num_tokens - ngram_size + 1`.  We then do an activation function,", "\n", "# then do max pooling over each filter for the whole input sequence.  Because our max", "\n", "# pooling is simple, we just use `torch.max`.  The resultant tensor of has shape", "\n", "# `(batch_size, num_conv_layers * num_filters)`, which then gets projected using the", "\n", "# projection layer, if requested.", "\n", "\n", "filter_outputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_convolution_layers", ")", ")", ":", "\n", "            ", "ngram_filter_size", "=", "self", ".", "_ngram_filter_sizes", "[", "i", "]", "\n", "padder", "=", "nn", ".", "ConstantPad1d", "(", "(", "0", ",", "ngram_filter_size", "-", "1", ")", ",", "0", ")", "\n", "tokens_input", "=", "padder", "(", "tokens", ")", "\n", "convolution_layer", "=", "getattr", "(", "self", ",", "'conv_layer_{}'", ".", "format", "(", "i", ")", ")", "\n", "filter_outputs", ".", "append", "(", "\n", "self", ".", "_activation", "(", "convolution_layer", "(", "tokens_input", ")", ")", "\n", ")", "\n", "", "filter_outputs_transformed", "=", "[", "torch", ".", "transpose", "(", "e", ",", "1", ",", "2", ")", "for", "e", "in", "filter_outputs", "]", "\n", "result", "=", "torch", ".", "cat", "(", "filter_outputs_transformed", ",", "dim", "=", "-", "1", ")", "\n", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.__init__": [[17, 20], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "threshold", ":", "float", ")", ":", "\n", "        ", "self", ".", "threshold", "=", "threshold", "\n", "self", ".", "values", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.__call__": [[21, 52], ["allennlp_metrics.BinaryF1.unwrap_to_tensors", "gold_labels.numpy", "predictions.numpy", "predictions_np.astype.astype.astype", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "__call__", "(", "self", ",", "\n", "predictions", ":", "torch", ".", "Tensor", ",", "\n", "gold_labels", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        predictions : ``torch.Tensor``, required.\n            A tensor of predictions of shape (batch_size, ..., num_classes).\n        gold_labels : ``torch.Tensor``, required.\n            A tensor of integer class label of shape (batch_size, ...). It must be the same\n            shape as the ``predictions`` tensor without the ``num_classes`` dimension.\n        mask: ``torch.Tensor``, optional (default = None).\n            A masking tensor the same size as ``gold_labels``.\n        \"\"\"", "\n", "predictions", ",", "gold_labels", ",", "mask", "=", "self", ".", "unwrap_to_tensors", "(", "predictions", ",", "gold_labels", ",", "mask", ")", "\n", "\n", "gold_labels_np", "=", "gold_labels", ".", "numpy", "(", ")", "\n", "predictions_np", "=", "predictions", ".", "numpy", "(", ")", "\n", "predictions_np", "=", "predictions_np", ">=", "self", ".", "threshold", "\n", "predictions_np", "=", "predictions_np", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "precision", "=", "precision_score", "(", "gold_labels_np", ",", "predictions_np", ")", "\n", "recall", "=", "recall_score", "(", "gold_labels_np", ",", "predictions_np", ")", "\n", "f1", "=", "f1_score", "(", "gold_labels_np", ",", "predictions_np", ")", "\n", "\n", "self", ".", "values", "=", "{", "\n", "\"precision\"", ":", "precision", ",", "\n", "\"recall\"", ":", "recall", ",", "\n", "\"fscore\"", ":", "f1", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.get_metric": [[54, 62], ["allennlp_metrics.BinaryF1.reset"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.reset"], ["", "def", "get_metric", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Union", "[", "float", ",", "Tuple", "[", "float", ",", "...", "]", ",", "Dict", "[", "str", ",", "float", "]", ",", "Dict", "[", "str", ",", "List", "[", "float", "]", "]", "]", ":", "\n", "        ", "\"\"\"\n        Compute and return the metric. Optionally also call :func:`self.reset`.\n        \"\"\"", "\n", "result", "=", "self", ".", "values", "\n", "if", "reset", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.reset": [[63, 69], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Reset any accumulators or internal state.\n        \"\"\"", "\n", "self", ".", "threshold", "=", "0.5", "\n", "self", ".", "values", "=", "None", "", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AttentionInHtt.__init__": [[49, 54], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "bias", "=", "True", ",", "softmax", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "W", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "self", ".", "uw", "=", "nn", ".", "Linear", "(", "out_features", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "softmax", "=", "softmax", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AttentionInHtt.forward": [[55, 65], ["pytorch_models.AttentionInHtt.W", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "pytorch_models.AttentionInHtt.uw", "similarities.squeeze.squeeze.squeeze", "allennlp.nn.util.masked_softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "u", "=", "self", ".", "W", "(", "h", ")", "\n", "u", "=", "torch", ".", "tanh", "(", "u", ")", "\n", "similarities", "=", "self", ".", "uw", "(", "u", ")", "\n", "similarities", "=", "similarities", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "\n", "if", "self", ".", "softmax", ":", "\n", "            ", "alpha", "=", "allennlp_util", ".", "masked_softmax", "(", "similarities", ",", "mask", ")", "\n", "return", "alpha", "\n", "", "else", ":", "\n", "            ", "return", "similarities", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.DotProductAttentionInHtt.__init__": [[72, 76], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "bias", "=", "True", ",", "softmax", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "uw", "=", "nn", ".", "Linear", "(", "in_features", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "softmax", "=", "softmax", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.DotProductAttentionInHtt.forward": [[77, 85], ["pytorch_models.DotProductAttentionInHtt.uw", "similarities.squeeze.squeeze.squeeze", "allennlp.nn.util.masked_softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "similarities", "=", "self", ".", "uw", "(", "h", ")", "\n", "similarities", "=", "similarities", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "\n", "if", "self", ".", "softmax", ":", "\n", "            ", "alpha", "=", "allennlp_util", ".", "masked_softmax", "(", "similarities", ",", "mask", ")", "\n", "return", "alpha", "\n", "", "else", ":", "\n", "            ", "return", "similarities", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AverageAttention.__init__": [[92, 94], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AverageAttention.forward": [[95, 98], ["allennlp.nn.util.masked_softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "alpha", "=", "allennlp_util", ".", "masked_softmax", "(", "mask", ",", "mask", ")", "\n", "return", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.BernoulliAttentionInHtt.__init__": [[105, 109], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "W", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "self", ".", "uw", "=", "nn", ".", "Linear", "(", "out_features", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.BernoulliAttentionInHtt.forward": [[110, 117], ["pytorch_models.BernoulliAttentionInHtt.W", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "pytorch_models.BernoulliAttentionInHtt.uw", "similarities.squeeze.squeeze.squeeze", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "u", "=", "self", ".", "W", "(", "h", ")", "\n", "u", "=", "torch", ".", "tanh", "(", "u", ")", "\n", "similarities", "=", "self", ".", "uw", "(", "u", ")", "\n", "similarities", "=", "similarities", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "\n", "alpha", "=", "torch", ".", "sigmoid", "(", "similarities", ")", "\n", "return", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AttentionInCan.__init__": [[124, 130], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "bias", "=", "True", ",", "softmax", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "W1", "=", "nn", ".", "Linear", "(", "in_features", ",", "in_features", ",", "bias", ")", "\n", "self", ".", "W2", "=", "nn", ".", "Linear", "(", "in_features", ",", "in_features", ",", "bias", ")", "\n", "self", ".", "uw", "=", "nn", ".", "Linear", "(", "in_features", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "softmax", "=", "softmax", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AttentionInCan.forward": [[131, 143], ["pytorch_models.AttentionInCan.W1", "pytorch_models.AttentionInCan.W2", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "pytorch_models.AttentionInCan.uw", "similarities.squeeze.squeeze.squeeze", "allennlp.nn.util.masked_softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h1", ":", "torch", ".", "Tensor", ",", "h2", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "u1", "=", "self", ".", "W1", "(", "h1", ")", "\n", "u2", "=", "self", ".", "W2", "(", "h2", ")", "\n", "u", "=", "u1", "+", "u2", "\n", "u", "=", "torch", ".", "tanh", "(", "u", ")", "\n", "similarities", "=", "self", ".", "uw", "(", "u", ")", "\n", "similarities", "=", "similarities", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "\n", "if", "self", ".", "softmax", ":", "\n", "            ", "alpha", "=", "allennlp_util", ".", "masked_softmax", "(", "similarities", ",", "mask", ")", "\n", "return", "alpha", "\n", "", "else", ":", "\n", "            ", "return", "similarities", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.LocationMaskLayer.__init__": [[150, 154], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "location_num", ",", "configuration", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "location_num", "=", "location_num", "\n", "self", ".", "configuration", "=", "configuration", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.LocationMaskLayer.forward": [[155, 165], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "alpha.mm", "range", "abs"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "alpha", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "location_num", "=", "self", ".", "location_num", "\n", "location_matrix", "=", "torch", ".", "zeros", "(", "[", "location_num", ",", "location_num", "]", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "device", "=", "self", ".", "configuration", "[", "'device'", "]", ",", "\n", "requires_grad", "=", "False", ")", "\n", "for", "i", "in", "range", "(", "location_num", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "location_num", ")", ":", "\n", "                ", "location_matrix", "[", "i", ",", "j", "]", "=", "1", "-", "(", "abs", "(", "i", "-", "j", ")", "/", "location_num", ")", "\n", "", "", "result", "=", "alpha", ".", "mm", "(", "location_matrix", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutModel.__init__": [[169, 173], ["allennlp.models.Model.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ":", "Vocabulary", ",", "category_loss_weight", "=", "1", ",", "sentiment_loss_weight", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "category_loss_weight", "=", "category_loss_weight", "\n", "self", ".", "sentiment_loss_weight", "=", "sentiment_loss_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutModel.matrix_mul": [[174, 184], ["torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "isinstance", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "feature_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bias.expand", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh().unsqueeze.size", "torch.tanh().unsqueeze.size", "torch.tanh().unsqueeze.size", "torch.tanh().unsqueeze.size", "bias.size"], "methods", ["None"], ["", "def", "matrix_mul", "(", "self", ",", "input", ",", "weight", ",", "bias", "=", "False", ")", ":", "\n", "        ", "feature_list", "=", "[", "]", "\n", "for", "feature", "in", "input", ":", "\n", "            ", "feature", "=", "torch", ".", "mm", "(", "feature", ",", "weight", ")", "\n", "if", "isinstance", "(", "bias", ",", "torch", ".", "nn", ".", "parameter", ".", "Parameter", ")", ":", "\n", "                ", "feature", "=", "feature", "+", "bias", ".", "expand", "(", "feature", ".", "size", "(", ")", "[", "0", "]", ",", "bias", ".", "size", "(", ")", "[", "1", "]", ")", "\n", "", "feature", "=", "torch", ".", "tanh", "(", "feature", ")", ".", "unsqueeze", "(", "0", ")", "\n", "feature_list", ".", "append", "(", "feature", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "feature_list", ",", "0", ")", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutModel.element_wise_mul": [[185, 200], ["zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "feature_2.expand_as.expand_as.unsqueeze", "feature_2.expand_as.expand_as.expand_as", "feature.unsqueeze.unsqueeze.unsqueeze", "feature_list.append"], "methods", ["None"], ["", "def", "element_wise_mul", "(", "self", ",", "input1", ",", "input2", ",", "return_not_sum_result", "=", "False", ")", ":", "\n", "        ", "feature_list", "=", "[", "]", "\n", "for", "feature_1", ",", "feature_2", "in", "zip", "(", "input1", ",", "input2", ")", ":", "\n", "            ", "feature_2", "=", "feature_2", ".", "unsqueeze", "(", "1", ")", "\n", "feature_2", "=", "feature_2", ".", "expand_as", "(", "feature_1", ")", "\n", "feature", "=", "feature_1", "*", "feature_2", "\n", "feature", "=", "feature", ".", "unsqueeze", "(", "0", ")", "\n", "feature_list", ".", "append", "(", "feature", ")", "\n", "", "output", "=", "torch", ".", "cat", "(", "feature_list", ",", "0", ")", "\n", "\n", "result", "=", "torch", ".", "sum", "(", "output", ",", "1", ")", "\n", "if", "return_not_sum_result", ":", "\n", "            ", "return", "result", ",", "output", "\n", "", "else", ":", "\n", "            ", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutModel.reduce": [[201, 207], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "", "def", "reduce", "(", "self", ",", "nodes", ")", ":", "\n", "        ", "\"\"\"Take an average over all neighbor node features hu and use it to\n        overwrite the original node feature.\"\"\"", "\n", "m", "=", "nodes", ".", "mailbox", "[", "'m'", "]", "\n", "accum", "=", "torch", ".", "sum", "(", "m", ",", "1", ")", "\n", "return", "{", "'h'", ":", "accum", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutModel.pad_dgl_graph": [[208, 216], ["copy.deepcopy", "graph.number_of_nodes", "copy.deepcopy.add_nodes", "graphs_padded.append"], "methods", ["None"], ["", "def", "pad_dgl_graph", "(", "self", ",", "graphs", ",", "max_node_num", ")", ":", "\n", "        ", "graphs_padded", "=", "[", "]", "\n", "for", "graph", "in", "graphs", ":", "\n", "            ", "graph_padded", "=", "copy", ".", "deepcopy", "(", "graph", ")", "\n", "node_num", "=", "graph", ".", "number_of_nodes", "(", ")", "\n", "graph_padded", ".", "add_nodes", "(", "max_node_num", "-", "node_num", ")", "\n", "graphs_padded", ".", "append", "(", "graph_padded", ")", "\n", "", "return", "graphs_padded", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutModel.no_grad_for_acd_parameter": [[217, 219], ["pytorch_models.TextInAllAspectSentimentOutModel.set_grad_for_acd_parameter"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.set_grad_for_acd_parameter"], ["", "def", "no_grad_for_acd_parameter", "(", "self", ")", ":", "\n", "        ", "self", ".", "set_grad_for_acd_parameter", "(", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutModel.set_grad_for_acd_parameter": [[220, 222], ["None"], "methods", ["None"], ["", "def", "set_grad_for_acd_parameter", "(", "self", ",", "requires_grad", "=", "True", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutModel.set_grad_for_acsc_parameter": [[223, 225], ["None"], "methods", ["None"], ["", "def", "set_grad_for_acsc_parameter", "(", "self", ",", "requires_grad", "=", "True", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutModel._get_model_visualization_picture_filepath": [[226, 233], ["re.sub", "os.path.join", "str", "time.time"], "methods", ["None"], ["", "def", "_get_model_visualization_picture_filepath", "(", "self", ",", "configuration", ":", "dict", ",", "words", ":", "list", ")", ":", "\n", "        ", "savefig_dir", "=", "configuration", "[", "'savefig_dir'", "]", "\n", "if", "not", "savefig_dir", ":", "\n", "            ", "return", "None", "\n", "", "filename", "=", "'%s-%s.svg'", "%", "(", "'-'", ".", "join", "(", "words", "[", ":", "3", "]", ")", ",", "str", "(", "time", ".", "time", "(", ")", ")", ")", "\n", "filename", "=", "re", ".", "sub", "(", "'/'", ",", "''", ",", "filename", ")", "\n", "return", "os", ".", "path", ".", "join", "(", "savefig_dir", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyV5.__init__": [[236, 300], ["pytorch_models.TextInAllAspectSentimentOutModel.__init__", "len", "len", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "allennlp.training.metrics.CategoricalAccuracy", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1", "word_embedder.get_output_dim", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "pytorch_models.AttentionInHtt", "position_embedder.get_output_dim", "allennlp.modules.seq2vec_encoders.CnnEncoder", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "range", "int", "int", "range", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "int", "range", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "range", "len"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.cnn_encoder_seq2seq.CnnEncoder.get_output_dim", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.cnn_encoder_seq2seq.CnnEncoder.get_output_dim"], ["    ", "def", "__init__", "(", "self", ",", "word_embedder", ":", "TextFieldEmbedder", ",", "position_embedder", ":", "TextFieldEmbedder", ",", "\n", "aspect_embedder", ":", "TextFieldEmbedder", ",", "categories", ":", "list", ",", "polarities", ":", "list", ",", "vocab", ":", "Vocabulary", ",", "\n", "configuration", ":", "dict", ",", "category_loss_weight", "=", "1", ",", "sentiment_loss_weight", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ",", "category_loss_weight", "=", "category_loss_weight", ",", "sentiment_loss_weight", "=", "sentiment_loss_weight", ")", "\n", "self", ".", "configuration", "=", "configuration", "\n", "self", ".", "word_embedder", "=", "word_embedder", "\n", "self", ".", "position_embedder", "=", "position_embedder", "\n", "self", ".", "aspect_embedder", "=", "aspect_embedder", "\n", "self", ".", "categories", "=", "categories", "\n", "self", ".", "polarites", "=", "polarities", "\n", "self", ".", "category_num", "=", "len", "(", "categories", ")", "\n", "self", ".", "polarity_num", "=", "len", "(", "polarities", ")", "\n", "self", ".", "category_loss", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "self", ".", "sentiment_loss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "_accuracy", "=", "metrics", ".", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "_f1", "=", "allennlp_metrics", ".", "BinaryF1", "(", "0.5", ")", "\n", "\n", "word_embedding_dim", "=", "word_embedder", ".", "get_output_dim", "(", ")", "\n", "if", "self", ".", "configuration", "[", "'lstm_or_fc_after_embedding_layer'", "]", "==", "'fc'", ":", "\n", "            ", "self", ".", "embedding_layer_fc", "=", "nn", ".", "Linear", "(", "word_embedding_dim", ",", "word_embedding_dim", ",", "bias", "=", "True", ")", "\n", "", "elif", "self", ".", "configuration", "[", "'lstm_or_fc_after_embedding_layer'", "]", "==", "'bilstm'", ":", "\n", "            ", "self", ".", "embedding_layer_lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "word_embedding_dim", ",", "int", "(", "word_embedding_dim", "/", "2", ")", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "True", ",", "num_layers", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embedding_layer_lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "word_embedding_dim", ",", "word_embedding_dim", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "False", ",", "num_layers", "=", "1", ")", "\n", "", "self", ".", "embedding_layer_aspect_attentions", "=", "[", "AttentionInHtt", "(", "word_embedding_dim", ",", "\n", "word_embedding_dim", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "self", ".", "embedding_layer_aspect_attentions", "=", "nn", ".", "ModuleList", "(", "self", ".", "embedding_layer_aspect_attentions", ")", "\n", "\n", "lstm_input_size", "=", "word_embedding_dim", "\n", "if", "self", ".", "configuration", "[", "'position'", "]", ":", "\n", "            ", "lstm_input_size", "+=", "position_embedder", ".", "get_output_dim", "(", ")", "\n", "", "if", "self", ".", "configuration", "[", "'sentence_encoder_for_sentiment'", "]", "==", "'cnn'", ":", "\n", "            ", "ngram_filter_sizes", "=", "(", "2", ",", "3", ",", "4", ")", "\n", "self", ".", "cnn_encoder", "=", "CnnEncoder", "(", "lstm_input_size", ",", "int", "(", "word_embedding_dim", "/", "len", "(", "ngram_filter_sizes", ")", ")", ",", "\n", "ngram_filter_sizes", "=", "ngram_filter_sizes", ")", "\n", "", "else", ":", "\n", "            ", "num_layers", "=", "self", ".", "configuration", "[", "'lstm_layer_num_in_lstm'", "]", "\n", "self", ".", "lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "lstm_input_size", ",", "int", "(", "word_embedding_dim", "/", "2", ")", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "True", ",", "num_layers", "=", "num_layers", ",", "dropout", "=", "0.5", ")", "\n", "\n", "", "self", ".", "category_fcs", "=", "[", "nn", ".", "Linear", "(", "word_embedding_dim", ",", "1", ")", "for", "_", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "self", ".", "category_fcs", "=", "nn", ".", "ModuleList", "(", "self", ".", "category_fcs", ")", "\n", "\n", "if", "self", ".", "configuration", "[", "'lstm_layer_category_classifier'", "]", ":", "\n", "            ", "self", ".", "lstm_category_fcs", "=", "[", "nn", ".", "Linear", "(", "word_embedding_dim", ",", "1", ")", "for", "_", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "self", ".", "lstm_category_fcs", "=", "nn", ".", "ModuleList", "(", "self", ".", "lstm_category_fcs", ")", "\n", "\n", "", "sentiment_fc_input_size", "=", "word_embedding_dim", "\n", "if", "not", "self", ".", "configuration", "[", "'share_sentiment_classifier'", "]", ":", "\n", "            ", "self", ".", "sentiment_fcs", "=", "[", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "sentiment_fc_input_size", ",", "sentiment_fc_input_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "sentiment_fc_input_size", ",", "self", ".", "polarity_num", ")", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "self", ".", "sentiment_fcs", "=", "nn", ".", "ModuleList", "(", "self", ".", "sentiment_fcs", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "sentiment_fc", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "sentiment_fc_input_size", ",", "sentiment_fc_input_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "sentiment_fc_input_size", ",", "self", ".", "polarity_num", ")", ")", "\n", "\n", "", "self", ".", "dropout_after_embedding_layer", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "dropout_after_lstm_layer", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "# self.gc1 = DglGraphConvolution(word_embedding_dim, word_embedding_dim, configuration)", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyV5.set_grad_for_acd_parameter": [[303, 314], ["acd_layers.append", "acd_layers.append", "acd_layers.append", "acd_layers.append", "layer.named_parameters"], "methods", ["None"], ["", "def", "set_grad_for_acd_parameter", "(", "self", ",", "requires_grad", "=", "True", ")", ":", "\n", "        ", "acd_layers", "=", "[", "]", "\n", "if", "self", ".", "configuration", "[", "'lstm_or_fc_after_embedding_layer'", "]", "==", "'fc'", ":", "\n", "            ", "acd_layers", ".", "append", "(", "self", ".", "embedding_layer_fc", ")", "\n", "", "else", ":", "\n", "            ", "acd_layers", ".", "append", "(", "self", ".", "embedding_layer_lstm", ")", "\n", "", "acd_layers", ".", "append", "(", "self", ".", "embedding_layer_aspect_attentions", ")", "\n", "acd_layers", ".", "append", "(", "self", ".", "category_fcs", ")", "\n", "for", "layer", "in", "acd_layers", ":", "\n", "            ", "for", "name", ",", "value", "in", "layer", ".", "named_parameters", "(", ")", ":", "\n", "                ", "value", ".", "requires_grad", "=", "requires_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyV5.forward": [[315, 586], ["allennlp.nn.util.get_text_field_mask", "pytorch_models.AsMilSimultaneouslyV5.word_embedder", "range", "range", "pytorch_models.AsMilSimultaneouslyV5.dropout_after_embedding_layer", "pytorch_models.AsMilSimultaneouslyV5.dropout_after_lstm_layer", "range", "range", "pytorch_models.AsMilSimultaneouslyV5.embedding_layer_fc", "pytorch_models.AsMilSimultaneouslyV5.aspect_embedder().squeeze", "pytorch_models.AsMilSimultaneouslyV5.aspect_embedder", "embedding_layer_aspect_attention", "embedding_layer_category_alphas.append", "pytorch_models.AsMilSimultaneouslyV5.element_wise_mul", "embedding_layer_category_outputs.append", "pytorch_models.AsMilSimultaneouslyV5.position_embedder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytorch_models.AsMilSimultaneouslyV5.cnn_encoder", "pytorch_models.AsMilSimultaneouslyV5.lstm", "pytorch_models.AsMilSimultaneouslyV5.element_wise_mul", "lstm_layer_category_outputs.append", "fc", "final_category_outputs.append", "final_sentiment_outputs.append", "range", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytorch_models.AsMilSimultaneouslyV5._accuracy", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytorch_models.AsMilSimultaneouslyV5._f1", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "range", "pytorch_models.AsMilSimultaneouslyV5.pad_dgl_graph", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "pytorch_models.AsMilSimultaneouslyV5.embedding_layer_lstm", "[].unsqueeze", "range", "range", "[].expand_as", "range", "range", "sentiment_alpha.unsqueeze.unsqueeze.unsqueeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "lstm_layer_sentiment_outputs.append", "pytorch_models.AsMilSimultaneouslyV5.element_wise_mul", "lstm_layer_sentiment_outputs.append", "fc_lstm", "final_lstm_category_outputs.append", "category_labels.append", "polarity_labels.append", "polarity_masks.append", "pytorch_models.AsMilSimultaneouslyV5.category_loss", "pytorch_models.AsMilSimultaneouslyV5.sentiment_loss", "range", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "len", "nlp_tasks.utils.attention_visualizer.plot_multi_attentions_of_sentence_backup", "range", "tokens[].size", "pytorch_models.AsMilSimultaneouslyV5.gc_aspect_category", "pytorch_models.AsMilSimultaneouslyV5.aspect_embedder", "pytorch_models.AsMilSimultaneouslyV5.sentiment_fc", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "lstm_layer_words_sentiment_soft.append", "lstm_layer_words_sentiment_soft.append", "pytorch_models.AsMilSimultaneouslyV5.sentiment_fc", "final_category_outputs[].squeeze", "polarity_labels[].long", "pytorch_models.AsMilSimultaneouslyV5.category_loss", "len", "range", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "category_eye.to.to.to", "category_alpha_similarity.to.to.to", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "label[].detach().cpu().numpy", "sum", "[].detach().cpu().numpy", "[].detach().cpu().numpy", "[].detach().cpu().numpy().tolist", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "final_lstm_category_outputs[].squeeze", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "len", "torch.cat.t", "torch.cat.t", "torch.cat.t", "torch.cat.t", "e.split", "range", "range", "range", "int", "[].detach().cpu().numpy", "visual_attentions_sentiment.append", "labels_sentiment.append", "range", "titles_sentiment.extend", "nlp_tasks.utils.attention_visualizer.plot_multi_attentions_of_sentence_backup", "print", "range", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.mean.append", "torch.mean.append", "torch.mean.append", "torch.mean.append", "range", "range", "label[].detach().cpu", "[].detach().cpu", "str", "str", "[].detach().cpu", "[].detach().cpu().numpy", "[].detach().cpu().numpy().tolist", "labels_sentiment.append", "visual_attentions_sentiment.append", "category_alpha_of_one_sample[].unsqueeze", "category_alpha_of_one_sample[].unsqueeze", "len", "range", "len", "[].detach().cpu().numpy", "[].detach().cpu().numpy", "[].detach().cpu", "pytorch_models.AsMilSimultaneouslyV5.categories[].split", "len", "label[].detach", "[].detach", "[].detach", "[].detach().cpu", "[].detach().cpu().numpy", "str", "str", "str", "[].detach().cpu", "[].detach().cpu", "[].detach().cpu().numpy", "[].detach", "[].detach", "[].detach().cpu", "[].detach", "[].detach", "[].detach().cpu", "len", "len", "[].detach", "[].detach", "len"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.element_wise_mul", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.element_wise_mul", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.pad_dgl_graph", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.element_wise_mul", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.attention_visualizer.plot_multi_attentions_of_sentence_backup", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.attention_visualizer.plot_multi_attentions_of_sentence_backup"], ["", "", "", "def", "forward", "(", "self", ",", "tokens", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "label", ":", "torch", ".", "Tensor", ",", "position", ":", "torch", ".", "Tensor", ",", "\n", "polarity_mask", ":", "torch", ".", "Tensor", ",", "sample", ":", "list", ",", "aspects", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "mask", "=", "get_text_field_mask", "(", "tokens", ")", "\n", "word_embeddings", "=", "self", ".", "word_embedder", "(", "tokens", ")", "\n", "if", "self", ".", "configuration", "[", "'lstm_or_fc_after_embedding_layer'", "]", "==", "'fc'", ":", "\n", "            ", "word_embeddings_fc", "=", "self", ".", "embedding_layer_fc", "(", "word_embeddings", ")", "\n", "", "elif", "self", ".", "configuration", "[", "'lstm_or_fc_after_embedding_layer'", "]", "==", "'gcn'", ":", "\n", "            ", "max_len", "=", "tokens", "[", "'tokens'", "]", ".", "size", "(", ")", "[", "1", "]", "\n", "graphs", "=", "[", "e", "[", "3", "]", "for", "e", "in", "sample", "]", "\n", "graphs_padded", "=", "self", ".", "pad_dgl_graph", "(", "graphs", ",", "max_len", ")", "\n", "word_embeddings_fc", "=", "F", ".", "relu", "(", "self", ".", "gc_aspect_category", "(", "word_embeddings", ",", "graphs_padded", ")", ")", "\n", "", "else", ":", "\n", "            ", "word_embeddings_fc", ",", "(", "_", ",", "_", ")", "=", "self", ".", "embedding_layer_lstm", "(", "word_embeddings", ")", "\n", "\n", "", "aspects_separate", "=", "[", "{", "'aspect'", ":", "aspects", "[", "'aspect'", "]", "[", ":", ",", "i", "]", ".", "unsqueeze", "(", "1", ")", "}", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "aspect_embeddings_singles", "=", "[", "self", ".", "aspect_embedder", "(", "aspects_separate", "[", "i", "]", ")", ".", "squeeze", "(", "1", ")", "for", "i", "in", "\n", "range", "(", "self", ".", "category_num", ")", "]", "\n", "aspects_seprate_repeat", "=", "[", "{", "'aspect'", ":", "aspects_separate", "[", "i", "]", "[", "'aspect'", "]", ".", "expand_as", "(", "tokens", "[", "'tokens'", "]", ")", "}", "for", "i", "in", "\n", "range", "(", "self", ".", "category_num", ")", "]", "\n", "aspect_embeddings_separate", "=", "[", "self", ".", "aspect_embedder", "(", "aspects_seprate_repeat", "[", "i", "]", ")", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "\n", "embedding_layer_category_outputs", "=", "[", "]", "\n", "embedding_layer_category_alphas", "=", "[", "]", "\n", "embedding_layer_sentiment_outputs", "=", "[", "]", "\n", "embedding_layer_sentiment_alphas", "=", "[", "]", "\n", "\n", "embedding_layer_category_alphas", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "            ", "embedding_layer_aspect_attention", "=", "self", ".", "embedding_layer_aspect_attentions", "[", "i", "]", "\n", "alpha", "=", "embedding_layer_aspect_attention", "(", "word_embeddings_fc", ",", "mask", ")", "\n", "embedding_layer_category_alphas", ".", "append", "(", "alpha", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "            ", "alpha", "=", "embedding_layer_category_alphas", "[", "i", "]", "\n", "category_output", "=", "self", ".", "element_wise_mul", "(", "word_embeddings_fc", ",", "alpha", ",", "return_not_sum_result", "=", "False", ")", "\n", "embedding_layer_category_outputs", ".", "append", "(", "category_output", ")", "\n", "\n", "", "lstm_input", "=", "word_embeddings", "\n", "if", "self", ".", "configuration", "[", "'position'", "]", ":", "\n", "            ", "position_embeddings", "=", "self", ".", "position_embedder", "(", "position", ")", "\n", "lstm_input", "=", "torch", ".", "cat", "(", "[", "word_embeddings", ",", "position_embeddings", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "lstm_input", "=", "self", ".", "dropout_after_embedding_layer", "(", "lstm_input", ")", "\n", "\n", "if", "self", ".", "configuration", "[", "'sentence_encoder_for_sentiment'", "]", "==", "'cnn'", ":", "\n", "            ", "lstm_result", "=", "self", ".", "cnn_encoder", "(", "lstm_input", ",", "mask", ")", "\n", "", "else", ":", "\n", "            ", "lstm_result", ",", "_", "=", "self", ".", "lstm", "(", "lstm_input", ")", "\n", "", "lstm_result", "=", "self", ".", "dropout_after_lstm_layer", "(", "lstm_result", ")", "\n", "# lstm_result_with_position = torch.cat([lstm_result, position_embeddings], dim=-1)", "\n", "lstm_layer_category_outputs", "=", "[", "]", "\n", "lstm_layer_sentiment_outputs", "=", "[", "]", "\n", "lstm_layer_words_sentiment_soft", "=", "[", "]", "\n", "\n", "# max_len = tokens['tokens'].size()[1]", "\n", "# graphs = [e[3] for e in sample]", "\n", "# graphs_padded = self.pad_dgl_graph(graphs, max_len)", "\n", "# graph_output1 = F.relu(self.gc1(word_embeddings, graphs_padded))", "\n", "# graph_output2 = F.relu(self.gc2(graph_output1, graphs_padded))", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "            ", "alpha", "=", "embedding_layer_category_alphas", "[", "i", "]", "\n", "category_output", "=", "self", ".", "element_wise_mul", "(", "lstm_result", ",", "alpha", ",", "return_not_sum_result", "=", "False", ")", "\n", "lstm_layer_category_outputs", ".", "append", "(", "category_output", ")", "\n", "\n", "# sentiment", "\n", "# word_representation_for_sentiment = torch.cat([graph_output2, lstm_result], dim=-1)", "\n", "word_representation_for_sentiment", "=", "lstm_result", "\n", "sentiment_alpha", "=", "embedding_layer_category_alphas", "[", "i", "]", "\n", "if", "self", ".", "configuration", "[", "'mil'", "]", ":", "\n", "                ", "sentiment_alpha", "=", "sentiment_alpha", ".", "unsqueeze", "(", "1", ")", "\n", "if", "not", "self", ".", "configuration", "[", "'share_sentiment_classifier'", "]", ":", "\n", "                    ", "words_sentiment", "=", "self", ".", "sentiment_fcs", "[", "i", "]", "(", "word_representation_for_sentiment", ")", "\n", "", "else", ":", "\n", "                    ", "words_sentiment", "=", "self", ".", "sentiment_fc", "(", "word_representation_for_sentiment", ")", "\n", "", "if", "self", ".", "configuration", "[", "'mil_softmax'", "]", ":", "\n", "                    ", "words_sentiment_soft", "=", "torch", ".", "softmax", "(", "words_sentiment", ",", "dim", "=", "-", "1", ")", "\n", "lstm_layer_words_sentiment_soft", ".", "append", "(", "words_sentiment_soft", ")", "\n", "", "else", ":", "\n", "                    ", "words_sentiment_soft", "=", "words_sentiment", "\n", "lstm_layer_words_sentiment_soft", ".", "append", "(", "torch", ".", "softmax", "(", "words_sentiment", ",", "dim", "=", "-", "1", ")", ")", "\n", "", "sentiment_output", "=", "torch", ".", "matmul", "(", "sentiment_alpha", ",", "words_sentiment_soft", ")", ".", "squeeze", "(", "1", ")", "# batch_size x 2*hidden_dim", "\n", "lstm_layer_sentiment_outputs", ".", "append", "(", "sentiment_output", ")", "\n", "", "else", ":", "\n", "                ", "sentiment_output_temp", "=", "self", ".", "element_wise_mul", "(", "word_representation_for_sentiment", ",", "sentiment_alpha", ",", "\n", "return_not_sum_result", "=", "False", ")", "\n", "if", "not", "self", ".", "configuration", "[", "'share_sentiment_classifier'", "]", ":", "\n", "                    ", "sentiment_output", "=", "self", ".", "sentiment_fcs", "[", "i", "]", "(", "sentiment_output_temp", ")", "\n", "", "else", ":", "\n", "                    ", "sentiment_output", "=", "self", ".", "sentiment_fc", "(", "sentiment_output_temp", ")", "\n", "", "lstm_layer_sentiment_outputs", ".", "append", "(", "sentiment_output", ")", "\n", "\n", "", "", "final_category_outputs", "=", "[", "]", "\n", "final_lstm_category_outputs", "=", "[", "]", "\n", "final_sentiment_outputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "            ", "fc", "=", "self", ".", "category_fcs", "[", "i", "]", "\n", "category_output", "=", "embedding_layer_category_outputs", "[", "i", "]", "\n", "final_category_output", "=", "fc", "(", "category_output", ")", "\n", "final_category_outputs", ".", "append", "(", "final_category_output", ")", "\n", "\n", "if", "self", ".", "configuration", "[", "'lstm_layer_category_classifier'", "]", ":", "\n", "                ", "fc_lstm", "=", "self", ".", "lstm_category_fcs", "[", "i", "]", "\n", "lstm_category_output", "=", "lstm_layer_category_outputs", "[", "i", "]", "\n", "final_lstm_category_output", "=", "fc_lstm", "(", "lstm_category_output", ")", "\n", "final_lstm_category_outputs", ".", "append", "(", "final_lstm_category_output", ")", "\n", "\n", "", "final_sentiment_output", "=", "lstm_layer_sentiment_outputs", "[", "i", "]", "\n", "final_sentiment_outputs", ".", "append", "(", "final_sentiment_output", ")", "\n", "\n", "", "output", "=", "{", "}", "\n", "output", "[", "'alpha'", "]", "=", "embedding_layer_category_alphas", "\n", "if", "label", "is", "not", "None", ":", "\n", "            ", "category_labels", "=", "[", "]", "\n", "polarity_labels", "=", "[", "]", "\n", "polarity_masks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "                ", "category_labels", ".", "append", "(", "label", "[", ":", ",", "i", "]", ")", "\n", "polarity_labels", ".", "append", "(", "label", "[", ":", ",", "i", "+", "self", ".", "category_num", "]", ")", "\n", "polarity_masks", ".", "append", "(", "polarity_mask", "[", ":", ",", "i", "]", ")", "\n", "", "loss", "=", "0", "\n", "total_category_loss", "=", "0", "\n", "total_sentiment_loss", "=", "0", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "                ", "category_temp_loss", "=", "self", ".", "category_loss", "(", "final_category_outputs", "[", "i", "]", ".", "squeeze", "(", "dim", "=", "-", "1", ")", ",", "category_labels", "[", "i", "]", ")", "\n", "sentiment_temp_loss", "=", "self", ".", "sentiment_loss", "(", "final_sentiment_outputs", "[", "i", "]", ",", "polarity_labels", "[", "i", "]", ".", "long", "(", ")", ")", "\n", "total_category_loss", "+=", "category_temp_loss", "\n", "if", "not", "self", ".", "configuration", "[", "'only_acd'", "]", ":", "\n", "                    ", "total_sentiment_loss", "+=", "sentiment_temp_loss", "\n", "", "if", "self", ".", "configuration", "[", "'lstm_layer_category_classifier'", "]", ":", "\n", "                    ", "lstm_category_temp_loss", "=", "self", ".", "category_loss", "(", "final_lstm_category_outputs", "[", "i", "]", ".", "squeeze", "(", "dim", "=", "-", "1", ")", ",", "\n", "category_labels", "[", "i", "]", ")", "\n", "total_category_loss", "+=", "lstm_category_temp_loss", "\n", "", "", "loss", "=", "self", ".", "category_loss_weight", "*", "total_category_loss", "+", "self", ".", "sentiment_loss_weight", "*", "total_sentiment_loss", "\n", "\n", "# Sparse Regularization Orthogonal Regularization", "\n", "if", "self", ".", "configuration", "[", "'sparse_reg'", "]", "or", "self", ".", "configuration", "[", "'orthogonal_reg'", "]", ":", "\n", "                ", "reg_loss", "=", "0", "\n", "for", "j", "in", "range", "(", "len", "(", "sample", ")", ")", ":", "\n", "                    ", "polarity_mask_of_one_sample", "=", "polarity_mask", "[", "j", "]", "\n", "category_alpha_of_one_sample", "=", "[", "embedding_layer_category_alphas", "[", "k", "]", "[", "j", "]", "for", "k", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "category_alpha_of_mentioned", "=", "[", "]", "\n", "category_alpha_of_not_mentioned", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "                        ", "if", "polarity_mask_of_one_sample", "[", "k", "]", "==", "1", ":", "\n", "                            ", "category_alpha_of_mentioned", ".", "append", "(", "category_alpha_of_one_sample", "[", "k", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                            ", "category_alpha_of_not_mentioned", ".", "append", "(", "category_alpha_of_one_sample", "[", "k", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "", "if", "len", "(", "category_alpha_of_not_mentioned", ")", "!=", "0", ":", "\n", "                        ", "category_alpha_of_not_mentioned", "=", "torch", ".", "cat", "(", "category_alpha_of_not_mentioned", ",", "dim", "=", "0", ")", "\n", "category_alpha_of_not_mentioned", "=", "torch", ".", "mean", "(", "category_alpha_of_not_mentioned", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "category_alpha_of_mentioned", ".", "append", "(", "category_alpha_of_not_mentioned", ")", "\n", "\n", "", "category_eye", "=", "torch", ".", "eye", "(", "len", "(", "category_alpha_of_mentioned", ")", ")", "\n", "category_alpha_of_mentioned", "=", "torch", ".", "cat", "(", "category_alpha_of_mentioned", ",", "dim", "=", "0", ")", "\n", "category_alpha_similarity", "=", "torch", ".", "mm", "(", "category_alpha_of_mentioned", ",", "category_alpha_of_mentioned", ".", "t", "(", ")", ")", "\n", "\n", "if", "self", ".", "configuration", "[", "'sparse_reg'", "]", "and", "self", ".", "configuration", "[", "'orthogonal_reg'", "]", ":", "\n", "                        ", "pass", "\n", "", "elif", "self", ".", "configuration", "[", "'sparse_reg'", "]", ":", "\n", "                        ", "for", "m", "in", "range", "(", "len", "(", "category_alpha_of_mentioned", ")", ")", ":", "\n", "                            ", "for", "n", "in", "range", "(", "len", "(", "category_alpha_of_mentioned", ")", ")", ":", "\n", "                                ", "if", "m", "!=", "n", ":", "\n", "                                    ", "category_eye", "[", "m", "]", "[", "n", "]", "=", "category_alpha_similarity", "[", "m", "]", "[", "n", "]", "\n", "", "", "", "", "else", ":", "\n", "# orthogonal_reg", "\n", "                        ", "for", "m", "in", "range", "(", "len", "(", "category_alpha_of_mentioned", ")", ")", ":", "\n", "                            ", "category_eye", "[", "m", "]", "[", "m", "]", "=", "category_alpha_similarity", "[", "m", "]", "[", "m", "]", "\n", "# category_eye = nn_util.move_to_device(category_eye, self.configuration['device'])", "\n", "", "", "category_eye", "=", "category_eye", ".", "to", "(", "self", ".", "configuration", "[", "'device'", "]", ")", "\n", "category_alpha_similarity", "=", "category_alpha_similarity", ".", "to", "(", "self", ".", "configuration", "[", "'device'", "]", ")", "\n", "category_reg_loss", "=", "category_alpha_similarity", "-", "category_eye", "\n", "category_reg_loss", "=", "torch", ".", "norm", "(", "category_reg_loss", ")", "\n", "reg_loss", "+=", "category_reg_loss", "\n", "", "loss", "+=", "(", "reg_loss", "*", "self", ".", "configuration", "[", "'attention_lamda'", "]", "/", "len", "(", "sample", ")", ")", "\n", "\n", "# sentiment accuracy", "\n", "", "sentiment_logit", "=", "torch", ".", "cat", "(", "final_sentiment_outputs", ")", "\n", "sentiment_label", "=", "torch", ".", "cat", "(", "polarity_labels", ")", "\n", "sentiment_mask", "=", "torch", ".", "cat", "(", "polarity_masks", ")", "\n", "self", ".", "_accuracy", "(", "sentiment_logit", ",", "sentiment_label", ",", "sentiment_mask", ")", "\n", "\n", "# category f1", "\n", "final_category_outputs_prob", "=", "[", "torch", ".", "sigmoid", "(", "e", ")", "for", "e", "in", "final_category_outputs", "]", "\n", "category_prob", "=", "torch", ".", "cat", "(", "final_category_outputs_prob", ")", ".", "squeeze", "(", ")", "\n", "category_label", "=", "torch", ".", "cat", "(", "category_labels", ")", "\n", "self", ".", "_f1", "(", "category_prob", ",", "category_label", ")", "\n", "\n", "output", "[", "'loss'", "]", "=", "loss", "\n", "\n", "# visualize attention", "\n", "", "pred_category", "=", "[", "torch", ".", "sigmoid", "(", "e", ")", "for", "e", "in", "final_category_outputs", "]", "\n", "pred_sentiment", "=", "[", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "e", ",", "dim", "=", "-", "1", ")", "for", "e", "in", "final_sentiment_outputs", "]", "\n", "output", "[", "'pred_category'", "]", "=", "pred_category", "\n", "output", "[", "'pred_sentiment'", "]", "=", "pred_sentiment", "\n", "output", "[", "'embedding_layer_category_alphas'", "]", "=", "embedding_layer_category_alphas", "\n", "output", "[", "'lstm_layer_words_sentiment_soft'", "]", "=", "lstm_layer_words_sentiment_soft", "\n", "if", "self", ".", "configuration", "[", "'visualize_attention'", "]", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "sample", ")", ")", ":", "\n", "                ", "words", "=", "sample", "[", "i", "]", "[", "2", "]", "\n", "# if not ('while' in words and 'there' in words):", "\n", "#     continue", "\n", "\n", "attention_labels", "=", "[", "e", ".", "split", "(", "'/'", ")", "[", "0", "]", "for", "e", "in", "self", ".", "categories", "]", "\n", "\n", "label_true", "=", "label", "[", "i", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", ":", "self", ".", "category_num", "]", "\n", "if", "sum", "(", "label_true", ")", "<=", "1", ":", "\n", "                    ", "continue", "\n", "# category", "\n", "", "visual_attentions_category", "=", "[", "embedding_layer_category_alphas", "[", "j", "]", "[", "i", "]", "[", ":", "len", "(", "words", ")", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "titles", "=", "[", "'true: %s - pred: %s'", "%", "(", "str", "(", "label", "[", "i", "]", "[", "j", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "str", "(", "pred_category", "[", "j", "]", "[", "i", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "attention_visualizer", ".", "plot_multi_attentions_of_sentence_backup", "(", "words", ",", "visual_attentions_category", ",", "\n", "attention_labels", ",", "titles", ")", "\n", "# savefig_filepath = super()._get_model_visualization_picture_filepath(self.configuration, words)", "\n", "# attention_visualizer.plot_multi_attentions_of_sentence(words, visual_attentions_category,", "\n", "#                                                        attention_labels, titles,", "\n", "#                                                        savefig_filepath=savefig_filepath)", "\n", "\n", "# sentiment embedding layer", "\n", "# visual_attentions = [embedding_layer_sentiment_alphas[j][i][: len(words)].detach().cpu().numpy()", "\n", "#                      for j in range(self.category_num)]", "\n", "# titles = ['true: %s - pred: %s - %s' % (str(label[i + self.category_num][j].detach().cpu().numpy()),", "\n", "#                                         str(pred_sentiment[j][i].detach().cpu().numpy()),", "\n", "#                                         str(self.polarites))", "\n", "#           for j in range(self.category_num)]", "\n", "# attention_visualizer.plot_multi_attentions_of_sentence(words, visual_attentions, attention_labels,", "\n", "#                                                        titles)", "\n", "\n", "# sentiment lstm layer", "\n", "# visual_attentions = [lstm_layer_sentiment_alphas[j][i][: len(words)].detach().cpu().numpy()", "\n", "#                      for j in range(self.category_num)]", "\n", "# titles = ['true: %s - pred: %s - %s' % (str(label[i + self.category_num][j].detach().cpu().numpy()),", "\n", "#                                         str(pred_sentiment[j][i].detach().cpu().numpy()),", "\n", "#                                         str(self.polarites))", "\n", "#           for j in range(self.category_num)]", "\n", "# attention_visualizer.plot_multi_attentions_of_sentence(words, visual_attentions, attention_labels,", "\n", "#                                                        titles)", "\n", "\n", "# sentiment lstm layer", "\n", "visual_attentions_sentiment_temp", "=", "[", "lstm_layer_words_sentiment_soft", "[", "j", "]", "[", "i", "]", "[", ":", "len", "(", "words", ")", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "                    ", "c_label", "=", "label", "[", "i", "]", "[", "j", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "if", "c_label", "==", "1", ":", "\n", "                        ", "visual_attentions_sentiment", "=", "[", "]", "\n", "labels_sentiment", "=", "[", "]", "\n", "sentiment_true_index", "=", "int", "(", "label", "[", "i", "]", "[", "j", "+", "self", ".", "category_num", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "if", "sentiment_true_index", "==", "-", "100", ":", "\n", "                            ", "continue", "\n", "", "titles_sentiment", "=", "[", "'true: %s - pred: %s - %s'", "%", "(", "str", "(", "self", ".", "polarites", "[", "sentiment_true_index", "]", ")", ",", "\n", "str", "(", "pred_sentiment", "[", "j", "]", "[", "i", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "str", "(", "self", ".", "polarites", ")", ")", "]", "\n", "c_attention", "=", "embedding_layer_category_alphas", "[", "j", "]", "[", "i", "]", "[", ":", "len", "(", "words", ")", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "visual_attentions_sentiment", ".", "append", "(", "c_attention", ")", "\n", "labels_sentiment", ".", "append", "(", "self", ".", "categories", "[", "j", "]", ".", "split", "(", "'/'", ")", "[", "0", "]", ")", "\n", "\n", "s_distributions", "=", "visual_attentions_sentiment_temp", "[", "j", "]", "\n", "for", "k", "in", "range", "(", "self", ".", "polarity_num", ")", ":", "\n", "                            ", "labels_sentiment", ".", "append", "(", "self", ".", "polarites", "[", "k", "]", ")", "\n", "visual_attentions_sentiment", ".", "append", "(", "s_distributions", "[", ":", ",", "k", "]", ")", "\n", "", "titles_sentiment", ".", "extend", "(", "[", "''", "]", "*", "3", ")", "\n", "attention_visualizer", ".", "plot_multi_attentions_of_sentence_backup", "(", "words", ",", "visual_attentions_sentiment", ",", "\n", "labels_sentiment", ",", "\n", "titles_sentiment", ")", "\n", "# savefig_filepath = super()._get_model_visualization_picture_filepath(self.configuration, words)", "\n", "# attention_visualizer.plot_multi_attentions_of_sentence(words, visual_attentions_category,", "\n", "#                                                        attention_labels, titles,", "\n", "#                                                        savefig_filepath=savefig_filepath)", "\n", "print", "(", ")", "\n", "", "", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyV5.get_metrics": [[587, 593], ["pytorch_models.AsMilSimultaneouslyV5._accuracy.get_metric", "pytorch_models.AsMilSimultaneouslyV5._f1.get_metric"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.get_metric", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.get_metric"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "metrics", "=", "{", "\n", "'accuracy'", ":", "self", ".", "_accuracy", ".", "get_metric", "(", "reset", ")", ",", "\n", "'category_f1'", ":", "self", ".", "_f1", ".", "get_metric", "(", "reset", ")", "[", "'fscore'", "]", "\n", "}", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.__init__": [[596, 630], ["allennlp.models.Model.__init__", "len", "len", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "allennlp.training.metrics.CategoricalAccuracy", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1", "word_embedder.get_output_dim", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "position_embedder.get_output_dim", "pytorch_models.AttentionInHtt", "int", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "range", "range", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.cnn_encoder_seq2seq.CnnEncoder.get_output_dim", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.cnn_encoder_seq2seq.CnnEncoder.get_output_dim"], ["    ", "def", "__init__", "(", "self", ",", "word_embedder", ":", "TextFieldEmbedder", ",", "position_embedder", ":", "TextFieldEmbedder", ",", "\n", "categories", ":", "list", ",", "polarities", ":", "list", ",", "vocab", ":", "Vocabulary", ",", "configuration", ":", "dict", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "configuration", "=", "configuration", "\n", "self", ".", "word_embedder", "=", "word_embedder", "\n", "self", ".", "position_embedder", "=", "position_embedder", "\n", "self", ".", "categories", "=", "categories", "\n", "self", ".", "polarites", "=", "polarities", "\n", "self", ".", "category_num", "=", "len", "(", "categories", ")", "\n", "self", ".", "polarity_num", "=", "len", "(", "polarities", ")", "\n", "self", ".", "category_loss", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "self", ".", "sentiment_loss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "_accuracy", "=", "metrics", ".", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "_f1", "=", "allennlp_metrics", ".", "BinaryF1", "(", "0.5", ")", "\n", "\n", "word_embedding_dim", "=", "word_embedder", ".", "get_output_dim", "(", ")", "\n", "if", "self", ".", "configuration", "[", "'position'", "]", ":", "\n", "            ", "word_embedding_dim", "+=", "position_embedder", ".", "get_output_dim", "(", ")", "\n", "", "self", ".", "embedding_layer_fc", "=", "nn", ".", "Linear", "(", "word_embedding_dim", ",", "word_embedding_dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "embedding_layer_aspect_attentions", "=", "[", "AttentionInHtt", "(", "word_embedding_dim", ",", "\n", "word_embedding_dim", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "\n", "lstm_input_size", "=", "word_embedding_dim", "\n", "num_layers", "=", "3", "\n", "self", ".", "lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "lstm_input_size", ",", "int", "(", "word_embedding_dim", "/", "2", ")", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "True", ",", "num_layers", "=", "num_layers", ",", "dropout", "=", "0.5", ")", "\n", "\n", "self", ".", "category_fcs", "=", "[", "nn", ".", "Linear", "(", "word_embedding_dim", ",", "1", ")", "for", "_", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "if", "self", ".", "configuration", "[", "'lstm_layer_category_classifier'", "]", ":", "\n", "            ", "self", ".", "lstm_category_fcs", "=", "[", "nn", ".", "Linear", "(", "word_embedding_dim", ",", "1", ")", "for", "_", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "", "self", ".", "sentiment_fc", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "word_embedding_dim", ",", "word_embedding_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "word_embedding_dim", ",", "self", ".", "polarity_num", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.matrix_mul": [[634, 644], ["torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "isinstance", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "torch.tanh().unsqueeze", "feature_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bias.expand", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh().unsqueeze.size", "torch.tanh().unsqueeze.size", "torch.tanh().unsqueeze.size", "torch.tanh().unsqueeze.size", "bias.size"], "methods", ["None"], ["", "def", "matrix_mul", "(", "self", ",", "input", ",", "weight", ",", "bias", "=", "False", ")", ":", "\n", "        ", "feature_list", "=", "[", "]", "\n", "for", "feature", "in", "input", ":", "\n", "            ", "feature", "=", "torch", ".", "mm", "(", "feature", ",", "weight", ")", "\n", "if", "isinstance", "(", "bias", ",", "torch", ".", "nn", ".", "parameter", ".", "Parameter", ")", ":", "\n", "                ", "feature", "=", "feature", "+", "bias", ".", "expand", "(", "feature", ".", "size", "(", ")", "[", "0", "]", ",", "bias", ".", "size", "(", ")", "[", "1", "]", ")", "\n", "", "feature", "=", "torch", ".", "tanh", "(", "feature", ")", ".", "unsqueeze", "(", "0", ")", "\n", "feature_list", ".", "append", "(", "feature", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "feature_list", ",", "0", ")", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.element_wise_mul": [[645, 660], ["zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "feature_2.expand_as.expand_as.unsqueeze", "feature_2.expand_as.expand_as.expand_as", "feature.unsqueeze.unsqueeze.unsqueeze", "feature_list.append"], "methods", ["None"], ["", "def", "element_wise_mul", "(", "self", ",", "input1", ",", "input2", ",", "return_not_sum_result", "=", "False", ")", ":", "\n", "        ", "feature_list", "=", "[", "]", "\n", "for", "feature_1", ",", "feature_2", "in", "zip", "(", "input1", ",", "input2", ")", ":", "\n", "            ", "feature_2", "=", "feature_2", ".", "unsqueeze", "(", "1", ")", "\n", "feature_2", "=", "feature_2", ".", "expand_as", "(", "feature_1", ")", "\n", "feature", "=", "feature_1", "*", "feature_2", "\n", "feature", "=", "feature", ".", "unsqueeze", "(", "0", ")", "\n", "feature_list", ".", "append", "(", "feature", ")", "\n", "", "output", "=", "torch", ".", "cat", "(", "feature_list", ",", "0", ")", "\n", "\n", "result", "=", "torch", ".", "sum", "(", "output", ",", "1", ")", "\n", "if", "return_not_sum_result", ":", "\n", "            ", "return", "result", ",", "output", "\n", "", "else", ":", "\n", "            ", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.reduce": [[661, 667], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "", "def", "reduce", "(", "self", ",", "nodes", ")", ":", "\n", "        ", "\"\"\"Take an average over all neighbor node features hu and use it to\n        overwrite the original node feature.\"\"\"", "\n", "m", "=", "nodes", ".", "mailbox", "[", "'m'", "]", "\n", "accum", "=", "torch", ".", "sum", "(", "m", ",", "1", ")", "\n", "return", "{", "'h'", ":", "accum", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.pad_dgl_graph": [[668, 676], ["copy.deepcopy", "graph.number_of_nodes", "copy.deepcopy.add_nodes", "graphs_padded.append"], "methods", ["None"], ["", "def", "pad_dgl_graph", "(", "self", ",", "graphs", ",", "max_node_num", ")", ":", "\n", "        ", "graphs_padded", "=", "[", "]", "\n", "for", "graph", "in", "graphs", ":", "\n", "            ", "graph_padded", "=", "copy", ".", "deepcopy", "(", "graph", ")", "\n", "node_num", "=", "graph", ".", "number_of_nodes", "(", ")", "\n", "graph_padded", ".", "add_nodes", "(", "max_node_num", "-", "node_num", ")", "\n", "graphs_padded", ".", "append", "(", "graph_padded", ")", "\n", "", "return", "graphs_padded", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.forward": [[677, 858], ["allennlp.nn.util.get_text_field_mask", "pytorch_models.AsMil.word_embedder", "pytorch_models.AsMil.embedding_layer_fc", "range", "pytorch_models.AsMil.lstm", "range", "range", "pytorch_models.AsMil.position_embedder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "embedding_layer_aspect_attention", "embedding_layer_category_alphas.append", "pytorch_models.AsMil.element_wise_mul", "embedding_layer_category_outputs.append", "pytorch_models.AsMil.element_wise_mul", "lstm_layer_category_outputs.append", "fc", "final_category_outputs.append", "final_sentiment_outputs.append", "range", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytorch_models.AsMil._accuracy", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytorch_models.AsMil._f1", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "range", "sentiment_alpha.unsqueeze.unsqueeze.unsqueeze", "pytorch_models.AsMil.sentiment_fc", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "lstm_layer_sentiment_outputs.append", "pytorch_models.AsMil.element_wise_mul", "lstm_layer_sentiment_outputs.append", "fc_lstm", "final_lstm_category_outputs.append", "pytorch_models.AsMil.sentiment_fc", "category_labels.append", "polarity_labels.append", "polarity_masks.append", "pytorch_models.AsMil.category_loss", "pytorch_models.AsMil.sentiment_loss", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "len", "nlp_tasks.utils.attention_visualizer.plot_multi_attentions_of_sentence", "range", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "lstm_layer_words_sentiment_soft.append", "lstm_layer_words_sentiment_soft.append", "final_category_outputs[].squeeze", "polarity_labels[].long", "pytorch_models.AsMil.category_loss", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "[].detach().cpu().numpy", "[].detach().cpu().numpy", "[].detach().cpu().numpy().tolist", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "final_lstm_category_outputs[].squeeze", "e.split", "range", "range", "range", "int", "[].detach().cpu().numpy", "visual_attentions_sentiment.append", "labels_sentiment.append", "range", "titles_sentiment.extend", "nlp_tasks.utils.attention_visualizer.plot_multi_attentions_of_sentence", "print", "[].detach().cpu", "str", "str", "[].detach().cpu", "[].detach().cpu().numpy", "[].detach().cpu().numpy().tolist", "labels_sentiment.append", "visual_attentions_sentiment.append", "[].detach().cpu().numpy", "[].detach().cpu().numpy", "[].detach().cpu", "pytorch_models.AsMil.categories[].split", "[].detach", "[].detach", "[].detach().cpu", "[].detach().cpu().numpy", "str", "str", "str", "[].detach().cpu", "[].detach().cpu", "[].detach().cpu().numpy", "[].detach", "[].detach", "[].detach().cpu", "[].detach", "[].detach", "[].detach().cpu", "len", "len", "[].detach", "[].detach", "len"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.element_wise_mul", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.element_wise_mul", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.element_wise_mul", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.attention_visualizer.plot_multi_attentions_of_sentence", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.attention_visualizer.plot_multi_attentions_of_sentence"], ["", "def", "forward", "(", "self", ",", "tokens", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "label", ":", "torch", ".", "Tensor", ",", "position", ":", "torch", ".", "Tensor", ",", "\n", "polarity_mask", ":", "torch", ".", "Tensor", ",", "sample", ":", "list", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "mask", "=", "get_text_field_mask", "(", "tokens", ")", "\n", "word_embeddings", "=", "self", ".", "word_embedder", "(", "tokens", ")", "\n", "if", "self", ".", "configuration", "[", "'position'", "]", ":", "\n", "            ", "position_embeddings", "=", "self", ".", "position_embedder", "(", "position", ")", "\n", "word_embeddings", "=", "torch", ".", "cat", "(", "[", "word_embeddings", ",", "position_embeddings", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "word_embeddings_fc", "=", "self", ".", "embedding_layer_fc", "(", "word_embeddings", ")", "\n", "\n", "embedding_layer_category_outputs", "=", "[", "]", "\n", "embedding_layer_category_alphas", "=", "[", "]", "\n", "embedding_layer_sentiment_outputs", "=", "[", "]", "\n", "embedding_layer_sentiment_alphas", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "            ", "embedding_layer_aspect_attention", "=", "self", ".", "embedding_layer_aspect_attentions", "[", "i", "]", "\n", "alpha", "=", "embedding_layer_aspect_attention", "(", "word_embeddings_fc", ",", "mask", ")", "\n", "embedding_layer_category_alphas", ".", "append", "(", "alpha", ")", "\n", "\n", "category_output", "=", "self", ".", "element_wise_mul", "(", "word_embeddings_fc", ",", "alpha", ",", "return_not_sum_result", "=", "False", ")", "\n", "embedding_layer_category_outputs", ".", "append", "(", "category_output", ")", "\n", "\n", "", "lstm_result", ",", "_", "=", "self", ".", "lstm", "(", "word_embeddings", ")", "\n", "# lstm_result_with_position = torch.cat([lstm_result, position_embeddings], dim=-1)", "\n", "lstm_layer_category_outputs", "=", "[", "]", "\n", "lstm_layer_sentiment_outputs", "=", "[", "]", "\n", "lstm_layer_words_sentiment_soft", "=", "[", "]", "\n", "\n", "# max_len = tokens['tokens'].size()[1]", "\n", "# graphs = [e[3] for e in sample]", "\n", "# graphs_padded = self.pad_dgl_graph(graphs, max_len)", "\n", "# graph_output1 = F.relu(self.gc1(word_embeddings, graphs_padded))", "\n", "# graph_output2 = F.relu(self.gc2(graph_output1, graphs_padded))", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "            ", "alpha", "=", "embedding_layer_category_alphas", "[", "i", "]", "\n", "category_output", "=", "self", ".", "element_wise_mul", "(", "lstm_result", ",", "alpha", ",", "return_not_sum_result", "=", "False", ")", "\n", "lstm_layer_category_outputs", ".", "append", "(", "category_output", ")", "\n", "\n", "# sentiment", "\n", "# word_representation_for_sentiment = torch.cat([graph_output2, lstm_result], dim=-1)", "\n", "word_representation_for_sentiment", "=", "lstm_result", "\n", "sentiment_alpha", "=", "embedding_layer_category_alphas", "[", "i", "]", "\n", "if", "self", ".", "configuration", "[", "'mil'", "]", ":", "\n", "                ", "sentiment_alpha", "=", "sentiment_alpha", ".", "unsqueeze", "(", "1", ")", "\n", "words_sentiment", "=", "self", ".", "sentiment_fc", "(", "word_representation_for_sentiment", ")", "\n", "if", "self", ".", "configuration", "[", "'mil_softmax'", "]", ":", "\n", "                    ", "words_sentiment_soft", "=", "torch", ".", "softmax", "(", "words_sentiment", ",", "dim", "=", "-", "1", ")", "\n", "lstm_layer_words_sentiment_soft", ".", "append", "(", "words_sentiment_soft", ")", "\n", "", "else", ":", "\n", "                    ", "words_sentiment_soft", "=", "words_sentiment", "\n", "lstm_layer_words_sentiment_soft", ".", "append", "(", "torch", ".", "softmax", "(", "words_sentiment", ",", "dim", "=", "-", "1", ")", ")", "\n", "", "sentiment_output", "=", "torch", ".", "matmul", "(", "sentiment_alpha", ",", "words_sentiment_soft", ")", ".", "squeeze", "(", "1", ")", "# batch_size x 2*hidden_dim", "\n", "lstm_layer_sentiment_outputs", ".", "append", "(", "sentiment_output", ")", "\n", "", "else", ":", "\n", "                ", "sentiment_output", "=", "self", ".", "element_wise_mul", "(", "word_representation_for_sentiment", ",", "sentiment_alpha", ",", "\n", "return_not_sum_result", "=", "False", ")", "\n", "lstm_layer_sentiment_outputs", ".", "append", "(", "sentiment_output", ")", "\n", "\n", "", "", "final_category_outputs", "=", "[", "]", "\n", "final_lstm_category_outputs", "=", "[", "]", "\n", "final_sentiment_outputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "            ", "fc", "=", "self", ".", "category_fcs", "[", "i", "]", "\n", "category_output", "=", "embedding_layer_category_outputs", "[", "i", "]", "\n", "final_category_output", "=", "fc", "(", "category_output", ")", "\n", "final_category_outputs", ".", "append", "(", "final_category_output", ")", "\n", "\n", "if", "self", ".", "configuration", "[", "'lstm_layer_category_classifier'", "]", ":", "\n", "                ", "fc_lstm", "=", "self", ".", "lstm_category_fcs", "[", "i", "]", "\n", "lstm_category_output", "=", "lstm_layer_category_outputs", "[", "i", "]", "\n", "final_lstm_category_output", "=", "fc_lstm", "(", "lstm_category_output", ")", "\n", "final_lstm_category_outputs", ".", "append", "(", "final_lstm_category_output", ")", "\n", "\n", "", "sentiment_output", "=", "lstm_layer_sentiment_outputs", "[", "i", "]", "\n", "if", "self", ".", "configuration", "[", "'mil'", "]", ":", "\n", "                ", "final_sentiment_output", "=", "sentiment_output", "\n", "", "else", ":", "\n", "                ", "final_sentiment_output", "=", "self", ".", "sentiment_fc", "(", "sentiment_output", ")", "\n", "", "final_sentiment_outputs", ".", "append", "(", "final_sentiment_output", ")", "\n", "\n", "", "output", "=", "{", "}", "\n", "if", "label", "is", "not", "None", ":", "\n", "            ", "category_labels", "=", "[", "]", "\n", "polarity_labels", "=", "[", "]", "\n", "polarity_masks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "                ", "category_labels", ".", "append", "(", "label", "[", ":", ",", "i", "]", ")", "\n", "polarity_labels", ".", "append", "(", "label", "[", ":", ",", "i", "+", "self", ".", "category_num", "]", ")", "\n", "polarity_masks", ".", "append", "(", "polarity_mask", "[", ":", ",", "i", "]", ")", "\n", "", "loss", "=", "0", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "                ", "category_temp_loss", "=", "self", ".", "category_loss", "(", "final_category_outputs", "[", "i", "]", ".", "squeeze", "(", "dim", "=", "-", "1", ")", ",", "category_labels", "[", "i", "]", ")", "\n", "sentiment_temp_loss", "=", "self", ".", "sentiment_loss", "(", "final_sentiment_outputs", "[", "i", "]", ",", "polarity_labels", "[", "i", "]", ".", "long", "(", ")", ")", "\n", "loss", "+=", "category_temp_loss", "\n", "if", "not", "self", ".", "configuration", "[", "'only_acd'", "]", ":", "\n", "                    ", "loss", "+=", "sentiment_temp_loss", "\n", "", "if", "self", ".", "configuration", "[", "'lstm_layer_category_classifier'", "]", ":", "\n", "                    ", "lstm_category_temp_loss", "=", "self", ".", "category_loss", "(", "final_lstm_category_outputs", "[", "i", "]", ".", "squeeze", "(", "dim", "=", "-", "1", ")", ",", "\n", "category_labels", "[", "i", "]", ")", "\n", "loss", "+=", "lstm_category_temp_loss", "\n", "\n", "# sentiment accuracy", "\n", "", "", "sentiment_logit", "=", "torch", ".", "cat", "(", "final_sentiment_outputs", ")", "\n", "sentiment_label", "=", "torch", ".", "cat", "(", "polarity_labels", ")", "\n", "sentiment_mask", "=", "torch", ".", "cat", "(", "polarity_masks", ")", "\n", "self", ".", "_accuracy", "(", "sentiment_logit", ",", "sentiment_label", ",", "sentiment_mask", ")", "\n", "\n", "# category f1", "\n", "final_category_outputs_prob", "=", "[", "torch", ".", "sigmoid", "(", "e", ")", "for", "e", "in", "final_category_outputs", "]", "\n", "category_prob", "=", "torch", ".", "cat", "(", "final_category_outputs_prob", ")", ".", "squeeze", "(", ")", "\n", "category_label", "=", "torch", ".", "cat", "(", "category_labels", ")", "\n", "self", ".", "_f1", "(", "category_prob", ",", "category_label", ")", "\n", "\n", "output", "[", "'loss'", "]", "=", "loss", "\n", "\n", "# visualize attention", "\n", "", "pred_category", "=", "[", "torch", ".", "sigmoid", "(", "e", ")", "for", "e", "in", "final_category_outputs", "]", "\n", "pred_sentiment", "=", "[", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "e", ",", "dim", "=", "-", "1", ")", "for", "e", "in", "final_sentiment_outputs", "]", "\n", "output", "[", "'pred_category'", "]", "=", "pred_category", "\n", "output", "[", "'pred_sentiment'", "]", "=", "pred_sentiment", "\n", "if", "self", ".", "configuration", "[", "'visualize_attention'", "]", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "sample", ")", ")", ":", "\n", "                ", "words", "=", "sample", "[", "i", "]", "[", "2", "]", "\n", "attention_labels", "=", "[", "e", ".", "split", "(", "'/'", ")", "[", "0", "]", "for", "e", "in", "self", ".", "categories", "]", "\n", "\n", "# category", "\n", "visual_attentions_category", "=", "[", "embedding_layer_category_alphas", "[", "j", "]", "[", "i", "]", "[", ":", "len", "(", "words", ")", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "titles", "=", "[", "'true: %s - pred: %s'", "%", "(", "str", "(", "label", "[", "i", "]", "[", "j", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "str", "(", "pred_category", "[", "j", "]", "[", "i", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "attention_visualizer", ".", "plot_multi_attentions_of_sentence", "(", "words", ",", "visual_attentions_category", ",", "\n", "attention_labels", ",", "titles", ")", "\n", "\n", "# sentiment embedding layer", "\n", "# visual_attentions = [embedding_layer_sentiment_alphas[j][i][: len(words)].detach().cpu().numpy()", "\n", "#                      for j in range(self.category_num)]", "\n", "# titles = ['true: %s - pred: %s - %s' % (str(label[i + self.category_num][j].detach().cpu().numpy()),", "\n", "#                                         str(pred_sentiment[j][i].detach().cpu().numpy()),", "\n", "#                                         str(self.polarites))", "\n", "#           for j in range(self.category_num)]", "\n", "# attention_visualizer.plot_multi_attentions_of_sentence(words, visual_attentions, attention_labels,", "\n", "#                                                        titles)", "\n", "\n", "# sentiment lstm layer", "\n", "# visual_attentions = [lstm_layer_sentiment_alphas[j][i][: len(words)].detach().cpu().numpy()", "\n", "#                      for j in range(self.category_num)]", "\n", "# titles = ['true: %s - pred: %s - %s' % (str(label[i + self.category_num][j].detach().cpu().numpy()),", "\n", "#                                         str(pred_sentiment[j][i].detach().cpu().numpy()),", "\n", "#                                         str(self.polarites))", "\n", "#           for j in range(self.category_num)]", "\n", "# attention_visualizer.plot_multi_attentions_of_sentence(words, visual_attentions, attention_labels,", "\n", "#                                                        titles)", "\n", "\n", "# sentiment lstm layer", "\n", "visual_attentions_sentiment_temp", "=", "[", "lstm_layer_words_sentiment_soft", "[", "j", "]", "[", "i", "]", "[", ":", "len", "(", "words", ")", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "                    ", "c_label", "=", "label", "[", "i", "]", "[", "j", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "if", "c_label", "==", "1", ":", "\n", "                        ", "visual_attentions_sentiment", "=", "[", "]", "\n", "labels_sentiment", "=", "[", "]", "\n", "sentiment_true_index", "=", "int", "(", "label", "[", "i", "]", "[", "j", "+", "self", ".", "category_num", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "if", "sentiment_true_index", "==", "-", "100", ":", "\n", "                            ", "continue", "\n", "", "titles_sentiment", "=", "[", "'true: %s - pred: %s - %s'", "%", "(", "str", "(", "self", ".", "polarites", "[", "sentiment_true_index", "]", ")", ",", "\n", "str", "(", "pred_sentiment", "[", "j", "]", "[", "i", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "str", "(", "self", ".", "polarites", ")", ")", "]", "\n", "c_attention", "=", "embedding_layer_category_alphas", "[", "j", "]", "[", "i", "]", "[", ":", "len", "(", "words", ")", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "visual_attentions_sentiment", ".", "append", "(", "c_attention", ")", "\n", "labels_sentiment", ".", "append", "(", "self", ".", "categories", "[", "j", "]", ".", "split", "(", "'/'", ")", "[", "0", "]", ")", "\n", "\n", "s_distributions", "=", "visual_attentions_sentiment_temp", "[", "j", "]", "\n", "for", "k", "in", "range", "(", "self", ".", "polarity_num", ")", ":", "\n", "                            ", "labels_sentiment", ".", "append", "(", "self", ".", "polarites", "[", "k", "]", ")", "\n", "visual_attentions_sentiment", ".", "append", "(", "s_distributions", "[", ":", ",", "k", "]", ")", "\n", "", "titles_sentiment", ".", "extend", "(", "[", "''", "]", "*", "3", ")", "\n", "attention_visualizer", ".", "plot_multi_attentions_of_sentence", "(", "words", ",", "visual_attentions_sentiment", ",", "\n", "labels_sentiment", ",", "\n", "titles_sentiment", ")", "\n", "print", "(", ")", "\n", "", "", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.get_metrics": [[859, 865], ["pytorch_models.AsMil._accuracy.get_metric", "pytorch_models.AsMil._f1.get_metric"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.get_metric", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.get_metric"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "metrics", "=", "{", "\n", "'accuracy'", ":", "self", ".", "_accuracy", ".", "get_metric", "(", "reset", ")", ",", "\n", "'category_f1'", ":", "self", ".", "_f1", ".", "get_metric", "(", "reset", ")", "[", "'fscore'", "]", "\n", "}", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBert.__init__": [[868, 926], ["pytorch_models.TextInAllAspectSentimentOutModel.__init__", "len", "len", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "allennlp.training.metrics.CategoricalAccuracy", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1", "word_embedder.get_output_dim", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "pytorch_models.AttentionInHtt", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "range", "range", "int", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "int"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.cnn_encoder_seq2seq.CnnEncoder.get_output_dim"], ["    ", "def", "__init__", "(", "self", ",", "word_embedder", ":", "TextFieldEmbedder", ",", "position_embedder", ":", "TextFieldEmbedder", ",", "\n", "categories", ":", "list", ",", "polarities", ":", "list", ",", "vocab", ":", "Vocabulary", ",", "configuration", ":", "dict", ",", "\n", "bert_word_embedder", ":", "TextFieldEmbedder", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "configuration", "=", "configuration", "\n", "self", ".", "word_embedder", "=", "word_embedder", "\n", "self", ".", "position_embedder", "=", "position_embedder", "\n", "self", ".", "categories", "=", "categories", "\n", "self", ".", "polarites", "=", "polarities", "\n", "self", ".", "category_num", "=", "len", "(", "categories", ")", "\n", "self", ".", "polarity_num", "=", "len", "(", "polarities", ")", "\n", "self", ".", "category_loss", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "self", ".", "sentiment_loss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "_accuracy", "=", "metrics", ".", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "_f1", "=", "allennlp_metrics", ".", "BinaryF1", "(", "0.5", ")", "\n", "\n", "word_embedding_dim", "=", "word_embedder", ".", "get_output_dim", "(", ")", "\n", "if", "self", ".", "configuration", "[", "'lstm_or_fc_after_embedding_layer'", "]", "==", "'fc'", ":", "\n", "            ", "self", ".", "embedding_layer_fc", "=", "nn", ".", "Linear", "(", "word_embedding_dim", ",", "word_embedding_dim", ",", "bias", "=", "True", ")", "\n", "", "elif", "self", ".", "configuration", "[", "'lstm_or_fc_after_embedding_layer'", "]", "==", "'bilstm'", ":", "\n", "            ", "self", ".", "embedding_layer_lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "word_embedding_dim", ",", "int", "(", "word_embedding_dim", "/", "2", ")", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "True", ",", "num_layers", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embedding_layer_lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "word_embedding_dim", ",", "word_embedding_dim", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "False", ",", "num_layers", "=", "1", ")", "\n", "\n", "", "self", ".", "embedding_layer_aspect_attentions", "=", "[", "AttentionInHtt", "(", "word_embedding_dim", ",", "\n", "word_embedding_dim", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "self", ".", "embedding_layer_aspect_attentions", "=", "nn", ".", "ModuleList", "(", "self", ".", "embedding_layer_aspect_attentions", ")", "\n", "\n", "self", ".", "category_fcs", "=", "[", "nn", ".", "Linear", "(", "word_embedding_dim", ",", "1", ")", "for", "_", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "self", ".", "category_fcs", "=", "nn", ".", "ModuleList", "(", "self", ".", "category_fcs", ")", "\n", "\n", "if", "self", ".", "configuration", "[", "'lstm_layer_num_in_bert'", "]", "!=", "0", ":", "\n", "            ", "num_layers", "=", "self", ".", "configuration", "[", "'lstm_layer_num_in_bert'", "]", "\n", "bilstm_hidden_size_in_bert", "=", "self", ".", "configuration", "[", "'bilstm_hidden_size_in_bert'", "]", "\n", "if", "bilstm_hidden_size_in_bert", "==", "0", ":", "\n", "                ", "bilstm_hidden_size_in_bert", "=", "int", "(", "word_embedding_dim", "/", "2", ")", "\n", "", "self", ".", "lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "768", ",", "bilstm_hidden_size_in_bert", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "True", ",", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "self", ".", "configuration", "[", "'dropout_in_bert'", "]", ")", "\n", "hidden_size", "=", "bilstm_hidden_size_in_bert", "*", "2", "\n", "", "else", ":", "\n", "            ", "hidden_size", "=", "768", "\n", "", "if", "self", ".", "configuration", "[", "'only_bert'", "]", ":", "\n", "            ", "self", ".", "sentiment_fc", "=", "nn", ".", "Sequential", "(", "\n", "# nn.Linear(768, 768),", "\n", "# nn.ReLU(),", "\n", "nn", ".", "Linear", "(", "768", ",", "self", ".", "polarity_num", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "sentiment_fc", "=", "nn", ".", "Sequential", "(", "\n", "# nn.Linear(hidden_size, hidden_size),", "\n", "# nn.ReLU(),", "\n", "nn", ".", "Linear", "(", "hidden_size", ",", "self", ".", "polarity_num", ")", ")", "\n", "", "self", ".", "bert_word_embedder", "=", "bert_word_embedder", "\n", "\n", "self", ".", "dropout_after_embedding_layer", "=", "nn", ".", "Dropout", "(", "self", ".", "configuration", "[", "'dropout_in_bert'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBert.set_bert_word_embedder": [[927, 929], ["None"], "methods", ["None"], ["", "def", "set_bert_word_embedder", "(", "self", ",", "bert_word_embedder", ":", "TextFieldEmbedder", "=", "None", ")", ":", "\n", "        ", "self", ".", "bert_word_embedder", "=", "bert_word_embedder", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBert.set_grad_for_acd_parameter": [[930, 941], ["acd_layers.append", "acd_layers.append", "acd_layers.append", "acd_layers.append", "layer.named_parameters"], "methods", ["None"], ["", "def", "set_grad_for_acd_parameter", "(", "self", ",", "requires_grad", "=", "True", ")", ":", "\n", "        ", "acd_layers", "=", "[", "]", "\n", "if", "self", ".", "configuration", "[", "'lstm_or_fc_after_embedding_layer'", "]", "==", "'fc'", ":", "\n", "            ", "acd_layers", ".", "append", "(", "self", ".", "embedding_layer_fc", ")", "\n", "", "else", ":", "\n", "            ", "acd_layers", ".", "append", "(", "self", ".", "embedding_layer_lstm", ")", "\n", "", "acd_layers", ".", "append", "(", "self", ".", "embedding_layer_aspect_attentions", ")", "\n", "acd_layers", ".", "append", "(", "self", ".", "category_fcs", ")", "\n", "for", "layer", "in", "acd_layers", ":", "\n", "            ", "for", "name", ",", "value", "in", "layer", ".", "named_parameters", "(", ")", ":", "\n", "                ", "value", ".", "requires_grad", "=", "requires_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBert.set_grad_for_acsc_parameter": [[942, 953], ["acsc_layers.append", "bert_model.parameters", "acsc_layers.append", "layer.named_parameters"], "methods", ["None"], ["", "", "", "def", "set_grad_for_acsc_parameter", "(", "self", ",", "requires_grad", "=", "True", ")", ":", "\n", "        ", "acsc_layers", "=", "[", "]", "\n", "if", "self", ".", "configuration", "[", "'lstm_layer_num_in_bert'", "]", "!=", "0", ":", "\n", "            ", "acsc_layers", ".", "append", "(", "self", ".", "lstm", ")", "\n", "", "acsc_layers", ".", "append", "(", "self", ".", "sentiment_fc", ")", "\n", "for", "layer", "in", "acsc_layers", ":", "\n", "            ", "for", "name", ",", "value", "in", "layer", ".", "named_parameters", "(", ")", ":", "\n", "                ", "value", ".", "requires_grad", "=", "requires_grad", "\n", "", "", "bert_model", "=", "self", ".", "bert_word_embedder", ".", "_token_embedders", "[", "'bert'", "]", ".", "bert_model", "\n", "for", "param", "in", "bert_model", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBert.forward": [[954, 1187], ["pytorch_models.AsMilSimultaneouslyBert.bert_word_embedder", "allennlp.nn.util.get_text_field_mask", "pytorch_models.AsMilSimultaneouslyBert.word_embedder", "pytorch_models.AsMilSimultaneouslyBert.size", "range", "range", "range", "pytorch_models.AsMilSimultaneouslyBert.embedding_layer_fc", "pytorch_models.AsMilSimultaneouslyBert.embedding_layer_lstm", "embedding_layer_aspect_attention", "embedding_layer_category_alphas.append", "pytorch_models.AsMilSimultaneouslyBert.element_wise_mul", "embedding_layer_category_outputs.append", "bert_clses_of_all_aspect.append", "pytorch_models.AsMilSimultaneouslyBert.sentiment_fc", "sentiment_output_clses_soft.append", "fc", "final_category_outputs.append", "final_sentiment_outputs.append", "range", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytorch_models.AsMilSimultaneouslyBert._accuracy", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytorch_models.AsMilSimultaneouslyBert._f1", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "range", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "embedding_layer_sentiment_outputs.append", "pytorch_models.AsMilSimultaneouslyBert.dropout_after_embedding_layer", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "lstm_layer_sentiment_outputs.append", "pytorch_models.AsMilSimultaneouslyBert.dropout_after_embedding_layer", "category_labels.append", "polarity_labels.append", "polarity_masks.append", "pytorch_models.AsMilSimultaneouslyBert.category_loss", "pytorch_models.AsMilSimultaneouslyBert.sentiment_loss", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "len", "nlp_tasks.utils.attention_visualizer.plot_multi_attentions_of_sentence_backup", "range", "len", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "aspect_word_embeddings_from_bert.append", "pytorch_models.AsMilSimultaneouslyBert.lstm", "sentiment_alpha.unsqueeze.unsqueeze.unsqueeze", "pytorch_models.AsMilSimultaneouslyBert.sentiment_fc", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "lstm_layer_sentiment_outputs.append", "pytorch_models.AsMilSimultaneouslyBert.element_wise_mul", "pytorch_models.AsMilSimultaneouslyBert.sentiment_fc", "lstm_layer_sentiment_outputs.append", "final_category_outputs[].squeeze", "polarity_labels[].long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "[].detach().cpu().numpy", "words.insert", "e.detach().cpu().numpy", "[].detach().cpu().numpy().tolist", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "lstm_layer_words_sentiment_soft.append", "lstm_layer_words_sentiment_soft.append", "e.split", "range", "range", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "int", "[].detach().cpu().numpy", "visual_attentions_sentiment.append", "labels_sentiment.append", "range", "titles_sentiment.extend", "nlp_tasks.utils.attention_visualizer.plot_multi_attentions_of_sentence_backup", "aspect_word_embeddings_from_bert_of_one_sample.append", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "aspect_word_embeddings_from_bert_of_one_sample.append", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "[].detach().cpu", "str", "str", "len", "e.unsqueeze", "range", "e.detach().cpu", "[].detach().cpu().numpy", "[].detach().cpu().numpy().tolist", "numpy.array", "labels_sentiment.append", "visual_attentions_sentiment.append", "word_bert_embeddings.append", "len", "print", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "[].detach().cpu().numpy", "[].detach().cpu().numpy", "len", "[].detach().cpu", "pytorch_models.AsMilSimultaneouslyBert.categories[].split", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "len", "[].detach", "e.detach", "[].detach().cpu", "[].detach().cpu().numpy", "str", "str", "str", "numpy.array.tolist", "[].detach().cpu", "[].detach().cpu", "[].detach().cpu().numpy", "[].detach", "[].detach", "[].detach().cpu", "[].detach", "[].detach", "[].detach().cpu", "len", "[].detach", "[].detach", "len"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.element_wise_mul", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.attention_visualizer.plot_multi_attentions_of_sentence_backup", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.element_wise_mul", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.attention_visualizer.plot_multi_attentions_of_sentence_backup"], ["", "", "def", "forward", "(", "self", ",", "tokens", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "label", ":", "torch", ".", "Tensor", ",", "position", ":", "torch", ".", "Tensor", ",", "\n", "polarity_mask", ":", "torch", ".", "Tensor", ",", "sample", ":", "list", ",", "bert", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "bert_mask", "=", "bert", "[", "'mask'", "]", "\n", "# bert_word_embeddings = self.bert_word_embedder(bert)", "\n", "token_type_ids", "=", "bert", "[", "'bert-type-ids'", "]", "\n", "# token_type_ids_size = token_type_ids.size()", "\n", "# for i in range(token_type_ids_size[1]):", "\n", "#     print(token_type_ids[0][i])", "\n", "offsets", "=", "bert", "[", "'bert-offsets'", "]", "\n", "bert_word_embeddings", "=", "self", ".", "bert_word_embedder", "(", "bert", ",", "token_type_ids", "=", "token_type_ids", ",", "offsets", "=", "offsets", ")", "\n", "\n", "mask", "=", "get_text_field_mask", "(", "tokens", ")", "\n", "word_embeddings", "=", "self", ".", "word_embedder", "(", "tokens", ")", "\n", "word_embeddings_size", "=", "word_embeddings", ".", "size", "(", ")", "\n", "if", "self", ".", "configuration", "[", "'lstm_or_fc_after_embedding_layer'", "]", "==", "'fc'", ":", "\n", "            ", "word_embeddings_fc", "=", "self", ".", "embedding_layer_fc", "(", "word_embeddings", ")", "\n", "", "else", ":", "\n", "            ", "word_embeddings_fc", ",", "(", "_", ",", "_", ")", "=", "self", ".", "embedding_layer_lstm", "(", "word_embeddings", ")", "\n", "\n", "", "embedding_layer_category_outputs", "=", "[", "]", "\n", "embedding_layer_category_alphas", "=", "[", "]", "\n", "embedding_layer_sentiment_outputs", "=", "[", "]", "\n", "embedding_layer_sentiment_alphas", "=", "[", "]", "\n", "bert_clses_of_all_aspect", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "            ", "embedding_layer_aspect_attention", "=", "self", ".", "embedding_layer_aspect_attentions", "[", "i", "]", "\n", "alpha", "=", "embedding_layer_aspect_attention", "(", "word_embeddings_fc", ",", "mask", ")", "\n", "embedding_layer_category_alphas", ".", "append", "(", "alpha", ")", "\n", "\n", "category_output", "=", "self", ".", "element_wise_mul", "(", "word_embeddings_fc", ",", "alpha", ",", "return_not_sum_result", "=", "False", ")", "\n", "embedding_layer_category_outputs", ".", "append", "(", "category_output", ")", "\n", "\n", "bert_clses_of_aspect", "=", "bert_word_embeddings", "[", ":", ",", "i", ",", "0", ",", ":", "]", "\n", "bert_clses_of_all_aspect", ".", "append", "(", "bert_clses_of_aspect", ")", "\n", "\n", "if", "not", "self", ".", "configuration", "[", "'only_bert'", "]", ":", "\n", "                ", "bert_word_embeddings_of_aspect", "=", "bert_word_embeddings", "[", ":", ",", "i", ",", ":", ",", ":", "]", "\n", "aspect_word_embeddings_from_bert", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "sample", ")", ")", ":", "\n", "                    ", "aspect_word_embeddings_from_bert_of_one_sample", "=", "[", "]", "\n", "all_word_indices_in_bert", "=", "sample", "[", "j", "]", "[", "6", "]", "\n", "for", "k", "in", "range", "(", "word_embeddings_size", "[", "1", "]", ")", ":", "\n", "                        ", "if", "k", "in", "all_word_indices_in_bert", ":", "\n", "                            ", "word_indices_in_bert", "=", "all_word_indices_in_bert", "[", "k", "]", "\n", "word_bert_embeddings", "=", "[", "]", "\n", "for", "word_index_in_bert", "in", "word_indices_in_bert", ":", "\n", "                                ", "word_bert_embedding", "=", "bert_word_embeddings_of_aspect", "[", "j", "]", "[", "word_index_in_bert", "]", "\n", "word_bert_embeddings", ".", "append", "(", "word_bert_embedding", ")", "\n", "", "if", "len", "(", "word_bert_embeddings", ")", "==", "0", ":", "\n", "                                ", "print", "(", ")", "\n", "", "if", "len", "(", "word_bert_embeddings", ")", ">", "1", ":", "\n", "                                ", "word_bert_embeddings_unsqueeze", "=", "[", "torch", ".", "unsqueeze", "(", "e", ",", "dim", "=", "0", ")", "for", "e", "in", "word_bert_embeddings", "]", "\n", "word_bert_embeddings_cat", "=", "torch", ".", "cat", "(", "word_bert_embeddings_unsqueeze", ",", "dim", "=", "0", ")", "\n", "word_bert_embeddings_sum", "=", "torch", ".", "sum", "(", "word_bert_embeddings_cat", ",", "dim", "=", "0", ")", "\n", "word_bert_embeddings_ave", "=", "word_bert_embeddings_sum", "/", "len", "(", "word_bert_embeddings", ")", "\n", "", "else", ":", "\n", "                                ", "word_bert_embeddings_ave", "=", "word_bert_embeddings", "[", "0", "]", "\n", "", "aspect_word_embeddings_from_bert_of_one_sample", ".", "append", "(", "\n", "torch", ".", "unsqueeze", "(", "word_bert_embeddings_ave", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "                            ", "zero", "=", "torch", ".", "zeros_like", "(", "aspect_word_embeddings_from_bert_of_one_sample", "[", "-", "1", "]", ")", "\n", "aspect_word_embeddings_from_bert_of_one_sample", ".", "append", "(", "zero", ")", "\n", "", "", "aspect_word_embeddings_from_bert_of_one_sample_cat", "=", "torch", ".", "cat", "(", "aspect_word_embeddings_from_bert_of_one_sample", ",", "dim", "=", "0", ")", "\n", "aspect_word_embeddings_from_bert", ".", "append", "(", "torch", ".", "unsqueeze", "(", "aspect_word_embeddings_from_bert_of_one_sample_cat", ",", "dim", "=", "0", ")", ")", "\n", "", "aspect_word_embeddings_from_bert_cat", "=", "torch", ".", "cat", "(", "aspect_word_embeddings_from_bert", ",", "dim", "=", "0", ")", "\n", "if", "self", ".", "configuration", "[", "'lstm_layer_num_in_bert'", "]", "!=", "0", ":", "\n", "                    ", "aspect_word_embeddings_from_bert_cat", ",", "_", "=", "self", ".", "lstm", "(", "aspect_word_embeddings_from_bert_cat", ")", "\n", "", "embedding_layer_sentiment_outputs", ".", "append", "(", "aspect_word_embeddings_from_bert_cat", ")", "\n", "\n", "", "", "lstm_layer_category_outputs", "=", "[", "]", "\n", "lstm_layer_sentiment_outputs", "=", "[", "]", "\n", "lstm_layer_words_sentiment_soft", "=", "[", "]", "\n", "sentiment_output_clses_soft", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "            ", "sentiment_output_temp", "=", "bert_clses_of_all_aspect", "[", "i", "]", "\n", "if", "self", ".", "configuration", "[", "'dropout_after_cls'", "]", ":", "\n", "                ", "sentiment_output_temp", "=", "self", ".", "dropout_after_embedding_layer", "(", "sentiment_output_temp", ")", "\n", "", "sentiment_output_cls", "=", "self", ".", "sentiment_fc", "(", "sentiment_output_temp", ")", "\n", "sentiment_output_clses_soft", ".", "append", "(", "torch", ".", "softmax", "(", "sentiment_output_cls", ",", "dim", "=", "-", "1", ")", ")", "\n", "if", "self", ".", "configuration", "[", "'only_bert'", "]", ":", "\n", "                ", "sentiment_output", "=", "sentiment_output_cls", "\n", "lstm_layer_sentiment_outputs", ".", "append", "(", "sentiment_output", ")", "\n", "", "else", ":", "\n", "# sentiment", "\n", "                ", "aspect_word_embeddings_from_bert", "=", "embedding_layer_sentiment_outputs", "[", "i", "]", "\n", "word_representation_for_sentiment", "=", "self", ".", "dropout_after_embedding_layer", "(", "aspect_word_embeddings_from_bert", ")", "\n", "\n", "sentiment_alpha", "=", "embedding_layer_category_alphas", "[", "i", "]", "\n", "if", "self", ".", "configuration", "[", "'mil'", "]", ":", "\n", "                    ", "sentiment_alpha", "=", "sentiment_alpha", ".", "unsqueeze", "(", "1", ")", "\n", "words_sentiment", "=", "self", ".", "sentiment_fc", "(", "word_representation_for_sentiment", ")", "\n", "if", "self", ".", "configuration", "[", "'mil_softmax'", "]", ":", "\n", "                        ", "words_sentiment_soft", "=", "torch", ".", "softmax", "(", "words_sentiment", ",", "dim", "=", "-", "1", ")", "\n", "lstm_layer_words_sentiment_soft", ".", "append", "(", "words_sentiment_soft", ")", "\n", "", "else", ":", "\n", "                        ", "words_sentiment_soft", "=", "words_sentiment", "\n", "lstm_layer_words_sentiment_soft", ".", "append", "(", "torch", ".", "softmax", "(", "words_sentiment", ",", "dim", "=", "-", "1", ")", ")", "\n", "", "sentiment_output_mil", "=", "torch", ".", "matmul", "(", "sentiment_alpha", ",", "words_sentiment_soft", ")", ".", "squeeze", "(", "1", ")", "# batch_size x 2*hidden_dim", "\n", "if", "self", ".", "configuration", "[", "'concat_cls_vector'", "]", ":", "\n", "                        ", "if", "self", ".", "configuration", "[", "'concat_cls_vector_mode'", "]", "==", "'average'", ":", "\n", "                            ", "sentiment_output", "=", "(", "sentiment_output_mil", "+", "sentiment_output_cls", ")", "/", "2", "\n", "", "else", ":", "\n", "                            ", "sentiment_output", "=", "sentiment_output_mil", "+", "sentiment_output_cls", "\n", "", "", "else", ":", "\n", "                        ", "sentiment_output", "=", "sentiment_output_mil", "\n", "", "lstm_layer_sentiment_outputs", ".", "append", "(", "sentiment_output", ")", "\n", "", "else", ":", "\n", "                    ", "sentiment_output_temp", "=", "self", ".", "element_wise_mul", "(", "word_representation_for_sentiment", ",", "sentiment_alpha", ",", "\n", "return_not_sum_result", "=", "False", ")", "\n", "sentiment_output_not_mil", "=", "self", ".", "sentiment_fc", "(", "sentiment_output_temp", ")", "\n", "if", "self", ".", "configuration", "[", "'concat_cls_vector'", "]", ":", "\n", "                        ", "if", "self", ".", "configuration", "[", "'concat_cls_vector_mode'", "]", "==", "'average'", ":", "\n", "                            ", "sentiment_output", "=", "(", "sentiment_output_not_mil", "+", "sentiment_output_cls", ")", "/", "2", "\n", "", "else", ":", "\n", "                            ", "sentiment_output", "=", "sentiment_output_not_mil", "+", "sentiment_output_cls", "\n", "", "", "else", ":", "\n", "                        ", "sentiment_output", "=", "sentiment_output_not_mil", "\n", "", "lstm_layer_sentiment_outputs", ".", "append", "(", "sentiment_output", ")", "\n", "\n", "", "", "", "final_category_outputs", "=", "[", "]", "\n", "final_lstm_category_outputs", "=", "[", "]", "\n", "final_sentiment_outputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "            ", "fc", "=", "self", ".", "category_fcs", "[", "i", "]", "\n", "category_output", "=", "embedding_layer_category_outputs", "[", "i", "]", "\n", "final_category_output", "=", "fc", "(", "category_output", ")", "\n", "final_category_outputs", ".", "append", "(", "final_category_output", ")", "\n", "\n", "sentiment_output", "=", "lstm_layer_sentiment_outputs", "[", "i", "]", "\n", "final_sentiment_output", "=", "sentiment_output", "\n", "final_sentiment_outputs", ".", "append", "(", "final_sentiment_output", ")", "\n", "\n", "", "output", "=", "{", "}", "\n", "if", "label", "is", "not", "None", ":", "\n", "            ", "category_labels", "=", "[", "]", "\n", "polarity_labels", "=", "[", "]", "\n", "polarity_masks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "                ", "category_labels", ".", "append", "(", "label", "[", ":", ",", "i", "]", ")", "\n", "polarity_labels", ".", "append", "(", "label", "[", ":", ",", "i", "+", "self", ".", "category_num", "]", ")", "\n", "polarity_masks", ".", "append", "(", "polarity_mask", "[", ":", ",", "i", "]", ")", "\n", "", "loss", "=", "0", "\n", "total_category_loss", "=", "0", "\n", "total_sentiment_loss", "=", "0", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "                ", "category_temp_loss", "=", "self", ".", "category_loss", "(", "final_category_outputs", "[", "i", "]", ".", "squeeze", "(", "dim", "=", "-", "1", ")", ",", "category_labels", "[", "i", "]", ")", "\n", "sentiment_temp_loss", "=", "self", ".", "sentiment_loss", "(", "final_sentiment_outputs", "[", "i", "]", ",", "polarity_labels", "[", "i", "]", ".", "long", "(", ")", ")", "\n", "if", "not", "self", ".", "configuration", "[", "'only_sc'", "]", ":", "\n", "                    ", "total_category_loss", "+=", "category_temp_loss", "\n", "", "if", "not", "self", ".", "configuration", "[", "'only_acd'", "]", ":", "\n", "                    ", "total_sentiment_loss", "+=", "sentiment_temp_loss", "\n", "\n", "", "", "loss", "=", "self", ".", "category_loss_weight", "*", "total_category_loss", "+", "self", ".", "sentiment_loss_weight", "*", "total_sentiment_loss", "\n", "\n", "# sentiment accuracy", "\n", "sentiment_logit", "=", "torch", ".", "cat", "(", "final_sentiment_outputs", ")", "\n", "sentiment_label", "=", "torch", ".", "cat", "(", "polarity_labels", ")", "\n", "sentiment_mask", "=", "torch", ".", "cat", "(", "polarity_masks", ")", "\n", "self", ".", "_accuracy", "(", "sentiment_logit", ",", "sentiment_label", ",", "sentiment_mask", ")", "\n", "\n", "# category f1", "\n", "final_category_outputs_prob", "=", "[", "torch", ".", "sigmoid", "(", "e", ")", "for", "e", "in", "final_category_outputs", "]", "\n", "category_prob", "=", "torch", ".", "cat", "(", "final_category_outputs_prob", ")", ".", "squeeze", "(", ")", "\n", "category_label", "=", "torch", ".", "cat", "(", "category_labels", ")", "\n", "self", ".", "_f1", "(", "category_prob", ",", "category_label", ")", "\n", "\n", "output", "[", "'loss'", "]", "=", "loss", "\n", "\n", "# visualize attention", "\n", "", "pred_category", "=", "[", "torch", ".", "sigmoid", "(", "e", ")", "for", "e", "in", "final_category_outputs", "]", "\n", "pred_sentiment", "=", "[", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "e", ",", "dim", "=", "-", "1", ")", "for", "e", "in", "final_sentiment_outputs", "]", "\n", "output", "[", "'pred_category'", "]", "=", "pred_category", "\n", "output", "[", "'pred_sentiment'", "]", "=", "pred_sentiment", "\n", "output", "[", "'embedding_layer_category_alphas'", "]", "=", "embedding_layer_category_alphas", "\n", "output", "[", "'lstm_layer_words_sentiment_soft'", "]", "=", "lstm_layer_words_sentiment_soft", "\n", "if", "self", ".", "configuration", "[", "'visualize_attention'", "]", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "sample", ")", ")", ":", "\n", "                ", "words", ":", "list", "=", "sample", "[", "i", "]", "[", "2", "]", "\n", "# if not ('while' in words and 'it' in words):", "\n", "#     continue", "\n", "attention_labels", "=", "[", "e", ".", "split", "(", "'/'", ")", "[", "0", "]", "for", "e", "in", "self", ".", "categories", "]", "\n", "\n", "# category", "\n", "visual_attentions_category", "=", "[", "embedding_layer_category_alphas", "[", "j", "]", "[", "i", "]", "[", ":", "len", "(", "words", ")", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "titles", "=", "[", "'true: %s - pred: %s'", "%", "(", "str", "(", "label", "[", "i", "]", "[", "j", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "str", "(", "pred_category", "[", "j", "]", "[", "i", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "# savefig_filepath = super()._get_model_visualization_picture_filepath(self.configuration, words)", "\n", "# attention_visualizer.plot_multi_attentions_of_sentence(words, visual_attentions_category,", "\n", "#                                                        attention_labels, titles, savefig_filepath)", "\n", "attention_visualizer", ".", "plot_multi_attentions_of_sentence_backup", "(", "words", ",", "visual_attentions_category", ",", "\n", "attention_labels", ",", "titles", ")", "\n", "\n", "# sentiment lstm layer", "\n", "visual_attentions_sentiment_temp", "=", "[", "lstm_layer_words_sentiment_soft", "[", "j", "]", "[", "i", "]", "[", ":", "len", "(", "words", ")", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "if", "self", ".", "configuration", "[", "'concat_cls_vector'", "]", ":", "\n", "                    ", "words", ".", "insert", "(", "0", ",", "'[CLS]'", ")", "\n", "clses_sentiment_temp", "=", "[", "e", ".", "unsqueeze", "(", "dim", "=", "1", ")", "[", "i", "]", "for", "e", "in", "sentiment_output_clses_soft", "]", "\n", "visual_attentions_sentiment_temp", "=", "[", "torch", ".", "cat", "(", "[", "visual_attentions_sentiment_temp", "[", "j", "]", ",", "clses_sentiment_temp", "[", "j", "]", "]", ",", "dim", "=", "0", ")", "for", "j", "in", "range", "(", "len", "(", "visual_attentions_sentiment_temp", ")", ")", "]", "\n", "", "visual_attentions_sentiment_temp", "=", "[", "e", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "for", "e", "in", "visual_attentions_sentiment_temp", "]", "\n", "\n", "for", "j", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "                    ", "c_label", "=", "label", "[", "i", "]", "[", "j", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "if", "c_label", "==", "1", ":", "\n", "                        ", "visual_attentions_sentiment", "=", "[", "]", "\n", "labels_sentiment", "=", "[", "]", "\n", "sentiment_true_index", "=", "int", "(", "label", "[", "i", "]", "[", "j", "+", "self", ".", "category_num", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "if", "sentiment_true_index", "==", "-", "100", ":", "\n", "                            ", "continue", "\n", "", "titles_sentiment", "=", "[", "'true: %s - pred: %s - %s'", "%", "(", "str", "(", "self", ".", "polarites", "[", "sentiment_true_index", "]", ")", ",", "\n", "str", "(", "pred_sentiment", "[", "j", "]", "[", "i", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "str", "(", "self", ".", "polarites", ")", ")", "]", "\n", "c_attention", "=", "embedding_layer_category_alphas", "[", "j", "]", "[", "i", "]", "[", ":", "len", "(", "words", ")", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "self", ".", "configuration", "[", "'concat_cls_vector'", "]", ":", "\n", "                            ", "c_attention", "=", "np", ".", "array", "(", "[", "1", "]", "+", "c_attention", ".", "tolist", "(", ")", ")", "\n", "", "visual_attentions_sentiment", ".", "append", "(", "c_attention", ")", "\n", "labels_sentiment", ".", "append", "(", "self", ".", "categories", "[", "j", "]", ".", "split", "(", "'/'", ")", "[", "0", "]", ")", "\n", "\n", "s_distributions", "=", "visual_attentions_sentiment_temp", "[", "j", "]", "\n", "for", "k", "in", "range", "(", "self", ".", "polarity_num", ")", ":", "\n", "                            ", "labels_sentiment", ".", "append", "(", "self", ".", "polarites", "[", "k", "]", ")", "\n", "visual_attentions_sentiment", ".", "append", "(", "s_distributions", "[", ":", ",", "k", "]", ")", "\n", "", "titles_sentiment", ".", "extend", "(", "[", "''", "]", "*", "3", ")", "\n", "# savefig_filepath = super()._get_model_visualization_picture_filepath(self.configuration, words)", "\n", "# attention_visualizer.plot_multi_attentions_of_sentence(words, visual_attentions_sentiment,", "\n", "#                                                        labels_sentiment,", "\n", "#                                                        titles_sentiment, savefig_filepath)", "\n", "attention_visualizer", ".", "plot_multi_attentions_of_sentence_backup", "(", "words", ",", "visual_attentions_sentiment", ",", "\n", "labels_sentiment", ",", "\n", "titles_sentiment", ")", "\n", "", "", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBert.get_metrics": [[1188, 1194], ["pytorch_models.AsMilSimultaneouslyBert._accuracy.get_metric", "pytorch_models.AsMilSimultaneouslyBert._f1.get_metric"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.get_metric", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.get_metric"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "metrics", "=", "{", "\n", "'accuracy'", ":", "self", ".", "_accuracy", ".", "get_metric", "(", "reset", ")", ",", "\n", "'category_f1'", ":", "self", ".", "_f1", ".", "get_metric", "(", "reset", ")", "[", "'fscore'", "]", "\n", "}", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.__init__": [[1197, 1241], ["pytorch_models.TextInAllAspectSentimentOutModel.__init__", "len", "len", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "allennlp.training.metrics.CategoricalAccuracy", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1", "word_embedder.get_output_dim", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "pytorch_models.AttentionInHtt", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "range", "range", "int"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.cnn_encoder_seq2seq.CnnEncoder.get_output_dim"], ["    ", "def", "__init__", "(", "self", ",", "word_embedder", ":", "TextFieldEmbedder", ",", "position_embedder", ":", "TextFieldEmbedder", ",", "\n", "categories", ":", "list", ",", "polarities", ":", "list", ",", "vocab", ":", "Vocabulary", ",", "configuration", ":", "dict", ",", "\n", "bert_word_embedder", ":", "TextFieldEmbedder", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "configuration", "=", "configuration", "\n", "self", ".", "word_embedder", "=", "word_embedder", "\n", "self", ".", "position_embedder", "=", "position_embedder", "\n", "self", ".", "categories", "=", "categories", "\n", "self", ".", "polarites", "=", "polarities", "\n", "self", ".", "category_num", "=", "len", "(", "categories", ")", "\n", "self", ".", "polarity_num", "=", "len", "(", "polarities", ")", "\n", "self", ".", "category_loss", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "self", ".", "sentiment_loss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "_accuracy", "=", "metrics", ".", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "_f1", "=", "allennlp_metrics", ".", "BinaryF1", "(", "0.5", ")", "\n", "\n", "word_embedding_dim", "=", "word_embedder", ".", "get_output_dim", "(", ")", "\n", "if", "self", ".", "configuration", "[", "'lstm_or_fc_after_embedding_layer'", "]", "==", "'fc'", ":", "\n", "            ", "self", ".", "embedding_layer_fc", "=", "nn", ".", "Linear", "(", "word_embedding_dim", ",", "word_embedding_dim", ",", "bias", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embedding_layer_lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "word_embedding_dim", ",", "word_embedding_dim", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "False", ",", "num_layers", "=", "1", ")", "\n", "\n", "", "self", ".", "embedding_layer_aspect_attentions", "=", "[", "AttentionInHtt", "(", "word_embedding_dim", ",", "\n", "word_embedding_dim", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "self", ".", "embedding_layer_aspect_attentions", "=", "nn", ".", "ModuleList", "(", "self", ".", "embedding_layer_aspect_attentions", ")", "\n", "\n", "self", ".", "category_fcs", "=", "[", "nn", ".", "Linear", "(", "word_embedding_dim", ",", "1", ")", "for", "_", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "self", ".", "category_fcs", "=", "nn", ".", "ModuleList", "(", "self", ".", "category_fcs", ")", "\n", "\n", "if", "self", ".", "configuration", "[", "'lstm_layer_num_in_bert'", "]", "!=", "0", ":", "\n", "            ", "num_layers", "=", "self", ".", "configuration", "[", "'lstm_layer_num_in_bert'", "]", "\n", "self", ".", "lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "768", ",", "int", "(", "word_embedding_dim", "/", "2", ")", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "True", ",", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "self", ".", "configuration", "[", "'dropout_in_bert'", "]", ")", "\n", "hidden_size", "=", "word_embedding_dim", "\n", "", "else", ":", "\n", "            ", "hidden_size", "=", "768", "\n", "", "self", ".", "sentiment_fc", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "hidden_size", ",", "self", ".", "polarity_num", ")", ")", "\n", "\n", "self", ".", "bert_word_embedder", "=", "bert_word_embedder", "\n", "\n", "self", ".", "dropout_after_embedding_layer", "=", "nn", ".", "Dropout", "(", "self", ".", "configuration", "[", "'dropout_in_bert'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.set_grad_for_acd_parameter": [[1242, 1253], ["acd_layers.append", "acd_layers.append", "acd_layers.append", "acd_layers.append", "layer.named_parameters"], "methods", ["None"], ["", "def", "set_grad_for_acd_parameter", "(", "self", ",", "requires_grad", "=", "True", ")", ":", "\n", "        ", "acd_layers", "=", "[", "]", "\n", "if", "self", ".", "configuration", "[", "'lstm_or_fc_after_embedding_layer'", "]", "==", "'fc'", ":", "\n", "            ", "acd_layers", ".", "append", "(", "self", ".", "embedding_layer_fc", ")", "\n", "", "else", ":", "\n", "            ", "acd_layers", ".", "append", "(", "self", ".", "embedding_layer_lstm", ")", "\n", "", "acd_layers", ".", "append", "(", "self", ".", "embedding_layer_aspect_attentions", ")", "\n", "acd_layers", ".", "append", "(", "self", ".", "category_fcs", ")", "\n", "for", "layer", "in", "acd_layers", ":", "\n", "            ", "for", "name", ",", "value", "in", "layer", ".", "named_parameters", "(", ")", ":", "\n", "                ", "value", ".", "requires_grad", "=", "requires_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.set_grad_for_acsc_parameter": [[1254, 1265], ["acsc_layers.append", "bert_model.parameters", "acsc_layers.append", "layer.named_parameters"], "methods", ["None"], ["", "", "", "def", "set_grad_for_acsc_parameter", "(", "self", ",", "requires_grad", "=", "True", ")", ":", "\n", "        ", "acsc_layers", "=", "[", "]", "\n", "if", "self", ".", "configuration", "[", "'lstm_layer_num_in_bert'", "]", "!=", "0", ":", "\n", "            ", "acsc_layers", ".", "append", "(", "self", ".", "lstm", ")", "\n", "", "acsc_layers", ".", "append", "(", "self", ".", "sentiment_fc", ")", "\n", "for", "layer", "in", "acsc_layers", ":", "\n", "            ", "for", "name", ",", "value", "in", "layer", ".", "named_parameters", "(", ")", ":", "\n", "                ", "value", ".", "requires_grad", "=", "requires_grad", "\n", "", "", "bert_model", "=", "self", ".", "bert_word_embedder", ".", "_token_embedders", "[", "'bert'", "]", ".", "bert_model", "\n", "for", "param", "in", "bert_model", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.set_bert_word_embedder": [[1266, 1268], ["None"], "methods", ["None"], ["", "", "def", "set_bert_word_embedder", "(", "self", ",", "bert_word_embedder", ":", "TextFieldEmbedder", "=", "None", ")", ":", "\n", "        ", "self", ".", "bert_word_embedder", "=", "bert_word_embedder", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.forward": [[1269, 1475], ["pytorch_models.AsMilSimultaneouslyBertSingle.bert_word_embedder", "allennlp.nn.util.get_text_field_mask", "pytorch_models.AsMilSimultaneouslyBertSingle.word_embedder", "pytorch_models.AsMilSimultaneouslyBertSingle.size", "range", "bert_clses_of_all_aspect.append", "range", "range", "pytorch_models.AsMilSimultaneouslyBertSingle.embedding_layer_fc", "pytorch_models.AsMilSimultaneouslyBertSingle.embedding_layer_lstm", "embedding_layer_aspect_attention", "embedding_layer_category_alphas.append", "pytorch_models.AsMilSimultaneouslyBertSingle.element_wise_mul", "embedding_layer_category_outputs.append", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "embedding_layer_sentiment_outputs.append", "pytorch_models.AsMilSimultaneouslyBertSingle.sentiment_fc", "fc", "final_category_outputs.append", "final_sentiment_outputs.append", "range", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytorch_models.AsMilSimultaneouslyBertSingle._accuracy", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytorch_models.AsMilSimultaneouslyBertSingle._f1", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "range", "len", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "aspect_word_embeddings_from_bert.append", "pytorch_models.AsMilSimultaneouslyBertSingle.lstm", "lstm_layer_sentiment_outputs.append", "pytorch_models.AsMilSimultaneouslyBertSingle.dropout_after_embedding_layer", "category_labels.append", "polarity_labels.append", "polarity_masks.append", "pytorch_models.AsMilSimultaneouslyBertSingle.category_loss", "pytorch_models.AsMilSimultaneouslyBertSingle.sentiment_loss", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "len", "pytorch_models.TextInAllAspectSentimentOutModel._get_model_visualization_picture_filepath", "nlp_tasks.utils.attention_visualizer.plot_multi_attentions_of_sentence", "range", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "sentiment_alpha.unsqueeze.unsqueeze.unsqueeze", "pytorch_models.AsMilSimultaneouslyBertSingle.sentiment_fc", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "lstm_layer_sentiment_outputs.append", "pytorch_models.AsMilSimultaneouslyBertSingle.element_wise_mul", "pytorch_models.AsMilSimultaneouslyBertSingle.sentiment_fc", "lstm_layer_sentiment_outputs.append", "final_category_outputs[].squeeze", "polarity_labels[].long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "[].detach().cpu().numpy", "[].detach().cpu().numpy", "[].detach().cpu().numpy().tolist", "aspect_word_embeddings_from_bert_of_one_sample.append", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "aspect_word_embeddings_from_bert_of_one_sample.append", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "lstm_layer_words_sentiment_soft.append", "lstm_layer_words_sentiment_soft.append", "e.split", "range", "range", "range", "int", "[].detach().cpu().numpy", "visual_attentions_sentiment.append", "labels_sentiment.append", "range", "titles_sentiment.extend", "pytorch_models.TextInAllAspectSentimentOutModel._get_model_visualization_picture_filepath", "nlp_tasks.utils.attention_visualizer.plot_multi_attentions_of_sentence", "word_bert_embeddings.append", "len", "print", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "[].detach().cpu", "str", "str", "[].detach().cpu", "[].detach().cpu().numpy", "[].detach().cpu().numpy().tolist", "labels_sentiment.append", "visual_attentions_sentiment.append", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "len", "[].detach().cpu().numpy", "[].detach().cpu().numpy", "[].detach().cpu", "pytorch_models.AsMilSimultaneouslyBertSingle.categories[].split", "[].detach", "[].detach", "[].detach().cpu", "[].detach().cpu().numpy", "str", "str", "str", "[].detach().cpu", "[].detach().cpu", "[].detach().cpu().numpy", "[].detach", "[].detach", "[].detach().cpu", "[].detach", "[].detach", "[].detach().cpu", "len", "len", "[].detach", "[].detach", "len"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.element_wise_mul", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutModel._get_model_visualization_picture_filepath", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.attention_visualizer.plot_multi_attentions_of_sentence", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMil.element_wise_mul", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutModel._get_model_visualization_picture_filepath", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.attention_visualizer.plot_multi_attentions_of_sentence"], ["", "def", "forward", "(", "self", ",", "tokens", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "label", ":", "torch", ".", "Tensor", ",", "position", ":", "torch", ".", "Tensor", ",", "\n", "polarity_mask", ":", "torch", ".", "Tensor", ",", "sample", ":", "list", ",", "bert", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "bert_mask", "=", "bert", "[", "'mask'", "]", "\n", "bert_word_embeddings", "=", "self", ".", "bert_word_embedder", "(", "bert", ")", "\n", "\n", "mask", "=", "get_text_field_mask", "(", "tokens", ")", "\n", "word_embeddings", "=", "self", ".", "word_embedder", "(", "tokens", ")", "\n", "word_embeddings_size", "=", "word_embeddings", ".", "size", "(", ")", "\n", "if", "self", ".", "configuration", "[", "'lstm_or_fc_after_embedding_layer'", "]", "==", "'fc'", ":", "\n", "            ", "word_embeddings_fc", "=", "self", ".", "embedding_layer_fc", "(", "word_embeddings", ")", "\n", "", "else", ":", "\n", "            ", "word_embeddings_fc", ",", "(", "_", ",", "_", ")", "=", "self", ".", "embedding_layer_lstm", "(", "word_embeddings", ")", "\n", "\n", "", "embedding_layer_category_outputs", "=", "[", "]", "\n", "embedding_layer_category_alphas", "=", "[", "]", "\n", "embedding_layer_sentiment_outputs", "=", "[", "]", "\n", "embedding_layer_sentiment_alphas", "=", "[", "]", "\n", "bert_clses_of_all_aspect", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "            ", "embedding_layer_aspect_attention", "=", "self", ".", "embedding_layer_aspect_attentions", "[", "i", "]", "\n", "alpha", "=", "embedding_layer_aspect_attention", "(", "word_embeddings_fc", ",", "mask", ")", "\n", "embedding_layer_category_alphas", ".", "append", "(", "alpha", ")", "\n", "\n", "category_output", "=", "self", ".", "element_wise_mul", "(", "word_embeddings_fc", ",", "alpha", ",", "return_not_sum_result", "=", "False", ")", "\n", "embedding_layer_category_outputs", ".", "append", "(", "category_output", ")", "\n", "\n", "", "bert_clses_of_aspect", "=", "bert_word_embeddings", "[", ":", ",", "0", ",", "0", ",", ":", "]", "\n", "bert_clses_of_all_aspect", ".", "append", "(", "bert_clses_of_aspect", ")", "\n", "\n", "if", "not", "self", ".", "configuration", "[", "'only_bert'", "]", ":", "\n", "            ", "bert_word_embeddings_of_aspect", "=", "bert_word_embeddings", "[", ":", ",", "0", ",", ":", ",", ":", "]", "\n", "aspect_word_embeddings_from_bert", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "sample", ")", ")", ":", "\n", "                ", "aspect_word_embeddings_from_bert_of_one_sample", "=", "[", "]", "\n", "all_word_indices_in_bert", "=", "sample", "[", "j", "]", "[", "6", "]", "\n", "for", "k", "in", "range", "(", "word_embeddings_size", "[", "1", "]", ")", ":", "\n", "                    ", "if", "k", "in", "all_word_indices_in_bert", ":", "\n", "                        ", "word_indices_in_bert", "=", "all_word_indices_in_bert", "[", "k", "]", "\n", "word_bert_embeddings", "=", "[", "]", "\n", "for", "word_index_in_bert", "in", "word_indices_in_bert", ":", "\n", "                            ", "word_bert_embedding", "=", "bert_word_embeddings_of_aspect", "[", "j", "]", "[", "word_index_in_bert", "]", "\n", "word_bert_embeddings", ".", "append", "(", "word_bert_embedding", ")", "\n", "", "if", "len", "(", "word_bert_embeddings", ")", "==", "0", ":", "\n", "                            ", "print", "(", ")", "\n", "", "if", "len", "(", "word_bert_embeddings", ")", ">", "1", ":", "\n", "                            ", "word_bert_embeddings_unsqueeze", "=", "[", "torch", ".", "unsqueeze", "(", "e", ",", "dim", "=", "0", ")", "for", "e", "in", "word_bert_embeddings", "]", "\n", "word_bert_embeddings_cat", "=", "torch", ".", "cat", "(", "word_bert_embeddings_unsqueeze", ",", "dim", "=", "0", ")", "\n", "word_bert_embeddings_sum", "=", "torch", ".", "sum", "(", "word_bert_embeddings_cat", ",", "dim", "=", "0", ")", "\n", "word_bert_embeddings_ave", "=", "word_bert_embeddings_sum", "/", "len", "(", "word_bert_embeddings", ")", "\n", "", "else", ":", "\n", "                            ", "word_bert_embeddings_ave", "=", "word_bert_embeddings", "[", "0", "]", "\n", "", "aspect_word_embeddings_from_bert_of_one_sample", ".", "append", "(", "\n", "torch", ".", "unsqueeze", "(", "word_bert_embeddings_ave", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "                        ", "zero", "=", "torch", ".", "zeros_like", "(", "aspect_word_embeddings_from_bert_of_one_sample", "[", "-", "1", "]", ")", "\n", "aspect_word_embeddings_from_bert_of_one_sample", ".", "append", "(", "zero", ")", "\n", "", "", "aspect_word_embeddings_from_bert_of_one_sample_cat", "=", "torch", ".", "cat", "(", "\n", "aspect_word_embeddings_from_bert_of_one_sample", ",", "dim", "=", "0", ")", "\n", "aspect_word_embeddings_from_bert", ".", "append", "(", "\n", "torch", ".", "unsqueeze", "(", "aspect_word_embeddings_from_bert_of_one_sample_cat", ",", "dim", "=", "0", ")", ")", "\n", "", "aspect_word_embeddings_from_bert_cat", "=", "torch", ".", "cat", "(", "aspect_word_embeddings_from_bert", ",", "dim", "=", "0", ")", "\n", "if", "self", ".", "configuration", "[", "'lstm_layer_num_in_bert'", "]", "!=", "0", ":", "\n", "                ", "aspect_word_embeddings_from_bert_cat", ",", "_", "=", "self", ".", "lstm", "(", "aspect_word_embeddings_from_bert_cat", ")", "\n", "", "embedding_layer_sentiment_outputs", ".", "append", "(", "aspect_word_embeddings_from_bert_cat", ")", "\n", "\n", "", "lstm_layer_category_outputs", "=", "[", "]", "\n", "lstm_layer_sentiment_outputs", "=", "[", "]", "\n", "lstm_layer_words_sentiment_soft", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "            ", "sentiment_output_temp", "=", "bert_clses_of_all_aspect", "[", "0", "]", "\n", "sentiment_output_cls", "=", "self", ".", "sentiment_fc", "(", "sentiment_output_temp", ")", "\n", "if", "self", ".", "configuration", "[", "'only_bert'", "]", ":", "\n", "                ", "sentiment_output", "=", "sentiment_output_cls", "\n", "lstm_layer_sentiment_outputs", ".", "append", "(", "sentiment_output", ")", "\n", "", "else", ":", "\n", "# sentiment", "\n", "                ", "aspect_word_embeddings_from_bert", "=", "embedding_layer_sentiment_outputs", "[", "0", "]", "\n", "word_representation_for_sentiment", "=", "self", ".", "dropout_after_embedding_layer", "(", "aspect_word_embeddings_from_bert", ")", "\n", "\n", "sentiment_alpha", "=", "embedding_layer_category_alphas", "[", "i", "]", "\n", "if", "self", ".", "configuration", "[", "'mil'", "]", ":", "\n", "                    ", "sentiment_alpha", "=", "sentiment_alpha", ".", "unsqueeze", "(", "1", ")", "\n", "words_sentiment", "=", "self", ".", "sentiment_fc", "(", "word_representation_for_sentiment", ")", "\n", "if", "self", ".", "configuration", "[", "'mil_softmax'", "]", ":", "\n", "                        ", "words_sentiment_soft", "=", "torch", ".", "softmax", "(", "words_sentiment", ",", "dim", "=", "-", "1", ")", "\n", "lstm_layer_words_sentiment_soft", ".", "append", "(", "words_sentiment_soft", ")", "\n", "", "else", ":", "\n", "                        ", "words_sentiment_soft", "=", "words_sentiment", "\n", "lstm_layer_words_sentiment_soft", ".", "append", "(", "torch", ".", "softmax", "(", "words_sentiment", ",", "dim", "=", "-", "1", ")", ")", "\n", "", "sentiment_output_mil", "=", "torch", ".", "matmul", "(", "sentiment_alpha", ",", "words_sentiment_soft", ")", ".", "squeeze", "(", "1", ")", "# batch_size x 2*hidden_dim", "\n", "if", "self", ".", "configuration", "[", "'concat_cls_vector'", "]", ":", "\n", "                        ", "if", "self", ".", "configuration", "[", "'mil_softmax'", "]", ":", "\n", "                            ", "sentiment_output_cls_softmax", "=", "torch", ".", "softmax", "(", "sentiment_output_cls", ",", "dim", "=", "-", "1", ")", "\n", "sentiment_output", "=", "sentiment_output_mil", "+", "sentiment_output_cls_softmax", "\n", "", "else", ":", "\n", "                            ", "sentiment_output", "=", "sentiment_output_mil", "+", "sentiment_output_cls", "\n", "", "", "else", ":", "\n", "                        ", "sentiment_output", "=", "sentiment_output_mil", "\n", "", "lstm_layer_sentiment_outputs", ".", "append", "(", "sentiment_output", ")", "\n", "", "else", ":", "\n", "                    ", "sentiment_output_temp", "=", "self", ".", "element_wise_mul", "(", "word_representation_for_sentiment", ",", "sentiment_alpha", ",", "\n", "return_not_sum_result", "=", "False", ")", "\n", "sentiment_output_not_mil", "=", "self", ".", "sentiment_fc", "(", "sentiment_output_temp", ")", "\n", "if", "self", ".", "configuration", "[", "'concat_cls_vector'", "]", ":", "\n", "                        ", "sentiment_output", "=", "sentiment_output_not_mil", "+", "sentiment_output_cls", "\n", "", "else", ":", "\n", "                        ", "sentiment_output", "=", "sentiment_output_not_mil", "\n", "", "lstm_layer_sentiment_outputs", ".", "append", "(", "sentiment_output", ")", "\n", "\n", "", "", "", "final_category_outputs", "=", "[", "]", "\n", "final_lstm_category_outputs", "=", "[", "]", "\n", "final_sentiment_outputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "            ", "fc", "=", "self", ".", "category_fcs", "[", "i", "]", "\n", "category_output", "=", "embedding_layer_category_outputs", "[", "i", "]", "\n", "final_category_output", "=", "fc", "(", "category_output", ")", "\n", "final_category_outputs", ".", "append", "(", "final_category_output", ")", "\n", "\n", "sentiment_output", "=", "lstm_layer_sentiment_outputs", "[", "i", "]", "\n", "final_sentiment_output", "=", "sentiment_output", "\n", "final_sentiment_outputs", ".", "append", "(", "final_sentiment_output", ")", "\n", "\n", "", "output", "=", "{", "}", "\n", "if", "label", "is", "not", "None", ":", "\n", "            ", "category_labels", "=", "[", "]", "\n", "polarity_labels", "=", "[", "]", "\n", "polarity_masks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "                ", "category_labels", ".", "append", "(", "label", "[", ":", ",", "i", "]", ")", "\n", "polarity_labels", ".", "append", "(", "label", "[", ":", ",", "i", "+", "self", ".", "category_num", "]", ")", "\n", "polarity_masks", ".", "append", "(", "polarity_mask", "[", ":", ",", "i", "]", ")", "\n", "", "loss", "=", "0", "\n", "total_category_loss", "=", "0", "\n", "total_sentiment_loss", "=", "0", "\n", "for", "i", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "                ", "category_temp_loss", "=", "self", ".", "category_loss", "(", "final_category_outputs", "[", "i", "]", ".", "squeeze", "(", "dim", "=", "-", "1", ")", ",", "category_labels", "[", "i", "]", ")", "\n", "sentiment_temp_loss", "=", "self", ".", "sentiment_loss", "(", "final_sentiment_outputs", "[", "i", "]", ",", "polarity_labels", "[", "i", "]", ".", "long", "(", ")", ")", "\n", "total_category_loss", "+=", "category_temp_loss", "\n", "if", "not", "self", ".", "configuration", "[", "'only_acd'", "]", ":", "\n", "                    ", "total_sentiment_loss", "+=", "sentiment_temp_loss", "\n", "\n", "", "", "loss", "=", "self", ".", "category_loss_weight", "*", "total_category_loss", "+", "self", ".", "sentiment_loss_weight", "*", "total_sentiment_loss", "\n", "\n", "# sentiment accuracy", "\n", "sentiment_logit", "=", "torch", ".", "cat", "(", "final_sentiment_outputs", ")", "\n", "sentiment_label", "=", "torch", ".", "cat", "(", "polarity_labels", ")", "\n", "sentiment_mask", "=", "torch", ".", "cat", "(", "polarity_masks", ")", "\n", "self", ".", "_accuracy", "(", "sentiment_logit", ",", "sentiment_label", ",", "sentiment_mask", ")", "\n", "\n", "# category f1", "\n", "final_category_outputs_prob", "=", "[", "torch", ".", "sigmoid", "(", "e", ")", "for", "e", "in", "final_category_outputs", "]", "\n", "category_prob", "=", "torch", ".", "cat", "(", "final_category_outputs_prob", ")", ".", "squeeze", "(", ")", "\n", "category_label", "=", "torch", ".", "cat", "(", "category_labels", ")", "\n", "self", ".", "_f1", "(", "category_prob", ",", "category_label", ")", "\n", "\n", "output", "[", "'loss'", "]", "=", "loss", "\n", "\n", "# visualize attention", "\n", "", "pred_category", "=", "[", "torch", ".", "sigmoid", "(", "e", ")", "for", "e", "in", "final_category_outputs", "]", "\n", "pred_sentiment", "=", "[", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "e", ",", "dim", "=", "-", "1", ")", "for", "e", "in", "final_sentiment_outputs", "]", "\n", "output", "[", "'pred_category'", "]", "=", "pred_category", "\n", "output", "[", "'pred_sentiment'", "]", "=", "pred_sentiment", "\n", "if", "self", ".", "configuration", "[", "'visualize_attention'", "]", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "sample", ")", ")", ":", "\n", "                ", "words", "=", "sample", "[", "i", "]", "[", "2", "]", "\n", "attention_labels", "=", "[", "e", ".", "split", "(", "'/'", ")", "[", "0", "]", "for", "e", "in", "self", ".", "categories", "]", "\n", "\n", "# category", "\n", "visual_attentions_category", "=", "[", "embedding_layer_category_alphas", "[", "j", "]", "[", "i", "]", "[", ":", "len", "(", "words", ")", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "titles", "=", "[", "'true: %s - pred: %s'", "%", "(", "str", "(", "label", "[", "i", "]", "[", "j", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "str", "(", "pred_category", "[", "j", "]", "[", "i", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "savefig_filepath", "=", "super", "(", ")", ".", "_get_model_visualization_picture_filepath", "(", "self", ".", "configuration", ",", "words", ")", "\n", "attention_visualizer", ".", "plot_multi_attentions_of_sentence", "(", "words", ",", "visual_attentions_category", ",", "\n", "attention_labels", ",", "titles", ",", "savefig_filepath", ")", "\n", "\n", "# sentiment lstm layer", "\n", "visual_attentions_sentiment_temp", "=", "[", "lstm_layer_words_sentiment_soft", "[", "j", "]", "[", "i", "]", "[", ":", "len", "(", "words", ")", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "category_num", ")", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "category_num", ")", ":", "\n", "                    ", "c_label", "=", "label", "[", "i", "]", "[", "j", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "if", "c_label", "==", "1", ":", "\n", "                        ", "visual_attentions_sentiment", "=", "[", "]", "\n", "labels_sentiment", "=", "[", "]", "\n", "sentiment_true_index", "=", "int", "(", "label", "[", "i", "]", "[", "j", "+", "self", ".", "category_num", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "if", "sentiment_true_index", "==", "-", "100", ":", "\n", "                            ", "continue", "\n", "", "titles_sentiment", "=", "[", "'true: %s - pred: %s - %s'", "%", "(", "str", "(", "self", ".", "polarites", "[", "sentiment_true_index", "]", ")", ",", "\n", "str", "(", "pred_sentiment", "[", "j", "]", "[", "i", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "str", "(", "self", ".", "polarites", ")", ")", "]", "\n", "c_attention", "=", "embedding_layer_category_alphas", "[", "j", "]", "[", "i", "]", "[", ":", "len", "(", "words", ")", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "visual_attentions_sentiment", ".", "append", "(", "c_attention", ")", "\n", "labels_sentiment", ".", "append", "(", "self", ".", "categories", "[", "j", "]", ".", "split", "(", "'/'", ")", "[", "0", "]", ")", "\n", "\n", "s_distributions", "=", "visual_attentions_sentiment_temp", "[", "j", "]", "\n", "for", "k", "in", "range", "(", "self", ".", "polarity_num", ")", ":", "\n", "                            ", "labels_sentiment", ".", "append", "(", "self", ".", "polarites", "[", "k", "]", ")", "\n", "visual_attentions_sentiment", ".", "append", "(", "s_distributions", "[", ":", ",", "k", "]", ")", "\n", "", "titles_sentiment", ".", "extend", "(", "[", "''", "]", "*", "3", ")", "\n", "savefig_filepath", "=", "super", "(", ")", ".", "_get_model_visualization_picture_filepath", "(", "self", ".", "configuration", ",", "words", ")", "\n", "attention_visualizer", ".", "plot_multi_attentions_of_sentence", "(", "words", ",", "visual_attentions_sentiment", ",", "\n", "labels_sentiment", ",", "\n", "titles_sentiment", ",", "savefig_filepath", ")", "\n", "", "", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.get_metrics": [[1476, 1482], ["pytorch_models.AsMilSimultaneouslyBertSingle._accuracy.get_metric", "pytorch_models.AsMilSimultaneouslyBertSingle._f1.get_metric"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.get_metric", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.get_metric"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "metrics", "=", "{", "\n", "'accuracy'", ":", "self", ".", "_accuracy", ".", "get_metric", "(", "reset", ")", ",", "\n", "'category_f1'", ":", "self", ".", "_f1", ".", "get_metric", "(", "reset", ")", "[", "'fscore'", "]", "\n", "}", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.Estimator.estimate": [[1486, 1488], ["NotImplementedError"], "methods", ["None"], ["    ", "def", "estimate", "(", "self", ",", "ds", ":", "Iterable", "[", "Instance", "]", ")", "->", "dict", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'estimate'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator.__init__": [[1491, 1506], ["super().__init__", "allennlp.training.metrics.CategoricalAccuracy", "allennlp.training.metrics.CategoricalAccuracy", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ":", "Model", ",", "iterator", ":", "DataIterator", ",", "categories", ":", "list", ",", "polarities", ":", "list", ",", "\n", "cuda_device", ":", "int", "=", "-", "1", ",", "configuration", ":", "dict", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "iterator", "=", "iterator", "\n", "self", ".", "categories", "=", "categories", "\n", "self", ".", "polarities", "=", "polarities", "\n", "self", ".", "_sentiment_accuracy", "=", "metrics", ".", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "_sentiment_accuracy_temp", "=", "metrics", ".", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "_aspect_f1", "=", "allennlp_metrics", ".", "BinaryF1", "(", "0.5", ")", "\n", "self", ".", "_aspect_f1_temp", "=", "allennlp_metrics", ".", "BinaryF1", "(", "0.5", ")", "\n", "self", ".", "cuda_device", "=", "cuda_device", "\n", "self", ".", "configuration", "=", "configuration", "\n", "self", ".", "other_metrics", "=", "{", "}", "\n", "self", ".", "debug", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator._get_other_metrics": [[1507, 1512], ["None"], "methods", ["None"], ["", "def", "_get_other_metrics", "(", "self", ",", "reset", "=", "True", ")", ":", "\n", "        ", "result", "=", "self", ".", "other_metrics", "\n", "if", "reset", ":", "\n", "            ", "self", ".", "other_metrics", "=", "{", "}", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator._print_tensor": [[1513, 1520], ["print", "range", "len", "tuple", "print", "e.detach().cpu().numpy().tolist", "e.tolist", "isinstance", "len", "e.detach().cpu().numpy", "e.detach().cpu", "e.detach"], "methods", ["None"], ["", "def", "_print_tensor", "(", "self", ",", "tensors", ":", "List", ")", ":", "\n", "        ", "print", "(", "'------------------------------------------------------'", ")", "\n", "list_list", "=", "[", "e", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "if", "not", "isinstance", "(", "e", ",", "np", ".", "ndarray", ")", "else", "e", ".", "tolist", "(", ")", "for", "e", "in", "tensors", "]", "\n", "for", "k", "in", "range", "(", "len", "(", "list_list", "[", "0", "]", ")", ")", ":", "\n", "            ", "format_str", "=", "'-'", ".", "join", "(", "[", "'%s'", "]", "*", "len", "(", "list_list", ")", ")", "\n", "values", "=", "tuple", "(", "e", "[", "k", "]", "for", "e", "in", "list_list", ")", "\n", "print", "(", "format_str", "%", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator._acd_aspect_and_metrics": [[1521, 1537], ["enumerate", "category_labels[].detach().cpu().numpy().astype", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "pytorch_models.TextInAllAspectSentimentOutEstimator._print_tensor", "category_labels[].detach().cpu().numpy", "aspect_pred[].squeeze().detach().cpu().numpy", "category_labels[].detach().cpu", "aspect_pred[].squeeze().detach().cpu", "category_labels[].detach", "aspect_pred[].squeeze().detach", "aspect_pred[].squeeze"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel._print_tensor"], ["", "", "def", "_acd_aspect_and_metrics", "(", "self", ",", "category_labels", ",", "aspect_pred", ")", ":", "\n", "        ", "acd_aspect_and_metrics", "=", "{", "}", "\n", "for", "i", ",", "aspect", "in", "enumerate", "(", "self", ".", "categories", ")", ":", "\n", "            ", "aspect_label_i", "=", "category_labels", "[", "i", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "int", ")", "\n", "aspect_pred_i", "=", "(", "aspect_pred", "[", "i", "]", ".", "squeeze", "(", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">", "0.5", ")", ".", "astype", "(", "int", ")", "\n", "if", "self", ".", "debug", ":", "\n", "                ", "self", ".", "_print_tensor", "(", "[", "aspect_pred_i", ",", "aspect_label_i", "]", ")", "\n", "", "aspect_f1", "=", "f1_score", "(", "aspect_label_i", ",", "aspect_pred_i", ",", "average", "=", "'binary'", ")", "\n", "aspect_precision", "=", "precision_score", "(", "aspect_label_i", ",", "aspect_pred_i", ",", "average", "=", "'binary'", ")", "\n", "aspect_recall", "=", "recall_score", "(", "aspect_label_i", ",", "aspect_pred_i", ",", "average", "=", "'binary'", ")", "\n", "acd_aspect_and_metrics", "[", "aspect", "]", "=", "{", "\n", "'f1'", ":", "aspect_f1", ",", "\n", "'precision'", ":", "aspect_precision", ",", "\n", "'recall'", ":", "aspect_recall", "\n", "}", "\n", "", "return", "acd_aspect_and_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator._acsc_aspect_and_metrics": [[1538, 1551], ["enumerate", "pytorch_models.TextInAllAspectSentimentOutEstimator._sentiment_accuracy_temp", "pytorch_models.TextInAllAspectSentimentOutEstimator._sentiment_accuracy_temp.get_metric"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.get_metric"], ["", "def", "_acsc_aspect_and_metrics", "(", "self", ",", "polarity_labels", ",", "sentiment_pred", ",", "polarity_masks", ")", ":", "\n", "        ", "acsc_aspect_and_metrics", "=", "{", "}", "\n", "for", "i", ",", "aspect", "in", "enumerate", "(", "self", ".", "categories", ")", ":", "\n", "            ", "aspect_sentiment_label_i", "=", "polarity_labels", "[", "i", "]", "\n", "aspect_sentiment_pred_i", "=", "sentiment_pred", "[", "i", "]", "\n", "aspect_sentiment_mask_i", "=", "polarity_masks", "[", "i", "]", "\n", "self", ".", "_sentiment_accuracy_temp", "(", "aspect_sentiment_pred_i", ",", "aspect_sentiment_label_i", ",", "\n", "aspect_sentiment_mask_i", ")", "\n", "aspect_acc_temp", "=", "self", ".", "_sentiment_accuracy_temp", ".", "get_metric", "(", "reset", "=", "True", ")", ",", "\n", "acsc_aspect_and_metrics", "[", "aspect", "]", "=", "{", "\n", "'acc'", ":", "aspect_acc_temp", "[", "0", "]", ",", "\n", "}", "\n", "", "return", "acsc_aspect_and_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator._polarity_metrics": [[1552, 1580], ["sentiment_logit.argmax().detach().cpu().numpy().tolist", "sentiment_label.detach().cpu().numpy().tolist", "sentiment_mask.detach().cpu().numpy().tolist", "range", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "enumerate", "len", "sentiment_label_pred_final.append", "sentiment_label_final.append", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "sentiment_logit.argmax().detach().cpu().numpy", "sentiment_label.detach().cpu().numpy", "sentiment_mask.detach().cpu().numpy", "list", "list", "list", "range", "range", "range", "sentiment_logit.argmax().detach().cpu", "sentiment_label.detach().cpu", "sentiment_mask.detach().cpu", "len", "len", "len", "sentiment_logit.argmax().detach", "sentiment_label.detach", "sentiment_mask.detach", "sentiment_logit.argmax"], "methods", ["None"], ["", "def", "_polarity_metrics", "(", "self", ",", "sentiment_logit", ",", "sentiment_label", ",", "sentiment_mask", ")", ":", "\n", "        ", "sentiment_label_pred_list", "=", "sentiment_logit", ".", "argmax", "(", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "sentiment_label_list", "=", "sentiment_label", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "sentiment_mask_list", "=", "sentiment_mask", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "sentiment_label_pred_final", "=", "[", "]", "\n", "sentiment_label_final", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "sentiment_mask_list", ")", ")", ":", "\n", "            ", "sentiment_label_list_i", "=", "sentiment_label_list", "[", "i", "]", "\n", "sentiment_label_pred_list_i", "=", "sentiment_label_pred_list", "[", "i", "]", "\n", "sentiment_mask_list_i", "=", "sentiment_mask_list", "[", "i", "]", "\n", "if", "sentiment_mask_list_i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "sentiment_label_pred_final", ".", "append", "(", "sentiment_label_pred_list_i", ")", "\n", "sentiment_label_final", ".", "append", "(", "sentiment_label_list_i", ")", "\n", "", "sentiment_f1s", "=", "f1_score", "(", "np", ".", "array", "(", "sentiment_label_final", ")", ",", "np", ".", "array", "(", "sentiment_label_pred_final", ")", ",", "average", "=", "None", ",", "\n", "labels", "=", "list", "(", "range", "(", "len", "(", "self", ".", "polarities", ")", ")", ")", ")", "\n", "sentiment_precisions", "=", "precision_score", "(", "np", ".", "array", "(", "sentiment_label_final", ")", ",", "np", ".", "array", "(", "sentiment_label_pred_final", ")", ",", "\n", "average", "=", "None", ",", "labels", "=", "list", "(", "range", "(", "len", "(", "self", ".", "polarities", ")", ")", ")", ")", "\n", "sentiment_recalls", "=", "recall_score", "(", "np", ".", "array", "(", "sentiment_label_final", ")", ",", "np", ".", "array", "(", "sentiment_label_pred_final", ")", ",", "\n", "average", "=", "None", ",", "labels", "=", "list", "(", "range", "(", "len", "(", "self", ".", "polarities", ")", ")", ")", ")", "\n", "polarity_metrics", "=", "{", "}", "\n", "for", "i", ",", "polarity", "in", "enumerate", "(", "self", ".", "polarities", ")", ":", "\n", "            ", "polarity_metrics", "[", "polarity", "]", "=", "{", "\n", "'f1'", ":", "sentiment_f1s", "[", "i", "]", ",", "\n", "'precision'", ":", "sentiment_precisions", "[", "i", "]", ",", "\n", "'recall'", ":", "sentiment_recalls", "[", "i", "]", "\n", "}", "\n", "", "return", "polarity_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator._merge_micro_f1": [[1581, 1605], ["range"], "methods", ["None"], ["", "def", "_merge_micro_f1", "(", "self", ",", "merge_label_real", ",", "merge_logit_real", ")", ":", "\n", "        ", "tp", "=", "0", "\n", "pred_total", "=", "0", "\n", "true_total", "=", "0", "\n", "for", "i", "in", "range", "(", "merge_logit_real", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "pred", "=", "merge_logit_real", "[", "i", "]", "\n", "true", "=", "merge_label_real", "[", "i", "]", "\n", "if", "pred", "!=", "0", ":", "\n", "                ", "pred_total", "+=", "1", "\n", "", "if", "true", "!=", "0", ":", "\n", "                ", "true_total", "+=", "1", "\n", "", "if", "pred", "==", "true", "!=", "0", ":", "\n", "                ", "tp", "+=", "1", "\n", "", "", "if", "pred_total", "==", "0", ":", "\n", "            ", "pred_total", "=", "0.0000000000000001", "\n", "", "if", "true_total", "==", "0", ":", "\n", "            ", "true_total", "=", "0.0000000000000001", "\n", "", "p", "=", "tp", "/", "pred_total", "\n", "r", "=", "tp", "/", "true_total", "\n", "if", "p", "==", "0", "and", "r", "==", "0", ":", "\n", "            ", "f1", "=", "0", "\n", "", "else", ":", "\n", "            ", "f1", "=", "2", "*", "(", "p", "*", "r", ")", "/", "(", "p", "+", "r", ")", "\n", "", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator._inner_estimate": [[1606, 1662], ["len", "range", "pytorch_models.TextInAllAspectSentimentOutEstimator._acd_aspect_and_metrics", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytorch_models.TextInAllAspectSentimentOutEstimator._aspect_f1", "category_labels.append", "polarity_labels.append", "polarity_masks.append", "merge_labeles.append", "pytorch_models.TextInAllAspectSentimentOutEstimator._print_tensor", "pytorch_models.TextInAllAspectSentimentOutEstimator._print_tensor", "pytorch_models.TextInAllAspectSentimentOutEstimator._acsc_aspect_and_metrics", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytorch_models.TextInAllAspectSentimentOutEstimator._sentiment_accuracy", "pytorch_models.TextInAllAspectSentimentOutEstimator._polarity_metrics", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "allennlp.nn.util.move_to_device", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "allennlp.nn.util.move_to_device", "merge_logit[].argmax().detach().cpu().numpy", "merge_label[].detach().cpu().numpy", "pytorch_models.TextInAllAspectSentimentOutEstimator._merge_micro_f1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.argmax", "torch.cat.argmax", "torch.cat.argmax", "torch.cat.argmax", "pytorch_models.TextInAllAspectSentimentOutEstimator._print_tensor", "pytorch_models.TextInAllAspectSentimentOutEstimator._print_tensor", "merge_logit[].argmax().detach().cpu", "merge_label[].detach().cpu", "merge_logit[].argmax().detach", "merge_label[].detach", "merge_logit[].argmax"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator._acd_aspect_and_metrics", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel._print_tensor", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel._print_tensor", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator._acsc_aspect_and_metrics", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator._polarity_metrics", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator._merge_micro_f1", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel._print_tensor", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel._print_tensor"], ["", "def", "_inner_estimate", "(", "self", ",", "label", ",", "polarity_mask", ",", "aspect_pred", ",", "sentiment_pred", ",", "merge_pred", ")", ":", "\n", "        ", "category_labels", "=", "[", "]", "\n", "polarity_labels", "=", "[", "]", "\n", "merge_labeles", "=", "[", "]", "\n", "polarity_masks", "=", "[", "]", "\n", "category_num", "=", "len", "(", "self", ".", "categories", ")", "\n", "for", "i", "in", "range", "(", "category_num", ")", ":", "\n", "            ", "category_labels", ".", "append", "(", "label", "[", ":", ",", "i", "]", ")", "\n", "polarity_labels", ".", "append", "(", "label", "[", ":", ",", "i", "+", "category_num", "]", ")", "\n", "polarity_masks", ".", "append", "(", "polarity_mask", "[", ":", ",", "i", "]", ")", "\n", "merge_labeles", ".", "append", "(", "label", "[", ":", ",", "i", "+", "category_num", "*", "2", "]", ")", "\n", "", "if", "self", ".", "debug", ":", "\n", "            ", "self", ".", "_print_tensor", "(", "[", "label", "]", "+", "category_labels", "+", "polarity_labels", "+", "merge_labeles", ")", "\n", "self", ".", "_print_tensor", "(", "[", "polarity_mask", "]", "+", "polarity_masks", ")", "\n", "", "acd_aspect_and_metrics", "=", "self", ".", "_acd_aspect_and_metrics", "(", "category_labels", ",", "aspect_pred", ")", "\n", "self", ".", "other_metrics", "[", "'acd_metrics'", "]", "=", "acd_aspect_and_metrics", "\n", "# category f1", "\n", "category_prob", "=", "torch", ".", "cat", "(", "aspect_pred", ")", ".", "squeeze", "(", ")", "\n", "category_label", "=", "torch", ".", "cat", "(", "category_labels", ")", "\n", "self", ".", "_aspect_f1", "(", "category_prob", ",", "category_label", ")", "\n", "\n", "if", "not", "self", ".", "configuration", "[", "'only_acd'", "]", ":", "\n", "            ", "acsc_aspect_and_metrics", "=", "self", ".", "_acsc_aspect_and_metrics", "(", "polarity_labels", ",", "sentiment_pred", ",", "\n", "polarity_masks", ")", "\n", "self", ".", "other_metrics", "[", "'acsc_metrics'", "]", "=", "acsc_aspect_and_metrics", "\n", "\n", "# sentiment accuracy", "\n", "sentiment_logit", "=", "torch", ".", "cat", "(", "sentiment_pred", ")", "\n", "sentiment_label", "=", "torch", ".", "cat", "(", "polarity_labels", ")", "\n", "sentiment_mask", "=", "torch", ".", "cat", "(", "polarity_masks", ")", "\n", "self", ".", "_sentiment_accuracy", "(", "sentiment_logit", ",", "sentiment_label", ",", "sentiment_mask", ")", "\n", "\n", "polarity_metrics", "=", "self", ".", "_polarity_metrics", "(", "sentiment_logit", ",", "sentiment_label", ",", "\n", "sentiment_mask", ")", "\n", "self", ".", "other_metrics", "[", "'polarity_metrics'", "]", "=", "polarity_metrics", "\n", "\n", "# merge", "\n", "merge_logit", "=", "torch", ".", "cat", "(", "merge_pred", ")", "\n", "merge_pred_aspect_indicator", "=", "(", "merge_logit", ".", "argmax", "(", "dim", "=", "-", "1", ")", "!=", "0", ")", "\n", "merge_pred_aspect_indicator", "=", "nn_util", ".", "move_to_device", "(", "merge_pred_aspect_indicator", ",", "self", ".", "cuda_device", ")", "\n", "\n", "merge_label", "=", "torch", ".", "cat", "(", "merge_labeles", ")", "\n", "merge_label_aspect_indicator", "=", "(", "merge_label", "!=", "0", ")", "\n", "merge_label_aspect_indicator", "=", "nn_util", ".", "move_to_device", "(", "merge_label_aspect_indicator", ",", "self", ".", "cuda_device", ")", "\n", "\n", "merge_aspect_indicator", "=", "merge_pred_aspect_indicator", "|", "merge_label_aspect_indicator", "\n", "if", "self", ".", "debug", ":", "\n", "                ", "self", ".", "_print_tensor", "(", "[", "merge_logit", ",", "merge_pred_aspect_indicator", ",", "merge_label", ",", "merge_label_aspect_indicator", ",", "merge_aspect_indicator", "]", ")", "\n", "\n", "", "merge_logit_real", "=", "merge_logit", "[", "merge_aspect_indicator", "]", ".", "argmax", "(", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "merge_label_real", "=", "merge_label", "[", "merge_aspect_indicator", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "self", ".", "debug", ":", "\n", "                ", "self", ".", "_print_tensor", "(", "[", "merge_logit_real", ",", "merge_label_real", "]", ")", "\n", "# merge_micro_f1 = f1_score(merge_label_real, merge_logit_real, average='micro')", "\n", "", "merge_micro_f1", "=", "self", ".", "_merge_micro_f1", "(", "merge_label_real", ",", "merge_logit_real", ")", "\n", "self", ".", "other_metrics", "[", "'merge_micro_f1'", "]", "=", "merge_micro_f1", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator.estimate": [[1663, 1732], ["pytorch_models.TextInAllAspectSentimentOutEstimator.model.eval", "pytorch_models.TextInAllAspectSentimentOutEstimator.iterator", "tqdm.tqdm.tqdm", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "pytorch_models.TextInAllAspectSentimentOutEstimator._inner_estimate", "pytorch_models.TextInAllAspectSentimentOutEstimator._sentiment_accuracy.get_metric", "pytorch_models.TextInAllAspectSentimentOutEstimator._aspect_f1.get_metric", "pytorch_models.TextInAllAspectSentimentOutEstimator._get_other_metrics", "pytorch_models.TextInAllAspectSentimentOutEstimator.iterator.get_num_batches", "labels.append", "polarity_masks.append", "allennlp.nn.util.move_to_device", "pytorch_models.TextInAllAspectSentimentOutEstimator.model", "pred_categorys.append", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pred_category_final.append", "pred_sentiments.append", "pred_merges.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pred_sentiment_final.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pred_merge_final.append", "range", "len", "pred_category[].detach().clone().squeeze", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "pred_category_i.unsqueeze.unsqueeze.unsqueeze", "pred_merge.append", "print", "pytorch_models.TextInAllAspectSentimentOutEstimator._print_tensor", "pytorch_models.TextInAllAspectSentimentOutEstimator._print_tensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pred_category[].detach().clone", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pred_category[].detach"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator._inner_estimate", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.get_metric", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.get_metric", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator._get_other_metrics", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel._print_tensor", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel._print_tensor"], ["", "", "def", "estimate", "(", "self", ",", "ds", ":", "Iterable", "[", "Instance", "]", ")", "->", "dict", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "pred_generator", "=", "self", ".", "iterator", "(", "ds", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "pred_generator_tqdm", "=", "tqdm", "(", "pred_generator", ",", "total", "=", "self", ".", "iterator", ".", "get_num_batches", "(", "ds", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "labels", "=", "[", "]", "\n", "polarity_masks", "=", "[", "]", "\n", "pred_categorys", "=", "[", "]", "\n", "pred_sentiments", "=", "[", "]", "\n", "pred_merges", "=", "[", "]", "\n", "for", "batch", "in", "pred_generator_tqdm", ":", "\n", "                ", "label", "=", "batch", "[", "'label'", "]", "\n", "labels", ".", "append", "(", "label", ")", "\n", "\n", "polarity_mask", "=", "batch", "[", "'polarity_mask'", "]", "\n", "polarity_masks", ".", "append", "(", "polarity_mask", ")", "\n", "\n", "batch", "=", "nn_util", ".", "move_to_device", "(", "batch", ",", "self", ".", "cuda_device", ")", "\n", "out_dict", "=", "self", ".", "model", "(", "**", "batch", ")", "\n", "pred_category", "=", "out_dict", "[", "'pred_category'", "]", "\n", "pred_categorys", ".", "append", "(", "pred_category", ")", "\n", "if", "not", "self", ".", "configuration", "[", "'only_acd'", "]", ":", "\n", "                    ", "pred_sentiment", "=", "out_dict", "[", "'pred_sentiment'", "]", "\n", "pred_sentiments", ".", "append", "(", "pred_sentiment", ")", "\n", "\n", "if", "'merge_pred'", "in", "out_dict", ":", "\n", "                        ", "pred_merge", "=", "out_dict", "[", "'merge_pred'", "]", "\n", "", "else", ":", "\n", "                        ", "pred_merge", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "categories", ")", ")", ":", "\n", "                            ", "pred_category_i", "=", "pred_category", "[", "i", "]", ".", "detach", "(", ")", ".", "clone", "(", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "pred_sentiment_i", "=", "torch", ".", "softmax", "(", "pred_sentiment", "[", "i", "]", ",", "dim", "=", "-", "1", ")", "\n", "aspect_threshold", "=", "0.5", "if", "'aspect_threshold'", "not", "in", "self", ".", "configuration", "else", "self", ".", "configuration", "[", "'aspect_threshold'", "]", "\n", "pred_category_i_indicator", "=", "pred_category_i", ">", "aspect_threshold", "\n", "pred_category_i_indicator_not", "=", "pred_category_i", "<=", "aspect_threshold", "\n", "if", "self", ".", "debug", ":", "\n", "                                ", "print", "(", "i", ")", "\n", "self", ".", "_print_tensor", "(", "[", "pred_category_i", ",", "pred_sentiment_i", ",", "pred_category_i_indicator", ",", "pred_category_i_indicator_not", "]", ")", "\n", "", "pred_category_i", "[", "pred_category_i_indicator", "]", "=", "0", "\n", "pred_category_i", "[", "pred_category_i_indicator_not", "]", "=", "1.1", "\n", "pred_category_i", "=", "pred_category_i", ".", "unsqueeze", "(", "-", "1", ")", "\n", "if", "self", ".", "debug", ":", "\n", "                                ", "self", ".", "_print_tensor", "(", "[", "pred_category", "[", "i", "]", ",", "pred_category_i", ",", "torch", ".", "cat", "(", "[", "pred_category_i", ",", "pred_sentiment_i", "]", ",", "dim", "=", "-", "1", ")", "]", ")", "\n", "", "pred_merge", ".", "append", "(", "torch", ".", "cat", "(", "[", "pred_category_i", ",", "pred_sentiment_i", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "", "", "pred_merges", ".", "append", "(", "pred_merge", ")", "\n", "", "", "label_final", "=", "torch", ".", "cat", "(", "labels", ",", "dim", "=", "0", ")", "\n", "polarity_mask_final", "=", "torch", ".", "cat", "(", "polarity_masks", ",", "dim", "=", "0", ")", "\n", "pred_category_final", "=", "[", "]", "\n", "pred_sentiment_final", "=", "[", "]", "\n", "pred_merge_final", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "categories", ")", ")", ":", "\n", "                ", "pred_category_i", "=", "[", "e", "[", "i", "]", "for", "e", "in", "pred_categorys", "]", "\n", "pred_category_i_cat", "=", "torch", ".", "cat", "(", "pred_category_i", ",", "dim", "=", "0", ")", "\n", "pred_category_final", ".", "append", "(", "pred_category_i_cat", ")", "\n", "if", "not", "self", ".", "configuration", "[", "'only_acd'", "]", ":", "\n", "                    ", "pred_sentiment_i", "=", "[", "e", "[", "i", "]", "for", "e", "in", "pred_sentiments", "]", "\n", "pred_sentiment_i_cat", "=", "torch", ".", "cat", "(", "pred_sentiment_i", ",", "dim", "=", "0", ")", "\n", "pred_sentiment_final", ".", "append", "(", "pred_sentiment_i_cat", ")", "\n", "\n", "pred_merge_i", "=", "[", "e", "[", "i", "]", "for", "e", "in", "pred_merges", "]", "\n", "pred_merge_i_cat", "=", "torch", ".", "cat", "(", "pred_merge_i", ",", "dim", "=", "0", ")", "\n", "pred_merge_final", ".", "append", "(", "pred_merge_i_cat", ")", "\n", "\n", "# self._estimate(label_final, polarity_mask_final, pred_category_final, pred_sentiment_final)", "\n", "", "", "self", ".", "_inner_estimate", "(", "label_final", ",", "polarity_mask_final", ",", "pred_category_final", ",", "pred_sentiment_final", ",", "\n", "pred_merge_final", ")", "\n", "", "return", "{", "'sentiment_acc'", ":", "self", ".", "_sentiment_accuracy", ".", "get_metric", "(", "reset", "=", "True", ")", ",", "\n", "'category_f1'", ":", "self", ".", "_aspect_f1", ".", "get_metric", "(", "reset", "=", "True", ")", ",", "\n", "'other_metrics'", ":", "self", ".", "_get_other_metrics", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.Predictor.predict": [[1736, 1738], ["NotImplementedError"], "methods", ["None"], ["    ", "def", "predict", "(", "self", ",", "ds", ":", "Iterable", "[", "Instance", "]", ")", "->", "dict", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'predict'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictor.__init__": [[1741, 1751], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ":", "Model", ",", "iterator", ":", "DataIterator", ",", "categories", ":", "list", ",", "polarities", ":", "list", ",", "\n", "cuda_device", ":", "int", "=", "-", "1", ",", "configuration", ":", "dict", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "iterator", "=", "iterator", "\n", "self", ".", "categories", "=", "categories", "\n", "self", ".", "polarities", "=", "polarities", "\n", "self", ".", "cuda_device", "=", "cuda_device", "\n", "self", ".", "configuration", "=", "configuration", "\n", "self", ".", "debug", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictor._print_tensor": [[1752, 1759], ["print", "range", "len", "tuple", "print", "e.detach().cpu().numpy().tolist", "e.tolist", "isinstance", "len", "e.detach().cpu().numpy", "e.detach().cpu", "e.detach"], "methods", ["None"], ["", "def", "_print_tensor", "(", "self", ",", "tensors", ":", "List", ")", ":", "\n", "        ", "print", "(", "'------------------------------------------------------'", ")", "\n", "list_list", "=", "[", "e", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "if", "not", "isinstance", "(", "e", ",", "np", ".", "ndarray", ")", "else", "e", ".", "tolist", "(", ")", "for", "e", "in", "tensors", "]", "\n", "for", "k", "in", "range", "(", "len", "(", "list_list", "[", "0", "]", ")", ")", ":", "\n", "            ", "format_str", "=", "'-'", ".", "join", "(", "[", "'%s'", "]", "*", "len", "(", "list_list", ")", ")", "\n", "values", "=", "tuple", "(", "e", "[", "k", "]", "for", "e", "in", "list_list", ")", "\n", "print", "(", "format_str", "%", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictor.predict": [[1760, 1836], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "pytorch_models.TextInAllAspectSentimentOutPredictor.model.eval", "pytorch_models.TextInAllAspectSentimentOutPredictor.iterator", "tqdm.tqdm.tqdm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "range", "labels.append", "polarity_masks.append", "allennlp.nn.util.move_to_device", "pytorch_models.TextInAllAspectSentimentOutPredictor.model", "pred_categorys.append", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pred_category_final.append", "len", "range", "result.append", "pytorch_models.TextInAllAspectSentimentOutPredictor.iterator.get_num_batches", "pred_sentiments.append", "pred_merges.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pred_sentiment_final.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pred_merge_final.append", "len", "sample_predict[].argmax", "sample_result.append", "range", "len", "range", "len", "pred_category[].detach().clone().squeeze", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "pred_category_i.unsqueeze.unsqueeze.unsqueeze", "pred_merge.append", "len", "len", "len", "print", "pytorch_models.TextInAllAspectSentimentOutPredictor._print_tensor", "pytorch_models.TextInAllAspectSentimentOutPredictor._print_tensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pred_category[].detach().clone", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pred_category[].detach"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel._print_tensor", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel._print_tensor"], ["", "", "def", "predict", "(", "self", ",", "ds", ":", "Iterable", "[", "Instance", "]", ")", "->", "dict", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "pred_generator", "=", "self", ".", "iterator", "(", "ds", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "pred_generator_tqdm", "=", "tqdm", "(", "pred_generator", ",", "total", "=", "self", ".", "iterator", ".", "get_num_batches", "(", "ds", ")", ")", "\n", "labels", "=", "[", "]", "\n", "polarity_masks", "=", "[", "]", "\n", "pred_categorys", "=", "[", "]", "\n", "pred_sentiments", "=", "[", "]", "\n", "pred_merges", "=", "[", "]", "\n", "for", "batch", "in", "pred_generator_tqdm", ":", "\n", "                ", "label", "=", "batch", "[", "'label'", "]", "\n", "labels", ".", "append", "(", "label", ")", "\n", "\n", "polarity_mask", "=", "batch", "[", "'polarity_mask'", "]", "\n", "polarity_masks", ".", "append", "(", "polarity_mask", ")", "\n", "\n", "batch", "=", "nn_util", ".", "move_to_device", "(", "batch", ",", "self", ".", "cuda_device", ")", "\n", "out_dict", "=", "self", ".", "model", "(", "**", "batch", ")", "\n", "pred_category", "=", "out_dict", "[", "'pred_category'", "]", "\n", "pred_categorys", ".", "append", "(", "pred_category", ")", "\n", "if", "not", "self", ".", "configuration", "[", "'only_acd'", "]", ":", "\n", "                    ", "pred_sentiment", "=", "out_dict", "[", "'pred_sentiment'", "]", "\n", "pred_sentiments", ".", "append", "(", "pred_sentiment", ")", "\n", "\n", "if", "'merge_pred'", "in", "out_dict", ":", "\n", "                        ", "pred_merge", "=", "out_dict", "[", "'merge_pred'", "]", "\n", "", "else", ":", "\n", "                        ", "pred_merge", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "categories", ")", ")", ":", "\n", "                            ", "pred_category_i", "=", "pred_category", "[", "i", "]", ".", "detach", "(", ")", ".", "clone", "(", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "pred_sentiment_i", "=", "torch", ".", "softmax", "(", "pred_sentiment", "[", "i", "]", ",", "dim", "=", "-", "1", ")", "\n", "aspect_threshold", "=", "0.5", "if", "'aspect_threshold'", "not", "in", "self", ".", "configuration", "else", "self", ".", "configuration", "[", "'aspect_threshold'", "]", "\n", "pred_category_i_indicator", "=", "pred_category_i", ">", "aspect_threshold", "\n", "pred_category_i_indicator_not", "=", "pred_category_i", "<=", "aspect_threshold", "\n", "if", "self", ".", "debug", ":", "\n", "                                ", "print", "(", "i", ")", "\n", "self", ".", "_print_tensor", "(", "[", "pred_category_i", ",", "pred_sentiment_i", ",", "pred_category_i_indicator", ",", "pred_category_i_indicator_not", "]", ")", "\n", "", "pred_category_i", "[", "pred_category_i_indicator", "]", "=", "0", "\n", "pred_category_i", "[", "pred_category_i_indicator_not", "]", "=", "1.1", "\n", "pred_category_i", "=", "pred_category_i", ".", "unsqueeze", "(", "-", "1", ")", "\n", "if", "self", ".", "debug", ":", "\n", "                                ", "self", ".", "_print_tensor", "(", "[", "pred_category", "[", "i", "]", ",", "pred_category_i", ",", "torch", ".", "cat", "(", "[", "pred_category_i", ",", "pred_sentiment_i", "]", ",", "dim", "=", "-", "1", ")", "]", ")", "\n", "", "pred_merge", ".", "append", "(", "torch", ".", "cat", "(", "[", "pred_category_i", ",", "pred_sentiment_i", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "", "", "pred_merges", ".", "append", "(", "pred_merge", ")", "\n", "", "", "label_final", "=", "torch", ".", "cat", "(", "labels", ",", "dim", "=", "0", ")", "\n", "polarity_mask_final", "=", "torch", ".", "cat", "(", "polarity_masks", ",", "dim", "=", "0", ")", "\n", "pred_category_final", "=", "[", "]", "\n", "pred_sentiment_final", "=", "[", "]", "\n", "pred_merge_final", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "categories", ")", ")", ":", "\n", "                ", "pred_category_i", "=", "[", "e", "[", "i", "]", "for", "e", "in", "pred_categorys", "]", "\n", "pred_category_i_cat", "=", "torch", ".", "cat", "(", "pred_category_i", ",", "dim", "=", "0", ")", "\n", "pred_category_final", ".", "append", "(", "pred_category_i_cat", ")", "\n", "if", "not", "self", ".", "configuration", "[", "'only_acd'", "]", ":", "\n", "                    ", "pred_sentiment_i", "=", "[", "e", "[", "i", "]", "for", "e", "in", "pred_sentiments", "]", "\n", "pred_sentiment_i_cat", "=", "torch", ".", "cat", "(", "pred_sentiment_i", ",", "dim", "=", "0", ")", "\n", "pred_sentiment_final", ".", "append", "(", "pred_sentiment_i_cat", ")", "\n", "\n", "pred_merge_i", "=", "[", "e", "[", "i", "]", "for", "e", "in", "pred_merges", "]", "\n", "pred_merge_i_cat", "=", "torch", ".", "cat", "(", "pred_merge_i", ",", "dim", "=", "0", ")", "\n", "pred_merge_final", ".", "append", "(", "pred_merge_i_cat", ")", "\n", "", "", "result", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "ds", ")", ")", ":", "\n", "                ", "sample_label", "=", "label_final", "[", "i", "]", "[", "len", "(", "self", ".", "categories", ")", ":", "len", "(", "self", ".", "categories", ")", "+", "len", "(", "self", ".", "categories", ")", "]", "\n", "sample_predict", "=", "[", "pred_sentiment_final", "[", "j", "]", "[", "i", "]", "for", "j", "in", "range", "(", "len", "(", "self", ".", "categories", ")", ")", "]", "\n", "sample_result", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "self", ".", "categories", ")", ")", ":", "\n", "                    ", "if", "sample_label", "[", "j", "]", "==", "-", "100", ":", "\n", "                        ", "continue", "\n", "", "category", "=", "self", ".", "categories", "[", "j", "]", "\n", "sentiment_index", "=", "sample_predict", "[", "j", "]", ".", "argmax", "(", "dim", "=", "-", "1", ")", "\n", "sentiment", "=", "self", ".", "polarities", "[", "sentiment_index", "]", "\n", "sample_result", ".", "append", "(", "(", "category", ",", "sentiment", ")", ")", "\n", "", "result", ".", "append", "(", "sample_result", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel.__init__": [[1839, 1849], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ":", "Model", ",", "iterator", ":", "DataIterator", ",", "categories", ":", "list", ",", "polarities", ":", "list", ",", "\n", "cuda_device", ":", "int", "=", "-", "1", ",", "configuration", ":", "dict", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "iterator", "=", "iterator", "\n", "self", ".", "categories", "=", "categories", "\n", "self", ".", "polarities", "=", "polarities", "\n", "self", ".", "cuda_device", "=", "cuda_device", "\n", "self", ".", "configuration", "=", "configuration", "\n", "self", ".", "debug", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel._print_tensor": [[1850, 1857], ["print", "range", "len", "tuple", "print", "e.detach().cpu().numpy().tolist", "e.tolist", "isinstance", "len", "e.detach().cpu().numpy", "e.detach().cpu", "e.detach"], "methods", ["None"], ["", "def", "_print_tensor", "(", "self", ",", "tensors", ":", "List", ")", ":", "\n", "        ", "print", "(", "'------------------------------------------------------'", ")", "\n", "list_list", "=", "[", "e", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "if", "not", "isinstance", "(", "e", ",", "np", ".", "ndarray", ")", "else", "e", ".", "tolist", "(", ")", "for", "e", "in", "tensors", "]", "\n", "for", "k", "in", "range", "(", "len", "(", "list_list", "[", "0", "]", ")", ")", ":", "\n", "            ", "format_str", "=", "'-'", ".", "join", "(", "[", "'%s'", "]", "*", "len", "(", "list_list", ")", ")", "\n", "values", "=", "tuple", "(", "e", "[", "k", "]", "for", "e", "in", "list_list", ")", "\n", "print", "(", "format_str", "%", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel.predict": [[1858, 1875], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel.model.eval", "pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel.iterator", "tqdm.tqdm.tqdm", "allennlp.nn.util.move_to_device", "pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel.model", "range", "pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel.iterator.get_num_batches", "result.append", "e[].detach().cpu().numpy", "e[].detach().cpu().numpy", "e[].detach().cpu", "e[].detach().cpu", "e[].detach", "e[].detach"], "methods", ["None"], ["", "", "def", "predict", "(", "self", ",", "ds", ":", "Iterable", "[", "Instance", "]", ")", "->", "dict", ":", "\n", "        ", "result", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "pred_generator", "=", "self", ".", "iterator", "(", "ds", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "pred_generator_tqdm", "=", "tqdm", "(", "pred_generator", ",", "total", "=", "self", ".", "iterator", ".", "get_num_batches", "(", "ds", ")", ")", "\n", "for", "batch", "in", "pred_generator_tqdm", ":", "\n", "                ", "batch", "=", "nn_util", ".", "move_to_device", "(", "batch", ",", "self", ".", "cuda_device", ")", "\n", "out_dict", "=", "self", ".", "model", "(", "**", "batch", ")", "\n", "attention_weights", "=", "out_dict", "[", "'embedding_layer_category_alphas'", "]", "\n", "word_sentiments", "=", "out_dict", "[", "'lstm_layer_words_sentiment_soft'", "]", "\n", "for", "i", "in", "range", "(", "word_sentiments", "[", "0", "]", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "attention_weights_of_one_sample", "=", "[", "e", "[", "i", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "for", "e", "in", "attention_weights", "]", "\n", "word_sentiments_of_one_sample", "=", "[", "e", "[", "i", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "for", "e", "in", "word_sentiments", "]", "\n", "result", ".", "append", "(", "{", "'attention_weights'", ":", "attention_weights_of_one_sample", ",", "\n", "'word_sentiments'", ":", "word_sentiments_of_one_sample", "}", ")", "\n", "", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimatorAll.__init__": [[1878, 1889], ["super().__init__", "allennlp.training.metrics.CategoricalAccuracy", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ":", "Model", ",", "iterator", ":", "DataIterator", ",", "categories", ":", "list", ",", "polarities", ":", "list", ",", "\n", "cuda_device", ":", "int", "=", "-", "1", ",", "configuration", ":", "dict", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "iterator", "=", "iterator", "\n", "self", ".", "categories", "=", "categories", "\n", "self", ".", "polarities", "=", "polarities", "\n", "self", ".", "_accuracy", "=", "metrics", ".", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "_f1", "=", "allennlp_metrics", ".", "BinaryF1", "(", "0.5", ")", "\n", "self", ".", "cuda_device", "=", "cuda_device", "\n", "self", ".", "configuration", "=", "configuration", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimatorAll._estimate": [[1890, 1916], ["range", "pytorch_models.TextInAllAspectSentimentOutEstimatorAll.model", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytorch_models.TextInAllAspectSentimentOutEstimatorAll._f1", "len", "category_labels.append", "polarity_labels.append", "polarity_masks.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytorch_models.TextInAllAspectSentimentOutEstimatorAll._accuracy", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len"], "methods", ["None"], ["", "def", "_estimate", "(", "self", ",", "batch", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "label", "=", "batch", "[", "'label'", "]", "\n", "polarity_mask", "=", "batch", "[", "'polarity_mask'", "]", "\n", "category_labels", "=", "[", "]", "\n", "polarity_labels", "=", "[", "]", "\n", "polarity_masks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "categories", ")", ")", ":", "\n", "            ", "category_labels", ".", "append", "(", "label", "[", ":", ",", "i", "]", ")", "\n", "polarity_labels", ".", "append", "(", "label", "[", ":", ",", "i", "+", "len", "(", "self", ".", "categories", ")", "]", ")", "\n", "polarity_masks", ".", "append", "(", "polarity_mask", "[", ":", ",", "i", "]", ")", "\n", "\n", "", "out_dict", "=", "self", ".", "model", "(", "**", "batch", ")", "\n", "pred_category", "=", "out_dict", "[", "'pred_category'", "]", "\n", "\n", "if", "not", "self", ".", "configuration", "[", "'only_acd'", "]", ":", "\n", "            ", "pred_sentiment", "=", "out_dict", "[", "'pred_sentiment'", "]", "\n", "\n", "sentiment_logit", "=", "torch", ".", "cat", "(", "pred_sentiment", ")", "\n", "sentiment_label", "=", "torch", ".", "cat", "(", "polarity_labels", ")", "\n", "sentiment_mask", "=", "torch", ".", "cat", "(", "polarity_masks", ")", "\n", "self", ".", "_accuracy", "(", "sentiment_logit", ",", "sentiment_label", ",", "sentiment_mask", ")", "\n", "\n", "# category f1", "\n", "", "category_prob", "=", "torch", ".", "cat", "(", "pred_category", ")", ".", "squeeze", "(", ")", "\n", "category_label", "=", "torch", ".", "cat", "(", "category_labels", ")", "\n", "self", ".", "_f1", "(", "category_prob", ",", "category_label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimatorAll.estimate": [[1917, 1928], ["pytorch_models.TextInAllAspectSentimentOutEstimatorAll.model.eval", "pytorch_models.TextInAllAspectSentimentOutEstimatorAll.iterator", "tqdm.tqdm.tqdm", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "pytorch_models.TextInAllAspectSentimentOutEstimatorAll._accuracy.get_metric", "pytorch_models.TextInAllAspectSentimentOutEstimatorAll._f1.get_metric", "pytorch_models.TextInAllAspectSentimentOutEstimatorAll.iterator.get_num_batches", "allennlp.nn.util.move_to_device", "pytorch_models.TextInAllAspectSentimentOutEstimatorAll._estimate"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.get_metric", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_metrics.BinaryF1.get_metric", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimatorAll._estimate"], ["", "def", "estimate", "(", "self", ",", "ds", ":", "Iterable", "[", "Instance", "]", ")", "->", "dict", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "pred_generator", "=", "self", ".", "iterator", "(", "ds", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "pred_generator_tqdm", "=", "tqdm", "(", "pred_generator", ",", "\n", "total", "=", "self", ".", "iterator", ".", "get_num_batches", "(", "ds", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch", "in", "pred_generator_tqdm", ":", "\n", "                ", "batch", "=", "nn_util", ".", "move_to_device", "(", "batch", ",", "self", ".", "cuda_device", ")", "\n", "self", ".", "_estimate", "(", "batch", ")", "\n", "", "", "return", "{", "'sentiment_acc'", ":", "self", ".", "_accuracy", ".", "get_metric", "(", "reset", "=", "True", ")", ",", "\n", "'category_f1'", ":", "self", ".", "_f1", ".", "get_metric", "(", "reset", "=", "True", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.__init__": [[49, 73], ["nlp_tasks.absa.entities.ModelTrainTemplate.ModelTrainTemplate.__init__", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._load_data", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_max_sentence_len", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._build_vocab", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._build_iterator"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_data", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_max_sentence_len", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._build_vocab", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._build_iterator"], ["def", "__init__", "(", "self", ",", "configuration", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "configuration", ")", "\n", "self", ".", "data_reader", ":", "DatasetReader", "=", "None", "\n", "self", ".", "train_data", "=", "None", "\n", "self", ".", "dev_data", "=", "None", "\n", "self", ".", "test_data", "=", "None", "\n", "self", ".", "hard_test_data", "=", "None", "\n", "self", ".", "distinct_categories", ":", "List", "[", "str", "]", "=", "None", "\n", "self", ".", "distinct_polarities", ":", "List", "[", "str", "]", "=", "None", "\n", "self", ".", "_load_data", "(", ")", "\n", "self", ".", "_get_max_sentence_len", "(", ")", "\n", "if", "self", ".", "configuration", "[", "'debug'", "]", ":", "\n", "            ", "self", ".", "train_data", "=", "self", ".", "train_data", "[", ":", "128", "]", "\n", "self", ".", "dev_data", "=", "self", ".", "dev_data", "[", ":", "128", "]", "\n", "self", ".", "test_data", "=", "self", ".", "test_data", "[", ":", "128", "]", "\n", "\n", "", "self", ".", "vocab", "=", "None", "\n", "self", ".", "_build_vocab", "(", ")", "\n", "\n", "self", ".", "iterator", "=", "None", "\n", "self", ".", "val_iterator", "=", "None", "\n", "self", ".", "_build_iterator", "(", ")", "\n", "\n", "self", ".", "acd_model_dir", "=", "self", ".", "model_dir", "+", "'acd/'", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_max_sentence_len": [[74, 88], ["collections.defaultdict", "len_count_list.sort", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.logger.info", "collections.defaultdict.items", "str", "len"], "methods", ["None"], ["", "def", "_get_max_sentence_len", "(", "self", ")", ":", "\n", "        ", "len_count", "=", "collections", ".", "defaultdict", "(", "int", ")", "\n", "for", "data", "in", "[", "self", ".", "train_data", ",", "self", ".", "test_data", ",", "self", ".", "dev_data", "]", ":", "\n", "            ", "if", "data", "is", "None", ":", "\n", "                ", "continue", "\n", "", "for", "sample", "in", "data", ":", "\n", "                ", "tokens", "=", "sample", ".", "fields", "[", "'tokens'", "]", ".", "tokens", "\n", "# tokens = sample.fields['sample'].metadata[4]", "\n", "# if len(tokens) > self.configuration['max_len']:", "\n", "#     print(tokens)", "\n", "len_count", "[", "len", "(", "tokens", ")", "]", "+=", "1", "\n", "", "", "len_count_list", "=", "[", "[", "items", "[", "0", "]", ",", "items", "[", "1", "]", "]", "for", "items", "in", "len_count", ".", "items", "(", ")", "]", "\n", "len_count_list", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "self", ".", "logger", ".", "info", "(", "'len_count_list: %s'", "%", "str", "(", "len_count_list", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_data_reader": [[89, 102], ["allennlp.data.token_indexers.SingleIdTokenIndexer", "allennlp.data.token_indexers.SingleIdTokenIndexer", "allennlp.data.token_indexers.SingleIdTokenIndexer", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.TextInAllAspectSentimentOut", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_word_segmenter"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._get_word_segmenter"], ["", "def", "_get_data_reader", "(", "self", ")", ":", "\n", "        ", "token_indexer", "=", "SingleIdTokenIndexer", "(", "namespace", "=", "\"tokens\"", ")", "\n", "position_indexer", "=", "SingleIdTokenIndexer", "(", "namespace", "=", "'position'", ")", "\n", "aspect_indexer", "=", "SingleIdTokenIndexer", "(", "namespace", "=", "'aspect'", ")", "\n", "reader", "=", "acd_and_sc_data_reader", ".", "TextInAllAspectSentimentOut", "(", "\n", "self", ".", "distinct_categories", ",", "self", ".", "distinct_polarities", ",", "\n", "tokenizer", "=", "self", ".", "_get_word_segmenter", "(", ")", ",", "\n", "token_indexers", "=", "{", "\"tokens\"", ":", "token_indexer", "}", ",", "\n", "position_indexers", "=", "{", "'position'", ":", "position_indexer", "}", ",", "\n", "aspect_indexers", "=", "{", "'aspect'", ":", "aspect_indexer", "}", ",", "\n", "configuration", "=", "self", ".", "configuration", "\n", ")", "\n", "return", "reader", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._load_data": [[103, 160], ["os.path.exists", "super()._load_object", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_data_reader", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.dataset.generate_acd_and_sc_data", "train_dev_test_data.items", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_data_reader", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.read", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.read", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.read", "super()._save_object", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.read", "set", "distinct_polarities_new.append", "len", "train_dev_test_data[].append", "distinct_categories.index", "labels_new.append", "len", "sample_new.append", "data_new.append", "distinct_polarities_new.index"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_object", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBert._get_data_reader", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Semeval2014Task4RestDevSplits.generate_acd_and_sc_data", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBert._get_data_reader", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._save_object"], ["", "def", "_load_data", "(", "self", ")", ":", "\n", "        ", "data_filepath", "=", "self", ".", "base_data_dir", "+", "'data'", "\n", "if", "os", ".", "path", ".", "exists", "(", "data_filepath", ")", ":", "\n", "            ", "self", ".", "train_data", ",", "self", ".", "dev_data", ",", "self", ".", "test_data", ",", "self", ".", "distinct_categories", ",", "self", ".", "distinct_polarities", ",", "self", ".", "hard_test_data", "=", "super", "(", ")", ".", "_load_object", "(", "data_filepath", ")", "\n", "reader", "=", "self", ".", "_get_data_reader", "(", ")", "\n", "self", ".", "data_reader", "=", "reader", "\n", "", "else", ":", "\n", "            ", "train_dev_test_data", ",", "distinct_categories", ",", "distinct_polarities", "=", "self", ".", "dataset", ".", "generate_acd_and_sc_data", "(", "dev_size", "=", "0.2", ")", "\n", "\n", "if", "self", ".", "configuration", "[", "'hard_test'", "]", ":", "\n", "                ", "train_dev_test_data", "[", "'hard_test'", "]", "=", "[", "]", "\n", "for", "sample", "in", "train_dev_test_data", "[", "'test'", "]", ":", "\n", "                    ", "polarities", "=", "set", "(", "[", "e", "[", "1", "]", "for", "e", "in", "sample", "[", "1", "]", "]", ")", "\n", "if", "len", "(", "polarities", ")", ">=", "2", ":", "\n", "                        ", "train_dev_test_data", "[", "'hard_test'", "]", ".", "append", "(", "sample", ")", "\n", "\n", "", "", "", "distinct_polarities_new", "=", "[", "]", "\n", "for", "polarity", "in", "distinct_polarities", ":", "\n", "                ", "if", "polarity", "!=", "'conflict'", ":", "\n", "                    ", "distinct_polarities_new", ".", "append", "(", "polarity", ")", "\n", "", "", "self", ".", "distinct_categories", "=", "distinct_categories", "\n", "self", ".", "distinct_polarities", "=", "distinct_polarities_new", "\n", "\n", "train_dev_test_data_label_indexed", "=", "{", "}", "\n", "for", "data_type", ",", "data", "in", "train_dev_test_data", ".", "items", "(", ")", ":", "\n", "                ", "if", "data", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "data_new", "=", "[", "]", "\n", "for", "sample", "in", "data", ":", "\n", "                    ", "sample_new", "=", "[", "sample", "[", "0", "]", "]", "\n", "labels_new", "=", "[", "]", "\n", "for", "label", "in", "sample", "[", "1", "]", ":", "\n", "                        ", "aspect", "=", "label", "[", "0", "]", "\n", "polarity", "=", "label", "[", "1", "]", "\n", "aspect_index", "=", "distinct_categories", ".", "index", "(", "aspect", ")", "\n", "if", "polarity", "==", "'conflict'", ":", "\n", "                            ", "polarity_index", "=", "-", "100", "\n", "", "else", ":", "\n", "                            ", "polarity_index", "=", "distinct_polarities_new", ".", "index", "(", "polarity", ")", "\n", "", "labels_new", ".", "append", "(", "(", "aspect_index", ",", "polarity_index", ")", ")", "\n", "", "if", "len", "(", "labels_new", ")", "!=", "0", ":", "\n", "                        ", "sample_new", ".", "append", "(", "labels_new", ")", "\n", "data_new", ".", "append", "(", "sample_new", ")", "\n", "", "", "train_dev_test_data_label_indexed", "[", "data_type", "]", "=", "data_new", "\n", "\n", "", "reader", "=", "self", ".", "_get_data_reader", "(", ")", "\n", "self", ".", "data_reader", "=", "reader", "\n", "self", ".", "train_data", "=", "reader", ".", "read", "(", "train_dev_test_data_label_indexed", "[", "'train'", "]", ")", "\n", "self", ".", "dev_data", "=", "reader", ".", "read", "(", "train_dev_test_data_label_indexed", "[", "'dev'", "]", ")", "\n", "self", ".", "test_data", "=", "reader", ".", "read", "(", "train_dev_test_data_label_indexed", "[", "'test'", "]", ")", "\n", "if", "self", ".", "configuration", "[", "'hard_test'", "]", ":", "\n", "                ", "self", ".", "hard_test_data", "=", "reader", ".", "read", "(", "train_dev_test_data_label_indexed", "[", "'hard_test'", "]", ")", "\n", "", "data", "=", "[", "self", ".", "train_data", ",", "self", ".", "dev_data", ",", "self", ".", "test_data", ",", "self", ".", "distinct_categories", ",", "\n", "self", ".", "distinct_polarities", ",", "self", ".", "hard_test_data", "]", "\n", "super", "(", ")", ".", "_save_object", "(", "data_filepath", ",", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._build_vocab": [[161, 173], ["os.path.exists", "super()._load_object", "allennlp.data.vocabulary.Vocabulary.from_instances", "super()._save_object"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_object", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._save_object"], ["", "", "def", "_build_vocab", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "configuration", "[", "'train'", "]", ":", "\n", "            ", "vocab_file_path", "=", "self", ".", "base_data_dir", "+", "'vocab'", "\n", "if", "os", ".", "path", ".", "exists", "(", "vocab_file_path", ")", ":", "\n", "                ", "self", ".", "vocab", "=", "super", "(", ")", ".", "_load_object", "(", "vocab_file_path", ")", "\n", "", "else", ":", "\n", "                ", "data", "=", "self", ".", "train_data", "+", "self", ".", "dev_data", "+", "self", ".", "test_data", "\n", "self", ".", "vocab", "=", "Vocabulary", ".", "from_instances", "(", "data", ",", "max_vocab_size", "=", "sys", ".", "maxsize", ")", "\n", "super", "(", ")", ".", "_save_object", "(", "vocab_file_path", ",", "self", ".", "vocab", ")", "\n", "", "self", ".", "model_meta_data", "[", "'vocab'", "]", "=", "self", ".", "vocab", "\n", "", "else", ":", "\n", "            ", "self", ".", "vocab", "=", "self", ".", "model_meta_data", "[", "'vocab'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._build_iterator": [[174, 181], ["allennlp.data.iterators.BucketIterator", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.iterator.index_with", "allennlp.data.iterators.BasicIterator", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.val_iterator.index_with"], "methods", ["None"], ["", "", "def", "_build_iterator", "(", "self", ")", ":", "\n", "        ", "self", ".", "iterator", "=", "BucketIterator", "(", "batch_size", "=", "self", ".", "configuration", "[", "'batch_size'", "]", ",", "\n", "sorting_keys", "=", "[", "(", "\"tokens\"", ",", "\"num_tokens\"", ")", "]", ",", "\n", ")", "\n", "self", ".", "iterator", ".", "index_with", "(", "self", ".", "vocab", ")", "\n", "self", ".", "val_iterator", "=", "BasicIterator", "(", "batch_size", "=", "self", ".", "configuration", "[", "'batch_size'", "]", ")", "\n", "self", ".", "val_iterator", ".", "index_with", "(", "self", ".", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._print_args": [[182, 194], ["model.parameters", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.logger.info", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.logger.info", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.configuration.keys", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.logger.info", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "_print_args", "(", "self", ",", "model", ")", ":", "\n", "        ", "n_trainable_params", ",", "n_nontrainable_params", "=", "0", ",", "0", "\n", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "n_params", "=", "torch", ".", "prod", "(", "torch", ".", "tensor", "(", "p", ".", "shape", ")", ")", ".", "item", "(", ")", "\n", "if", "p", ".", "requires_grad", ":", "\n", "                ", "n_trainable_params", "+=", "n_params", "\n", "", "else", ":", "\n", "                ", "n_nontrainable_params", "+=", "n_params", "\n", "", "", "self", ".", "logger", ".", "info", "(", "'n_trainable_params: {0}, n_nontrainable_params: {1}'", ".", "format", "(", "n_trainable_params", ",", "n_nontrainable_params", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "'> training arguments:'", ")", "\n", "for", "arg", "in", "self", ".", "configuration", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "'>>> {0}: {1}'", ".", "format", "(", "arg", ",", "self", ".", "configuration", "[", "arg", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._find_model_function_pure": [[195, 197], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "_find_model_function_pure", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'_find_model_function_pure'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_aspect_embeddings_dim": [[198, 200], ["None"], "methods", ["None"], ["", "def", "_get_aspect_embeddings_dim", "(", "self", ")", ":", "\n", "        ", "return", "300", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_position_embeddings_dim": [[201, 203], ["None"], "methods", ["None"], ["", "def", "_get_position_embeddings_dim", "(", "self", ")", ":", "\n", "        ", "return", "300", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._is_train_token_embeddings": [[204, 206], ["None"], "methods", ["None"], ["", "def", "_is_train_token_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._find_model_function": [[207, 248], ["os.path.exists", "allennlp.modules.token_embedders.embedding._read_embeddings_from_text_file.to", "allennlp.modules.token_embedders.Embedding", "allennlp.modules.text_field_embedders.BasicTextFieldEmbedder", "allennlp.modules.token_embedders.Embedding", "allennlp.modules.text_field_embedders.BasicTextFieldEmbedder", "allennlp.modules.token_embedders.Embedding", "allennlp.modules.text_field_embedders.BasicTextFieldEmbedder", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._find_model_function_pure", "model_function", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._print_args", "model.to.to.to", "super()._load_object", "allennlp.modules.token_embedders.embedding._read_embeddings_from_text_file", "super()._save_object", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.vocab.get_vocab_size", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._is_train_token_embeddings", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.vocab.get_vocab_size", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_position_embeddings_dim", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.vocab.get_vocab_size", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_aspect_embeddings_dim"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMil._find_model_function_pure", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._print_args", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_object", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._save_object", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._is_train_token_embeddings", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMil._get_position_embeddings_dim", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_aspect_embeddings_dim"], ["", "def", "_find_model_function", "(", "self", ")", ":", "\n", "        ", "embedding_dim", "=", "self", ".", "configuration", "[", "'embed_size'", "]", "\n", "embedding_matrix_filepath", "=", "self", ".", "base_data_dir", "+", "'embedding_matrix'", "\n", "if", "os", ".", "path", ".", "exists", "(", "embedding_matrix_filepath", ")", ":", "\n", "            ", "embedding_matrix", "=", "super", "(", ")", ".", "_load_object", "(", "embedding_matrix_filepath", ")", "\n", "", "else", ":", "\n", "            ", "embedding_filepath", "=", "self", ".", "configuration", "[", "'embedding_filepath'", "]", "\n", "embedding_matrix", "=", "embedding", ".", "_read_embeddings_from_text_file", "(", "embedding_filepath", ",", "embedding_dim", ",", "\n", "self", ".", "vocab", ",", "namespace", "=", "'tokens'", ")", "\n", "super", "(", ")", ".", "_save_object", "(", "embedding_matrix_filepath", ",", "embedding_matrix", ")", "\n", "", "embedding_matrix", "=", "embedding_matrix", ".", "to", "(", "self", ".", "configuration", "[", "'device'", "]", ")", "\n", "token_embedding", "=", "Embedding", "(", "num_embeddings", "=", "self", ".", "vocab", ".", "get_vocab_size", "(", "namespace", "=", "'tokens'", ")", ",", "\n", "embedding_dim", "=", "embedding_dim", ",", "padding_index", "=", "0", ",", "vocab_namespace", "=", "'tokens'", ",", "\n", "trainable", "=", "self", ".", "_is_train_token_embeddings", "(", ")", ",", "weight", "=", "embedding_matrix", ")", "\n", "# the embedder maps the input tokens to the appropriate embedding matrix", "\n", "word_embedder", ":", "TextFieldEmbedder", "=", "BasicTextFieldEmbedder", "(", "{", "\"tokens\"", ":", "token_embedding", "}", ")", "\n", "\n", "position_embedding", "=", "Embedding", "(", "num_embeddings", "=", "self", ".", "vocab", ".", "get_vocab_size", "(", "namespace", "=", "'position'", ")", ",", "\n", "embedding_dim", "=", "self", ".", "_get_position_embeddings_dim", "(", ")", ",", "padding_index", "=", "0", ")", "\n", "position_embedder", ":", "TextFieldEmbedder", "=", "BasicTextFieldEmbedder", "(", "{", "\"position\"", ":", "position_embedding", "}", ",", "\n", "# we'll be ignoring masks so we'll need to set this to True", "\n", "allow_unmatched_keys", "=", "True", ")", "\n", "\n", "aspect_embedding", "=", "Embedding", "(", "num_embeddings", "=", "self", ".", "vocab", ".", "get_vocab_size", "(", "namespace", "=", "'aspect'", ")", ",", "\n", "embedding_dim", "=", "self", ".", "_get_aspect_embeddings_dim", "(", ")", ",", "padding_index", "=", "0", ")", "\n", "aspect_embedder", ":", "TextFieldEmbedder", "=", "BasicTextFieldEmbedder", "(", "{", "\"aspect\"", ":", "aspect_embedding", "}", ",", "\n", "# we'll be ignoring masks so we'll need to set this to True", "\n", "allow_unmatched_keys", "=", "True", ")", "\n", "model_function", ":", "pytorch_models", ".", "TextInAllAspectSentimentOutModel", "=", "self", ".", "_find_model_function_pure", "(", ")", "\n", "model", "=", "model_function", "(", "\n", "word_embedder", ",", "\n", "position_embedder", ",", "\n", "aspect_embedder", ",", "\n", "self", ".", "distinct_categories", ",", "\n", "self", ".", "distinct_polarities", ",", "\n", "self", ".", "vocab", ",", "\n", "self", ".", "configuration", ",", "\n", ")", "\n", "self", ".", "_print_args", "(", "model", ")", "\n", "model", "=", "model", ".", "to", "(", "self", ".", "configuration", "[", "'device'", "]", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_optimizer": [[249, 252], ["filter", "torch.Adam", "torch.Adam", "model.parameters"], "methods", ["None"], ["", "def", "_get_optimizer", "(", "self", ",", "model", ")", ":", "\n", "        ", "_params", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", "\n", "return", "optim", ".", "Adam", "(", "_params", ",", "lr", "=", "0.001", ",", "weight_decay", "=", "0.00001", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_acd_optimizer": [[253, 256], ["filter", "torch.Adam", "torch.Adam", "model.parameters"], "methods", ["None"], ["", "def", "_get_acd_optimizer", "(", "self", ",", "model", ")", ":", "\n", "        ", "_params", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", "\n", "return", "optim", ".", "Adam", "(", "_params", ",", "lr", "=", "0.001", ",", "weight_decay", "=", "0.00001", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_acd_warmup_epoch_num": [[257, 259], ["None"], "methods", ["None"], ["", "def", "_get_acd_warmup_epoch_num", "(", "self", ")", ":", "\n", "        ", "return", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_estimator": [[260, 272], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator"], "methods", ["None"], ["", "def", "_get_estimator", "(", "self", ",", "model", ")", ":", "\n", "        ", "USE_GPU", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "if", "USE_GPU", ":", "\n", "            ", "gpu_id", "=", "self", ".", "configuration", "[", "'gpu_id'", "]", "\n", "", "else", ":", "\n", "            ", "gpu_id", "=", "-", "1", "\n", "", "estimator", "=", "pytorch_models", ".", "TextInAllAspectSentimentOutEstimator", "(", "model", ",", "self", ".", "val_iterator", ",", "\n", "self", ".", "distinct_categories", ",", "\n", "self", ".", "distinct_polarities", ",", "\n", "configuration", "=", "self", ".", "configuration", ",", "\n", "cuda_device", "=", "gpu_id", ")", "\n", "return", "estimator", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_estimate_callback": [[273, 286], ["acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_estimator", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.allennlp_callback.EstimateCallback", "result.append"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_estimator"], ["", "def", "_get_estimate_callback", "(", "self", ",", "model", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "data_type_and_data", "=", "{", "\n", "'train'", ":", "self", ".", "train_data", ",", "\n", "'dev'", ":", "self", ".", "dev_data", ",", "\n", "'test'", ":", "self", ".", "test_data", "\n", "}", "\n", "if", "self", ".", "hard_test_data", ":", "\n", "            ", "data_type_and_data", "[", "'hard_test'", "]", "=", "self", ".", "hard_test_data", "\n", "", "estimator", "=", "self", ".", "_get_estimator", "(", "model", ")", "\n", "estimate_callback", "=", "allennlp_callback", ".", "EstimateCallback", "(", "data_type_and_data", ",", "estimator", ",", "self", ".", "logger", ")", "\n", "result", ".", "append", "(", "estimate_callback", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_loss_weight_callback": [[287, 293], ["nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.allennlp_callback.SetLossWeightCallback", "result.append", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_acd_warmup_epoch_num"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_acd_warmup_epoch_num"], ["", "def", "_get_loss_weight_callback", "(", "self", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "set_loss_weight_callback", "=", "allennlp_callback", ".", "SetLossWeightCallback", "(", "self", ".", "model", ",", "self", ".", "logger", ",", "\n", "acd_warmup_epoch_num", "=", "self", ".", "_get_acd_warmup_epoch_num", "(", ")", ")", "\n", "result", ".", "append", "(", "set_loss_weight_callback", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_fixed_loss_weight_callback": [[294, 301], ["nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.allennlp_callback.FixedLossWeightCallback", "result.append"], "methods", ["None"], ["", "def", "_get_fixed_loss_weight_callback", "(", "self", ",", "model", ",", "category_loss_weight", "=", "1", ",", "sentiment_loss_weight", "=", "1", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "fixed_loss_weight_callback", "=", "allennlp_callback", ".", "FixedLossWeightCallback", "(", "model", ",", "self", ".", "logger", ",", "\n", "category_loss_weight", "=", "category_loss_weight", ",", "\n", "sentiment_loss_weight", "=", "sentiment_loss_weight", ")", "\n", "result", ".", "append", "(", "fixed_loss_weight_callback", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_bert_word_embedder": [[302, 304], ["None"], "methods", ["None"], ["", "def", "_get_bert_word_embedder", "(", "self", ")", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._inner_train": [[305, 389], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._find_model_function", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_estimator", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_estimate_callback", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.logger.info", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_optimizer", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._print_args", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer.Trainer", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer.Trainer.train", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.logger.info", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_acd_optimizer", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.logger.info", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_estimate_callback", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.extend", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._print_args", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer.Trainer", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer.Trainer.train", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.logger.info", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.extend", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.model.no_grad_for_acd_parameter", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.extend", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.model.set_grad_for_acsc_parameter", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_fixed_loss_weight_callback", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.model.set_grad_for_acsc_parameter", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.model.set_bert_word_embedder", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_bert_word_embedder", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.model.set_bert_word_embedder", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_fixed_loss_weight_callback", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_fixed_loss_weight_callback", "str", "str"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._find_model_function", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_estimator", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_estimate_callback", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBertSingle._get_optimizer", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._print_args", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate.train", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_acd_optimizer", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_estimate_callback", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._print_args", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate.train", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutModel.no_grad_for_acd_parameter", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.set_grad_for_acsc_parameter", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_fixed_loss_weight_callback", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.set_grad_for_acsc_parameter", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.set_bert_word_embedder", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBertSingle._get_bert_word_embedder", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.set_bert_word_embedder", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_fixed_loss_weight_callback", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_fixed_loss_weight_callback"], ["", "def", "_inner_train", "(", "self", ")", ":", "\n", "        ", "USE_GPU", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "if", "USE_GPU", ":", "\n", "            ", "gpu_id", "=", "self", ".", "configuration", "[", "'gpu_id'", "]", "\n", "", "else", ":", "\n", "            ", "gpu_id", "=", "-", "1", "\n", "\n", "", "self", ".", "model", ":", "pytorch_models", ".", "TextInAllAspectSentimentOutModel", "=", "self", ".", "_find_model_function", "(", ")", "\n", "\n", "estimator", "=", "self", ".", "_get_estimator", "(", "self", ".", "model", ")", "\n", "if", "self", ".", "configuration", "[", "'acd_warmup'", "]", ":", "\n", "            ", "if", "self", ".", "configuration", "[", "'frozen_all_acsc_parameter_while_pretrain_acd'", "]", ":", "\n", "                ", "self", ".", "model", ".", "set_grad_for_acsc_parameter", "(", "requires_grad", "=", "False", ")", "\n", "\n", "", "optimizer", "=", "self", ".", "_get_acd_optimizer", "(", "self", ".", "model", ")", "\n", "self", ".", "logger", ".", "info", "(", "'acd warmup'", ")", "\n", "validation_metric", "=", "'+category_f1'", "\n", "callbacks", "=", "self", ".", "_get_estimate_callback", "(", "self", ".", "model", ")", "\n", "callbacks", ".", "extend", "(", "self", ".", "_get_fixed_loss_weight_callback", "(", "self", ".", "model", ",", "category_loss_weight", "=", "1", ",", "sentiment_loss_weight", "=", "0", ")", ")", "\n", "self", ".", "_print_args", "(", "self", ".", "model", ")", "\n", "trainer", "=", "Trainer", "(", "\n", "model", "=", "self", ".", "model", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "iterator", "=", "self", ".", "iterator", ",", "\n", "train_dataset", "=", "self", ".", "train_data", ",", "\n", "validation_dataset", "=", "self", ".", "dev_data", ",", "\n", "cuda_device", "=", "gpu_id", ",", "\n", "num_epochs", "=", "self", ".", "configuration", "[", "'acd_warmup_epochs'", "]", ",", "\n", "validation_metric", "=", "validation_metric", ",", "\n", "validation_iterator", "=", "self", ".", "val_iterator", ",", "\n", "serialization_dir", "=", "self", ".", "acd_model_dir", ",", "\n", "patience", "=", "None", "if", "self", ".", "configuration", "[", "'acd_warmup_patience'", "]", "==", "-", "1", "else", "self", ".", "configuration", "[", "'acd_warmup_patience'", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "num_serialized_models_to_keep", "=", "2", ",", "\n", "early_stopping_by_batch", "=", "self", ".", "configuration", "[", "'early_stopping_by_batch'", "]", ",", "\n", "estimator", "=", "estimator", ",", "\n", "grad_clipping", "=", "5", "\n", ")", "\n", "metrics", "=", "trainer", ".", "train", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "'acd metrics: %s'", "%", "str", "(", "metrics", ")", ")", "\n", "\n", "if", "self", ".", "configuration", "[", "'frozen_all_acsc_parameter_while_pretrain_acd'", "]", ":", "\n", "                ", "self", ".", "model", ".", "set_grad_for_acsc_parameter", "(", "requires_grad", "=", "True", ")", "\n", "", "if", "'bert'", "in", "self", ".", "configuration", "and", "self", ".", "configuration", "[", "'bert'", "]", ":", "\n", "                ", "self", ".", "model", ".", "set_bert_word_embedder", "(", ")", "\n", "bert_word_embedder", "=", "self", ".", "_get_bert_word_embedder", "(", ")", "\n", "self", ".", "model", ".", "set_bert_word_embedder", "(", "bert_word_embedder", ")", "\n", "\n", "", "", "if", "self", ".", "configuration", "[", "'only_acd'", "]", ":", "\n", "            ", "return", "None", "\n", "", "validation_metric", "=", "'+accuracy'", "\n", "if", "'early_stopping_metric'", "in", "self", ".", "configuration", ":", "\n", "            ", "validation_metric", "=", "'+%s'", "%", "self", ".", "configuration", "[", "'early_stopping_metric'", "]", "\n", "", "callbacks", "=", "self", ".", "_get_estimate_callback", "(", "self", ".", "model", ")", "\n", "if", "self", ".", "configuration", "[", "'acd_warmup'", "]", "and", "self", ".", "configuration", "[", "'pipeline'", "]", ":", "\n", "            ", "callbacks", ".", "extend", "(", "self", ".", "_get_fixed_loss_weight_callback", "(", "self", ".", "model", ",", "category_loss_weight", "=", "0", ",", "sentiment_loss_weight", "=", "1", ")", ")", "\n", "self", ".", "model", ".", "no_grad_for_acd_parameter", "(", ")", "\n", "", "else", ":", "\n", "            ", "callbacks", ".", "extend", "(", "self", ".", "_get_fixed_loss_weight_callback", "(", "self", ".", "model", ",", "\n", "category_loss_weight", "=", "self", ".", "configuration", "[", "'acd_init_weight'", "]", ",", "\n", "sentiment_loss_weight", "=", "1", ")", ")", "\n", "", "self", ".", "logger", ".", "info", "(", "'validation_metric: %s'", "%", "validation_metric", ")", "\n", "optimizer", "=", "self", ".", "_get_optimizer", "(", "self", ".", "model", ")", "\n", "self", ".", "_print_args", "(", "self", ".", "model", ")", "\n", "trainer", "=", "Trainer", "(", "\n", "model", "=", "self", ".", "model", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "iterator", "=", "self", ".", "iterator", ",", "\n", "train_dataset", "=", "self", ".", "train_data", ",", "\n", "validation_dataset", "=", "self", ".", "dev_data", "if", "self", ".", "configuration", "[", "'early_stopping'", "]", "else", "None", ",", "\n", "cuda_device", "=", "gpu_id", ",", "\n", "num_epochs", "=", "self", ".", "configuration", "[", "'epochs'", "]", ",", "\n", "validation_metric", "=", "validation_metric", ",", "\n", "validation_iterator", "=", "self", ".", "val_iterator", ",", "\n", "serialization_dir", "=", "self", ".", "model_dir", ",", "\n", "patience", "=", "self", ".", "configuration", "[", "'patience'", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "num_serialized_models_to_keep", "=", "2", ",", "\n", "early_stopping_by_batch", "=", "self", ".", "configuration", "[", "'early_stopping_by_batch'", "]", ",", "\n", "estimator", "=", "estimator", ",", "\n", "grad_clipping", "=", "5", "\n", ")", "\n", "metrics", "=", "trainer", ".", "train", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "'metrics: %s'", "%", "str", "(", "metrics", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._save_model": [[390, 392], ["torch.save", "torch.save", "torch.save", "torch.save"], "methods", ["None"], ["", "def", "_save_model", "(", "self", ")", ":", "\n", "        ", "torch", ".", "save", "(", "self", ".", "model", ",", "self", ".", "best_model_filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._load_model": [[393, 399], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.device", "torch.device", "torch.device", "torch.device"], "methods", ["None"], ["", "def", "_load_model", "(", "self", ")", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "model", "=", "torch", ".", "load", "(", "self", ".", "best_model_filepath", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", "=", "torch", ".", "load", "(", "self", ".", "best_model_filepath", ",", "map_location", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", "\n", "", "self", ".", "model", ".", "configuration", "=", "self", ".", "configuration", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.evaluate": [[400, 434], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator", "data_type_and_data.items", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.configuration[].split", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimator.estimate", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.logger.info", "len", "data_of_different_lengths.items", "int", "len", "len", "data_of_different_lengths[].append"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimatorAll.estimate"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "USE_GPU", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "if", "USE_GPU", ":", "\n", "            ", "gpu_id", "=", "self", ".", "configuration", "[", "'gpu_id'", "]", "\n", "", "else", ":", "\n", "            ", "gpu_id", "=", "-", "1", "\n", "", "estimator", "=", "pytorch_models", ".", "TextInAllAspectSentimentOutEstimator", "(", "self", ".", "model", ",", "self", ".", "val_iterator", ",", "\n", "self", ".", "distinct_categories", ",", "\n", "self", ".", "distinct_polarities", ",", "\n", "configuration", "=", "self", ".", "configuration", ",", "\n", "cuda_device", "=", "gpu_id", ")", "\n", "\n", "data_type_and_data", "=", "{", "\n", "# 'train': self.train_data,", "\n", "'dev'", ":", "self", ".", "dev_data", ",", "\n", "'test'", ":", "self", ".", "test_data", "\n", "}", "\n", "if", "self", ".", "hard_test_data", ":", "\n", "            ", "data_type_and_data", "[", "'hard_test'", "]", "=", "self", ".", "hard_test_data", "\n", "", "if", "'performance_of_different_lengths'", "in", "self", ".", "configuration", ":", "\n", "            ", "lengths", "=", "self", ".", "configuration", "[", "'performance_of_different_lengths'", "]", ".", "split", "(", "','", ")", "\n", "if", "len", "(", "lengths", ")", ">", "1", ":", "\n", "                ", "data_of_different_lengths", "=", "{", "int", "(", "length", ")", ":", "[", "]", "for", "length", "in", "lengths", "}", "\n", "for", "sample", "in", "data_type_and_data", "[", "'test'", "]", ":", "\n", "                    ", "tokens", "=", "sample", ".", "fields", "[", "'tokens'", "]", ".", "tokens", "\n", "for", "length", "in", "data_of_different_lengths", ":", "\n", "                        ", "if", "len", "(", "tokens", ")", "<=", "length", ":", "\n", "                            ", "data_of_different_lengths", "[", "length", "]", ".", "append", "(", "sample", ")", "\n", "", "", "", "for", "length", ",", "data", "in", "data_of_different_lengths", ".", "items", "(", ")", ":", "\n", "                    ", "if", "len", "(", "data", ")", ">", "0", ":", "\n", "                        ", "data_type_and_data", "[", "'test_%d'", "%", "length", "]", "=", "data", "\n", "", "", "", "", "for", "data_type", ",", "data", "in", "data_type_and_data", ".", "items", "(", ")", ":", "\n", "            ", "result", "=", "estimator", ".", "estimate", "(", "data", ")", "\n", "self", ".", "logger", ".", "info", "(", "'data_type: %s result: %s'", "%", "(", "data_type", ",", "result", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.evaluation_on_instance_level": [[435, 527], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "nlp_tasks.absa.data_adapter.mil_data.MAMSACSAMil.load_samples", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.data_reader.read", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictorOnInstanceLevel.predict", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._get_word_segmenter", "range", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.logger.info", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.logger.info", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.logger.info", "print", "nlp_tasks.absa.data_adapter.mil_data.SemEval2014Task4RESTHardMil", "texts.append", "len", "collections.defaultdict", "collections.defaultdict", "set", "set", "set.difference", "set.difference", "len", "len", "len", "collections.defaultdict.items", "nlp_tasks.absa.data_adapter.mil_data.MAMSACSAMil", "NotImplementedError", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.", "range", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.distinct_categories.index", "range", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.distinct_categories.index", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.distinct_categories.index", "len", "key_instances_true[].append", "len", "numpy.argmax", "len", "key_instances_pred[].append", "collections.defaultdict.values", "collections.defaultdict.values", "len"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.MAMSACSAMil.load_samples", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.predict", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._get_word_segmenter"], ["", "", "def", "evaluation_on_instance_level", "(", "self", ")", ":", "\n", "        ", "USE_GPU", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "if", "USE_GPU", ":", "\n", "            ", "gpu_id", "=", "self", ".", "configuration", "[", "'gpu_id'", "]", "\n", "", "else", ":", "\n", "            ", "gpu_id", "=", "-", "1", "\n", "\n", "", "dataset_name", "=", "self", ".", "configuration", "[", "'current_dataset'", "]", "\n", "if", "dataset_name", "==", "'SemEval-2014-Task-4-REST-DevSplits'", ":", "\n", "# mil = mil_data.SemEval2014Task4RESTMil()", "\n", "            ", "mil", "=", "mil_data", ".", "SemEval2014Task4RESTHardMil", "(", ")", "\n", "", "elif", "dataset_name", "==", "'MAMSACSA'", ":", "\n", "            ", "mil", "=", "mil_data", ".", "MAMSACSAMil", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'don\\'t support evaluate performance on instance for the dataset %s'", "\n", "%", "dataset_name", ")", "\n", "", "samples", "=", "mil", ".", "load_samples", "(", ")", "\n", "texts", "=", "[", "]", "\n", "for", "sample", "in", "samples", ":", "\n", "            ", "text", "=", "sample", ".", "text", "\n", "labels", "=", "[", "[", "self", ".", "distinct_categories", ".", "index", "(", "category", ")", ",", "0", "]", "for", "category", "in", "sample", ".", "categories", "]", "\n", "texts", ".", "append", "(", "[", "text", ",", "labels", "]", ")", "\n", "", "predictor", "=", "pytorch_models", ".", "TextInAllAspectSentimentOutPredictorOnInstanceLevel", "(", "self", ".", "model", ",", "self", ".", "val_iterator", ",", "\n", "self", ".", "distinct_categories", ",", "\n", "self", ".", "distinct_polarities", ",", "\n", "configuration", "=", "self", ".", "configuration", ",", "\n", "cuda_device", "=", "gpu_id", ")", "\n", "\n", "data", "=", "self", ".", "data_reader", ".", "read", "(", "texts", ")", "\n", "result", "=", "predictor", ".", "predict", "(", "data", ")", "\n", "tokenizer", "=", "self", ".", "_get_word_segmenter", "(", ")", "\n", "correct_sentiment_num", "=", "0", "\n", "total_sentiment_num", "=", "0", "\n", "tp_for_key_instance", "=", "0", "\n", "fp_for_key_instance", "=", "0", "\n", "fn_for_key_instance", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "samples", ")", ")", ":", "\n", "            ", "sample", "=", "samples", "[", "i", "]", "\n", "words", "=", "data", "[", "i", "]", ".", "fields", "[", "'tokens'", "]", ".", "tokens", "\n", "key_instances_true", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "key_instance", "in", "sample", ".", "key_instances", ":", "\n", "                ", "text_before_key_instance", "=", "sample", ".", "text", "[", ":", "key_instance", ".", "from_index", "]", "\n", "words_before_key_instance", "=", "tokenizer", "(", "text_before_key_instance", ")", "\n", "words_of_key_instance", "=", "tokenizer", "(", "key_instance", ".", "text", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "words_of_key_instance", ")", ")", ":", "\n", "                    ", "key_instances_true", "[", "key_instance", ".", "category", "]", ".", "append", "(", "{", "'word'", ":", "words_of_key_instance", "[", "j", "]", ",", "\n", "'index'", ":", "len", "(", "words_before_key_instance", ")", "+", "j", ",", "\n", "'polarity'", ":", "key_instance", ".", "polarity", "}", ")", "\n", "", "", "attention_weights", "=", "result", "[", "i", "]", "[", "'attention_weights'", "]", "\n", "categories", "=", "sample", ".", "categories", "\n", "key_instances_pred", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "category", "in", "categories", ":", "\n", "                ", "category_index", "=", "self", ".", "distinct_categories", ".", "index", "(", "category", ")", "\n", "attention_weights_of_this_category", "=", "attention_weights", "[", "category_index", "]", "[", ":", "len", "(", "words", ")", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "words", ")", ")", ":", "\n", "                    ", "word", "=", "words", "[", "j", "]", "\n", "weight", "=", "attention_weights_of_this_category", "[", "j", "]", "\n", "if", "weight", ">=", "0.1", ":", "\n", "                        ", "key_instances_pred", "[", "category", "]", ".", "append", "(", "{", "'word'", ":", "word", ",", "'index'", ":", "j", "}", ")", "\n", "\n", "", "", "", "key_instances_true_str", "=", "set", "(", "[", "'%s-%d'", "%", "(", "e", "[", "'word'", "]", ",", "e", "[", "'index'", "]", ")", "for", "key_instances_of_a_category", "in", "key_instances_true", ".", "values", "(", ")", "for", "e", "in", "key_instances_of_a_category", "]", ")", "\n", "key_instances_pred_str", "=", "set", "(", "[", "'%s-%d'", "%", "(", "e", "[", "'word'", "]", ",", "e", "[", "'index'", "]", ")", "for", "key_instances_of_a_category", "in", "key_instances_pred", ".", "values", "(", ")", "for", "e", "in", "key_instances_of_a_category", "]", ")", "\n", "tp_instances", "=", "key_instances_true_str", "&", "key_instances_pred_str", "\n", "fp_instances", "=", "key_instances_pred_str", ".", "difference", "(", "key_instances_true_str", ")", "\n", "fn_instances", "=", "key_instances_true_str", ".", "difference", "(", "key_instances_pred_str", ")", "\n", "\n", "tp_for_key_instance", "+=", "len", "(", "tp_instances", ")", "\n", "fp_for_key_instance", "+=", "len", "(", "fp_instances", ")", "\n", "fn_for_key_instance", "+=", "len", "(", "fn_instances", ")", "\n", "\n", "word_sentiments", "=", "result", "[", "i", "]", "[", "'word_sentiments'", "]", "\n", "for", "category", ",", "key_instances", "in", "key_instances_true", ".", "items", "(", ")", ":", "\n", "                ", "category_index", "=", "self", ".", "distinct_categories", ".", "index", "(", "category", ")", "\n", "word_sentiments_of_this_category", "=", "word_sentiments", "[", "category_index", "]", "\n", "for", "key_instance", "in", "key_instances", ":", "\n", "                    ", "total_sentiment_num", "+=", "1", "\n", "word", ",", "index", "=", "key_instance", "[", "'word'", "]", ",", "key_instance", "[", "'index'", "]", "\n", "word_sentiment", "=", "word_sentiments_of_this_category", "[", "index", "]", "\n", "polarity_index", "=", "np", ".", "argmax", "(", "word_sentiment", ")", "\n", "word_polarity", "=", "self", ".", "distinct_polarities", "[", "polarity_index", "]", "\n", "if", "key_instance", "[", "'polarity'", "]", "==", "word_polarity", ":", "\n", "                        ", "correct_sentiment_num", "+=", "1", "\n", "\n", "", "", "", "", "self", ".", "logger", ".", "info", "(", "'tp_for_key_instance: %d fp_for_key_instance: %d fn_for_key_instance: %d'", "%", "\n", "(", "tp_for_key_instance", ",", "fp_for_key_instance", ",", "fn_for_key_instance", ")", ")", "\n", "precision", "=", "tp_for_key_instance", "/", "(", "tp_for_key_instance", "+", "fp_for_key_instance", ")", "\n", "recall", "=", "tp_for_key_instance", "/", "(", "tp_for_key_instance", "+", "fn_for_key_instance", ")", "\n", "f1", "=", "2", "*", "(", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "self", ".", "logger", ".", "info", "(", "'precision: %.5f recall: %.5f f1: %.5f'", "%", "(", "precision", ",", "recall", ",", "f1", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "'correct_sentiment_num: %d total_sentiment_num: %d sentiment_acc: %.5f'", "%", "\n", "(", "correct_sentiment_num", ",", "total_sentiment_num", ",", "correct_sentiment_num", "/", "total_sentiment_num", ")", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.predict": [[528, 547], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictor", "acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.data_reader.read", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictor.predict"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.predict"], ["", "def", "predict", "(", "self", ",", "texts", ":", "List", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        :return:\n        \"\"\"", "\n", "USE_GPU", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "if", "USE_GPU", ":", "\n", "            ", "gpu_id", "=", "self", ".", "configuration", "[", "'gpu_id'", "]", "\n", "", "else", ":", "\n", "            ", "gpu_id", "=", "-", "1", "\n", "", "predictor", "=", "pytorch_models", ".", "TextInAllAspectSentimentOutPredictor", "(", "self", ".", "model", ",", "self", ".", "val_iterator", ",", "\n", "self", ".", "distinct_categories", ",", "\n", "self", ".", "distinct_polarities", ",", "\n", "configuration", "=", "self", ".", "configuration", ",", "\n", "cuda_device", "=", "gpu_id", ")", "\n", "\n", "data", "=", "self", ".", "data_reader", ".", "read", "(", "texts", ")", "\n", "result", "=", "predictor", ".", "predict", "(", "data", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.error_analysis": [[548, 582], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictor", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutPredictor.predict", "range", "os.path.join", "nlp_tasks.utils.file_utils.write_lines", "len", "result_final.append"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.predict", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.write_lines"], ["", "def", "error_analysis", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n\n        :return:\n        \"\"\"", "\n", "USE_GPU", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "if", "USE_GPU", ":", "\n", "            ", "gpu_id", "=", "self", ".", "configuration", "[", "'gpu_id'", "]", "\n", "", "else", ":", "\n", "            ", "gpu_id", "=", "-", "1", "\n", "", "predictor", "=", "pytorch_models", ".", "TextInAllAspectSentimentOutPredictor", "(", "self", ".", "model", ",", "self", ".", "val_iterator", ",", "\n", "self", ".", "distinct_categories", ",", "\n", "self", ".", "distinct_polarities", ",", "\n", "configuration", "=", "self", ".", "configuration", ",", "\n", "cuda_device", "=", "gpu_id", ")", "\n", "\n", "data", "=", "self", ".", "test_data", "\n", "result", "=", "predictor", ".", "predict", "(", "data", ")", "\n", "result_final", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "            ", "instance", ":", "Instance", "=", "data", "[", "i", "]", "\n", "metadata", "=", "instance", ".", "fields", "[", "'sample'", "]", ".", "metadata", "\n", "sentence", "=", "metadata", "[", "0", "]", "\n", "labels_true", "=", "{", "self", ".", "distinct_categories", "[", "e", "[", "0", "]", "]", ":", "self", ".", "distinct_polarities", "[", "e", "[", "1", "]", "]", "for", "e", "in", "metadata", "[", "1", "]", "}", "\n", "labels_pred", "=", "result", "[", "i", "]", "\n", "for", "label_pred", "in", "labels_pred", ":", "\n", "                ", "label_true", "=", "labels_true", "[", "label_pred", "[", "0", "]", "]", "\n", "if", "label_true", "==", "label_pred", "[", "1", "]", ":", "\n", "                    ", "continue", "\n", "", "result_final", ".", "append", "(", "(", "sentence", ",", "label_pred", "[", "0", "]", ",", "label_pred", "[", "1", "]", ",", "label_true", ")", ")", "\n", "", "", "result_str", "=", "[", "'\\t'", ".", "join", "(", "e", ")", "for", "e", "in", "result_final", "]", "\n", "output_filepath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_dir", ",", "'error_analysis.csv'", ")", "\n", "file_utils", ".", "write_lines", "(", "result_str", ",", "output_filepath", ")", "\n", "return", "result_final", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMil.__init__": [[589, 591], ["acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "configuration", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "configuration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMil._get_optimizer": [[592, 598], ["filter", "torch.Adam", "torch.Adam", "model.parameters"], "methods", ["None"], ["", "def", "_get_optimizer", "(", "self", ",", "model", ")", ":", "\n", "# _params = filter(lambda p: p.requires_grad, model.parameters())", "\n", "# return optim.Adam(_params, lr=0.001)", "\n", "\n", "        ", "_params", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", "\n", "return", "optim", ".", "Adam", "(", "_params", ",", "lr", "=", "0.001", ",", "weight_decay", "=", "0.00001", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMil._get_position_embeddings_dim": [[599, 601], ["None"], "methods", ["None"], ["", "def", "_get_position_embeddings_dim", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "configuration", "[", "'position_embeddings_dim'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMil._find_model_function_pure": [[602, 604], ["None"], "methods", ["None"], ["", "def", "_find_model_function_pure", "(", "self", ")", ":", "\n", "        ", "return", "pytorch_models", ".", "AsMilSimultaneouslyV5", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBert.__init__": [[611, 616], ["acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "configuration", ")", ":", "\n", "        ", "self", ".", "bert_file_path", "=", "configuration", "[", "'bert_file_path'", "]", "\n", "self", ".", "bert_vocab_file_path", "=", "configuration", "[", "'bert_vocab_file_path'", "]", "\n", "self", ".", "max_len", "=", "configuration", "[", "'max_len'", "]", "\n", "super", "(", ")", ".", "__init__", "(", "configuration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBert._get_bert_word_segmenter": [[617, 625], ["nlp_tasks.utils.file_utils.read_all_lines", "nlp_tasks.bert_keras.tokenizer.EnglishTokenizer", "line.strip", "len"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.read_all_lines"], ["", "def", "_get_bert_word_segmenter", "(", "self", ")", ":", "\n", "        ", "token_dict", "=", "{", "}", "\n", "for", "line", "in", "file_utils", ".", "read_all_lines", "(", "self", ".", "bert_vocab_file_path", ")", ":", "\n", "            ", "token", "=", "line", ".", "strip", "(", ")", "\n", "token_dict", "[", "token", "]", "=", "len", "(", "token_dict", ")", "\n", "\n", "", "result", "=", "bert_tokenizer", ".", "EnglishTokenizer", "(", "token_dict", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBert._get_data_reader": [[626, 652], ["allennlp.data.token_indexers.SingleIdTokenIndexer", "pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained", "allennlp.data.token_indexers.WordpieceIndexer", "allennlp.data.token_indexers.SingleIdTokenIndexer", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBert", "acd_and_sc_train_templates_pytorch.AsMilBert._get_word_segmenter"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._get_word_segmenter"], ["", "def", "_get_data_reader", "(", "self", ")", ":", "\n", "        ", "token_indexer", "=", "SingleIdTokenIndexer", "(", "namespace", "=", "\"tokens\"", ")", "\n", "bert_tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "self", ".", "bert_vocab_file_path", ",", "do_lower_case", "=", "True", ")", "\n", "bert_token_indexer", "=", "WordpieceIndexer", "(", "vocab", "=", "bert_tokenizer", ".", "vocab", ",", "\n", "wordpiece_tokenizer", "=", "bert_tokenizer", ".", "wordpiece_tokenizer", ".", "tokenize", ",", "\n", "namespace", "=", "\"bert\"", ",", "\n", "use_starting_offsets", "=", "False", ",", "\n", "max_pieces", "=", "self", ".", "max_len", ",", "\n", "do_lowercase", "=", "True", ",", "\n", "never_lowercase", "=", "None", ",", "\n", "start_tokens", "=", "None", ",", "\n", "end_tokens", "=", "None", ",", "\n", "separator_token", "=", "\"[SEP]\"", ",", "\n", "truncate_long_sequences", "=", "True", ")", "\n", "position_indexer", "=", "SingleIdTokenIndexer", "(", "namespace", "=", "'position'", ")", "\n", "reader", "=", "acd_and_sc_data_reader", ".", "AcdAndScDatasetReaderMilSimultaneouslyBert", "(", "\n", "self", ".", "distinct_categories", ",", "self", ".", "distinct_polarities", ",", "\n", "tokenizer", "=", "self", ".", "_get_word_segmenter", "(", ")", ",", "\n", "token_indexers", "=", "{", "\"tokens\"", ":", "token_indexer", "}", ",", "\n", "position_indexers", "=", "{", "'position'", ":", "position_indexer", "}", ",", "\n", "configuration", "=", "self", ".", "configuration", ",", "\n", "# bert_tokenizer=self._get_bert_word_segmenter(),", "\n", "bert_tokenizer", "=", "bert_tokenizer", ",", "\n", "bert_token_indexers", "=", "{", "\"bert\"", ":", "bert_token_indexer", "}", "\n", ")", "\n", "return", "reader", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBert._load_data": [[653, 739], ["os.path.exists", "super()._load_object", "acd_and_sc_train_templates_pytorch.AsMilBert._get_data_reader", "acd_and_sc_train_templates_pytorch.AsMilBert.dataset.generate_acd_and_sc_data", "acd_and_sc_train_templates_pytorch.AsMilBert._get_data_reader", "train_dev_test_data.items", "acd_and_sc_train_templates_pytorch.AsMilBert.read", "acd_and_sc_train_templates_pytorch.AsMilBert.read", "acd_and_sc_train_templates_pytorch.AsMilBert.read", "super()._save_object", "acd_and_sc_train_templates_pytorch.AsMilBert.read", "set", "distinct_polarities_new.append", "len", "train_dev_test_data[].append", "distinct_categories.index", "labels_new.append", "len", "sample_new.append", "data_new.append", "distinct_polarities_new.index"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_object", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBert._get_data_reader", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Semeval2014Task4RestDevSplits.generate_acd_and_sc_data", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBert._get_data_reader", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._save_object"], ["", "def", "_load_data", "(", "self", ")", ":", "\n", "        ", "data_filepath", "=", "self", ".", "base_data_dir", "+", "'data'", "\n", "if", "os", ".", "path", ".", "exists", "(", "data_filepath", ")", ":", "\n", "            ", "self", ".", "train_data", ",", "self", ".", "dev_data", ",", "self", ".", "test_data", ",", "self", ".", "distinct_categories", ",", "self", ".", "distinct_polarities", ",", "self", ".", "hard_test_data", "=", "super", "(", ")", ".", "_load_object", "(", "data_filepath", ")", "\n", "reader", "=", "self", ".", "_get_data_reader", "(", ")", "\n", "self", ".", "data_reader", "=", "reader", "\n", "", "else", ":", "\n", "            ", "train_dev_test_data", ",", "distinct_categories", ",", "distinct_polarities", "=", "self", ".", "dataset", ".", "generate_acd_and_sc_data", "(", ")", "\n", "\n", "# train_dev_test_data['hard_test'] = None", "\n", "# if self.hard_dataset:", "\n", "#     train_dev_test_data_hard, _, _ = self.hard_dataset.generate_acd_and_sc_data()", "\n", "#     train_dev_test_data['hard_test'] = train_dev_test_data_hard['test']", "\n", "\n", "if", "self", ".", "configuration", "[", "'hard_test'", "]", ":", "\n", "                ", "train_dev_test_data", "[", "'hard_test'", "]", "=", "[", "]", "\n", "for", "sample", "in", "train_dev_test_data", "[", "'test'", "]", ":", "\n", "                    ", "polarities", "=", "set", "(", "[", "e", "[", "1", "]", "for", "e", "in", "sample", "[", "1", "]", "]", ")", "\n", "if", "len", "(", "polarities", ")", ">=", "2", ":", "\n", "                        ", "train_dev_test_data", "[", "'hard_test'", "]", ".", "append", "(", "sample", ")", "\n", "\n", "", "", "", "distinct_polarities_new", "=", "[", "]", "\n", "for", "polarity", "in", "distinct_polarities", ":", "\n", "                ", "if", "polarity", "!=", "'conflict'", ":", "\n", "                    ", "distinct_polarities_new", ".", "append", "(", "polarity", ")", "\n", "", "", "self", ".", "distinct_categories", "=", "distinct_categories", "\n", "self", ".", "distinct_polarities", "=", "distinct_polarities_new", "\n", "\n", "# token_indexer = SingleIdTokenIndexer(namespace=\"tokens\")", "\n", "# bert_tokenizer = BertTokenizer.from_pretrained(self.bert_vocab_file_path, do_lower_case=True)", "\n", "# bert_token_indexer = WordpieceIndexer(vocab=bert_tokenizer.vocab,", "\n", "#                                         wordpiece_tokenizer=bert_tokenizer.wordpiece_tokenizer.tokenize,", "\n", "#                                          namespace=\"bert\",", "\n", "#                                          use_starting_offsets=False,", "\n", "#                                          max_pieces=self.max_len,", "\n", "#                                          do_lowercase=True,", "\n", "#                                          never_lowercase=None,", "\n", "#                                          start_tokens=None,", "\n", "#                                          end_tokens=None,", "\n", "#                                          separator_token=\"[SEP]\",", "\n", "#                                          truncate_long_sequences=True)", "\n", "# position_indexer = SingleIdTokenIndexer(namespace='position')", "\n", "# reader = acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBert(", "\n", "#     self.distinct_categories, self.distinct_polarities,", "\n", "#     tokenizer=self._get_word_segmenter(),", "\n", "#     token_indexers={\"tokens\": token_indexer},", "\n", "#     position_indexers={'position': position_indexer},", "\n", "#     configuration=self.configuration,", "\n", "#     # bert_tokenizer=self._get_bert_word_segmenter(),", "\n", "#     bert_tokenizer=bert_tokenizer,", "\n", "#     bert_token_indexers={\"bert\": bert_token_indexer}", "\n", "# )", "\n", "reader", "=", "self", ".", "_get_data_reader", "(", ")", "\n", "self", ".", "data_reader", "=", "reader", "\n", "\n", "train_dev_test_data_label_indexed", "=", "{", "}", "\n", "for", "data_type", ",", "data", "in", "train_dev_test_data", ".", "items", "(", ")", ":", "\n", "                ", "if", "data", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "data_new", "=", "[", "]", "\n", "for", "sample", "in", "data", ":", "\n", "                    ", "sample_new", "=", "[", "sample", "[", "0", "]", "]", "\n", "labels_new", "=", "[", "]", "\n", "for", "label", "in", "sample", "[", "1", "]", ":", "\n", "                        ", "aspect", "=", "label", "[", "0", "]", "\n", "polarity", "=", "label", "[", "1", "]", "\n", "aspect_index", "=", "distinct_categories", ".", "index", "(", "aspect", ")", "\n", "if", "polarity", "==", "'conflict'", ":", "\n", "                            ", "polarity_index", "=", "-", "100", "\n", "", "else", ":", "\n", "                            ", "polarity_index", "=", "distinct_polarities_new", ".", "index", "(", "polarity", ")", "\n", "", "labels_new", ".", "append", "(", "(", "aspect_index", ",", "polarity_index", ")", ")", "\n", "", "if", "len", "(", "labels_new", ")", "!=", "0", ":", "\n", "                        ", "sample_new", ".", "append", "(", "labels_new", ")", "\n", "data_new", ".", "append", "(", "sample_new", ")", "\n", "", "", "train_dev_test_data_label_indexed", "[", "data_type", "]", "=", "data_new", "\n", "", "self", ".", "train_data", "=", "reader", ".", "read", "(", "train_dev_test_data_label_indexed", "[", "'train'", "]", ")", "\n", "self", ".", "dev_data", "=", "reader", ".", "read", "(", "train_dev_test_data_label_indexed", "[", "'dev'", "]", ")", "\n", "self", ".", "test_data", "=", "reader", ".", "read", "(", "train_dev_test_data_label_indexed", "[", "'test'", "]", ")", "\n", "if", "self", ".", "configuration", "[", "'hard_test'", "]", ":", "\n", "                ", "self", ".", "hard_test_data", "=", "reader", ".", "read", "(", "train_dev_test_data_label_indexed", "[", "'hard_test'", "]", ")", "\n", "", "data", "=", "[", "self", ".", "train_data", ",", "self", ".", "dev_data", ",", "self", ".", "test_data", ",", "self", ".", "distinct_categories", ",", "\n", "self", ".", "distinct_polarities", ",", "self", ".", "hard_test_data", "]", "\n", "super", "(", ")", ".", "_save_object", "(", "data_filepath", ",", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBert._get_bert_word_embedder": [[740, 758], ["allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertModel.load", "allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertModel.load.parameters", "allennlp.modules.token_embedders.bert_token_embedder.BertEmbedder", "allennlp.modules.text_field_embedders.BasicTextFieldEmbedder", "bert_word_embedder.to"], "methods", ["None"], ["", "", "def", "_get_bert_word_embedder", "(", "self", ")", ":", "\n", "# bert_embedder = PretrainedBertEmbedder(", "\n", "#     pretrained_model=self.bert_file_path,", "\n", "#     top_layer_only=True,  # conserve memory", "\n", "#     requires_grad=(not self.configuration['fixed'])", "\n", "# )", "\n", "\n", "        ", "pretrained_model", "=", "self", ".", "bert_file_path", "\n", "bert_model", "=", "PretrainedBertModel", ".", "load", "(", "pretrained_model", ",", "cache_model", "=", "False", ")", "\n", "for", "param", "in", "bert_model", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "(", "not", "self", ".", "configuration", "[", "'fixed'", "]", ")", "\n", "", "bert_embedder", "=", "BertEmbedder", "(", "bert_model", "=", "bert_model", ",", "top_layer_only", "=", "True", ")", "\n", "\n", "bert_word_embedder", ":", "TextFieldEmbedder", "=", "BasicTextFieldEmbedder", "(", "{", "\"bert\"", ":", "bert_embedder", "}", ",", "\n", "# we'll be ignoring masks so we'll need to set this to True", "\n", "allow_unmatched_keys", "=", "True", ")", "\n", "bert_word_embedder", ".", "to", "(", "self", ".", "configuration", "[", "'device'", "]", ")", "\n", "return", "bert_word_embedder", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBert._find_model_function": [[759, 803], ["os.path.exists", "allennlp.modules.token_embedders.Embedding", "allennlp.modules.text_field_embedders.BasicTextFieldEmbedder", "allennlp.modules.token_embedders.Embedding", "allennlp.modules.text_field_embedders.BasicTextFieldEmbedder", "acd_and_sc_train_templates_pytorch.AsMilBert._get_bert_word_embedder", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBert", "acd_and_sc_train_templates_pytorch.AsMilBert._print_args", "model.to.to.to", "super()._load_object", "allennlp.modules.token_embedders.embedding._read_embeddings_from_text_file", "super()._save_object", "acd_and_sc_train_templates_pytorch.AsMilBert.vocab.get_vocab_size", "acd_and_sc_train_templates_pytorch.AsMilBert.vocab.get_vocab_size"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBertSingle._get_bert_word_embedder", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._print_args", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_object", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._save_object"], ["", "def", "_find_model_function", "(", "self", ")", ":", "\n", "        ", "embedding_dim", "=", "self", ".", "configuration", "[", "'embed_size'", "]", "\n", "embedding_matrix_filepath", "=", "self", ".", "base_data_dir", "+", "'embedding_matrix'", "\n", "if", "os", ".", "path", ".", "exists", "(", "embedding_matrix_filepath", ")", ":", "\n", "            ", "embedding_matrix", "=", "super", "(", ")", ".", "_load_object", "(", "embedding_matrix_filepath", ")", "\n", "", "else", ":", "\n", "            ", "embedding_filepath", "=", "self", ".", "configuration", "[", "'embedding_filepath'", "]", "\n", "embedding_matrix", "=", "embedding", ".", "_read_embeddings_from_text_file", "(", "embedding_filepath", ",", "embedding_dim", ",", "\n", "self", ".", "vocab", ",", "namespace", "=", "'tokens'", ")", "\n", "super", "(", ")", ".", "_save_object", "(", "embedding_matrix_filepath", ",", "embedding_matrix", ")", "\n", "", "token_embedding", "=", "Embedding", "(", "num_embeddings", "=", "self", ".", "vocab", ".", "get_vocab_size", "(", "namespace", "=", "'tokens'", ")", ",", "\n", "embedding_dim", "=", "embedding_dim", ",", "padding_index", "=", "0", ",", "vocab_namespace", "=", "'tokens'", ",", "\n", "trainable", "=", "False", ",", "weight", "=", "embedding_matrix", ")", "\n", "# the embedder maps the input tokens to the appropriate embedding matrix", "\n", "word_embedder", ":", "TextFieldEmbedder", "=", "BasicTextFieldEmbedder", "(", "{", "\"tokens\"", ":", "token_embedding", "}", ")", "\n", "\n", "position_embedding", "=", "Embedding", "(", "num_embeddings", "=", "self", ".", "vocab", ".", "get_vocab_size", "(", "namespace", "=", "'position'", ")", ",", "\n", "embedding_dim", "=", "25", ",", "padding_index", "=", "0", ")", "\n", "position_embedder", ":", "TextFieldEmbedder", "=", "BasicTextFieldEmbedder", "(", "{", "\"position\"", ":", "position_embedding", "}", ",", "\n", "# we'll be ignoring masks so we'll need to set this to True", "\n", "allow_unmatched_keys", "=", "True", ")", "\n", "\n", "# bert_embedder = PretrainedBertEmbedder(", "\n", "#     pretrained_model=self.bert_file_path,", "\n", "#     top_layer_only=True,  # conserve memory", "\n", "#     requires_grad=True", "\n", "# )", "\n", "# bert_word_embedder: TextFieldEmbedder = BasicTextFieldEmbedder({\"bert\": bert_embedder},", "\n", "#                                                                  # we'll be ignoring masks so we'll need to set this to True", "\n", "#                                                                  allow_unmatched_keys=True)", "\n", "bert_word_embedder", "=", "self", ".", "_get_bert_word_embedder", "(", ")", "\n", "\n", "model", "=", "pytorch_models", ".", "AsMilSimultaneouslyBert", "(", "\n", "word_embedder", ",", "\n", "position_embedder", ",", "\n", "self", ".", "distinct_categories", ",", "\n", "self", ".", "distinct_polarities", ",", "\n", "self", ".", "vocab", ",", "\n", "self", ".", "configuration", ",", "\n", "bert_word_embedder", "=", "bert_word_embedder", "\n", ")", "\n", "self", ".", "_print_args", "(", "model", ")", "\n", "model", "=", "model", ".", "to", "(", "self", ".", "configuration", "[", "'device'", "]", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBert._get_optimizer": [[804, 811], ["filter", "model.parameters", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam"], "methods", ["None"], ["", "def", "_get_optimizer", "(", "self", ",", "model", ")", ":", "\n", "        ", "_params", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", "\n", "if", "self", ".", "configuration", "[", "'fixed'", "]", ":", "\n", "            ", "return", "optim", ".", "Adam", "(", "_params", ",", "lr", "=", "0.001", ",", "weight_decay", "=", "0.00001", ")", "\n", "", "else", ":", "\n", "            ", "return", "optim", ".", "Adam", "(", "_params", ",", "lr", "=", "self", ".", "configuration", "[", "'learning_rate_in_bert'", "]", ",", "\n", "weight_decay", "=", "self", ".", "configuration", "[", "'l2_in_bert'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBertSingle.__init__": [[818, 823], ["acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "configuration", ")", ":", "\n", "        ", "self", ".", "bert_file_path", "=", "configuration", "[", "'bert_file_path'", "]", "\n", "self", ".", "bert_vocab_file_path", "=", "configuration", "[", "'bert_vocab_file_path'", "]", "\n", "self", ".", "max_len", "=", "configuration", "[", "'max_len'", "]", "\n", "super", "(", ")", ".", "__init__", "(", "configuration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBertSingle._get_bert_word_segmenter": [[824, 832], ["nlp_tasks.utils.file_utils.read_all_lines", "nlp_tasks.bert_keras.tokenizer.EnglishTokenizer", "line.strip", "len"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.read_all_lines"], ["", "def", "_get_bert_word_segmenter", "(", "self", ")", ":", "\n", "        ", "token_dict", "=", "{", "}", "\n", "for", "line", "in", "file_utils", ".", "read_all_lines", "(", "self", ".", "bert_vocab_file_path", ")", ":", "\n", "            ", "token", "=", "line", ".", "strip", "(", ")", "\n", "token_dict", "[", "token", "]", "=", "len", "(", "token_dict", ")", "\n", "\n", "", "result", "=", "bert_tokenizer", ".", "EnglishTokenizer", "(", "token_dict", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBertSingle._load_data": [[833, 909], ["os.path.exists", "super()._load_object", "acd_and_sc_train_templates_pytorch.AsMilBertSingle.dataset.generate_acd_and_sc_data", "allennlp.data.token_indexers.SingleIdTokenIndexer", "pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained", "allennlp.data.token_indexers.WordpieceIndexer", "allennlp.data.token_indexers.SingleIdTokenIndexer", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle", "train_dev_test_data.items", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.read", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.read", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.read", "super()._save_object", "acd_and_sc_train_templates_pytorch.AsMilBertSingle.hard_dataset.generate_acd_and_sc_data", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.read", "distinct_polarities_new.append", "acd_and_sc_train_templates_pytorch.AsMilBertSingle._get_word_segmenter", "distinct_categories.index", "labels_new.append", "len", "sample_new.append", "data_new.append", "distinct_polarities_new.index"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_object", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Semeval2014Task4RestDevSplits.generate_acd_and_sc_data", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._save_object", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Semeval2014Task4RestDevSplits.generate_acd_and_sc_data", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._get_word_segmenter"], ["", "def", "_load_data", "(", "self", ")", ":", "\n", "        ", "data_filepath", "=", "self", ".", "base_data_dir", "+", "'data'", "\n", "if", "os", ".", "path", ".", "exists", "(", "data_filepath", ")", ":", "\n", "            ", "self", ".", "train_data", ",", "self", ".", "dev_data", ",", "self", ".", "test_data", ",", "self", ".", "distinct_categories", ",", "self", ".", "distinct_polarities", ",", "self", ".", "hard_test_data", "=", "super", "(", ")", ".", "_load_object", "(", "data_filepath", ")", "\n", "", "else", ":", "\n", "            ", "train_dev_test_data", ",", "distinct_categories", ",", "distinct_polarities", "=", "self", ".", "dataset", ".", "generate_acd_and_sc_data", "(", ")", "\n", "\n", "train_dev_test_data", "[", "'hard_test'", "]", "=", "None", "\n", "if", "self", ".", "hard_dataset", ":", "\n", "                ", "train_dev_test_data_hard", ",", "_", ",", "_", "=", "self", ".", "hard_dataset", ".", "generate_acd_and_sc_data", "(", ")", "\n", "train_dev_test_data", "[", "'hard_test'", "]", "=", "train_dev_test_data_hard", "[", "'test'", "]", "\n", "\n", "", "distinct_polarities_new", "=", "[", "]", "\n", "for", "polarity", "in", "distinct_polarities", ":", "\n", "                ", "if", "polarity", "!=", "'conflict'", ":", "\n", "                    ", "distinct_polarities_new", ".", "append", "(", "polarity", ")", "\n", "", "", "self", ".", "distinct_categories", "=", "distinct_categories", "\n", "self", ".", "distinct_polarities", "=", "distinct_polarities_new", "\n", "\n", "token_indexer", "=", "SingleIdTokenIndexer", "(", "namespace", "=", "\"tokens\"", ")", "\n", "bert_tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "self", ".", "bert_vocab_file_path", ",", "do_lower_case", "=", "True", ")", "\n", "bert_token_indexer", "=", "WordpieceIndexer", "(", "vocab", "=", "bert_tokenizer", ".", "vocab", ",", "\n", "wordpiece_tokenizer", "=", "bert_tokenizer", ".", "wordpiece_tokenizer", ".", "tokenize", ",", "\n", "namespace", "=", "\"bert\"", ",", "\n", "use_starting_offsets", "=", "False", ",", "\n", "max_pieces", "=", "self", ".", "max_len", ",", "\n", "do_lowercase", "=", "True", ",", "\n", "never_lowercase", "=", "None", ",", "\n", "start_tokens", "=", "None", ",", "\n", "end_tokens", "=", "None", ",", "\n", "separator_token", "=", "\"[SEP]\"", ",", "\n", "truncate_long_sequences", "=", "True", ")", "\n", "position_indexer", "=", "SingleIdTokenIndexer", "(", "namespace", "=", "'position'", ")", "\n", "reader", "=", "acd_and_sc_data_reader", ".", "AcdAndScDatasetReaderMilSimultaneouslyBertSingle", "(", "\n", "self", ".", "distinct_categories", ",", "self", ".", "distinct_polarities", ",", "\n", "tokenizer", "=", "self", ".", "_get_word_segmenter", "(", ")", ",", "\n", "token_indexers", "=", "{", "\"tokens\"", ":", "token_indexer", "}", ",", "\n", "position_indexers", "=", "{", "'position'", ":", "position_indexer", "}", ",", "\n", "configuration", "=", "self", ".", "configuration", ",", "\n", "# bert_tokenizer=self._get_bert_word_segmenter(),", "\n", "bert_tokenizer", "=", "bert_tokenizer", ",", "\n", "bert_token_indexers", "=", "{", "\"bert\"", ":", "bert_token_indexer", "}", "\n", ")", "\n", "self", ".", "data_reader", "=", "reader", "\n", "\n", "train_dev_test_data_label_indexed", "=", "{", "}", "\n", "for", "data_type", ",", "data", "in", "train_dev_test_data", ".", "items", "(", ")", ":", "\n", "                ", "if", "data", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "data_new", "=", "[", "]", "\n", "for", "sample", "in", "data", ":", "\n", "                    ", "sample_new", "=", "[", "sample", "[", "0", "]", "]", "\n", "labels_new", "=", "[", "]", "\n", "for", "label", "in", "sample", "[", "1", "]", ":", "\n", "                        ", "aspect", "=", "label", "[", "0", "]", "\n", "polarity", "=", "label", "[", "1", "]", "\n", "aspect_index", "=", "distinct_categories", ".", "index", "(", "aspect", ")", "\n", "if", "polarity", "==", "'conflict'", ":", "\n", "                            ", "polarity_index", "=", "-", "100", "\n", "", "else", ":", "\n", "                            ", "polarity_index", "=", "distinct_polarities_new", ".", "index", "(", "polarity", ")", "\n", "", "labels_new", ".", "append", "(", "(", "aspect_index", ",", "polarity_index", ")", ")", "\n", "", "if", "len", "(", "labels_new", ")", "!=", "0", ":", "\n", "                        ", "sample_new", ".", "append", "(", "labels_new", ")", "\n", "data_new", ".", "append", "(", "sample_new", ")", "\n", "", "", "train_dev_test_data_label_indexed", "[", "data_type", "]", "=", "data_new", "\n", "", "self", ".", "train_data", "=", "reader", ".", "read", "(", "train_dev_test_data_label_indexed", "[", "'train'", "]", ")", "\n", "self", ".", "dev_data", "=", "reader", ".", "read", "(", "train_dev_test_data_label_indexed", "[", "'dev'", "]", ")", "\n", "self", ".", "test_data", "=", "reader", ".", "read", "(", "train_dev_test_data_label_indexed", "[", "'test'", "]", ")", "\n", "if", "self", ".", "hard_dataset", ":", "\n", "                ", "self", ".", "hard_test_data", "=", "reader", ".", "read", "(", "train_dev_test_data_label_indexed", "[", "'hard_test'", "]", ")", "\n", "", "data", "=", "[", "self", ".", "train_data", ",", "self", ".", "dev_data", ",", "self", ".", "test_data", ",", "self", ".", "distinct_categories", ",", "\n", "self", ".", "distinct_polarities", ",", "self", ".", "hard_test_data", "]", "\n", "super", "(", ")", ".", "_save_object", "(", "data_filepath", ",", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBertSingle._get_bert_word_embedder": [[910, 928], ["allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertModel.load", "allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertModel.load.parameters", "allennlp.modules.token_embedders.bert_token_embedder.BertEmbedder", "allennlp.modules.text_field_embedders.BasicTextFieldEmbedder", "bert_word_embedder.to"], "methods", ["None"], ["", "", "def", "_get_bert_word_embedder", "(", "self", ")", ":", "\n", "# bert_embedder = PretrainedBertEmbedder(", "\n", "#     pretrained_model=self.bert_file_path,", "\n", "#     top_layer_only=True,  # conserve memory", "\n", "#     requires_grad=(not self.configuration['fixed'])", "\n", "# )", "\n", "\n", "        ", "pretrained_model", "=", "self", ".", "bert_file_path", "\n", "bert_model", "=", "PretrainedBertModel", ".", "load", "(", "pretrained_model", ",", "cache_model", "=", "False", ")", "\n", "for", "param", "in", "bert_model", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "(", "not", "self", ".", "configuration", "[", "'fixed'", "]", ")", "\n", "", "bert_embedder", "=", "BertEmbedder", "(", "bert_model", "=", "bert_model", ",", "top_layer_only", "=", "True", ")", "\n", "\n", "bert_word_embedder", ":", "TextFieldEmbedder", "=", "BasicTextFieldEmbedder", "(", "{", "\"bert\"", ":", "bert_embedder", "}", ",", "\n", "# we'll be ignoring masks so we'll need to set this to True", "\n", "allow_unmatched_keys", "=", "True", ")", "\n", "bert_word_embedder", ".", "to", "(", "self", ".", "configuration", "[", "'device'", "]", ")", "\n", "return", "bert_word_embedder", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBertSingle._find_model_function": [[929, 964], ["os.path.exists", "allennlp.modules.token_embedders.Embedding", "allennlp.modules.text_field_embedders.BasicTextFieldEmbedder", "allennlp.modules.token_embedders.Embedding", "allennlp.modules.text_field_embedders.BasicTextFieldEmbedder", "acd_and_sc_train_templates_pytorch.AsMilBertSingle._get_bert_word_embedder", "nlp_tasks.absa.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle", "acd_and_sc_train_templates_pytorch.AsMilBertSingle._print_args", "model.to.to.to", "super()._load_object", "allennlp.modules.token_embedders.embedding._read_embeddings_from_text_file", "super()._save_object", "acd_and_sc_train_templates_pytorch.AsMilBertSingle.vocab.get_vocab_size", "acd_and_sc_train_templates_pytorch.AsMilBertSingle.vocab.get_vocab_size"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBertSingle._get_bert_word_embedder", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.TextInAllAspectSentimentOutTrainTemplate._print_args", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_object", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._save_object"], ["", "def", "_find_model_function", "(", "self", ")", ":", "\n", "        ", "embedding_dim", "=", "self", ".", "configuration", "[", "'embed_size'", "]", "\n", "embedding_matrix_filepath", "=", "self", ".", "base_data_dir", "+", "'embedding_matrix'", "\n", "if", "os", ".", "path", ".", "exists", "(", "embedding_matrix_filepath", ")", ":", "\n", "            ", "embedding_matrix", "=", "super", "(", ")", ".", "_load_object", "(", "embedding_matrix_filepath", ")", "\n", "", "else", ":", "\n", "            ", "embedding_filepath", "=", "self", ".", "configuration", "[", "'embedding_filepath'", "]", "\n", "embedding_matrix", "=", "embedding", ".", "_read_embeddings_from_text_file", "(", "embedding_filepath", ",", "embedding_dim", ",", "\n", "self", ".", "vocab", ",", "namespace", "=", "'tokens'", ")", "\n", "super", "(", ")", ".", "_save_object", "(", "embedding_matrix_filepath", ",", "embedding_matrix", ")", "\n", "", "token_embedding", "=", "Embedding", "(", "num_embeddings", "=", "self", ".", "vocab", ".", "get_vocab_size", "(", "namespace", "=", "'tokens'", ")", ",", "\n", "embedding_dim", "=", "embedding_dim", ",", "padding_index", "=", "0", ",", "vocab_namespace", "=", "'tokens'", ",", "\n", "trainable", "=", "False", ",", "weight", "=", "embedding_matrix", ")", "\n", "# the embedder maps the input tokens to the appropriate embedding matrix", "\n", "word_embedder", ":", "TextFieldEmbedder", "=", "BasicTextFieldEmbedder", "(", "{", "\"tokens\"", ":", "token_embedding", "}", ")", "\n", "\n", "position_embedding", "=", "Embedding", "(", "num_embeddings", "=", "self", ".", "vocab", ".", "get_vocab_size", "(", "namespace", "=", "'position'", ")", ",", "\n", "embedding_dim", "=", "25", ",", "padding_index", "=", "0", ")", "\n", "position_embedder", ":", "TextFieldEmbedder", "=", "BasicTextFieldEmbedder", "(", "{", "\"position\"", ":", "position_embedding", "}", ",", "\n", "# we'll be ignoring masks so we'll need to set this to True", "\n", "allow_unmatched_keys", "=", "True", ")", "\n", "\n", "bert_word_embedder", ":", "TextFieldEmbedder", "=", "self", ".", "_get_bert_word_embedder", "(", ")", "\n", "model", "=", "pytorch_models", ".", "AsMilSimultaneouslyBertSingle", "(", "\n", "word_embedder", ",", "\n", "position_embedder", ",", "\n", "self", ".", "distinct_categories", ",", "\n", "self", ".", "distinct_polarities", ",", "\n", "self", ".", "vocab", ",", "\n", "self", ".", "configuration", ",", "\n", "bert_word_embedder", "=", "bert_word_embedder", "\n", ")", "\n", "self", ".", "_print_args", "(", "model", ")", "\n", "model", "=", "model", ".", "to", "(", "self", ".", "configuration", "[", "'device'", "]", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_train_templates_pytorch.AsMilBertSingle._get_optimizer": [[965, 972], ["filter", "model.parameters", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam"], "methods", ["None"], ["", "def", "_get_optimizer", "(", "self", ",", "model", ")", ":", "\n", "        ", "_params", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", "\n", "if", "self", ".", "configuration", "[", "'fixed'", "]", ":", "\n", "            ", "return", "optim", ".", "Adam", "(", "_params", ",", "lr", "=", "0.001", ",", "weight_decay", "=", "0.00001", ")", "\n", "", "else", ":", "\n", "            ", "return", "optim", ".", "Adam", "(", "_params", ",", "lr", "=", "self", ".", "configuration", "[", "'learning_rate_in_bert'", "]", ",", "\n", "weight_decay", "=", "self", ".", "configuration", "[", "'l2_in_bert'", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderCae.__init__": [[45, 60], ["allennlp.data.dataset_readers.DatasetReader.__init__", "spacy.load", "x.split", "allennlp.data.token_indexers.SingleIdTokenIndexer", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "categories", ":", "List", "[", "str", "]", ",", "polarities", ":", "List", "[", "str", "]", ",", "\n", "tokenizer", ":", "Callable", "[", "[", "str", "]", ",", "List", "[", "str", "]", "]", "=", "lambda", "x", ":", "x", ".", "split", "(", ")", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "position_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "core_nlp", ":", "my_corenlp", ".", "StanfordCoreNLP", "=", "None", ",", "\n", "configuration", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", "=", "False", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "token_indexers", "=", "token_indexers", "or", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", "namespace", "=", "\"tokens\"", ")", "}", "\n", "self", ".", "position_indexers", "=", "position_indexers", "or", "{", "\"position\"", ":", "SingleIdTokenIndexer", "(", "namespace", "=", "'position'", ")", "}", "\n", "self", ".", "categories", "=", "categories", "\n", "self", ".", "polarities", "=", "polarities", "\n", "self", ".", "spacy_nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "self", ".", "core_nlp", "=", "core_nlp", "\n", "self", ".", "configuration", "=", "configuration", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderCae._build_graph": [[61, 64], ["nlp_tasks.utils.create_graph.create_dependency_graph_for_dgl"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.create_graph.create_dependency_graph_for_dgl"], ["", "def", "_build_graph", "(", "self", ",", "text", ")", ":", "\n", "        ", "graph", "=", "create_graph", ".", "create_dependency_graph_for_dgl", "(", "text", ",", "self", ".", "spacy_nlp", ",", "None", ")", "\n", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderCae.text_to_instance": [[65, 101], ["sample[].strip", "acd_and_sc_data_reader.AcdAndScDatasetReaderCae.tokenizer", "sample.append", "acd_and_sc_data_reader.AcdAndScDatasetReaderCae._build_graph", "sample.append", "allennlp.data.fields.TextField", "allennlp.data.fields.TextField", "allennlp.data.fields.ArrayField", "allennlp.data.fields.ArrayField", "allennlp.data.fields.MetadataField", "allennlp.data.Instance", "allennlp.data.tokenizers.Token", "allennlp.data.tokenizers.Token", "len", "len", "len", "numpy.array", "numpy.array", "str", "range", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle._build_graph"], ["", "@", "overrides", "\n", "def", "text_to_instance", "(", "self", ",", "sample", ":", "list", ")", "->", "Instance", ":", "\n", "        ", "fields", "=", "{", "}", "\n", "\n", "text", ":", "str", "=", "sample", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "words", "=", "self", ".", "tokenizer", "(", "text", ")", "\n", "sample", ".", "append", "(", "words", ")", "\n", "\n", "graph", "=", "self", ".", "_build_graph", "(", "text", ")", "\n", "sample", ".", "append", "(", "graph", ")", "\n", "\n", "tokens", "=", "[", "Token", "(", "word", ")", "for", "word", "in", "words", "]", "\n", "\n", "sentence_field", "=", "TextField", "(", "tokens", ",", "self", ".", "token_indexers", ")", "\n", "fields", "[", "'tokens'", "]", "=", "sentence_field", "\n", "\n", "position", "=", "[", "Token", "(", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "tokens", ")", ")", "]", "\n", "position_field", "=", "TextField", "(", "position", ",", "self", ".", "position_indexers", ")", "\n", "fields", "[", "'position'", "]", "=", "position_field", "\n", "\n", "category_labels", "=", "[", "0", "]", "*", "len", "(", "self", ".", "categories", ")", "\n", "polarity_labels", "=", "[", "-", "100", "]", "*", "len", "(", "self", ".", "categories", ")", "\n", "if", "len", "(", "sample", ")", ">", "1", ":", "\n", "            ", "labels", ":", "list", "=", "sample", "[", "1", "]", "\n", "for", "label", "in", "labels", ":", "\n", "                ", "category_labels", "[", "label", "[", "0", "]", "]", "=", "1", "\n", "polarity_labels", "[", "label", "[", "0", "]", "]", "=", "label", "[", "1", "]", "\n", "", "", "label_field", "=", "ArrayField", "(", "np", ".", "array", "(", "category_labels", "+", "polarity_labels", ")", ")", "\n", "fields", "[", "\"label\"", "]", "=", "label_field", "\n", "polarity_mask", "=", "[", "1", "if", "polarity_labels", "[", "i", "]", "!=", "-", "100", "else", "0", "for", "i", "in", "range", "(", "len", "(", "self", ".", "categories", ")", ")", "]", "\n", "polarity_mask_field", "=", "ArrayField", "(", "np", ".", "array", "(", "polarity_mask", ")", ")", "\n", "fields", "[", "'polarity_mask'", "]", "=", "polarity_mask_field", "\n", "sample_field", "=", "MetadataField", "(", "sample", ")", "\n", "fields", "[", "\"sample\"", "]", "=", "sample_field", "\n", "return", "Instance", "(", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderCae._read": [[102, 106], ["acd_and_sc_data_reader.AcdAndScDatasetReaderCae.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.text_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "samples", ":", "list", ")", "->", "Iterator", "[", "Instance", "]", ":", "\n", "        ", "for", "sample", "in", "samples", ":", "\n", "            ", "yield", "self", ".", "text_to_instance", "(", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.TextInAllAspectSentimentOut.__init__": [[109, 126], ["allennlp.data.dataset_readers.DatasetReader.__init__", "spacy.load", "x.split", "allennlp.data.token_indexers.SingleIdTokenIndexer", "allennlp.data.token_indexers.SingleIdTokenIndexer", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "categories", ":", "List", "[", "str", "]", ",", "polarities", ":", "List", "[", "str", "]", ",", "\n", "tokenizer", ":", "Callable", "[", "[", "str", "]", ",", "List", "[", "str", "]", "]", "=", "lambda", "x", ":", "x", ".", "split", "(", ")", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "position_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "aspect_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "core_nlp", ":", "my_corenlp", ".", "StanfordCoreNLP", "=", "None", ",", "\n", "configuration", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", "=", "False", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "token_indexers", "=", "token_indexers", "or", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", "namespace", "=", "\"tokens\"", ")", "}", "\n", "self", ".", "position_indexers", "=", "position_indexers", "or", "{", "\"position\"", ":", "SingleIdTokenIndexer", "(", "namespace", "=", "'position'", ")", "}", "\n", "self", ".", "aspect_indexers", "=", "aspect_indexers", "or", "{", "\"aspect\"", ":", "SingleIdTokenIndexer", "(", "namespace", "=", "'aspect'", ")", "}", "\n", "self", ".", "categories", "=", "categories", "\n", "self", ".", "polarities", "=", "polarities", "\n", "self", ".", "spacy_nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "self", ".", "core_nlp", "=", "core_nlp", "\n", "self", ".", "configuration", "=", "configuration", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.TextInAllAspectSentimentOut._build_graph": [[127, 130], ["nlp_tasks.utils.create_graph.create_dependency_graph_for_dgl"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.create_graph.create_dependency_graph_for_dgl"], ["", "def", "_build_graph", "(", "self", ",", "text", ")", ":", "\n", "        ", "graph", "=", "create_graph", ".", "create_dependency_graph_for_dgl", "(", "text", ",", "self", ".", "spacy_nlp", ",", "None", ")", "\n", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.TextInAllAspectSentimentOut.text_to_instance": [[131, 186], ["sample[].strip", "acd_and_sc_data_reader.TextInAllAspectSentimentOut.tokenizer", "sample.append", "acd_and_sc_data_reader.TextInAllAspectSentimentOut._build_graph", "sample.append", "allennlp.data.fields.TextField", "allennlp.data.fields.TextField", "allennlp.data.fields.TextField", "range", "allennlp.data.fields.ArrayField", "allennlp.data.fields.ArrayField", "allennlp.data.fields.MetadataField", "allennlp.data.Instance", "allennlp.data.tokenizers.Token", "allennlp.data.tokenizers.Token", "allennlp.data.tokenizers.Token", "len", "len", "len", "len", "numpy.array", "numpy.array", "str", "range", "total_labels.append", "total_labels.append", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle._build_graph"], ["", "@", "overrides", "\n", "def", "text_to_instance", "(", "self", ",", "sample", ":", "list", ")", "->", "Instance", ":", "\n", "        ", "fields", "=", "{", "}", "\n", "\n", "text", ":", "str", "=", "sample", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "words", "=", "self", ".", "tokenizer", "(", "text", ")", "\n", "if", "'max_word_len'", "in", "self", ".", "configuration", ":", "\n", "            ", "words", "=", "words", "[", ":", "self", ".", "configuration", "[", "'max_word_len'", "]", "]", "\n", "", "sample", ".", "append", "(", "words", ")", "\n", "\n", "graph", "=", "self", ".", "_build_graph", "(", "text", ")", "\n", "sample", ".", "append", "(", "graph", ")", "\n", "\n", "tokens", "=", "[", "Token", "(", "word", ")", "for", "word", "in", "words", "]", "\n", "\n", "sentence_field", "=", "TextField", "(", "tokens", ",", "self", ".", "token_indexers", ")", "\n", "fields", "[", "'tokens'", "]", "=", "sentence_field", "\n", "\n", "position", "=", "[", "Token", "(", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "tokens", ")", ")", "]", "\n", "position_field", "=", "TextField", "(", "position", ",", "self", ".", "position_indexers", ")", "\n", "fields", "[", "'position'", "]", "=", "position_field", "\n", "\n", "aspects", "=", "[", "Token", "(", "category", ")", "for", "category", "in", "self", ".", "categories", "]", "\n", "aspect_field", "=", "TextField", "(", "aspects", ",", "self", ".", "aspect_indexers", ")", "\n", "fields", "[", "'aspects'", "]", "=", "aspect_field", "\n", "\n", "category_labels", "=", "[", "0", "]", "*", "len", "(", "self", ".", "categories", ")", "\n", "polarity_labels", "=", "[", "-", "100", "]", "*", "len", "(", "self", ".", "categories", ")", "\n", "total_labels", "=", "[", "]", "\n", "if", "len", "(", "sample", ")", ">", "1", ":", "\n", "            ", "labels", ":", "list", "=", "sample", "[", "1", "]", "\n", "for", "label", "in", "labels", ":", "\n", "                ", "category_labels", "[", "label", "[", "0", "]", "]", "=", "1", "\n", "polarity_labels", "[", "label", "[", "0", "]", "]", "=", "label", "[", "1", "]", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "categories", ")", ")", ":", "\n", "            ", "if", "polarity_labels", "[", "i", "]", "==", "-", "100", ":", "\n", "                ", "total_labels", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "total_labels", ".", "append", "(", "polarity_labels", "[", "i", "]", "+", "category_labels", "[", "i", "]", ")", "\n", "\n", "", "", "label_field", "=", "ArrayField", "(", "np", ".", "array", "(", "category_labels", "+", "polarity_labels", "+", "total_labels", ")", ")", "\n", "fields", "[", "\"label\"", "]", "=", "label_field", "\n", "polarity_mask", "=", "[", "1", "if", "polarity_labels", "[", "i", "]", "!=", "-", "100", "else", "0", "for", "i", "in", "range", "(", "len", "(", "self", ".", "categories", ")", ")", "]", "\n", "polarity_mask_field", "=", "ArrayField", "(", "np", ".", "array", "(", "polarity_mask", ")", ")", "\n", "fields", "[", "'polarity_mask'", "]", "=", "polarity_mask_field", "\n", "\n", "# stop_word_labels = [1 if word in english_stop_words else 0 for word in words]", "\n", "# stop_word_num = sum(stop_word_labels)", "\n", "# stop_word_labels = [label / stop_word_num for label in stop_word_labels]", "\n", "# sample.append(stop_word_labels)", "\n", "\n", "sample_field", "=", "MetadataField", "(", "sample", ")", "\n", "fields", "[", "\"sample\"", "]", "=", "sample_field", "\n", "return", "Instance", "(", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.TextInAllAspectSentimentOut._read": [[187, 205], ["acd_and_sc_data_reader.TextInAllAspectSentimentOut.text_to_instance", "range", "NotImplementedError", "len", "enumerate", "list", "acd_and_sc_data_reader.TextInAllAspectSentimentOut.text_to_instance", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.text_to_instance", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.text_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "samples", ":", "list", ")", "->", "Iterator", "[", "Instance", "]", ":", "\n", "        ", "acd_sc_mode", "=", "self", ".", "configuration", "[", "'acd_sc_mode'", "]", "\n", "if", "acd_sc_mode", "==", "'multi-multi'", ":", "\n", "            ", "for", "sample", "in", "samples", ":", "\n", "                ", "yield", "self", ".", "text_to_instance", "(", "sample", ")", "\n", "", "", "elif", "acd_sc_mode", "==", "'multi-single'", ":", "\n", "            ", "for", "sample", "in", "samples", ":", "\n", "                ", "text", "=", "sample", "[", "0", "]", "\n", "labels", "=", "sample", "[", "1", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "                    ", "labels_copy", "=", "[", "list", "(", "e", ")", "for", "e", "in", "copy", ".", "deepcopy", "(", "labels", ")", "]", "\n", "for", "j", ",", "label", "in", "enumerate", "(", "labels_copy", ")", ":", "\n", "                        ", "if", "j", "!=", "i", ":", "\n", "                            ", "labels_copy", "[", "j", "]", "[", "1", "]", "=", "-", "100", "\n", "", "", "yield", "self", ".", "text_to_instance", "(", "[", "text", ",", "labels_copy", "]", ")", "\n", "", "", "", "elif", "acd_sc_mode", "==", "'single-single'", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'single-single'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBert.__init__": [[208, 227], ["allennlp.data.dataset_readers.DatasetReader.__init__", "spacy.load", "x.split", "allennlp.data.token_indexers.SingleIdTokenIndexer", "allennlp.data.token_indexers.SingleIdTokenIndexer", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "categories", ":", "List", "[", "str", "]", ",", "polarities", ":", "List", "[", "str", "]", ",", "\n", "tokenizer", ":", "Callable", "[", "[", "str", "]", ",", "List", "[", "str", "]", "]", "=", "lambda", "x", ":", "x", ".", "split", "(", ")", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "position_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "core_nlp", ":", "my_corenlp", ".", "StanfordCoreNLP", "=", "None", ",", "\n", "configuration", "=", "None", ",", "\n", "bert_tokenizer", "=", "None", ",", "\n", "bert_token_indexers", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", "=", "False", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "token_indexers", "=", "token_indexers", "or", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", "namespace", "=", "\"tokens\"", ")", "}", "\n", "self", ".", "bert_tokenizer", "=", "bert_tokenizer", "\n", "self", ".", "bert_token_indexers", "=", "bert_token_indexers", "or", "{", "\"bert\"", ":", "SingleIdTokenIndexer", "(", "namespace", "=", "\"bert\"", ")", "}", "\n", "self", ".", "position_indexers", "=", "position_indexers", "or", "{", "\"position\"", ":", "SingleIdTokenIndexer", "(", "namespace", "=", "'position'", ")", "}", "\n", "self", ".", "categories", "=", "categories", "\n", "self", ".", "polarities", "=", "polarities", "\n", "self", ".", "spacy_nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "self", ".", "core_nlp", "=", "core_nlp", "\n", "self", ".", "configuration", "=", "configuration", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBert._build_graph": [[228, 231], ["nlp_tasks.utils.create_graph.create_dependency_graph_for_dgl"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.create_graph.create_dependency_graph_for_dgl"], ["", "def", "_build_graph", "(", "self", ",", "text", ")", ":", "\n", "        ", "graph", "=", "create_graph", ".", "create_dependency_graph_for_dgl", "(", "text", ",", "self", ".", "spacy_nlp", ",", "None", ")", "\n", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBert.text_to_instance": [[232, 305], ["sample[].strip", "acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBert.tokenizer", "sample.append", "acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBert._build_graph", "sample.append", "allennlp.data.fields.TextField", "enumerate", "bert_words.append", "allennlp.data.fields.ListField", "sample.append", "sample.append", "sample.append", "allennlp.data.fields.TextField", "range", "allennlp.data.fields.ArrayField", "allennlp.data.fields.ArrayField", "allennlp.data.fields.MetadataField", "allennlp.data.Instance", "words.append", "allennlp.data.tokenizers.Token", "acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBert.bert_tokenizer.tokenize", "range", "bert_words.extend", "acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBert.bert_tokenizer.tokenize", "bert_words_of_all_aspect.append", "allennlp.data.fields.TextField", "bert_text_fileds.append", "allennlp.data.tokenizers.Token", "len", "len", "len", "len", "numpy.array", "numpy.array", "word.strip", "len", "word_index_and_bert_indices[].append", "allennlp.data.tokenizers.Token", "str", "range", "total_labels.append", "total_labels.append", "range", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle._build_graph"], ["", "@", "overrides", "\n", "def", "text_to_instance", "(", "self", ",", "sample", ":", "list", ")", "->", "Instance", ":", "\n", "        ", "fields", "=", "{", "}", "\n", "\n", "text", ":", "str", "=", "sample", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "words", "=", "[", "]", "\n", "for", "word", "in", "self", ".", "tokenizer", "(", "text", ")", ":", "\n", "            ", "if", "word", ".", "strip", "(", ")", "==", "''", ":", "\n", "                ", "continue", "\n", "", "words", ".", "append", "(", "word", ")", "\n", "", "sample", ".", "append", "(", "words", ")", "\n", "\n", "graph", "=", "self", ".", "_build_graph", "(", "text", ")", "\n", "sample", ".", "append", "(", "graph", ")", "\n", "\n", "tokens", "=", "[", "Token", "(", "word", ")", "for", "word", "in", "words", "]", "\n", "\n", "sentence_field", "=", "TextField", "(", "tokens", ",", "self", ".", "token_indexers", ")", "\n", "fields", "[", "'tokens'", "]", "=", "sentence_field", "\n", "\n", "bert_words", "=", "[", "'[CLS]'", "]", "\n", "word_index_and_bert_indices", "=", "{", "}", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "            ", "bert_ws", "=", "self", ".", "bert_tokenizer", ".", "tokenize", "(", "word", ")", "\n", "word_index_and_bert_indices", "[", "i", "]", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "bert_ws", ")", ")", ":", "\n", "                ", "word_index_and_bert_indices", "[", "i", "]", ".", "append", "(", "len", "(", "bert_words", ")", "+", "j", ")", "\n", "", "bert_words", ".", "extend", "(", "bert_ws", ")", "\n", "", "bert_words", ".", "append", "(", "'[SEP]'", ")", "\n", "# for i in range(len(words)):", "\n", "#     print('%s-%s' % (words[i], str([bert_words[j] for j in word_index_and_bert_indices[i]])))", "\n", "bert_text_fileds", "=", "[", "]", "\n", "bert_words_of_all_aspect", "=", "[", "]", "\n", "for", "aspect", "in", "self", ".", "categories", ":", "\n", "            ", "aspect_words", "=", "self", ".", "bert_tokenizer", ".", "tokenize", "(", "aspect", ")", "\n", "bert_words_of_aspect", "=", "bert_words", "+", "aspect_words", "+", "[", "'[SEP]'", "]", "\n", "bert_words_of_all_aspect", ".", "append", "(", "bert_words_of_aspect", ")", "\n", "bert_tokens_of_aspect", "=", "[", "Token", "(", "word", ")", "for", "word", "in", "bert_words_of_aspect", "]", "\n", "bert_text_field", "=", "TextField", "(", "bert_tokens_of_aspect", ",", "self", ".", "bert_token_indexers", ")", "\n", "bert_text_fileds", ".", "append", "(", "bert_text_field", ")", "\n", "", "bert_field", "=", "ListField", "(", "bert_text_fileds", ")", "\n", "fields", "[", "'bert'", "]", "=", "bert_field", "\n", "sample", ".", "append", "(", "bert_words", ")", "\n", "sample", ".", "append", "(", "bert_words_of_all_aspect", ")", "\n", "sample", ".", "append", "(", "word_index_and_bert_indices", ")", "\n", "\n", "position", "=", "[", "Token", "(", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "tokens", ")", ")", "]", "\n", "position_field", "=", "TextField", "(", "position", ",", "self", ".", "position_indexers", ")", "\n", "fields", "[", "'position'", "]", "=", "position_field", "\n", "\n", "category_labels", "=", "[", "0", "]", "*", "len", "(", "self", ".", "categories", ")", "\n", "polarity_labels", "=", "[", "-", "100", "]", "*", "len", "(", "self", ".", "categories", ")", "\n", "total_labels", "=", "[", "]", "\n", "if", "len", "(", "sample", ")", ">", "1", ":", "\n", "            ", "labels", ":", "list", "=", "sample", "[", "1", "]", "\n", "for", "label", "in", "labels", ":", "\n", "                ", "category_labels", "[", "label", "[", "0", "]", "]", "=", "1", "\n", "polarity_labels", "[", "label", "[", "0", "]", "]", "=", "label", "[", "1", "]", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "categories", ")", ")", ":", "\n", "            ", "if", "polarity_labels", "[", "i", "]", "==", "-", "100", ":", "\n", "                ", "total_labels", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "total_labels", ".", "append", "(", "polarity_labels", "[", "i", "]", "+", "category_labels", "[", "i", "]", ")", "\n", "\n", "", "", "label_field", "=", "ArrayField", "(", "np", ".", "array", "(", "category_labels", "+", "polarity_labels", "+", "total_labels", ")", ")", "\n", "fields", "[", "\"label\"", "]", "=", "label_field", "\n", "polarity_mask", "=", "[", "1", "if", "polarity_labels", "[", "i", "]", "!=", "-", "100", "else", "0", "for", "i", "in", "range", "(", "len", "(", "self", ".", "categories", ")", ")", "]", "\n", "polarity_mask_field", "=", "ArrayField", "(", "np", ".", "array", "(", "polarity_mask", ")", ")", "\n", "fields", "[", "'polarity_mask'", "]", "=", "polarity_mask_field", "\n", "sample_field", "=", "MetadataField", "(", "sample", ")", "\n", "fields", "[", "\"sample\"", "]", "=", "sample_field", "\n", "return", "Instance", "(", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBert._read": [[306, 324], ["acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBert.text_to_instance", "range", "NotImplementedError", "len", "enumerate", "list", "acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBert.text_to_instance", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.text_to_instance", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.text_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "samples", ":", "list", ")", "->", "Iterator", "[", "Instance", "]", ":", "\n", "        ", "acd_sc_mode", "=", "self", ".", "configuration", "[", "'acd_sc_mode'", "]", "\n", "if", "acd_sc_mode", "==", "'multi-multi'", ":", "\n", "            ", "for", "sample", "in", "samples", ":", "\n", "                ", "yield", "self", ".", "text_to_instance", "(", "sample", ")", "\n", "", "", "elif", "acd_sc_mode", "==", "'multi-single'", ":", "\n", "            ", "for", "sample", "in", "samples", ":", "\n", "                ", "text", "=", "sample", "[", "0", "]", "\n", "labels", "=", "sample", "[", "1", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "                    ", "labels_copy", "=", "[", "list", "(", "e", ")", "for", "e", "in", "copy", ".", "deepcopy", "(", "labels", ")", "]", "\n", "for", "j", ",", "label", "in", "enumerate", "(", "labels_copy", ")", ":", "\n", "                        ", "if", "j", "!=", "i", ":", "\n", "                            ", "labels_copy", "[", "j", "]", "[", "1", "]", "=", "-", "100", "\n", "", "", "yield", "self", ".", "text_to_instance", "(", "[", "text", ",", "labels_copy", "]", ")", "\n", "", "", "", "elif", "acd_sc_mode", "==", "'single-single'", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'single-single'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.__init__": [[327, 346], ["allennlp.data.dataset_readers.DatasetReader.__init__", "spacy.load", "x.split", "allennlp.data.token_indexers.SingleIdTokenIndexer", "allennlp.data.token_indexers.SingleIdTokenIndexer", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "categories", ":", "List", "[", "str", "]", ",", "polarities", ":", "List", "[", "str", "]", ",", "\n", "tokenizer", ":", "Callable", "[", "[", "str", "]", ",", "List", "[", "str", "]", "]", "=", "lambda", "x", ":", "x", ".", "split", "(", ")", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "position_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "core_nlp", ":", "my_corenlp", ".", "StanfordCoreNLP", "=", "None", ",", "\n", "configuration", "=", "None", ",", "\n", "bert_tokenizer", "=", "None", ",", "\n", "bert_token_indexers", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", "=", "False", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "token_indexers", "=", "token_indexers", "or", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", "namespace", "=", "\"tokens\"", ")", "}", "\n", "self", ".", "bert_tokenizer", "=", "bert_tokenizer", "\n", "self", ".", "bert_token_indexers", "=", "bert_token_indexers", "or", "{", "\"bert\"", ":", "SingleIdTokenIndexer", "(", "namespace", "=", "\"bert\"", ")", "}", "\n", "self", ".", "position_indexers", "=", "position_indexers", "or", "{", "\"position\"", ":", "SingleIdTokenIndexer", "(", "namespace", "=", "'position'", ")", "}", "\n", "self", ".", "categories", "=", "categories", "\n", "self", ".", "polarities", "=", "polarities", "\n", "self", ".", "spacy_nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "self", ".", "core_nlp", "=", "core_nlp", "\n", "self", ".", "configuration", "=", "configuration", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle._build_graph": [[347, 350], ["nlp_tasks.utils.create_graph.create_dependency_graph_for_dgl"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.create_graph.create_dependency_graph_for_dgl"], ["", "def", "_build_graph", "(", "self", ",", "text", ")", ":", "\n", "        ", "graph", "=", "create_graph", ".", "create_dependency_graph_for_dgl", "(", "text", ",", "self", ".", "spacy_nlp", ",", "None", ")", "\n", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.text_to_instance": [[351, 422], ["sample[].strip", "acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.tokenizer", "sample.append", "acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle._build_graph", "sample.append", "allennlp.data.fields.TextField", "enumerate", "bert_words.append", "bert_words_of_all_aspect.append", "allennlp.data.fields.TextField", "bert_text_fileds.append", "allennlp.data.fields.ListField", "sample.append", "sample.append", "sample.append", "allennlp.data.fields.TextField", "range", "allennlp.data.fields.ArrayField", "allennlp.data.fields.ArrayField", "allennlp.data.fields.MetadataField", "allennlp.data.Instance", "words.append", "allennlp.data.tokenizers.Token", "acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.bert_tokenizer.tokenize", "range", "bert_words.extend", "allennlp.data.tokenizers.Token", "allennlp.data.tokenizers.Token", "len", "len", "len", "len", "numpy.array", "numpy.array", "word.strip", "len", "word_index_and_bert_indices[].append", "str", "range", "total_labels.append", "total_labels.append", "range", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle._build_graph"], ["", "@", "overrides", "\n", "def", "text_to_instance", "(", "self", ",", "sample", ":", "list", ")", "->", "Instance", ":", "\n", "        ", "fields", "=", "{", "}", "\n", "\n", "text", ":", "str", "=", "sample", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "words", "=", "[", "]", "\n", "for", "word", "in", "self", ".", "tokenizer", "(", "text", ")", ":", "\n", "            ", "if", "word", ".", "strip", "(", ")", "==", "''", ":", "\n", "                ", "continue", "\n", "", "words", ".", "append", "(", "word", ")", "\n", "", "sample", ".", "append", "(", "words", ")", "\n", "\n", "graph", "=", "self", ".", "_build_graph", "(", "text", ")", "\n", "sample", ".", "append", "(", "graph", ")", "\n", "\n", "tokens", "=", "[", "Token", "(", "word", ")", "for", "word", "in", "words", "]", "\n", "\n", "sentence_field", "=", "TextField", "(", "tokens", ",", "self", ".", "token_indexers", ")", "\n", "fields", "[", "'tokens'", "]", "=", "sentence_field", "\n", "\n", "bert_words", "=", "[", "'[CLS]'", "]", "\n", "word_index_and_bert_indices", "=", "{", "}", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "            ", "bert_ws", "=", "self", ".", "bert_tokenizer", ".", "tokenize", "(", "word", ")", "\n", "word_index_and_bert_indices", "[", "i", "]", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "bert_ws", ")", ")", ":", "\n", "                ", "word_index_and_bert_indices", "[", "i", "]", ".", "append", "(", "len", "(", "bert_words", ")", "+", "j", ")", "\n", "", "bert_words", ".", "extend", "(", "bert_ws", ")", "\n", "", "bert_words", ".", "append", "(", "'[SEP]'", ")", "\n", "# for i in range(len(words)):", "\n", "#     print('%s-%s' % (words[i], str([bert_words[j] for j in word_index_and_bert_indices[i]])))", "\n", "bert_text_fileds", "=", "[", "]", "\n", "bert_words_of_all_aspect", "=", "[", "]", "\n", "\n", "bert_words_of_all_aspect", ".", "append", "(", "bert_words", ")", "\n", "bert_tokens", "=", "[", "Token", "(", "word", ")", "for", "word", "in", "bert_words", "]", "\n", "bert_text_field", "=", "TextField", "(", "bert_tokens", ",", "self", ".", "bert_token_indexers", ")", "\n", "bert_text_fileds", ".", "append", "(", "bert_text_field", ")", "\n", "bert_field", "=", "ListField", "(", "bert_text_fileds", ")", "\n", "fields", "[", "'bert'", "]", "=", "bert_field", "\n", "sample", ".", "append", "(", "bert_words", ")", "\n", "sample", ".", "append", "(", "bert_words_of_all_aspect", ")", "\n", "sample", ".", "append", "(", "word_index_and_bert_indices", ")", "\n", "\n", "position", "=", "[", "Token", "(", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "tokens", ")", ")", "]", "\n", "position_field", "=", "TextField", "(", "position", ",", "self", ".", "position_indexers", ")", "\n", "fields", "[", "'position'", "]", "=", "position_field", "\n", "\n", "category_labels", "=", "[", "0", "]", "*", "len", "(", "self", ".", "categories", ")", "\n", "polarity_labels", "=", "[", "-", "100", "]", "*", "len", "(", "self", ".", "categories", ")", "\n", "total_labels", "=", "[", "]", "\n", "if", "len", "(", "sample", ")", ">", "1", ":", "\n", "            ", "labels", ":", "list", "=", "sample", "[", "1", "]", "\n", "for", "label", "in", "labels", ":", "\n", "                ", "category_labels", "[", "label", "[", "0", "]", "]", "=", "1", "\n", "polarity_labels", "[", "label", "[", "0", "]", "]", "=", "label", "[", "1", "]", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "categories", ")", ")", ":", "\n", "            ", "if", "polarity_labels", "[", "i", "]", "==", "-", "100", ":", "\n", "                ", "total_labels", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "total_labels", ".", "append", "(", "polarity_labels", "[", "i", "]", "+", "category_labels", "[", "i", "]", ")", "\n", "\n", "", "", "label_field", "=", "ArrayField", "(", "np", ".", "array", "(", "category_labels", "+", "polarity_labels", "+", "total_labels", ")", ")", "\n", "fields", "[", "\"label\"", "]", "=", "label_field", "\n", "polarity_mask", "=", "[", "1", "if", "polarity_labels", "[", "i", "]", "!=", "-", "100", "else", "0", "for", "i", "in", "range", "(", "len", "(", "self", ".", "categories", ")", ")", "]", "\n", "polarity_mask_field", "=", "ArrayField", "(", "np", ".", "array", "(", "polarity_mask", ")", ")", "\n", "fields", "[", "'polarity_mask'", "]", "=", "polarity_mask_field", "\n", "sample_field", "=", "MetadataField", "(", "sample", ")", "\n", "fields", "[", "\"sample\"", "]", "=", "sample_field", "\n", "return", "Instance", "(", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle._read": [[423, 441], ["acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.text_to_instance", "range", "NotImplementedError", "len", "enumerate", "list", "acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.text_to_instance", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.text_to_instance", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.acd_and_sc_data_reader.AcdAndScDatasetReaderMilSimultaneouslyBertSingle.text_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "samples", ":", "list", ")", "->", "Iterator", "[", "Instance", "]", ":", "\n", "        ", "acd_sc_mode", "=", "self", ".", "configuration", "[", "'acd_sc_mode'", "]", "\n", "if", "acd_sc_mode", "==", "'multi-multi'", ":", "\n", "            ", "for", "sample", "in", "samples", ":", "\n", "                ", "yield", "self", ".", "text_to_instance", "(", "sample", ")", "\n", "", "", "elif", "acd_sc_mode", "==", "'multi-single'", ":", "\n", "            ", "for", "sample", "in", "samples", ":", "\n", "                ", "text", "=", "sample", "[", "0", "]", "\n", "labels", "=", "sample", "[", "1", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "                    ", "labels_copy", "=", "[", "list", "(", "e", ")", "for", "e", "in", "copy", ".", "deepcopy", "(", "labels", ")", "]", "\n", "for", "j", ",", "label", "in", "enumerate", "(", "labels_copy", ")", ":", "\n", "                        ", "if", "j", "!=", "i", ":", "\n", "                            ", "labels_copy", "[", "j", "]", "[", "1", "]", "=", "-", "100", "\n", "", "", "yield", "self", ".", "text_to_instance", "(", "[", "text", ",", "labels_copy", "]", ")", "\n", "", "", "", "elif", "acd_sc_mode", "==", "'single-single'", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'single-single'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.Callback.__init__": [[12, 14], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.Callback.on_epoch_end": [[15, 17], ["None"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ":", "int", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.Callback.on_epoch_begin": [[18, 20], ["None"], "methods", ["None"], ["", "def", "on_epoch_begin", "(", "self", ",", "epoch", ":", "int", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.Callback.on_batch_end": [[21, 23], ["None"], "methods", ["None"], ["", "def", "on_batch_end", "(", "self", ",", "batch", ":", "int", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.Callback.on_train_begin": [[24, 26], ["None"], "methods", ["None"], ["", "def", "on_train_begin", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.EstimateCallback.__init__": [[30, 34], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_type_and_data", ":", "dict", ",", "estimator", ":", "pytorch_models", ".", "Estimator", ",", "logger", ")", ":", "\n", "        ", "self", ".", "data_type_and_data", "=", "data_type_and_data", "\n", "self", ".", "estimator", "=", "estimator", "\n", "self", ".", "logger", "=", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.EstimateCallback.on_epoch_end": [[35, 39], ["allennlp_callback.EstimateCallback.data_type_and_data.items", "allennlp_callback.EstimateCallback.estimator.estimate", "allennlp_callback.EstimateCallback.logger.info", "str"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimatorAll.estimate"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "for", "data_type", ",", "data", "in", "self", ".", "data_type_and_data", ".", "items", "(", ")", ":", "\n", "            ", "result", "=", "self", ".", "estimator", ".", "estimate", "(", "data", ")", "\n", "self", ".", "logger", ".", "info", "(", "'epoch: %d data_type: %s result: %s'", "%", "(", "epoch", ",", "data_type", ",", "str", "(", "result", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.EstimateCallback.on_batch_end": [[40, 44], ["allennlp_callback.EstimateCallback.data_type_and_data.items", "allennlp_callback.EstimateCallback.estimator.estimate", "allennlp_callback.EstimateCallback.logger.info", "str"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimatorAll.estimate"], ["", "", "def", "on_batch_end", "(", "self", ",", "batch", ":", "int", ")", ":", "\n", "        ", "for", "data_type", ",", "data", "in", "self", ".", "data_type_and_data", ".", "items", "(", ")", ":", "\n", "            ", "result", "=", "self", ".", "estimator", ".", "estimate", "(", "data", ")", "\n", "self", ".", "logger", ".", "info", "(", "'batch: %d data_type: %s result: %s'", "%", "(", "batch", ",", "data_type", ",", "str", "(", "result", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.SetLossWeightCallback.__init__": [[48, 52], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ":", "pytorch_models", ".", "TextInAllAspectSentimentOutModel", ",", "logger", ",", "acd_warmup_epoch_num", "=", "0", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "acd_warmup_epoch_num", "=", "acd_warmup_epoch_num", "\n", "self", ".", "logger", "=", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.SetLossWeightCallback.on_epoch_begin": [[53, 59], ["None"], "methods", ["None"], ["", "def", "on_epoch_begin", "(", "self", ",", "epoch", ":", "int", ")", ":", "\n", "        ", "if", "epoch", "<", "self", ".", "acd_warmup_epoch_num", ":", "\n", "            ", "self", ".", "model", ".", "sentiment_loss_weight", "=", "0", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", ".", "category_loss_weight", "=", "1", "\n", "self", ".", "model", ".", "sentiment_loss_weight", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.FixedLossWeightCallback.__init__": [[63, 68], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ":", "pytorch_models", ".", "TextInAllAspectSentimentOutModel", ",", "logger", ",", "category_loss_weight", "=", "1", ",", "\n", "sentiment_loss_weight", "=", "1", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "category_loss_weight", "=", "category_loss_weight", "\n", "self", ".", "sentiment_loss_weight", "=", "sentiment_loss_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.FixedLossWeightCallback.on_train_begin": [[69, 72], ["None"], "methods", ["None"], ["", "def", "on_train_begin", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", ".", "category_loss_weight", "=", "self", ".", "category_loss_weight", "\n", "self", ".", "model", ".", "sentiment_loss_weight", "=", "self", ".", "sentiment_loss_weight", "\n", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer.Trainer.__init__": [[43, 261], ["allennlp.training.trainer_base.TrainerBase.__init__", "allennlp.training.metric_tracker.MetricTracker", "allennlp.training.tensorboard_writer.TensorboardWriter", "allennlp.training.checkpointer.Checkpointer", "my_allennlp_trainer.Trainer._tensorboard.enable_activation_logging", "logger.warning", "allennlp.common.checks.ConfigurationError", "allennlp.common.checks.ConfigurationError", "isinstance"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ":", "Model", ",", "\n", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "iterator", ":", "DataIterator", ",", "\n", "train_dataset", ":", "Iterable", "[", "Instance", "]", ",", "\n", "validation_dataset", ":", "Optional", "[", "Iterable", "[", "Instance", "]", "]", "=", "None", ",", "\n", "patience", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "validation_metric", ":", "str", "=", "\"-loss\"", ",", "\n", "validation_iterator", ":", "DataIterator", "=", "None", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "num_epochs", ":", "int", "=", "20", ",", "\n", "serialization_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "num_serialized_models_to_keep", ":", "int", "=", "20", ",", "\n", "keep_serialized_model_every_num_seconds", ":", "int", "=", "None", ",", "\n", "checkpointer", ":", "Checkpointer", "=", "None", ",", "\n", "model_save_interval", ":", "float", "=", "None", ",", "\n", "cuda_device", ":", "Union", "[", "int", ",", "List", "]", "=", "-", "1", ",", "\n", "grad_norm", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "grad_clipping", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "learning_rate_scheduler", ":", "Optional", "[", "LearningRateScheduler", "]", "=", "None", ",", "\n", "momentum_scheduler", ":", "Optional", "[", "MomentumScheduler", "]", "=", "None", ",", "\n", "summary_interval", ":", "int", "=", "100", ",", "\n", "histogram_interval", ":", "int", "=", "None", ",", "\n", "should_log_parameter_statistics", ":", "bool", "=", "True", ",", "\n", "should_log_learning_rate", ":", "bool", "=", "False", ",", "\n", "log_batch_size_period", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "moving_average", ":", "Optional", "[", "MovingAverage", "]", "=", "None", ",", "\n", "callbacks", ":", "List", "[", "allennlp_callback", ".", "Callback", "]", "=", "None", ",", "\n", "early_stopping_by_batch", ":", "bool", "=", "True", ",", "\n", "estimator", ":", "Estimator", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        A trainer for doing supervised learning. It just takes a labeled dataset\n        and a ``DataIterator``, and uses the supplied ``Optimizer`` to learn the weights\n        for your model over some fixed number of epochs. You can also pass in a validation\n        dataset and enable early stopping. There are many other bells and whistles as well.\n\n        Parameters\n        ----------\n        model : ``Model``, required.\n            An AllenNLP model to be optimized. Pytorch Modules can also be optimized if\n            their ``forward`` method returns a dictionary with a \"loss\" key, containing a\n            scalar tensor representing the loss function to be optimized.\n\n            If you are training your model using GPUs, your model should already be\n            on the correct device. (If you use `Trainer.from_params` this will be\n            handled for you.)\n        optimizer : ``torch.nn.Optimizer``, required.\n            An instance of a Pytorch Optimizer, instantiated with the parameters of the\n            model to be optimized.\n        iterator : ``DataIterator``, required.\n            A method for iterating over a ``Dataset``, yielding padded indexed batches.\n        train_dataset : ``Dataset``, required.\n            A ``Dataset`` to train on. The dataset should have already been indexed.\n        validation_dataset : ``Dataset``, optional, (default = None).\n            A ``Dataset`` to evaluate on. The dataset should have already been indexed.\n        patience : Optional[int] > 0, optional (default=None)\n            Number of epochs to be patient before early stopping: the training is stopped\n            after ``patience`` epochs with no improvement. If given, it must be ``> 0``.\n            If None, early stopping is disabled.\n        validation_metric : str, optional (default=\"loss\")\n            Validation metric to measure for whether to stop training using patience\n            and whether to serialize an ``is_best`` model each epoch. The metric name\n            must be prepended with either \"+\" or \"-\", which specifies whether the metric\n            is an increasing or decreasing function.\n        validation_iterator : ``DataIterator``, optional (default=None)\n            An iterator to use for the validation set.  If ``None``, then\n            use the training `iterator`.\n        shuffle: ``bool``, optional (default=True)\n            Whether to shuffle the instances in the iterator or not.\n        num_epochs : int, optional (default = 20)\n            Number of training epochs.\n        serialization_dir : str, optional (default=None)\n            Path to directory for saving and loading model files. Models will not be saved if\n            this parameter is not passed.\n        num_serialized_models_to_keep : ``int``, optional (default=20)\n            Number of previous model checkpoints to retain.  Default is to keep 20 checkpoints.\n            A value of None or -1 means all checkpoints will be kept.\n        keep_serialized_model_every_num_seconds : ``int``, optional (default=None)\n            If num_serialized_models_to_keep is not None, then occasionally it's useful to\n            save models at a given interval in addition to the last num_serialized_models_to_keep.\n            To do so, specify keep_serialized_model_every_num_seconds as the number of seconds\n            between permanently saved checkpoints.  Note that this option is only used if\n            num_serialized_models_to_keep is not None, otherwise all checkpoints are kept.\n        checkpointer : ``Checkpointer``, optional (default=None)\n            An instance of class Checkpointer to use instead of the default. If a checkpointer is specified,\n            the arguments num_serialized_models_to_keep and keep_serialized_model_every_num_seconds should\n            not be specified. The caller is responsible for initializing the checkpointer so that it is\n            consistent with serialization_dir.\n        model_save_interval : ``float``, optional (default=None)\n            If provided, then serialize models every ``model_save_interval``\n            seconds within single epochs.  In all cases, models are also saved\n            at the end of every epoch if ``serialization_dir`` is provided.\n        cuda_device : ``Union[int, List[int]]``, optional (default = -1)\n            An integer or list of integers specifying the CUDA device(s) to use. If -1, the CPU is used.\n        grad_norm : ``float``, optional, (default = None).\n            If provided, gradient norms will be rescaled to have a maximum of this value.\n        grad_clipping : ``float``, optional (default = ``None``).\n            If provided, gradients will be clipped `during the backward pass` to have an (absolute)\n            maximum of this value.  If you are getting ``NaNs`` in your gradients during training\n            that are not solved by using ``grad_norm``, you may need this.\n        learning_rate_scheduler : ``LearningRateScheduler``, optional (default = None)\n            If specified, the learning rate will be decayed with respect to\n            this schedule at the end of each epoch (or batch, if the scheduler implements\n            the ``step_batch`` method). If you use :class:`torch.optim.lr_scheduler.ReduceLROnPlateau`,\n            this will use the ``validation_metric`` provided to determine if learning has plateaued.\n            To support updating the learning rate on every batch, this can optionally implement\n            ``step_batch(batch_num_total)`` which updates the learning rate given the batch number.\n        momentum_scheduler : ``MomentumScheduler``, optional (default = None)\n            If specified, the momentum will be updated at the end of each batch or epoch\n            according to the schedule.\n        summary_interval: ``int``, optional, (default = 100)\n            Number of batches between logging scalars to tensorboard\n        histogram_interval : ``int``, optional, (default = ``None``)\n            If not None, then log histograms to tensorboard every ``histogram_interval`` batches.\n            When this parameter is specified, the following additional logging is enabled:\n                * Histograms of model parameters\n                * The ratio of parameter update norm to parameter norm\n                * Histogram of layer activations\n            We log histograms of the parameters returned by\n            ``model.get_parameters_for_histogram_tensorboard_logging``.\n            The layer activations are logged for any modules in the ``Model`` that have\n            the attribute ``should_log_activations`` set to ``True``.  Logging\n            histograms requires a number of GPU-CPU copies during training and is typically\n            slow, so we recommend logging histograms relatively infrequently.\n            Note: only Modules that return tensors, tuples of tensors or dicts\n            with tensors as values currently support activation logging.\n        should_log_parameter_statistics : ``bool``, optional, (default = True)\n            Whether to send parameter statistics (mean and standard deviation\n            of parameters and gradients) to tensorboard.\n        should_log_learning_rate : ``bool``, optional, (default = False)\n            Whether to send parameter specific learning rate to tensorboard.\n        log_batch_size_period : ``int``, optional, (default = ``None``)\n            If defined, how often to log the average batch size.\n        moving_average: ``MovingAverage``, optional, (default = None)\n            If provided, we will maintain moving averages for all parameters. During training, we\n            employ a shadow variable for each parameter, which maintains the moving average. During\n            evaluation, we backup the original parameters and assign the moving averages to corresponding\n            parameters. Be careful that when saving the checkpoint, we will save the moving averages of\n            parameters. This is necessary because we want the saved model to perform as well as the validated\n            model if we load it later. But this may cause problems if you restart the training from checkpoint.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "serialization_dir", ",", "cuda_device", ")", "\n", "\n", "# I am not calling move_to_gpu here, because if the model is", "\n", "# not already on the GPU then the optimizer is going to be wrong.", "\n", "self", ".", "model", "=", "model", "\n", "\n", "self", ".", "iterator", "=", "iterator", "\n", "self", ".", "_validation_iterator", "=", "validation_iterator", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "train_data", "=", "train_dataset", "\n", "self", ".", "_validation_data", "=", "validation_dataset", "\n", "\n", "if", "patience", "is", "None", ":", "# no early stopping", "\n", "            ", "if", "validation_dataset", ":", "\n", "                ", "logger", ".", "warning", "(", "'You provided a validation dataset but patience was set to None, '", "\n", "'meaning that early stopping is disabled'", ")", "\n", "", "", "elif", "(", "not", "isinstance", "(", "patience", ",", "int", ")", ")", "or", "patience", "<=", "0", ":", "\n", "            ", "raise", "ConfigurationError", "(", "'{} is an invalid value for \"patience\": it must be a positive integer '", "\n", "'or None (if you want to disable early stopping)'", ".", "format", "(", "patience", ")", ")", "\n", "\n", "# For tracking is_best_so_far and should_stop_early", "\n", "", "self", ".", "_metric_tracker", "=", "MetricTracker", "(", "patience", ",", "validation_metric", ")", "\n", "# Get rid of + or -", "\n", "self", ".", "_validation_metric", "=", "validation_metric", "[", "1", ":", "]", "\n", "\n", "self", ".", "_num_epochs", "=", "num_epochs", "\n", "\n", "if", "checkpointer", "is", "not", "None", ":", "\n", "# We can't easily check if these parameters were passed in, so check against their default values.", "\n", "# We don't check against serialization_dir since it is also used by the parent class.", "\n", "            ", "if", "num_serialized_models_to_keep", "!=", "20", "or", "keep_serialized_model_every_num_seconds", "is", "not", "None", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\n", "\"When passing a custom Checkpointer, you may not also pass in separate checkpointer \"", "\n", "\"args 'num_serialized_models_to_keep' or 'keep_serialized_model_every_num_seconds'.\"", ")", "\n", "", "self", ".", "_checkpointer", "=", "checkpointer", "\n", "", "else", ":", "\n", "            ", "self", ".", "_checkpointer", "=", "Checkpointer", "(", "serialization_dir", ",", "\n", "keep_serialized_model_every_num_seconds", ",", "\n", "num_serialized_models_to_keep", ")", "\n", "\n", "", "self", ".", "_model_save_interval", "=", "model_save_interval", "\n", "\n", "self", ".", "_grad_norm", "=", "grad_norm", "\n", "self", ".", "_grad_clipping", "=", "grad_clipping", "\n", "\n", "self", ".", "_learning_rate_scheduler", "=", "learning_rate_scheduler", "\n", "self", ".", "_momentum_scheduler", "=", "momentum_scheduler", "\n", "self", ".", "_moving_average", "=", "moving_average", "\n", "\n", "# We keep the total batch number as an instance variable because it", "\n", "# is used inside a closure for the hook which logs activations in", "\n", "# ``_enable_activation_logging``.", "\n", "self", ".", "_batch_num_total", "=", "0", "\n", "\n", "self", ".", "_tensorboard", "=", "TensorboardWriter", "(", "\n", "get_batch_num_total", "=", "lambda", ":", "self", ".", "_batch_num_total", ",", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "summary_interval", "=", "summary_interval", ",", "\n", "histogram_interval", "=", "histogram_interval", ",", "\n", "should_log_parameter_statistics", "=", "should_log_parameter_statistics", ",", "\n", "should_log_learning_rate", "=", "should_log_learning_rate", ")", "\n", "\n", "self", ".", "_log_batch_size_period", "=", "log_batch_size_period", "\n", "\n", "self", ".", "_last_log", "=", "0.0", "# time of last logging", "\n", "\n", "# Enable activation logging.", "\n", "if", "histogram_interval", "is", "not", "None", ":", "\n", "            ", "self", ".", "_tensorboard", ".", "enable_activation_logging", "(", "self", ".", "model", ")", "\n", "", "self", ".", "callbacks", "=", "callbacks", "\n", "\n", "self", ".", "_early_stopping_by_batch", "=", "early_stopping_by_batch", "\n", "\n", "self", ".", "_estimator", "=", "estimator", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer.Trainer.rescale_gradients": [[262, 264], ["allennlp.training.util.rescale_gradients"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.rescale_gradients"], ["", "def", "rescale_gradients", "(", "self", ")", "->", "Optional", "[", "float", "]", ":", "\n", "        ", "return", "training_util", ".", "rescale_gradients", "(", "self", ".", "model", ",", "self", ".", "_grad_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer.Trainer.batch_loss": [[265, 289], ["allennlp.training.util.data_parallel", "allennlp.nn.util.move_to_device", "my_allennlp_trainer.Trainer.model", "len", "my_allennlp_trainer.Trainer.model.get_regularization_penalty", "RuntimeError"], "methods", ["None"], ["", "def", "batch_loss", "(", "self", ",", "batch_group", ":", "List", "[", "TensorDict", "]", ",", "for_training", ":", "bool", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Does a forward pass on the given batches and returns the ``loss`` value in the result.\n        If ``for_training`` is `True` also applies regularization penalty.\n        \"\"\"", "\n", "if", "self", ".", "_multiple_gpu", ":", "\n", "            ", "output_dict", "=", "training_util", ".", "data_parallel", "(", "batch_group", ",", "self", ".", "model", ",", "self", ".", "_cuda_devices", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "batch_group", ")", "==", "1", "\n", "batch", "=", "batch_group", "[", "0", "]", "\n", "batch", "=", "nn_util", ".", "move_to_device", "(", "batch", ",", "self", ".", "_cuda_devices", "[", "0", "]", ")", "\n", "output_dict", "=", "self", ".", "model", "(", "**", "batch", ")", "\n", "\n", "", "try", ":", "\n", "            ", "loss", "=", "output_dict", "[", "\"loss\"", "]", "\n", "if", "for_training", ":", "\n", "                ", "loss", "+=", "self", ".", "model", ".", "get_regularization_penalty", "(", ")", "\n", "", "", "except", "KeyError", ":", "\n", "            ", "if", "for_training", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"The model you are trying to optimize does not contain a\"", "\n", "\" 'loss' key in the output of model.forward(inputs).\"", ")", "\n", "", "loss", "=", "None", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer.Trainer._train_epoch": [[290, 436], ["logger.info", "allennlp.common.util.peak_memory_mb", "logger.info", "allennlp.common.util.gpu_memory_mb().items", "my_allennlp_trainer.Trainer.model.train", "len", "my_allennlp_trainer.Trainer.iterator", "allennlp.common.util.lazy_groups_of", "math.ceil", "time.time", "time.time", "set", "logger.info", "allennlp.common.tqdm.Tqdm.tqdm", "allennlp.training.util.get_metrics", "gpu_usage.append", "logger.info", "my_allennlp_trainer.Trainer.model.get_parameters_for_histogram_tensorboard_logging", "my_allennlp_trainer.Trainer.model.train", "my_allennlp_trainer.Trainer.optimizer.zero_grad", "my_allennlp_trainer.Trainer.batch_loss", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "my_allennlp_trainer.Trainer.backward", "my_allennlp_trainer.Trainer.item", "my_allennlp_trainer.Trainer.rescale_gradients", "my_allennlp_trainer.Trainer._tensorboard.should_log_histograms_this_batch", "allennlp.training.util.get_metrics", "allennlp.training.util.description_from_metrics", "allennlp.common.tqdm.Tqdm.tqdm.set_description", "my_allennlp_trainer.Trainer._tensorboard.should_log_this_batch", "my_allennlp_trainer.Trainer._tensorboard.should_log_histograms_this_batch", "allennlp.common.util.gpu_memory_mb", "my_allennlp_trainer.Trainer.iterator.get_num_batches", "ValueError", "my_allennlp_trainer.Trainer._learning_rate_scheduler.step_batch", "my_allennlp_trainer.Trainer._momentum_scheduler.step_batch", "my_allennlp_trainer.Trainer.optimizer.step", "my_allennlp_trainer.Trainer.model.named_parameters", "my_allennlp_trainer.Trainer.optimizer.step", "my_allennlp_trainer.Trainer._moving_average.apply", "my_allennlp_trainer.Trainer._tensorboard.log_parameter_and_gradient_statistics", "my_allennlp_trainer.Trainer._tensorboard.log_learning_rates", "my_allennlp_trainer.Trainer._tensorboard.add_train_scalar", "my_allennlp_trainer.Trainer._tensorboard.log_metrics", "my_allennlp_trainer.Trainer._tensorboard.log_histograms", "sum", "time.time", "my_allennlp_trainer.Trainer._save_checkpoint", "param.detach().cpu().clone", "param_updates[].sub_", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm().cpu", "torch.norm().cpu", "torch.norm().cpu", "torch.norm().cpu", "my_allennlp_trainer.Trainer._tensorboard.add_train_scalar", "logger.info", "my_allennlp_trainer.Trainer._tensorboard.add_train_scalar", "my_allennlp_trainer.Trainer._tensorboard.add_train_scalar", "my_allennlp_trainer.Trainer.model.named_parameters", "param.detach().cpu", "param_updates[].view", "allennlp.training.util.get_batch_size", "time.time", "allennlp.training.util.time_to_str", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "my_allennlp_trainer.Trainer._validation_loss", "allennlp.training.util.get_metrics", "my_allennlp_trainer.Trainer._metric_tracker.add_metric", "my_allennlp_trainer.Trainer._metric_tracker.is_best_so_far", "my_allennlp_trainer.Trainer._save_checkpoint", "param.detach().cpu", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "allennlp.training.util.get_metrics.items", "int", "allennlp.training.util.get_metrics.items", "str", "param.detach", "param.view", "callback.on_batch_end", "param.detach"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate.train", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.get_metrics", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate.train", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.batch_loss", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.rescale_gradients", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.get_metrics", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer._save_checkpoint", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer._validation_loss", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.get_metrics", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer._save_checkpoint", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.EstimateCallback.on_batch_end"], ["", "def", "_train_epoch", "(", "self", ",", "epoch", ":", "int", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"\"\"\n        Trains one epoch and returns metrics.\n        \"\"\"", "\n", "logger", ".", "info", "(", "\"Epoch %d/%d\"", ",", "epoch", ",", "self", ".", "_num_epochs", "-", "1", ")", "\n", "peak_cpu_usage", "=", "peak_memory_mb", "(", ")", "\n", "logger", ".", "info", "(", "f\"Peak CPU memory usage MB: {peak_cpu_usage}\"", ")", "\n", "gpu_usage", "=", "[", "]", "\n", "for", "gpu", ",", "memory", "in", "gpu_memory_mb", "(", ")", ".", "items", "(", ")", ":", "\n", "            ", "gpu_usage", ".", "append", "(", "(", "gpu", ",", "memory", ")", ")", "\n", "logger", ".", "info", "(", "f\"GPU {gpu} memory usage MB: {memory}\"", ")", "\n", "\n", "", "train_loss", "=", "0.0", "\n", "# Set the model to \"train\" mode.", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "num_gpus", "=", "len", "(", "self", ".", "_cuda_devices", ")", "\n", "\n", "# Get tqdm for the training batches", "\n", "raw_train_generator", "=", "self", ".", "iterator", "(", "self", ".", "train_data", ",", "\n", "num_epochs", "=", "1", ",", "\n", "shuffle", "=", "self", ".", "shuffle", ")", "\n", "train_generator", "=", "lazy_groups_of", "(", "raw_train_generator", ",", "num_gpus", ")", "\n", "num_training_batches", "=", "math", ".", "ceil", "(", "self", ".", "iterator", ".", "get_num_batches", "(", "self", ".", "train_data", ")", "/", "num_gpus", ")", "\n", "self", ".", "_last_log", "=", "time", ".", "time", "(", ")", "\n", "last_save_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "batches_this_epoch", "=", "0", "\n", "if", "self", ".", "_batch_num_total", "is", "None", ":", "\n", "            ", "self", ".", "_batch_num_total", "=", "0", "\n", "\n", "", "histogram_parameters", "=", "set", "(", "self", ".", "model", ".", "get_parameters_for_histogram_tensorboard_logging", "(", ")", ")", "\n", "\n", "\n", "logger", ".", "info", "(", "\"Training\"", ")", "\n", "train_generator_tqdm", "=", "Tqdm", ".", "tqdm", "(", "train_generator", ",", "\n", "total", "=", "num_training_batches", ")", "\n", "cumulative_batch_size", "=", "0", "\n", "for", "batch_group", "in", "train_generator_tqdm", ":", "\n", "            ", "self", ".", "model", ".", "train", "(", ")", "\n", "batches_this_epoch", "+=", "1", "\n", "self", ".", "_batch_num_total", "+=", "1", "\n", "batch_num_total", "=", "self", ".", "_batch_num_total", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "loss", "=", "self", ".", "batch_loss", "(", "batch_group", ",", "for_training", "=", "True", ")", "\n", "\n", "if", "torch", ".", "isnan", "(", "loss", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"nan loss encountered\"", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "batch_grad_norm", "=", "self", ".", "rescale_gradients", "(", ")", "\n", "\n", "# This does nothing if batch_num_total is None or you are using a", "\n", "# scheduler which doesn't update per batch.", "\n", "if", "self", ".", "_learning_rate_scheduler", ":", "\n", "                ", "self", ".", "_learning_rate_scheduler", ".", "step_batch", "(", "batch_num_total", ")", "\n", "", "if", "self", ".", "_momentum_scheduler", ":", "\n", "                ", "self", ".", "_momentum_scheduler", ".", "step_batch", "(", "batch_num_total", ")", "\n", "\n", "", "if", "self", ".", "_tensorboard", ".", "should_log_histograms_this_batch", "(", ")", ":", "\n", "# get the magnitude of parameter updates for logging", "\n", "# We need a copy of current parameters to compute magnitude of updates,", "\n", "# and copy them to CPU so large models won't go OOM on the GPU.", "\n", "                ", "param_updates", "=", "{", "name", ":", "param", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "clone", "(", ")", "\n", "for", "name", ",", "param", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "}", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "for", "name", ",", "param", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "param_updates", "[", "name", "]", ".", "sub_", "(", "param", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", "\n", "update_norm", "=", "torch", ".", "norm", "(", "param_updates", "[", "name", "]", ".", "view", "(", "-", "1", ",", ")", ")", "\n", "param_norm", "=", "torch", ".", "norm", "(", "param", ".", "view", "(", "-", "1", ",", ")", ")", ".", "cpu", "(", ")", "\n", "self", ".", "_tensorboard", ".", "add_train_scalar", "(", "\"gradient_update/\"", "+", "name", ",", "\n", "update_norm", "/", "(", "param_norm", "+", "1e-7", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Update moving averages", "\n", "", "if", "self", ".", "_moving_average", "is", "not", "None", ":", "\n", "                ", "self", ".", "_moving_average", ".", "apply", "(", "batch_num_total", ")", "\n", "\n", "# Update the description with the latest metrics", "\n", "", "metrics", "=", "training_util", ".", "get_metrics", "(", "self", ".", "model", ",", "train_loss", ",", "batches_this_epoch", ")", "\n", "description", "=", "training_util", ".", "description_from_metrics", "(", "metrics", ")", "\n", "\n", "train_generator_tqdm", ".", "set_description", "(", "description", ",", "refresh", "=", "False", ")", "\n", "\n", "# Log parameter values to Tensorboard", "\n", "if", "self", ".", "_tensorboard", ".", "should_log_this_batch", "(", ")", ":", "\n", "                ", "self", ".", "_tensorboard", ".", "log_parameter_and_gradient_statistics", "(", "self", ".", "model", ",", "batch_grad_norm", ")", "\n", "self", ".", "_tensorboard", ".", "log_learning_rates", "(", "self", ".", "model", ",", "self", ".", "optimizer", ")", "\n", "\n", "self", ".", "_tensorboard", ".", "add_train_scalar", "(", "\"loss/loss_train\"", ",", "metrics", "[", "\"loss\"", "]", ")", "\n", "self", ".", "_tensorboard", ".", "log_metrics", "(", "{", "\"epoch_metrics/\"", "+", "k", ":", "v", "for", "k", ",", "v", "in", "metrics", ".", "items", "(", ")", "}", ")", "\n", "\n", "", "if", "self", ".", "_tensorboard", ".", "should_log_histograms_this_batch", "(", ")", ":", "\n", "                ", "self", ".", "_tensorboard", ".", "log_histograms", "(", "self", ".", "model", ",", "histogram_parameters", ")", "\n", "\n", "", "if", "self", ".", "_log_batch_size_period", ":", "\n", "                ", "cur_batch", "=", "sum", "(", "[", "training_util", ".", "get_batch_size", "(", "batch", ")", "for", "batch", "in", "batch_group", "]", ")", "\n", "cumulative_batch_size", "+=", "cur_batch", "\n", "if", "(", "batches_this_epoch", "-", "1", ")", "%", "self", ".", "_log_batch_size_period", "==", "0", ":", "\n", "                    ", "average", "=", "cumulative_batch_size", "/", "batches_this_epoch", "\n", "logger", ".", "info", "(", "f\"current batch size: {cur_batch} mean batch size: {average}\"", ")", "\n", "self", ".", "_tensorboard", ".", "add_train_scalar", "(", "\"current_batch_size\"", ",", "cur_batch", ")", "\n", "self", ".", "_tensorboard", ".", "add_train_scalar", "(", "\"mean_batch_size\"", ",", "average", ")", "\n", "\n", "# Save model if needed.", "\n", "", "", "if", "self", ".", "_model_save_interval", "is", "not", "None", "and", "(", "\n", "time", ".", "time", "(", ")", "-", "last_save_time", ">", "self", ".", "_model_save_interval", "\n", ")", ":", "\n", "                ", "last_save_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "_save_checkpoint", "(", "\n", "'{0}.{1}'", ".", "format", "(", "epoch", ",", "training_util", ".", "time_to_str", "(", "int", "(", "last_save_time", ")", ")", ")", "\n", ")", "\n", "", "if", "self", ".", "_early_stopping_by_batch", "and", "self", ".", "_batch_num_total", "%", "10", "==", "0", ":", "\n", "                ", "if", "self", ".", "_validation_data", "is", "not", "None", ":", "\n", "                    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# We have a validation set, so compute all the metrics on it.", "\n", "                        ", "val_loss", ",", "num_batches", "=", "self", ".", "_validation_loss", "(", ")", "\n", "val_metrics", "=", "training_util", ".", "get_metrics", "(", "self", ".", "model", ",", "val_loss", ",", "num_batches", ",", "reset", "=", "True", ")", "\n", "\n", "# Check validation metric for early stopping", "\n", "this_epoch_val_metric", "=", "val_metrics", "[", "self", ".", "_validation_metric", "]", "\n", "self", ".", "_metric_tracker", ".", "add_metric", "(", "this_epoch_val_metric", ")", "\n", "\n", "if", "self", ".", "_metric_tracker", ".", "is_best_so_far", "(", ")", ":", "\n", "                            ", "metrics", "[", "'best_batch'", "]", "=", "self", ".", "_batch_num_total", "\n", "for", "key", ",", "value", "in", "val_metrics", ".", "items", "(", ")", ":", "\n", "                                ", "metrics", "[", "\"best_validation_\"", "+", "key", "]", "=", "value", "\n", "", "self", ".", "_metric_tracker", ".", "best_epoch_metrics", "=", "val_metrics", "\n", "\n", "", "self", ".", "_save_checkpoint", "(", "self", ".", "_batch_num_total", ")", "\n", "\n", "if", "self", ".", "callbacks", "is", "not", "None", ":", "\n", "                            ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "                                ", "callback", ".", "on_batch_end", "(", "self", ".", "_batch_num_total", ")", "\n", "\n", "", "", "", "", "", "", "metrics", "=", "training_util", ".", "get_metrics", "(", "self", ".", "model", ",", "train_loss", ",", "batches_this_epoch", ",", "reset", "=", "True", ")", "\n", "metrics", "[", "'cpu_memory_MB'", "]", "=", "peak_cpu_usage", "\n", "for", "(", "gpu_num", ",", "memory", ")", "in", "gpu_usage", ":", "\n", "            ", "metrics", "[", "'gpu_'", "+", "str", "(", "gpu_num", ")", "+", "'_memory_MB'", "]", "=", "memory", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer.Trainer._validation_loss": [[437, 487], ["logger.info", "my_allennlp_trainer.Trainer.model.eval", "len", "val_iterator", "allennlp.common.util.lazy_groups_of", "math.ceil", "allennlp.common.tqdm.Tqdm.tqdm", "my_allennlp_trainer.Trainer._moving_average.assign_average_value", "my_allennlp_trainer.Trainer.batch_loss", "allennlp.training.util.get_metrics", "allennlp.training.util.description_from_metrics", "allennlp.common.tqdm.Tqdm.tqdm.set_description", "my_allennlp_trainer.Trainer._moving_average.restore", "val_iterator.get_num_batches", "my_allennlp_trainer.Trainer.detach().cpu().numpy", "my_allennlp_trainer.Trainer.detach().cpu", "my_allennlp_trainer.Trainer.detach"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.batch_loss", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.get_metrics"], ["", "def", "_validation_loss", "(", "self", ")", "->", "Tuple", "[", "float", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Computes the validation loss. Returns it and the number of batches.\n        \"\"\"", "\n", "logger", ".", "info", "(", "\"Validating\"", ")", "\n", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "# Replace parameter values with the shadow values from the moving averages.", "\n", "if", "self", ".", "_moving_average", "is", "not", "None", ":", "\n", "            ", "self", ".", "_moving_average", ".", "assign_average_value", "(", ")", "\n", "\n", "", "if", "self", ".", "_validation_iterator", "is", "not", "None", ":", "\n", "            ", "val_iterator", "=", "self", ".", "_validation_iterator", "\n", "", "else", ":", "\n", "            ", "val_iterator", "=", "self", ".", "iterator", "\n", "\n", "", "num_gpus", "=", "len", "(", "self", ".", "_cuda_devices", ")", "\n", "\n", "raw_val_generator", "=", "val_iterator", "(", "self", ".", "_validation_data", ",", "\n", "num_epochs", "=", "1", ",", "\n", "shuffle", "=", "False", ")", "\n", "val_generator", "=", "lazy_groups_of", "(", "raw_val_generator", ",", "num_gpus", ")", "\n", "num_validation_batches", "=", "math", ".", "ceil", "(", "val_iterator", ".", "get_num_batches", "(", "self", ".", "_validation_data", ")", "/", "num_gpus", ")", "\n", "val_generator_tqdm", "=", "Tqdm", ".", "tqdm", "(", "val_generator", ",", "\n", "total", "=", "num_validation_batches", ")", "\n", "batches_this_epoch", "=", "0", "\n", "val_loss", "=", "0", "\n", "for", "batch_group", "in", "val_generator_tqdm", ":", "\n", "\n", "            ", "loss", "=", "self", ".", "batch_loss", "(", "batch_group", ",", "for_training", "=", "False", ")", "\n", "if", "loss", "is", "not", "None", ":", "\n", "# You shouldn't necessarily have to compute a loss for validation, so we allow for", "\n", "# `loss` to be None.  We need to be careful, though - `batches_this_epoch` is", "\n", "# currently only used as the divisor for the loss function, so we can safely only", "\n", "# count those batches for which we actually have a loss.  If this variable ever", "\n", "# gets used for something else, we might need to change things around a bit.", "\n", "                ", "batches_this_epoch", "+=", "1", "\n", "val_loss", "+=", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Update the description with the latest metrics", "\n", "", "val_metrics", "=", "training_util", ".", "get_metrics", "(", "self", ".", "model", ",", "val_loss", ",", "batches_this_epoch", ")", "\n", "description", "=", "training_util", ".", "description_from_metrics", "(", "val_metrics", ")", "\n", "val_generator_tqdm", ".", "set_description", "(", "description", ",", "refresh", "=", "False", ")", "\n", "\n", "# Now restore the original parameter values.", "\n", "", "if", "self", ".", "_moving_average", "is", "not", "None", ":", "\n", "            ", "self", ".", "_moving_average", ".", "restore", "(", ")", "\n", "\n", "", "return", "val_loss", ",", "batches_this_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer.Trainer.train": [[488, 626], ["allennlp.training.util.enable_gradient_clipping", "logger.info", "time.time", "my_allennlp_trainer.Trainer._metric_tracker.best_epoch_metrics.items", "range", "my_allennlp_trainer.Trainer._checkpointer.best_model_state", "my_allennlp_trainer.Trainer._restore_checkpoint", "time.time", "my_allennlp_trainer.Trainer._train_epoch", "logger.info", "my_allennlp_trainer.Trainer.model.load_state_dict", "traceback.print_exc", "allennlp.common.checks.ConfigurationError", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "my_allennlp_trainer.Trainer.items", "my_allennlp_trainer.Trainer._tensorboard.log_metrics", "str", "my_allennlp_trainer.Trainer.items", "val_metrics.items", "my_allennlp_trainer.Trainer._metric_tracker.is_best_so_far", "my_allennlp_trainer.Trainer._save_checkpoint", "my_allennlp_trainer.Trainer._metric_tracker.should_stop_early", "time.time", "datetime.timedelta", "str", "logger.info", "callback.on_train_begin", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "max", "key.startswith", "time.time", "datetime.timedelta", "val_metrics.items", "allennlp.common.util.dump_metrics", "my_allennlp_trainer.Trainer._learning_rate_scheduler.step", "my_allennlp_trainer.Trainer._momentum_scheduler.step", "logger.info", "time.time", "datetime.timedelta", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "callback.on_epoch_begin", "metrics.get", "max", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "my_allennlp_trainer.Trainer._estimator.estimate", "my_allennlp_trainer.Trainer._metric_tracker.add_metric", "my_allennlp_trainer.Trainer._metric_tracker.should_stop_early", "os.path.join", "callback.on_epoch_end", "metrics.get", "logger.info", "float", "int"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer._restore_checkpoint", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer._train_epoch", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer._save_checkpoint", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.FixedLossWeightCallback.on_train_begin", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.SetLossWeightCallback.on_epoch_begin", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.TextInAllAspectSentimentOutEstimatorAll.estimate", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.EstimateCallback.on_epoch_end"], ["", "def", "train", "(", "self", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Trains the supplied model with the supplied parameters.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "epoch_counter", "=", "self", ".", "_restore_checkpoint", "(", ")", "\n", "", "except", "RuntimeError", ":", "\n", "            ", "traceback", ".", "print_exc", "(", ")", "\n", "raise", "ConfigurationError", "(", "\"Could not recover training from the checkpoint.  Did you mean to output to \"", "\n", "\"a different serialization directory or delete the existing serialization \"", "\n", "\"directory?\"", ")", "\n", "\n", "", "training_util", ".", "enable_gradient_clipping", "(", "self", ".", "model", ",", "self", ".", "_grad_clipping", ")", "\n", "\n", "logger", ".", "info", "(", "\"Beginning training.\"", ")", "\n", "\n", "train_metrics", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "val_metrics", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "this_epoch_val_metric", ":", "float", "=", "None", "\n", "metrics", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "epochs_trained", "=", "0", "\n", "training_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "metrics", "[", "'best_epoch'", "]", "=", "self", ".", "_metric_tracker", ".", "best_epoch", "\n", "for", "key", ",", "value", "in", "self", ".", "_metric_tracker", ".", "best_epoch_metrics", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "\"best_validation_\"", "+", "key", "]", "=", "value", "\n", "\n", "", "if", "self", ".", "callbacks", "is", "not", "None", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "                    ", "callback", ".", "on_train_begin", "(", ")", "\n", "\n", "", "", "", "for", "epoch", "in", "range", "(", "epoch_counter", ",", "self", ".", "_num_epochs", ")", ":", "\n", "            ", "epoch_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "self", ".", "callbacks", "is", "not", "None", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "                        ", "callback", ".", "on_epoch_begin", "(", "epoch", ")", "\n", "\n", "", "", "", "train_metrics", "=", "self", ".", "_train_epoch", "(", "epoch", ")", "\n", "if", "not", "self", ".", "_early_stopping_by_batch", ":", "\n", "# get peak of memory usage", "\n", "                ", "if", "'cpu_memory_MB'", "in", "train_metrics", ":", "\n", "                    ", "metrics", "[", "'peak_cpu_memory_MB'", "]", "=", "max", "(", "metrics", ".", "get", "(", "'peak_cpu_memory_MB'", ",", "0", ")", ",", "\n", "train_metrics", "[", "'cpu_memory_MB'", "]", ")", "\n", "", "for", "key", ",", "value", "in", "train_metrics", ".", "items", "(", ")", ":", "\n", "                    ", "if", "key", ".", "startswith", "(", "'gpu_'", ")", ":", "\n", "                        ", "metrics", "[", "\"peak_\"", "+", "key", "]", "=", "max", "(", "metrics", ".", "get", "(", "\"peak_\"", "+", "key", ",", "0", ")", ",", "value", ")", "\n", "\n", "", "", "if", "self", ".", "_validation_data", "is", "not", "None", ":", "\n", "                    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                        ", "val_metrics_temp", "=", "self", ".", "_estimator", ".", "estimate", "(", "self", ".", "_validation_data", ")", "\n", "# We have a validation set, so compute all the metrics on it.", "\n", "# val_loss, num_batches = self._validation_loss()", "\n", "# val_metrics = training_util.get_metrics(self.model, val_loss, num_batches, reset=True)", "\n", "val_metrics", "=", "{", "'loss'", ":", "0", "}", "\n", "if", "'sentiment_acc'", "in", "val_metrics_temp", ":", "\n", "                            ", "val_metrics", "[", "'accuracy'", "]", "=", "val_metrics_temp", "[", "'sentiment_acc'", "]", "\n", "", "if", "'category_f1'", "in", "val_metrics_temp", ":", "\n", "                            ", "val_metrics", "[", "'category_f1'", "]", "=", "val_metrics_temp", "[", "'category_f1'", "]", "[", "'fscore'", "]", "\n", "", "if", "'other_metrics'", "in", "val_metrics_temp", "and", "'merge_micro_f1'", "in", "val_metrics_temp", "[", "'other_metrics'", "]", ":", "\n", "                            ", "val_metrics", "[", "'merge_micro_f1'", "]", "=", "val_metrics_temp", "[", "'other_metrics'", "]", "[", "'merge_micro_f1'", "]", "\n", "# Check validation metric for early stopping", "\n", "", "this_epoch_val_metric", "=", "val_metrics", "[", "self", ".", "_validation_metric", "]", "\n", "self", ".", "_metric_tracker", ".", "add_metric", "(", "this_epoch_val_metric", ")", "\n", "\n", "if", "self", ".", "_metric_tracker", ".", "should_stop_early", "(", ")", ":", "\n", "                            ", "logger", ".", "info", "(", "\"Ran out of patience.  Stopping training.\"", ")", "\n", "break", "\n", "\n", "", "", "", "self", ".", "_tensorboard", ".", "log_metrics", "(", "train_metrics", ",", "\n", "val_metrics", "=", "val_metrics", ",", "\n", "log_to_console", "=", "True", ",", "\n", "epoch", "=", "epoch", "+", "1", ")", "# +1 because tensorboard doesn't like 0", "\n", "\n", "# Create overall metrics dict", "\n", "training_elapsed_time", "=", "time", ".", "time", "(", ")", "-", "training_start_time", "\n", "metrics", "[", "\"training_duration\"", "]", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "training_elapsed_time", ")", ")", "\n", "metrics", "[", "\"training_start_epoch\"", "]", "=", "epoch_counter", "\n", "metrics", "[", "\"training_epochs\"", "]", "=", "epochs_trained", "\n", "metrics", "[", "\"epoch\"", "]", "=", "epoch", "\n", "\n", "for", "key", ",", "value", "in", "train_metrics", ".", "items", "(", ")", ":", "\n", "                    ", "metrics", "[", "\"training_\"", "+", "key", "]", "=", "value", "\n", "", "for", "key", ",", "value", "in", "val_metrics", ".", "items", "(", ")", ":", "\n", "                    ", "metrics", "[", "\"validation_\"", "+", "key", "]", "=", "value", "\n", "\n", "", "if", "self", ".", "_metric_tracker", ".", "is_best_so_far", "(", ")", ":", "\n", "# Update all the best_ metrics.", "\n", "# (Otherwise they just stay the same as they were.)", "\n", "                    ", "metrics", "[", "'best_epoch'", "]", "=", "epoch", "\n", "for", "key", ",", "value", "in", "val_metrics", ".", "items", "(", ")", ":", "\n", "                        ", "metrics", "[", "\"best_validation_\"", "+", "key", "]", "=", "value", "\n", "\n", "", "self", ".", "_metric_tracker", ".", "best_epoch_metrics", "=", "val_metrics", "\n", "\n", "", "if", "self", ".", "_serialization_dir", ":", "\n", "                    ", "dump_metrics", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_serialization_dir", ",", "f'metrics_epoch_{epoch}.json'", ")", ",", "metrics", ")", "\n", "\n", "# The Scheduler API is agnostic to whether your schedule requires a validation metric -", "\n", "# if it doesn't, the validation metric passed here is ignored.", "\n", "", "if", "self", ".", "_learning_rate_scheduler", ":", "\n", "                    ", "self", ".", "_learning_rate_scheduler", ".", "step", "(", "this_epoch_val_metric", ",", "epoch", ")", "\n", "", "if", "self", ".", "_momentum_scheduler", ":", "\n", "                    ", "self", ".", "_momentum_scheduler", ".", "step", "(", "this_epoch_val_metric", ",", "epoch", ")", "\n", "\n", "", "self", ".", "_save_checkpoint", "(", "epoch", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "_metric_tracker", ".", "should_stop_early", "(", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Ran out of patience.  Stopping training.\"", ")", "\n", "break", "\n", "\n", "", "", "epoch_elapsed_time", "=", "time", ".", "time", "(", ")", "-", "epoch_start_time", "\n", "logger", ".", "info", "(", "\"Epoch duration: %s\"", ",", "datetime", ".", "timedelta", "(", "seconds", "=", "epoch_elapsed_time", ")", ")", "\n", "\n", "if", "epoch", "<", "self", ".", "_num_epochs", "-", "1", ":", "\n", "                ", "training_elapsed_time", "=", "time", ".", "time", "(", ")", "-", "training_start_time", "\n", "estimated_time_remaining", "=", "training_elapsed_time", "*", "(", "(", "self", ".", "_num_epochs", "-", "epoch_counter", ")", "/", "float", "(", "epoch", "-", "epoch_counter", "+", "1", ")", "-", "1", ")", "\n", "formatted_time", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "estimated_time_remaining", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Estimated training time remaining: %s\"", ",", "formatted_time", ")", "\n", "\n", "", "if", "self", ".", "callbacks", "is", "not", "None", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "                        ", "callback", ".", "on_epoch_end", "(", "epoch", ")", "\n", "", "", "", "epochs_trained", "+=", "1", "\n", "\n", "# make sure pending events are flushed to disk and files are closed properly", "\n", "# self._tensorboard.close()", "\n", "\n", "# Load the best model state before returning", "\n", "", "best_model_state", "=", "self", ".", "_checkpointer", ".", "best_model_state", "(", ")", "\n", "if", "best_model_state", ":", "\n", "            ", "self", ".", "model", ".", "load_state_dict", "(", "best_model_state", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer.Trainer._save_checkpoint": [[627, 665], ["my_allennlp_trainer.Trainer._checkpointer.save_checkpoint", "my_allennlp_trainer.Trainer._moving_average.assign_average_value", "my_allennlp_trainer.Trainer._metric_tracker.state_dict", "my_allennlp_trainer.Trainer.optimizer.state_dict", "my_allennlp_trainer.Trainer._learning_rate_scheduler.state_dict", "my_allennlp_trainer.Trainer._momentum_scheduler.state_dict", "my_allennlp_trainer.Trainer._moving_average.restore", "my_allennlp_trainer.Trainer.model.state_dict", "my_allennlp_trainer.Trainer._metric_tracker.is_best_so_far"], "methods", ["None"], ["", "def", "_save_checkpoint", "(", "self", ",", "epoch", ":", "Union", "[", "int", ",", "str", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Saves a checkpoint of the model to self._serialization_dir.\n        Is a no-op if self._serialization_dir is None.\n\n        Parameters\n        ----------\n        epoch : Union[int, str], required.\n            The epoch of training.  If the checkpoint is saved in the middle\n            of an epoch, the parameter is a string with the epoch and timestamp.\n        \"\"\"", "\n", "# If moving averages are used for parameters, we save", "\n", "# the moving average values into checkpoint, instead of the current values.", "\n", "if", "self", ".", "_moving_average", "is", "not", "None", ":", "\n", "            ", "self", ".", "_moving_average", ".", "assign_average_value", "(", ")", "\n", "\n", "# These are the training states we need to persist.", "\n", "", "training_states", "=", "{", "\n", "\"metric_tracker\"", ":", "self", ".", "_metric_tracker", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer\"", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"batch_num_total\"", ":", "self", ".", "_batch_num_total", "\n", "}", "\n", "\n", "# If we have a learning rate or momentum scheduler, we should persist them too.", "\n", "if", "self", ".", "_learning_rate_scheduler", "is", "not", "None", ":", "\n", "            ", "training_states", "[", "\"learning_rate_scheduler\"", "]", "=", "self", ".", "_learning_rate_scheduler", ".", "state_dict", "(", ")", "\n", "", "if", "self", ".", "_momentum_scheduler", "is", "not", "None", ":", "\n", "            ", "training_states", "[", "\"momentum_scheduler\"", "]", "=", "self", ".", "_momentum_scheduler", ".", "state_dict", "(", ")", "\n", "\n", "", "self", ".", "_checkpointer", ".", "save_checkpoint", "(", "\n", "model_state", "=", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "epoch", "=", "epoch", ",", "\n", "training_states", "=", "training_states", ",", "\n", "is_best_so_far", "=", "self", ".", "_metric_tracker", ".", "is_best_so_far", "(", ")", ")", "\n", "\n", "# Restore the original values for parameters so that training will not be affected.", "\n", "if", "self", ".", "_moving_average", "is", "not", "None", ":", "\n", "            ", "self", ".", "_moving_average", ".", "restore", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer.Trainer._restore_checkpoint": [[666, 721], ["my_allennlp_trainer.Trainer._checkpointer.restore_checkpoint", "my_allennlp_trainer.Trainer.model.load_state_dict", "my_allennlp_trainer.Trainer.optimizer.load_state_dict", "allennlp.training.util.move_optimizer_to_cuda", "isinstance", "training_state.get", "my_allennlp_trainer.Trainer._learning_rate_scheduler.load_state_dict", "my_allennlp_trainer.Trainer._momentum_scheduler.load_state_dict", "my_allennlp_trainer.Trainer._metric_tracker.load_state_dict", "my_allennlp_trainer.Trainer._metric_tracker.clear", "my_allennlp_trainer.Trainer._metric_tracker.add_metrics", "my_allennlp_trainer.Trainer._metric_tracker.clear", "int", "training_state[].split"], "methods", ["None"], ["", "", "def", "_restore_checkpoint", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Restores the model and training state from the last saved checkpoint.\n        This includes an epoch count and optimizer state, which is serialized separately\n        from model parameters. This function should only be used to continue training -\n        if you wish to load a model for inference/load parts of a model into a new\n        computation graph, you should use the native Pytorch functions:\n        `` model.load_state_dict(torch.load(\"/path/to/model/weights.th\"))``\n\n        If ``self._serialization_dir`` does not exist or does not contain any checkpointed weights,\n        this function will do nothing and return 0.\n\n        Returns\n        -------\n        epoch: int\n            The epoch at which to resume training, which should be one after the epoch\n            in the saved training state.\n        \"\"\"", "\n", "model_state", ",", "training_state", "=", "self", ".", "_checkpointer", ".", "restore_checkpoint", "(", ")", "\n", "\n", "if", "not", "training_state", ":", "\n", "# No checkpoint to restore, start at 0", "\n", "            ", "return", "0", "\n", "\n", "", "self", ".", "model", ".", "load_state_dict", "(", "model_state", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "training_state", "[", "\"optimizer\"", "]", ")", "\n", "if", "self", ".", "_learning_rate_scheduler", "is", "not", "None", "and", "\"learning_rate_scheduler\"", "in", "training_state", ":", "\n", "            ", "self", ".", "_learning_rate_scheduler", ".", "load_state_dict", "(", "training_state", "[", "\"learning_rate_scheduler\"", "]", ")", "\n", "", "if", "self", ".", "_momentum_scheduler", "is", "not", "None", "and", "\"momentum_scheduler\"", "in", "training_state", ":", "\n", "            ", "self", ".", "_momentum_scheduler", ".", "load_state_dict", "(", "training_state", "[", "\"momentum_scheduler\"", "]", ")", "\n", "", "training_util", ".", "move_optimizer_to_cuda", "(", "self", ".", "optimizer", ")", "\n", "\n", "# Currently the ``training_state`` contains a serialized ``MetricTracker``.", "\n", "if", "\"metric_tracker\"", "in", "training_state", ":", "\n", "            ", "self", ".", "_metric_tracker", ".", "load_state_dict", "(", "training_state", "[", "\"metric_tracker\"", "]", ")", "\n", "# It used to be the case that we tracked ``val_metric_per_epoch``.", "\n", "", "elif", "\"val_metric_per_epoch\"", "in", "training_state", ":", "\n", "            ", "self", ".", "_metric_tracker", ".", "clear", "(", ")", "\n", "self", ".", "_metric_tracker", ".", "add_metrics", "(", "training_state", "[", "\"val_metric_per_epoch\"", "]", ")", "\n", "# And before that we didn't track anything.", "\n", "", "else", ":", "\n", "            ", "self", ".", "_metric_tracker", ".", "clear", "(", ")", "\n", "\n", "", "if", "isinstance", "(", "training_state", "[", "\"epoch\"", "]", ",", "int", ")", ":", "\n", "            ", "epoch_to_return", "=", "training_state", "[", "\"epoch\"", "]", "+", "1", "\n", "", "else", ":", "\n", "            ", "epoch_to_return", "=", "int", "(", "training_state", "[", "\"epoch\"", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "+", "1", "\n", "\n", "# For older checkpoints with batch_num_total missing, default to old behavior where", "\n", "# it is unchanged.", "\n", "", "batch_num_total", "=", "training_state", ".", "get", "(", "'batch_num_total'", ")", "\n", "if", "batch_num_total", "is", "not", "None", ":", "\n", "            ", "self", ".", "_batch_num_total", "=", "batch_num_total", "\n", "\n", "", "return", "epoch_to_return", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer.Trainer.from_params": [[723, 813], ["params.pop_int", "params.pop", "params.pop_bool", "params.pop_int", "allennlp.common.checks.parse_cuda_device", "params.pop_float", "params.pop_float", "params.pop", "params.pop", "isinstance", "allennlp.training.optimizers.Optimizer.from_params", "params.pop_float", "params.pop_int", "params.pop_int", "params.pop_bool", "params.pop_bool", "params.pop_int", "params.assert_empty", "cls", "params.pop", "model.cuda.cuda.cuda", "params.pop", "allennlp.training.moving_average.MovingAverage.from_params", "allennlp.training.learning_rate_schedulers.LearningRateScheduler.from_params", "allennlp.training.momentum_schedulers.MomentumScheduler.from_params", "allennlp.training.checkpointer.Checkpointer.from_params", "params.pop_int", "params.pop_int", "allennlp.training.checkpointer.Checkpointer", "model.cuda.cuda.named_parameters", "params.pop", "allennlp.common.checks.ConfigurationError", "params.pop"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.from_params", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.from_params", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.from_params", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.from_params", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.from_params"], ["", "@", "classmethod", "\n", "def", "from_params", "(", "cls", ",", "# type: ignore", "\n", "model", ":", "Model", ",", "\n", "serialization_dir", ":", "str", ",", "\n", "iterator", ":", "DataIterator", ",", "\n", "train_data", ":", "Iterable", "[", "Instance", "]", ",", "\n", "validation_data", ":", "Optional", "[", "Iterable", "[", "Instance", "]", "]", ",", "\n", "params", ":", "Params", ",", "\n", "validation_iterator", ":", "DataIterator", "=", "None", ")", "->", "'Trainer'", ":", "\n", "# pylint: disable=arguments-differ", "\n", "        ", "patience", "=", "params", ".", "pop_int", "(", "\"patience\"", ",", "None", ")", "\n", "validation_metric", "=", "params", ".", "pop", "(", "\"validation_metric\"", ",", "\"-loss\"", ")", "\n", "shuffle", "=", "params", ".", "pop_bool", "(", "\"shuffle\"", ",", "True", ")", "\n", "num_epochs", "=", "params", ".", "pop_int", "(", "\"num_epochs\"", ",", "20", ")", "\n", "cuda_device", "=", "parse_cuda_device", "(", "params", ".", "pop", "(", "\"cuda_device\"", ",", "-", "1", ")", ")", "\n", "grad_norm", "=", "params", ".", "pop_float", "(", "\"grad_norm\"", ",", "None", ")", "\n", "grad_clipping", "=", "params", ".", "pop_float", "(", "\"grad_clipping\"", ",", "None", ")", "\n", "lr_scheduler_params", "=", "params", ".", "pop", "(", "\"learning_rate_scheduler\"", ",", "None", ")", "\n", "momentum_scheduler_params", "=", "params", ".", "pop", "(", "\"momentum_scheduler\"", ",", "None", ")", "\n", "\n", "if", "isinstance", "(", "cuda_device", ",", "list", ")", ":", "\n", "            ", "model_device", "=", "cuda_device", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "model_device", "=", "cuda_device", "\n", "", "if", "model_device", ">=", "0", ":", "\n", "# Moving model to GPU here so that the optimizer state gets constructed on", "\n", "# the right device.", "\n", "            ", "model", "=", "model", ".", "cuda", "(", "model_device", ")", "\n", "\n", "", "parameters", "=", "[", "[", "n", ",", "p", "]", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "optimizer", "=", "Optimizer", ".", "from_params", "(", "parameters", ",", "params", ".", "pop", "(", "\"optimizer\"", ")", ")", "\n", "if", "\"moving_average\"", "in", "params", ":", "\n", "            ", "moving_average", "=", "MovingAverage", ".", "from_params", "(", "params", ".", "pop", "(", "\"moving_average\"", ")", ",", "parameters", "=", "parameters", ")", "\n", "", "else", ":", "\n", "            ", "moving_average", "=", "None", "\n", "\n", "", "if", "lr_scheduler_params", ":", "\n", "            ", "lr_scheduler", "=", "LearningRateScheduler", ".", "from_params", "(", "optimizer", ",", "lr_scheduler_params", ")", "\n", "", "else", ":", "\n", "            ", "lr_scheduler", "=", "None", "\n", "", "if", "momentum_scheduler_params", ":", "\n", "            ", "momentum_scheduler", "=", "MomentumScheduler", ".", "from_params", "(", "optimizer", ",", "momentum_scheduler_params", ")", "\n", "", "else", ":", "\n", "            ", "momentum_scheduler", "=", "None", "\n", "\n", "", "if", "'checkpointer'", "in", "params", ":", "\n", "            ", "if", "'keep_serialized_model_every_num_seconds'", "in", "params", "or", "'num_serialized_models_to_keep'", "in", "params", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\n", "\"Checkpointer may be initialized either from the 'checkpointer' key or from the \"", "\n", "\"keys 'num_serialized_models_to_keep' and 'keep_serialized_model_every_num_seconds'\"", "\n", "\" but the passed config uses both methods.\"", ")", "\n", "", "checkpointer", "=", "Checkpointer", ".", "from_params", "(", "params", ".", "pop", "(", "\"checkpointer\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "num_serialized_models_to_keep", "=", "params", ".", "pop_int", "(", "\"num_serialized_models_to_keep\"", ",", "20", ")", "\n", "keep_serialized_model_every_num_seconds", "=", "params", ".", "pop_int", "(", "\n", "\"keep_serialized_model_every_num_seconds\"", ",", "None", ")", "\n", "checkpointer", "=", "Checkpointer", "(", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "num_serialized_models_to_keep", "=", "num_serialized_models_to_keep", ",", "\n", "keep_serialized_model_every_num_seconds", "=", "keep_serialized_model_every_num_seconds", ")", "\n", "", "model_save_interval", "=", "params", ".", "pop_float", "(", "\"model_save_interval\"", ",", "None", ")", "\n", "summary_interval", "=", "params", ".", "pop_int", "(", "\"summary_interval\"", ",", "100", ")", "\n", "histogram_interval", "=", "params", ".", "pop_int", "(", "\"histogram_interval\"", ",", "None", ")", "\n", "should_log_parameter_statistics", "=", "params", ".", "pop_bool", "(", "\"should_log_parameter_statistics\"", ",", "True", ")", "\n", "should_log_learning_rate", "=", "params", ".", "pop_bool", "(", "\"should_log_learning_rate\"", ",", "False", ")", "\n", "log_batch_size_period", "=", "params", ".", "pop_int", "(", "\"log_batch_size_period\"", ",", "None", ")", "\n", "\n", "params", ".", "assert_empty", "(", "cls", ".", "__name__", ")", "\n", "return", "cls", "(", "model", ",", "optimizer", ",", "iterator", ",", "\n", "train_data", ",", "validation_data", ",", "\n", "patience", "=", "patience", ",", "\n", "validation_metric", "=", "validation_metric", ",", "\n", "validation_iterator", "=", "validation_iterator", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "num_epochs", "=", "num_epochs", ",", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "cuda_device", "=", "cuda_device", ",", "\n", "grad_norm", "=", "grad_norm", ",", "\n", "grad_clipping", "=", "grad_clipping", ",", "\n", "learning_rate_scheduler", "=", "lr_scheduler", ",", "\n", "momentum_scheduler", "=", "momentum_scheduler", ",", "\n", "checkpointer", "=", "checkpointer", ",", "\n", "model_save_interval", "=", "model_save_interval", ",", "\n", "summary_interval", "=", "summary_interval", ",", "\n", "histogram_interval", "=", "histogram_interval", ",", "\n", "should_log_parameter_statistics", "=", "should_log_parameter_statistics", ",", "\n", "should_log_learning_rate", "=", "should_log_learning_rate", ",", "\n", "log_batch_size_period", "=", "log_batch_size_period", ",", "\n", "moving_average", "=", "moving_average", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.__init__": [[43, 255], ["allennlp.training.trainer_base.TrainerBase.__init__", "allennlp.training.metric_tracker.MetricTracker", "allennlp.training.tensorboard_writer.TensorboardWriter", "allennlp.training.checkpointer.Checkpointer", "my_allennlp_trainer_epoch.Trainer._tensorboard.enable_activation_logging", "logger.warning", "allennlp.common.checks.ConfigurationError", "allennlp.common.checks.ConfigurationError", "isinstance"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ":", "Model", ",", "\n", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "iterator", ":", "DataIterator", ",", "\n", "train_dataset", ":", "Iterable", "[", "Instance", "]", ",", "\n", "validation_dataset", ":", "Optional", "[", "Iterable", "[", "Instance", "]", "]", "=", "None", ",", "\n", "patience", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "validation_metric", ":", "str", "=", "\"-loss\"", ",", "\n", "validation_iterator", ":", "DataIterator", "=", "None", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "num_epochs", ":", "int", "=", "20", ",", "\n", "serialization_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "num_serialized_models_to_keep", ":", "int", "=", "20", ",", "\n", "keep_serialized_model_every_num_seconds", ":", "int", "=", "None", ",", "\n", "checkpointer", ":", "Checkpointer", "=", "None", ",", "\n", "model_save_interval", ":", "float", "=", "None", ",", "\n", "cuda_device", ":", "Union", "[", "int", ",", "List", "]", "=", "-", "1", ",", "\n", "grad_norm", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "grad_clipping", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "learning_rate_scheduler", ":", "Optional", "[", "LearningRateScheduler", "]", "=", "None", ",", "\n", "momentum_scheduler", ":", "Optional", "[", "MomentumScheduler", "]", "=", "None", ",", "\n", "summary_interval", ":", "int", "=", "100", ",", "\n", "histogram_interval", ":", "int", "=", "None", ",", "\n", "should_log_parameter_statistics", ":", "bool", "=", "True", ",", "\n", "should_log_learning_rate", ":", "bool", "=", "False", ",", "\n", "log_batch_size_period", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "moving_average", ":", "Optional", "[", "MovingAverage", "]", "=", "None", ",", "\n", "callbacks", ":", "List", "[", "allennlp_callback", ".", "Callback", "]", "=", "None", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        A trainer for doing supervised learning. It just takes a labeled dataset\n        and a ``DataIterator``, and uses the supplied ``Optimizer`` to learn the weights\n        for your model over some fixed number of epochs. You can also pass in a validation\n        dataset and enable early stopping. There are many other bells and whistles as well.\n\n        Parameters\n        ----------\n        model : ``Model``, required.\n            An AllenNLP model to be optimized. Pytorch Modules can also be optimized if\n            their ``forward`` method returns a dictionary with a \"loss\" key, containing a\n            scalar tensor representing the loss function to be optimized.\n\n            If you are training your model using GPUs, your model should already be\n            on the correct device. (If you use `Trainer.from_params` this will be\n            handled for you.)\n        optimizer : ``torch.nn.Optimizer``, required.\n            An instance of a Pytorch Optimizer, instantiated with the parameters of the\n            model to be optimized.\n        iterator : ``DataIterator``, required.\n            A method for iterating over a ``Dataset``, yielding padded indexed batches.\n        train_dataset : ``Dataset``, required.\n            A ``Dataset`` to train on. The dataset should have already been indexed.\n        validation_dataset : ``Dataset``, optional, (default = None).\n            A ``Dataset`` to evaluate on. The dataset should have already been indexed.\n        patience : Optional[int] > 0, optional (default=None)\n            Number of epochs to be patient before early stopping: the training is stopped\n            after ``patience`` epochs with no improvement. If given, it must be ``> 0``.\n            If None, early stopping is disabled.\n        validation_metric : str, optional (default=\"loss\")\n            Validation metric to measure for whether to stop training using patience\n            and whether to serialize an ``is_best`` model each epoch. The metric name\n            must be prepended with either \"+\" or \"-\", which specifies whether the metric\n            is an increasing or decreasing function.\n        validation_iterator : ``DataIterator``, optional (default=None)\n            An iterator to use for the validation set.  If ``None``, then\n            use the training `iterator`.\n        shuffle: ``bool``, optional (default=True)\n            Whether to shuffle the instances in the iterator or not.\n        num_epochs : int, optional (default = 20)\n            Number of training epochs.\n        serialization_dir : str, optional (default=None)\n            Path to directory for saving and loading model files. Models will not be saved if\n            this parameter is not passed.\n        num_serialized_models_to_keep : ``int``, optional (default=20)\n            Number of previous model checkpoints to retain.  Default is to keep 20 checkpoints.\n            A value of None or -1 means all checkpoints will be kept.\n        keep_serialized_model_every_num_seconds : ``int``, optional (default=None)\n            If num_serialized_models_to_keep is not None, then occasionally it's useful to\n            save models at a given interval in addition to the last num_serialized_models_to_keep.\n            To do so, specify keep_serialized_model_every_num_seconds as the number of seconds\n            between permanently saved checkpoints.  Note that this option is only used if\n            num_serialized_models_to_keep is not None, otherwise all checkpoints are kept.\n        checkpointer : ``Checkpointer``, optional (default=None)\n            An instance of class Checkpointer to use instead of the default. If a checkpointer is specified,\n            the arguments num_serialized_models_to_keep and keep_serialized_model_every_num_seconds should\n            not be specified. The caller is responsible for initializing the checkpointer so that it is\n            consistent with serialization_dir.\n        model_save_interval : ``float``, optional (default=None)\n            If provided, then serialize models every ``model_save_interval``\n            seconds within single epochs.  In all cases, models are also saved\n            at the end of every epoch if ``serialization_dir`` is provided.\n        cuda_device : ``Union[int, List[int]]``, optional (default = -1)\n            An integer or list of integers specifying the CUDA device(s) to use. If -1, the CPU is used.\n        grad_norm : ``float``, optional, (default = None).\n            If provided, gradient norms will be rescaled to have a maximum of this value.\n        grad_clipping : ``float``, optional (default = ``None``).\n            If provided, gradients will be clipped `during the backward pass` to have an (absolute)\n            maximum of this value.  If you are getting ``NaNs`` in your gradients during training\n            that are not solved by using ``grad_norm``, you may need this.\n        learning_rate_scheduler : ``LearningRateScheduler``, optional (default = None)\n            If specified, the learning rate will be decayed with respect to\n            this schedule at the end of each epoch (or batch, if the scheduler implements\n            the ``step_batch`` method). If you use :class:`torch.optim.lr_scheduler.ReduceLROnPlateau`,\n            this will use the ``validation_metric`` provided to determine if learning has plateaued.\n            To support updating the learning rate on every batch, this can optionally implement\n            ``step_batch(batch_num_total)`` which updates the learning rate given the batch number.\n        momentum_scheduler : ``MomentumScheduler``, optional (default = None)\n            If specified, the momentum will be updated at the end of each batch or epoch\n            according to the schedule.\n        summary_interval: ``int``, optional, (default = 100)\n            Number of batches between logging scalars to tensorboard\n        histogram_interval : ``int``, optional, (default = ``None``)\n            If not None, then log histograms to tensorboard every ``histogram_interval`` batches.\n            When this parameter is specified, the following additional logging is enabled:\n                * Histograms of model parameters\n                * The ratio of parameter update norm to parameter norm\n                * Histogram of layer activations\n            We log histograms of the parameters returned by\n            ``model.get_parameters_for_histogram_tensorboard_logging``.\n            The layer activations are logged for any modules in the ``Model`` that have\n            the attribute ``should_log_activations`` set to ``True``.  Logging\n            histograms requires a number of GPU-CPU copies during training and is typically\n            slow, so we recommend logging histograms relatively infrequently.\n            Note: only Modules that return tensors, tuples of tensors or dicts\n            with tensors as values currently support activation logging.\n        should_log_parameter_statistics : ``bool``, optional, (default = True)\n            Whether to send parameter statistics (mean and standard deviation\n            of parameters and gradients) to tensorboard.\n        should_log_learning_rate : ``bool``, optional, (default = False)\n            Whether to send parameter specific learning rate to tensorboard.\n        log_batch_size_period : ``int``, optional, (default = ``None``)\n            If defined, how often to log the average batch size.\n        moving_average: ``MovingAverage``, optional, (default = None)\n            If provided, we will maintain moving averages for all parameters. During training, we\n            employ a shadow variable for each parameter, which maintains the moving average. During\n            evaluation, we backup the original parameters and assign the moving averages to corresponding\n            parameters. Be careful that when saving the checkpoint, we will save the moving averages of\n            parameters. This is necessary because we want the saved model to perform as well as the validated\n            model if we load it later. But this may cause problems if you restart the training from checkpoint.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "serialization_dir", ",", "cuda_device", ")", "\n", "\n", "# I am not calling move_to_gpu here, because if the model is", "\n", "# not already on the GPU then the optimizer is going to be wrong.", "\n", "self", ".", "model", "=", "model", "\n", "\n", "self", ".", "iterator", "=", "iterator", "\n", "self", ".", "_validation_iterator", "=", "validation_iterator", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "train_data", "=", "train_dataset", "\n", "self", ".", "_validation_data", "=", "validation_dataset", "\n", "\n", "if", "patience", "is", "None", ":", "# no early stopping", "\n", "            ", "if", "validation_dataset", ":", "\n", "                ", "logger", ".", "warning", "(", "'You provided a validation dataset but patience was set to None, '", "\n", "'meaning that early stopping is disabled'", ")", "\n", "", "", "elif", "(", "not", "isinstance", "(", "patience", ",", "int", ")", ")", "or", "patience", "<=", "0", ":", "\n", "            ", "raise", "ConfigurationError", "(", "'{} is an invalid value for \"patience\": it must be a positive integer '", "\n", "'or None (if you want to disable early stopping)'", ".", "format", "(", "patience", ")", ")", "\n", "\n", "# For tracking is_best_so_far and should_stop_early", "\n", "", "self", ".", "_metric_tracker", "=", "MetricTracker", "(", "patience", ",", "validation_metric", ")", "\n", "# Get rid of + or -", "\n", "self", ".", "_validation_metric", "=", "validation_metric", "[", "1", ":", "]", "\n", "\n", "self", ".", "_num_epochs", "=", "num_epochs", "\n", "\n", "if", "checkpointer", "is", "not", "None", ":", "\n", "# We can't easily check if these parameters were passed in, so check against their default values.", "\n", "# We don't check against serialization_dir since it is also used by the parent class.", "\n", "            ", "if", "num_serialized_models_to_keep", "!=", "20", "or", "keep_serialized_model_every_num_seconds", "is", "not", "None", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\n", "\"When passing a custom Checkpointer, you may not also pass in separate checkpointer \"", "\n", "\"args 'num_serialized_models_to_keep' or 'keep_serialized_model_every_num_seconds'.\"", ")", "\n", "", "self", ".", "_checkpointer", "=", "checkpointer", "\n", "", "else", ":", "\n", "            ", "self", ".", "_checkpointer", "=", "Checkpointer", "(", "serialization_dir", ",", "\n", "keep_serialized_model_every_num_seconds", ",", "\n", "num_serialized_models_to_keep", ")", "\n", "\n", "", "self", ".", "_model_save_interval", "=", "model_save_interval", "\n", "\n", "self", ".", "_grad_norm", "=", "grad_norm", "\n", "self", ".", "_grad_clipping", "=", "grad_clipping", "\n", "\n", "self", ".", "_learning_rate_scheduler", "=", "learning_rate_scheduler", "\n", "self", ".", "_momentum_scheduler", "=", "momentum_scheduler", "\n", "self", ".", "_moving_average", "=", "moving_average", "\n", "\n", "# We keep the total batch number as an instance variable because it", "\n", "# is used inside a closure for the hook which logs activations in", "\n", "# ``_enable_activation_logging``.", "\n", "self", ".", "_batch_num_total", "=", "0", "\n", "\n", "self", ".", "_tensorboard", "=", "TensorboardWriter", "(", "\n", "get_batch_num_total", "=", "lambda", ":", "self", ".", "_batch_num_total", ",", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "summary_interval", "=", "summary_interval", ",", "\n", "histogram_interval", "=", "histogram_interval", ",", "\n", "should_log_parameter_statistics", "=", "should_log_parameter_statistics", ",", "\n", "should_log_learning_rate", "=", "should_log_learning_rate", ")", "\n", "\n", "self", ".", "_log_batch_size_period", "=", "log_batch_size_period", "\n", "\n", "self", ".", "_last_log", "=", "0.0", "# time of last logging", "\n", "\n", "# Enable activation logging.", "\n", "if", "histogram_interval", "is", "not", "None", ":", "\n", "            ", "self", ".", "_tensorboard", ".", "enable_activation_logging", "(", "self", ".", "model", ")", "\n", "", "self", ".", "callbacks", "=", "callbacks", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.rescale_gradients": [[256, 258], ["allennlp.training.util.rescale_gradients"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.rescale_gradients"], ["", "def", "rescale_gradients", "(", "self", ")", "->", "Optional", "[", "float", "]", ":", "\n", "        ", "return", "training_util", ".", "rescale_gradients", "(", "self", ".", "model", ",", "self", ".", "_grad_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.batch_loss": [[259, 283], ["allennlp.training.util.data_parallel", "allennlp.nn.util.move_to_device", "my_allennlp_trainer_epoch.Trainer.model", "len", "my_allennlp_trainer_epoch.Trainer.model.get_regularization_penalty", "RuntimeError"], "methods", ["None"], ["", "def", "batch_loss", "(", "self", ",", "batch_group", ":", "List", "[", "TensorDict", "]", ",", "for_training", ":", "bool", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Does a forward pass on the given batches and returns the ``loss`` value in the result.\n        If ``for_training`` is `True` also applies regularization penalty.\n        \"\"\"", "\n", "if", "self", ".", "_multiple_gpu", ":", "\n", "            ", "output_dict", "=", "training_util", ".", "data_parallel", "(", "batch_group", ",", "self", ".", "model", ",", "self", ".", "_cuda_devices", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "batch_group", ")", "==", "1", "\n", "batch", "=", "batch_group", "[", "0", "]", "\n", "batch", "=", "nn_util", ".", "move_to_device", "(", "batch", ",", "self", ".", "_cuda_devices", "[", "0", "]", ")", "\n", "output_dict", "=", "self", ".", "model", "(", "**", "batch", ")", "\n", "\n", "", "try", ":", "\n", "            ", "loss", "=", "output_dict", "[", "\"loss\"", "]", "\n", "if", "for_training", ":", "\n", "                ", "loss", "+=", "self", ".", "model", ".", "get_regularization_penalty", "(", ")", "\n", "", "", "except", "KeyError", ":", "\n", "            ", "if", "for_training", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"The model you are trying to optimize does not contain a\"", "\n", "\" 'loss' key in the output of model.forward(inputs).\"", ")", "\n", "", "loss", "=", "None", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer._train_epoch": [[284, 406], ["logger.info", "allennlp.common.util.peak_memory_mb", "logger.info", "allennlp.common.util.gpu_memory_mb().items", "my_allennlp_trainer_epoch.Trainer.model.train", "len", "my_allennlp_trainer_epoch.Trainer.iterator", "allennlp.common.util.lazy_groups_of", "math.ceil", "time.time", "time.time", "set", "logger.info", "allennlp.common.tqdm.Tqdm.tqdm", "allennlp.training.util.get_metrics", "gpu_usage.append", "logger.info", "my_allennlp_trainer_epoch.Trainer.model.get_parameters_for_histogram_tensorboard_logging", "my_allennlp_trainer_epoch.Trainer.optimizer.zero_grad", "my_allennlp_trainer_epoch.Trainer.batch_loss", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "my_allennlp_trainer_epoch.Trainer.backward", "my_allennlp_trainer_epoch.Trainer.item", "my_allennlp_trainer_epoch.Trainer.rescale_gradients", "my_allennlp_trainer_epoch.Trainer._tensorboard.should_log_histograms_this_batch", "allennlp.training.util.get_metrics", "allennlp.training.util.description_from_metrics", "allennlp.common.tqdm.Tqdm.tqdm.set_description", "my_allennlp_trainer_epoch.Trainer._tensorboard.should_log_this_batch", "my_allennlp_trainer_epoch.Trainer._tensorboard.should_log_histograms_this_batch", "allennlp.common.util.gpu_memory_mb", "my_allennlp_trainer_epoch.Trainer.iterator.get_num_batches", "ValueError", "my_allennlp_trainer_epoch.Trainer._learning_rate_scheduler.step_batch", "my_allennlp_trainer_epoch.Trainer._momentum_scheduler.step_batch", "my_allennlp_trainer_epoch.Trainer.optimizer.step", "my_allennlp_trainer_epoch.Trainer.model.named_parameters", "my_allennlp_trainer_epoch.Trainer.optimizer.step", "my_allennlp_trainer_epoch.Trainer._moving_average.apply", "my_allennlp_trainer_epoch.Trainer._tensorboard.log_parameter_and_gradient_statistics", "my_allennlp_trainer_epoch.Trainer._tensorboard.log_learning_rates", "my_allennlp_trainer_epoch.Trainer._tensorboard.add_train_scalar", "my_allennlp_trainer_epoch.Trainer._tensorboard.log_metrics", "my_allennlp_trainer_epoch.Trainer._tensorboard.log_histograms", "sum", "time.time", "my_allennlp_trainer_epoch.Trainer._save_checkpoint", "param.detach().cpu().clone", "param_updates[].sub_", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm().cpu", "torch.norm().cpu", "torch.norm().cpu", "torch.norm().cpu", "my_allennlp_trainer_epoch.Trainer._tensorboard.add_train_scalar", "logger.info", "my_allennlp_trainer_epoch.Trainer._tensorboard.add_train_scalar", "my_allennlp_trainer_epoch.Trainer._tensorboard.add_train_scalar", "my_allennlp_trainer_epoch.Trainer.model.named_parameters", "param.detach().cpu", "param_updates[].view", "allennlp.training.util.get_batch_size", "time.time", "allennlp.training.util.time_to_str", "param.detach().cpu", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "allennlp.training.util.get_metrics.items", "int", "str", "param.detach", "param.view", "param.detach"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate.train", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.get_metrics", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.batch_loss", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.rescale_gradients", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.get_metrics", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer._save_checkpoint"], ["", "def", "_train_epoch", "(", "self", ",", "epoch", ":", "int", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"\"\"\n        Trains one epoch and returns metrics.\n        \"\"\"", "\n", "logger", ".", "info", "(", "\"Epoch %d/%d\"", ",", "epoch", ",", "self", ".", "_num_epochs", "-", "1", ")", "\n", "peak_cpu_usage", "=", "peak_memory_mb", "(", ")", "\n", "logger", ".", "info", "(", "f\"Peak CPU memory usage MB: {peak_cpu_usage}\"", ")", "\n", "gpu_usage", "=", "[", "]", "\n", "for", "gpu", ",", "memory", "in", "gpu_memory_mb", "(", ")", ".", "items", "(", ")", ":", "\n", "            ", "gpu_usage", ".", "append", "(", "(", "gpu", ",", "memory", ")", ")", "\n", "logger", ".", "info", "(", "f\"GPU {gpu} memory usage MB: {memory}\"", ")", "\n", "\n", "", "train_loss", "=", "0.0", "\n", "# Set the model to \"train\" mode.", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "num_gpus", "=", "len", "(", "self", ".", "_cuda_devices", ")", "\n", "\n", "# Get tqdm for the training batches", "\n", "raw_train_generator", "=", "self", ".", "iterator", "(", "self", ".", "train_data", ",", "\n", "num_epochs", "=", "1", ",", "\n", "shuffle", "=", "self", ".", "shuffle", ")", "\n", "train_generator", "=", "lazy_groups_of", "(", "raw_train_generator", ",", "num_gpus", ")", "\n", "num_training_batches", "=", "math", ".", "ceil", "(", "self", ".", "iterator", ".", "get_num_batches", "(", "self", ".", "train_data", ")", "/", "num_gpus", ")", "\n", "self", ".", "_last_log", "=", "time", ".", "time", "(", ")", "\n", "last_save_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "batches_this_epoch", "=", "0", "\n", "if", "self", ".", "_batch_num_total", "is", "None", ":", "\n", "            ", "self", ".", "_batch_num_total", "=", "0", "\n", "\n", "", "histogram_parameters", "=", "set", "(", "self", ".", "model", ".", "get_parameters_for_histogram_tensorboard_logging", "(", ")", ")", "\n", "\n", "\n", "logger", ".", "info", "(", "\"Training\"", ")", "\n", "train_generator_tqdm", "=", "Tqdm", ".", "tqdm", "(", "train_generator", ",", "\n", "total", "=", "num_training_batches", ")", "\n", "cumulative_batch_size", "=", "0", "\n", "for", "batch_group", "in", "train_generator_tqdm", ":", "\n", "            ", "batches_this_epoch", "+=", "1", "\n", "self", ".", "_batch_num_total", "+=", "1", "\n", "batch_num_total", "=", "self", ".", "_batch_num_total", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "loss", "=", "self", ".", "batch_loss", "(", "batch_group", ",", "for_training", "=", "True", ")", "\n", "\n", "if", "torch", ".", "isnan", "(", "loss", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"nan loss encountered\"", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "batch_grad_norm", "=", "self", ".", "rescale_gradients", "(", ")", "\n", "\n", "# This does nothing if batch_num_total is None or you are using a", "\n", "# scheduler which doesn't update per batch.", "\n", "if", "self", ".", "_learning_rate_scheduler", ":", "\n", "                ", "self", ".", "_learning_rate_scheduler", ".", "step_batch", "(", "batch_num_total", ")", "\n", "", "if", "self", ".", "_momentum_scheduler", ":", "\n", "                ", "self", ".", "_momentum_scheduler", ".", "step_batch", "(", "batch_num_total", ")", "\n", "\n", "", "if", "self", ".", "_tensorboard", ".", "should_log_histograms_this_batch", "(", ")", ":", "\n", "# get the magnitude of parameter updates for logging", "\n", "# We need a copy of current parameters to compute magnitude of updates,", "\n", "# and copy them to CPU so large models won't go OOM on the GPU.", "\n", "                ", "param_updates", "=", "{", "name", ":", "param", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "clone", "(", ")", "\n", "for", "name", ",", "param", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "}", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "for", "name", ",", "param", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "param_updates", "[", "name", "]", ".", "sub_", "(", "param", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", "\n", "update_norm", "=", "torch", ".", "norm", "(", "param_updates", "[", "name", "]", ".", "view", "(", "-", "1", ",", ")", ")", "\n", "param_norm", "=", "torch", ".", "norm", "(", "param", ".", "view", "(", "-", "1", ",", ")", ")", ".", "cpu", "(", ")", "\n", "self", ".", "_tensorboard", ".", "add_train_scalar", "(", "\"gradient_update/\"", "+", "name", ",", "\n", "update_norm", "/", "(", "param_norm", "+", "1e-7", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Update moving averages", "\n", "", "if", "self", ".", "_moving_average", "is", "not", "None", ":", "\n", "                ", "self", ".", "_moving_average", ".", "apply", "(", "batch_num_total", ")", "\n", "\n", "# Update the description with the latest metrics", "\n", "", "metrics", "=", "training_util", ".", "get_metrics", "(", "self", ".", "model", ",", "train_loss", ",", "batches_this_epoch", ")", "\n", "description", "=", "training_util", ".", "description_from_metrics", "(", "metrics", ")", "\n", "\n", "train_generator_tqdm", ".", "set_description", "(", "description", ",", "refresh", "=", "False", ")", "\n", "\n", "# Log parameter values to Tensorboard", "\n", "if", "self", ".", "_tensorboard", ".", "should_log_this_batch", "(", ")", ":", "\n", "                ", "self", ".", "_tensorboard", ".", "log_parameter_and_gradient_statistics", "(", "self", ".", "model", ",", "batch_grad_norm", ")", "\n", "self", ".", "_tensorboard", ".", "log_learning_rates", "(", "self", ".", "model", ",", "self", ".", "optimizer", ")", "\n", "\n", "self", ".", "_tensorboard", ".", "add_train_scalar", "(", "\"loss/loss_train\"", ",", "metrics", "[", "\"loss\"", "]", ")", "\n", "self", ".", "_tensorboard", ".", "log_metrics", "(", "{", "\"epoch_metrics/\"", "+", "k", ":", "v", "for", "k", ",", "v", "in", "metrics", ".", "items", "(", ")", "}", ")", "\n", "\n", "", "if", "self", ".", "_tensorboard", ".", "should_log_histograms_this_batch", "(", ")", ":", "\n", "                ", "self", ".", "_tensorboard", ".", "log_histograms", "(", "self", ".", "model", ",", "histogram_parameters", ")", "\n", "\n", "", "if", "self", ".", "_log_batch_size_period", ":", "\n", "                ", "cur_batch", "=", "sum", "(", "[", "training_util", ".", "get_batch_size", "(", "batch", ")", "for", "batch", "in", "batch_group", "]", ")", "\n", "cumulative_batch_size", "+=", "cur_batch", "\n", "if", "(", "batches_this_epoch", "-", "1", ")", "%", "self", ".", "_log_batch_size_period", "==", "0", ":", "\n", "                    ", "average", "=", "cumulative_batch_size", "/", "batches_this_epoch", "\n", "logger", ".", "info", "(", "f\"current batch size: {cur_batch} mean batch size: {average}\"", ")", "\n", "self", ".", "_tensorboard", ".", "add_train_scalar", "(", "\"current_batch_size\"", ",", "cur_batch", ")", "\n", "self", ".", "_tensorboard", ".", "add_train_scalar", "(", "\"mean_batch_size\"", ",", "average", ")", "\n", "\n", "# Save model if needed.", "\n", "", "", "if", "self", ".", "_model_save_interval", "is", "not", "None", "and", "(", "\n", "time", ".", "time", "(", ")", "-", "last_save_time", ">", "self", ".", "_model_save_interval", "\n", ")", ":", "\n", "                ", "last_save_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "_save_checkpoint", "(", "\n", "'{0}.{1}'", ".", "format", "(", "epoch", ",", "training_util", ".", "time_to_str", "(", "int", "(", "last_save_time", ")", ")", ")", "\n", ")", "\n", "", "", "metrics", "=", "training_util", ".", "get_metrics", "(", "self", ".", "model", ",", "train_loss", ",", "batches_this_epoch", ",", "reset", "=", "True", ")", "\n", "metrics", "[", "'cpu_memory_MB'", "]", "=", "peak_cpu_usage", "\n", "for", "(", "gpu_num", ",", "memory", ")", "in", "gpu_usage", ":", "\n", "            ", "metrics", "[", "'gpu_'", "+", "str", "(", "gpu_num", ")", "+", "'_memory_MB'", "]", "=", "memory", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer._validation_loss": [[407, 457], ["logger.info", "my_allennlp_trainer_epoch.Trainer.model.eval", "len", "val_iterator", "allennlp.common.util.lazy_groups_of", "math.ceil", "allennlp.common.tqdm.Tqdm.tqdm", "my_allennlp_trainer_epoch.Trainer._moving_average.assign_average_value", "my_allennlp_trainer_epoch.Trainer.batch_loss", "allennlp.training.util.get_metrics", "allennlp.training.util.description_from_metrics", "allennlp.common.tqdm.Tqdm.tqdm.set_description", "my_allennlp_trainer_epoch.Trainer._moving_average.restore", "val_iterator.get_num_batches", "my_allennlp_trainer_epoch.Trainer.detach().cpu().numpy", "my_allennlp_trainer_epoch.Trainer.detach().cpu", "my_allennlp_trainer_epoch.Trainer.detach"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.batch_loss", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.get_metrics"], ["", "def", "_validation_loss", "(", "self", ")", "->", "Tuple", "[", "float", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Computes the validation loss. Returns it and the number of batches.\n        \"\"\"", "\n", "logger", ".", "info", "(", "\"Validating\"", ")", "\n", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "# Replace parameter values with the shadow values from the moving averages.", "\n", "if", "self", ".", "_moving_average", "is", "not", "None", ":", "\n", "            ", "self", ".", "_moving_average", ".", "assign_average_value", "(", ")", "\n", "\n", "", "if", "self", ".", "_validation_iterator", "is", "not", "None", ":", "\n", "            ", "val_iterator", "=", "self", ".", "_validation_iterator", "\n", "", "else", ":", "\n", "            ", "val_iterator", "=", "self", ".", "iterator", "\n", "\n", "", "num_gpus", "=", "len", "(", "self", ".", "_cuda_devices", ")", "\n", "\n", "raw_val_generator", "=", "val_iterator", "(", "self", ".", "_validation_data", ",", "\n", "num_epochs", "=", "1", ",", "\n", "shuffle", "=", "False", ")", "\n", "val_generator", "=", "lazy_groups_of", "(", "raw_val_generator", ",", "num_gpus", ")", "\n", "num_validation_batches", "=", "math", ".", "ceil", "(", "val_iterator", ".", "get_num_batches", "(", "self", ".", "_validation_data", ")", "/", "num_gpus", ")", "\n", "val_generator_tqdm", "=", "Tqdm", ".", "tqdm", "(", "val_generator", ",", "\n", "total", "=", "num_validation_batches", ")", "\n", "batches_this_epoch", "=", "0", "\n", "val_loss", "=", "0", "\n", "for", "batch_group", "in", "val_generator_tqdm", ":", "\n", "\n", "            ", "loss", "=", "self", ".", "batch_loss", "(", "batch_group", ",", "for_training", "=", "False", ")", "\n", "if", "loss", "is", "not", "None", ":", "\n", "# You shouldn't necessarily have to compute a loss for validation, so we allow for", "\n", "# `loss` to be None.  We need to be careful, though - `batches_this_epoch` is", "\n", "# currently only used as the divisor for the loss function, so we can safely only", "\n", "# count those batches for which we actually have a loss.  If this variable ever", "\n", "# gets used for something else, we might need to change things around a bit.", "\n", "                ", "batches_this_epoch", "+=", "1", "\n", "val_loss", "+=", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Update the description with the latest metrics", "\n", "", "val_metrics", "=", "training_util", ".", "get_metrics", "(", "self", ".", "model", ",", "val_loss", ",", "batches_this_epoch", ")", "\n", "description", "=", "training_util", ".", "description_from_metrics", "(", "val_metrics", ")", "\n", "val_generator_tqdm", ".", "set_description", "(", "description", ",", "refresh", "=", "False", ")", "\n", "\n", "# Now restore the original parameter values.", "\n", "", "if", "self", ".", "_moving_average", "is", "not", "None", ":", "\n", "            ", "self", ".", "_moving_average", ".", "restore", "(", ")", "\n", "\n", "", "return", "val_loss", ",", "batches_this_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.train": [[458, 585], ["allennlp.training.util.enable_gradient_clipping", "logger.info", "time.time", "my_allennlp_trainer_epoch.Trainer._metric_tracker.best_epoch_metrics.items", "range", "my_allennlp_trainer_epoch.Trainer._tensorboard.close", "my_allennlp_trainer_epoch.Trainer._checkpointer.best_model_state", "my_allennlp_trainer_epoch.Trainer._restore_checkpoint", "time.time", "my_allennlp_trainer_epoch.Trainer._train_epoch", "my_allennlp_trainer_epoch.Trainer.items", "my_allennlp_trainer_epoch.Trainer._tensorboard.log_metrics", "str", "my_allennlp_trainer_epoch.Trainer.items", "allennlp.training.util.get_metrics.items", "my_allennlp_trainer_epoch.Trainer._metric_tracker.is_best_so_far", "my_allennlp_trainer_epoch.Trainer._save_checkpoint", "logger.info", "my_allennlp_trainer_epoch.Trainer.model.load_state_dict", "traceback.print_exc", "allennlp.common.checks.ConfigurationError", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "max", "key.startswith", "time.time", "datetime.timedelta", "allennlp.training.util.get_metrics.items", "allennlp.common.util.dump_metrics", "my_allennlp_trainer_epoch.Trainer._learning_rate_scheduler.step", "my_allennlp_trainer_epoch.Trainer._momentum_scheduler.step", "time.time", "datetime.timedelta", "str", "logger.info", "callback.on_train_begin", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "metrics.get", "max", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "my_allennlp_trainer_epoch.Trainer._validation_loss", "allennlp.training.util.get_metrics", "my_allennlp_trainer_epoch.Trainer._metric_tracker.add_metric", "my_allennlp_trainer_epoch.Trainer._metric_tracker.should_stop_early", "os.path.join", "time.time", "datetime.timedelta", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "callback.on_epoch_begin", "metrics.get", "logger.info", "callback.on_epoch_end", "float", "int"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.my_corenlp.StanfordCoreNLP.close", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer._restore_checkpoint", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer._train_epoch", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer._save_checkpoint", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.FixedLossWeightCallback.on_train_begin", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer._validation_loss", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.pytorch_models.AsMilSimultaneouslyBertSingle.get_metrics", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.SetLossWeightCallback.on_epoch_begin", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.allennlp_callback.EstimateCallback.on_epoch_end"], ["", "def", "train", "(", "self", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Trains the supplied model with the supplied parameters.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "epoch_counter", "=", "self", ".", "_restore_checkpoint", "(", ")", "\n", "", "except", "RuntimeError", ":", "\n", "            ", "traceback", ".", "print_exc", "(", ")", "\n", "raise", "ConfigurationError", "(", "\"Could not recover training from the checkpoint.  Did you mean to output to \"", "\n", "\"a different serialization directory or delete the existing serialization \"", "\n", "\"directory?\"", ")", "\n", "\n", "", "training_util", ".", "enable_gradient_clipping", "(", "self", ".", "model", ",", "self", ".", "_grad_clipping", ")", "\n", "\n", "logger", ".", "info", "(", "\"Beginning training.\"", ")", "\n", "\n", "train_metrics", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "val_metrics", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "this_epoch_val_metric", ":", "float", "=", "None", "\n", "metrics", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "epochs_trained", "=", "0", "\n", "training_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "metrics", "[", "'best_epoch'", "]", "=", "self", ".", "_metric_tracker", ".", "best_epoch", "\n", "for", "key", ",", "value", "in", "self", ".", "_metric_tracker", ".", "best_epoch_metrics", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "\"best_validation_\"", "+", "key", "]", "=", "value", "\n", "\n", "", "if", "self", ".", "callbacks", "is", "not", "None", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "                    ", "callback", ".", "on_train_begin", "(", ")", "\n", "\n", "", "", "", "for", "epoch", "in", "range", "(", "epoch_counter", ",", "self", ".", "_num_epochs", ")", ":", "\n", "            ", "epoch_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "self", ".", "callbacks", "is", "not", "None", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "                        ", "callback", ".", "on_epoch_begin", "(", "epoch", ")", "\n", "\n", "", "", "", "train_metrics", "=", "self", ".", "_train_epoch", "(", "epoch", ")", "\n", "\n", "# get peak of memory usage", "\n", "if", "'cpu_memory_MB'", "in", "train_metrics", ":", "\n", "                ", "metrics", "[", "'peak_cpu_memory_MB'", "]", "=", "max", "(", "metrics", ".", "get", "(", "'peak_cpu_memory_MB'", ",", "0", ")", ",", "\n", "train_metrics", "[", "'cpu_memory_MB'", "]", ")", "\n", "", "for", "key", ",", "value", "in", "train_metrics", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", ".", "startswith", "(", "'gpu_'", ")", ":", "\n", "                    ", "metrics", "[", "\"peak_\"", "+", "key", "]", "=", "max", "(", "metrics", ".", "get", "(", "\"peak_\"", "+", "key", ",", "0", ")", ",", "value", ")", "\n", "\n", "", "", "if", "self", ".", "_validation_data", "is", "not", "None", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# We have a validation set, so compute all the metrics on it.", "\n", "                    ", "val_loss", ",", "num_batches", "=", "self", ".", "_validation_loss", "(", ")", "\n", "val_metrics", "=", "training_util", ".", "get_metrics", "(", "self", ".", "model", ",", "val_loss", ",", "num_batches", ",", "reset", "=", "True", ")", "\n", "\n", "# Check validation metric for early stopping", "\n", "this_epoch_val_metric", "=", "val_metrics", "[", "self", ".", "_validation_metric", "]", "\n", "self", ".", "_metric_tracker", ".", "add_metric", "(", "this_epoch_val_metric", ")", "\n", "\n", "if", "self", ".", "_metric_tracker", ".", "should_stop_early", "(", ")", ":", "\n", "                        ", "logger", ".", "info", "(", "\"Ran out of patience.  Stopping training.\"", ")", "\n", "break", "\n", "\n", "", "", "", "self", ".", "_tensorboard", ".", "log_metrics", "(", "train_metrics", ",", "\n", "val_metrics", "=", "val_metrics", ",", "\n", "log_to_console", "=", "True", ",", "\n", "epoch", "=", "epoch", "+", "1", ")", "# +1 because tensorboard doesn't like 0", "\n", "\n", "# Create overall metrics dict", "\n", "training_elapsed_time", "=", "time", ".", "time", "(", ")", "-", "training_start_time", "\n", "metrics", "[", "\"training_duration\"", "]", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "training_elapsed_time", ")", ")", "\n", "metrics", "[", "\"training_start_epoch\"", "]", "=", "epoch_counter", "\n", "metrics", "[", "\"training_epochs\"", "]", "=", "epochs_trained", "\n", "metrics", "[", "\"epoch\"", "]", "=", "epoch", "\n", "\n", "for", "key", ",", "value", "in", "train_metrics", ".", "items", "(", ")", ":", "\n", "                ", "metrics", "[", "\"training_\"", "+", "key", "]", "=", "value", "\n", "", "for", "key", ",", "value", "in", "val_metrics", ".", "items", "(", ")", ":", "\n", "                ", "metrics", "[", "\"validation_\"", "+", "key", "]", "=", "value", "\n", "\n", "", "if", "self", ".", "_metric_tracker", ".", "is_best_so_far", "(", ")", ":", "\n", "# Update all the best_ metrics.", "\n", "# (Otherwise they just stay the same as they were.)", "\n", "                ", "metrics", "[", "'best_epoch'", "]", "=", "epoch", "\n", "for", "key", ",", "value", "in", "val_metrics", ".", "items", "(", ")", ":", "\n", "                    ", "metrics", "[", "\"best_validation_\"", "+", "key", "]", "=", "value", "\n", "\n", "", "self", ".", "_metric_tracker", ".", "best_epoch_metrics", "=", "val_metrics", "\n", "\n", "", "if", "self", ".", "_serialization_dir", ":", "\n", "                ", "dump_metrics", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_serialization_dir", ",", "f'metrics_epoch_{epoch}.json'", ")", ",", "metrics", ")", "\n", "\n", "# The Scheduler API is agnostic to whether your schedule requires a validation metric -", "\n", "# if it doesn't, the validation metric passed here is ignored.", "\n", "", "if", "self", ".", "_learning_rate_scheduler", ":", "\n", "                ", "self", ".", "_learning_rate_scheduler", ".", "step", "(", "this_epoch_val_metric", ",", "epoch", ")", "\n", "", "if", "self", ".", "_momentum_scheduler", ":", "\n", "                ", "self", ".", "_momentum_scheduler", ".", "step", "(", "this_epoch_val_metric", ",", "epoch", ")", "\n", "\n", "", "self", ".", "_save_checkpoint", "(", "epoch", ")", "\n", "\n", "epoch_elapsed_time", "=", "time", ".", "time", "(", ")", "-", "epoch_start_time", "\n", "logger", ".", "info", "(", "\"Epoch duration: %s\"", ",", "datetime", ".", "timedelta", "(", "seconds", "=", "epoch_elapsed_time", ")", ")", "\n", "\n", "if", "epoch", "<", "self", ".", "_num_epochs", "-", "1", ":", "\n", "                ", "training_elapsed_time", "=", "time", ".", "time", "(", ")", "-", "training_start_time", "\n", "estimated_time_remaining", "=", "training_elapsed_time", "*", "(", "(", "self", ".", "_num_epochs", "-", "epoch_counter", ")", "/", "float", "(", "epoch", "-", "epoch_counter", "+", "1", ")", "-", "1", ")", "\n", "formatted_time", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "estimated_time_remaining", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Estimated training time remaining: %s\"", ",", "formatted_time", ")", "\n", "\n", "", "if", "self", ".", "callbacks", "is", "not", "None", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "                        ", "callback", ".", "on_epoch_end", "(", "epoch", ")", "\n", "", "", "", "epochs_trained", "+=", "1", "\n", "\n", "# make sure pending events are flushed to disk and files are closed properly", "\n", "", "self", ".", "_tensorboard", ".", "close", "(", ")", "\n", "\n", "# Load the best model state before returning", "\n", "best_model_state", "=", "self", ".", "_checkpointer", ".", "best_model_state", "(", ")", "\n", "if", "best_model_state", ":", "\n", "            ", "self", ".", "model", ".", "load_state_dict", "(", "best_model_state", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer._save_checkpoint": [[586, 624], ["my_allennlp_trainer_epoch.Trainer._checkpointer.save_checkpoint", "my_allennlp_trainer_epoch.Trainer._moving_average.assign_average_value", "my_allennlp_trainer_epoch.Trainer._metric_tracker.state_dict", "my_allennlp_trainer_epoch.Trainer.optimizer.state_dict", "my_allennlp_trainer_epoch.Trainer._learning_rate_scheduler.state_dict", "my_allennlp_trainer_epoch.Trainer._momentum_scheduler.state_dict", "my_allennlp_trainer_epoch.Trainer._moving_average.restore", "my_allennlp_trainer_epoch.Trainer.model.state_dict", "my_allennlp_trainer_epoch.Trainer._metric_tracker.is_best_so_far"], "methods", ["None"], ["", "def", "_save_checkpoint", "(", "self", ",", "epoch", ":", "Union", "[", "int", ",", "str", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Saves a checkpoint of the model to self._serialization_dir.\n        Is a no-op if self._serialization_dir is None.\n\n        Parameters\n        ----------\n        epoch : Union[int, str], required.\n            The epoch of training.  If the checkpoint is saved in the middle\n            of an epoch, the parameter is a string with the epoch and timestamp.\n        \"\"\"", "\n", "# If moving averages are used for parameters, we save", "\n", "# the moving average values into checkpoint, instead of the current values.", "\n", "if", "self", ".", "_moving_average", "is", "not", "None", ":", "\n", "            ", "self", ".", "_moving_average", ".", "assign_average_value", "(", ")", "\n", "\n", "# These are the training states we need to persist.", "\n", "", "training_states", "=", "{", "\n", "\"metric_tracker\"", ":", "self", ".", "_metric_tracker", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer\"", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"batch_num_total\"", ":", "self", ".", "_batch_num_total", "\n", "}", "\n", "\n", "# If we have a learning rate or momentum scheduler, we should persist them too.", "\n", "if", "self", ".", "_learning_rate_scheduler", "is", "not", "None", ":", "\n", "            ", "training_states", "[", "\"learning_rate_scheduler\"", "]", "=", "self", ".", "_learning_rate_scheduler", ".", "state_dict", "(", ")", "\n", "", "if", "self", ".", "_momentum_scheduler", "is", "not", "None", ":", "\n", "            ", "training_states", "[", "\"momentum_scheduler\"", "]", "=", "self", ".", "_momentum_scheduler", ".", "state_dict", "(", ")", "\n", "\n", "", "self", ".", "_checkpointer", ".", "save_checkpoint", "(", "\n", "model_state", "=", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "epoch", "=", "epoch", ",", "\n", "training_states", "=", "training_states", ",", "\n", "is_best_so_far", "=", "self", ".", "_metric_tracker", ".", "is_best_so_far", "(", ")", ")", "\n", "\n", "# Restore the original values for parameters so that training will not be affected.", "\n", "if", "self", ".", "_moving_average", "is", "not", "None", ":", "\n", "            ", "self", ".", "_moving_average", ".", "restore", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer._restore_checkpoint": [[625, 680], ["my_allennlp_trainer_epoch.Trainer._checkpointer.restore_checkpoint", "my_allennlp_trainer_epoch.Trainer.model.load_state_dict", "my_allennlp_trainer_epoch.Trainer.optimizer.load_state_dict", "allennlp.training.util.move_optimizer_to_cuda", "isinstance", "training_state.get", "my_allennlp_trainer_epoch.Trainer._learning_rate_scheduler.load_state_dict", "my_allennlp_trainer_epoch.Trainer._momentum_scheduler.load_state_dict", "my_allennlp_trainer_epoch.Trainer._metric_tracker.load_state_dict", "my_allennlp_trainer_epoch.Trainer._metric_tracker.clear", "my_allennlp_trainer_epoch.Trainer._metric_tracker.add_metrics", "my_allennlp_trainer_epoch.Trainer._metric_tracker.clear", "int", "training_state[].split"], "methods", ["None"], ["", "", "def", "_restore_checkpoint", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Restores the model and training state from the last saved checkpoint.\n        This includes an epoch count and optimizer state, which is serialized separately\n        from model parameters. This function should only be used to continue training -\n        if you wish to load a model for inference/load parts of a model into a new\n        computation graph, you should use the native Pytorch functions:\n        `` model.load_state_dict(torch.load(\"/path/to/model/weights.th\"))``\n\n        If ``self._serialization_dir`` does not exist or does not contain any checkpointed weights,\n        this function will do nothing and return 0.\n\n        Returns\n        -------\n        epoch: int\n            The epoch at which to resume training, which should be one after the epoch\n            in the saved training state.\n        \"\"\"", "\n", "model_state", ",", "training_state", "=", "self", ".", "_checkpointer", ".", "restore_checkpoint", "(", ")", "\n", "\n", "if", "not", "training_state", ":", "\n", "# No checkpoint to restore, start at 0", "\n", "            ", "return", "0", "\n", "\n", "", "self", ".", "model", ".", "load_state_dict", "(", "model_state", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "training_state", "[", "\"optimizer\"", "]", ")", "\n", "if", "self", ".", "_learning_rate_scheduler", "is", "not", "None", "and", "\"learning_rate_scheduler\"", "in", "training_state", ":", "\n", "            ", "self", ".", "_learning_rate_scheduler", ".", "load_state_dict", "(", "training_state", "[", "\"learning_rate_scheduler\"", "]", ")", "\n", "", "if", "self", ".", "_momentum_scheduler", "is", "not", "None", "and", "\"momentum_scheduler\"", "in", "training_state", ":", "\n", "            ", "self", ".", "_momentum_scheduler", ".", "load_state_dict", "(", "training_state", "[", "\"momentum_scheduler\"", "]", ")", "\n", "", "training_util", ".", "move_optimizer_to_cuda", "(", "self", ".", "optimizer", ")", "\n", "\n", "# Currently the ``training_state`` contains a serialized ``MetricTracker``.", "\n", "if", "\"metric_tracker\"", "in", "training_state", ":", "\n", "            ", "self", ".", "_metric_tracker", ".", "load_state_dict", "(", "training_state", "[", "\"metric_tracker\"", "]", ")", "\n", "# It used to be the case that we tracked ``val_metric_per_epoch``.", "\n", "", "elif", "\"val_metric_per_epoch\"", "in", "training_state", ":", "\n", "            ", "self", ".", "_metric_tracker", ".", "clear", "(", ")", "\n", "self", ".", "_metric_tracker", ".", "add_metrics", "(", "training_state", "[", "\"val_metric_per_epoch\"", "]", ")", "\n", "# And before that we didn't track anything.", "\n", "", "else", ":", "\n", "            ", "self", ".", "_metric_tracker", ".", "clear", "(", ")", "\n", "\n", "", "if", "isinstance", "(", "training_state", "[", "\"epoch\"", "]", ",", "int", ")", ":", "\n", "            ", "epoch_to_return", "=", "training_state", "[", "\"epoch\"", "]", "+", "1", "\n", "", "else", ":", "\n", "            ", "epoch_to_return", "=", "int", "(", "training_state", "[", "\"epoch\"", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "+", "1", "\n", "\n", "# For older checkpoints with batch_num_total missing, default to old behavior where", "\n", "# it is unchanged.", "\n", "", "batch_num_total", "=", "training_state", ".", "get", "(", "'batch_num_total'", ")", "\n", "if", "batch_num_total", "is", "not", "None", ":", "\n", "            ", "self", ".", "_batch_num_total", "=", "batch_num_total", "\n", "\n", "", "return", "epoch_to_return", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.from_params": [[682, 772], ["params.pop_int", "params.pop", "params.pop_bool", "params.pop_int", "allennlp.common.checks.parse_cuda_device", "params.pop_float", "params.pop_float", "params.pop", "params.pop", "isinstance", "allennlp.training.optimizers.Optimizer.from_params", "params.pop_float", "params.pop_int", "params.pop_int", "params.pop_bool", "params.pop_bool", "params.pop_int", "params.assert_empty", "cls", "params.pop", "model.cuda.cuda.cuda", "params.pop", "allennlp.training.moving_average.MovingAverage.from_params", "allennlp.training.learning_rate_schedulers.LearningRateScheduler.from_params", "allennlp.training.momentum_schedulers.MomentumScheduler.from_params", "allennlp.training.checkpointer.Checkpointer.from_params", "params.pop_int", "params.pop_int", "allennlp.training.checkpointer.Checkpointer", "model.cuda.cuda.named_parameters", "params.pop", "allennlp.common.checks.ConfigurationError", "params.pop"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.from_params", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.from_params", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.from_params", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.from_params", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.aspect_category_detection_and_sentiment_classification.my_allennlp_trainer_epoch.Trainer.from_params"], ["", "@", "classmethod", "\n", "def", "from_params", "(", "cls", ",", "# type: ignore", "\n", "model", ":", "Model", ",", "\n", "serialization_dir", ":", "str", ",", "\n", "iterator", ":", "DataIterator", ",", "\n", "train_data", ":", "Iterable", "[", "Instance", "]", ",", "\n", "validation_data", ":", "Optional", "[", "Iterable", "[", "Instance", "]", "]", ",", "\n", "params", ":", "Params", ",", "\n", "validation_iterator", ":", "DataIterator", "=", "None", ")", "->", "'Trainer'", ":", "\n", "# pylint: disable=arguments-differ", "\n", "        ", "patience", "=", "params", ".", "pop_int", "(", "\"patience\"", ",", "None", ")", "\n", "validation_metric", "=", "params", ".", "pop", "(", "\"validation_metric\"", ",", "\"-loss\"", ")", "\n", "shuffle", "=", "params", ".", "pop_bool", "(", "\"shuffle\"", ",", "True", ")", "\n", "num_epochs", "=", "params", ".", "pop_int", "(", "\"num_epochs\"", ",", "20", ")", "\n", "cuda_device", "=", "parse_cuda_device", "(", "params", ".", "pop", "(", "\"cuda_device\"", ",", "-", "1", ")", ")", "\n", "grad_norm", "=", "params", ".", "pop_float", "(", "\"grad_norm\"", ",", "None", ")", "\n", "grad_clipping", "=", "params", ".", "pop_float", "(", "\"grad_clipping\"", ",", "None", ")", "\n", "lr_scheduler_params", "=", "params", ".", "pop", "(", "\"learning_rate_scheduler\"", ",", "None", ")", "\n", "momentum_scheduler_params", "=", "params", ".", "pop", "(", "\"momentum_scheduler\"", ",", "None", ")", "\n", "\n", "if", "isinstance", "(", "cuda_device", ",", "list", ")", ":", "\n", "            ", "model_device", "=", "cuda_device", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "model_device", "=", "cuda_device", "\n", "", "if", "model_device", ">=", "0", ":", "\n", "# Moving model to GPU here so that the optimizer state gets constructed on", "\n", "# the right device.", "\n", "            ", "model", "=", "model", ".", "cuda", "(", "model_device", ")", "\n", "\n", "", "parameters", "=", "[", "[", "n", ",", "p", "]", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "optimizer", "=", "Optimizer", ".", "from_params", "(", "parameters", ",", "params", ".", "pop", "(", "\"optimizer\"", ")", ")", "\n", "if", "\"moving_average\"", "in", "params", ":", "\n", "            ", "moving_average", "=", "MovingAverage", ".", "from_params", "(", "params", ".", "pop", "(", "\"moving_average\"", ")", ",", "parameters", "=", "parameters", ")", "\n", "", "else", ":", "\n", "            ", "moving_average", "=", "None", "\n", "\n", "", "if", "lr_scheduler_params", ":", "\n", "            ", "lr_scheduler", "=", "LearningRateScheduler", ".", "from_params", "(", "optimizer", ",", "lr_scheduler_params", ")", "\n", "", "else", ":", "\n", "            ", "lr_scheduler", "=", "None", "\n", "", "if", "momentum_scheduler_params", ":", "\n", "            ", "momentum_scheduler", "=", "MomentumScheduler", ".", "from_params", "(", "optimizer", ",", "momentum_scheduler_params", ")", "\n", "", "else", ":", "\n", "            ", "momentum_scheduler", "=", "None", "\n", "\n", "", "if", "'checkpointer'", "in", "params", ":", "\n", "            ", "if", "'keep_serialized_model_every_num_seconds'", "in", "params", "or", "'num_serialized_models_to_keep'", "in", "params", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\n", "\"Checkpointer may be initialized either from the 'checkpointer' key or from the \"", "\n", "\"keys 'num_serialized_models_to_keep' and 'keep_serialized_model_every_num_seconds'\"", "\n", "\" but the passed config uses both methods.\"", ")", "\n", "", "checkpointer", "=", "Checkpointer", ".", "from_params", "(", "params", ".", "pop", "(", "\"checkpointer\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "num_serialized_models_to_keep", "=", "params", ".", "pop_int", "(", "\"num_serialized_models_to_keep\"", ",", "20", ")", "\n", "keep_serialized_model_every_num_seconds", "=", "params", ".", "pop_int", "(", "\n", "\"keep_serialized_model_every_num_seconds\"", ",", "None", ")", "\n", "checkpointer", "=", "Checkpointer", "(", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "num_serialized_models_to_keep", "=", "num_serialized_models_to_keep", ",", "\n", "keep_serialized_model_every_num_seconds", "=", "keep_serialized_model_every_num_seconds", ")", "\n", "", "model_save_interval", "=", "params", ".", "pop_float", "(", "\"model_save_interval\"", ",", "None", ")", "\n", "summary_interval", "=", "params", ".", "pop_int", "(", "\"summary_interval\"", ",", "100", ")", "\n", "histogram_interval", "=", "params", ".", "pop_int", "(", "\"histogram_interval\"", ",", "None", ")", "\n", "should_log_parameter_statistics", "=", "params", ".", "pop_bool", "(", "\"should_log_parameter_statistics\"", ",", "True", ")", "\n", "should_log_learning_rate", "=", "params", ".", "pop_bool", "(", "\"should_log_learning_rate\"", ",", "False", ")", "\n", "log_batch_size_period", "=", "params", ".", "pop_int", "(", "\"log_batch_size_period\"", ",", "None", ")", "\n", "\n", "params", ".", "assert_empty", "(", "cls", ".", "__name__", ")", "\n", "return", "cls", "(", "model", ",", "optimizer", ",", "iterator", ",", "\n", "train_data", ",", "validation_data", ",", "\n", "patience", "=", "patience", ",", "\n", "validation_metric", "=", "validation_metric", ",", "\n", "validation_iterator", "=", "validation_iterator", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "num_epochs", "=", "num_epochs", ",", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "cuda_device", "=", "cuda_device", ",", "\n", "grad_norm", "=", "grad_norm", ",", "\n", "grad_clipping", "=", "grad_clipping", ",", "\n", "learning_rate_scheduler", "=", "lr_scheduler", ",", "\n", "momentum_scheduler", "=", "momentum_scheduler", ",", "\n", "checkpointer", "=", "checkpointer", ",", "\n", "model_save_interval", "=", "model_save_interval", ",", "\n", "summary_interval", "=", "summary_interval", ",", "\n", "histogram_interval", "=", "histogram_interval", ",", "\n", "should_log_parameter_statistics", "=", "should_log_parameter_statistics", ",", "\n", "should_log_learning_rate", "=", "should_log_learning_rate", ",", "\n", "log_batch_size_period", "=", "log_batch_size_period", ",", "\n", "moving_average", "=", "moving_average", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.KeyInstance.__init__": [[19, 26], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "text", ":", "str", ",", "from_index", ":", "int", ",", "to_index", ":", "int", ",", "polarity", ":", "str", ",", "category", ":", "str", ")", ":", "\n", "        ", "self", ".", "text", "=", "text", "\n", "self", ".", "from_index", "=", "from_index", "\n", "self", ".", "to_index", "=", "to_index", "\n", "self", ".", "polarity", "=", "polarity", "\n", "self", ".", "category", "=", "category", "\n", "self", ".", "metadata", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.KeyInstance.__str__": [[27, 29], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.Sentence.__init__": [[36, 40], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "text", ":", "str", ",", "categories", ":", "List", "[", "str", "]", ",", "key_instances", ":", "List", "[", "KeyInstance", "]", ")", ":", "\n", "        ", "self", ".", "text", "=", "text", "\n", "self", ".", "categories", "=", "categories", "\n", "self", ".", "key_instances", "=", "key_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.Mil.__init__": [[47, 49], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "configuration", ":", "dict", "=", "None", ")", ":", "\n", "        ", "self", ".", "configuration", "=", "configuration", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.Mil._get_category": [[50, 52], ["None"], "methods", ["None"], ["", "def", "_get_category", "(", "self", ",", "category", ":", "str", ")", ":", "\n", "        ", "return", "category", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.Mil._load_samples_by_filepath": [[53, 73], ["open", "json.load", "mil_data.Sentence", "samples.append", "int", "int", "mil_data.Mil._get_category", "mil_data.KeyInstance", "key_instances.append"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.MAMSACSAMil._get_category"], ["", "def", "_load_samples_by_filepath", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "with", "open", "(", "filepath", ",", "encoding", "=", "'utf-8'", ")", "as", "input_file", ":", "\n", "            ", "json_dict", "=", "json", ".", "load", "(", "input_file", ")", "\n", "samples", "=", "[", "]", "\n", "for", "e", "in", "json_dict", ":", "\n", "                ", "text", "=", "e", "[", "'text'", "]", "\n", "categories", "=", "e", "[", "'categories'", "]", "\n", "key_instance_dicts", "=", "e", "[", "'key_instances'", "]", "\n", "key_instances", ":", "List", "[", "KeyInstance", "]", "=", "[", "]", "\n", "for", "key_instance_dict", "in", "key_instance_dicts", ":", "\n", "                    ", "key_instance_text", "=", "key_instance_dict", "[", "'key_instance'", "]", "\n", "from_index", "=", "int", "(", "key_instance_dict", "[", "'from'", "]", ")", "\n", "to_index", "=", "int", "(", "key_instance_dict", "[", "'to'", "]", ")", "\n", "polarity", "=", "key_instance_dict", "[", "'polarity'", "]", "\n", "category", "=", "self", ".", "_get_category", "(", "key_instance_dict", "[", "'category'", "]", ")", "\n", "key_instance", "=", "KeyInstance", "(", "key_instance_text", ",", "from_index", ",", "to_index", ",", "polarity", ",", "category", ")", "\n", "key_instances", ".", "append", "(", "key_instance", ")", "\n", "", "sentence", "=", "Sentence", "(", "text", ",", "categories", ",", "key_instances", ")", "\n", "samples", ".", "append", "(", "sentence", ")", "\n", "", "", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.Mil.load_samples": [[74, 76], ["None"], "methods", ["None"], ["", "def", "load_samples", "(", "self", ")", "->", "List", "[", "Sentence", "]", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.SemEval2014Task4RESTMil.load_samples": [[83, 90], ["nlp_tasks.common.common_path.get_task_data_dir", "os.path.join", "mil_data.Mil._load_samples_by_filepath"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.common.common_path.get_task_data_dir", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.Mil._load_samples_by_filepath"], ["def", "load_samples", "(", "self", ")", ":", "\n", "        ", "base_dir", "=", "common_path", ".", "get_task_data_dir", "(", "'absa'", ",", "is_original", "=", "True", ")", "\n", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'SemEval-2014-Task-4-REST'", ",", "'SemEval-2014-Task-4-REST-mil'", ",", "\n", "'SemEval-2014-Task-4-REST-mil.json'", ")", "\n", "samples", "=", "super", "(", ")", ".", "_load_samples_by_filepath", "(", "filepath", ")", "\n", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.SemEval2014Task4RESTMil._get_category": [[91, 93], ["None"], "methods", ["None"], ["", "def", "_get_category", "(", "self", ",", "category", ":", "str", ")", ":", "\n", "        ", "return", "'anecdotes/miscellaneous'", "if", "category", "==", "'anecdotes_miscellaneous'", "else", "category", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.SemEval2014Task4RESTHardMil.load_samples": [[100, 111], ["nlp_tasks.common.common_path.get_task_data_dir", "os.path.join", "mil_data.Mil._load_samples_by_filepath", "os.path.join", "set", "nlp_tasks.utils.file_utils.read_all_lines", "sample.text.lower"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.common.common_path.get_task_data_dir", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.Mil._load_samples_by_filepath", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.read_all_lines"], ["def", "load_samples", "(", "self", ")", ":", "\n", "        ", "base_dir", "=", "common_path", ".", "get_task_data_dir", "(", "'absa'", ",", "is_original", "=", "True", ")", "\n", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'SemEval-2014-Task-4-REST'", ",", "'SemEval-2014-Task-4-REST-mil'", ",", "\n", "'SemEval-2014-Task-4-REST-mil.json'", ")", "\n", "samples", "=", "super", "(", ")", ".", "_load_samples_by_filepath", "(", "filepath", ")", "\n", "filepath_hard", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'SemEval-2014-Task-4-REST'", ",", "'SemEval-2014-Task-4-REST-mil'", ",", "\n", "'SemEval-2014-Task-4-REST-hard-mil.txt'", ")", "\n", "hard_sentences", "=", "set", "(", "file_utils", ".", "read_all_lines", "(", "filepath_hard", ")", ")", "\n", "result", "=", "[", "sample", "for", "sample", "in", "samples", "if", "sample", ".", "text", ".", "lower", "(", ")", "in", "hard_sentences", "]", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.SemEval2014Task4RESTHardMil._get_category": [[112, 114], ["None"], "methods", ["None"], ["", "def", "_get_category", "(", "self", ",", "category", ":", "str", ")", ":", "\n", "        ", "return", "'anecdotes/miscellaneous'", "if", "category", "==", "'anecdotes_miscellaneous'", "else", "category", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.MAMSACSAMil.load_samples": [[121, 128], ["nlp_tasks.common.common_path.get_task_data_dir", "os.path.join", "mil_data.Mil._load_samples_by_filepath"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.common.common_path.get_task_data_dir", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.Mil._load_samples_by_filepath"], ["def", "load_samples", "(", "self", ")", ":", "\n", "        ", "base_dir", "=", "common_path", ".", "get_task_data_dir", "(", "'absa'", ",", "is_original", "=", "True", ")", "\n", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'MAMS-for-ABSA'", ",", "'MAMS-ACSA-mil'", ",", "\n", "'AMS-ACSA-mil.json'", ")", "\n", "samples", "=", "super", "(", ")", ".", "_load_samples_by_filepath", "(", "filepath", ")", "\n", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.mil_data.MAMSACSAMil._get_category": [[129, 131], ["None"], "methods", ["None"], ["", "def", "_get_category", "(", "self", ",", "category", ":", "str", ")", ":", "\n", "        ", "return", "'miscellaneous'", "if", "category", "==", "'anecdotes_miscellaneous'", "else", "category", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.AspectTerm.__init__": [[32, 40], ["int", "int"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "term", ",", "polarity", ",", "from_index", ",", "to_index", ",", "category", "=", "None", ")", ":", "\n", "        ", "self", ".", "term", "=", "term", "\n", "self", ".", "polarity", "=", "polarity", "\n", "# inclusive", "\n", "self", ".", "from_index", "=", "int", "(", "from_index", ")", "\n", "# exclusive", "\n", "self", ".", "to_index", "=", "int", "(", "to_index", ")", "\n", "self", ".", "category", "=", "category", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.AspectTerm.__str__": [[41, 44], ["str", "str", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'%s-%s-%s-%s-%s'", "%", "(", "self", ".", "term", ",", "str", "(", "self", ".", "polarity", ")", ",", "str", "(", "self", ".", "from_index", ")", ",", "str", "(", "self", ".", "to_index", ")", ",", "\n", "self", ".", "category", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.AspectCategory.__init__": [[51, 54], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "category", ",", "polarity", ")", ":", "\n", "        ", "self", ".", "category", "=", "category", "\n", "self", ".", "polarity", "=", "polarity", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.AspectCategory.__str__": [[55, 57], ["str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'%s-%s'", "%", "(", "self", ".", "category", ",", "str", "(", "self", ".", "polarity", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Text.__init__": [[64, 68], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "text", ",", "polarity", ",", "sample_id", "=", "''", ")", ":", "\n", "        ", "self", ".", "text", "=", "text", "\n", "self", ".", "polarity", "=", "polarity", "\n", "self", ".", "sample_id", "=", "sample_id", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Text.__str__": [[69, 71], ["str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'%s-%s'", "%", "(", "self", ".", "text", ",", "str", "(", "self", ".", "polarity", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.AbsaText.__init__": [[78, 82], ["data_object.Text.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "text", ",", "polarity", ",", "aspect_categories", ",", "aspect_terms", ",", "sample_id", "=", "''", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "text", ",", "polarity", ",", "sample_id", "=", "sample_id", ")", "\n", "self", ".", "aspect_categories", "=", "aspect_categories", "\n", "self", ".", "aspect_terms", "=", "aspect_terms", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.AbsaSentence.__init__": [[89, 92], ["data_object.AbsaText.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "text", ",", "polarity", ",", "aspect_categories", ",", "aspect_terms", ",", "sample_id", "=", "''", ",", "start_index_in_doc", "=", "-", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "text", ",", "polarity", ",", "aspect_categories", ",", "aspect_terms", ",", "sample_id", "=", "sample_id", ")", "\n", "self", ".", "start_index_in_doc", "=", "start_index_in_doc", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.AbsaDocument.__init__": [[99, 102], ["data_object.AbsaText.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "text", ",", "polarity", ",", "aspect_categories", ",", "aspect_terms", ",", "absa_sentences", ",", "sample_id", "=", "''", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "text", ",", "polarity", ",", "aspect_categories", ",", "aspect_terms", ",", "sample_id", "=", "sample_id", ")", "\n", "self", ".", "absa_sentences", "=", "absa_sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.AbsaDocument.get_plain_text_of_sentences": [[103, 114], ["result.append"], "methods", ["None"], ["", "def", "get_plain_text_of_sentences", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n\n        :return:\n        \"\"\"", "\n", "result", "=", "[", "]", "\n", "if", "self", ".", "absa_sentences", "is", "None", ":", "\n", "            ", "return", "result", "\n", "", "for", "sentence", "in", "self", ".", "absa_sentences", ":", "\n", "            ", "result", ".", "append", "(", "sentence", ".", "text", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.__init__": [[122, 125], ["data_object.BaseDataset._load_train_dev_test_data"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Semeval2014Task4RestDevSplits._load_train_dev_test_data"], ["def", "__init__", "(", "self", ",", "configuration", ":", "dict", "=", "None", ")", ":", "\n", "        ", "self", ".", "configuration", "=", "configuration", "\n", "self", ".", "train_data", ",", "self", ".", "dev_data", ",", "self", ".", "test_data", "=", "self", ".", "_load_train_dev_test_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset._load_train_dev_test_data": [[126, 131], ["None"], "methods", ["None"], ["", "def", "_load_train_dev_test_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        return:\n        \"\"\"", "\n", "return", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.get_data_type_and_data_dict": [[132, 139], ["None"], "methods", ["None"], ["", "def", "get_data_type_and_data_dict", "(", "self", ")", ":", "\n", "        ", "data_type_and_data", "=", "{", "\n", "'train'", ":", "self", ".", "train_data", ",", "\n", "'dev'", ":", "self", ".", "dev_data", ",", "\n", "'test'", ":", "self", ".", "test_data", "\n", "}", "\n", "return", "data_type_and_data", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.get_sentences": [[140, 157], ["data_object.BaseDataset.get_data_type_and_data_dict", "logger.info", "document.get_plain_text_of_sentences", "sentences.append", "str"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.get_data_type_and_data_dict", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.AbsaDocument.get_plain_text_of_sentences"], ["", "def", "get_sentences", "(", "self", ",", "data_type", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n\n        :param data_type: train, dev, or test\n        :return: all sentences in the specified dataset\n        \"\"\"", "\n", "\n", "data_type_and_data", "=", "self", ".", "get_data_type_and_data_dict", "(", ")", "\n", "if", "data_type", "is", "None", "or", "data_type", "not", "in", "data_type_and_data", ":", "\n", "            ", "logger", ".", "info", "(", "'unknown data type: %s'", "%", "str", "(", "data_type", ")", ")", "\n", "return", "[", "]", "\n", "", "data", "=", "data_type_and_data", "[", "data_type", "]", "\n", "sentences", "=", "[", "]", "\n", "for", "document", "in", "data", ":", "\n", "            ", "for", "sentence", "in", "document", ".", "get_plain_text_of_sentences", "(", ")", ":", "\n", "                ", "sentences", ".", "append", "(", "sentence", ")", "\n", "", "", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.get_documents": [[158, 174], ["data_object.BaseDataset.get_data_type_and_data_dict", "logger.info", "documents.append", "str"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.get_data_type_and_data_dict"], ["", "def", "get_documents", "(", "self", ",", "data_type", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n\n        :param data_type: train, dev, or test\n        :return: all sentences in the specified dataset\n        \"\"\"", "\n", "\n", "data_type_and_data", "=", "self", ".", "get_data_type_and_data_dict", "(", ")", "\n", "if", "data_type", "is", "None", "or", "data_type", "not", "in", "data_type_and_data", ":", "\n", "            ", "logger", ".", "info", "(", "'unknown data type: %s'", "%", "str", "(", "data_type", ")", ")", "\n", "return", "[", "]", "\n", "", "data", "=", "data_type_and_data", "[", "data_type", "]", "\n", "documents", "=", "[", "]", "\n", "for", "document", "in", "data", ":", "\n", "            ", "documents", ".", "append", "(", "document", ".", "text", ")", "\n", "", "return", "documents", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.generate_atsa_data": [[175, 210], ["set", "data_object.BaseDataset.get_data_type_and_data_dict", "data_object.BaseDataset.items", "list", "list.sort", "sklearn.model_selection.train_test_split", "re.sub", "samples.append", "label.append", "list.add"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.get_data_type_and_data_dict"], ["", "def", "generate_atsa_data", "(", "self", ",", "test_size", "=", "0.2", ")", ":", "\n", "        ", "\"\"\"\n\n        :return:\n        \"\"\"", "\n", "result", "=", "{", "\n", "'train'", ":", "None", ",", "\n", "'dev'", ":", "None", ",", "\n", "'test'", ":", "None", "\n", "}", "\n", "distinct_polarities", "=", "set", "(", ")", "\n", "data_type_and_data", "=", "self", ".", "get_data_type_and_data_dict", "(", ")", "\n", "for", "data_type", ",", "data", "in", "data_type_and_data", ".", "items", "(", ")", ":", "\n", "            ", "if", "data", "is", "None", ":", "\n", "                ", "continue", "\n", "", "samples", "=", "[", "]", "\n", "for", "document", "in", "data", ":", "\n", "                ", "for", "sentence", "in", "document", ".", "absa_sentences", ":", "\n", "                    ", "content", "=", "re", ".", "sub", "(", "'[\\r\\n]'", ",", "''", ",", "sentence", ".", "text", ")", "\n", "# content = re.sub('[\\-/]', ' ', content)", "\n", "label", "=", "[", "]", "\n", "for", "aspect_term", "in", "sentence", ".", "aspect_terms", ":", "\n", "                        ", "label", ".", "append", "(", "aspect_term", ")", "\n", "polarity", "=", "aspect_term", ".", "polarity", "\n", "distinct_polarities", ".", "add", "(", "polarity", ")", "\n", "", "samples", ".", "append", "(", "[", "content", ",", "label", "]", ")", "\n", "", "", "result", "[", "data_type", "]", "=", "samples", "\n", "", "if", "result", "[", "'dev'", "]", "is", "None", "and", "test_size", "is", "not", "None", ":", "\n", "            ", "original_train_samples", "=", "result", "[", "'train'", "]", "\n", "train_samples", ",", "dev_samples", "=", "train_test_split", "(", "original_train_samples", ",", "test_size", "=", "test_size", ")", "\n", "result", "[", "'train'", "]", "=", "train_samples", "\n", "result", "[", "'dev'", "]", "=", "dev_samples", "\n", "", "distinct_polarities", "=", "list", "(", "distinct_polarities", ")", "\n", "distinct_polarities", ".", "sort", "(", ")", "\n", "return", "result", ",", "distinct_polarities", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.generate_dev_data": [[211, 225], ["sklearn.model_selection.train_test_split"], "methods", ["None"], ["", "def", "generate_dev_data", "(", "self", ",", "result", ",", "dev_size", ",", "random_state", "=", "1234", ")", ":", "\n", "        ", "\"\"\"\n        :return:\n        \"\"\"", "\n", "\n", "if", "result", "[", "'dev'", "]", "is", "None", ":", "\n", "            ", "if", "dev_size", "!=", "0.0", ":", "\n", "                ", "original_train_samples", "=", "result", "[", "'train'", "]", "\n", "train_samples", ",", "dev_samples", "=", "train_test_split", "(", "original_train_samples", ",", "test_size", "=", "dev_size", ",", "\n", "random_state", "=", "random_state", ")", "\n", "result", "[", "'train'", "]", "=", "train_samples", "\n", "result", "[", "'dev'", "]", "=", "dev_samples", "\n", "", "else", ":", "\n", "                ", "result", "[", "'dev'", "]", "=", "result", "[", "'test'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.AsgcnData.__init__": [[233, 235], ["data_object.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "configuration", ":", "dict", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "configuration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.AsgcnData._load_train_dev_test_data_by_filepath": [[236, 267], ["data_type_and_filepath.items", "nlp_tasks.utils.file_utils.read_all_lines", "range", "len", "lines[].lower().strip", "lines[].strip", "data_object.AspectTerm", "data_object.AbsaSentence", "sentences.append", "data_object.AbsaDocument", "s.lower().strip", "len", "logger.error", "lines[].partition", "lines[].lower", "len", "s.lower"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.read_all_lines"], ["", "def", "_load_train_dev_test_data_by_filepath", "(", "self", ",", "train_filepath", ",", "test_filepath", ")", ":", "\n", "        ", "data_type_and_filepath", "=", "{", "'train'", ":", "train_filepath", ",", "\n", "'test'", ":", "test_filepath", "}", "\n", "data_type_and_data", "=", "{", "}", "\n", "for", "data_type", ",", "filepath", "in", "data_type_and_filepath", ".", "items", "(", ")", ":", "\n", "            ", "lines", "=", "file_utils", ".", "read_all_lines", "(", "filepath", ")", "\n", "sentences", "=", "[", "]", "\n", "polarity_mapping", "=", "{", "'-1'", ":", "'negative'", ",", "\n", "'0'", ":", "'neutral'", ",", "\n", "'1'", ":", "'positive'", "}", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "lines", ")", ",", "3", ")", ":", "\n", "                ", "text_left", ",", "_", ",", "text_right", "=", "[", "s", ".", "lower", "(", ")", ".", "strip", "(", ")", "for", "s", "in", "lines", "[", "i", "]", ".", "partition", "(", "\"$T$\"", ")", "]", "\n", "aspect", "=", "lines", "[", "i", "+", "1", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "polarity", "=", "lines", "[", "i", "+", "2", "]", ".", "strip", "(", ")", "\n", "if", "text_left", "!=", "''", ":", "\n", "                    ", "text", "=", "text_left", "+", "\" \"", "+", "aspect", "\n", "from_index", "=", "len", "(", "text_left", ")", "+", "1", "\n", "", "else", ":", "\n", "                    ", "text", "=", "aspect", "\n", "from_index", "=", "0", "\n", "", "if", "text_right", "!=", "''", ":", "\n", "                    ", "text", "=", "text", "+", "' '", "+", "text_right", "\n", "", "to_index", "=", "from_index", "+", "len", "(", "aspect", ")", "\n", "if", "text", "[", "from_index", ":", "to_index", "]", "!=", "aspect", ":", "\n", "                    ", "logger", ".", "error", "(", "'error aspect index: %s != %s'", "(", "text", "[", "from_index", ":", "to_index", "]", ",", "aspect", ")", ")", "\n", "", "aspect_term", "=", "AspectTerm", "(", "aspect", ",", "polarity_mapping", "[", "polarity", "]", ",", "from_index", ",", "to_index", ")", "\n", "sentence", "=", "AbsaSentence", "(", "text", ",", "None", ",", "None", ",", "[", "aspect_term", "]", ")", "\n", "sentences", ".", "append", "(", "sentence", ")", "\n", "", "documents", "=", "[", "AbsaDocument", "(", "sentence", ".", "text", ",", "None", ",", "None", ",", "None", ",", "[", "sentence", "]", ")", "for", "sentence", "in", "sentences", "]", "\n", "data_type_and_data", "[", "data_type", "]", "=", "documents", "\n", "", "return", "data_type_and_data", "[", "'train'", "]", ",", "None", ",", "data_type_and_data", "[", "'test'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Semeval2014Task4._load_semeval_by_filepath": [[274, 325], ["data_type_and_filepath.items", "nlp_tasks.utils.file_utils.read_all_content", "bs4.BeautifulSoup", "bs4.BeautifulSoup.find_all", "sentence_tag.find_all", "sentence_tag.find_all", "data_object.AbsaSentence", "sentences.append", "data_object.AbsaDocument", "data_object.AspectTerm", "aspect_terms.append", "data_object.AspectCategory", "aspect_categories.append"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.read_all_content"], ["def", "_load_semeval_by_filepath", "(", "self", ",", "train_filepath", ",", "test_filepath", ",", "val_filepath", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        :return:\n        \"\"\"", "\n", "data_type_and_datas", "=", "{", "}", "\n", "data_type_and_filepath", "=", "{", "\n", "'train'", ":", "train_filepath", ",", "\n", "'test'", ":", "test_filepath", ",", "\n", "'dev'", ":", "val_filepath", "\n", "}", "\n", "for", "data_type", ",", "filepath", "in", "data_type_and_filepath", ".", "items", "(", ")", ":", "\n", "            ", "if", "filepath", "is", "None", ":", "\n", "                ", "data_type_and_datas", "[", "data_type", "]", "=", "None", "\n", "continue", "\n", "", "content", "=", "file_utils", ".", "read_all_content", "(", "filepath", ")", "\n", "soup", "=", "BeautifulSoup", "(", "content", ",", "\"lxml\"", ")", "\n", "sentence_tags", "=", "soup", ".", "find_all", "(", "'sentence'", ")", "\n", "sentences", "=", "[", "]", "\n", "for", "sentence_tag", "in", "sentence_tags", ":", "\n", "                ", "text", "=", "sentence_tag", ".", "text", "\n", "aspect_term_tags", "=", "sentence_tag", ".", "find_all", "(", "'aspectterm'", ")", "\n", "aspect_terms", "=", "[", "]", "\n", "for", "aspect_term_tag", "in", "aspect_term_tags", ":", "\n", "                    ", "term", "=", "aspect_term_tag", "[", "'term'", "]", "\n", "try", ":", "\n", "                        ", "polarity", "=", "aspect_term_tag", "[", "'polarity'", "]", "\n", "", "except", ":", "\n", "                        ", "polarity", "=", "'positive'", "\n", "", "from_index", "=", "aspect_term_tag", "[", "'from'", "]", "\n", "to_index", "=", "aspect_term_tag", "[", "'to'", "]", "\n", "aspect_term", "=", "AspectTerm", "(", "term", ",", "polarity", ",", "from_index", ",", "to_index", ")", "\n", "aspect_terms", ".", "append", "(", "aspect_term", ")", "\n", "", "aspect_categories", "=", "[", "]", "\n", "aspect_category_tags", "=", "sentence_tag", ".", "find_all", "(", "'aspectcategory'", ")", "\n", "for", "aspect_category_tag", "in", "aspect_category_tags", ":", "\n", "                    ", "category", "=", "aspect_category_tag", "[", "'category'", "]", "\n", "try", ":", "\n", "                        ", "polarity", "=", "aspect_category_tag", "[", "'polarity'", "]", "\n", "", "except", ":", "\n", "                        ", "polarity", "=", "'positive'", "\n", "", "aspect_category", "=", "AspectCategory", "(", "category", ",", "polarity", ")", "\n", "aspect_categories", ".", "append", "(", "aspect_category", ")", "\n", "", "sentence", "=", "AbsaSentence", "(", "text", ",", "None", ",", "aspect_categories", ",", "aspect_terms", ")", "\n", "sentences", ".", "append", "(", "sentence", ")", "\n", "", "documents", "=", "[", "AbsaDocument", "(", "sentence", ".", "text", ",", "None", ",", "None", ",", "None", ",", "[", "sentence", "]", ")", "for", "sentence", "in", "sentences", "]", "\n", "data_type_and_datas", "[", "data_type", "]", "=", "documents", "\n", "", "train_data", "=", "data_type_and_datas", "[", "'train'", "]", "\n", "dev_data", "=", "data_type_and_datas", "[", "'dev'", "]", "\n", "test_data", "=", "data_type_and_datas", "[", "'test'", "]", "\n", "return", "train_data", ",", "dev_data", ",", "test_data", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.MAMSACSA.__init__": [[334, 336], ["data_object.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "configuration", ":", "dict", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "configuration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.MAMSACSA._load_train_dev_test_data": [[337, 345], ["os.path.join", "os.path.join", "os.path.join", "data_object.Semeval2014Task4._load_semeval_by_filepath"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Semeval2014Task4._load_semeval_by_filepath"], ["", "def", "_load_train_dev_test_data", "(", "self", ")", ":", "\n", "        ", "train_filepath", "=", "os", ".", "path", ".", "join", "(", "base_data_dir", ",", "'MAMS-for-ABSA'", ",", "'MAMS-ACSA'", ",", "'raw'", ",", "\n", "\"train.xml\"", ")", "\n", "test_filepath", "=", "os", ".", "path", ".", "join", "(", "base_data_dir", ",", "'MAMS-for-ABSA'", ",", "'MAMS-ACSA'", ",", "'raw'", ",", "\n", "\"test.xml\"", ")", "\n", "val_filepath", "=", "os", ".", "path", ".", "join", "(", "base_data_dir", ",", "'MAMS-for-ABSA'", ",", "'MAMS-ACSA'", ",", "'raw'", ",", "\n", "\"val.xml\"", ")", "\n", "return", "super", "(", ")", ".", "_load_semeval_by_filepath", "(", "train_filepath", ",", "test_filepath", ",", "val_filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.MAMSACSA.generate_acd_and_sc_data": [[346, 382], ["set", "set", "data_object.MAMSACSA.get_data_type_and_data_dict", "data_object.MAMSACSA.items", "data_object.BaseDataset.generate_dev_data", "list", "list.sort", "list", "list.sort", "re.sub", "samples.append", "label.append", "list.add", "list.add"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.get_data_type_and_data_dict", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.generate_dev_data"], ["", "def", "generate_acd_and_sc_data", "(", "self", ",", "dev_size", "=", "0.2", ")", ":", "\n", "        ", "\"\"\"\n\n        :return:\n        \"\"\"", "\n", "result", "=", "{", "\n", "'train'", ":", "None", ",", "\n", "'dev'", ":", "None", ",", "\n", "'test'", ":", "None", "\n", "}", "\n", "distinct_categories", "=", "set", "(", ")", "\n", "distinct_polarities", "=", "set", "(", ")", "\n", "data_type_and_data", "=", "self", ".", "get_data_type_and_data_dict", "(", ")", "\n", "for", "data_type", ",", "data", "in", "data_type_and_data", ".", "items", "(", ")", ":", "\n", "            ", "if", "data", "is", "None", ":", "\n", "                ", "continue", "\n", "", "samples", "=", "[", "]", "\n", "for", "document", "in", "data", ":", "\n", "                ", "for", "sentence", "in", "document", ".", "absa_sentences", ":", "\n", "                    ", "content", "=", "re", ".", "sub", "(", "'[\\r\\n]'", ",", "' '", ",", "sentence", ".", "text", ")", "\n", "label", "=", "[", "]", "\n", "for", "aspect_category", "in", "sentence", ".", "aspect_categories", ":", "\n", "                        ", "category", "=", "aspect_category", ".", "category", "\n", "polarity", "=", "aspect_category", ".", "polarity", "\n", "label", ".", "append", "(", "(", "category", ",", "polarity", ")", ")", "\n", "distinct_categories", ".", "add", "(", "category", ")", "\n", "distinct_polarities", ".", "add", "(", "polarity", ")", "\n", "", "samples", ".", "append", "(", "[", "content", ",", "label", "]", ")", "\n", "", "", "result", "[", "data_type", "]", "=", "samples", "\n", "", "super", "(", ")", ".", "generate_dev_data", "(", "result", ",", "dev_size", ")", "\n", "\n", "distinct_categories", "=", "list", "(", "distinct_categories", ")", "\n", "distinct_categories", ".", "sort", "(", ")", "\n", "distinct_polarities", "=", "list", "(", "distinct_polarities", ")", "\n", "distinct_polarities", ".", "sort", "(", ")", "\n", "return", "result", ",", "distinct_categories", ",", "distinct_polarities", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Semeval2015Task12._load_train_dev_test_data_by_filepath": [[389, 436], ["nlp_tasks.utils.file_utils.read_all_content", "bs4.BeautifulSoup", "bs4.BeautifulSoup.find_all", "datas.append", "datas.append", "doc_tag.find_all", "data_object.AbsaDocument", "docs.append", "sentence_tag.find_all", "data_object.AbsaSentence", "sentences.append", "doc_texts.append", "data_object.AspectTerm", "aspect_terms.append", "data_object.AspectCategory", "aspect_categories.append"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.read_all_content"], ["def", "_load_train_dev_test_data_by_filepath", "(", "self", ",", "train_filepath", ",", "test_filepath", ")", ":", "\n", "        ", "\"\"\"\n\n        :param train_filepath:\n        :param test_filepath:\n        :return:\n        \"\"\"", "\n", "datas", "=", "[", "]", "\n", "for", "filepath", "in", "[", "train_filepath", ",", "test_filepath", "]", ":", "\n", "            ", "if", "filepath", "is", "None", ":", "\n", "                ", "datas", ".", "append", "(", "None", ")", "\n", "continue", "\n", "", "content", "=", "file_utils", ".", "read_all_content", "(", "filepath", ")", "\n", "soup", "=", "BeautifulSoup", "(", "content", ",", "\"lxml\"", ")", "\n", "doc_tags", "=", "soup", ".", "find_all", "(", "'review'", ")", "\n", "docs", "=", "[", "]", "\n", "for", "doc_tag", "in", "doc_tags", ":", "\n", "                ", "sentence_tags", "=", "doc_tag", ".", "find_all", "(", "'sentence'", ")", "\n", "doc_texts", "=", "[", "]", "\n", "sentences", "=", "[", "]", "\n", "for", "sentence_tag", "in", "sentence_tags", ":", "\n", "                    ", "text", "=", "sentence_tag", ".", "text", "\n", "opinion_tags", "=", "sentence_tag", ".", "find_all", "(", "'opinion'", ")", "\n", "aspect_terms", "=", "[", "]", "\n", "aspect_categories", "=", "[", "]", "\n", "for", "opinion_tag", "in", "opinion_tags", ":", "\n", "                        ", "category", "=", "opinion_tag", "[", "'category'", "]", "\n", "polarity", "=", "opinion_tag", "[", "'polarity'", "]", "\n", "if", "'target'", "in", "opinion_tag", ".", "attrs", ":", "\n", "                            ", "term", "=", "opinion_tag", "[", "'target'", "]", "\n", "from_index", "=", "opinion_tag", "[", "'from'", "]", "\n", "to_index", "=", "opinion_tag", "[", "'to'", "]", "\n", "aspect_term", "=", "AspectTerm", "(", "term", ",", "polarity", ",", "from_index", ",", "to_index", ",", "category", ")", "\n", "aspect_terms", ".", "append", "(", "aspect_term", ")", "\n", "", "else", ":", "\n", "                            ", "aspect_category", "=", "AspectCategory", "(", "category", ",", "polarity", ")", "\n", "aspect_categories", ".", "append", "(", "aspect_category", ")", "\n", "", "", "sentence", "=", "AbsaSentence", "(", "text", ",", "None", ",", "aspect_categories", ",", "aspect_terms", ")", "\n", "sentences", ".", "append", "(", "sentence", ")", "\n", "doc_texts", ".", "append", "(", "sentence", ".", "text", ")", "\n", "", "doc", "=", "AbsaDocument", "(", "''", ".", "join", "(", "doc_texts", ")", ",", "None", ",", "None", ",", "None", ",", "sentences", ")", "\n", "docs", ".", "append", "(", "doc", ")", "\n", "", "datas", ".", "append", "(", "docs", ")", "\n", "", "train_data", "=", "datas", "[", "0", "]", "\n", "test_data", "=", "datas", "[", "1", "]", "\n", "dev_data", "=", "None", "\n", "return", "train_data", ",", "dev_data", ",", "test_data", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Semeval2015Task12.generate_acd_and_sc_data": [[437, 493], ["set", "set", "data_object.Semeval2015Task12.get_data_type_and_data_dict", "data_object.Semeval2015Task12.items", "data_object.BaseDataset.generate_dev_data", "list", "list.sort", "list", "list.sort", "re.sub", "aspect_categories_temp.items", "samples.append", "aspect_categories_temp[].add", "len", "set", "len", "label.append", "list.add", "list.add", "label.append", "list.add", "list.add", "polarities.pop", "label.append", "list.add", "list.add", "label.append", "list.add", "list.add"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.get_data_type_and_data_dict", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.generate_dev_data"], ["", "def", "generate_acd_and_sc_data", "(", "self", ",", "dev_size", "=", "0.2", ")", ":", "\n", "        ", "\"\"\"\n\n        :return:\n        \"\"\"", "\n", "result", "=", "{", "\n", "'train'", ":", "None", ",", "\n", "'dev'", ":", "None", ",", "\n", "'test'", ":", "None", "\n", "}", "\n", "distinct_categories", "=", "set", "(", ")", "\n", "distinct_polarities", "=", "set", "(", ")", "\n", "data_type_and_data", "=", "self", ".", "get_data_type_and_data_dict", "(", ")", "\n", "for", "data_type", ",", "data", "in", "data_type_and_data", ".", "items", "(", ")", ":", "\n", "            ", "if", "data", "is", "None", ":", "\n", "                ", "continue", "\n", "", "samples", "=", "[", "]", "\n", "for", "document", "in", "data", ":", "\n", "                ", "for", "sentence", "in", "document", ".", "absa_sentences", ":", "\n", "                    ", "content", "=", "re", ".", "sub", "(", "'[\\r\\n]+'", ",", "' '", ",", "sentence", ".", "text", ")", "\n", "label", "=", "[", "]", "\n", "aspect_categories_temp", "=", "{", "}", "\n", "for", "aspect_term", "in", "sentence", ".", "aspect_terms", ":", "\n", "                        ", "category", "=", "aspect_term", ".", "category", "\n", "polarity", "=", "aspect_term", ".", "polarity", "\n", "if", "category", "not", "in", "aspect_categories_temp", ":", "\n", "                            ", "aspect_categories_temp", "[", "category", "]", "=", "set", "(", ")", "\n", "", "aspect_categories_temp", "[", "category", "]", ".", "add", "(", "polarity", ")", "\n", "", "for", "category", ",", "polarities", "in", "aspect_categories_temp", ".", "items", "(", ")", ":", "\n", "                        ", "if", "len", "(", "polarities", ")", "==", "1", ":", "\n", "                            ", "label", ".", "append", "(", "(", "category", ",", "polarities", ".", "pop", "(", ")", ")", ")", "\n", "distinct_categories", ".", "add", "(", "category", ")", "\n", "distinct_polarities", ".", "add", "(", "polarity", ")", "\n", "", "else", ":", "\n", "                            ", "if", "(", "'positive'", "in", "polarities", "and", "'negative'", "in", "polarities", ")", "or", "'conflict'", "in", "polarities", ":", "\n", "                                ", "label", ".", "append", "(", "(", "category", ",", "'conflict'", ")", ")", "\n", "distinct_categories", ".", "add", "(", "category", ")", "\n", "distinct_polarities", ".", "add", "(", "'conflict'", ")", "\n", "", "elif", "'positive'", "in", "polarities", "and", "'neutral'", "in", "polarities", ":", "\n", "                                ", "label", ".", "append", "(", "(", "category", ",", "'positive'", ")", ")", "\n", "distinct_categories", ".", "add", "(", "category", ")", "\n", "distinct_polarities", ".", "add", "(", "'positive'", ")", "\n", "", "else", ":", "\n", "                                ", "label", ".", "append", "(", "(", "category", ",", "'negative'", ")", ")", "\n", "distinct_categories", ".", "add", "(", "category", ")", "\n", "distinct_polarities", ".", "add", "(", "'negative'", ")", "\n", "", "", "", "if", "len", "(", "label", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "samples", ".", "append", "(", "[", "content", ",", "label", "]", ")", "\n", "", "", "result", "[", "data_type", "]", "=", "samples", "\n", "", "super", "(", ")", ".", "generate_dev_data", "(", "result", ",", "dev_size", ")", "\n", "distinct_categories", "=", "list", "(", "distinct_categories", ")", "\n", "distinct_categories", ".", "sort", "(", ")", "\n", "distinct_polarities", "=", "list", "(", "distinct_polarities", ")", "\n", "distinct_polarities", ".", "sort", "(", ")", "\n", "return", "result", ",", "distinct_categories", ",", "distinct_polarities", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Semeval2016Task5Sub1.generate_aspect_category_detection_data": [[500, 533], ["set", "data_object.Semeval2016Task5Sub1.get_data_type_and_data_dict().items", "list", "list.sort", "sklearn.model_selection.train_test_split", "data_object.Semeval2016Task5Sub1.get_data_type_and_data_dict", "re.sub", "samples.append", "label.append", "list.add"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.get_data_type_and_data_dict"], ["def", "generate_aspect_category_detection_data", "(", "self", ",", "test_size", "=", "0.2", ")", ":", "\n", "        ", "\"\"\"\n\n        :return:\n        \"\"\"", "\n", "result", "=", "{", "\n", "'train'", ":", "None", ",", "\n", "'dev'", ":", "None", ",", "\n", "'test'", ":", "None", "\n", "}", "\n", "distinct_categories", "=", "set", "(", ")", "\n", "for", "data_type", ",", "data", "in", "self", ".", "get_data_type_and_data_dict", "(", ")", ".", "items", "(", ")", ":", "\n", "            ", "if", "data", "is", "None", ":", "\n", "                ", "continue", "\n", "", "samples", "=", "[", "]", "\n", "for", "document", "in", "data", ":", "\n", "                ", "for", "sentence", "in", "document", ".", "absa_sentences", ":", "\n", "                    ", "content", "=", "re", ".", "sub", "(", "'[\\r\\n]'", ",", "' '", ",", "sentence", ".", "text", ")", "\n", "label", "=", "[", "]", "\n", "for", "aspect_category", "in", "sentence", ".", "aspect_categories", ":", "\n", "                        ", "category", "=", "aspect_category", ".", "category", "\n", "label", ".", "append", "(", "category", ")", "\n", "distinct_categories", ".", "add", "(", "category", ")", "\n", "", "samples", ".", "append", "(", "[", "content", ",", "label", "]", ")", "\n", "", "", "result", "[", "data_type", "]", "=", "samples", "\n", "", "if", "result", "[", "'dev'", "]", "is", "None", ":", "\n", "            ", "original_train_samples", "=", "result", "[", "'train'", "]", "\n", "train_samples", ",", "dev_samples", "=", "train_test_split", "(", "original_train_samples", ",", "test_size", "=", "test_size", ")", "\n", "result", "[", "'train'", "]", "=", "train_samples", "\n", "result", "[", "'dev'", "]", "=", "dev_samples", "\n", "", "distinct_categories", "=", "list", "(", "distinct_categories", ")", "\n", "distinct_categories", ".", "sort", "(", ")", "\n", "return", "result", ",", "distinct_categories", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Semeval2016Task5Sub2._load_train_dev_test_data_by_filepath": [[540, 588], ["nlp_tasks.utils.file_utils.read_all_content", "bs4.BeautifulSoup", "bs4.BeautifulSoup.find_all", "datas.append", "datas.append", "doc_tag.find_all", "doc_tag.find_all", "data_object.AbsaDocument", "docs.append", "data_object.AbsaSentence", "sentences.append", "doc_texts.append", "data_object.AspectTerm", "aspect_terms.append", "data_object.AspectCategory", "aspect_categories.append"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.read_all_content"], ["def", "_load_train_dev_test_data_by_filepath", "(", "self", ",", "train_filepath", ",", "test_filepath", ")", ":", "\n", "        ", "\"\"\"\n\n        :param train_filepath:\n        :param test_filepath:\n        :return:\n        \"\"\"", "\n", "datas", "=", "[", "]", "\n", "for", "filepath", "in", "[", "train_filepath", ",", "test_filepath", "]", ":", "\n", "            ", "if", "filepath", "is", "None", ":", "\n", "                ", "datas", ".", "append", "(", "None", ")", "\n", "continue", "\n", "", "content", "=", "file_utils", ".", "read_all_content", "(", "filepath", ")", "\n", "soup", "=", "BeautifulSoup", "(", "content", ",", "\"lxml\"", ")", "\n", "doc_tags", "=", "soup", ".", "find_all", "(", "'review'", ")", "\n", "docs", "=", "[", "]", "\n", "for", "doc_tag", "in", "doc_tags", ":", "\n", "                ", "sentence_tags", "=", "doc_tag", ".", "find_all", "(", "'sentence'", ")", "\n", "doc_texts", "=", "[", "]", "\n", "sentences", "=", "[", "]", "\n", "for", "sentence_tag", "in", "sentence_tags", ":", "\n", "                    ", "text", "=", "sentence_tag", ".", "text", "\n", "sentence", "=", "AbsaSentence", "(", "text", ",", "None", ",", "None", ",", "None", ")", "\n", "sentences", ".", "append", "(", "sentence", ")", "\n", "doc_texts", ".", "append", "(", "sentence", ".", "text", ")", "\n", "\n", "", "opinion_tags", "=", "doc_tag", ".", "find_all", "(", "'opinion'", ")", "\n", "aspect_terms", "=", "[", "]", "\n", "aspect_categories", "=", "[", "]", "\n", "for", "opinion_tag", "in", "opinion_tags", ":", "\n", "                    ", "category", "=", "opinion_tag", "[", "'category'", "]", "\n", "polarity", "=", "opinion_tag", "[", "'polarity'", "]", "\n", "if", "'target'", "in", "opinion_tag", ":", "\n", "                        ", "term", "=", "opinion_tag", "[", "'target'", "]", "\n", "from_index", "=", "opinion_tag", "[", "'from'", "]", "\n", "to_index", "=", "opinion_tag", "[", "'to'", "]", "\n", "aspect_term", "=", "AspectTerm", "(", "term", ",", "polarity", ",", "from_index", ",", "to_index", ",", "category", ")", "\n", "aspect_terms", ".", "append", "(", "aspect_term", ")", "\n", "", "else", ":", "\n", "                        ", "aspect_category", "=", "AspectCategory", "(", "category", ",", "polarity", ")", "\n", "aspect_categories", ".", "append", "(", "aspect_category", ")", "\n", "", "", "doc", "=", "AbsaDocument", "(", "''", ".", "join", "(", "doc_texts", ")", ",", "None", ",", "aspect_categories", ",", "aspect_terms", ",", "sentences", ")", "\n", "docs", ".", "append", "(", "doc", ")", "\n", "", "datas", ".", "append", "(", "docs", ")", "\n", "", "train_data", "=", "datas", "[", "0", "]", "\n", "test_data", "=", "datas", "[", "1", "]", "\n", "dev_data", "=", "None", "\n", "return", "train_data", ",", "dev_data", ",", "test_data", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Semeval2016Task5Sub2.generate_acd_and_sc_data": [[589, 634], ["set", "set", "data_object.Semeval2016Task5Sub2.get_data_type_and_data_dict", "data_object.Semeval2016Task5Sub2.items", "data_object.BaseDataset.generate_dev_data", "result.items", "list", "list.sort", "list", "list.sort", "list", "list.sort", "logger.info", "re.sub", "samples.append", "list.items", "label.append", "list.add", "list.add", "str"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.get_data_type_and_data_dict", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.generate_dev_data"], ["", "def", "generate_acd_and_sc_data", "(", "self", ",", "dev_size", "=", "0.2", ",", "random_state", "=", "1234", ")", ":", "\n", "        ", "\"\"\"\n\n        :return:\n        \"\"\"", "\n", "result", "=", "{", "\n", "'train'", ":", "None", ",", "\n", "'dev'", ":", "None", ",", "\n", "'test'", ":", "None", "\n", "}", "\n", "distinct_categories", "=", "set", "(", ")", "\n", "distinct_polarities", "=", "set", "(", ")", "\n", "data_type_and_data", "=", "self", ".", "get_data_type_and_data_dict", "(", ")", "\n", "for", "data_type", ",", "data", "in", "data_type_and_data", ".", "items", "(", ")", ":", "\n", "            ", "if", "data", "is", "None", ":", "\n", "                ", "continue", "\n", "", "samples", "=", "[", "]", "\n", "for", "document", "in", "data", ":", "\n", "                ", "content", "=", "re", ".", "sub", "(", "'[\\r\\n]'", ",", "' '", ",", "document", ".", "text", ")", "\n", "label", "=", "[", "]", "\n", "for", "aspect_category", "in", "document", ".", "aspect_categories", ":", "\n", "                    ", "category", "=", "aspect_category", ".", "category", "\n", "polarity", "=", "aspect_category", ".", "polarity", "\n", "label", ".", "append", "(", "(", "category", ",", "polarity", ")", ")", "\n", "distinct_categories", ".", "add", "(", "category", ")", "\n", "distinct_polarities", ".", "add", "(", "polarity", ")", "\n", "", "samples", ".", "append", "(", "[", "content", ",", "label", "]", ")", "\n", "", "result", "[", "data_type", "]", "=", "samples", "\n", "", "super", "(", ")", ".", "generate_dev_data", "(", "result", ",", "dev_size", ",", "random_state", "=", "random_state", ")", "\n", "for", "data_type", ",", "data", "in", "result", ".", "items", "(", ")", ":", "\n", "            ", "category_distribution", "=", "{", "}", "\n", "for", "sample", "in", "data", ":", "\n", "                ", "sample_labels", "=", "[", "e", "[", "0", "]", "for", "e", "in", "sample", "[", "1", "]", "]", "\n", "for", "sample_label", "in", "sample_labels", ":", "\n", "                    ", "if", "sample_label", "not", "in", "category_distribution", ":", "\n", "                        ", "category_distribution", "[", "sample_label", "]", "=", "0", "\n", "", "category_distribution", "[", "sample_label", "]", "+=", "1", "\n", "", "", "category_distribution", "=", "list", "(", "category_distribution", ".", "items", "(", ")", ")", "\n", "category_distribution", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "logger", ".", "info", "(", "'%s: %s'", "%", "(", "data_type", ",", "str", "(", "category_distribution", ")", ")", ")", "\n", "", "distinct_categories", "=", "list", "(", "distinct_categories", ")", "\n", "distinct_categories", ".", "sort", "(", ")", "\n", "distinct_polarities", "=", "list", "(", "distinct_polarities", ")", "\n", "distinct_polarities", ".", "sort", "(", ")", "\n", "return", "result", ",", "distinct_categories", ",", "distinct_polarities", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Semeval2016Task5Sub2.generate_aspect_category_detection_data": [[635, 667], ["set", "data_object.Semeval2016Task5Sub2.get_data_type_and_data_dict().items", "list", "list.sort", "sklearn.model_selection.train_test_split", "data_object.Semeval2016Task5Sub2.get_data_type_and_data_dict", "re.sub", "samples.append", "label.append", "list.add"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.get_data_type_and_data_dict"], ["", "def", "generate_aspect_category_detection_data", "(", "self", ",", "test_size", "=", "0.2", ")", ":", "\n", "        ", "\"\"\"\n\n        :return:\n        \"\"\"", "\n", "result", "=", "{", "\n", "'train'", ":", "None", ",", "\n", "'dev'", ":", "None", ",", "\n", "'test'", ":", "None", "\n", "}", "\n", "distinct_categories", "=", "set", "(", ")", "\n", "for", "data_type", ",", "data", "in", "self", ".", "get_data_type_and_data_dict", "(", ")", ".", "items", "(", ")", ":", "\n", "            ", "if", "data", "is", "None", ":", "\n", "                ", "continue", "\n", "", "samples", "=", "[", "]", "\n", "for", "document", "in", "data", ":", "\n", "                ", "content", "=", "re", ".", "sub", "(", "'[\\r\\n]'", ",", "' '", ",", "document", ".", "text", ")", "\n", "label", "=", "[", "]", "\n", "for", "aspect_category", "in", "document", ".", "aspect_categories", ":", "\n", "                    ", "category", "=", "aspect_category", ".", "category", "\n", "label", ".", "append", "(", "category", ")", "\n", "distinct_categories", ".", "add", "(", "category", ")", "\n", "", "samples", ".", "append", "(", "[", "content", ",", "label", "]", ")", "\n", "", "result", "[", "data_type", "]", "=", "samples", "\n", "", "if", "result", "[", "'dev'", "]", "is", "None", ":", "\n", "            ", "original_train_samples", "=", "result", "[", "'train'", "]", "\n", "train_samples", ",", "dev_samples", "=", "train_test_split", "(", "original_train_samples", ",", "test_size", "=", "test_size", ")", "\n", "result", "[", "'train'", "]", "=", "train_samples", "\n", "result", "[", "'dev'", "]", "=", "dev_samples", "\n", "", "distinct_categories", "=", "list", "(", "distinct_categories", ")", "\n", "distinct_categories", ".", "sort", "(", ")", "\n", "return", "result", ",", "distinct_categories", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Semeval2014Task4RestDevSplits.__init__": [[694, 699], ["data_object.BaseDataset.__init__", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__"], ["def", "__init__", "(", "self", ",", "configuration", ":", "dict", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "configuration", ")", "\n", "self", ".", "conceptnet_augment_data_filepath", "=", "os", ".", "path", ".", "join", "(", "base_data_dir", ",", "'SemEval-2014-Task-4-REST'", ",", "'origin'", ",", "\n", "\"SemEval'14-ABSA-TrainData_v2 & AnnotationGuidelines\"", ",", "\n", "'conceptnet_augment_data.pkl'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Semeval2014Task4RestDevSplits._load_train_dev_test_data": [[700, 743], ["os.path.join", "os.path.join", "open", "in_file.read", "in_file.read.splitlines", "pickle.loads", "line.split", "line.split", "nlp_tasks.utils.file_utils.read_all_lines", "text_and_categories.items", "datasets.append", "str.encode", "data_object.AspectCategory", "text_and_categories[].append", "data_object.AbsaSentence", "data_object.AbsaDocument", "dataset.append"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.read_all_lines"], ["", "def", "_load_train_dev_test_data", "(", "self", ")", ":", "\n", "        ", "sentence_map_filepath", "=", "os", ".", "path", ".", "join", "(", "base_data_dir", ",", "'ABSA_DevSplits'", ",", "'dataset'", ",", "\n", "'sentence_map.txt'", ")", "\n", "sentence_map", "=", "{", "line", ".", "split", "(", "'\\t'", ")", "[", "0", "]", ":", "line", ".", "split", "(", "'\\t'", ")", "[", "1", "]", "for", "line", "in", "\n", "file_utils", ".", "read_all_lines", "(", "sentence_map_filepath", ",", "strip_type", "=", "'line_separator'", ")", "}", "\n", "\n", "data_filepath", "=", "os", ".", "path", ".", "join", "(", "base_data_dir", ",", "'ABSA_DevSplits'", ",", "'dataset'", ",", "\n", "'Restaurants_category.pkl'", ")", "\n", "polarity_index_and_text", "=", "{", "\n", "0", ":", "'negative'", ",", "\n", "1", ":", "'positive'", ",", "\n", "2", ":", "'neutral'", "\n", "}", "\n", "datasets", "=", "[", "]", "\n", "with", "open", "(", "data_filepath", ",", "mode", "=", "'rb'", ")", "as", "in_file", ":", "\n", "            ", "content", "=", "in_file", ".", "read", "(", ")", "\n", "content_correct", "=", "b''", "\n", "for", "line", "in", "content", ".", "splitlines", "(", ")", ":", "\n", "                ", "content_correct", "+=", "line", "+", "str", ".", "encode", "(", "'\\n'", ")", "\n", "", "data", "=", "pickle", ".", "loads", "(", "content_correct", ",", "encoding", "=", "'utf-8'", ")", "\n", "# data = pickle.load(in_file, encoding='utf-8')", "\n", "datasets_indexed", "=", "[", "data", "[", "'train'", "]", ",", "data", "[", "'dev'", "]", ",", "data", "[", "'test'", "]", "]", "\n", "index2word", "=", "data", "[", "'index_word'", "]", "\n", "for", "dataset_indexed", "in", "datasets_indexed", ":", "\n", "                ", "dataset", "=", "[", "]", "\n", "text_and_categories", "=", "{", "}", "\n", "for", "sample", "in", "dataset_indexed", ":", "\n", "                    ", "words", "=", "[", "index2word", "[", "index", "]", "for", "index", "in", "sample", "[", "0", "]", "]", "\n", "text", "=", "' '", ".", "join", "(", "words", ")", "\n", "category", "=", "[", "index2word", "[", "index", "]", "for", "index", "in", "sample", "[", "2", "]", "]", "[", "0", "]", "\n", "polarity", "=", "polarity_index_and_text", "[", "sample", "[", "4", "]", "]", "\n", "aspect_category", "=", "AspectCategory", "(", "category", ",", "polarity", ")", "\n", "if", "text", "not", "in", "text_and_categories", ":", "\n", "                        ", "text_and_categories", "[", "text", "]", "=", "[", "]", "\n", "", "text_and_categories", "[", "text", "]", ".", "append", "(", "aspect_category", ")", "\n", "", "for", "text", ",", "categories", "in", "text_and_categories", ".", "items", "(", ")", ":", "\n", "                    ", "text", "=", "sentence_map", "[", "text", "]", "\n", "sentence", "=", "AbsaSentence", "(", "text", ",", "None", ",", "categories", ",", "None", ")", "\n", "document", "=", "AbsaDocument", "(", "sentence", ".", "text", ",", "None", ",", "None", ",", "None", ",", "[", "sentence", "]", ")", "\n", "dataset", ".", "append", "(", "document", ")", "\n", "", "datasets", ".", "append", "(", "dataset", ")", "\n", "\n", "", "", "return", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.Semeval2014Task4RestDevSplits.generate_acd_and_sc_data": [[744, 779], ["set", "set", "data_object.Semeval2014Task4RestDevSplits.get_data_type_and_data_dict", "data_object.Semeval2014Task4RestDevSplits.items", "data_object.BaseDataset.generate_dev_data", "list", "list.sort", "list", "list.sort", "re.sub", "samples.append", "label.append", "list.add", "list.add"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.get_data_type_and_data_dict", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.BaseDataset.generate_dev_data"], ["", "def", "generate_acd_and_sc_data", "(", "self", ",", "dev_size", "=", "0.2", ")", ":", "\n", "        ", "\"\"\"\n\n        :return:\n        \"\"\"", "\n", "result", "=", "{", "\n", "'train'", ":", "None", ",", "\n", "'dev'", ":", "None", ",", "\n", "'test'", ":", "None", "\n", "}", "\n", "distinct_categories", "=", "set", "(", ")", "\n", "distinct_polarities", "=", "set", "(", ")", "\n", "data_type_and_data", "=", "self", ".", "get_data_type_and_data_dict", "(", ")", "\n", "for", "data_type", ",", "data", "in", "data_type_and_data", ".", "items", "(", ")", ":", "\n", "            ", "if", "data", "is", "None", ":", "\n", "                ", "continue", "\n", "", "samples", "=", "[", "]", "\n", "for", "document", "in", "data", ":", "\n", "                ", "for", "sentence", "in", "document", ".", "absa_sentences", ":", "\n", "                    ", "content", "=", "re", ".", "sub", "(", "'[\\r\\n]'", ",", "' '", ",", "sentence", ".", "text", ")", "\n", "label", "=", "[", "]", "\n", "for", "aspect_category", "in", "sentence", ".", "aspect_categories", ":", "\n", "                        ", "category", "=", "aspect_category", ".", "category", "\n", "polarity", "=", "aspect_category", ".", "polarity", "\n", "label", ".", "append", "(", "(", "category", ",", "polarity", ")", ")", "\n", "distinct_categories", ".", "add", "(", "category", ")", "\n", "distinct_polarities", ".", "add", "(", "polarity", ")", "\n", "", "samples", ".", "append", "(", "[", "content", ",", "label", "]", ")", "\n", "", "", "result", "[", "data_type", "]", "=", "samples", "\n", "", "super", "(", ")", ".", "generate_dev_data", "(", "result", ",", "dev_size", ")", "\n", "distinct_categories", "=", "list", "(", "distinct_categories", ")", "\n", "distinct_categories", ".", "sort", "(", ")", "\n", "distinct_polarities", "=", "list", "(", "distinct_polarities", ")", "\n", "distinct_polarities", ".", "sort", "(", ")", "\n", "return", "result", ",", "distinct_categories", ",", "distinct_polarities", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.load_csv_data": [[669, 687], ["nlp_tasks.utils.file_utils.read_all_lines", "csv.reader", "result.append", "len", "len", "print"], "function", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.read_all_lines"], ["", "", "def", "load_csv_data", "(", "filepath", ",", "skip_first_line", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n\n    :param filepath:\n    :param skip_first_line:\n    :return:\n    \"\"\"", "\n", "result", "=", "[", "]", "\n", "lines", "=", "file_utils", ".", "read_all_lines", "(", "filepath", ")", "\n", "for", "line", "in", "lines", ":", "\n", "        ", "rows", "=", "csv", ".", "reader", "(", "[", "line", "]", ")", "\n", "for", "row", "in", "rows", ":", "\n", "            ", "result", ".", "append", "(", "row", ")", "\n", "if", "len", "(", "row", ")", "!=", "len", "(", "result", "[", "0", "]", ")", ":", "\n", "                ", "print", "(", "row", ")", "\n", "", "", "", "if", "skip_first_line", ":", "\n", "        ", "result", "=", "result", "[", "1", ":", "]", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.get_dataset_class_by_name": [[787, 794], ["None"], "function", ["None"], ["def", "get_dataset_class_by_name", "(", "dataset_name", ")", ":", "\n", "    ", "\"\"\"\n\n    :param dataset_name:\n    :return:\n    \"\"\"", "\n", "return", "suported_dataset_names_and_data_loader", "[", "dataset_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate.__init__": [[27, 77], ["logging.getLogger", "ModelTrainTemplate.ModelTrainTemplate.logger.setLevel", "logging.Formatter", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "ModelTrainTemplate.ModelTrainTemplate.logger.addHandler", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "ModelTrainTemplate.ModelTrainTemplate.logger.addHandler", "ModelTrainTemplate.ModelTrainTemplate._get_dataset", "os.path.exists", "os.makedirs", "os.path.exists", "nlp_tasks.utils.file_utils.rm_r", "os.path.exists", "os.makedirs", "ModelTrainTemplate.ModelTrainTemplate._load_model_meta_data", "ModelTrainTemplate.ModelTrainTemplate._load_model", "os.path.exists", "os.makedirs"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._get_dataset", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.rm_r", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_model_meta_data", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_model"], ["def", "__init__", "(", "self", ",", "configuration", ":", "dict", ")", ":", "\n", "        ", "self", ".", "configuration", "=", "configuration", "\n", "if", "'data_type'", "not", "in", "self", ".", "configuration", ":", "\n", "            ", "self", ".", "configuration", "[", "'data_type'", "]", "=", "'common'", "\n", "", "self", ".", "base_data_dir", "=", "task_dir", "+", "(", "'{task_name}/{current_dataset}/{data_type}/'", ".", "format_map", "(", "self", ".", "configuration", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "base_data_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "base_data_dir", ")", "\n", "", "self", ".", "embedding_matrix_file_path", "=", "self", ".", "base_data_dir", "+", "'embedding_matrix'", "\n", "self", ".", "keras_tokenizer_file_path", "=", "self", ".", "base_data_dir", "+", "'keras_tokenizer'", "\n", "\n", "self", ".", "base_model_dir", "=", "self", ".", "base_data_dir", "+", "(", "'{model_name_complete}/{timestamp}/'", ".", "format_map", "(", "self", ".", "configuration", ")", ")", "\n", "self", ".", "model_dir", "=", "self", ".", "base_model_dir", "+", "'models/'", "\n", "if", "self", ".", "configuration", "[", "'train'", "]", "and", "os", ".", "path", ".", "exists", "(", "self", ".", "model_dir", ")", ":", "\n", "            ", "file_utils", ".", "rm_r", "(", "self", ".", "model_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "model_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "model_dir", ")", "\n", "", "self", ".", "best_model_filepath", "=", "self", ".", "model_dir", "+", "self", ".", "configuration", "[", "'model_name'", "]", "+", "'.hdf5'", "\n", "self", ".", "model_meta_data_filepath", "=", "self", ".", "model_dir", "+", "self", ".", "configuration", "[", "'model_name'", "]", "+", "'.model_meta_data'", "\n", "self", ".", "model_meta_data", "=", "{", "}", "\n", "self", ".", "model", "=", "None", "\n", "if", "not", "self", ".", "configuration", "[", "'train'", "]", ":", "\n", "            ", "self", ".", "_load_model_meta_data", "(", ")", "\n", "self", ".", "_load_model", "(", ")", "\n", "\n", "", "self", ".", "model_log_dir", "=", "self", ".", "base_model_dir", "+", "'model-log/'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "model_log_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "model_log_dir", ")", "\n", "\n", "# log", "\n", "", "logger_name", "=", "'performance'", "\n", "log_filepath", "=", "self", ".", "base_model_dir", "+", "(", "'%s.log'", "%", "logger_name", ")", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "logger_name", ")", "\n", "self", ".", "logger", ".", "propagate", "=", "False", "\n", "logging_level", "=", "logging", ".", "INFO", "\n", "self", ".", "logger", ".", "setLevel", "(", "logging_level", ")", "\n", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'%(filename)s-%(lineno)d-%(asctime)s-%(message)s'", ")", "\n", "\n", "console", "=", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "\n", "console", ".", "setLevel", "(", "logging_level", ")", "\n", "console", ".", "setFormatter", "(", "formatter", ")", "\n", "self", ".", "logger", ".", "addHandler", "(", "console", ")", "\n", "\n", "file", "=", "logging", ".", "FileHandler", "(", "log_filepath", ")", "\n", "file", ".", "setLevel", "(", "logging_level", ")", "\n", "file", ".", "setFormatter", "(", "formatter", ")", "\n", "self", ".", "logger", ".", "addHandler", "(", "file", ")", "\n", "\n", "self", ".", "dataset", "=", "self", ".", "_get_dataset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._get_dataset": [[78, 80], ["nlp_tasks.absa.data_adapter.data_object.get_dataset_class_by_name"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.data_adapter.data_object.get_dataset_class_by_name"], ["", "def", "_get_dataset", "(", "self", ")", ":", "\n", "        ", "return", "data_object", ".", "get_dataset_class_by_name", "(", "self", ".", "configuration", "[", "'current_dataset'", "]", ")", "(", "self", ".", "configuration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_word_vec": [[81, 92], ["open", "line.rstrip().split", "line.rstrip", "word2idx.keys", "numpy.asarray"], "methods", ["None"], ["", "def", "_load_word_vec", "(", "self", ",", "path", ",", "word2idx", "=", "None", ")", ":", "\n", "        ", "fin", "=", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ",", "newline", "=", "'\\n'", ",", "errors", "=", "'ignore'", ")", "\n", "word_vec", "=", "{", "}", "\n", "for", "line", "in", "fin", ":", "\n", "            ", "tokens", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", ")", "\n", "if", "word2idx", "is", "None", "or", "tokens", "[", "0", "]", "in", "word2idx", ".", "keys", "(", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "word_vec", "[", "tokens", "[", "0", "]", "]", "=", "np", ".", "asarray", "(", "tokens", "[", "1", ":", "]", ",", "dtype", "=", "'float32'", ")", "\n", "", "except", ":", "\n", "                    ", "continue", "\n", "", "", "", "return", "word_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._build_embedding_matrix": [[93, 110], ["os.path.exists", "print", "pickle.load", "print", "numpy.zeros", "numpy.random.uniform", "ModelTrainTemplate.ModelTrainTemplate._load_word_vec", "print", "word2idx.items", "pickle.dump", "open", "ModelTrainTemplate.ModelTrainTemplate.get", "open", "numpy.sqrt", "numpy.sqrt", "len"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_word_vec"], ["", "def", "_build_embedding_matrix", "(", "self", ",", "embedding_filepath", ",", "word2idx", ",", "embed_dim", ")", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "embedding_matrix_file_path", ")", ":", "\n", "            ", "print", "(", "'loading embedding_matrix:'", ",", "self", ".", "embedding_matrix_file_path", ")", "\n", "embedding_matrix", "=", "pickle", ".", "load", "(", "open", "(", "self", ".", "embedding_matrix_file_path", ",", "'rb'", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'loading word vectors ...'", ")", "\n", "embedding_matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "word2idx", ")", "+", "1", ",", "embed_dim", ")", ")", "# idx 0 and 1 are all-zeros", "\n", "embedding_matrix", "[", "1", ",", ":", "]", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", "/", "np", ".", "sqrt", "(", "embed_dim", ")", ",", "1", "/", "np", ".", "sqrt", "(", "embed_dim", ")", ",", "(", "1", ",", "embed_dim", ")", ")", "\n", "word_vec", "=", "self", ".", "_load_word_vec", "(", "embedding_filepath", ",", "word2idx", "=", "word2idx", ")", "\n", "print", "(", "'building embedding_matrix:'", ",", "self", ".", "embedding_matrix_file_path", ")", "\n", "for", "word", ",", "i", "in", "word2idx", ".", "items", "(", ")", ":", "\n", "                ", "vec", "=", "word_vec", ".", "get", "(", "word", ")", "\n", "if", "vec", "is", "not", "None", ":", "\n", "# words not found in embedding index will be all-zeros.", "\n", "                    ", "embedding_matrix", "[", "i", "]", "=", "vec", "\n", "", "", "pickle", ".", "dump", "(", "embedding_matrix", ",", "open", "(", "self", ".", "embedding_matrix_file_path", ",", "'wb'", ")", ")", "\n", "", "return", "embedding_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_data": [[111, 113], ["None"], "methods", ["None"], ["", "def", "_load_data", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._save_model": [[114, 116], ["None"], "methods", ["None"], ["", "def", "_save_model", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._save_model_meta_data": [[117, 120], ["open", "pickle.dump"], "methods", ["None"], ["", "def", "_save_model_meta_data", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "model_meta_data_filepath", ",", "mode", "=", "'wb'", ")", "as", "meta_data_file", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "model_meta_data", ",", "meta_data_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_model_meta_data": [[121, 124], ["open", "pickle.load"], "methods", ["None"], ["", "", "def", "_load_model_meta_data", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "model_meta_data_filepath", ",", "mode", "=", "'rb'", ")", "as", "meta_data_file", ":", "\n", "            ", "self", ".", "model_meta_data", "=", "pickle", ".", "load", "(", "meta_data_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._save_object": [[125, 128], ["open", "pickle.dump"], "methods", ["None"], ["", "", "def", "_save_object", "(", "self", ",", "filepath", ",", "data", ")", ":", "\n", "        ", "with", "open", "(", "filepath", ",", "mode", "=", "'wb'", ")", "as", "data_file", ":", "\n", "            ", "pickle", ".", "dump", "(", "data", ",", "data_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_object": [[129, 133], ["open", "pickle.load"], "methods", ["None"], ["", "", "def", "_load_object", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "with", "open", "(", "filepath", ",", "mode", "=", "'rb'", ")", "as", "data_file", ":", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "data_file", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_model": [[134, 136], ["None"], "methods", ["None"], ["", "", "def", "_load_model", "(", "self", ",", "return_model_meta_data", "=", "False", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._get_word_segmenter": [[137, 145], ["nlp_tasks.utils.tokenizers.JiebaTokenizer", "nlp_tasks.utils.word_processor.LowerProcessor", "nlp_tasks.utils.tokenizers.SpacyTokenizer"], "methods", ["None"], ["", "def", "_get_word_segmenter", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "configuration", "[", "'current_dataset'", "]", "in", "[", "'SemEval-2016-Task-5-CH-CAME-SB1'", ",", "\n", "'SemEval-2016-Task-5-CH-PHNS-SB1'", "]", ":", "\n", "            ", "word_segmenter", "=", "tokenizers", ".", "JiebaTokenizer", "(", ")", "\n", "", "else", ":", "\n", "            ", "word_processor1", "=", "word_processor", ".", "LowerProcessor", "(", ")", "\n", "word_segmenter", "=", "tokenizers", ".", "SpacyTokenizer", "(", "word_processor", "=", "word_processor1", ")", "\n", "", "return", "word_segmenter", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._get_keras_tokenizer": [[146, 155], ["os.path.exists", "ModelTrainTemplate.ModelTrainTemplate._get_word_segmenter", "nlp_tasks.utils.tokenizer_wrappers.TokenizerWithCustomWordSegmenter", "ModelTrainTemplate.ModelTrainTemplate.fit_on_texts", "ModelTrainTemplate.ModelTrainTemplate._save_object", "ModelTrainTemplate.ModelTrainTemplate._load_object"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._get_word_segmenter", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.tokenizer_wrappers.TokenizerWithCustomWordSegmenter.fit_on_texts", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._save_object", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_object"], ["", "def", "_get_keras_tokenizer", "(", "self", ",", "texts", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "keras_tokenizer_file_path", ")", ":", "\n", "            ", "word_segmenter", "=", "self", ".", "_get_word_segmenter", "(", ")", "\n", "keras_tokenizer", "=", "tokenizer_wrappers", ".", "TokenizerWithCustomWordSegmenter", "(", "word_segmenter", ",", "oov_token", "=", "'oov'", ")", "\n", "keras_tokenizer", ".", "fit_on_texts", "(", "texts", ")", "\n", "self", ".", "_save_object", "(", "self", ".", "keras_tokenizer_file_path", ",", "keras_tokenizer", ")", "\n", "", "else", ":", "\n", "            ", "keras_tokenizer", "=", "self", ".", "_load_object", "(", "self", ".", "keras_tokenizer_file_path", ")", "\n", "", "return", "keras_tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._find_model_function": [[156, 161], ["None"], "methods", ["None"], ["", "def", "_find_model_function", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :return:\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._transform_data_for_model": [[162, 167], ["None"], "methods", ["None"], ["", "def", "_transform_data_for_model", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :return:\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._transform_label_for_model": [[168, 170], ["None"], "methods", ["None"], ["", "def", "_transform_label_for_model", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._get_word_index": [[171, 173], ["None"], "methods", ["None"], ["", "def", "_get_word_index", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._inner_train": [[174, 176], ["None"], "methods", ["None"], ["", "def", "_inner_train", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate.train": [[177, 182], ["ModelTrainTemplate.ModelTrainTemplate._inner_train", "ModelTrainTemplate.ModelTrainTemplate._save_model_meta_data", "ModelTrainTemplate.ModelTrainTemplate._save_model", "ModelTrainTemplate.ModelTrainTemplate._load_model"], "methods", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._inner_train", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._save_model_meta_data", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._save_model", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate._load_model"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "_inner_train", "(", ")", "\n", "self", ".", "_save_model_meta_data", "(", ")", "\n", "self", ".", "_save_model", "(", ")", "\n", "self", ".", "_load_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate.evaluate": [[183, 185], ["None"], "methods", ["None"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.entities.ModelTrainTemplate.ModelTrainTemplate.observe": [[186, 188], ["None"], "methods", ["None"], ["", "def", "observe", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SingleSentenceGenerator.__init__": [[38, 47], ["len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "tokenizer", ",", "batch_size", "=", "32", ",", "maxlen", "=", "512", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "self", ".", "data", "=", "data", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "steps", "=", "len", "(", "self", ".", "data", ")", "//", "self", ".", "batch_size", "\n", "if", "len", "(", "self", ".", "data", ")", "%", "self", ".", "batch_size", "!=", "0", ":", "\n", "            ", "self", ".", "steps", "+=", "1", "\n", "", "self", ".", "maxlen", "=", "maxlen", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SingleSentenceGenerator.__len__": [[48, 50], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "steps", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SingleSentenceGenerator.__iter__": [[51, 71], ["list", "range", "numpy.random.shuffle", "data_adapter.SingleSentenceGenerator.tokenizer.encode", "keras.preprocessing.sequence.pad_sequences.append", "keras.preprocessing.sequence.pad_sequences.append", "numpy.array.append", "len", "keras.preprocessing.sequence.pad_sequences", "keras.preprocessing.sequence.pad_sequences", "numpy.array", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "idxs", "=", "list", "(", "range", "(", "len", "(", "self", ".", "data", ")", ")", ")", "\n", "if", "self", ".", "shuffle", ":", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "idxs", ")", "\n", "", "X1", ",", "X2", ",", "Y", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "idxs", ":", "\n", "                ", "d", "=", "self", ".", "data", "[", "i", "]", "\n", "text", "=", "d", "[", "0", "]", "[", ":", "self", ".", "maxlen", "]", "\n", "x1", ",", "x2", "=", "self", ".", "tokenizer", ".", "encode", "(", "first", "=", "text", ")", "\n", "y", "=", "d", "[", "1", "]", "\n", "X1", ".", "append", "(", "x1", ")", "\n", "X2", ".", "append", "(", "x2", ")", "\n", "Y", ".", "append", "(", "[", "y", "]", ")", "\n", "if", "len", "(", "X1", ")", "==", "self", ".", "batch_size", "or", "i", "==", "idxs", "[", "-", "1", "]", ":", "\n", "                    ", "X1", "=", "sequence", ".", "pad_sequences", "(", "X1", ",", "maxlen", "=", "self", ".", "maxlen", ")", "\n", "X2", "=", "sequence", ".", "pad_sequences", "(", "X2", ",", "maxlen", "=", "self", ".", "maxlen", ")", "\n", "Y", "=", "np", ".", "array", "(", "Y", ")", "\n", "yield", "[", "X1", ",", "X2", "]", ",", "Y", "\n", "[", "X1", ",", "X2", ",", "Y", "]", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__init__": [[76, 86], ["len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "tokenizer", ",", "batch_size", "=", "32", ",", "maxlen", "=", "512", ",", "shuffle", "=", "False", ",", "class_num", "=", "2", ")", ":", "\n", "        ", "self", ".", "data", "=", "data", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "steps", "=", "len", "(", "self", ".", "data", ")", "//", "self", ".", "batch_size", "\n", "if", "len", "(", "self", ".", "data", ")", "%", "self", ".", "batch_size", "!=", "0", ":", "\n", "            ", "self", ".", "steps", "+=", "1", "\n", "", "self", ".", "maxlen", "=", "maxlen", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "class_num", "=", "class_num", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__len__": [[87, 89], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "steps", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.SentencePairGenerator.__iter__": [[90, 115], ["list", "range", "numpy.random.shuffle", "data_adapter.SentencePairGenerator.tokenizer.encode", "keras.preprocessing.sequence.pad_sequences.append", "keras.preprocessing.sequence.pad_sequences.append", "numpy.array.append", "len", "keras.preprocessing.sequence.pad_sequences", "keras.preprocessing.sequence.pad_sequences", "numpy.array", "len", "range"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "idxs", "=", "list", "(", "range", "(", "len", "(", "self", ".", "data", ")", ")", ")", "\n", "if", "self", ".", "shuffle", ":", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "idxs", ")", "\n", "", "X1", ",", "X2", ",", "Y", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "idxs", ":", "\n", "                ", "d", "=", "self", ".", "data", "[", "i", "]", "\n", "text1", "=", "d", "[", "0", "]", "\n", "text2", "=", "d", "[", "1", "]", "\n", "x1", ",", "x2", "=", "self", ".", "tokenizer", ".", "encode", "(", "first", "=", "text1", ",", "second", "=", "text2", ",", "max_len", "=", "self", ".", "maxlen", ")", "\n", "if", "self", ".", "class_num", ">", "2", ":", "\n", "                    ", "y", "=", "[", "0", "for", "_", "in", "range", "(", "self", ".", "class_num", ")", "]", "\n", "y", "[", "d", "[", "2", "]", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "y", "=", "[", "d", "[", "2", "]", "]", "\n", "", "X1", ".", "append", "(", "x1", ")", "\n", "X2", ".", "append", "(", "x2", ")", "\n", "Y", ".", "append", "(", "y", ")", "\n", "if", "len", "(", "X1", ")", "==", "self", ".", "batch_size", "or", "i", "==", "idxs", "[", "-", "1", "]", ":", "\n", "                    ", "X1", "=", "sequence", ".", "pad_sequences", "(", "X1", ",", "maxlen", "=", "self", ".", "maxlen", ")", "\n", "X2", "=", "sequence", ".", "pad_sequences", "(", "X2", ",", "maxlen", "=", "self", ".", "maxlen", ")", "\n", "Y", "=", "np", ".", "array", "(", "Y", ")", "\n", "yield", "[", "X1", ",", "X2", "]", ",", "Y", "\n", "[", "X1", ",", "X2", ",", "Y", "]", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_adapter.convert_data": [[9, 33], ["list", "keras.preprocessing.sequence.pad_sequences", "keras.preprocessing.sequence.pad_sequences", "numpy.array", "range", "numpy.random.shuffle", "tokenizer.encode", "sequence.pad_sequences.append", "sequence.pad_sequences.append", "np.array.append", "len"], "function", ["None"], ["def", "convert_data", "(", "data", ",", "maxlen", ",", "tokenizer", ",", "shuffle", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    :param data:\n    :param maxlen:\n    :param shuffle:\n    :param tokenizer:\n    :return:\n    \"\"\"", "\n", "idxs", "=", "list", "(", "range", "(", "len", "(", "data", ")", ")", ")", "\n", "if", "shuffle", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "idxs", ")", "\n", "", "X1", ",", "X2", ",", "Y", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "idxs", ":", "\n", "        ", "d", "=", "data", "[", "i", "]", "\n", "text", "=", "d", "[", "0", "]", "[", ":", "maxlen", "]", "\n", "x1", ",", "x2", "=", "tokenizer", ".", "encode", "(", "first", "=", "text", ")", "\n", "y", "=", "d", "[", "1", "]", "\n", "X1", ".", "append", "(", "x1", ")", "\n", "X2", ".", "append", "(", "x2", ")", "\n", "Y", ".", "append", "(", "[", "y", "]", ")", "\n", "", "X1", "=", "sequence", ".", "pad_sequences", "(", "X1", ",", "maxlen", "=", "maxlen", ")", "\n", "X2", "=", "sequence", ".", "pad_sequences", "(", "X2", ",", "maxlen", "=", "maxlen", ")", "\n", "Y", "=", "np", ".", "array", "(", "Y", ")", "\n", "return", "[", "X1", ",", "X2", "]", ",", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_loader.get_data_from_file": [[7, 22], ["nlp_tasks.utils.file_utils.read_all_lines", "nlp_tasks.utils.file_utils.read_all_lines", "data.append", "data.append"], "function", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.read_all_lines", "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.read_all_lines"], ["def", "get_data_from_file", "(", "pos_filepath", ",", "neg_filepath", ")", ":", "\n", "    ", "\"\"\"\n\n    :param pos_filepath:\n    :param neg_filepath:\n    :return:\n    \"\"\"", "\n", "neg", "=", "file_utils", ".", "read_all_lines", "(", "neg_filepath", ")", "\n", "pos", "=", "file_utils", ".", "read_all_lines", "(", "pos_filepath", ")", "\n", "data", "=", "[", "]", "\n", "for", "d", "in", "neg", ":", "\n", "        ", "data", ".", "append", "(", "(", "d", ",", "0", ")", ")", "\n", "", "for", "d", "in", "pos", ":", "\n", "        ", "data", ".", "append", "(", "(", "d", ",", "1", ")", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.data_loader.get_pair_data_from_file": [[24, 33], ["nlp_tasks.utils.file_utils.read_all_lines", "line.split", "int"], "function", ["home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.utils.file_utils.read_all_lines"], ["", "def", "get_pair_data_from_file", "(", "filepath", ")", ":", "\n", "    ", "\"\"\"\n    :param filepath:\n    :return:\n    \"\"\"", "\n", "lines", "=", "file_utils", ".", "read_all_lines", "(", "filepath", ")", "\n", "samples", "=", "[", "line", ".", "split", "(", "'\\t'", ")", "for", "line", "in", "lines", "]", "\n", "samples", "=", "[", "(", "sample", "[", "0", "]", ",", "sample", "[", "1", "]", ",", "int", "(", "sample", "[", "2", "]", ")", ")", "for", "sample", "in", "samples", "]", "\n", "return", "samples", "", "", ""]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.bert_keras.tokenizer.TokenizerReturningSpace._tokenize": [[11, 21], ["R.append", "tokenizer.TokenizerReturningSpace._is_space", "R.append", "R.append"], "methods", ["None"], ["def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "R", "=", "[", "]", "\n", "for", "c", "in", "text", ":", "\n", "            ", "if", "c", "in", "self", ".", "_token_dict", ":", "\n", "                ", "R", ".", "append", "(", "c", ")", "\n", "", "elif", "self", ".", "_is_space", "(", "c", ")", ":", "\n", "                ", "R", ".", "append", "(", "'[unused1]'", ")", "\n", "", "else", ":", "\n", "                ", "R", ".", "append", "(", "'[UNK]'", ")", "\n", "", "", "return", "R", "\n", "\n"]], "home.repos.pwc.inspect_result.l294265421_AC-MIMLLN.common.common_path.get_task_data_dir": [[11, 18], ["None"], "function", ["None"], ["def", "get_task_data_dir", "(", "task_name", ":", "str", ",", "is_original", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "if", "not", "is_original", ":", "\n", "        ", "return", "'%s%s/data/'", "%", "(", "common_data_dir", ",", "task_name", ")", "\n", "", "else", ":", "\n", "        ", "return", "'%s%s/'", "%", "(", "original_data_dir", ",", "task_name", ")", "\n", "", "", ""]]}