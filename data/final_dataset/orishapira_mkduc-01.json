{"home.repos.pwc.inspect_result.orishapira_mkduc-01.None.MKDUC01_eval.MKDUC01_Eval.__init__": [[30, 38], ["os.path.join", "nltk.stem.PorterStemmer", "os.path.dirname", "os.path.realpath", "open", "json.load"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "DATA_FILEPATH", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", ",", "'data'", ",", "'MKDUC01.json'", ")", "\n", "try", ":", "\n", "            ", "with", "open", "(", "self", ".", "DATA_FILEPATH", ",", "'r'", ")", "as", "fIn", ":", "\n", "                ", "self", ".", "data", "=", "json", ".", "load", "(", "fIn", ")", "\n", "", "", "except", ":", "\n", "            ", "raise", "(", "f'Error: cannot load data file {self.DATA_FILEPATH}'", ")", "\n", "", "self", ".", "stemmer", "=", "PorterStemmer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.None.MKDUC01_eval.MKDUC01_Eval.get_topic_docs": [[39, 45], ["[].items"], "methods", ["None"], ["", "def", "get_topic_docs", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the documents per topic, where each document is a single strings.\n        The data is given as a dictionary {topicId -> [list of strings]}.\n        \"\"\"", "\n", "return", "{", "topicId", ":", "[", "docTxt", "for", "docId", ",", "docTxt", "in", "self", ".", "data", "[", "topicId", "]", "[", "'documents'", "]", ".", "items", "(", ")", "]", "for", "topicId", "in", "self", ".", "data", "}", "# topicId -> [docs]", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.None.MKDUC01_eval.MKDUC01_Eval.evaluate": [[46, 56], ["MKDUC01_eval.MKDUC01_Eval.__f1AtKAllTopics"], "methods", ["home.repos.pwc.inspect_result.orishapira_mkduc-01.None.MKDUC01_eval.MKDUC01_Eval.__f1AtKAllTopics"], ["", "def", "evaluate", "(", "self", ",", "pred_kps", ",", "pred_trunc", "=", "[", "1", ",", "5", ",", "10", ",", "15", ",", "20", "]", ",", "gold_trunc20", "=", "True", ",", "clusterLevel", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Scores the given predicted KPs against the gold KPs with F1@k and unigram F1@k scores (with stemming).\n        :param pred_kps: dictionary of topic ID to list of predicted keyphrases. {topicId -> [list of strings]}\n        :param pred_trunc: list of Ks, at which to truncate the predicted lists. Returns scores at each K.\n        :param gold_trunc20: whether to use the Trunc20 version of the data, using the top20 gold KPs per topic.\n        :param clusterLevel: whether to evaluate with te substitute clusters or not.\n        :return: A dictionary of scores {<score_name>: <score>}, f1@k and unigram f1@k scores (e.g. f1_unigram@5 or f1@20)\n        \"\"\"", "\n", "return", "self", ".", "__f1AtKAllTopics", "(", "pred_kps", ",", "cutoffs", "=", "pred_trunc", ",", "cutGold", "=", "(", "20", "if", "gold_trunc20", "else", "0", ")", ",", "clusterLevel", "=", "clusterLevel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.None.MKDUC01_eval.MKDUC01_Eval.__f1AtK_clusters": [[59, 126], ["list", "len", "list", "list", "len", "len", "len", "set", "enumerate", "len", "len", "cytoolz.concat", "list", "kpsUniqueGoldStemsPerCluster.append", "cytoolz.concat", "list", "list", "MKDUC01_eval.MKDUC01_Eval.stemmer.stem", "set", "cytoolz.concat", "kp.split", "MKDUC01_eval.MKDUC01_Eval.stemmer.stem", "matchGoldIndices.append", "kp.split", "list", "kp.split", "list", "cytoolz.concat", "kp.split", "set", "collections.Counter", "collections.Counter", "kp.split"], "methods", ["None"], ["", "def", "__f1AtK_clusters", "(", "self", ",", "kpsPred", ",", "kpsGoldClusters", ",", "cutoffs", "=", "[", "1", ",", "5", ",", "10", ",", "15", ",", "20", "]", ",", "cutGold", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Score the given predicted KPs against the gold KPs with F1@k and unigram F1@k scores (with stemming).\n        :param kpsPred: list of strings (one per KP)\n        :param kpsGoldClusters: list of list of strings (KP clusters, each KP is a string)\n        :param cutoffs: list of ks for the F1@k score\n        :param cutGold: where should the gold list be truncated (default 0 - no truncation)\n        :return: A dictionary of scores {<score_name>: <score>}, f1@k and unigram f1@k scores\n        \"\"\"", "\n", "# stemmed KPs:", "\n", "kpsPredStem", "=", "[", "' '", ".", "join", "(", "[", "self", ".", "stemmer", ".", "stem", "(", "t", ")", "for", "t", "in", "kp", ".", "split", "(", ")", "]", ")", "for", "kp", "in", "kpsPred", "]", "\n", "kpsGoldClustersStem", "=", "[", "[", "' '", ".", "join", "(", "[", "self", ".", "stemmer", ".", "stem", "(", "t", ")", "for", "t", "in", "kp", ".", "split", "(", ")", "]", ")", "for", "kp", "in", "kpCluster", "]", "for", "kpCluster", "in", "kpsGoldClusters", "]", "\n", "\n", "all_scores", "=", "{", "}", "# metric -> score", "\n", "\n", "for", "cutoff", "in", "cutoffs", ":", "\n", "\n", "# truncate the pred and gold lists:", "\n", "            ", "kpsPredStemUse", "=", "kpsPredStem", "[", ":", "cutoff", "]", "\n", "if", "cutGold", ">", "0", ":", "\n", "                ", "kpsGoldClustersStemUse", "=", "kpsGoldClustersStem", "[", ":", "cutGold", "]", "\n", "", "else", ":", "\n", "                ", "kpsGoldClustersStemUse", "=", "kpsGoldClustersStem", "\n", "\n", "# compute f1@k scores:", "\n", "", "kpsPredStemUnique", "=", "list", "(", "set", "(", "kpsPredStemUse", ")", ")", "\n", "matchGoldIndices", "=", "[", "]", "\n", "for", "kpPred", "in", "kpsPredStemUnique", ":", "\n", "                ", "for", "goldIdx", ",", "kpGoldCluster", "in", "enumerate", "(", "kpsGoldClustersStemUse", ")", ":", "\n", "                    ", "if", "goldIdx", "in", "matchGoldIndices", ":", "\n", "                        ", "continue", "# this gold KP cluster was already used as a match, so don't reuse it", "\n", "", "if", "kpPred", "in", "kpGoldCluster", ":", "\n", "                        ", "matchGoldIndices", ".", "append", "(", "goldIdx", ")", "\n", "", "", "", "matchCount", "=", "len", "(", "matchGoldIndices", ")", "\n", "precision", "=", "matchCount", "/", "len", "(", "kpsPredStemUse", ")", "\n", "recall", "=", "matchCount", "/", "len", "(", "kpsGoldClustersStemUse", ")", "\n", "f1", "=", "2", "*", "(", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "if", "precision", "+", "recall", ">", "0", "else", "0.", "\n", "all_scores", "[", "f'rec@{cutoff}'", "]", "=", "recall", "\n", "all_scores", "[", "f'prec@{cutoff}'", "]", "=", "precision", "\n", "all_scores", "[", "f'f1@{cutoff}'", "]", "=", "f1", "\n", "\n", "\n", "# get bag of unigrams from the non-redundant lists:", "\n", "# (remove redundant predicted KPs after cutting at k so that we don't count a match more than once)", "\n", "kpsUniquePredStems", "=", "list", "(", "concat", "(", "[", "kp", ".", "split", "(", ")", "for", "kp", "in", "list", "(", "set", "(", "kpsPredStemUse", ")", ")", "]", ")", ")", "\n", "# for the gold clusters, first keep the unqie tokens in each cluster, then combine all tokens from all clusters:", "\n", "kpsUniqueGoldStemsPerCluster", "=", "[", "]", "\n", "for", "goldCluster", "in", "kpsGoldClustersStemUse", ":", "\n", "                ", "clusterTokens", "=", "list", "(", "set", "(", "list", "(", "concat", "(", "[", "kp", ".", "split", "(", ")", "for", "kp", "in", "goldCluster", "]", ")", ")", ")", ")", "# keep unique tokens in the cluster", "\n", "kpsUniqueGoldStemsPerCluster", ".", "append", "(", "clusterTokens", ")", "\n", "", "kpsUniqueGoldStems", "=", "list", "(", "concat", "(", "kpsUniqueGoldStemsPerCluster", ")", ")", "\n", "\n", "# compute unigram f1@k scores:", "\n", "\n", "# find number of stem matches (number of common unigrams with possible repeating ones in their intersection):", "\n", "stemMatchCount", "=", "len", "(", "list", "(", "(", "Counter", "(", "kpsUniquePredStems", ")", "&", "Counter", "(", "kpsUniqueGoldStems", ")", ")", ".", "elements", "(", ")", ")", ")", "\n", "numStemsInKpsPred", "=", "len", "(", "list", "(", "concat", "(", "[", "kp", ".", "split", "(", ")", "for", "kp", "in", "kpsPredStemUse", "]", ")", ")", ")", "\n", "numStemsInKpsGold", "=", "len", "(", "kpsUniqueGoldStems", ")", "\n", "\n", "precision", "=", "stemMatchCount", "/", "numStemsInKpsPred", "\n", "recall", "=", "stemMatchCount", "/", "numStemsInKpsGold", "\n", "f1", "=", "2", "*", "(", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "if", "precision", "+", "recall", ">", "0", "else", "0.", "\n", "all_scores", "[", "f'rec_unigram@{cutoff}'", "]", "=", "recall", "\n", "all_scores", "[", "f'prec_unigram@{cutoff}'", "]", "=", "precision", "\n", "all_scores", "[", "f'f1_unigram@{cutoff}'", "]", "=", "f1", "\n", "\n", "", "return", "all_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.None.MKDUC01_eval.MKDUC01_Eval.__f1AtK": [[129, 183], ["len", "list", "list", "len", "len", "len", "len", "len", "cytoolz.concat", "cytoolz.concat", "list", "list", "MKDUC01_eval.MKDUC01_Eval.stemmer.stem", "MKDUC01_eval.MKDUC01_Eval.stemmer.stem", "set", "set", "cytoolz.concat", "kp.split", "kp.split", "kp.split", "kp.split", "list", "kp.split", "set", "collections.Counter", "collections.Counter"], "methods", ["None"], ["", "def", "__f1AtK", "(", "self", ",", "kpsPred", ",", "kpsGold", ",", "cutoffs", "=", "[", "1", ",", "5", ",", "10", ",", "15", ",", "20", "]", ",", "cutGold", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Score the given predicted KPs against the gold KPs with F1@k and unigram F1@k scores (with stemming).\n        :param kpsPred: list of strings (one per KP)\n        :param kpsGold: list of strings (one per KP)\n        :param cutoffs: list of ks for the F1@k score\n        :param cutGold: where should the gold list be truncated (default 0 - no truncation)\n        :return: A dictionary of scores {<score_name>: <score>}, f1@k and unigram f1@k scores\n        \"\"\"", "\n", "# stemmed KPs:", "\n", "kpsPredStem", "=", "[", "' '", ".", "join", "(", "[", "self", ".", "stemmer", ".", "stem", "(", "t", ")", "for", "t", "in", "kp", ".", "split", "(", ")", "]", ")", "for", "kp", "in", "kpsPred", "]", "\n", "kpsGoldStem", "=", "[", "' '", ".", "join", "(", "[", "self", ".", "stemmer", ".", "stem", "(", "t", ")", "for", "t", "in", "kp", ".", "split", "(", ")", "]", ")", "for", "kp", "in", "kpsGold", "]", "\n", "\n", "all_scores", "=", "{", "}", "# metric -> score", "\n", "\n", "for", "cutoff", "in", "cutoffs", ":", "\n", "\n", "            ", "kpsPredStemUse", "=", "kpsPredStem", "[", ":", "cutoff", "]", "\n", "if", "cutGold", ">", "0", ":", "\n", "                ", "kpsGoldStemUse", "=", "kpsGoldStem", "[", ":", "cutGold", "]", "\n", "", "else", ":", "\n", "                ", "kpsGoldStemUse", "=", "kpsGoldStem", "\n", "\n", "# compute f1@k scores:", "\n", "", "matchCount", "=", "len", "(", "set", "(", "kpsPredStemUse", ")", "&", "set", "(", "kpsGoldStemUse", ")", ")", "\n", "precision", "=", "matchCount", "/", "len", "(", "kpsPredStemUse", ")", "\n", "recall", "=", "matchCount", "/", "len", "(", "kpsGoldStemUse", ")", "\n", "f1", "=", "2", "*", "(", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "if", "precision", "+", "recall", ">", "0", "else", "0.", "\n", "all_scores", "[", "f'rec@{cutoff}'", "]", "=", "recall", "\n", "all_scores", "[", "f'prec@{cutoff}'", "]", "=", "precision", "\n", "all_scores", "[", "f'f1@{cutoff}'", "]", "=", "f1", "\n", "\n", "\n", "# get bag of unigrams from the non-redundant lists:", "\n", "# (remove redundant predicted KPs after cutting at k so that we don't count a match more than once)", "\n", "kpsUniquePredStems", "=", "list", "(", "concat", "(", "[", "kp", ".", "split", "(", ")", "for", "kp", "in", "list", "(", "set", "(", "kpsPredStemUse", ")", ")", "]", ")", ")", "\n", "kpsUniqueGoldStems", "=", "list", "(", "concat", "(", "[", "kp", ".", "split", "(", ")", "for", "kp", "in", "kpsGoldStemUse", "]", ")", ")", "\n", "\n", "# compute unigram f1@k scores:", "\n", "\n", "# find number of stem matches (number of common unigrams with possible repeating ones in their intersection):", "\n", "stemMatchCount", "=", "len", "(", "list", "(", "(", "Counter", "(", "kpsUniquePredStems", ")", "&", "Counter", "(", "kpsUniqueGoldStems", ")", ")", ".", "elements", "(", ")", ")", ")", "\n", "\n", "numStemsInKpsPred", "=", "len", "(", "list", "(", "concat", "(", "[", "kp", ".", "split", "(", ")", "for", "kp", "in", "kpsPredStemUse", "]", ")", ")", ")", "\n", "numStemsInKpsGold", "=", "len", "(", "kpsUniqueGoldStems", ")", "\n", "\n", "precision", "=", "stemMatchCount", "/", "numStemsInKpsPred", "\n", "recall", "=", "stemMatchCount", "/", "numStemsInKpsGold", "\n", "f1", "=", "2", "*", "(", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "if", "precision", "+", "recall", ">", "0", "else", "0.", "\n", "all_scores", "[", "f'rec_unigram@{cutoff}'", "]", "=", "recall", "\n", "all_scores", "[", "f'prec_unigram@{cutoff}'", "]", "=", "precision", "\n", "all_scores", "[", "f'f1_unigram@{cutoff}'", "]", "=", "f1", "\n", "\n", "", "return", "all_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.None.MKDUC01_eval.MKDUC01_Eval.__f1AtKForTopic": [[185, 191], ["MKDUC01_eval.MKDUC01_Eval.__f1AtK_clusters", "MKDUC01_eval.MKDUC01_Eval.__f1AtK"], "methods", ["home.repos.pwc.inspect_result.orishapira_mkduc-01.None.MKDUC01_eval.MKDUC01_Eval.__f1AtK_clusters", "home.repos.pwc.inspect_result.orishapira_mkduc-01.None.MKDUC01_eval.MKDUC01_Eval.__f1AtK"], ["", "def", "__f1AtKForTopic", "(", "self", ",", "topicId", ",", "kpsPred", ",", "cutoffs", "=", "[", "1", ",", "5", ",", "10", ",", "15", ",", "20", "]", ",", "cutGold", "=", "0", ",", "clusterLevel", "=", "True", ")", ":", "\n", "        ", "if", "clusterLevel", ":", "\n", "            ", "return", "self", ".", "__f1AtK_clusters", "(", "kpsPred", ",", "self", ".", "data", "[", "topicId", "]", "[", "'keyphrases'", "]", ",", "cutoffs", "=", "cutoffs", ",", "cutGold", "=", "cutGold", ")", "\n", "", "else", ":", "\n", "            ", "kpsGold", "=", "[", "kp", "[", "0", "]", "for", "kp", "in", "self", ".", "data", "[", "topicId", "]", "[", "'keyphrases'", "]", "]", "# use only the first KP of each cluster", "\n", "return", "self", ".", "__f1AtK", "(", "kpsPred", ",", "kpsGold", ",", "cutoffs", "=", "cutoffs", ",", "cutGold", "=", "cutGold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.None.MKDUC01_eval.MKDUC01_Eval.__f1AtKAllTopics": [[192, 211], ["list", "len", "[].keys", "numpy.mean", "MKDUC01_eval.MKDUC01_Eval.__f1AtKForTopic", "list", "scoresPerTopic.values"], "methods", ["home.repos.pwc.inspect_result.orishapira_mkduc-01.None.MKDUC01_eval.MKDUC01_Eval.__f1AtKForTopic"], ["", "", "def", "__f1AtKAllTopics", "(", "self", ",", "kpsPredPerTopic", ",", "cutoffs", "=", "[", "1", ",", "5", ",", "10", ",", "15", ",", "20", "]", ",", "cutGold", "=", "0", ",", "clusterLevel", "=", "True", ")", ":", "\n", "# get the scores per topic:", "\n", "        ", "scoresPerTopic", "=", "{", "}", "\n", "for", "topicId", "in", "self", ".", "data", ":", "\n", "            ", "if", "topicId", "in", "kpsPredPerTopic", ":", "\n", "                ", "scoresPerTopic", "[", "topicId", "]", "=", "self", ".", "__f1AtKForTopic", "(", "topicId", ",", "kpsPredPerTopic", "[", "topicId", "]", ",", "\n", "cutoffs", "=", "cutoffs", ",", "cutGold", "=", "cutGold", ",", "\n", "clusterLevel", "=", "clusterLevel", ")", "\n", "\n", "", "", "if", "len", "(", "scoresPerTopic", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "# get the mean scores over all topics:", "\n", "", "metrics", "=", "list", "(", "list", "(", "scoresPerTopic", ".", "values", "(", ")", ")", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "overallScores", "=", "{", "}", "\n", "for", "metric", "in", "metrics", ":", "\n", "            ", "overallScores", "[", "metric", "]", "=", "mean", "(", "[", "scoresPerTopic", "[", "topicId", "]", "[", "metric", "]", "for", "topicId", "in", "scoresPerTopic", "]", ")", "\n", "\n", "", "return", "overallScores", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.None.MKDUC01_eval.test": [[215, 246], ["time.time", "print", "MKDUC01_eval.MKDUC01_Eval", "MKDUC01_eval.MKDUC01_Eval.get_topic_docs", "mkde_evaluator.get_topic_docs.items", "print", "MKDUC01_eval.MKDUC01_Eval.evaluate", "print", "print", "pke.unsupervised.PositionRank", "pke.unsupervised.PositionRank.load_document", "pke.unsupervised.PositionRank.candidate_selection", "pke.unsupervised.PositionRank.candidate_weighting", "pke.unsupervised.PositionRank.get_n_best", "time.time", "time.time", "time.time"], "function", ["home.repos.pwc.inspect_result.orishapira_mkduc-01.None.MKDUC01_eval.MKDUC01_Eval.get_topic_docs", "home.repos.pwc.inspect_result.orishapira_mkduc-01.None.MKDUC01_eval.MKDUC01_Eval.evaluate"], ["", "", "def", "test", "(", ")", ":", "\n", "#########################################", "\n", "# EXAMPLE code for testing PositionRank #", "\n", "#########################################", "\n", "    ", "import", "pke", "\n", "import", "time", "\n", "\n", "startTime", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "f'Initializing - {time.time() - startTime}'", ")", "\n", "mkde_evaluator", "=", "MKDUC01_Eval", "(", ")", "\n", "topic_docs", "=", "mkde_evaluator", ".", "get_topic_docs", "(", ")", "\n", "\n", "pred_kps_per_topic", "=", "{", "}", "\n", "for", "topicId", ",", "doc_list", "in", "topic_docs", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "f'Getting KPs for {topicId} - {time.time() - startTime}'", ")", "\n", "# concatenate the documents, since this is a single-doc algorithms:", "\n", "docs_concat", "=", "' '", ".", "join", "(", "doc_list", ")", "\n", "# run positionrank:", "\n", "kp_extractor", "=", "pke", ".", "unsupervised", ".", "PositionRank", "(", ")", "\n", "kp_extractor", ".", "load_document", "(", "input", "=", "docs_concat", ",", "language", "=", "'en'", ")", "\n", "kp_extractor", ".", "candidate_selection", "(", ")", "\n", "kp_extractor", ".", "candidate_weighting", "(", ")", "\n", "kps_scores", "=", "kp_extractor", ".", "get_n_best", "(", "n", "=", "20", ")", "# (keyphrase, score) tuples", "\n", "# keep the KPs in the dictionary:", "\n", "kps", "=", "[", "kp", "for", "(", "kp", ",", "kpScore", ")", "in", "kps_scores", "]", "\n", "pred_kps_per_topic", "[", "topicId", "]", "=", "kps", "\n", "\n", "# Evaluate the predicted KPs over all topics:", "\n", "", "print", "(", "f'Evaluating predicted KPs - {time.time() - startTime}'", ")", "\n", "final_scores", "=", "mkde_evaluator", ".", "evaluate", "(", "pred_kps_per_topic", ",", "clusterLevel", "=", "True", ")", "\n", "print", "(", "final_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.baselines.runBayatmakouMDKE.output_results": [[10, 34], ["list", "os.path.join", "os.path.exists", "os.makedirs", "[].keys", "os.path.join", "numpy.mean", "numpy.mean", "results_csv_lines.append", "open", "fOut.write", "open", "json.dump", "numpy.mean", "len", "list", "all_scores.values", "len", "k.split"], "function", ["None"], ["def", "output_results", "(", "pred_kps", ",", "all_scores", ",", "output_dir", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "#print(all_scores)", "\n", "", "metrics", "=", "list", "(", "list", "(", "all_scores", ".", "values", "(", ")", ")", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "results_csv_lines", "=", "[", "'algorithm,'", "+", "','", ".", "join", "(", "metrics", ")", "+", "',avg_num_tokens_in_summ, avg_num_kps_in_summ'", "]", "\n", "for", "algName", "in", "pred_kps", ":", "\n", "# output the KPs for the algorithm (for all topics) in a JSON:", "\n", "        ", "algOutFilepath", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "f'{algName}.json'", ")", "\n", "with", "open", "(", "algOutFilepath", ",", "'w'", ")", "as", "fOut", ":", "\n", "            ", "json", ".", "dump", "(", "pred_kps", "[", "algName", "]", ",", "fOut", ",", "indent", "=", "4", ")", "\n", "\n", "", "mean_token_len", "=", "np", ".", "mean", "(", "[", "np", ".", "mean", "(", "[", "len", "(", "k", ".", "split", "(", ")", ")", "for", "k", "in", "pred_kps", "[", "algName", "]", "[", "topic_id", "]", "]", ")", "\n", "for", "topic_id", "in", "pred_kps", "[", "algName", "]", "]", ")", "\n", "mean_num_kps", "=", "np", ".", "mean", "(", "[", "len", "(", "pred_kps", "[", "algName", "]", "[", "topic_id", "]", ")", "for", "topic_id", "in", "pred_kps", "[", "algName", "]", "]", ")", "\n", "\n", "line", "=", "f'{algName},'", "+", "','", ".", "join", "(", "[", "f\"{all_scores[algName][m]:.4f}\"", "for", "m", "in", "all_scores", "[", "algName", "]", "]", ")", "+", "','", "+", "f'{mean_token_len:.4f}'", "+", "','", "+", "f'{mean_num_kps:.4f}'", "\n", "results_csv_lines", ".", "append", "(", "line", ")", "\n", "\n", "# write the CSV file with the results:", "\n", "", "scoresFilepath", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "f'scores.csv'", ")", "\n", "with", "open", "(", "scoresFilepath", ",", "'w'", ")", "as", "fOut", ":", "\n", "        ", "fOut", ".", "write", "(", "'\\n'", ".", "join", "(", "results_csv_lines", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.baselines.runBayatmakouMDKE.merge_kps": [[36, 55], ["merge_kps.items", "sum", "len", "merge_kps[].append", "sorted", "final_merge_kps.items"], "function", ["None"], ["", "", "def", "merge_kps", "(", "scores_kps", ",", "truncate", "=", "20", ")", ":", "\n", "    ", "\"\"\"\n    scores_kps = [[(scores11, kp11), (scores12, kp12)], [(scores21, kp21), (scores22, kp22)]]\n    \"\"\"", "\n", "merge_kps", "=", "{", "}", "\n", "for", "each", "in", "scores_kps", ":", "\n", "        ", "for", "score", ",", "kp", "in", "each", ":", "\n", "            ", "if", "kp", "in", "merge_kps", ":", "\n", "                ", "merge_kps", "[", "kp", "]", ".", "append", "(", "score", ")", "\n", "", "else", ":", "\n", "                ", "merge_kps", "[", "kp", "]", "=", "[", "score", "]", "\n", "\n", "", "", "", "final_merge_kps", "=", "{", "}", "\n", "for", "kps", ",", "scores", "in", "merge_kps", ".", "items", "(", ")", ":", "\n", "        ", "final_merge_kps", "[", "kps", "]", "=", "sum", "(", "scores", ")", "/", "len", "(", "scores", ")", "\n", "\n", "", "final_kps", "=", "[", "kp_text", "for", "kp_text", ",", "kp_score", "in", "\n", "sorted", "(", "final_merge_kps", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "item", "[", "1", "]", ",", "reverse", "=", "True", ")", "]", "[", ":", "truncate", "]", "\n", "return", "final_kps", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.baselines.runBayatmakouMDKE.generate_kps": [[57, 71], ["rake_nltk.Rake", "topic_docs.items", "runBayatmakouMDKE.merge_kps", "rake_nltk.Rake.extract_keywords_from_text", "rake_nltk.Rake.get_ranked_phrases_with_scores", "per_doc_scores_kps.append", "len", "kp.split"], "function", ["home.repos.pwc.inspect_result.orishapira_mkduc-01.baselines.runBayatmakouMDKE.merge_kps"], ["", "def", "generate_kps", "(", "topic_docs", ",", "max_kp_length", "=", "3", ")", ":", "\n", "    ", "r", "=", "Rake", "(", ")", "\n", "pred_kps", "=", "{", "}", "\n", "\n", "for", "topicId", ",", "doc_list", "in", "topic_docs", ".", "items", "(", ")", ":", "\n", "        ", "per_doc_scores_kps", "=", "[", "]", "\n", "for", "docTxt", "in", "doc_list", ":", "\n", "            ", "r", ".", "extract_keywords_from_text", "(", "docTxt", ")", "\n", "kps_with_scores", "=", "r", ".", "get_ranked_phrases_with_scores", "(", ")", "\n", "kps_with_scores", "=", "[", "(", "s", ",", "kp", ")", "for", "s", ",", "kp", "in", "kps_with_scores", "if", "len", "(", "kp", ".", "split", "(", ")", ")", "<=", "max_kp_length", "]", "\n", "per_doc_scores_kps", ".", "append", "(", "kps_with_scores", ")", "\n", "", "pred_kps", "[", "topicId", "]", "=", "merge_kps", "(", "per_doc_scores_kps", ")", "\n", "\n", "", "return", "pred_kps", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.baselines.runSingleDocAlgorithmsMDKE.removeNearDuplicateKPs": [[23, 48], ["range", "len", "kpsStemmed[].split", "range", "len", "kpsStemmed[].split", "range", "range", "len", "len", "all", "all", "len", "len", "removalIndices.append", "removalIndices.append"], "function", ["None"], ["def", "removeNearDuplicateKPs", "(", "kps", ",", "kpsStemmed", ")", ":", "\n", "# remove kps that are contained in (stemmed) a longer kp", "\n", "    ", "removalIndices", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "kps", ")", ")", ":", "\n", "        ", "tokensI", "=", "kpsStemmed", "[", "i", "]", ".", "split", "(", ")", "\n", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "kps", ")", ")", ":", "\n", "            ", "if", "j", "in", "removalIndices", ":", "\n", "                ", "continue", "\n", "", "tokensJ", "=", "kpsStemmed", "[", "j", "]", ".", "split", "(", ")", "\n", "# if kp i is shorter or equal in length to kp j:", "\n", "if", "len", "(", "tokensI", ")", "<=", "len", "(", "tokensJ", ")", ":", "\n", "# all i tokens are in j, so remove i:", "\n", "                ", "if", "all", "(", "t", "in", "tokensJ", "for", "t", "in", "tokensI", ")", ":", "\n", "                    ", "removalIndices", ".", "append", "(", "i", ")", "\n", "#print(f'Remove first: {kpsStemmed[i]}, {kpsStemmed[j]}')", "\n", "break", "\n", "# if kp j is shorter or equal in length to kp i, and all j tokens are in i, remove j:", "\n", "", "", "elif", "all", "(", "t", "in", "tokensI", "for", "t", "in", "tokensJ", ")", ":", "\n", "                ", "removalIndices", ".", "append", "(", "j", ")", "\n", "#print(f'Remove first: {kpsStemmed[j]}, {kpsStemmed[i]}')", "\n", "break", "\n", "\n", "", "", "", "kpsCleaned", "=", "[", "kps", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "kps", ")", ")", "if", "i", "not", "in", "removalIndices", "]", "\n", "kpsStemmedCleaned", "=", "[", "kpsStemmed", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "kpsStemmed", ")", ")", "if", "i", "not", "in", "removalIndices", "]", "\n", "return", "kpsCleaned", ",", "kpsStemmedCleaned", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.baselines.runSingleDocAlgorithmsMDKE.merge_docs_kps": [[49, 86], ["collections.Counter", "len", "list", "zip", "runSingleDocAlgorithmsMDKE.removeNearDuplicateKPs", "list", "collections.Counter.update", "cytoolz.concat", "numpy.mean", "set", "float", "kpsToUse.append", "kpsToUseStemmed.append", "stemmer.stem().lower", "kpStemmed.split", "sorted", "stemmer.stem().lower", "nltk.tokenize.word_tokenize", "kpScores.items", "nltk.tokenize.word_tokenize", "stemmer.stem", "stemmer.stem"], "function", ["home.repos.pwc.inspect_result.orishapira_mkduc-01.baselines.runSingleDocAlgorithmsMDKE.removeNearDuplicateKPs"], ["", "def", "merge_docs_kps", "(", "docs_kps", ",", "doc_list", ",", "truncate", "=", "20", ")", ":", "\n", "\n", "# get how many documents each KP token appears in (document-frequency of stems):", "\n", "    ", "docsTokensCounter", "=", "Counter", "(", ")", "# how many docs is it in", "\n", "for", "docStr", "in", "doc_list", ":", "\n", "        ", "docTokens", "=", "list", "(", "set", "(", "[", "stemmer", ".", "stem", "(", "t", ")", ".", "lower", "(", ")", "for", "t", "in", "word_tokenize", "(", "docStr", ")", "]", ")", ")", "# just to see if a token is there or not", "\n", "docsTokensCounter", ".", "update", "(", "docTokens", ")", "\n", "", "docsCount", "=", "len", "(", "doc_list", ")", "\n", "tokenScoresDocs", "=", "{", "t", ":", "float", "(", "docsTokensCounter", "[", "t", "]", ")", "/", "docsCount", "for", "t", "in", "docsTokensCounter", "}", "\n", "\n", "# flatten the docs kps:", "\n", "kpsAll", "=", "list", "(", "concat", "(", "docs_kps", ")", ")", "\n", "# stem KPs", "\n", "kpsAllStemmed", "=", "[", "' '", ".", "join", "(", "[", "stemmer", ".", "stem", "(", "t", ")", ".", "lower", "(", ")", "for", "t", "in", "word_tokenize", "(", "kp", ")", "]", ")", "for", "kp", "in", "kpsAll", "]", "\n", "\n", "# KP scoring by how many docs the stems appear in:", "\n", "kpScores", "=", "{", "}", "\n", "kpsToUse", "=", "[", "]", "\n", "kpsToUseStemmed", "=", "[", "]", "\n", "for", "kp", ",", "kpStemmed", "in", "zip", "(", "kpsAll", ",", "kpsAllStemmed", ")", ":", "\n", "        ", "kpTokenScores", "=", "[", "tokenScoresDocs", "[", "t", "]", "if", "t", "in", "tokenScoresDocs", "else", "0.", "for", "t", "in", "kpStemmed", ".", "split", "(", ")", "]", "\n", "kpScore", "=", "np", ".", "mean", "(", "kpTokenScores", ")", "\n", "kpScores", "[", "kp", "]", "=", "kpScore", "\n", "if", "kp", "not", "in", "kpsToUse", ":", "\n", "            ", "kpsToUse", ".", "append", "(", "kp", ")", "\n", "kpsToUseStemmed", ".", "append", "(", "kpStemmed", ")", "\n", "\n", "# get rid of near duplicate or contained KPs:", "\n", "", "", "kpsCleaned", ",", "kpsStemmedCleaned", "=", "removeNearDuplicateKPs", "(", "kpsToUse", ",", "kpsToUseStemmed", ")", "\n", "\n", "# the topic's sorted list of kps, by score, for the KPs left in kpsCleaned, whose score is above 0,", "\n", "# and truncated to the length requested:", "\n", "finalKPs", "=", "[", "kpTxt", "for", "kpTxt", ",", "kpScore", "in", "\n", "sorted", "(", "kpScores", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "item", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "if", "kpTxt", "in", "kpsCleaned", "and", "kpScore", ">", "0", "]", "[", ":", "truncate", "]", "\n", "\n", "return", "finalKPs", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.baselines.runSingleDocAlgorithmsMDKE.get_kps_collab_rank": [[89, 105], ["enumerate", "nlp", "pke.unsupervised.CollabRank", "pke.unsupervised.CollabRank.load_document", "pke.unsupervised.CollabRank.candidate_selection", "pke.unsupervised.CollabRank.candidate_weighting", "pke.unsupervised.CollabRank.get_n_best", "docs_kps.append", "enumerate", "enumerate", "docsSpacy[].similarity", "zip"], "function", ["None"], ["", "def", "get_kps_collab_rank", "(", "nlp", ",", "doc_list", ")", ":", "\n", "    ", "docsSpacy", "=", "[", "nlp", "(", "docTxt", ")", "for", "docTxt", "in", "doc_list", "]", "\n", "pos", "=", "{", "'NOUN'", ",", "'PROPN'", ",", "'ADJ'", "}", "\n", "docs_kps", "=", "[", "]", "\n", "for", "docIdx", ",", "docTxt", "in", "enumerate", "(", "doc_list", ")", ":", "\n", "        ", "collab_docs", "=", "[", "d", "for", "k", ",", "d", "in", "enumerate", "(", "doc_list", ")", "if", "k", "!=", "docIdx", "]", "\n", "collab_docs_spacy", "=", "[", "d_spacy", "for", "k", ",", "d_spacy", "in", "enumerate", "(", "docsSpacy", ")", "if", "k", "!=", "docIdx", "]", "\n", "extractor", "=", "pke", ".", "unsupervised", ".", "CollabRank", "(", ")", "\n", "extractor", ".", "load_document", "(", "input", "=", "docTxt", ",", "language", "=", "\"en\"", ")", "\n", "collab_items", "=", "[", "(", "d", ",", "docsSpacy", "[", "docIdx", "]", ".", "similarity", "(", "d_spacy", ")", ")", "for", "d", ",", "d_spacy", "in", "zip", "(", "collab_docs", ",", "collab_docs_spacy", ")", "]", "\n", "extractor", ".", "candidate_selection", "(", "pos", "=", "pos", ")", "\n", "extractor", ".", "candidate_weighting", "(", "window", "=", "10", ",", "pos", "=", "pos", ",", "collab_documents", "=", "collab_items", ")", "\n", "kps_with_scores", "=", "extractor", ".", "get_n_best", "(", "n", "=", "20", ")", "\n", "doc_kps", "=", "[", "kp", "for", "kp", ",", "s", "in", "kps_with_scores", "]", "\n", "docs_kps", ".", "append", "(", "doc_kps", ")", "\n", "", "return", "docs_kps", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.baselines.runSingleDocAlgorithmsMDKE.get_kps_BERTKPE": [[108, 123], ["len", "open", "json.loads", "docInfo[].split", "_bertKPE_data[].append", "line.strip"], "function", ["None"], ["def", "get_kps_BERTKPE", "(", "topicId", ")", ":", "\n", "    ", "if", "len", "(", "_bertKPE_data", ")", "==", "0", ":", "\n", "        ", "results_path", "=", "'bertkpe_single_doc_outputs/bert2joint.duc2001_dev.roberta.epoch_6.checkpoint_single'", "\n", "with", "open", "(", "results_path", ",", "'r'", ")", "as", "fIn", ":", "\n", "            ", "for", "line", "in", "fIn", ":", "\n", "                ", "docInfo", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "docFullIdParts", "=", "docInfo", "[", "'url'", "]", ".", "split", "(", "'_'", ")", "\n", "topicId", "=", "docFullIdParts", "[", "0", "]", "\n", "docId", "=", "docFullIdParts", "[", "1", "]", "\n", "docKps", "=", "[", "' '", ".", "join", "(", "kpTokens", ")", "for", "kpTokens", "in", "docInfo", "[", "'KeyPhrases'", "]", "]", "\n", "if", "topicId", "not", "in", "_bertKPE_data", ":", "\n", "                    ", "_bertKPE_data", "[", "topicId", "]", "=", "[", "]", "\n", "", "_bertKPE_data", "[", "topicId", "]", ".", "append", "(", "docKps", ")", "\n", "\n", "", "", "", "return", "_bertKPE_data", "[", "topicId", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.baselines.runSingleDocAlgorithmsMDKE.generate_kps": [[125, 167], ["topics_docs.items", "spacy.load", "print", "algClass", "algClass.load_document", "algClass.candidate_selection", "algClass.candidate_weighting", "algClass.get_n_best", "random.shuffle", "runSingleDocAlgorithmsMDKE.generate_kps.get_kps"], "function", ["None"], ["", "def", "generate_kps", "(", "algName", ",", "algClass", ",", "topics_docs", ",", "num_kps_generate", "=", "20", ",", "generation_mode", "=", "GENERATION_MODE_DOCS_CONCAT", ")", ":", "\n", "    ", "assert", "generation_mode", "in", "[", "GENERATION_MODE_DOCS_CONCAT", ",", "GENERATION_MODE_DOCS_MERGE", "]", "\n", "if", "algName", "in", "[", "'CollabRank'", ",", "'BERTKPE'", "]", "and", "generation_mode", "==", "GENERATION_MODE_DOCS_CONCAT", ":", "\n", "        ", "raise", "(", "'Error: cannot run CollabRank or BERTKPE in CONCAT mode.'", ")", "\n", "\n", "", "def", "get_kps", "(", "algClass", ",", "text", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "extractor", "=", "algClass", "(", ")", "\n", "extractor", ".", "load_document", "(", "input", "=", "text", ",", "language", "=", "'en'", ")", "\n", "extractor", ".", "candidate_selection", "(", ")", "\n", "extractor", ".", "candidate_weighting", "(", ")", "\n", "kps", "=", "extractor", ".", "get_n_best", "(", "n", "=", "num_kps_generate", ")", "# (keyphrase, score) tuples", "\n", "results", "=", "[", "kp", "for", "(", "kp", ",", "kpScore", ")", "in", "kps", "]", "\n", "", "except", ":", "\n", "            ", "results", "=", "[", "]", "\n", "print", "(", "f'------------\\nWARNING: SKIPPED DOC for algclass {str(algClass)}\\n{text}\\n-------------'", ")", "\n", "", "return", "results", "\n", "\n", "\n", "", "pred_kps", "=", "{", "}", "# {topicId -> list of kps}", "\n", "\n", "if", "algName", "==", "'CollabRank'", ":", "\n", "        ", "nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_md\"", ")", "\n", "\n", "", "for", "topicId", ",", "doc_list", "in", "topics_docs", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "f'Generating for topic {topicId}'", ")", "\n", "# in concat mode, shuffle the documents (kept the same for all algorithms):", "\n", "if", "generation_mode", "==", "GENERATION_MODE_DOCS_CONCAT", ":", "\n", "            ", "topicDocsCopy", "=", "doc_list", "[", ":", "]", "\n", "random", ".", "shuffle", "(", "topicDocsCopy", ")", "\n", "topicDocsConcat", "=", "' '", ".", "join", "(", "topicDocsCopy", ")", "\n", "pred_kps", "[", "topicId", "]", "=", "get_kps", "(", "algClass", ",", "topicDocsConcat", ")", "\n", "", "elif", "generation_mode", "==", "GENERATION_MODE_DOCS_MERGE", ":", "\n", "            ", "if", "algName", "==", "'CollabRank'", ":", "\n", "                ", "docs_kps", "=", "get_kps_collab_rank", "(", "nlp", ",", "doc_list", ")", "\n", "", "elif", "algName", "==", "'BERTKPE'", ":", "\n", "                    ", "docs_kps", "=", "get_kps_BERTKPE", "(", "topicId", ")", "\n", "", "else", ":", "\n", "                ", "docs_kps", "=", "[", "get_kps", "(", "algClass", ",", "docTxt", ")", "for", "docTxt", "in", "doc_list", "]", "\n", "", "pred_kps", "[", "topicId", "]", "=", "merge_docs_kps", "(", "docs_kps", ",", "doc_list", ")", "\n", "\n", "", "", "return", "pred_kps", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.baselines.runSingleDocAlgorithmsMDKE.output_results": [[169, 193], ["list", "os.path.join", "os.path.exists", "os.makedirs", "[].keys", "os.path.join", "numpy.mean", "numpy.mean", "results_csv_lines.append", "open", "fOut.write", "open", "json.dump", "numpy.mean", "len", "list", "all_scores.values", "len", "k.split"], "function", ["None"], ["", "def", "output_results", "(", "pred_kps", ",", "all_scores", ",", "output_dir", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "#print(all_scores)", "\n", "", "metrics", "=", "list", "(", "list", "(", "all_scores", ".", "values", "(", ")", ")", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "results_csv_lines", "=", "[", "'algorithm,'", "+", "','", ".", "join", "(", "metrics", ")", "+", "',avg_num_tokens_in_summ, avg_num_kps_in_summ'", "]", "\n", "for", "algName", "in", "pred_kps", ":", "\n", "# output the KPs for the algorithm (for all topics) in a JSON:", "\n", "        ", "algOutFilepath", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "f'{algName}.json'", ")", "\n", "with", "open", "(", "algOutFilepath", ",", "'w'", ")", "as", "fOut", ":", "\n", "            ", "json", ".", "dump", "(", "pred_kps", "[", "algName", "]", ",", "fOut", ",", "indent", "=", "4", ")", "\n", "\n", "", "mean_token_len", "=", "np", ".", "mean", "(", "[", "np", ".", "mean", "(", "[", "len", "(", "k", ".", "split", "(", ")", ")", "for", "k", "in", "pred_kps", "[", "algName", "]", "[", "topic_id", "]", "]", ")", "\n", "for", "topic_id", "in", "pred_kps", "[", "algName", "]", "]", ")", "\n", "mean_num_kps", "=", "np", ".", "mean", "(", "[", "len", "(", "pred_kps", "[", "algName", "]", "[", "topic_id", "]", ")", "for", "topic_id", "in", "pred_kps", "[", "algName", "]", "]", ")", "\n", "\n", "line", "=", "f'{algName},'", "+", "','", ".", "join", "(", "[", "f\"{all_scores[algName][m]:.4f}\"", "for", "m", "in", "all_scores", "[", "algName", "]", "]", ")", "+", "','", "+", "f'{mean_token_len:.4f}'", "+", "','", "+", "f'{mean_num_kps:.4f}'", "\n", "results_csv_lines", ".", "append", "(", "line", ")", "\n", "\n", "# write the CSV file with the results:", "\n", "", "scoresFilepath", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "f'scores.csv'", ")", "\n", "with", "open", "(", "scoresFilepath", ",", "'w'", ")", "as", "fOut", ":", "\n", "        ", "fOut", ".", "write", "(", "'\\n'", ".", "join", "(", "results_csv_lines", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.baselines.runSingleDocAlgorithmsMDKE.main": [[196, 210], ["MKDUC01_eval.MKDUC01_Eval", "MKDUC01_eval.MKDUC01_Eval.get_topic_docs", "algorithms.items", "print", "runSingleDocAlgorithmsMDKE.output_results", "print", "runSingleDocAlgorithmsMDKE.generate_kps", "print", "MKDUC01_eval.MKDUC01_Eval.evaluate"], "function", ["home.repos.pwc.inspect_result.orishapira_mkduc-01.None.MKDUC01_eval.MKDUC01_Eval.get_topic_docs", "home.repos.pwc.inspect_result.orishapira_mkduc-01.baselines.runSingleDocAlgorithmsMDKE.output_results", "home.repos.pwc.inspect_result.orishapira_mkduc-01.baselines.runSingleDocAlgorithmsMDKE.generate_kps", "home.repos.pwc.inspect_result.orishapira_mkduc-01.None.MKDUC01_eval.MKDUC01_Eval.evaluate"], ["", "", "def", "main", "(", "algorithms", ",", "generation_mode", ",", "outputFolderpath", ",", "useTrunc20", "=", "True", ",", "evalClusterLevel", "=", "True", ")", ":", "\n", "    ", "mkde_evaluator", "=", "MKDUC01_Eval", "(", ")", "\n", "topics_docs", "=", "mkde_evaluator", ".", "get_topic_docs", "(", ")", "\n", "all_kps", "=", "{", "}", "\n", "all_scores", "=", "{", "}", "\n", "for", "algName", ",", "algClass", "in", "algorithms", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "f'Generating KPs for {algName}...'", ")", "\n", "pred_kps_per_topic", "=", "generate_kps", "(", "algName", ",", "algClass", ",", "topics_docs", ",", "generation_mode", "=", "generation_mode", ")", "\n", "print", "(", "f'Evaluating KPs for {algName}...'", ")", "\n", "final_scores", "=", "mkde_evaluator", ".", "evaluate", "(", "pred_kps_per_topic", ",", "gold_trunc20", "=", "useTrunc20", ",", "clusterLevel", "=", "evalClusterLevel", ")", "\n", "all_kps", "[", "algName", "]", "=", "pred_kps_per_topic", "\n", "all_scores", "[", "algName", "]", "=", "final_scores", "\n", "", "print", "(", "'Outputing KPs for all algorithms...'", ")", "\n", "output_results", "(", "all_kps", ",", "all_scores", ",", "outputFolderpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.orishapira_mkduc-01.data.generate_mkduc01_dataset.main": [[24, 47], ["sacrerouge.datasets.duc_tac.duc2001.tasks.load_test_data", "cluster_to_doc_ids.items", "open", "json.load", "open", "json.dump"], "function", ["None"], ["def", "main", "(", "duc_2001_docs_tar_path", ",", "mk_duc_2001_data_json_path", ",", "output_json_path", ")", ":", "\n", "\n", "# read in the documents from the tarball using sacrerouge:", "\n", "    ", "cluster_to_doc_ids", ",", "documents", ",", "mds_summaries", ",", "sds_summaries", "=", "load_test_data", "(", "duc_2001_docs_tar_path", ")", "\n", "\n", "# load the documents per topic:", "\n", "topicDocs", "=", "{", "}", "\n", "for", "topicId", ",", "docIds", "in", "cluster_to_doc_ids", ".", "items", "(", ")", ":", "\n", "        ", "topicDocs", "[", "topicId", "]", "=", "{", "}", "\n", "for", "docId", "in", "docIds", ":", "\n", "            ", "docTxt", "=", "' '", ".", "join", "(", "documents", "[", "docId", "]", "[", "'text'", "]", ")", "\n", "topicDocs", "[", "topicId", "]", "[", "docId", "]", "=", "docTxt", "\n", "\n", "# load the MK_DUC_01 keyphrases:", "\n", "", "", "with", "open", "(", "mk_duc_2001_data_json_path", ",", "'r'", ")", "as", "fIn", ":", "\n", "        ", "topicKPs", "=", "json", ".", "load", "(", "fIn", ")", "\n", "\n", "# output the full data to a new JSON:", "\n", "", "topicsData", "=", "{", "}", "\n", "for", "topicId", "in", "topicDocs", ":", "\n", "        ", "topicsData", "[", "topicId", "]", "=", "{", "'documents'", ":", "topicDocs", "[", "topicId", "]", ",", "'keyphrases'", ":", "topicKPs", "[", "topicId", "]", "}", "\n", "", "with", "open", "(", "output_json_path", ",", "'w'", ")", "as", "fOut", ":", "\n", "        ", "json", ".", "dump", "(", "topicsData", ",", "fOut", ",", "indent", "=", "2", ")", "\n", "\n"]]}