{"home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_ner.set_seed": [[84, 90], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_ner.train": [[92, 290], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "os.path.exists", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_ner.set_seed", "SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "os.path.isfile", "os.path.isfile", "transformers.AdamW.load_state_dict", "transformers.get_linear_schedule_with_warmup.load_state_dict", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "logger.info", "logger.info", "logger.info", "logger.info", "int", "tqdm.tqdm", "enumerate", "SummaryWriter.close", "os.path.join", "os.path.join", "torch.load", "torch.load", "int", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "os.path.join", "os.path.join", "ImportError", "torch.distributed.get_world_size", "len", "len", "loss.mean.mean", "loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "[].split", "t.to", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "os.path.join", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "torch.save", "torch.save", "logger.info", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_ner.evaluate", "results.items", "run_ner.evaluate", "int", "os.path.join", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "transformers.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr", "os.makedirs", "os.path.exists", "open", "writer.write", "args.model_name_or_path.split", "os.path.exists", "open", "writer.write"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.set_seed", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.train", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate"], ["", "", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "and", "os", ".", "path", ".", "isfile", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", "\n", ")", ":", "\n", "# Load in optimizer and scheduler states", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ":", "\n", "# set global_step to gobal_step of last saved checkpoint from model path", "\n", "        ", "try", ":", "\n", "            ", "global_step", "=", "int", "(", "args", ".", "model_name_or_path", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "0", "]", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "global_step", "=", "0", "\n", "", "epochs_trained", "=", "global_step", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "steps_trained_in_current_epoch", "=", "global_step", "%", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "\n", "logger", ".", "info", "(", "\"  Continuing training from checkpoint, will skip to saved global_step\"", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from epoch %d\"", ",", "epochs_trained", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from global step %d\"", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"  Will skip the first %d steps in the first epoch\"", ",", "steps_trained_in_current_epoch", ")", "\n", "\n", "", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "else", "None", "\n", ")", "# XLM and RoBERTa don\"t use segment_ids", "\n", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in pytorch-transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"dev\"", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "#ADD:", "\n", "# use \"--eval_every_epoch\" insted of \"--evaluate_during_training\".", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", "==", "0", "and", "args", ".", "eval_every_epoch", ":", "\n", "                    ", "if", "global_step", "%", "(", "t_total", "/", "args", ".", "num_train_epochs", ")", "==", "0", ":", "\n", "                        ", "results", ",", "_", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"dev\"", ")", "\n", "results", "[", "'gs'", "]", "=", "global_step", "\n", "results", "[", "'epochs'", "]", "=", "int", "(", "global_step", "/", "t_total", "*", "args", ".", "num_train_epochs", ")", "\n", "\n", "output_dev_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"dev_results.txt\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dev_file", ")", ":", "\n", "                            ", "with", "open", "(", "output_dev_file", ",", "'w'", ")", "as", "writer", ":", "\n", "                                ", "writer", ".", "write", "(", "'Global_step,Epochs,Loss,TP,FP,FN,Prec,Rec,FB1\\n'", ")", "\n", "", "", "with", "open", "(", "output_dev_file", ",", "'a'", ")", "as", "writer", ":", "\n", "                            ", "writer", ".", "write", "(", "\n", "'{gs},{epochs},{loss},{TP},{FP},{FN},{precision},{recall},{FB1}\\n'", ".", "format", "(", "**", "results", ")", "\n", ")", "\n", "\n", "", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_ner.evaluate": [[292, 365], ["run_ner.load_and_cache_examples", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "tqdm.tqdm", "numpy.argmax", "range", "itertools.chain.from_iterable", "itertools.chain.from_iterable", "metrics.ner.eval_ner", "logger.info", "results.keys", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "len", "tuple", "range", "logger.info", "torch.no_grad", "torch.nn.DataParallel.", "tmp_eval_loss.mean.item", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "enumerate", "range", "range", "zip", "str", "t.to", "tmp_eval_loss.mean.mean", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "out_label_list[].append", "preds_list[].append", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach", "inputs[].detach", "logits.detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.load_and_cache_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.ner.eval_ner"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "mode", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation %s *****\"", ",", "prefix", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "model", ".", "eval", "(", ")", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "else", "None", "\n", ")", "# XLM and RoBERTa don\"t use segment_ids", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "tmp_eval_loss", "=", "tmp_eval_loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel evaluating", "\n", "\n", "", "eval_loss", "+=", "tmp_eval_loss", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "            ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "2", ")", "\n", "\n", "label_map", "=", "{", "i", ":", "label", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", "}", "\n", "\n", "out_label_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", "]", "\n", "preds_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "out_label_ids", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "if", "out_label_ids", "[", "i", ",", "j", "]", "!=", "pad_token_label_id", ":", "\n", "                ", "out_label_list", "[", "i", "]", ".", "append", "(", "label_map", "[", "out_label_ids", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "preds_list", "[", "i", "]", ".", "append", "(", "label_map", "[", "preds", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "\n", "#ADD:", "\n", "#Replace original metrics with BLUE metrics.", "\n", "", "", "", "seq_labels", "=", "chain", ".", "from_iterable", "(", "out_label_list", ")", "\n", "seq_preds", "=", "chain", ".", "from_iterable", "(", "preds_list", ")", "\n", "sequences", "=", "[", "\"dummy {} {}\"", ".", "format", "(", "y_true", ",", "y_pred", ")", "for", "y_true", ",", "y_pred", "in", "zip", "(", "seq_labels", ",", "seq_preds", ")", "]", "\n", "results", ",", "report", "=", "eval_ner", "(", "sequences", ")", "\n", "\n", "results", "[", "'loss'", "]", "=", "eval_loss", "\n", "\n", "logger", ".", "info", "(", "\"***** Evaluate BLUE Benchmark %s *****\"", ",", "prefix", ")", "\n", "for", "key", "in", "results", ".", "keys", "(", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "results", "[", "key", "]", ")", ")", "\n", "\n", "", "return", "results", ",", "preds_list", ",", "report", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_ner.load_and_cache_examples": [[367, 425], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.distributed.barrier", "os.path.exists", "logger.info", "torch.load", "logger.info", "processors.utils_ner.convert_examples_to_features", "torch.distributed.barrier", "list().pop", "str", "processor.get_train_examples", "logger.info", "torch.save", "processor.get_dev_examples", "bool", "bool", "bool", "list", "processor.get_test_examples", "tokenizer.convert_tokens_to_ids", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.convert_examples_to_features", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_train_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_dev_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor.get_test_examples"], ["", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Load data features from cache or dataset file", "\n", "", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "data_dir", ",", "\n", "\"cached_{}_{}_{}\"", ".", "format", "(", "\n", "mode", ",", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "str", "(", "args", ".", "max_seq_length", ")", "\n", ")", ",", "\n", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "args", ".", "data_dir", ")", "\n", "# REPLACE:", "\n", "# examples = read_examples_from_file(args.data_dir, mode, args.task_name)", "\n", "if", "mode", "==", "\"train\"", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "", "elif", "mode", "==", "\"dev\"", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "\n", "", "elif", "mode", "==", "\"test\"", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ")", "\n", "\n", "", "features", "=", "convert_examples_to_features", "(", "\n", "examples", ",", "\n", "labels", ",", "\n", "args", ".", "max_seq_length", ",", "\n", "tokenizer", ",", "\n", "cls_token_at_end", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "\n", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "tokenizer", ".", "cls_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "\n", "sep_token_extra", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"roberta\"", "]", ")", ",", "\n", "# roberta uses an extra separator b/w pairs of sentences, cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "\n", "# pad on the left for xlnet", "\n", "pad_token", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "tokenizer", ".", "pad_token", "]", ")", "[", "0", "]", ",", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", "pad_token_label_id", "=", "pad_token_label_id", ",", "\n", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_label_ids", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_ner.main": [[427, 812], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_ner.set_seed", "processor.get_labels", "len", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "logger.info", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.nn.CrossEntropyLoss", "torch.distributed.barrier", "tokenizer_class.from_pretrained", "tokenizer_class.from_pretrained", "torch.distributed.barrier", "run_ner.load_and_cache_examples", "run_ner.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "logger.info", "os.path.join", "print", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_ner.evaluate", "os.path.join", "os.path.join", "logger.info", "print", "torch.cuda.device_count", "vars().items", "bool", "os.makedirs", "hasattr", "os.path.join", "tokenizer_class.from_pretrained", "tokenizer_class.from_pretrained", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_ner.evaluate", "results.update", "open", "sorted", "tokenizer_class.from_pretrained", "tokenizer_class.from_pretrained", "open", "sorted", "open", "open", "metrics.ner.eval_ner", "open", "fd.write", "str", "torch.distributed.get_rank", "os.path.exists", "results.keys", "writer.write", "result.keys", "writer.write", "open", "enumerate", "os.path.join", "MODEL_CLASSES.keys", "torch.cuda.is_available", "enumerate", "enumerate", "vars", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.join", "sorted", "result.items", "str", "str", "line.startswith", "writer.write", "glob.glob", "writer.write", "logger.warning", "line.split", "line.split", "predictions[].pop", "len", "line.split"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.set_seed", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_labels", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.load_and_cache_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.train", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.ner.eval_ner"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the training files for the CoNLL-2003 NER task.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--labels\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path to a file containing all labels. If not specified, CoNLL-2003 labels are used.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_predict\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run predictions on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run evaluation during training at each logging step.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--keep_accents\"", ",", "action", "=", "\"store_const\"", ",", "const", "=", "True", ",", "help", "=", "\"Set this flag if model is trained with accents.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--strip_accents\"", ",", "action", "=", "\"store_const\"", ",", "const", "=", "True", ",", "help", "=", "\"Set this flag if model is trained without accents.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_fast\"", ",", "action", "=", "\"store_const\"", ",", "const", "=", "True", ",", "help", "=", "\"Set this flag to use fast tokenization.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_ip\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_port\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "#ADD:", "\n", "parser", ".", "add_argument", "(", "\n", "\"--task_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "choices", "=", "{", "\n", "'bc5cdr'", ",", "\n", "'clefe'", ",", "\n", "}", ",", "\n", "help", "=", "\"The name of the selected task to train.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--use_tokenizer_config\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Ignore args of tokenizer and Use the setting of 'tokenizer_config.json' in the pre-trained model.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_every_epoch\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate the dev. dataset when every epoch reaches the end.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--result_prefix\"", ",", "\n", "default", "=", "''", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Prefix for eval_results.txt, test_predictions.txt, test_results_conlleval.txt and test_results.txt.\"", ",", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare BC5CDR/CLEFE task.", "\n", "global", "processor", "\n", "processor", "=", "PROCESSORS", "[", "args", ".", "task_name", "]", "(", ")", "\n", "labels", "=", "processor", ".", "get_labels", "(", ")", "\n", "num_labels", "=", "len", "(", "labels", ")", "\n", "\n", "# Use cross entropy ignore index as padding label id so that only real label ids contribute to the loss later", "\n", "pad_token_label_id", "=", "CrossEntropyLoss", "(", ")", ".", "ignore_index", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "id2label", "=", "{", "str", "(", "i", ")", ":", "label", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", "}", ",", "\n", "label2id", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", "}", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "tokenizer_args", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "vars", "(", "args", ")", ".", "items", "(", ")", "if", "v", "is", "not", "None", "and", "k", "in", "TOKENIZER_ARGS", "}", "\n", "logger", ".", "info", "(", "\"Tokenizer arguments: %s\"", ",", "tokenizer_args", ")", "\n", "if", "args", ".", "use_tokenizer_config", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", "**", "tokenizer_args", ",", "\n", ")", "\n", "\n", "", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"train\"", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "#MODIFY:", "\n", "        ", "if", "args", ".", "use_tokenizer_config", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "output_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "output_dir", ",", "\n", "**", "tokenizer_args", ",", "\n", ")", "\n", "", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "\n", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", "\n", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "_", ",", "report", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"dev\"", ",", "prefix", "=", "global_step", ")", "\n", "if", "global_step", ":", "\n", "                ", "result", "=", "{", "\"{}_{}\"", ".", "format", "(", "global_step", ",", "k", ")", ":", "v", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", "}", "\n", "", "results", ".", "update", "(", "result", ")", "\n", "", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "for", "key", "in", "sorted", "(", "results", ".", "keys", "(", ")", ")", ":", "\n", "                ", "writer", ".", "write", "(", "\"{} = {}\\n\"", ".", "format", "(", "key", ",", "str", "(", "results", "[", "key", "]", ")", ")", ")", "\n", "", "", "print", "(", "report", ")", "\n", "\n", "", "if", "args", ".", "do_predict", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "#MODIFY:", "\n", "        ", "if", "args", ".", "use_tokenizer_config", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "output_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "output_dir", ",", "\n", "**", "tokenizer_args", ",", "\n", ")", "\n", "", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "predictions", ",", "report", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"test\"", ")", "\n", "# Save results", "\n", "output_test_results_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"test_results.txt\"", ")", "\n", "with", "open", "(", "output_test_results_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                ", "writer", ".", "write", "(", "\"{} = {}\\n\"", ".", "format", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "# Save predictions", "\n", "", "", "output_test_predictions_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"test_predictions.txt\"", ")", "\n", "with", "open", "(", "output_test_predictions_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "if", "args", ".", "task_name", "==", "'bc5cdr'", ":", "\n", "                ", "test_file", "=", "'test.tsv'", "\n", "", "elif", "args", ".", "task_name", "==", "'clefe'", ":", "\n", "                ", "test_file", "=", "'Test.tsv'", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "test_file", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "example_id", "=", "0", "\n", "tokens", "=", "[", "]", "\n", "true_labels", "=", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                    ", "if", "line", ".", "startswith", "(", "\"-DOCSTART-\"", ")", "or", "line", "==", "\"\"", "or", "line", "==", "\"\\n\"", ":", "\n", "                        ", "writer", ".", "write", "(", "line", ")", "\n", "if", "not", "predictions", "[", "example_id", "]", ":", "\n", "                            ", "example_id", "+=", "1", "\n", "", "", "elif", "predictions", "[", "example_id", "]", ":", "\n", "                        ", "tok", "=", "line", ".", "split", "(", ")", "[", "0", "]", "\n", "true_label", "=", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "output_line", "=", "tok", "+", "\" \"", "+", "true_label", "+", "\" \"", "+", "predictions", "[", "example_id", "]", ".", "pop", "(", "0", ")", "+", "\"\\n\"", "\n", "writer", ".", "write", "(", "output_line", ")", "\n", "#ADD:", "\n", "if", "not", "predictions", "[", "example_id", "]", "and", "len", "(", "predictions", ")", "!=", "example_id", "+", "1", ":", "\n", "                            ", "example_id", "+=", "1", "\n", "", "", "else", ":", "\n", "                        ", "logger", ".", "warning", "(", "\"Maximum sequence length exceeded: No prediction for '%s'.\"", ",", "line", ".", "split", "(", ")", "[", "0", "]", ")", "\n", "\n", "", "", "", "", "logger", ".", "info", "(", "\"Finished writing test_predictions.txt (token y_true y_pred) :\"", ")", "\n", "\n", "# Evaluate BLUE metrics(load the prediciton file).", "\n", "with", "open", "(", "output_test_predictions_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "_", ",", "report", "=", "eval_ner", "(", "f", ")", "\n", "", "print", "(", "report", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"test_results_count.txt\"", ")", ",", "\"w\"", ")", "as", "fd", ":", "\n", "            ", "fd", ".", "write", "(", "report", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_label_classifier.set_seed": [[75, 81], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_label_classifier.train": [[83, 290], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "os.path.exists", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_multi_label_classifier.set_seed", "SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "os.path.isfile", "os.path.isfile", "transformers.AdamW.load_state_dict", "transformers.get_linear_schedule_with_warmup.load_state_dict", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "logger.info", "logger.info", "logger.info", "logger.info", "int", "tqdm.tqdm", "enumerate", "SummaryWriter.close", "os.path.join", "os.path.join", "torch.load", "torch.load", "int", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "os.path.join", "os.path.join", "ImportError", "torch.distributed.get_world_size", "len", "len", "loss.mean.mean", "loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "[].split", "t.to", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "logs.items", "print", "os.path.join", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "torch.save", "torch.save", "logger.info", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_multi_label_classifier.evaluate", "results.items", "transformers.get_linear_schedule_with_warmup.get_lr", "SummaryWriter.add_scalar", "json.dumps", "run_multi_label_classifier.evaluate", "int", "os.path.join", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "transformers.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "os.makedirs", "os.path.exists", "open", "writer.write", "args.model_name_or_path.split", "os.path.exists", "open", "writer.write"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.set_seed", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.train", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate"], ["", "", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "and", "os", ".", "path", ".", "isfile", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", "\n", ")", ":", "\n", "# Load in optimizer and scheduler states", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", ",", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ":", "\n", "# set global_step to global_step of last saved checkpoint from model path", "\n", "        ", "try", ":", "\n", "            ", "global_step", "=", "int", "(", "args", ".", "model_name_or_path", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "0", "]", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "global_step", "=", "0", "\n", "", "epochs_trained", "=", "global_step", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "steps_trained_in_current_epoch", "=", "global_step", "%", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "\n", "logger", ".", "info", "(", "\"  Continuing training from checkpoint, will skip to saved global_step\"", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from epoch %d\"", ",", "epochs_trained", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from global step %d\"", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"  Will skip the first %d steps in the first epoch\"", ",", "steps_trained_in_current_epoch", ")", "\n", "\n", "", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", ",", "\"albert\"", "]", "else", "None", "\n", ")", "# XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids", "\n", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                    ", "logs", "=", "{", "}", "\n", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", ",", "_", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "mode", "=", "\"dev\"", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "eval_key", "=", "\"eval_{}\"", ".", "format", "(", "key", ")", "\n", "logs", "[", "eval_key", "]", "=", "value", "\n", "\n", "", "", "loss_scalar", "=", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", "\n", "learning_rate_scalar", "=", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "logs", "[", "\"learning_rate\"", "]", "=", "learning_rate_scalar", "\n", "logs", "[", "\"loss\"", "]", "=", "loss_scalar", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "for", "key", ",", "value", "in", "logs", ".", "items", "(", ")", ":", "\n", "                        ", "tb_writer", ".", "add_scalar", "(", "key", ",", "value", ",", "global_step", ")", "\n", "", "print", "(", "json", ".", "dumps", "(", "{", "**", "logs", ",", "**", "{", "\"step\"", ":", "global_step", "}", "}", ")", ")", "\n", "\n", "#ADD:", "\n", "# use \"--eval_every_epoch\" insted of \"--evaluate_during_training\".", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", "==", "0", "and", "args", ".", "eval_every_epoch", ":", "\n", "                    ", "if", "global_step", "%", "(", "t_total", "/", "args", ".", "num_train_epochs", ")", "==", "0", ":", "\n", "                        ", "results", ",", "_", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "mode", "=", "\"dev\"", ",", "prefix", "=", "\"dev.tsv\"", ")", "\n", "results", "[", "'gs'", "]", "=", "global_step", "\n", "results", "[", "'epochs'", "]", "=", "int", "(", "global_step", "/", "t_total", "*", "args", ".", "num_train_epochs", ")", "\n", "\n", "output_dev_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"dev_results.txt\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dev_file", ")", ":", "\n", "                            ", "with", "open", "(", "output_dev_file", ",", "'w'", ")", "as", "writer", ":", "\n", "                                ", "writer", ".", "write", "(", "'Global_step,Epochs,Loss,Prec,Rec,FB1,Micro_ROC_AUC\\n'", ")", "\n", "", "", "with", "open", "(", "output_dev_file", ",", "'a'", ")", "as", "writer", ":", "\n", "                            ", "writer", ".", "write", "(", "\n", "'{gs},{epochs},{loss},{precision},{recall},{FB1},{micro_roc_auc}\\n'", ".", "format", "(", "**", "results", ")", "\n", ")", "\n", "\n", "", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_label_classifier.evaluate": [[292, 389], ["run_multi_label_classifier.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "tqdm.tqdm", "pandas.read_csv", "list", "metrics.hoc.eval_hoc", "metrics.hoc.eval_roc_auc", "os.path.join", "os.makedirs", "max", "torch.nn.DataParallel", "len", "torch.nn.DataParallel.eval", "tuple", "os.path.join", "map", "open", "logger.info", "metrics.hoc.eval_hoc.keys", "os.path.join", "os.path.join", "os.path.exists", "isinstance", "torch.no_grad", "torch.nn.DataParallel.", "logits.sigmoid.sigmoid", "tmp_eval_loss.mean().item", "logits.sigmoid.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "logger.info", "writer.write", "open", "logger.info", "open", "logger.info", "metrics.hoc.eval_roc_auc.keys", "t.to", "logits.sigmoid.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "str", "writer.write", "logger.info", "writer.write", "tmp_eval_loss.mean", "logits.sigmoid.detach().cpu", "inputs[].detach().cpu", "str", "logits.sigmoid.detach().cpu", "inputs[].detach().cpu", "str", "logits.sigmoid.detach", "inputs[].detach", "enumerate", "str", "logits.sigmoid.detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.load_and_cache_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.hoc.eval_hoc", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.hoc.eval_roc_auc"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "mode", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "eval_task", "=", "args", ".", "task_name", "\n", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "\n", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "eval_task", ",", "tokenizer", ",", "mode", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu eval", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "not", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", ",", "\"albert\"", "]", "else", "None", "\n", ")", "# XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "logits", "=", "logits", ".", "sigmoid", "(", ")", "# for multi label classification", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "            ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "\n", "# create DataFrame to compare y_pred with y_true.", "\n", "df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"{}.tsv\"", ".", "format", "(", "mode", ")", ")", ",", "\n", "sep", "=", "'\\t'", ")", "\n", "\n", "# compute F1-score for HoC", "\n", "threshold", "=", "0.5", "\n", "y_pred", "=", "(", "preds", ">", "threshold", ")", ".", "astype", "(", "int", ")", "\n", "df", "[", "'pred_labels'", "]", "=", "list", "(", "map", "(", "lambda", "x", ":", "','", ".", "join", "(", "[", "'{}_{}'", ".", "format", "(", "i", ",", "v", ")", "\n", "for", "i", ",", "v", "in", "enumerate", "(", "x", ")", "]", ")", ",", "y_pred", ")", ")", "\n", "\n", "result", "=", "eval_hoc", "(", "df", ",", "mode", ")", "\n", "\n", "# compute ROC-AUC for multi label classification", "\n", "roc_auc", "=", "eval_roc_auc", "(", "out_label_ids", ",", "preds", ",", "args", ".", "num_labels", ")", "\n", "result", "[", "'micro_roc_auc'", "]", "=", "roc_auc", "[", "'micro'", "]", "\n", "\n", "result", "[", "'loss'", "]", "=", "eval_loss", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"{}_results.txt\"", ".", "format", "(", "\n", "mode", "if", "mode", "!=", "'dev'", "else", "'eval'", ")", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "if", "args", ".", "output_all_logits", ":", "\n", "        ", "output_all_logit_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"{}_all_logits.txt\"", ".", "format", "(", "mode", ")", ")", "\n", "with", "open", "(", "output_all_logit_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "logger", ".", "info", "(", "\"***** Output all logits {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "sample", "in", "preds", ":", "\n", "                ", "writer", ".", "write", "(", "'\\t'", ".", "join", "(", "[", "'{:.3f}'", ".", "format", "(", "v", ")", "for", "v", "in", "sample", "]", ")", "+", "'\\n'", ")", "\n", "\n", "# output ROC curve and ROC area for each class", "\n", "", "", "output_roc_auc_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"{}_roc_auc_for_each_class.txt\"", ".", "format", "(", "mode", ")", ")", "\n", "with", "open", "(", "output_roc_auc_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "logger", ".", "info", "(", "\"***** output ROC curve and ROC area for each class {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "roc_auc", ".", "keys", "(", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "roc_auc", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "roc_auc", "[", "key", "]", ")", ")", ")", "\n", "\n", "\n", "", "", "", "return", "result", ",", "preds", ",", "df", "[", "[", "'index'", ",", "'labels'", ",", "'pred_labels'", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_label_classifier.load_and_cache_examples": [[391, 446], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.distributed.barrier", "os.path.exists", "logger.info", "torch.load", "logger.info", "processor.get_labels", "processors.utils_blue.convert_multi_label_examples_to_features", "torch.distributed.barrier", "list().pop", "str", "str", "processor.get_train_examples", "logger.info", "torch.save", "processor.get_dev_examples", "bool", "list", "processor.get_test_examples", "tokenizer.convert_tokens_to_ids", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_labels", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.convert_multi_label_examples_to_features", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_train_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_dev_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor.get_test_examples"], ["", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "mode", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "output_mode", "=", "output_modes", "[", "task", "]", "\n", "# Load data features from cache or dataset file", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "data_dir", ",", "\n", "\"cached_{}_{}_{}_{}\"", ".", "format", "(", "\n", "mode", ",", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "str", "(", "task", ")", ",", "\n", ")", ",", "\n", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "args", ".", "data_dir", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "# REPLACE:", "\n", "if", "mode", "==", "\"train\"", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "", "elif", "mode", "==", "\"dev\"", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "\n", "", "elif", "mode", "==", "\"test\"", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ")", "\n", "\n", "", "features", "=", "convert_examples_to_features", "(", "\n", "examples", ",", "\n", "tokenizer", ",", "\n", "label_list", "=", "label_list", ",", "\n", "max_length", "=", "args", ".", "max_seq_length", ",", "\n", "output_mode", "=", "output_mode", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "tokenizer", ".", "pad_token", "]", ")", "[", "0", "]", ",", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_attention_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "attention_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_token_type_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "token_type_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_attention_mask", ",", "all_token_type_ids", ",", "all_labels", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_label_classifier.main": [[448, 784], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_multi_label_classifier.set_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "tokenizer_class.from_pretrained", "tokenizer_class.from_pretrained", "torch.distributed.barrier", "run_multi_label_classifier.load_and_cache_examples", "run_multi_label_classifier.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "logger.info", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_multi_label_classifier.evaluate", "os.path.join", "pred_df.to_csv", "logger.info", "torch.cuda.device_count", "bool", "os.makedirs", "hasattr", "os.path.join", "tokenizer_class.from_pretrained", "tokenizer_class.from_pretrained", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_multi_label_classifier.evaluate", "dict", "tokenizer_class.from_pretrained", "tokenizer_class.from_pretrained", "os.path.join", "torch.distributed.get_rank", "os.path.exists", "MODEL_CLASSES.keys", "processors.utils_blue.blue_processors.keys", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "sorted", "dict.items", "glob.glob"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.set_seed", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_labels", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.load_and_cache_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.train", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--task_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train selected in the list: \"", "+", "\", \"", ".", "join", "(", "processors", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_ip\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_port\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "#ADD:", "\n", "parser", ".", "add_argument", "(", "\"--do_predict\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run predictions on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--use_tokenizer_config\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Ignore args of tokenizer and Use the setting of 'tokenizer_config.json' in the pre-trained model.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_every_epoch\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate the dev. dataset when every epoch reaches the end.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--result_prefix\"", ",", "\n", "default", "=", "''", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Prefix for eval_results.txt, test_predictions.txt, test_results_conlleval.txt and test_results.txt.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_all_logits\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Output all logits.\"", ",", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare BLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "args", ".", "num_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "args", ".", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "if", "args", ".", "use_tokenizer_config", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "\n", "", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "args", ".", "task_name", ",", "tokenizer", ",", "mode", "=", "\"train\"", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "#         model = model_class.from_pretrained(args.output_dir)", "\n", "#         tokenizer = tokenizer_class.from_pretrained(args.output_dir)", "\n", "#         model.to(args.device)", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "#MODIFY:", "\n", "        ", "if", "args", ".", "use_tokenizer_config", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "output_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "\n", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", "\n", ")", "\n", "logging", ".", "getLogger", "(", "\"transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "prefix", "=", "checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "if", "checkpoint", ".", "find", "(", "\"checkpoint\"", ")", "!=", "-", "1", "else", "\"\"", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "_", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "mode", "=", "\"dev\"", ",", "prefix", "=", "\"dev.tsv\"", ")", "\n", "result", "=", "dict", "(", "(", "k", "+", "\"_{}\"", ".", "format", "(", "global_step", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "\n", "#ADD:", "\n", "", "", "if", "args", ".", "do_predict", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "if", "args", ".", "use_tokenizer_config", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "output_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "pred_score", ",", "pred_df", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "mode", "=", "\"test\"", ",", "\n", "prefix", "=", "\"test.tsv\"", ")", "\n", "# Save results", "\n", "#         output_test_results_file = os.path.join(args.output_dir,", "\n", "#                                                 args.result_prefix + \"test_results.txt\")", "\n", "#         with open(output_test_results_file, \"w\") as writer:", "\n", "#             for key in sorted(result.keys()):", "\n", "#                 writer.write(\"{} = {}\\n\".format(key, str(result[key])))", "\n", "\n", "# Save predictions", "\n", "output_test_predictions_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"test_predictions.txt\"", ")", "\n", "pred_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"test_predictions.tsv\"", ")", ",", "\n", "index", "=", "False", ",", "sep", "=", "\"\\t\"", ")", "\n", "logger", ".", "info", "(", "\"Finished writing test_predictions.tsv (index y_true y_pred) :\"", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_sts.set_seed": [[70, 76], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_sts.train": [[78, 285], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "os.path.exists", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_sts.set_seed", "SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "os.path.isfile", "os.path.isfile", "transformers.AdamW.load_state_dict", "transformers.get_linear_schedule_with_warmup.load_state_dict", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "logger.info", "logger.info", "logger.info", "logger.info", "int", "tqdm.tqdm", "enumerate", "SummaryWriter.close", "os.path.join", "os.path.join", "torch.load", "torch.load", "int", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "os.path.join", "os.path.join", "ImportError", "torch.distributed.get_world_size", "len", "len", "loss.mean.mean", "loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "[].split", "t.to", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "logs.items", "print", "os.path.join", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "torch.save", "torch.save", "logger.info", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_sts.evaluate", "results.items", "transformers.get_linear_schedule_with_warmup.get_lr", "SummaryWriter.add_scalar", "json.dumps", "run_sts.evaluate", "int", "os.path.join", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "transformers.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "os.makedirs", "os.path.exists", "open", "writer.write", "args.model_name_or_path.split", "os.path.exists", "open", "writer.write"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.set_seed", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.train", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate"], ["", "", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "and", "os", ".", "path", ".", "isfile", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", "\n", ")", ":", "\n", "# Load in optimizer and scheduler states", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", ",", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ":", "\n", "# set global_step to global_step of last saved checkpoint from model path", "\n", "        ", "try", ":", "\n", "            ", "global_step", "=", "int", "(", "args", ".", "model_name_or_path", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "0", "]", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "global_step", "=", "0", "\n", "", "epochs_trained", "=", "global_step", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "steps_trained_in_current_epoch", "=", "global_step", "%", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "\n", "logger", ".", "info", "(", "\"  Continuing training from checkpoint, will skip to saved global_step\"", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from epoch %d\"", ",", "epochs_trained", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from global step %d\"", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"  Will skip the first %d steps in the first epoch\"", ",", "steps_trained_in_current_epoch", ")", "\n", "\n", "", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", ",", "\"albert\"", "]", "else", "None", "\n", ")", "# XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids", "\n", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                    ", "logs", "=", "{", "}", "\n", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "mode", "=", "\"dev\"", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "eval_key", "=", "\"eval_{}\"", ".", "format", "(", "key", ")", "\n", "logs", "[", "eval_key", "]", "=", "value", "\n", "\n", "", "", "loss_scalar", "=", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", "\n", "learning_rate_scalar", "=", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "logs", "[", "\"learning_rate\"", "]", "=", "learning_rate_scalar", "\n", "logs", "[", "\"loss\"", "]", "=", "loss_scalar", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "for", "key", ",", "value", "in", "logs", ".", "items", "(", ")", ":", "\n", "                        ", "tb_writer", ".", "add_scalar", "(", "key", ",", "value", ",", "global_step", ")", "\n", "", "print", "(", "json", ".", "dumps", "(", "{", "**", "logs", ",", "**", "{", "\"step\"", ":", "global_step", "}", "}", ")", ")", "\n", "\n", "#ADD:", "\n", "# use \"--eval_every_epoch\" insted of \"--evaluate_during_training\".", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", "==", "0", "and", "args", ".", "eval_every_epoch", ":", "\n", "                    ", "if", "global_step", "%", "(", "t_total", "/", "args", ".", "num_train_epochs", ")", "==", "0", ":", "\n", "                        ", "results", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "mode", "=", "\"dev\"", ",", "prefix", "=", "\"dev.tsv\"", ")", "\n", "results", "[", "'gs'", "]", "=", "global_step", "\n", "results", "[", "'epochs'", "]", "=", "int", "(", "global_step", "/", "t_total", "*", "args", ".", "num_train_epochs", ")", "\n", "\n", "output_dev_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"dev_results.txt\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dev_file", ")", ":", "\n", "                            ", "with", "open", "(", "output_dev_file", ",", "'w'", ")", "as", "writer", ":", "\n", "                                ", "writer", ".", "write", "(", "'Global_step,Epochs,Loss,Pearson\\n'", ")", "\n", "", "", "with", "open", "(", "output_dev_file", ",", "'a'", ")", "as", "writer", ":", "\n", "                            ", "writer", ".", "write", "(", "\n", "'{gs},{epochs},{loss},{pearson}\\n'", ".", "format", "(", "**", "results", ")", "\n", ")", "\n", "\n", "", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_sts.evaluate": [[287, 359], ["run_sts.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "tqdm.tqdm", "os.path.join", "os.makedirs", "max", "torch.nn.DataParallel", "len", "torch.nn.DataParallel.eval", "tuple", "numpy.argmax", "metrics.sts.eval_sts", "len", "open", "logger.info", "result.keys", "os.path.exists", "isinstance", "torch.no_grad", "torch.nn.DataParallel.", "tmp_eval_loss.mean().item", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "numpy.squeeze", "logger.info", "writer.write", "t.to", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "str", "tmp_eval_loss.mean", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach().cpu", "inputs[].detach().cpu", "str", "logits.detach", "inputs[].detach", "logits.detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.load_and_cache_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.sts.eval_sts"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "mode", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "eval_task", "=", "args", ".", "task_name", "\n", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "\n", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "eval_task", ",", "tokenizer", ",", "mode", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu eval", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "not", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", ",", "\"albert\"", "]", "else", "None", "\n", ")", "# XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "            ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "if", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "        ", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "", "elif", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "        ", "preds", "=", "np", ".", "squeeze", "(", "preds", ")", "\n", "\n", "", "result", "=", "{", "\n", "'pearson'", ":", "eval_sts", "(", "out_label_ids", ",", "preds", ")", ",", "\n", "'num'", ":", "len", "(", "eval_dataset", ")", ",", "\n", "}", "\n", "\n", "\n", "result", "[", "'loss'", "]", "=", "eval_loss", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"{}_results.txt\"", ".", "format", "(", "\n", "mode", "if", "mode", "!=", "'dev'", "else", "'eval'", ")", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "return", "result", ",", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_sts.load_and_cache_examples": [[361, 418], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.distributed.barrier", "os.path.exists", "logger.info", "torch.load", "logger.info", "processor.get_labels", "processors.utils_blue.blue_convert_examples_to_features", "torch.distributed.barrier", "torch.tensor", "list().pop", "str", "str", "processor.get_train_examples", "logger.info", "torch.save", "torch.tensor", "processor.get_dev_examples", "bool", "list", "processor.get_test_examples", "tokenizer.convert_tokens_to_ids", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_labels", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.blue_convert_examples_to_features", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_train_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_dev_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor.get_test_examples"], ["", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "mode", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "output_mode", "=", "output_modes", "[", "task", "]", "\n", "# Load data features from cache or dataset file", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "data_dir", ",", "\n", "\"cached_{}_{}_{}_{}\"", ".", "format", "(", "\n", "mode", ",", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "str", "(", "task", ")", ",", "\n", ")", ",", "\n", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "args", ".", "data_dir", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "# REPLACE:", "\n", "if", "mode", "==", "\"train\"", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "", "elif", "mode", "==", "\"dev\"", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "\n", "", "elif", "mode", "==", "\"test\"", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ")", "\n", "\n", "", "features", "=", "convert_examples_to_features", "(", "\n", "examples", ",", "\n", "tokenizer", ",", "\n", "label_list", "=", "label_list", ",", "\n", "max_length", "=", "args", ".", "max_seq_length", ",", "\n", "output_mode", "=", "output_mode", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "tokenizer", ".", "pad_token", "]", ")", "[", "0", "]", ",", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_attention_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "attention_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_token_type_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "token_type_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "        ", "all_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "        ", "all_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_attention_mask", ",", "all_token_type_ids", ",", "all_labels", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_sts.main": [[420, 755], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_sts.set_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "tokenizer_class.from_pretrained", "tokenizer_class.from_pretrained", "torch.distributed.barrier", "run_sts.load_and_cache_examples", "run_sts.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "logger.info", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_sts.evaluate", "os.path.join", "processor.get_y_true", "logger.info", "torch.cuda.device_count", "bool", "os.makedirs", "hasattr", "os.path.join", "tokenizer_class.from_pretrained", "tokenizer_class.from_pretrained", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_sts.evaluate", "dict", "tokenizer_class.from_pretrained", "tokenizer_class.from_pretrained", "open", "zip", "torch.distributed.get_rank", "os.path.exists", "writer.write", "MODEL_CLASSES.keys", "processors.utils_blue.blue_processors.keys", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "sorted", "dict.items", "glob.glob"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.set_seed", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_labels", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.load_and_cache_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.train", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor.get_y_true", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--task_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train selected in the list: \"", "+", "\", \"", ".", "join", "(", "processors", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_ip\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_port\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "#ADD:", "\n", "parser", ".", "add_argument", "(", "\"--do_predict\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run predictions on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--use_tokenizer_config\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Ignore args of tokenizer and Use the setting of 'tokenizer_config.json' in the pre-trained model.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_every_epoch\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate the dev. dataset when every epoch reaches the end.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--result_prefix\"", ",", "\n", "default", "=", "''", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Prefix for eval_results.txt, test_predictions.txt, test_results_conlleval.txt and test_results.txt.\"", ",", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare BLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "args", ".", "label_list", "=", "label_list", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "if", "args", ".", "use_tokenizer_config", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "\n", "", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "args", ".", "task_name", ",", "tokenizer", ",", "mode", "=", "\"train\"", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "#         model = model_class.from_pretrained(args.output_dir)", "\n", "#         tokenizer = tokenizer_class.from_pretrained(args.output_dir)", "\n", "#         model.to(args.device)", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "#MODIFY:", "\n", "        ", "if", "args", ".", "use_tokenizer_config", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "output_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "\n", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", "\n", ")", "\n", "logging", ".", "getLogger", "(", "\"transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "prefix", "=", "checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "if", "checkpoint", ".", "find", "(", "\"checkpoint\"", ")", "!=", "-", "1", "else", "\"\"", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "mode", "=", "\"dev\"", ",", "prefix", "=", "\"dev.tsv\"", ")", "\n", "result", "=", "dict", "(", "(", "k", "+", "\"_{}\"", ".", "format", "(", "global_step", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "\n", "#ADD:", "\n", "", "", "if", "args", ".", "do_predict", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "if", "args", ".", "use_tokenizer_config", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "output_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "predictions", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "mode", "=", "\"test\"", ",", "\n", "prefix", "=", "\"test.tsv\"", ")", "\n", "# Save results", "\n", "#         output_test_results_file = os.path.join(args.output_dir,", "\n", "#                                                 args.result_prefix + \"test_results.txt\")", "\n", "#         with open(output_test_results_file, \"w\") as writer:", "\n", "#             for key in sorted(result.keys()):", "\n", "#                 writer.write(\"{} = {}\\n\".format(key, str(result[key])))", "\n", "\n", "# Save predictions", "\n", "output_test_predictions_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"test_predictions.txt\"", ")", "\n", "y_true", "=", "processor", ".", "get_y_true", "(", "args", ".", "data_dir", ",", "\"test\"", ")", "\n", "y_pred", "=", "predictions", "\n", "\n", "with", "open", "(", "output_test_predictions_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "for", "true", ",", "pred", "in", "zip", "(", "y_true", ",", "y_pred", ")", ":", "\n", "                ", "writer", ".", "write", "(", "'{}\\t{}\\n'", ".", "format", "(", "true", ",", "pred", ")", ")", "\n", "", "", "logger", ".", "info", "(", "\"Finished writing test_predictions.txt (y_true y_pred) :\"", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.set_seed": [[94, 100], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.train": [[102, 309], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "os.path.exists", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_multi_class_classifier.set_seed", "SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "os.path.isfile", "os.path.isfile", "transformers.AdamW.load_state_dict", "transformers.get_linear_schedule_with_warmup.load_state_dict", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "logger.info", "logger.info", "logger.info", "logger.info", "int", "tqdm.tqdm", "enumerate", "SummaryWriter.close", "os.path.join", "os.path.join", "torch.load", "torch.load", "int", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "os.path.join", "os.path.join", "ImportError", "torch.distributed.get_world_size", "len", "len", "loss.mean.mean", "loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "[].split", "t.to", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "logs.items", "print", "os.path.join", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "torch.save", "torch.save", "logger.info", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_multi_class_classifier.evaluate", "results.items", "transformers.get_linear_schedule_with_warmup.get_lr", "SummaryWriter.add_scalar", "json.dumps", "run_multi_class_classifier.evaluate", "int", "os.path.join", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "transformers.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "os.makedirs", "os.path.exists", "open", "writer.write", "args.model_name_or_path.split", "os.path.exists", "open", "writer.write", "eval_dev_log_order[].format"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.set_seed", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.train", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate"], ["", "", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "and", "os", ".", "path", ".", "isfile", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", "\n", ")", ":", "\n", "# Load in optimizer and scheduler states", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", ",", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ":", "\n", "# set global_step to global_step of last saved checkpoint from model path", "\n", "        ", "try", ":", "\n", "            ", "global_step", "=", "int", "(", "args", ".", "model_name_or_path", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "0", "]", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "global_step", "=", "0", "\n", "", "epochs_trained", "=", "global_step", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "steps_trained_in_current_epoch", "=", "global_step", "%", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "\n", "logger", ".", "info", "(", "\"  Continuing training from checkpoint, will skip to saved global_step\"", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from epoch %d\"", ",", "epochs_trained", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from global step %d\"", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"  Will skip the first %d steps in the first epoch\"", ",", "steps_trained_in_current_epoch", ")", "\n", "\n", "", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", ",", "\"albert\"", "]", "else", "None", "\n", ")", "# XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids", "\n", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                    ", "logs", "=", "{", "}", "\n", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "mode", "=", "\"dev\"", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "eval_key", "=", "\"eval_{}\"", ".", "format", "(", "key", ")", "\n", "logs", "[", "eval_key", "]", "=", "value", "\n", "\n", "", "", "loss_scalar", "=", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", "\n", "learning_rate_scalar", "=", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "logs", "[", "\"learning_rate\"", "]", "=", "learning_rate_scalar", "\n", "logs", "[", "\"loss\"", "]", "=", "loss_scalar", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "for", "key", ",", "value", "in", "logs", ".", "items", "(", ")", ":", "\n", "                        ", "tb_writer", ".", "add_scalar", "(", "key", ",", "value", ",", "global_step", ")", "\n", "", "print", "(", "json", ".", "dumps", "(", "{", "**", "logs", ",", "**", "{", "\"step\"", ":", "global_step", "}", "}", ")", ")", "\n", "\n", "#ADD:", "\n", "# use \"--eval_every_epoch\" insted of \"--evaluate_during_training\".", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", "==", "0", "and", "args", ".", "eval_every_epoch", ":", "\n", "                    ", "if", "global_step", "%", "(", "t_total", "/", "args", ".", "num_train_epochs", ")", "==", "0", ":", "\n", "                        ", "results", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "mode", "=", "\"dev\"", ",", "prefix", "=", "\"dev.tsv\"", ")", "\n", "results", "[", "'gs'", "]", "=", "global_step", "\n", "results", "[", "'epochs'", "]", "=", "int", "(", "global_step", "/", "t_total", "*", "args", ".", "num_train_epochs", ")", "\n", "\n", "output_dev_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"dev_results.txt\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dev_file", ")", ":", "\n", "                            ", "with", "open", "(", "output_dev_file", ",", "'w'", ")", "as", "writer", ":", "\n", "                                ", "writer", ".", "write", "(", "eval_dev_log_header", "[", "args", ".", "task_name", "]", ")", "\n", "", "", "with", "open", "(", "output_dev_file", ",", "'a'", ")", "as", "writer", ":", "\n", "                            ", "writer", ".", "write", "(", "\n", "eval_dev_log_order", "[", "args", ".", "task_name", "]", ".", "format", "(", "**", "results", ")", "\n", ")", "\n", "\n", "", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate": [[311, 381], ["run_multi_class_classifier.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "tqdm.tqdm", "np.squeeze.copy", "os.path.join", "os.makedirs", "max", "torch.nn.DataParallel", "len", "torch.nn.DataParallel.eval", "tuple", "numpy.argmax", "open", "logger.info", "result.keys", "os.path.exists", "isinstance", "torch.no_grad", "torch.nn.DataParallel.", "tmp_eval_loss.mean().item", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "numpy.squeeze", "logger.info", "writer.write", "t.to", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "str", "tmp_eval_loss.mean", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach().cpu", "inputs[].detach().cpu", "str", "logits.detach", "inputs[].detach", "logits.detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.load_and_cache_examples"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "mode", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "eval_task", "=", "args", ".", "task_name", "\n", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "\n", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "eval_task", ",", "tokenizer", ",", "mode", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu eval", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "not", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", ",", "\"albert\"", "]", "else", "None", "\n", ")", "# XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "            ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "preds_score", "=", "preds", ".", "copy", "(", ")", "\n", "if", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "        ", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "", "elif", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "        ", "preds", "=", "np", ".", "squeeze", "(", "preds", ")", "\n", "\n", "", "result", ",", "_", "=", "eval_metrics", "[", "args", ".", "task_name", "]", "(", "out_label_ids", ",", "preds", ",", "args", ".", "label_list", ")", "\n", "\n", "\n", "result", "[", "'loss'", "]", "=", "eval_loss", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"{}_results.txt\"", ".", "format", "(", "\n", "mode", "if", "mode", "!=", "'dev'", "else", "'eval'", ")", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "return", "result", ",", "preds_score", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.load_and_cache_examples": [[383, 440], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.distributed.barrier", "os.path.exists", "logger.info", "torch.load", "logger.info", "processor.get_labels", "processors.utils_blue.blue_convert_examples_to_features", "torch.distributed.barrier", "torch.tensor", "list().pop", "str", "str", "processor.get_train_examples", "logger.info", "torch.save", "torch.tensor", "processor.get_dev_examples", "bool", "list", "processor.get_test_examples", "tokenizer.convert_tokens_to_ids", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_labels", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.blue_convert_examples_to_features", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_train_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_dev_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor.get_test_examples"], ["", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "mode", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "output_mode", "=", "output_modes", "[", "task", "]", "\n", "# Load data features from cache or dataset file", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "data_dir", ",", "\n", "\"cached_{}_{}_{}_{}\"", ".", "format", "(", "\n", "mode", ",", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "str", "(", "task", ")", ",", "\n", ")", ",", "\n", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "args", ".", "data_dir", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "# REPLACE:", "\n", "if", "mode", "==", "\"train\"", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "", "elif", "mode", "==", "\"dev\"", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "\n", "", "elif", "mode", "==", "\"test\"", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ")", "\n", "\n", "", "features", "=", "convert_examples_to_features", "(", "\n", "examples", ",", "\n", "tokenizer", ",", "\n", "label_list", "=", "label_list", ",", "\n", "max_length", "=", "args", ".", "max_seq_length", ",", "\n", "output_mode", "=", "output_mode", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "tokenizer", ".", "pad_token", "]", ")", "[", "0", "]", ",", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_attention_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "attention_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_token_type_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "token_type_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "        ", "all_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "        ", "all_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_attention_mask", ",", "all_token_type_ids", ",", "all_labels", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.main": [[442, 788], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_multi_class_classifier.set_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "tokenizer_class.from_pretrained", "tokenizer_class.from_pretrained", "torch.distributed.barrier", "run_multi_class_classifier.load_and_cache_examples", "run_multi_class_classifier.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "logger.info", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_multi_class_classifier.evaluate", "os.path.join", "list", "numpy.argmax", "logger.info", "logger.info", "report.to_csv", "logger.info", "torch.cuda.device_count", "enumerate", "enumerate", "bool", "os.makedirs", "hasattr", "os.path.join", "tokenizer_class.from_pretrained", "tokenizer_class.from_pretrained", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_multi_class_classifier.evaluate", "dict", "tokenizer_class.from_pretrained", "tokenizer_class.from_pretrained", "map", "open", "zip", "os.path.join", "torch.distributed.get_rank", "os.path.exists", "processor.get_y_true", "writer.write", "MODEL_CLASSES.keys", "processors.utils_blue.blue_processors.keys", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "sorted", "dict.items", "glob.glob"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.set_seed", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_labels", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.load_and_cache_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.train", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.utils.run_multi_class_classifier.evaluate", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor.get_y_true"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--task_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train selected in the list: \"", "+", "\", \"", ".", "join", "(", "processors", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_ip\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_port\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "#ADD:", "\n", "parser", ".", "add_argument", "(", "\"--do_predict\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run predictions on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--use_tokenizer_config\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Ignore args of tokenizer and Use the setting of 'tokenizer_config.json' in the pre-trained model.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_every_epoch\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate the dev. dataset when every epoch reaches the end.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--result_prefix\"", ",", "\n", "default", "=", "''", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Prefix for eval_results.txt, test_predictions.txt, test_results_conlleval.txt and test_results.txt.\"", ",", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare BLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "args", ".", "label_list", "=", "label_list", "\n", "label_to_id", "=", "{", "l", ":", "i", "for", "i", ",", "l", "in", "enumerate", "(", "label_list", ")", "}", "\n", "id_to_label", "=", "{", "i", ":", "l", "for", "i", ",", "l", "in", "enumerate", "(", "label_list", ")", "}", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "if", "args", ".", "use_tokenizer_config", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "\n", "", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "args", ".", "task_name", ",", "tokenizer", ",", "mode", "=", "\"train\"", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "#         model = model_class.from_pretrained(args.output_dir)", "\n", "#         tokenizer = tokenizer_class.from_pretrained(args.output_dir)", "\n", "#         model.to(args.device)", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "#MODIFY:", "\n", "        ", "if", "args", ".", "use_tokenizer_config", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "output_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "\n", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", "\n", ")", "\n", "logging", ".", "getLogger", "(", "\"transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "prefix", "=", "checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "if", "checkpoint", ".", "find", "(", "\"checkpoint\"", ")", "!=", "-", "1", "else", "\"\"", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "mode", "=", "\"dev\"", ",", "prefix", "=", "\"dev.tsv\"", ")", "\n", "result", "=", "dict", "(", "(", "k", "+", "\"_{}\"", ".", "format", "(", "global_step", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "\n", "#ADD:", "\n", "", "", "if", "args", ".", "do_predict", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "if", "args", ".", "use_tokenizer_config", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "output_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "predictions", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "mode", "=", "\"test\"", ",", "\n", "prefix", "=", "\"test.tsv\"", ")", "\n", "# Save results", "\n", "#         output_test_results_file = os.path.join(args.output_dir,", "\n", "#                                                 args.result_prefix + \"test_results.txt\")", "\n", "#         with open(output_test_results_file, \"w\") as writer:", "\n", "#             for key in sorted(result.keys()):", "\n", "#                 writer.write(\"{} = {}\\n\".format(key, str(result[key])))", "\n", "\n", "# Save predictions", "\n", "output_test_predictions_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"test_predictions.txt\"", ")", "\n", "y_true", "=", "list", "(", "map", "(", "label_to_id", ".", "get", ",", "processor", ".", "get_y_true", "(", "args", ".", "data_dir", ",", "\"test\"", ")", ")", ")", "\n", "y_pred", "=", "np", ".", "argmax", "(", "predictions", ",", "axis", "=", "1", ")", "\n", "\n", "with", "open", "(", "output_test_predictions_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "for", "true", ",", "pred", "in", "zip", "(", "y_true", ",", "y_pred", ")", ":", "\n", "                ", "writer", ".", "write", "(", "'{}\\t{}\\n'", ".", "format", "(", "id_to_label", "[", "true", "]", ",", "id_to_label", "[", "pred", "]", ")", ")", "\n", "", "", "logger", ".", "info", "(", "\"Finished writing test_predictions.txt (y_true y_pred) :\"", ")", "\n", "\n", "# Describe the detail of BLUE benchmark.", "\n", "logger", ".", "info", "(", "\"Evaluate test_predictions.txt by BLUE metrics:\"", ")", "\n", "_", ",", "report", "=", "eval_metrics", "[", "args", ".", "task_name", "]", "(", "y_true", "=", "y_true", ",", "y_pred", "=", "y_pred", ",", "label_list", "=", "label_list", ")", "\n", "\n", "report", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "result_prefix", "+", "\"test_results_classification_report.tsv\"", ")", ",", "\n", "index", "=", "False", ",", "sep", "=", "\"\\t\"", ")", "\n", "logger", ".", "info", "(", "\"Describe the report to test_results_classification_report.tsv.\"", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.models.BertForMultiLabelSequenceClassification.__init__": [[34, 43], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "models.BertForMultiLabelSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.SingleSentenceClassificationProcessor.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "pos_weight", "=", "None", ")", ":", "\n", "        ", "super", "(", "BertForMultiLabelSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "config", ".", "num_labels", ")", "\n", "self", ".", "pos_weight", "=", "pos_weight", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.models.BertForMultiLabelSequenceClassification.forward": [[44, 69], ["models.BertForMultiLabelSequenceClassification.bert", "models.BertForMultiLabelSequenceClassification.dropout", "models.BertForMultiLabelSequenceClassification.classifier", "torch.nn.BCEWithLogitsLoss", "labels.float.float.float", "torch.nn.BCEWithLogitsLoss.", "models.BertForMultiLabelSequenceClassification.view", "labels.float.float.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "BCEWithLogitsLoss", "(", "pos_weight", "=", "self", ".", "pos_weight", ")", "\n", "labels", "=", "labels", ".", "float", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "", "", "", ""]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.DataProcessor.get_train_examples": [[181, 184], ["NotImplementedError"], "methods", ["None"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.DataProcessor.get_dev_examples": [[185, 188], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.DataProcessor.get_test_examples": [[189, 192], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for prediction.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.DataProcessor.get_labels": [[193, 196], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.DataProcessor._read_tsv": [[197, 206], ["open", "csv.reader", "lines.append"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_read_tsv", "(", "cls", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.BlueBERTProcessor.get_train_examples": [[210, 214], ["utils_multilabel.BlueBERTProcessor._create_examples", "utils_multilabel.BlueBERTProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.BlueBERTProcessor.get_dev_examples": [[215, 219], ["utils_multilabel.BlueBERTProcessor._create_examples", "utils_multilabel.BlueBERTProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.BlueBERTProcessor.get_test_examples": [[220, 224], ["utils_multilabel.BlueBERTProcessor._create_examples", "utils_multilabel.BlueBERTProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.BlueBERTProcessor._create_examples": [[225, 251], ["enumerate", "tokenization.convert_to_unicode", "examples.append", "utils.InputExample", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "logging.exception", "exit", "logging.exception", "exit"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "# skip header", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "line", "[", "0", "]", "\n", "text_a", "=", "convert_to_unicode", "(", "line", "[", "1", "]", ")", "\n", "if", "set_type", "==", "\"test\"", ":", "\n", "# MODIFY:", "\n", "# We add the option \"--predict\" to calculate metrics and to describe outputs.", "\n", "# label = self.get_labels()[-1]", "\n", "                ", "try", ":", "\n", "                    ", "label", "=", "convert_to_unicode", "(", "line", "[", "2", "]", ")", "\n", "", "except", "IndexError", ":", "\n", "                    ", "logging", ".", "exception", "(", "line", ")", "\n", "exit", "(", "1", ")", "\n", "", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "label", "=", "convert_to_unicode", "(", "line", "[", "2", "]", ")", "\n", "", "except", "IndexError", ":", "\n", "                    ", "logging", ".", "exception", "(", "line", ")", "\n", "exit", "(", "1", ")", "\n", "", "", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.BlueBERTProcessor.get_y_true": [[253, 265], ["os.path.join", "open", "csv.reader", "enumerate", "labels.append", "tokenization.convert_to_unicode"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode"], ["", "def", "get_y_true", "(", "self", ",", "data_dir", ",", "set_type", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Read labels for evaluation.\"\"\"", "\n", "input_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.tsv\"", ".", "format", "(", "set_type", ")", ")", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "labels", "=", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "reader", ")", ":", "\n", "# skip header", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "labels", ".", "append", "(", "convert_to_unicode", "(", "line", "[", "2", "]", ")", ")", "\n", "", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.ChemProtProcessor.get_labels": [[267, 270], ["None"], "methods", ["None"], ["    ", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"CPR:3\"", ",", "\"CPR:4\"", ",", "\"CPR:5\"", ",", "\"CPR:6\"", ",", "\"CPR:9\"", ",", "\"false\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.DDI2013Processor.get_labels": [[273, 275], ["None"], "methods", ["None"], ["    ", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "return", "[", "\"DDI-advise\"", ",", "\"DDI-effect\"", ",", "\"DDI-int\"", ",", "\"DDI-mechanism\"", ",", "'DDI-false'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.I2b2_2010_Processor.get_labels": [[278, 280], ["None"], "methods", ["None"], ["    ", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "return", "[", "'PIP'", ",", "'TeCP'", ",", "'TeRP'", ",", "'TrAP'", ",", "'TrCP'", ",", "'TrIP'", ",", "'TrNAP'", ",", "'TrWP'", ",", "'false'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.StsProcessor.get_example_from_tensor_dict": [[285, 292], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["None"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"sentence1\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "tensor_dict", "[", "\"sentence2\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.StsProcessor.get_train_examples": [[294, 298], ["utils_multilabel.StsProcessor._create_examples", "utils_multilabel.StsProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.StsProcessor.get_dev_examples": [[299, 303], ["utils_multilabel.StsProcessor._create_examples", "utils_multilabel.StsProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.StsProcessor.get_test_examples": [[305, 309], ["utils_multilabel.StsProcessor._create_examples", "utils_multilabel.StsProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.StsProcessor.get_labels": [[310, 313], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.StsProcessor._create_examples": [[314, 326], ["enumerate", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "float", "examples.append", "utils.InputExample", "tokenization.convert_to_unicode"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "convert_to_unicode", "(", "line", "[", "0", "]", ")", ")", "\n", "text_a", "=", "convert_to_unicode", "(", "line", "[", "-", "3", "]", ")", "\n", "text_b", "=", "convert_to_unicode", "(", "line", "[", "-", "2", "]", ")", "\n", "label", "=", "float", "(", "line", "[", "-", "1", "]", ")", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.StsProcessor.get_y_true": [[328, 340], ["os.path.join", "open", "csv.reader", "enumerate", "labels.append", "tokenization.convert_to_unicode"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode"], ["", "def", "get_y_true", "(", "self", ",", "data_dir", ",", "set_type", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Read labels for evaluation.\"\"\"", "\n", "input_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.tsv\"", ".", "format", "(", "set_type", ")", ")", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "labels", "=", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "reader", ")", ":", "\n", "# skip header", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "labels", ".", "append", "(", "convert_to_unicode", "(", "line", "[", "-", "1", "]", ")", ")", "\n", "", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.MedNLIProcessor.get_train_examples": [[344, 348], ["utils_multilabel.MedNLIProcessor._create_examples", "utils_multilabel.MedNLIProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["    ", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.MedNLIProcessor.get_dev_examples": [[349, 353], ["utils_multilabel.MedNLIProcessor._create_examples", "utils_multilabel.MedNLIProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.MedNLIProcessor.get_test_examples": [[354, 358], ["utils_multilabel.MedNLIProcessor._create_examples", "utils_multilabel.MedNLIProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.MedNLIProcessor.get_labels": [[359, 362], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "'contradiction'", ",", "'entailment'", ",", "'neutral'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.MedNLIProcessor._create_examples": [[363, 379], ["enumerate", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "examples.append", "tokenization.convert_to_unicode", "utils.InputExample", "utils_multilabel.MedNLIProcessor.get_labels"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_labels"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "line", "[", "1", "]", "\n", "text_a", "=", "convert_to_unicode", "(", "line", "[", "2", "]", ")", "\n", "text_b", "=", "convert_to_unicode", "(", "line", "[", "3", "]", ")", "\n", "if", "set_type", "==", "\"test\"", ":", "\n", "                ", "label", "=", "self", ".", "get_labels", "(", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "label", "=", "convert_to_unicode", "(", "line", "[", "0", "]", ")", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_multilabel.blue_convert_examples_to_features": [[40, 177], ["enumerate", "file_utils.is_tf_available", "isinstance", "tokenizer.encode_plus", "features.append", "file_utils.is_tf_available", "tf.data.Dataset.from_generator", "processor.get_labels", "logger.info", "logger.info", "enumerate", "processor.get_example_from_tensor_dict", "processor.tfds_map", "tf.data.experimental.cardinality", "len", "logger.info", "len", "len", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils.InputFeatures", "float", "KeyError", "tf.TensorShape", "tokenizer.convert_ids_to_tokens", "tf.TensorShape", "tf.TensorShape", "tf.TensorShape", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.is_tf_available", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.is_tf_available", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_labels", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_example_from_tensor_dict", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.tfds_map"], ["def", "blue_convert_examples_to_features", "(", "\n", "examples", ",", "\n", "tokenizer", ",", "\n", "max_length", "=", "512", ",", "\n", "task", "=", "None", ",", "\n", "label_list", "=", "None", ",", "\n", "output_mode", "=", "None", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Loads a data file into a list of ``InputFeatures``\n\n    Args:\n        examples: List of ``InputExamples`` or ``tf.data.Dataset`` containing the examples.\n        tokenizer: Instance of a tokenizer that will tokenize the examples\n        max_length: Maximum example length\n        task: GLUE task\n        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method\n        output_mode: String indicating the output mode. Either ``regression`` or ``classification``\n        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)\n        pad_token: Padding token\n        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)\n        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values\n            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for\n            actual values)\n\n    Returns:\n        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``\n        containing the task-specific features. If the input is a list of ``InputExamples``, will return\n        a list of task-specific ``InputFeatures`` which can be fed to the model.\n\n    \"\"\"", "\n", "is_tf_dataset", "=", "False", "\n", "if", "is_tf_available", "(", ")", "and", "isinstance", "(", "examples", ",", "tf", ".", "data", ".", "Dataset", ")", ":", "\n", "        ", "is_tf_dataset", "=", "True", "\n", "\n", "", "if", "task", "is", "not", "None", ":", "\n", "        ", "processor", "=", "glue_processors", "[", "task", "]", "(", ")", "\n", "if", "label_list", "is", "None", ":", "\n", "            ", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "logger", ".", "info", "(", "\"Using label list %s for task %s\"", "%", "(", "label_list", ",", "task", ")", ")", "\n", "", "if", "output_mode", "is", "None", ":", "\n", "            ", "output_mode", "=", "glue_output_modes", "[", "task", "]", "\n", "logger", ".", "info", "(", "\"Using output mode %s for task %s\"", "%", "(", "output_mode", ",", "task", ")", ")", "\n", "\n", "", "", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "len_examples", "=", "0", "\n", "if", "is_tf_dataset", ":", "\n", "            ", "example", "=", "processor", ".", "get_example_from_tensor_dict", "(", "example", ")", "\n", "example", "=", "processor", ".", "tfds_map", "(", "example", ")", "\n", "len_examples", "=", "tf", ".", "data", ".", "experimental", ".", "cardinality", "(", "examples", ")", "\n", "", "else", ":", "\n", "            ", "len_examples", "=", "len", "(", "examples", ")", "\n", "", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d/%d\"", "%", "(", "ex_index", ",", "len_examples", ")", ")", "\n", "\n", "", "inputs", "=", "tokenizer", ".", "encode_plus", "(", "example", ".", "text_a", ",", "example", ".", "text_b", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "max_length", ",", ")", "\n", "input_ids", ",", "token_type_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "inputs", "[", "\"token_type_ids\"", "]", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "attention_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "attention_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "attention_mask", "\n", "token_type_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "token_type_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "attention_mask", "=", "attention_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "token_type_ids", "=", "token_type_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "len", "(", "input_ids", ")", ",", "max_length", ")", "\n", "assert", "len", "(", "attention_mask", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "\n", "len", "(", "attention_mask", ")", ",", "max_length", "\n", ")", "\n", "assert", "len", "(", "token_type_ids", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "\n", "len", "(", "token_type_ids", ")", ",", "max_length", "\n", ")", "\n", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "label", "=", "label_map", "[", "example", ".", "label", "]", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "label", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "output_mode", ")", "\n", "\n", "", "if", "ex_index", "<", "5", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", ",", "\" \"", ".", "join", "(", "tokenizer", ".", "convert_ids_to_tokens", "(", "input_ids", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"attention_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "attention_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"token_type_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "token_type_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %d)\"", "%", "(", "example", ".", "label", ",", "label", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "\n", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "token_type_ids", "=", "token_type_ids", ",", "label", "=", "label", "\n", ")", "\n", ")", "\n", "\n", "", "if", "is_tf_available", "(", ")", "and", "is_tf_dataset", ":", "\n", "\n", "        ", "def", "gen", "(", ")", ":", "\n", "            ", "for", "ex", "in", "features", ":", "\n", "                ", "yield", "(", "\n", "{", "\n", "\"input_ids\"", ":", "ex", ".", "input_ids", ",", "\n", "\"attention_mask\"", ":", "ex", ".", "attention_mask", ",", "\n", "\"token_type_ids\"", ":", "ex", ".", "token_type_ids", ",", "\n", "}", ",", "\n", "ex", ".", "label", ",", "\n", ")", "\n", "\n", "", "", "return", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "\n", "gen", ",", "\n", "(", "{", "\"input_ids\"", ":", "tf", ".", "int32", ",", "\"attention_mask\"", ":", "tf", ".", "int32", ",", "\"token_type_ids\"", ":", "tf", ".", "int32", "}", ",", "tf", ".", "int64", ")", ",", "\n", "(", "\n", "{", "\n", "\"input_ids\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "\"attention_mask\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "\"token_type_ids\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "}", ",", "\n", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.InputExample.__init__": [[31, 43], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "words", ",", "labels", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n\n        Args:\n            guid: Unique id for the example.\n            words: list. The words of the sequence.\n            labels: (Optional) list. The labels for each word of the sequence. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "words", "=", "words", "\n", "self", ".", "labels", "=", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.InputFeatures.__init__": [[48, 53], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "label_ids", "=", "label_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.DataProcessor.get_train_examples": [[57, 60], ["NotImplementedError"], "methods", ["None"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.DataProcessor.get_dev_examples": [[61, 64], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.DataProcessor.get_test_examples": [[65, 68], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the test set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.DataProcessor.get_labels": [[69, 72], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.DataProcessor._read_data": [[74, 116], ["open", "line.strip", "words.append", "labels.append", "len", "lines.append", "line.strip().split", "line.strip().split", "len", "len", "len", "len", "len", "range", "lines.append", "line.strip", "line.strip", "len", "tmplabel.pop", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_read_data", "(", "cls", ",", "input_file", ")", ":", "\n", "        ", "\"\"\"Reads a BIO data.\n        Same as the original: https://github.com/ncbi-nlp/bluebert/blob/master/bluebert/run_bluebert_ner.py\n        \"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "lines", "=", "[", "]", "\n", "words", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "                ", "contents", "=", "line", ".", "strip", "(", ")", "\n", "if", "len", "(", "contents", ")", "==", "0", ":", "\n", "                    ", "assert", "len", "(", "words", ")", "==", "len", "(", "labels", ")", "\n", "if", "len", "(", "words", ")", ">", "30", ":", "\n", "# split if the sentence is longer than 30", "\n", "                        ", "while", "len", "(", "words", ")", ">", "30", ":", "\n", "                            ", "tmplabel", "=", "labels", "[", ":", "30", "]", "\n", "for", "iidx", "in", "range", "(", "len", "(", "tmplabel", ")", ")", ":", "\n", "                                ", "if", "tmplabel", ".", "pop", "(", ")", "==", "'O'", ":", "\n", "                                    ", "break", "\n", "", "", "l", "=", "' '", ".", "join", "(", "\n", "[", "label", "for", "label", "in", "labels", "[", ":", "len", "(", "tmplabel", ")", "+", "1", "]", "if", "len", "(", "label", ")", ">", "0", "]", ")", "\n", "w", "=", "' '", ".", "join", "(", "\n", "[", "word", "for", "word", "in", "words", "[", ":", "len", "(", "tmplabel", ")", "+", "1", "]", "if", "len", "(", "word", ")", ">", "0", "]", ")", "\n", "lines", ".", "append", "(", "[", "l", ",", "w", "]", ")", "\n", "words", "=", "words", "[", "len", "(", "tmplabel", ")", "+", "1", ":", "]", "\n", "labels", "=", "labels", "[", "len", "(", "tmplabel", ")", "+", "1", ":", "]", "\n", "\n", "", "", "if", "len", "(", "words", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "l", "=", "' '", ".", "join", "(", "[", "label", "for", "label", "in", "labels", "if", "len", "(", "label", ")", ">", "0", "]", ")", "\n", "w", "=", "' '", ".", "join", "(", "[", "word", "for", "word", "in", "words", "if", "len", "(", "word", ")", ">", "0", "]", ")", "\n", "lines", ".", "append", "(", "[", "l", ",", "w", "]", ")", "\n", "words", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "continue", "\n", "\n", "", "word", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "0", "]", "\n", "label", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "words", ".", "append", "(", "word", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.BC5CDRProcessor.get_train_examples": [[119, 123], ["utils_ner.BC5CDRProcessor._read_data", "utils_ner.BC5CDRProcessor._read_data", "utils_ner.BC5CDRProcessor._create_example", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.DataProcessor._read_data", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.DataProcessor._read_data", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.CLEFEProcessor._create_example"], ["    ", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "l1", "=", "self", ".", "_read_data", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", "\n", "l2", "=", "self", ".", "_read_data", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"devel.tsv\"", ")", ")", "\n", "return", "self", ".", "_create_example", "(", "l1", "+", "l2", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.BC5CDRProcessor.get_dev_examples": [[124, 127], ["utils_ner.BC5CDRProcessor._create_example", "utils_ner.BC5CDRProcessor._read_data", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.CLEFEProcessor._create_example", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.DataProcessor._read_data"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "return", "self", ".", "_create_example", "(", "\n", "self", ".", "_read_data", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"devel.tsv\"", ")", ")", ",", "\"dev\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.BC5CDRProcessor.get_test_examples": [[129, 132], ["utils_ner.BC5CDRProcessor._create_example", "utils_ner.BC5CDRProcessor._read_data", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.CLEFEProcessor._create_example", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.DataProcessor._read_data"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "return", "self", ".", "_create_example", "(", "\n", "self", ".", "_read_data", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.BC5CDRProcessor.get_labels": [[133, 136], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "# remove \"X\", \"[CLS]\", \"[SEP]\".", "\n", "        ", "return", "[", "\"B\"", ",", "\"I\"", ",", "\"O\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.BC5CDRProcessor._create_example": [[137, 149], ["enumerate", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "text.split.split.split", "label.split.split.split", "examples.append", "utils_ner.InputExample"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode"], ["", "def", "_create_example", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text", "=", "convert_to_unicode", "(", "line", "[", "1", "]", ")", "\n", "label", "=", "convert_to_unicode", "(", "line", "[", "0", "]", ")", "\n", "# ADD:", "\n", "# To match the huggingface implimentation, convert str to list.", "\n", "text", "=", "text", ".", "split", "(", "' '", ")", "\n", "label", "=", "label", ".", "split", "(", "' '", ")", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "words", "=", "text", ",", "labels", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.CLEFEProcessor.get_train_examples": [[151, 156], ["utils_ner.CLEFEProcessor._read_data2", "utils_ner.CLEFEProcessor._read_data2", "utils_ner.CLEFEProcessor._create_example", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.CLEFEProcessor._read_data2", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.CLEFEProcessor._read_data2", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.CLEFEProcessor._create_example"], ["    ", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "lines1", "=", "self", ".", "_read_data2", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"Training.tsv\"", ")", ")", "\n", "lines2", "=", "self", ".", "_read_data2", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"Development.tsv\"", ")", ")", "\n", "return", "self", ".", "_create_example", "(", "\n", "lines1", "+", "lines2", ",", "\"train\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.CLEFEProcessor.get_dev_examples": [[158, 161], ["utils_ner.CLEFEProcessor._create_example", "utils_ner.CLEFEProcessor._read_data2", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.CLEFEProcessor._create_example", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.CLEFEProcessor._read_data2"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "return", "self", ".", "_create_example", "(", "\n", "self", ".", "_read_data2", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"Development.tsv\"", ")", ")", ",", "\"dev\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.CLEFEProcessor.get_test_examples": [[163, 166], ["utils_ner.CLEFEProcessor._create_example", "utils_ner.CLEFEProcessor._read_data2", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.CLEFEProcessor._create_example", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.CLEFEProcessor._read_data2"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "return", "self", ".", "_create_example", "(", "\n", "self", ".", "_read_data2", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"Test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.CLEFEProcessor.get_labels": [[167, 170], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "# remove \"X\", \"[CLS]\", \"[SEP]\".", "\n", "        ", "return", "[", "\"B\"", ",", "\"I\"", ",", "\"O\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.CLEFEProcessor._create_example": [[171, 183], ["enumerate", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "text.split.split.split", "label.split.split.split", "examples.append", "utils_ner.InputExample"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode"], ["", "def", "_create_example", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text", "=", "convert_to_unicode", "(", "line", "[", "1", "]", ")", "\n", "label", "=", "convert_to_unicode", "(", "line", "[", "0", "]", ")", "\n", "# ADD:", "\n", "# To fit the huggingface implimentation, convert str to list.", "\n", "text", "=", "text", ".", "split", "(", "' '", ")", "\n", "label", "=", "label", ".", "split", "(", "' '", ")", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "words", "=", "text", ",", "labels", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.CLEFEProcessor._read_data2": [[184, 229], ["open", "line.strip", "words.append", "labels.append", "len", "lines.append", "line.strip.startswith", "line.strip().split", "line.strip().split", "len", "len", "len", "len", "len", "range", "lines.append", "line.strip", "line.strip", "len", "tmplabel.pop", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_read_data2", "(", "cls", ",", "input_file", ")", ":", "\n", "        ", "\"\"\"Reads a BIO data.\n        Almost same as the original: https://github.com/ncbi-nlp/bluebert/blob/master/bluebert/run_bluebert_ner.py\n        \"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "lines", "=", "[", "]", "\n", "words", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "                ", "contents", "=", "line", ".", "strip", "(", ")", "\n", "if", "len", "(", "contents", ")", "==", "0", ":", "\n", "                    ", "assert", "len", "(", "words", ")", "==", "len", "(", "labels", ")", "\n", "if", "len", "(", "words", ")", ">", "30", ":", "\n", "# split if the sentence is longer than 30", "\n", "# quote from _read_?data1() in DataProcessor", "\n", "                        ", "while", "len", "(", "words", ")", ">", "30", ":", "\n", "                            ", "tmplabel", "=", "labels", "[", ":", "30", "]", "\n", "for", "iidx", "in", "range", "(", "len", "(", "tmplabel", ")", ")", ":", "\n", "                                ", "if", "tmplabel", ".", "pop", "(", ")", "==", "'O'", ":", "\n", "                                    ", "break", "\n", "", "", "l", "=", "' '", ".", "join", "(", "\n", "[", "label", "for", "label", "in", "labels", "[", ":", "len", "(", "tmplabel", ")", "+", "1", "]", "if", "len", "(", "label", ")", ">", "0", "]", ")", "\n", "w", "=", "' '", ".", "join", "(", "\n", "[", "word", "for", "word", "in", "words", "[", ":", "len", "(", "tmplabel", ")", "+", "1", "]", "if", "len", "(", "word", ")", ">", "0", "]", ")", "\n", "lines", ".", "append", "(", "[", "l", ",", "w", "]", ")", "\n", "words", "=", "words", "[", "len", "(", "tmplabel", ")", "+", "1", ":", "]", "\n", "labels", "=", "labels", "[", "len", "(", "tmplabel", ")", "+", "1", ":", "]", "\n", "\n", "", "", "if", "len", "(", "words", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "l", "=", "' '", ".", "join", "(", "[", "label", "for", "label", "in", "labels", "if", "len", "(", "label", ")", ">", "0", "]", ")", "\n", "w", "=", "' '", ".", "join", "(", "[", "word", "for", "word", "in", "words", "if", "len", "(", "word", ")", ">", "0", "]", ")", "\n", "lines", ".", "append", "(", "[", "l", ",", "w", "]", ")", "\n", "words", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "continue", "\n", "", "elif", "contents", ".", "startswith", "(", "'###'", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "word", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "0", "]", "\n", "label", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "words", ".", "append", "(", "word", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_ner.convert_examples_to_features": [[230, 347], ["enumerate", "zip", "tokenizer.convert_tokens_to_ids", "features.append", "enumerate", "logger.info", "tokenizer.tokenize", "tokens.extend", "label_ids.extend", "len", "len", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils_ner.InputFeatures", "len", "str", "str", "str", "str", "str", "len"], "function", ["None"], ["", "", "", "def", "convert_examples_to_features", "(", "\n", "examples", ",", "\n", "label_list", ",", "\n", "max_seq_length", ",", "\n", "tokenizer", ",", "\n", "cls_token_at_end", "=", "False", ",", "\n", "cls_token", "=", "\"[CLS]\"", ",", "\n", "cls_token_segment_id", "=", "1", ",", "\n", "sep_token", "=", "\"[SEP]\"", ",", "\n", "sep_token_extra", "=", "False", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "pad_token_label_id", "=", "-", "100", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\" Loads a data file into a list of `InputBatch`s\n        `cls_token_at_end` define the location of the CLS token:\n            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n    \"\"\"", "\n", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d of %d\"", ",", "ex_index", ",", "len", "(", "examples", ")", ")", "\n", "\n", "", "tokens", "=", "[", "]", "\n", "label_ids", "=", "[", "]", "\n", "for", "word", ",", "label", "in", "zip", "(", "example", ".", "words", ",", "example", ".", "labels", ")", ":", "\n", "            ", "word_tokens", "=", "tokenizer", ".", "tokenize", "(", "word", ")", "\n", "tokens", ".", "extend", "(", "word_tokens", ")", "\n", "# Use the real label id for the first token of the word, and padding ids for the remaining tokens", "\n", "label_ids", ".", "extend", "(", "[", "label_map", "[", "label", "]", "]", "+", "[", "pad_token_label_id", "]", "*", "(", "len", "(", "word_tokens", ")", "-", "1", ")", ")", "\n", "\n", "# Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.", "\n", "", "special_tokens_count", "=", "3", "if", "sep_token_extra", "else", "2", "\n", "if", "len", "(", "tokens", ")", ">", "max_seq_length", "-", "special_tokens_count", ":", "\n", "            ", "tokens", "=", "tokens", "[", ":", "(", "max_seq_length", "-", "special_tokens_count", ")", "]", "\n", "label_ids", "=", "label_ids", "[", ":", "(", "max_seq_length", "-", "special_tokens_count", ")", "]", "\n", "\n", "# The convention in BERT is:", "\n", "# (a) For sequence pairs:", "\n", "#  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]", "\n", "#  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1", "\n", "# (b) For single sequences:", "\n", "#  tokens:   [CLS] the dog is hairy . [SEP]", "\n", "#  type_ids:   0   0   0   0  0     0   0", "\n", "#", "\n", "# Where \"type_ids\" are used to indicate whether this is the first", "\n", "# sequence or the second sequence. The embedding vectors for `type=0` and", "\n", "# `type=1` were learned during pre-training and are added to the wordpiece", "\n", "# embedding vector (and position vector). This is not *strictly* necessary", "\n", "# since the [SEP] token unambiguously separates the sequences, but it makes", "\n", "# it easier for the model to learn the concept of sequences.", "\n", "#", "\n", "# For classification tasks, the first vector (corresponding to [CLS]) is", "\n", "# used as as the \"sentence vector\". Note that this only makes sense because", "\n", "# the entire model is fine-tuned.", "\n", "", "tokens", "+=", "[", "sep_token", "]", "\n", "label_ids", "+=", "[", "pad_token_label_id", "]", "\n", "if", "sep_token_extra", ":", "\n", "# roberta uses an extra separator b/w pairs of sentences", "\n", "            ", "tokens", "+=", "[", "sep_token", "]", "\n", "label_ids", "+=", "[", "pad_token_label_id", "]", "\n", "", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "cls_token_at_end", ":", "\n", "            ", "tokens", "+=", "[", "cls_token", "]", "\n", "label_ids", "+=", "[", "pad_token_label_id", "]", "\n", "segment_ids", "+=", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "label_ids", "=", "[", "pad_token_label_id", "]", "+", "label_ids", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "label_ids", "=", "(", "[", "pad_token_label_id", "]", "*", "padding_length", ")", "+", "label_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "+=", "[", "pad_token", "]", "*", "padding_length", "\n", "input_mask", "+=", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", "\n", "segment_ids", "+=", "[", "pad_token_segment_id", "]", "*", "padding_length", "\n", "label_ids", "+=", "[", "pad_token_label_id", "]", "*", "padding_length", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "label_ids", ")", "==", "max_seq_length", "\n", "\n", "if", "ex_index", "<", "5", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", ",", "example", ".", "guid", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "label_ids", "]", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "input_mask", "=", "input_mask", ",", "segment_ids", "=", "segment_ids", ",", "label_ids", "=", "label_ids", ")", "\n", ")", "\n", "", "return", "features", "\n", "", ""]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.is_torch_available": [[105, 107], ["None"], "function", ["None"], ["def", "is_torch_available", "(", ")", ":", "\n", "    ", "return", "_torch_available", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.is_tf_available": [[109, 111], ["None"], "function", ["None"], ["", "def", "is_tf_available", "(", ")", ":", "\n", "    ", "return", "_tf_available", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.add_start_docstrings": [[113, 119], ["None"], "function", ["None"], ["", "def", "add_start_docstrings", "(", "*", "docstr", ")", ":", "\n", "    ", "def", "docstring_decorator", "(", "fn", ")", ":", "\n", "        ", "fn", ".", "__doc__", "=", "\"\"", ".", "join", "(", "docstr", ")", "+", "(", "fn", ".", "__doc__", "if", "fn", ".", "__doc__", "is", "not", "None", "else", "\"\"", ")", "\n", "return", "fn", "\n", "\n", "", "return", "docstring_decorator", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.add_start_docstrings_to_callable": [[121, 137], ["fn.__qualname__.split"], "function", ["None"], ["", "def", "add_start_docstrings_to_callable", "(", "*", "docstr", ")", ":", "\n", "    ", "def", "docstring_decorator", "(", "fn", ")", ":", "\n", "        ", "class_name", "=", "\":class:`~transformers.{}`\"", ".", "format", "(", "fn", ".", "__qualname__", ".", "split", "(", "\".\"", ")", "[", "0", "]", ")", "\n", "intro", "=", "\"   The {} forward method, overrides the :func:`__call__` special method.\"", ".", "format", "(", "class_name", ")", "\n", "note", "=", "r\"\"\"\n\n    .. note::\n        Although the recipe for forward pass needs to be defined within\n        this function, one should call the :class:`Module` instance afterwards\n        instead of this since the former takes care of running the\n        pre and post processing steps while the latter silently ignores them.\n        \"\"\"", "\n", "fn", ".", "__doc__", "=", "intro", "+", "note", "+", "\"\"", ".", "join", "(", "docstr", ")", "+", "(", "fn", ".", "__doc__", "if", "fn", ".", "__doc__", "is", "not", "None", "else", "\"\"", ")", "\n", "return", "fn", "\n", "\n", "", "return", "docstring_decorator", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.add_end_docstrings": [[139, 145], ["None"], "function", ["None"], ["", "def", "add_end_docstrings", "(", "*", "docstr", ")", ":", "\n", "    ", "def", "docstring_decorator", "(", "fn", ")", ":", "\n", "        ", "fn", ".", "__doc__", "=", "fn", ".", "__doc__", "+", "\"\"", ".", "join", "(", "docstr", ")", "\n", "return", "fn", "\n", "\n", "", "return", "docstring_decorator", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.is_remote_url": [[147, 150], ["urllib.parse.urlparse"], "function", ["None"], ["", "def", "is_remote_url", "(", "url_or_filename", ")", ":", "\n", "    ", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "return", "parsed", ".", "scheme", "in", "(", "\"http\"", ",", "\"https\"", ",", "\"s3\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.hf_bucket_url": [[152, 158], ["None"], "function", ["None"], ["", "def", "hf_bucket_url", "(", "identifier", ",", "postfix", "=", "None", ",", "cdn", "=", "False", ")", "->", "str", ":", "\n", "    ", "endpoint", "=", "CLOUDFRONT_DISTRIB_PREFIX", "if", "cdn", "else", "S3_BUCKET_PREFIX", "\n", "if", "postfix", "is", "None", ":", "\n", "        ", "return", "\"/\"", ".", "join", "(", "(", "endpoint", ",", "identifier", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "\"/\"", ".", "join", "(", "(", "endpoint", ",", "identifier", ",", "postfix", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.url_to_filename": [[160, 182], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "url.endswith", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["None"], ["", "", "def", "url_to_filename", "(", "url", ",", "etag", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    If the url ends with .h5 (Keras HDF5 weights) adds '.h5' to the name\n    so that TF 2.0 can identify it as a HDF5 file\n    (see https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/python/keras/engine/network.py#L1380)\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "\"utf-8\"", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "\"utf-8\"", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "\".\"", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "if", "url", ".", "endswith", "(", "\".h5\"", ")", ":", "\n", "        ", "filename", "+=", "\".h5\"", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.filename_to_url": [[184, 208], ["isinstance", "os.path.join", "str", "os.path.exists", "EnvironmentError", "os.path.exists", "EnvironmentError", "open", "json.load"], "function", ["None"], ["", "def", "filename_to_url", "(", "filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``EnvironmentError`` if `filename` or its stored metadata do not exist.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "TRANSFORMERS_CACHE", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "cache_path", ")", ")", "\n", "\n", "", "meta_path", "=", "cache_path", "+", "\".json\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "meta_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "meta_path", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "        ", "metadata", "=", "json", ".", "load", "(", "meta_file", ")", "\n", "", "url", "=", "metadata", "[", "\"url\"", "]", "\n", "etag", "=", "metadata", "[", "\"etag\"", "]", "\n", "\n", "return", "url", ",", "etag", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.cached_path": [[210, 300], ["isinstance", "isinstance", "file_utils.is_remote_url", "str", "str", "file_utils.get_from_cache", "os.path.exists", "os.path.split", "os.path.join", "output_file.replace", "os.path.isdir", "os.listdir", "filelock.FileLock", "shutil.rmtree", "os.makedirs", "zipfile.is_zipfile", "EnvironmentError", "ValueError", "zipfile.is_zipfile", "tarfile.is_tarfile", "tarfile.is_tarfile", "urllib.parse.urlparse", "zipfile.ZipFile", "zip_file.extractall", "zip_file.close", "tarfile.open", "tarfile.open.extractall", "tarfile.open.close", "EnvironmentError"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.is_remote_url", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.get_from_cache"], ["", "def", "cached_path", "(", "\n", "url_or_filename", ",", "\n", "cache_dir", "=", "None", ",", "\n", "force_download", "=", "False", ",", "\n", "proxies", "=", "None", ",", "\n", "resume_download", "=", "False", ",", "\n", "user_agent", "=", "None", ",", "\n", "extract_compressed_file", "=", "False", ",", "\n", "force_extract", "=", "False", ",", "\n", "local_files_only", "=", "False", ",", "\n", ")", "->", "Optional", "[", "str", "]", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    Args:\n        cache_dir: specify a cache directory to save the file to (overwrite the default cache dir).\n        force_download: if True, re-dowload the file even if it's already cached in the cache dir.\n        resume_download: if True, resume the download if incompletly recieved file is found.\n        user_agent: Optional string or dict that will be appended to the user-agent on remote requests.\n        extract_compressed_file: if True and the path point to a zip or tar file, extract the compressed\n            file in a folder along the archive.\n        force_extract: if True when extract_compressed_file is True and the archive was already extracted,\n            re-extract the archive and overide the folder where it was extracted.\n\n    Return:\n        None in case of non-recoverable file (non-existent or inaccessible url + no cache on disk).\n        Local path (string) otherwise\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "TRANSFORMERS_CACHE", "\n", "", "if", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "if", "is_remote_url", "(", "url_or_filename", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "output_path", "=", "get_from_cache", "(", "\n", "url_or_filename", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "force_download", "=", "force_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", "resume_download", "=", "resume_download", ",", "\n", "user_agent", "=", "user_agent", ",", "\n", "local_files_only", "=", "local_files_only", ",", "\n", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n", "# File, and it exists.", "\n", "        ", "output_path", "=", "url_or_filename", "\n", "", "elif", "urlparse", "(", "url_or_filename", ")", ".", "scheme", "==", "\"\"", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "\n", "", "if", "extract_compressed_file", ":", "\n", "        ", "if", "not", "is_zipfile", "(", "output_path", ")", "and", "not", "tarfile", ".", "is_tarfile", "(", "output_path", ")", ":", "\n", "            ", "return", "output_path", "\n", "\n", "# Path where we extract compressed archives", "\n", "# We avoid '.' in dir name and add \"-extracted\" at the end: \"./model.zip\" => \"./model-zip-extracted/\"", "\n", "", "output_dir", ",", "output_file", "=", "os", ".", "path", ".", "split", "(", "output_path", ")", "\n", "output_extract_dir_name", "=", "output_file", ".", "replace", "(", "\".\"", ",", "\"-\"", ")", "+", "\"-extracted\"", "\n", "output_path_extracted", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "output_extract_dir_name", ")", "\n", "\n", "if", "os", ".", "path", ".", "isdir", "(", "output_path_extracted", ")", "and", "os", ".", "listdir", "(", "output_path_extracted", ")", "and", "not", "force_extract", ":", "\n", "            ", "return", "output_path_extracted", "\n", "\n", "# Prevent parallel extractions", "\n", "", "lock_path", "=", "output_path", "+", "\".lock\"", "\n", "with", "FileLock", "(", "lock_path", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "output_path_extracted", ",", "ignore_errors", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "output_path_extracted", ")", "\n", "if", "is_zipfile", "(", "output_path", ")", ":", "\n", "                ", "with", "ZipFile", "(", "output_path", ",", "\"r\"", ")", "as", "zip_file", ":", "\n", "                    ", "zip_file", ".", "extractall", "(", "output_path_extracted", ")", "\n", "zip_file", ".", "close", "(", ")", "\n", "", "", "elif", "tarfile", ".", "is_tarfile", "(", "output_path", ")", ":", "\n", "                ", "tar_file", "=", "tarfile", ".", "open", "(", "output_path", ")", "\n", "tar_file", ".", "extractall", "(", "output_path_extracted", ")", "\n", "tar_file", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"Archive format of {} could not be identified\"", ".", "format", "(", "output_path", ")", ")", "\n", "\n", "", "", "return", "output_path_extracted", "\n", "\n", "", "return", "output_path", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.split_s3_path": [[302, 313], ["urllib.parse.urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["", "def", "split_s3_path", "(", "url", ")", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "s3_path", "=", "s3_path", "[", "1", ":", "]", "\n", "", "return", "bucket_name", ",", "s3_path", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.s3_request": [[315, 332], ["functools.wraps", "func", "int", "EnvironmentError"], "function", ["None"], ["", "def", "s3_request", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.s3_etag": [[334, 341], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Object", "botocore.config.Config"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ",", "proxies", "=", "None", ")", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ",", "config", "=", "Config", "(", "proxies", "=", "proxies", ")", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n", "return", "s3_object", ".", "e_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.s3_get": [[343, 349], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Bucket().download_fileobj", "botocore.config.Config", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "None", ")", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ",", "config", "=", "Config", "(", "proxies", "=", "proxies", ")", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.http_get": [[351, 382], ["file_utils.is_torch_available", "file_utils.is_tf_available", "isinstance", "requests.get", "requests.get.headers.get", "tqdm.auto.tqdm", "requests.get.iter_content", "tqdm.auto.tqdm.close", "isinstance", "sys.version.split", "int", "bool", "tqdm.auto.tqdm.update", "temp_file.write", "len", "logger.getEffectiveLevel", "user_agent.items"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.is_torch_available", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.is_tf_available"], ["", "def", "http_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "None", ",", "resume_size", "=", "0", ",", "user_agent", "=", "None", ")", ":", "\n", "    ", "ua", "=", "\"transformers/{}; python/{}\"", ".", "format", "(", "__version__", ",", "sys", ".", "version", ".", "split", "(", ")", "[", "0", "]", ")", "\n", "if", "is_torch_available", "(", ")", ":", "\n", "        ", "ua", "+=", "\"; torch/{}\"", ".", "format", "(", "torch", ".", "__version__", ")", "\n", "", "if", "is_tf_available", "(", ")", ":", "\n", "        ", "ua", "+=", "\"; tensorflow/{}\"", ".", "format", "(", "tf", ".", "__version__", ")", "\n", "", "if", "isinstance", "(", "user_agent", ",", "dict", ")", ":", "\n", "        ", "ua", "+=", "\"; \"", "+", "\"; \"", ".", "join", "(", "\"{}/{}\"", ".", "format", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "user_agent", ".", "items", "(", ")", ")", "\n", "", "elif", "isinstance", "(", "user_agent", ",", "str", ")", ":", "\n", "        ", "ua", "+=", "\"; \"", "+", "user_agent", "\n", "", "headers", "=", "{", "\"user-agent\"", ":", "ua", "}", "\n", "if", "resume_size", ">", "0", ":", "\n", "        ", "headers", "[", "\"Range\"", "]", "=", "\"bytes=%d-\"", "%", "(", "resume_size", ",", ")", "\n", "", "response", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ",", "proxies", "=", "proxies", ",", "headers", "=", "headers", ")", "\n", "if", "response", ".", "status_code", "==", "416", ":", "# Range not satisfiable", "\n", "        ", "return", "\n", "", "content_length", "=", "response", ".", "headers", ".", "get", "(", "\"Content-Length\"", ")", "\n", "total", "=", "resume_size", "+", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "tqdm", "(", "\n", "unit", "=", "\"B\"", ",", "\n", "unit_scale", "=", "True", ",", "\n", "total", "=", "total", ",", "\n", "initial", "=", "resume_size", ",", "\n", "desc", "=", "\"Downloading\"", ",", "\n", "disable", "=", "bool", "(", "logger", ".", "getEffectiveLevel", "(", ")", "==", "logging", ".", "NOTSET", ")", ",", "\n", ")", "\n", "for", "chunk", "in", "response", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.get_from_cache": [[384, 501], ["isinstance", "os.makedirs", "file_utils.url_to_filename", "os.path.join", "str", "url.startswith", "os.path.exists", "os.path.exists", "filelock.FileLock", "logger.info", "os.rename", "logger.info", "file_utils.s3_etag", "os.path.exists", "functools.partial", "functools.partial.", "logger.info", "url.startswith", "open", "json.dump", "requests.head", "len", "os.path.join", "file_utils.s3_get", "file_utils.http_get", "requests.head.headers.get", "fnmatch.filter", "ValueError", "open", "os.stat", "logger.warn", "os.listdir", "file.endswith", "file.endswith"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.url_to_filename", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.s3_etag", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.s3_get", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.http_get"], ["", "def", "get_from_cache", "(", "\n", "url", ",", "\n", "cache_dir", "=", "None", ",", "\n", "force_download", "=", "False", ",", "\n", "proxies", "=", "None", ",", "\n", "etag_timeout", "=", "10", ",", "\n", "resume_download", "=", "False", ",", "\n", "user_agent", "=", "None", ",", "\n", "local_files_only", "=", "False", ",", "\n", ")", "->", "Optional", "[", "str", "]", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding file in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n\n    Return:\n        None in case of non-recoverable file (non-existent or inaccessible url + no cache on disk).\n        Local path (string) otherwise\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "TRANSFORMERS_CACHE", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "cache_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "etag", "=", "None", "\n", "if", "not", "local_files_only", ":", "\n", "# Get eTag to add to filename, if it exists.", "\n", "        ", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "            ", "etag", "=", "s3_etag", "(", "url", ",", "proxies", "=", "proxies", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "response", "=", "requests", ".", "head", "(", "url", ",", "allow_redirects", "=", "True", ",", "proxies", "=", "proxies", ",", "timeout", "=", "etag_timeout", ")", "\n", "if", "response", ".", "status_code", "==", "200", ":", "\n", "                    ", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "", "", "except", "(", "EnvironmentError", ",", "requests", ".", "exceptions", ".", "Timeout", ")", ":", "\n", "# etag is already None", "\n", "                ", "pass", "\n", "\n", "", "", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "# etag is None = we don't have a connection, or url doesn't exist, or is otherwise inaccessible.", "\n", "# try to get the last downloaded one", "\n", "if", "etag", "is", "None", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "            ", "return", "cache_path", "\n", "", "else", ":", "\n", "            ", "matching_files", "=", "[", "\n", "file", "\n", "for", "file", "in", "fnmatch", ".", "filter", "(", "os", ".", "listdir", "(", "cache_dir", ")", ",", "filename", "+", "\".*\"", ")", "\n", "if", "not", "file", ".", "endswith", "(", "\".json\"", ")", "and", "not", "file", ".", "endswith", "(", "\".lock\"", ")", "\n", "]", "\n", "if", "len", "(", "matching_files", ")", ">", "0", ":", "\n", "                ", "return", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "matching_files", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "# If files cannot be found and local_files_only=True,", "\n", "# the models might've been found if local_files_only=False", "\n", "# Notify the user about that", "\n", "                ", "if", "local_files_only", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Cannot find the requested files in the cached path and outgoing traffic has been\"", "\n", "\" disabled. To enable model look-ups and downloads online, set 'local_files_only'\"", "\n", "\" to False.\"", "\n", ")", "\n", "", "return", "None", "\n", "\n", "# From now on, etag is not None.", "\n", "", "", "", "if", "os", ".", "path", ".", "exists", "(", "cache_path", ")", "and", "not", "force_download", ":", "\n", "        ", "return", "cache_path", "\n", "\n", "# Prevent parallel downloads of the same file with a lock.", "\n", "", "lock_path", "=", "cache_path", "+", "\".lock\"", "\n", "with", "FileLock", "(", "lock_path", ")", ":", "\n", "\n", "        ", "if", "resume_download", ":", "\n", "            ", "incomplete_path", "=", "cache_path", "+", "\".incomplete\"", "\n", "\n", "@", "contextmanager", "\n", "def", "_resumable_file_manager", "(", ")", ":", "\n", "                ", "with", "open", "(", "incomplete_path", ",", "\"a+b\"", ")", "as", "f", ":", "\n", "                    ", "yield", "f", "\n", "\n", "", "", "temp_file_manager", "=", "_resumable_file_manager", "\n", "if", "os", ".", "path", ".", "exists", "(", "incomplete_path", ")", ":", "\n", "                ", "resume_size", "=", "os", ".", "stat", "(", "incomplete_path", ")", ".", "st_size", "\n", "", "else", ":", "\n", "                ", "resume_size", "=", "0", "\n", "", "", "else", ":", "\n", "            ", "temp_file_manager", "=", "partial", "(", "tempfile", ".", "NamedTemporaryFile", ",", "dir", "=", "cache_dir", ",", "delete", "=", "False", ")", "\n", "resume_size", "=", "0", "\n", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "", "with", "temp_file_manager", "(", ")", "as", "temp_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s not found in cache or force_download set to True, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", ")", "\n", "\n", "# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                ", "if", "resume_download", ":", "\n", "                    ", "logger", ".", "warn", "(", "'Warning: resumable downloads are not implemented for \"s3://\" urls'", ")", "\n", "", "s3_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "proxies", ")", "\n", "", "else", ":", "\n", "                ", "http_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "proxies", ",", "resume_size", "=", "resume_size", ",", "user_agent", "=", "user_agent", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"storing %s in cache at %s\"", ",", "url", ",", "cache_path", ")", "\n", "os", ".", "rename", "(", "temp_file", ".", "name", ",", "cache_path", ")", "\n", "\n", "logger", ".", "info", "(", "\"creating metadata file for %s\"", ",", "cache_path", ")", "\n", "meta", "=", "{", "\"url\"", ":", "url", ",", "\"etag\"", ":", "etag", "}", "\n", "meta_path", "=", "cache_path", "+", "\".json\"", "\n", "with", "open", "(", "meta_path", ",", "\"w\"", ")", "as", "meta_file", ":", "\n", "            ", "json", ".", "dump", "(", "meta", ",", "meta_file", ")", "\n", "\n", "", "", "return", "cache_path", "", "", ""]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.DataProcessor.get_train_examples": [[322, 325], ["NotImplementedError"], "methods", ["None"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.DataProcessor.get_dev_examples": [[326, 329], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.DataProcessor.get_test_examples": [[330, 333], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for prediction.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.DataProcessor.get_labels": [[334, 337], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.DataProcessor._read_tsv": [[338, 347], ["open", "csv.reader", "lines.append"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_read_tsv", "(", "cls", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.BlueBERTProcessor.get_train_examples": [[351, 355], ["utils_blue.BlueBERTProcessor._create_examples", "utils_blue.BlueBERTProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.BlueBERTProcessor.get_dev_examples": [[356, 360], ["utils_blue.BlueBERTProcessor._create_examples", "utils_blue.BlueBERTProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.BlueBERTProcessor.get_test_examples": [[361, 365], ["utils_blue.BlueBERTProcessor._create_examples", "utils_blue.BlueBERTProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.BlueBERTProcessor._create_examples": [[366, 392], ["enumerate", "tokenization.convert_to_unicode", "examples.append", "utils.InputExample", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "logging.exception", "exit", "logging.exception", "exit"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "# skip header", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "line", "[", "0", "]", "\n", "text_a", "=", "convert_to_unicode", "(", "line", "[", "1", "]", ")", "\n", "if", "set_type", "==", "\"test\"", ":", "\n", "# MODIFY:", "\n", "# We add the option \"--predict\" to calculate metrics and to describe outputs.", "\n", "# label = self.get_labels()[-1]", "\n", "                ", "try", ":", "\n", "                    ", "label", "=", "convert_to_unicode", "(", "line", "[", "2", "]", ")", "\n", "", "except", "IndexError", ":", "\n", "                    ", "logging", ".", "exception", "(", "line", ")", "\n", "exit", "(", "1", ")", "\n", "", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "label", "=", "convert_to_unicode", "(", "line", "[", "2", "]", ")", "\n", "", "except", "IndexError", ":", "\n", "                    ", "logging", ".", "exception", "(", "line", ")", "\n", "exit", "(", "1", ")", "\n", "", "", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.BlueBERTProcessor.get_y_true": [[394, 406], ["os.path.join", "open", "csv.reader", "enumerate", "labels.append", "tokenization.convert_to_unicode"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode"], ["", "def", "get_y_true", "(", "self", ",", "data_dir", ",", "set_type", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Read labels for evaluation.\"\"\"", "\n", "input_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.tsv\"", ".", "format", "(", "set_type", ")", ")", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "labels", "=", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "reader", ")", ":", "\n", "# skip header", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "labels", ".", "append", "(", "convert_to_unicode", "(", "line", "[", "2", "]", ")", ")", "\n", "", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.ChemProtProcessor.get_labels": [[408, 411], ["None"], "methods", ["None"], ["    ", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"CPR:3\"", ",", "\"CPR:4\"", ",", "\"CPR:5\"", ",", "\"CPR:6\"", ",", "\"CPR:9\"", ",", "\"false\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.DDI2013Processor.get_labels": [[414, 416], ["None"], "methods", ["None"], ["    ", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "return", "[", "\"DDI-advise\"", ",", "\"DDI-effect\"", ",", "\"DDI-int\"", ",", "\"DDI-mechanism\"", ",", "'DDI-false'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.I2b2_2010_Processor.get_labels": [[419, 421], ["None"], "methods", ["None"], ["    ", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "return", "[", "'PIP'", ",", "'TeCP'", ",", "'TeRP'", ",", "'TrAP'", ",", "'TrCP'", ",", "'TrIP'", ",", "'TrNAP'", ",", "'TrWP'", ",", "'false'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.StsProcessor.get_example_from_tensor_dict": [[426, 433], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["None"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"sentence1\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "tensor_dict", "[", "\"sentence2\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.StsProcessor.get_train_examples": [[435, 439], ["utils_blue.StsProcessor._create_examples", "utils_blue.StsProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.StsProcessor.get_dev_examples": [[440, 444], ["utils_blue.StsProcessor._create_examples", "utils_blue.StsProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.StsProcessor.get_test_examples": [[446, 450], ["utils_blue.StsProcessor._create_examples", "utils_blue.StsProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.StsProcessor.get_labels": [[451, 454], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.StsProcessor._create_examples": [[455, 467], ["enumerate", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "float", "examples.append", "utils.InputExample", "tokenization.convert_to_unicode"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "convert_to_unicode", "(", "line", "[", "0", "]", ")", ")", "\n", "text_a", "=", "convert_to_unicode", "(", "line", "[", "-", "3", "]", ")", "\n", "text_b", "=", "convert_to_unicode", "(", "line", "[", "-", "2", "]", ")", "\n", "label", "=", "float", "(", "line", "[", "-", "1", "]", ")", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.StsProcessor.get_y_true": [[469, 481], ["os.path.join", "open", "csv.reader", "enumerate", "labels.append", "tokenization.convert_to_unicode"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode"], ["", "def", "get_y_true", "(", "self", ",", "data_dir", ",", "set_type", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Read labels for evaluation.\"\"\"", "\n", "input_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.tsv\"", ".", "format", "(", "set_type", ")", ")", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "labels", "=", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "reader", ")", ":", "\n", "# skip header", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "labels", ".", "append", "(", "convert_to_unicode", "(", "line", "[", "-", "1", "]", ")", ")", "\n", "", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.HoCProcessor.get_train_examples": [[485, 489], ["utils_blue.HoCProcessor._create_examples", "utils_blue.HoCProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.HoCProcessor.get_dev_examples": [[490, 494], ["utils_blue.HoCProcessor._create_examples", "utils_blue.HoCProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.HoCProcessor.get_test_examples": [[495, 499], ["utils_blue.HoCProcessor._create_examples", "utils_blue.HoCProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.HoCProcessor.get_labels": [[500, 503], ["list", "range"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "list", "(", "range", "(", "10", ")", ")", "\n", "#         return ['activating invasion and metastasis', 'avoiding immune destruction',", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.HoCProcessor._create_examples": [[508, 535], ["enumerate", "labels.split", "utils_blue.HoCProcessor._create_examples.convert_str_to_list"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "#ADD:", "\n", "# convert the format of 'labels' from str to list.", "\n", "def", "convert_str_to_list", "(", "labels", ")", ":", "\n", "            ", "cols", "=", "labels", ".", "split", "(", "','", ")", "\n", "res", "=", "[", "int", "(", "v", "[", "-", "1", "]", ")", "for", "v", "in", "cols", "]", "\n", "return", "res", "\n", "\n", "", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "# Only the test set has a header", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "# if set_type == \"test\":", "\n", "#  text_a = tokenization.convert_to_unicode(line[1])", "\n", "#  label = \"0\"", "\n", "# else:", "\n", "#  text_a = tokenization.convert_to_unicode(line[3])", "\n", "#  label = tokenization.convert_to_unicode(line[1])", "\n", "label", "=", "convert_str_to_list", "(", "line", "[", "0", "]", ")", "\n", "text_a", "=", "convert_to_unicode", "(", "line", "[", "1", "]", ")", "\n", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor.get_train_examples": [[537, 541], ["utils_blue.MedNLIProcessor._create_examples", "utils_blue.MedNLIProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["    ", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor.get_dev_examples": [[542, 546], ["utils_blue.MedNLIProcessor._create_examples", "utils_blue.MedNLIProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor.get_test_examples": [[547, 551], ["utils_blue.MedNLIProcessor._create_examples", "utils_blue.MedNLIProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor.get_labels": [[552, 555], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "'contradiction'", ",", "'entailment'", ",", "'neutral'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor._create_examples": [[556, 576], ["enumerate", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "tokenization.convert_to_unicode", "examples.append", "utils.InputExample", "tokenization.convert_to_unicode"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "convert_to_unicode", "(", "line", "[", "0", "]", ")", ")", "\n", "text_a", "=", "convert_to_unicode", "(", "line", "[", "-", "3", "]", ")", "\n", "text_b", "=", "convert_to_unicode", "(", "line", "[", "-", "2", "]", ")", "\n", "label", "=", "convert_to_unicode", "(", "line", "[", "-", "1", "]", ")", "\n", "#             guid = line[1]", "\n", "#             text_a = convert_to_unicode(line[2])", "\n", "#             text_b = convert_to_unicode(line[3])", "\n", "#             if set_type == \"test\":", "\n", "#                 label = self.get_labels()[-1]", "\n", "#             else:", "\n", "#                 label = convert_to_unicode(line[0])", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.MedNLIProcessor.get_y_true": [[578, 590], ["os.path.join", "open", "csv.reader", "enumerate", "labels.append", "tokenization.convert_to_unicode"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode"], ["", "def", "get_y_true", "(", "self", ",", "data_dir", ",", "set_type", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Read labels for evaluation.\"\"\"", "\n", "input_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.tsv\"", ".", "format", "(", "set_type", ")", ")", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "labels", "=", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "reader", ")", ":", "\n", "# skip header", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "labels", ".", "append", "(", "convert_to_unicode", "(", "line", "[", "-", "1", "]", ")", ")", "\n", "", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.blue_convert_examples_to_features": [[42, 179], ["enumerate", "file_utils.is_tf_available", "isinstance", "tokenizer.encode_plus", "features.append", "file_utils.is_tf_available", "tf.data.Dataset.from_generator", "processor.get_labels", "logger.info", "logger.info", "enumerate", "processor.get_example_from_tensor_dict", "processor.tfds_map", "tf.data.experimental.cardinality", "len", "logger.info", "len", "len", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils.InputFeatures", "float", "KeyError", "tf.TensorShape", "tokenizer.convert_ids_to_tokens", "tf.TensorShape", "tf.TensorShape", "tf.TensorShape", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.is_tf_available", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.is_tf_available", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_labels", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_example_from_tensor_dict", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.tfds_map"], ["def", "blue_convert_examples_to_features", "(", "\n", "examples", ",", "\n", "tokenizer", ",", "\n", "max_length", "=", "512", ",", "\n", "task", "=", "None", ",", "\n", "label_list", "=", "None", ",", "\n", "output_mode", "=", "None", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Loads a data file into a list of ``InputFeatures``\n\n    Args:\n        examples: List of ``InputExamples`` or ``tf.data.Dataset`` containing the examples.\n        tokenizer: Instance of a tokenizer that will tokenize the examples\n        max_length: Maximum example length\n        task: GLUE task\n        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method\n        output_mode: String indicating the output mode. Either ``regression`` or ``classification``\n        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)\n        pad_token: Padding token\n        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)\n        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values\n            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for\n            actual values)\n\n    Returns:\n        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``\n        containing the task-specific features. If the input is a list of ``InputExamples``, will return\n        a list of task-specific ``InputFeatures`` which can be fed to the model.\n\n    \"\"\"", "\n", "is_tf_dataset", "=", "False", "\n", "if", "is_tf_available", "(", ")", "and", "isinstance", "(", "examples", ",", "tf", ".", "data", ".", "Dataset", ")", ":", "\n", "        ", "is_tf_dataset", "=", "True", "\n", "\n", "", "if", "task", "is", "not", "None", ":", "\n", "        ", "processor", "=", "glue_processors", "[", "task", "]", "(", ")", "\n", "if", "label_list", "is", "None", ":", "\n", "            ", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "logger", ".", "info", "(", "\"Using label list %s for task %s\"", "%", "(", "label_list", ",", "task", ")", ")", "\n", "", "if", "output_mode", "is", "None", ":", "\n", "            ", "output_mode", "=", "glue_output_modes", "[", "task", "]", "\n", "logger", ".", "info", "(", "\"Using output mode %s for task %s\"", "%", "(", "output_mode", ",", "task", ")", ")", "\n", "\n", "", "", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "len_examples", "=", "0", "\n", "if", "is_tf_dataset", ":", "\n", "            ", "example", "=", "processor", ".", "get_example_from_tensor_dict", "(", "example", ")", "\n", "example", "=", "processor", ".", "tfds_map", "(", "example", ")", "\n", "len_examples", "=", "tf", ".", "data", ".", "experimental", ".", "cardinality", "(", "examples", ")", "\n", "", "else", ":", "\n", "            ", "len_examples", "=", "len", "(", "examples", ")", "\n", "", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d/%d\"", "%", "(", "ex_index", ",", "len_examples", ")", ")", "\n", "\n", "", "inputs", "=", "tokenizer", ".", "encode_plus", "(", "example", ".", "text_a", ",", "example", ".", "text_b", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "max_length", ",", ")", "\n", "input_ids", ",", "token_type_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "inputs", "[", "\"token_type_ids\"", "]", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "attention_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "attention_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "attention_mask", "\n", "token_type_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "token_type_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "attention_mask", "=", "attention_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "token_type_ids", "=", "token_type_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "len", "(", "input_ids", ")", ",", "max_length", ")", "\n", "assert", "len", "(", "attention_mask", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "\n", "len", "(", "attention_mask", ")", ",", "max_length", "\n", ")", "\n", "assert", "len", "(", "token_type_ids", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "\n", "len", "(", "token_type_ids", ")", ",", "max_length", "\n", ")", "\n", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "label", "=", "label_map", "[", "example", ".", "label", "]", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "label", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "output_mode", ")", "\n", "\n", "", "if", "ex_index", "<", "5", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", ",", "\" \"", ".", "join", "(", "tokenizer", ".", "convert_ids_to_tokens", "(", "input_ids", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"attention_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "attention_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"token_type_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "token_type_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %d)\"", "%", "(", "example", ".", "label", ",", "label", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "\n", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "token_type_ids", "=", "token_type_ids", ",", "label", "=", "label", "\n", ")", "\n", ")", "\n", "\n", "", "if", "is_tf_available", "(", ")", "and", "is_tf_dataset", ":", "\n", "\n", "        ", "def", "gen", "(", ")", ":", "\n", "            ", "for", "ex", "in", "features", ":", "\n", "                ", "yield", "(", "\n", "{", "\n", "\"input_ids\"", ":", "ex", ".", "input_ids", ",", "\n", "\"attention_mask\"", ":", "ex", ".", "attention_mask", ",", "\n", "\"token_type_ids\"", ":", "ex", ".", "token_type_ids", ",", "\n", "}", ",", "\n", "ex", ".", "label", ",", "\n", ")", "\n", "\n", "", "", "return", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "\n", "gen", ",", "\n", "(", "{", "\"input_ids\"", ":", "tf", ".", "int32", ",", "\"attention_mask\"", ":", "tf", ".", "int32", ",", "\"token_type_ids\"", ":", "tf", ".", "int32", "}", ",", "tf", ".", "int64", ")", ",", "\n", "(", "\n", "{", "\n", "\"input_ids\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "\"attention_mask\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "\"token_type_ids\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "}", ",", "\n", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils_blue.convert_multi_label_examples_to_features": [[180, 318], ["enumerate", "file_utils.is_tf_available", "isinstance", "tokenizer.encode_plus", "features.append", "file_utils.is_tf_available", "tf.data.Dataset.from_generator", "processor.get_labels", "logger.info", "logger.info", "processor.get_example_from_tensor_dict", "processor.tfds_map", "tf.data.experimental.cardinality", "len", "logger.info", "len", "len", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils.InputFeatures", "tf.TensorShape", "tokenizer.convert_ids_to_tokens", "tf.TensorShape", "tf.TensorShape", "tf.TensorShape", "str", "str", "str", "enumerate"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.is_tf_available", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.is_tf_available", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_labels", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_example_from_tensor_dict", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.tfds_map"], ["", "def", "convert_multi_label_examples_to_features", "(", "\n", "examples", ",", "\n", "tokenizer", ",", "\n", "max_length", "=", "512", ",", "\n", "task", "=", "None", ",", "\n", "label_list", "=", "None", ",", "\n", "output_mode", "=", "None", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Loads a data file into a list of ``InputFeatures``\n\n    Args:\n        examples: List of ``InputExamples`` or ``tf.data.Dataset`` containing the examples.\n        tokenizer: Instance of a tokenizer that will tokenize the examples\n        max_length: Maximum example length\n        task: GLUE task\n        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method\n        output_mode: String indicating the output mode. Either ``regression`` or ``classification``\n        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)\n        pad_token: Padding token\n        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)\n        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values\n            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for\n            actual values)\n\n    Returns:\n        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``\n        containing the task-specific features. If the input is a list of ``InputExamples``, will return\n        a list of task-specific ``InputFeatures`` which can be fed to the model.\n\n    \"\"\"", "\n", "is_tf_dataset", "=", "False", "\n", "if", "is_tf_available", "(", ")", "and", "isinstance", "(", "examples", ",", "tf", ".", "data", ".", "Dataset", ")", ":", "\n", "        ", "is_tf_dataset", "=", "True", "\n", "\n", "", "if", "task", "is", "not", "None", ":", "\n", "        ", "processor", "=", "glue_processors", "[", "task", "]", "(", ")", "\n", "if", "label_list", "is", "None", ":", "\n", "            ", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "logger", ".", "info", "(", "\"Using label list %s for task %s\"", "%", "(", "label_list", ",", "task", ")", ")", "\n", "", "if", "output_mode", "is", "None", ":", "\n", "            ", "output_mode", "=", "glue_output_modes", "[", "task", "]", "\n", "logger", ".", "info", "(", "\"Using output mode %s for task %s\"", "%", "(", "output_mode", ",", "task", ")", ")", "\n", "\n", "# label_map = {label: i for i, label in enumerate(label_list)}", "\n", "\n", "", "", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "len_examples", "=", "0", "\n", "if", "is_tf_dataset", ":", "\n", "            ", "example", "=", "processor", ".", "get_example_from_tensor_dict", "(", "example", ")", "\n", "example", "=", "processor", ".", "tfds_map", "(", "example", ")", "\n", "len_examples", "=", "tf", ".", "data", ".", "experimental", ".", "cardinality", "(", "examples", ")", "\n", "", "else", ":", "\n", "            ", "len_examples", "=", "len", "(", "examples", ")", "\n", "", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d/%d\"", "%", "(", "ex_index", ",", "len_examples", ")", ")", "\n", "\n", "", "inputs", "=", "tokenizer", ".", "encode_plus", "(", "example", ".", "text_a", ",", "example", ".", "text_b", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "max_length", ",", ")", "\n", "input_ids", ",", "token_type_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "inputs", "[", "\"token_type_ids\"", "]", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "attention_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "attention_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "attention_mask", "\n", "token_type_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "token_type_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "attention_mask", "=", "attention_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "token_type_ids", "=", "token_type_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "len", "(", "input_ids", ")", ",", "max_length", ")", "\n", "assert", "len", "(", "attention_mask", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "\n", "len", "(", "attention_mask", ")", ",", "max_length", "\n", ")", "\n", "assert", "len", "(", "token_type_ids", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "\n", "len", "(", "token_type_ids", ")", ",", "max_length", "\n", ")", "\n", "\n", "#         if output_mode == \"classification\":", "\n", "#             label = label_map[example.label]", "\n", "#         elif output_mode == \"regression\":", "\n", "#             label = float(example.label)", "\n", "#         else:", "\n", "#             raise KeyError(output_mode)", "\n", "label", "=", "example", ".", "label", "\n", "\n", "if", "ex_index", "<", "5", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", ",", "\" \"", ".", "join", "(", "tokenizer", ".", "convert_ids_to_tokens", "(", "input_ids", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"attention_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "attention_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"token_type_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "token_type_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s \"", "%", "(", "','", ".", "join", "(", "[", "'{}_{}'", ".", "format", "(", "i", ",", "l", ")", "for", "i", ",", "l", "in", "enumerate", "(", "label", ")", "]", ")", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "\n", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "token_type_ids", "=", "token_type_ids", ",", "label", "=", "label", "\n", ")", "\n", ")", "\n", "\n", "", "if", "is_tf_available", "(", ")", "and", "is_tf_dataset", ":", "\n", "\n", "        ", "def", "gen", "(", ")", ":", "\n", "            ", "for", "ex", "in", "features", ":", "\n", "                ", "yield", "(", "\n", "{", "\n", "\"input_ids\"", ":", "ex", ".", "input_ids", ",", "\n", "\"attention_mask\"", ":", "ex", ".", "attention_mask", ",", "\n", "\"token_type_ids\"", ":", "ex", ".", "token_type_ids", ",", "\n", "}", ",", "\n", "ex", ".", "label", ",", "\n", ")", "\n", "\n", "", "", "return", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "\n", "gen", ",", "\n", "(", "{", "\"input_ids\"", ":", "tf", ".", "int32", ",", "\"attention_mask\"", ":", "tf", ".", "int32", ",", "\"token_type_ids\"", ":", "tf", ".", "int32", "}", ",", "tf", ".", "int64", ")", ",", "\n", "(", "\n", "{", "\n", "\"input_ids\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "\"attention_mask\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "\"token_type_ids\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "}", ",", "\n", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.tokenization.convert_to_unicode": [[19, 37], ["isinstance", "isinstance", "isinstance", "ValueError", "text.decode", "ValueError", "text.decode", "isinstance", "ValueError", "type", "type"], "function", ["None"], ["def", "convert_to_unicode", "(", "text", ")", ":", "\n", "    ", "\"\"\"Converts `text` to Unicode (if it's not already), assuming utf-8 input.\"\"\"", "\n", "if", "six", ".", "PY3", ":", "\n", "        ", "if", "isinstance", "(", "text", ",", "str", ")", ":", "\n", "            ", "return", "text", "\n", "", "elif", "isinstance", "(", "text", ",", "bytes", ")", ":", "\n", "            ", "return", "text", ".", "decode", "(", "\"utf-8\"", ",", "\"ignore\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unsupported string type: %s\"", "%", "(", "type", "(", "text", ")", ")", ")", "\n", "", "", "elif", "six", ".", "PY2", ":", "\n", "        ", "if", "isinstance", "(", "text", ",", "str", ")", ":", "\n", "            ", "return", "text", ".", "decode", "(", "\"utf-8\"", ",", "\"ignore\"", ")", "\n", "", "elif", "isinstance", "(", "text", ",", "unicode", ")", ":", "\n", "            ", "return", "text", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unsupported string type: %s\"", "%", "(", "type", "(", "text", ")", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Not running on Python2 or Python 3?\"", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.InputExample.__init__": [[46, 51], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "        ", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.InputExample.__repr__": [[52, 54], ["str", "utils.InputExample.to_json_string"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.InputFeatures.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.InputExample.to_dict": [[55, 59], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.InputExample.to_json_string": [[60, 63], ["json.dumps", "utils.InputExample.to_dict"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.InputFeatures.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.InputFeatures.__init__": [[78, 83], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "attention_mask", "=", "attention_mask", "\n", "self", ".", "token_type_ids", "=", "token_type_ids", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.InputFeatures.__repr__": [[84, 86], ["str", "utils.InputFeatures.to_json_string"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.InputFeatures.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.InputFeatures.to_dict": [[87, 91], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.InputFeatures.to_json_string": [[92, 95], ["json.dumps", "utils.InputFeatures.to_dict"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.InputFeatures.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_example_from_tensor_dict": [[100, 107], ["NotImplementedError"], "methods", ["None"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"Gets an example from a dict with tensorflow tensors\n        Args:\n            tensor_dict: Keys and values should match the corresponding Glue\n                tensorflow_dataset examples.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_train_examples": [[108, 111], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_dev_examples": [[112, 115], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_labels": [[116, 119], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.tfds_map": [[120, 126], ["len", "utils.DataProcessor.get_labels", "utils.DataProcessor.get_labels", "int"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_labels", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor.get_labels"], ["", "def", "tfds_map", "(", "self", ",", "example", ")", ":", "\n", "        ", "\"\"\"Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are.\n        This method converts examples to the correct format.\"\"\"", "\n", "if", "len", "(", "self", ".", "get_labels", "(", ")", ")", ">", "1", ":", "\n", "            ", "example", ".", "label", "=", "self", ".", "get_labels", "(", ")", "[", "int", "(", "example", ".", "label", ")", "]", "\n", "", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv": [[127, 132], ["open", "list", "csv.reader"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_read_tsv", "(", "cls", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8-sig\"", ")", "as", "f", ":", "\n", "            ", "return", "list", "(", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.SingleSentenceClassificationProcessor.__init__": [[137, 142], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "labels", "=", "None", ",", "examples", "=", "None", ",", "mode", "=", "\"classification\"", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "self", ".", "labels", "=", "[", "]", "if", "labels", "is", "None", "else", "labels", "\n", "self", ".", "examples", "=", "[", "]", "if", "examples", "is", "None", "else", "examples", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.SingleSentenceClassificationProcessor.__len__": [[143, 145], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.SingleSentenceClassificationProcessor.__getitem__": [[146, 150], ["isinstance", "utils.SingleSentenceClassificationProcessor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "isinstance", "(", "idx", ",", "slice", ")", ":", "\n", "            ", "return", "SingleSentenceClassificationProcessor", "(", "labels", "=", "self", ".", "labels", ",", "examples", "=", "self", ".", "examples", "[", "idx", "]", ")", "\n", "", "return", "self", ".", "examples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.SingleSentenceClassificationProcessor.create_from_csv": [[151, 167], ["cls", "cls.add_examples_from_csv"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.SingleSentenceClassificationProcessor.add_examples_from_csv"], ["", "@", "classmethod", "\n", "def", "create_from_csv", "(", "\n", "cls", ",", "file_name", ",", "split_name", "=", "\"\"", ",", "column_label", "=", "0", ",", "column_text", "=", "1", ",", "column_id", "=", "None", ",", "skip_first_row", "=", "False", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "processor", "=", "cls", "(", "**", "kwargs", ")", "\n", "processor", ".", "add_examples_from_csv", "(", "\n", "file_name", ",", "\n", "split_name", "=", "split_name", ",", "\n", "column_label", "=", "column_label", ",", "\n", "column_text", "=", "column_text", ",", "\n", "column_id", "=", "column_id", ",", "\n", "skip_first_row", "=", "skip_first_row", ",", "\n", "overwrite_labels", "=", "True", ",", "\n", "overwrite_examples", "=", "True", ",", "\n", ")", "\n", "return", "processor", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.SingleSentenceClassificationProcessor.create_from_examples": [[168, 173], ["cls", "cls.add_examples"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.SingleSentenceClassificationProcessor.add_examples"], ["", "@", "classmethod", "\n", "def", "create_from_examples", "(", "cls", ",", "texts_or_text_and_labels", ",", "labels", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "processor", "=", "cls", "(", "**", "kwargs", ")", "\n", "processor", ".", "add_examples", "(", "texts_or_text_and_labels", ",", "labels", "=", "labels", ")", "\n", "return", "processor", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.SingleSentenceClassificationProcessor.add_examples_from_csv": [[174, 202], ["utils.SingleSentenceClassificationProcessor._read_tsv", "enumerate", "utils.SingleSentenceClassificationProcessor.add_examples", "texts.append", "labels.append", "ids.append", "ids.append"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.DataProcessor._read_tsv", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.SingleSentenceClassificationProcessor.add_examples"], ["", "def", "add_examples_from_csv", "(", "\n", "self", ",", "\n", "file_name", ",", "\n", "split_name", "=", "\"\"", ",", "\n", "column_label", "=", "0", ",", "\n", "column_text", "=", "1", ",", "\n", "column_id", "=", "None", ",", "\n", "skip_first_row", "=", "False", ",", "\n", "overwrite_labels", "=", "False", ",", "\n", "overwrite_examples", "=", "False", ",", "\n", ")", ":", "\n", "        ", "lines", "=", "self", ".", "_read_tsv", "(", "file_name", ")", "\n", "if", "skip_first_row", ":", "\n", "            ", "lines", "=", "lines", "[", "1", ":", "]", "\n", "", "texts", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "ids", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "texts", ".", "append", "(", "line", "[", "column_text", "]", ")", "\n", "labels", ".", "append", "(", "line", "[", "column_label", "]", ")", "\n", "if", "column_id", "is", "not", "None", ":", "\n", "                ", "ids", ".", "append", "(", "line", "[", "column_id", "]", ")", "\n", "", "else", ":", "\n", "                ", "guid", "=", "\"%s-%s\"", "%", "(", "split_name", ",", "i", ")", "if", "split_name", "else", "\"%s\"", "%", "i", "\n", "ids", ".", "append", "(", "guid", ")", "\n", "\n", "", "", "return", "self", ".", "add_examples", "(", "\n", "texts", ",", "labels", ",", "ids", ",", "overwrite_labels", "=", "overwrite_labels", ",", "overwrite_examples", "=", "overwrite_examples", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.SingleSentenceClassificationProcessor.add_examples": [[204, 236], ["set", "zip", "set.add", "examples.append", "utils.SingleSentenceClassificationProcessor.examples.extend", "list", "list", "len", "len", "len", "len", "len", "len", "isinstance", "utils.InputExample", "set().union", "set"], "methods", ["None"], ["", "def", "add_examples", "(", "\n", "self", ",", "texts_or_text_and_labels", ",", "labels", "=", "None", ",", "ids", "=", "None", ",", "overwrite_labels", "=", "False", ",", "overwrite_examples", "=", "False", "\n", ")", ":", "\n", "        ", "assert", "labels", "is", "None", "or", "len", "(", "texts_or_text_and_labels", ")", "==", "len", "(", "labels", ")", "\n", "assert", "ids", "is", "None", "or", "len", "(", "texts_or_text_and_labels", ")", "==", "len", "(", "ids", ")", "\n", "if", "ids", "is", "None", ":", "\n", "            ", "ids", "=", "[", "None", "]", "*", "len", "(", "texts_or_text_and_labels", ")", "\n", "", "if", "labels", "is", "None", ":", "\n", "            ", "labels", "=", "[", "None", "]", "*", "len", "(", "texts_or_text_and_labels", ")", "\n", "", "examples", "=", "[", "]", "\n", "added_labels", "=", "set", "(", ")", "\n", "for", "(", "text_or_text_and_label", ",", "label", ",", "guid", ")", "in", "zip", "(", "texts_or_text_and_labels", ",", "labels", ",", "ids", ")", ":", "\n", "            ", "if", "isinstance", "(", "text_or_text_and_label", ",", "(", "tuple", ",", "list", ")", ")", "and", "label", "is", "None", ":", "\n", "                ", "text", ",", "label", "=", "text_or_text_and_label", "\n", "", "else", ":", "\n", "                ", "text", "=", "text_or_text_and_label", "\n", "", "added_labels", ".", "add", "(", "label", ")", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "\n", "# Update examples", "\n", "", "if", "overwrite_examples", ":", "\n", "            ", "self", ".", "examples", "=", "examples", "\n", "", "else", ":", "\n", "            ", "self", ".", "examples", ".", "extend", "(", "examples", ")", "\n", "\n", "# Update labels", "\n", "", "if", "overwrite_labels", ":", "\n", "            ", "self", ".", "labels", "=", "list", "(", "added_labels", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "labels", "=", "list", "(", "set", "(", "self", ".", "labels", ")", ".", "union", "(", "added_labels", ")", ")", "\n", "\n", "", "return", "self", ".", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.utils.SingleSentenceClassificationProcessor.get_features": [[237, 358], ["enumerate", "max", "enumerate", "tokenizer.encode", "torch.tensor.append", "zip", "features.append", "enumerate", "logger.info", "len", "logger.info", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils.InputFeatures", "tf.data.Dataset.from_generator", "min", "float", "ValueError", "file_utils.is_tf_available", "RuntimeError", "torch.tensor", "torch.tensor", "TensorDataset", "ValueError", "tf.TensorShape", "file_utils.is_torch_available", "RuntimeError", "torch.tensor", "len", "tf.TensorShape", "tf.TensorShape", "torch.tensor", "str", "str"], "methods", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.is_tf_available", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.processors.file_utils.is_torch_available"], ["", "def", "get_features", "(", "\n", "self", ",", "\n", "tokenizer", ",", "\n", "max_length", "=", "None", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", "return_tensors", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Convert examples in a list of ``InputFeatures``\n\n        Args:\n            tokenizer: Instance of a tokenizer that will tokenize the examples\n            max_length: Maximum example length\n            task: GLUE task\n            label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method\n            output_mode: String indicating the output mode. Either ``regression`` or ``classification``\n            pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)\n            pad_token: Padding token\n            mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values\n                and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for\n                actual values)\n\n        Returns:\n            If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``\n            containing the task-specific features. If the input is a list of ``InputExamples``, will return\n            a list of task-specific ``InputFeatures`` which can be fed to the model.\n\n        \"\"\"", "\n", "if", "max_length", "is", "None", ":", "\n", "            ", "max_length", "=", "tokenizer", ".", "max_len", "\n", "\n", "", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "labels", ")", "}", "\n", "\n", "all_input_ids", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "self", ".", "examples", ")", ":", "\n", "            ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"Tokenizing example %d\"", ",", "ex_index", ")", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "encode", "(", "\n", "example", ".", "text_a", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "min", "(", "max_length", ",", "tokenizer", ".", "max_len", ")", ",", "\n", ")", "\n", "all_input_ids", ".", "append", "(", "input_ids", ")", "\n", "\n", "", "batch_length", "=", "max", "(", "len", "(", "input_ids", ")", "for", "input_ids", "in", "all_input_ids", ")", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "(", "input_ids", ",", "example", ")", ")", "in", "enumerate", "(", "zip", "(", "all_input_ids", ",", "self", ".", "examples", ")", ")", ":", "\n", "            ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"Writing example %d/%d\"", "%", "(", "ex_index", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "", "attention_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "batch_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "                ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "attention_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "attention_mask", "\n", "", "else", ":", "\n", "                ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "attention_mask", "=", "attention_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "batch_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "\n", "len", "(", "input_ids", ")", ",", "batch_length", "\n", ")", "\n", "assert", "len", "(", "attention_mask", ")", "==", "batch_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "\n", "len", "(", "attention_mask", ")", ",", "batch_length", "\n", ")", "\n", "\n", "if", "self", ".", "mode", "==", "\"classification\"", ":", "\n", "                ", "label", "=", "label_map", "[", "example", ".", "label", "]", "\n", "", "elif", "self", ".", "mode", "==", "\"regression\"", ":", "\n", "                ", "label", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "self", ".", "mode", ")", "\n", "\n", "", "if", "ex_index", "<", "5", "and", "self", ".", "verbose", ":", "\n", "                ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"attention_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "attention_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %d)\"", "%", "(", "example", ".", "label", ",", "label", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "label", "=", "label", ")", ")", "\n", "\n", "", "if", "return_tensors", "is", "None", ":", "\n", "            ", "return", "features", "\n", "", "elif", "return_tensors", "==", "\"tf\"", ":", "\n", "            ", "if", "not", "is_tf_available", "(", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"return_tensors set to 'tf' but TensorFlow 2.0 can't be imported\"", ")", "\n", "", "import", "tensorflow", "as", "tf", "\n", "\n", "def", "gen", "(", ")", ":", "\n", "                ", "for", "ex", "in", "features", ":", "\n", "                    ", "yield", "(", "{", "\"input_ids\"", ":", "ex", ".", "input_ids", ",", "\"attention_mask\"", ":", "ex", ".", "attention_mask", "}", ",", "ex", ".", "label", ")", "\n", "\n", "", "", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "\n", "gen", ",", "\n", "(", "{", "\"input_ids\"", ":", "tf", ".", "int32", ",", "\"attention_mask\"", ":", "tf", ".", "int32", "}", ",", "tf", ".", "int64", ")", ",", "\n", "(", "{", "\"input_ids\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\"attention_mask\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", "}", ",", "tf", ".", "TensorShape", "(", "[", "]", ")", ")", ",", "\n", ")", "\n", "return", "dataset", "\n", "", "elif", "return_tensors", "==", "\"pt\"", ":", "\n", "            ", "if", "not", "is_torch_available", "(", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"return_tensors set to 'pt' but PyTorch can't be imported\"", ")", "\n", "", "import", "torch", "\n", "from", "torch", ".", "utils", ".", "data", "import", "TensorDataset", "\n", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_attention_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "attention_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "self", ".", "mode", "==", "\"classification\"", ":", "\n", "                ", "all_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "elif", "self", ".", "mode", "==", "\"regression\"", ":", "\n", "                ", "all_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_attention_mask", ",", "all_labels", ")", "\n", "return", "dataset", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"return_tensors should be one of 'tf' or 'pt'\"", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.ner.get_phrase": [[13, 19], ["phraselist.append", "phraselist[].append", "str", "str"], "function", ["None"], ["def", "get_phrase", "(", "phraselist", ",", "tag", ",", "index", ")", ":", "\n", "    ", "if", "tag", "==", "'B'", ":", "\n", "        ", "phraselist", ".", "append", "(", "[", "str", "(", "index", ")", "]", ")", "\n", "", "elif", "tag", "==", "'I'", ":", "\n", "        ", "phraselist", "[", "-", "1", "]", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.ner.eval_ner": [[20, 58], ["enumerate", "set", "set", "len", "ner.get_phrase", "ner.get_phrase", "map", "map", "len", "len", "len", "len", "line.strip().split", "line.strip"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.ner.get_phrase", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.ner.get_phrase"], ["", "def", "eval_ner", "(", "iterable", ")", ":", "\n", "    ", "y_true", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "num_token", "=", "0", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "iterable", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "token", ",", "true", ",", "pred", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "", "except", ":", "\n", "            ", "continue", "\n", "", "get_phrase", "(", "y_true", ",", "true", ",", "i", ")", "\n", "get_phrase", "(", "y_pred", ",", "pred", ",", "i", ")", "\n", "num_token", "+=", "1", "\n", "\n", "", "y_true", "=", "set", "(", "map", "(", "'_'", ".", "join", ",", "y_true", ")", ")", "\n", "y_pred", "=", "set", "(", "map", "(", "'_'", ".", "join", ",", "y_pred", ")", ")", "\n", "\n", "TP", "=", "len", "(", "y_true", "&", "y_pred", ")", "\n", "FN", "=", "len", "(", "y_true", ")", "-", "TP", "\n", "FP", "=", "len", "(", "y_pred", ")", "-", "TP", "\n", "prec", "=", "TP", "/", "(", "TP", "+", "FP", ")", "\n", "rec", "=", "TP", "/", "(", "TP", "+", "FN", ")", "\n", "fb1", "=", "2", "*", "rec", "*", "prec", "/", "(", "rec", "+", "prec", ")", "\n", "\n", "results", "=", "{", "\n", "\"TP\"", ":", "TP", ",", "\n", "\"FP\"", ":", "FP", ",", "\n", "\"FN\"", ":", "FN", ",", "\n", "\"precision\"", ":", "prec", ",", "\n", "\"recall\"", ":", "rec", ",", "\n", "\"FB1\"", ":", "fb1", ",", "\n", "}", "\n", "report", "=", "'processed {} tokens with {} phrases; found: {} phrases; correct: {}.\\n'", ".", "format", "(", "num_token", ",", "len", "(", "y_true", ")", ",", "len", "(", "y_pred", ")", ",", "TP", ")", "\n", "report", "+=", "'TP: {}, FP: {}, FN: {}\\n'", ".", "format", "(", "TP", ",", "FP", ",", "FN", ")", "\n", "report", "+=", "'Precision: {:.2f}%, Recall: {:.2f}%, FB1: {:.2f}%'", ".", "format", "(", "\n", "prec", "*", "100", ",", "\n", "rec", "*", "100", ",", "\n", "fb1", "*", "100", ")", "\n", "return", "results", ",", "report", "\n", "", ""]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.common_metrics.accuracy": [[10, 12], ["None"], "function", ["None"], ["def", "accuracy", "(", "tp", ",", "tn", ",", "fp", ",", "fn", ")", ":", "\n", "    ", "return", "tp", "/", "(", "tp", "+", "fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.common_metrics.precision": [[13, 15], ["None"], "function", ["None"], ["", "def", "precision", "(", "tp", ",", "tn", ",", "fp", ",", "fn", ")", ":", "\n", "    ", "return", "tp", "/", "(", "tp", "+", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.common_metrics.recall": [[16, 18], ["None"], "function", ["None"], ["", "def", "recall", "(", "tp", ",", "tn", ",", "fp", ",", "fn", ")", ":", "\n", "    ", "return", "tp", "/", "(", "tp", "+", "fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.common_metrics.fb1": [[19, 21], ["None"], "function", ["None"], ["", "def", "fb1", "(", "precision", ",", "recall", ")", ":", "\n", "    ", "return", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.common_metrics.overall_acc": [[22, 24], ["numpy.sum", "numpy.sum"], "function", ["None"], ["", "def", "overall_acc", "(", "tp", ",", "tn", ",", "fp", ",", "fn", ")", ":", "\n", "    ", "return", "np", ".", "sum", "(", "tp", ")", "/", "np", ".", "sum", "(", "tp", "+", "fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.common_metrics.a_p_r_f": [[25, 31], ["common_metrics.accuracy", "numpy.nan_to_num", "numpy.nan_to_num", "numpy.nan_to_num", "common_metrics.precision", "common_metrics.recall", "common_metrics.fb1"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.common_metrics.accuracy", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.common_metrics.precision", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.common_metrics.recall", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.common_metrics.fb1"], ["", "def", "a_p_r_f", "(", "tp", ",", "tn", ",", "fp", ",", "fn", ")", ":", "\n", "    ", "acc", "=", "accuracy", "(", "tp", ",", "tn", ",", "fp", ",", "fn", ")", "\n", "prec", "=", "np", ".", "nan_to_num", "(", "precision", "(", "tp", ",", "tn", ",", "fp", ",", "fn", ")", ")", "\n", "rec", "=", "np", ".", "nan_to_num", "(", "recall", "(", "tp", ",", "tn", ",", "fp", ",", "fn", ")", ")", "\n", "fscore", "=", "np", ".", "nan_to_num", "(", "fb1", "(", "prec", ",", "rec", ")", ")", "\n", "return", "acc", ",", "prec", ",", "rec", ",", "fscore", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.common_metrics.classification_report": [[32, 100], ["collections.Counter", "numpy.array", "sklearn.metrics.confusion_matrix", "numpy.diag", "enumerate", "numpy.array", "numpy.array", "pandas.DataFrame().astype", "common_metrics.a_p_r_f", "df.append.reset_index", "enumerate", "np.array.append", "np.array.append", "common_metrics.a_p_r_f", "macro_metrics.append", "df.append.sum", "micro_metrics.append", "df.append.append", "df.append.append", "np.array.get", "pandas.DataFrame", "numpy.average", "pandas.Series", "df.append.drop", "common_metrics.a_p_r_f", "macro_metrics.append", "df.append.drop().sum", "micro_metrics.append", "range", "cm[].sum", "cm[].sum", "numpy.average", "pandas.Series", "len", "df.append.drop", "set", "set", "len"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.common_metrics.a_p_r_f", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.common_metrics.a_p_r_f", "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.common_metrics.a_p_r_f"], ["", "def", "classification_report", "(", "y_true", ",", "y_pred", ",", "label_list", ",", "drop_false", "=", "False", ",", "\n", "micro", "=", "True", ",", "macro", "=", "True", ")", ":", "\n", "#search false label position.", "\n", "    ", "if", "drop_false", ":", "\n", "        ", "for", "i", ",", "l", "in", "enumerate", "(", "label_list", ")", ":", "\n", "            ", "if", "'false'", "in", "l", ":", "\n", "                ", "false_id", "=", "i", "\n", "\n", "", "", "", "supports", "=", "Counter", "(", "y_true", ")", "\n", "supports", "=", "np", ".", "array", "(", "[", "supports", ".", "get", "(", "i", ",", "0", ")", "for", "i", "in", "range", "(", "len", "(", "set", "(", "y_true", ")", "|", "set", "(", "y_pred", ")", ")", ")", "]", ")", "\n", "\n", "cm", "=", "confusion_matrix", "(", "y_true", ",", "y_pred", ")", "\n", "\n", "tps", "=", "np", ".", "diag", "(", "cm", ")", "# TP", "\n", "fps", "=", "[", "]", "\n", "fns", "=", "[", "]", "\n", "for", "i", ",", "tp", "in", "enumerate", "(", "tps", ")", ":", "\n", "        ", "fps", ".", "append", "(", "cm", "[", ":", ",", "i", "]", ".", "sum", "(", ")", "-", "tp", ")", "# FP", "\n", "fns", ".", "append", "(", "cm", "[", "i", "]", ".", "sum", "(", ")", "-", "tp", ")", "# FN", "\n", "", "fps", "=", "np", ".", "array", "(", "fps", ")", "\n", "fns", "=", "np", ".", "array", "(", "fns", ")", "\n", "\n", "df", "=", "pd", ".", "DataFrame", "(", "{", "\n", "'Class'", ":", "0", ",", "\n", "'TP'", ":", "tps", ",", "\n", "'TN'", ":", "len", "(", "y_true", ")", "-", "tps", "-", "fps", "-", "fns", ",", "\n", "'FP'", ":", "fps", ",", "\n", "'FN'", ":", "fns", ",", "\n", "'Support'", ":", "supports", "}", ")", ".", "astype", "(", "int", ")", "\n", "\n", "df", "[", "'Class'", "]", "=", "label_list", "\n", "if", "macro", ":", "\n", "        ", "macro_metrics", "=", "[", "]", "\n", "acc", ",", "prec", ",", "rec", ",", "fscore", "=", "a_p_r_f", "(", "df", ".", "TP", ",", "df", ".", "TN", ",", "df", ".", "FP", ",", "df", ".", "FN", ")", "\n", "row", "=", "[", "'macro_include_false'", "]", "+", "[", "''", "]", "*", "5", "\n", "row", "+=", "[", "np", ".", "average", "(", "t", ")", "for", "t", "in", "[", "prec", ",", "rec", ",", "fscore", ",", "acc", "]", "]", "\n", "macro_metrics", ".", "append", "(", "pd", ".", "Series", "(", "row", ",", "index", "=", "report_columns", ")", ")", "\n", "if", "drop_false", ":", "\n", "            ", "df_d", "=", "df", ".", "drop", "(", "false_id", ",", "axis", "=", "0", ")", "\n", "acc", ",", "prec", ",", "rec", ",", "fscore", "=", "a_p_r_f", "(", "df_d", ".", "TP", ",", "df_d", ".", "TN", ",", "df_d", ".", "FP", ",", "df_d", ".", "FN", ")", "\n", "row", "=", "[", "'macro_drop_false'", "]", "+", "[", "''", "]", "*", "5", "\n", "row", "+=", "[", "np", ".", "average", "(", "t", ")", "for", "t", "in", "[", "prec", ",", "rec", ",", "fscore", ",", "acc", "]", "]", "\n", "macro_metrics", ".", "append", "(", "pd", ".", "Series", "(", "row", ",", "index", "=", "report_columns", ")", ")", "\n", "\n", "", "", "if", "micro", ":", "\n", "        ", "micro_metrics", "=", "[", "]", "\n", "micro_include_false", "=", "df", ".", "sum", "(", ")", "\n", "micro_include_false", "[", "'Class'", "]", "=", "'micro_include_false'", "\n", "micro_metrics", ".", "append", "(", "micro_include_false", ")", "\n", "if", "drop_false", ":", "\n", "            ", "micro_drop_false", "=", "df", ".", "drop", "(", "false_id", ",", "axis", "=", "0", ")", ".", "sum", "(", ")", "\n", "micro_drop_false", "[", "'Class'", "]", "=", "'micro_drop_false'", "\n", "micro_metrics", ".", "append", "(", "micro_drop_false", ")", "\n", "\n", "", "df", "=", "df", ".", "append", "(", "micro_metrics", ")", "\n", "\n", "# compute micro_metrics", "\n", "", "acc", ",", "prec", ",", "rec", ",", "fscore", "=", "a_p_r_f", "(", "df", ".", "TP", ",", "df", ".", "TN", ",", "df", ".", "FP", ",", "df", ".", "FN", ")", "\n", "\n", "df", "[", "'Precision'", "]", "=", "prec", "\n", "df", "[", "'Recall'", "]", "=", "rec", "\n", "df", "[", "'F1score'", "]", "=", "fscore", "\n", "df", "[", "'Accuracy'", "]", "=", "acc", "\n", "\n", "if", "macro", ":", "\n", "        ", "df", "=", "df", ".", "append", "(", "macro_metrics", ")", "\n", "\n", "", "return", "df", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.mednli.eval_mednli": [[9, 25], ["common_metrics.classification_report", "sklearn.metrics.accuracy_score"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.common_metrics.classification_report"], ["def", "eval_mednli", "(", "y_true", ",", "y_pred", ",", "label_list", ")", ":", "\n", "    ", "df", "=", "classification_report", "(", "y_true", ",", "y_pred", ",", "label_list", ",", "drop_false", "=", "False", ")", "\n", "\n", "# add micro average to the result", "\n", "row", "=", "df", "[", "df", "[", "'Class'", "]", "==", "'micro_include_false'", "]", ".", "iloc", "[", "0", "]", "\n", "results", "=", "{", "\n", "\"TP\"", ":", "row", ".", "TP", ",", "\n", "\"FP\"", ":", "row", ".", "FP", ",", "\n", "\"FN\"", ":", "row", ".", "FN", ",", "\n", "\"precision\"", ":", "row", ".", "Precision", ",", "\n", "\"recall\"", ":", "row", ".", "Recall", ",", "\n", "\"FB1\"", ":", "row", ".", "F1score", ",", "\n", "\"overall_acc\"", ":", "accuracy_score", "(", "y_true", ",", "y_pred", ")", ",", "\n", "}", "\n", "\n", "return", "results", ",", "df", "\n", "", ""]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.sts.eval_sts": [[5, 8], ["scipy.stats.pearsonr"], "function", ["None"], ["def", "eval_sts", "(", "x", ",", "y", ")", ":", "\n", "    ", "r", ",", "p", "=", "pearsonr", "(", "x", ",", "y", ")", "\n", "return", "r", "", "", ""]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.hoc.eval_roc_auc": [[18, 31], ["dict", "dict", "dict", "range", "sklearn.metrics.roc_curve", "sklearn.metrics.auc", "sklearn.metrics.roc_curve", "sklearn.metrics.auc", "y_true.ravel", "pred_score.ravel"], "function", ["None"], ["def", "eval_roc_auc", "(", "y_true", ",", "pred_score", ",", "num_labels", ")", ":", "\n", "    ", "fpr", "=", "dict", "(", ")", "\n", "tpr", "=", "dict", "(", ")", "\n", "roc_auc", "=", "dict", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_labels", ")", ":", "\n", "        ", "fpr", "[", "i", "]", ",", "tpr", "[", "i", "]", ",", "_", "=", "roc_curve", "(", "y_true", "[", ":", ",", "i", "]", ",", "pred_score", "[", ":", ",", "i", "]", ")", "\n", "roc_auc", "[", "i", "]", "=", "auc", "(", "fpr", "[", "i", "]", ",", "tpr", "[", "i", "]", ")", "\n", "\n", "# Compute micro-average ROC curve and ROC area", "\n", "", "fpr", "[", "\"micro\"", "]", ",", "tpr", "[", "\"micro\"", "]", ",", "_", "=", "roc_curve", "(", "y_true", ".", "ravel", "(", ")", ",", "pred_score", ".", "ravel", "(", ")", ")", "\n", "roc_auc", "[", "\"micro\"", "]", "=", "auc", "(", "fpr", "[", "\"micro\"", "]", ",", "tpr", "[", "\"micro\"", "]", ")", "\n", "return", "roc_auc", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.hoc.get_p_r_f_arrary": [[37, 80], ["range", "numpy.mean", "numpy.mean", "set", "set", "range", "set.union", "set.intersection", "len", "acc_list.append", "prc_list.append", "rec_list.append", "f_score_list.append", "len", "len", "len", "set.add", "set.add", "len"], "function", ["None"], ["", "def", "get_p_r_f_arrary", "(", "test_predict_label", ",", "test_true_label", ")", ":", "\n", "    ", "num", ",", "cat", "=", "test_predict_label", ".", "shape", "\n", "acc_list", "=", "[", "]", "\n", "prc_list", "=", "[", "]", "\n", "rec_list", "=", "[", "]", "\n", "f_score_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num", ")", ":", "\n", "        ", "label_pred_set", "=", "set", "(", ")", "\n", "label_gold_set", "=", "set", "(", ")", "\n", "\n", "for", "j", "in", "range", "(", "cat", ")", ":", "\n", "            ", "if", "test_predict_label", "[", "i", ",", "j", "]", "==", "1", ":", "\n", "                ", "label_pred_set", ".", "add", "(", "j", ")", "\n", "", "if", "test_true_label", "[", "i", ",", "j", "]", "==", "1", ":", "\n", "                ", "label_gold_set", ".", "add", "(", "j", ")", "\n", "\n", "", "", "uni_set", "=", "label_gold_set", ".", "union", "(", "label_pred_set", ")", "\n", "intersec_set", "=", "label_gold_set", ".", "intersection", "(", "label_pred_set", ")", "\n", "\n", "tt", "=", "len", "(", "intersec_set", ")", "\n", "if", "len", "(", "label_pred_set", ")", "==", "0", ":", "\n", "            ", "prc", "=", "0", "\n", "", "else", ":", "\n", "            ", "prc", "=", "tt", "/", "len", "(", "label_pred_set", ")", "\n", "\n", "", "acc", "=", "tt", "/", "len", "(", "uni_set", ")", "\n", "\n", "rec", "=", "tt", "/", "len", "(", "label_gold_set", ")", "\n", "\n", "if", "prc", "==", "0", "and", "rec", "==", "0", ":", "\n", "            ", "f_score", "=", "0", "\n", "", "else", ":", "\n", "            ", "f_score", "=", "2", "*", "prc", "*", "rec", "/", "(", "prc", "+", "rec", ")", "\n", "\n", "", "acc_list", ".", "append", "(", "acc", ")", "\n", "prc_list", ".", "append", "(", "prc", ")", "\n", "rec_list", ".", "append", "(", "rec", ")", "\n", "f_score_list", ".", "append", "(", "f_score", ")", "\n", "\n", "", "mean_prc", "=", "np", ".", "mean", "(", "prc_list", ")", "\n", "mean_rec", "=", "np", ".", "mean", "(", "rec_list", ")", "\n", "f_score", "=", "2", "*", "mean_prc", "*", "mean_rec", "/", "(", "mean_prc", "+", "mean_rec", ")", "\n", "return", "mean_prc", ",", "mean_rec", ",", "f_score", "\n", "\n"]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.hoc.eval_hoc": [[82, 149], ["df.drop", "df.drop().rename", "range", "data.items", "numpy.array", "numpy.array", "hoc.get_p_r_f_arrary", "len", "len", "len", "len", "len", "np.array.append", "np.array.append", "df.drop", "len", "len", "pandas.isna", "true_row[].split", "pandas.isna", "pred_row[].split", "len", "len", "true_row[].find", "set", "set", "l.endswith", "l.endswith", "[].add", "[].add", "LABELS.index", "LABELS.index"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.hoc.get_p_r_f_arrary"], ["", "def", "eval_hoc", "(", "df", ",", "mode", ")", ":", "\n", "    ", "\"\"\"\n    df is DataFrame of pandas. It needs 3 columns below:\n    index, labels(=y_true), pred_labels(=y_preds)\n    We create two DataFrames (true_df, pred_df) from df and rename 'pred_labels' as 'labels' in pred_df.\n    \"\"\"", "\n", "data", "=", "{", "}", "\n", "\n", "true_df", "=", "df", ".", "drop", "(", "'pred_labels'", ",", "axis", "=", "1", ")", "\n", "pred_df", "=", "df", ".", "drop", "(", "'labels'", ",", "axis", "=", "1", ")", ".", "rename", "(", "columns", "=", "{", "'pred_labels'", ":", "'labels'", "}", ")", "\n", "\n", "assert", "len", "(", "true_df", ")", "==", "len", "(", "pred_df", ")", ",", "f'Gold line no {len(true_df)} vs Prediction line no {len(pred_df)}'", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "true_df", ")", ")", ":", "\n", "        ", "true_row", "=", "true_df", ".", "iloc", "[", "i", "]", "\n", "pred_row", "=", "pred_df", ".", "iloc", "[", "i", "]", "\n", "assert", "true_row", "[", "'index'", "]", "==", "pred_row", "[", "'index'", "]", ",", "'Index does not match @{}: {} vs {}'", ".", "format", "(", "i", ",", "true_row", "[", "'index'", "]", ",", "pred_row", "[", "'index'", "]", ")", "\n", "\n", "key", "=", "true_row", "[", "'index'", "]", "[", ":", "true_row", "[", "'index'", "]", ".", "find", "(", "'_'", ")", "]", "\n", "if", "key", "not", "in", "data", ":", "\n", "            ", "data", "[", "key", "]", "=", "(", "set", "(", ")", ",", "set", "(", ")", ")", "\n", "\n", "", "if", "not", "pd", ".", "isna", "(", "true_row", "[", "'labels'", "]", ")", ":", "\n", "            ", "for", "l", "in", "true_row", "[", "'labels'", "]", ".", "split", "(", "','", ")", ":", "\n", "                ", "if", "l", ".", "endswith", "(", "'_1'", ")", ":", "#ADD:", "\n", "                    ", "data", "[", "key", "]", "[", "0", "]", ".", "add", "(", "LABELS", ".", "index", "(", "l", ")", ")", "\n", "\n", "", "", "", "if", "not", "pd", ".", "isna", "(", "pred_row", "[", "'labels'", "]", ")", ":", "\n", "            ", "for", "l", "in", "pred_row", "[", "'labels'", "]", ".", "split", "(", "','", ")", ":", "\n", "                ", "if", "l", ".", "endswith", "(", "'_1'", ")", ":", "#ADD:", "\n", "                    ", "data", "[", "key", "]", "[", "1", "]", ".", "add", "(", "LABELS", ".", "index", "(", "l", ")", ")", "\n", "\n", "#ADD:", "\n", "", "", "", "", "if", "mode", "==", "'test'", ":", "\n", "        ", "num_docs", "=", "315", "\n", "", "elif", "mode", "==", "'dev'", ":", "\n", "        ", "num_docs", "=", "157", "\n", "\n", "", "assert", "len", "(", "data", ")", "==", "num_docs", ",", "'There are {} documents in the {} set: %d'", ".", "format", "(", "num_docs", ",", "mode", ")", "%", "len", "(", "data", ")", "\n", "\n", "y_test", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "for", "k", ",", "(", "true", ",", "pred", ")", "in", "data", ".", "items", "(", ")", ":", "\n", "        ", "t", "=", "[", "0", "]", "*", "len", "(", "LABELS", ")", "\n", "for", "i", "in", "true", ":", "\n", "            ", "t", "[", "i", "]", "=", "1", "\n", "\n", "", "p", "=", "[", "0", "]", "*", "len", "(", "LABELS", ")", "\n", "for", "i", "in", "pred", ":", "\n", "            ", "p", "[", "i", "]", "=", "1", "\n", "\n", "", "y_test", ".", "append", "(", "t", ")", "\n", "y_pred", ".", "append", "(", "p", ")", "\n", "\n", "", "y_test", "=", "np", ".", "array", "(", "y_test", ")", "\n", "y_pred", "=", "np", ".", "array", "(", "y_pred", ")", "\n", "\n", "p", ",", "r", ",", "f1", "=", "get_p_r_f_arrary", "(", "y_pred", ",", "y_test", ")", "\n", "results", "=", "{", "\n", "\"precision\"", ":", "p", ",", "\n", "\"recall\"", ":", "r", ",", "\n", "\"FB1\"", ":", "f1", ",", "\n", "}", "\n", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.__init__.is_sklearn_available": [[30, 32], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.re.calculate_metrics": [[7, 34], ["common_metrics.classification_report", "len", "len", "list", "list", "set", "map", "map", "label_list.index", "label_list.index", "set"], "function", ["home.repos.pwc.inspect_result.sy-wada_blue_benchmark_with_transformers.metrics.common_metrics.classification_report"], ["def", "calculate_metrics", "(", "y_true", ",", "y_pred", ",", "label_list", ")", ":", "\n", "# delete unused labels to calculate metrics.", "\n", "    ", "if", "len", "(", "label_list", ")", "!=", "len", "(", "set", "(", "y_true", "+", "y_pred", ")", ")", ":", "\n", "# replace index into label.", "\n", "        ", "y_true", "=", "list", "(", "map", "(", "lambda", "x", ":", "label_list", "[", "x", "]", ",", "y_true", ")", ")", "\n", "y_pred", "=", "list", "(", "map", "(", "lambda", "x", ":", "label_list", "[", "x", "]", ",", "y_pred", ")", ")", "\n", "label_list", "=", "[", "label", "for", "label", "in", "label_list", "if", "label", "in", "set", "(", "y_true", "+", "y_pred", ")", "]", "\n", "# replace label into new index in y_true and y_pred.", "\n", "y_true", "=", "[", "label_list", ".", "index", "(", "value", ")", "for", "value", "in", "y_true", "]", "\n", "y_pred", "=", "[", "label_list", ".", "index", "(", "value", ")", "for", "value", "in", "y_pred", "]", "\n", "\n", "", "df", "=", "classification_report", "(", "y_true", ",", "y_pred", ",", "label_list", ",", "drop_false", "=", "True", ",", "\n", "micro", "=", "True", ",", "macro", "=", "True", ")", "\n", "\n", "row", "=", "df", "[", "df", "[", "'Class'", "]", "==", "'micro_drop_false'", "]", ".", "iloc", "[", "0", "]", "\n", "\n", "\n", "results", "=", "{", "\n", "\"TP\"", ":", "row", ".", "TP", ",", "\n", "\"FP\"", ":", "row", ".", "FP", ",", "\n", "\"FN\"", ":", "row", ".", "FN", ",", "\n", "\"precision\"", ":", "row", ".", "Precision", ",", "\n", "\"recall\"", ":", "row", ".", "Recall", ",", "\n", "\"FB1\"", ":", "row", ".", "F1score", ",", "\n", "\"FB1_macro\"", ":", "df", "[", "df", "[", "'Class'", "]", "==", "'macro_drop_false'", "]", ".", "iloc", "[", "0", "]", ".", "F1score", ",", "\n", "}", "\n", "return", "results", ",", "df", "\n", "", ""]]}