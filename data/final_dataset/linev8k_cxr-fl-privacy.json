{"home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.chexpert_data.CheXpertDataSet.__init__": [[15, 63], ["open", "csv.reader", "next", "range", "image_names.append", "labels.append", "len", "float"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_path", ",", "data_file", ",", "class_idx", ",", "policy", ",", "colour_input", ",", "transform", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        data_path: path to where the data lives.\n        data_file: path to the file containing image paths with corresponding labels.\n        class_idx: Indices of findings/classes to be included.\n        policy: name the policy with regard to the uncertainty labels.\n        transform: optional transform to be applied on a sample.\n        \"\"\"", "\n", "image_names", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "\n", "with", "open", "(", "data_file", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "csvReader", "=", "csv", ".", "reader", "(", "f", ")", "\n", "next", "(", "csvReader", ",", "None", ")", "# skip the header", "\n", "\n", "for", "line", "in", "csvReader", ":", "\n", "                ", "image_name", "=", "line", "[", "0", "]", "\n", "label", "=", "line", "[", "5", ":", "]", "\n", "#keep only labels that should be included", "\n", "label", "=", "[", "label", "[", "i", "]", "for", "i", "in", "class_idx", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "class_idx", ")", ")", ":", "\n", "                    ", "if", "label", "[", "i", "]", ":", "\n", "                        ", "a", "=", "float", "(", "label", "[", "i", "]", ")", "\n", "if", "a", "==", "1", ":", "\n", "                            ", "label", "[", "i", "]", "=", "1", "\n", "", "elif", "a", "==", "-", "1", ":", "\n", "                            ", "if", "policy", "==", "\"ones\"", ":", "\n", "                                ", "label", "[", "i", "]", "=", "1", "\n", "", "elif", "policy", "==", "\"zeros\"", ":", "\n", "                                ", "label", "[", "i", "]", "=", "0", "\n", "", "else", ":", "\n", "                                ", "label", "[", "i", "]", "=", "0", "\n", "", "", "else", ":", "\n", "                            ", "label", "[", "i", "]", "=", "0", "\n", "", "", "else", ":", "\n", "                        ", "label", "[", "i", "]", "=", "0", "\n", "\n", "", "", "image_names", ".", "append", "(", "data_path", "+", "image_name", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "\n", "", "", "self", ".", "image_names", "=", "image_names", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "class_names", "=", "[", "'No Finding'", ",", "'Enlarged Cardiomediastinum'", ",", "'Cardiomegaly'", ",", "'Lung Opacity'", ",", "\n", "'Lung Lesion'", ",", "'Edema'", ",", "'Consolidation'", ",", "'Pneumonia'", ",", "'Atelectasis'", ",", "'Pneumothorax'", ",", "\n", "'Pleural Effusion'", ",", "'Pleural Other'", ",", "'Fracture'", ",", "'Support Devices'", "]", "\n", "self", ".", "colour_input", "=", "colour_input", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.chexpert_data.CheXpertDataSet.__getitem__": [[64, 73], ["PIL.Image.open().convert", "chexpert_data.CheXpertDataSet.transform", "torch.FloatTensor", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'''Take the index of item and return the image and its labels'''", "\n", "\n", "image_name", "=", "self", ".", "image_names", "[", "index", "]", "\n", "image", "=", "Image", ".", "open", "(", "image_name", ")", ".", "convert", "(", "self", ".", "colour_input", ")", "# RGB or L for greyscale", "\n", "label", "=", "self", ".", "labels", "[", "index", "]", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "image", "=", "self", ".", "transform", "(", "image", ")", "\n", "", "return", "image", ",", "torch", ".", "FloatTensor", "(", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.chexpert_data.CheXpertDataSet.__len__": [[74, 76], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "image_names", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.test_model.main": [[34, 238], ["torch.cuda.is_available", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "len", "utils.check_path", "utils.check_path", "torchvision.Compose", "utils.check_path", "range", "utils.check_path", "print", "range", "numpy.nanmean", "print", "aurocMean_global_clients.append", "save_clients.append", "print", "open", "json.load", "test_model.check_gpu_usage", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "random.seed", "print", "list", "list", "numpy.mean", "numpy.mean", "trainer.Client", "print", "utils.check_path", "os.path.exists", "net().cuda", "net", "print", "print", "print", "numpy.array", "open", "csv.writer", "csv.writer.writerow", "csv.writer.writerows", "range", "range", "range", "torchvision.Resize", "torchvision.ToTensor", "torchvision.Normalize", "range", "utils.check_path", "chexpert_data.CheXpertDataSet", "chexpert_data.CheXpertDataSet", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "trainer.Trainer.test", "aurocMean_global_clients.append", "range", "aurocMean_global_clients.append", "print", "zip", "len", "len", "utils.check_path", "net", "utils.check_path"], "function", ["home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.train_FL.check_gpu_usage", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Trainer.test", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path"], ["def", "main", "(", ")", ":", "\n", "    ", "use_gpu", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "#parse config file", "\n", "parser", ".", "add_argument", "(", "'cfg_path'", ",", "type", "=", "str", ",", "help", "=", "'Path to the config file in json format.'", ")", "\n", "#model checkpoint path", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "'-m'", ",", "dest", "=", "'model_path'", ",", "help", "=", "'Path to model.'", ",", "required", "=", "True", ")", "\n", "#output path for storing results", "\n", "parser", ".", "add_argument", "(", "'--output_path'", ",", "'-o'", ",", "help", "=", "'Path to save results.'", ",", "default", "=", "'results/'", ")", "\n", "#output file for storing results", "\n", "parser", ".", "add_argument", "(", "'--output_file'", ",", "'-of'", ",", "help", "=", "'CSV file for saving results.'", ",", "default", "=", "'auc.csv'", ")", "\n", "#set path to chexpert data", "\n", "parser", ".", "add_argument", "(", "'--data'", ",", "'-d'", ",", "dest", "=", "'data_path'", ",", "help", "=", "'Path to data.'", ",", "default", "=", "'./'", ")", "\n", "#specify path to client files for data reading", "\n", "parser", ".", "add_argument", "(", "'--data_files'", ",", "'-df'", ",", "dest", "=", "'data_files'", ",", "help", "=", "'Path to data files.'", ",", "default", "=", "'./'", ")", "\n", "#whether to assert GPU usage (disable for testing without GPU)", "\n", "parser", ".", "add_argument", "(", "'--no_gpu'", ",", "dest", "=", "'no_gpu'", ",", "help", "=", "'Don\\'t verify GPU usage.'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--val'", ",", "dest", "=", "'use_val'", ",", "help", "=", "'Whether to use validation data. Test data is used by default.'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--combine'", ",", "dest", "=", "'combine'", ",", "help", "=", "\"Combine CheXpert and Mendeley data.\"", ",", "action", "=", "'store_true'", ")", "\n", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "with", "open", "(", "args", ".", "cfg_path", ")", "as", "f", ":", "\n", "        ", "cfg", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "not", "args", ".", "no_gpu", ":", "\n", "        ", "check_gpu_usage", "(", "use_gpu", ")", "\n", "", "else", ":", "\n", "        ", "use_gpu", "=", "False", "\n", "\n", "#only use pytorch randomness for direct usage with pytorch", "\n", "#check for pitfalls when using other modules", "\n", "", "random_seed", "=", "cfg", "[", "'random_seed'", "]", "\n", "if", "random_seed", "!=", "None", ":", "\n", "        ", "torch", ".", "manual_seed", "(", "random_seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "random_seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "random_seed", ")", "# if use multi-GPU", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "random", ".", "seed", "(", "random_seed", ")", "\n", "\n", "", "if", "args", ".", "combine", ":", "# adjust this manually if needed", "\n", "        ", "print", "(", "\"Combining CheXpert and Mendeley clients\"", ")", "\n", "chexpert_client_n", "=", "list", "(", "range", "(", "14", ",", "36", ")", ")", "\n", "mendeley_client_n", "=", "list", "(", "range", "(", "0", ",", "14", ")", ")", "\n", "assert", "cfg", "[", "'num_clients'", "]", "==", "len", "(", "chexpert_client_n", ")", "+", "len", "(", "mendeley_client_n", ")", ",", "\"Check client combination\"", "\n", "\n", "\n", "# Parameters from config file, client training", "\n", "", "nnIsTrained", "=", "cfg", "[", "'pre_trained'", "]", "# pre-trained using ImageNet", "\n", "trBatchSize", "=", "cfg", "[", "'batch_size'", "]", "\n", "trMaxEpoch", "=", "cfg", "[", "'max_epochs'", "]", "\n", "\n", "if", "cfg", "[", "'net'", "]", "==", "'DenseNet121'", ":", "\n", "        ", "net", "=", "DenseNet121", "\n", "", "elif", "cfg", "[", "'net'", "]", "==", "'ResNet50'", ":", "\n", "        ", "net", "=", "ResNet50", "\n", "\n", "# Parameters related to image transforms: size of the down-scaled image, cropped image", "\n", "", "imgtransResize", "=", "cfg", "[", "'imgtransResize'", "]", "\n", "# imgtransCrop = cfg['imgtransCrop']", "\n", "policy", "=", "cfg", "[", "'policy'", "]", "\n", "colour_input", "=", "cfg", "[", "'input'", "]", "\n", "augment", "=", "cfg", "[", "'augment'", "]", "\n", "\n", "class_idx", "=", "cfg", "[", "'class_idx'", "]", "#indices of classes used for classification", "\n", "nnClassCount", "=", "len", "(", "class_idx", ")", "# dimension of the output", "\n", "\n", "\n", "#federated learning parameters", "\n", "num_clients", "=", "cfg", "[", "'num_clients'", "]", "\n", "client_dirs", "=", "[", "f\"client{num}/\"", "for", "num", "in", "range", "(", "num_clients", ")", "]", "\n", "fraction", "=", "cfg", "[", "'fraction'", "]", "\n", "com_rounds", "=", "cfg", "[", "'com_rounds'", "]", "\n", "\n", "data_path", "=", "check_path", "(", "args", ".", "data_path", ",", "warn_exists", "=", "False", ",", "require_exists", "=", "True", ")", "\n", "data_files", "=", "check_path", "(", "args", ".", "data_files", ",", "warn_exists", "=", "False", ",", "require_exists", "=", "True", ")", "\n", "\n", "#define mean and std dependent on whether using a pretrained model", "\n", "if", "nnIsTrained", ":", "\n", "        ", "data_mean", "=", "IMAGENET_MEAN", "\n", "data_std", "=", "IMAGENET_STD", "\n", "", "else", ":", "\n", "        ", "data_mean", "=", "CHEXPERT_MEAN", "\n", "data_std", "=", "CHEXPERT_STD", "\n", "", "if", "colour_input", "==", "'L'", ":", "\n", "        ", "data_mean", "=", "np", ".", "mean", "(", "data_mean", ")", "\n", "data_std", "=", "np", ".", "mean", "(", "data_std", ")", "\n", "\n", "# define transforms", "\n", "", "test_transformSequence", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "Resize", "(", "(", "imgtransResize", ",", "imgtransResize", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "data_mean", ",", "data_std", ")", "\n", "]", ")", "\n", "\n", "num_no_val", "=", "0", "\n", "#initialize client instances and their datasets", "\n", "data_files", "=", "check_path", "(", "args", ".", "data_files", ",", "warn_exists", "=", "False", ",", "require_exists", "=", "True", ")", "\n", "clients", "=", "[", "Client", "(", "name", "=", "f'client{n}'", ")", "for", "n", "in", "range", "(", "num_clients", ")", "]", "\n", "for", "i", "in", "range", "(", "num_clients", ")", ":", "\n", "\n", "        ", "cur_client", "=", "clients", "[", "i", "]", "\n", "print", "(", "f\"Initializing {cur_client.name}\"", ")", "\n", "\n", "if", "args", ".", "combine", ":", "\n", "            ", "if", "i", "in", "chexpert_client_n", ":", "\n", "                ", "data_path", "=", "check_path", "(", "args", ".", "data_path", "+", "'ChestXrays/CheXpert/'", ",", "warn_exists", "=", "False", ",", "require_exists", "=", "True", ")", "\n", "", "elif", "i", "in", "mendeley_client_n", ":", "\n", "                ", "data_path", "=", "check_path", "(", "args", ".", "data_path", ",", "warn_exists", "=", "False", ",", "require_exists", "=", "True", ")", "\n", "", "", "else", ":", "\n", "            ", "data_path", "=", "check_path", "(", "args", ".", "data_path", ",", "warn_exists", "=", "False", ",", "require_exists", "=", "True", ")", "\n", "\n", "", "path_to_client", "=", "check_path", "(", "data_files", "+", "client_dirs", "[", "i", "]", ",", "warn_exists", "=", "False", ",", "require_exists", "=", "True", ")", "\n", "\n", "val_file", "=", "path_to_client", "+", "'client_val.csv'", "\n", "test_file", "=", "path_to_client", "+", "'client_test.csv'", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "val_file", ")", ":", "\n", "            ", "cur_client", ".", "val_data", "=", "CheXpertDataSet", "(", "data_path", ",", "val_file", ",", "class_idx", ",", "policy", ",", "colour_input", "=", "colour_input", ",", "transform", "=", "test_transformSequence", ")", "\n", "cur_client", ".", "test_data", "=", "CheXpertDataSet", "(", "data_path", ",", "test_file", ",", "class_idx", ",", "policy", ",", "colour_input", "=", "colour_input", ",", "transform", "=", "test_transformSequence", ")", "\n", "\n", "cur_client", ".", "val_loader", "=", "DataLoader", "(", "dataset", "=", "cur_client", ".", "val_data", ",", "batch_size", "=", "trBatchSize", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "cur_client", ".", "test_loader", "=", "DataLoader", "(", "dataset", "=", "cur_client", ".", "test_data", ",", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "\n", "", "else", ":", "# clients that don't", "\n", "            ", "print", "(", "f\"No validation data for client{i}\"", ")", "\n", "cur_client", ".", "val_loader", "=", "None", "\n", "cur_client", ".", "test_loader", "=", "None", "\n", "num_no_val", "+=", "1", "\n", "\n", "# show images for testing", "\n", "# for batch in clients[0].train_loader:", "\n", "#     transforms.ToPILImage()(batch[0][0]).show()", "\n", "#     print(batch[1][0])", "\n", "#", "\n", "# for batch in clients[0].val_loader:", "\n", "#     transforms.ToPILImage()(batch[0][0]).show()", "\n", "#     print(batch[1][0])", "\n", "\n", "\n", "# create model", "\n", "", "", "if", "use_gpu", ":", "\n", "        ", "model", "=", "net", "(", "nnClassCount", ",", "colour_input", ",", "pre_trained", "=", "False", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "net", "(", "nnClassCount", ",", "colour_input", ",", "pre_trained", "=", "False", ")", "\n", "\n", "# define path to store results in", "\n", "", "output_path", "=", "check_path", "(", "args", ".", "output_path", ",", "warn_exists", "=", "True", ")", "\n", "\n", "# read model checkpoint", "\n", "checkpoint", "=", "args", ".", "model_path", "\n", "\n", "#validate global model on client validation data", "\n", "print", "(", "\"Validating model on each client's data...\"", ")", "\n", "\n", "aurocMean_global_clients", "=", "[", "]", "# list of AUCs of clients", "\n", "aurocMean_individual_clients", "=", "[", "0", "for", "idx", "in", "class_idx", "]", "# collect summed AUCs for each finding", "\n", "\n", "# check if validation or test data should be used", "\n", "if", "args", ".", "use_val", ":", "\n", "        ", "print", "(", "'Using validation data'", ")", "\n", "\n", "", "for", "cl", "in", "clients", ":", "\n", "        ", "if", "args", ".", "use_val", ":", "\n", "            ", "use_dataloader", "=", "cl", ".", "val_loader", "\n", "", "else", ":", "\n", "            ", "use_dataloader", "=", "cl", ".", "test_loader", "\n", "\n", "", "print", "(", "cl", ".", "name", ")", "\n", "if", "use_dataloader", "is", "not", "None", ":", "\n", "# get AUC mean and per class for current client", "\n", "            ", "LABEL", ",", "PRED", ",", "cl_aurocMean", ",", "aurocIndividual", "=", "Trainer", ".", "test", "(", "model", ",", "use_dataloader", ",", "class_idx", ",", "use_gpu", ",", "checkpoint", "=", "checkpoint", ")", "\n", "aurocMean_global_clients", ".", "append", "(", "cl_aurocMean", ")", "\n", "for", "i", "in", "range", "(", "nnClassCount", ")", ":", "\n", "# track sum per class over all clients", "\n", "                ", "aurocMean_individual_clients", "[", "i", "]", "+=", "aurocIndividual", "[", "i", "]", "\n", "# print(LABEL)", "\n", "# print(PRED)", "\n", "", "", "else", ":", "\n", "            ", "aurocMean_global_clients", ".", "append", "(", "np", ".", "nan", ")", "\n", "print", "(", "f\"No data available for {cl.name}\"", ")", "\n", "\n", "# get mean of per class AUCs of all clients", "\n", "", "", "aurocMean_individual_clients", "=", "[", "auc", "/", "(", "num_clients", "-", "num_no_val", ")", "for", "auc", "in", "aurocMean_individual_clients", "]", "\n", "for", "i", "in", "range", "(", "nnClassCount", ")", ":", "\n", "        ", "print", "(", "f'Mean for label {class_idx[i]}: {aurocMean_individual_clients[i]}  '", ")", "\n", "\n", "# overall mean of client AUCs", "\n", "", "auc_global", "=", "np", ".", "nanmean", "(", "np", ".", "array", "(", "aurocMean_global_clients", ")", ")", "\n", "print", "(", "\"AUC Mean of all clients: {:.3f}\"", ".", "format", "(", "auc_global", ")", ")", "\n", "aurocMean_global_clients", ".", "append", "(", "auc_global", ")", "# save global mean", "\n", "save_clients", "=", "[", "cl", ".", "name", "for", "cl", "in", "clients", "]", "\n", "save_clients", ".", "append", "(", "'avg'", ")", "\n", "\n", "# save AUC in CSV", "\n", "print", "(", "f'Saving in {output_path+args.output_file}'", ")", "\n", "all_metrics", "=", "[", "save_clients", ",", "aurocMean_global_clients", "]", "\n", "with", "open", "(", "output_path", "+", "args", ".", "output_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "header", "=", "[", "'client'", ",", "'AUC'", "]", "\n", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "header", ")", "\n", "writer", ".", "writerows", "(", "zip", "(", "*", "all_metrics", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.test_model.check_gpu_usage": [[240, 249], ["print", "torch.cuda.device_count", "len", "torch.cuda.device_count"], "function", ["None"], ["", "", "def", "check_gpu_usage", "(", "use_gpu", ")", ":", "\n", "\n", "    ", "\"\"\"Give feedback to whether GPU is available and if the expected number of GPUs are visible to PyTorch.\n    \"\"\"", "\n", "assert", "use_gpu", "is", "True", ",", "\"GPU not used\"", "\n", "assert", "torch", ".", "cuda", ".", "device_count", "(", ")", "==", "len", "(", "selected_gpus", ")", ",", "\"Wrong number of GPUs available to Pytorch\"", "\n", "print", "(", "f\"{torch.cuda.device_count()} GPUs available\"", ")", "\n", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Trainer.train": [[25, 132], ["torch.nn.BCELoss", "client_k.model.state_dict().copy", "range", "print", "torch.load", "client_k.model.load_state_dict", "client_k.optimizer.load_state_dict", "train_start.append", "trainer.Trainer.epochTrain", "train_end.append", "torch.save", "save_epoch.append", "save_train_loss.append", "save_val_loss.append", "save_val_AUC.append", "numpy.array", "numpy.array", "open", "csv.writer", "csv.writer.writerow", "csv.writer.writerows", "client_k.model.state_dict", "time.time", "time.time", "print", "trainer.Trainer.epochVal", "print", "client_k.model.state_dict().copy", "print", "client_k.model.state_dict().copy", "print", "client_k.optimizer.privacy_engine.get_privacy_spent", "print", "save_epsilon.append", "save_alpha.append", "save_delta.append", "list", "train_time.round", "zip", "client_k.model.state_dict", "client_k.optimizer.state_dict", "filter", "p.grad.data.norm().item", "grad_norm.append", "client_k.model.state_dict", "client_k.model.state_dict", "client_k.model.parameters", "str", "str", "p.grad.data.norm"], "methods", ["home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Trainer.epochTrain", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Trainer.epochVal"], ["    ", "def", "train", "(", "client_k", ",", "cfg", ",", "use_gpu", ",", "out_csv", "=", "'train_log.csv'", ",", "checkpoint", "=", "None", ",", "freeze_mode", "=", "'none'", ")", ":", "\n", "\n", "        ", "\"\"\"Train a local model from a client instance.\n        Args:\n            client_k (Client object): Client instance with client model, data laoders, output path attributes.\n            cfg (dict): Config dictionary containing training parameters.\n            use_gpu (bool): Whether to use available GPUs.\n            out_csv (str): Name of CSV file used for logging. Stored in output path.\n            checkpoint (str): A model checkpoint to load from for continuing training.\n            freeze_mode (str): Information about which layers to freeze during training.\n        Returns nothing.\n        \"\"\"", "\n", "out_csv_path", "=", "client_k", ".", "output_path", "+", "out_csv", "\n", "\n", "loss", "=", "torch", ".", "nn", ".", "BCELoss", "(", ")", "# setting binary cross entropy as loss function", "\n", "\n", "if", "checkpoint", "!=", "None", ":", "# load checkpoint", "\n", "            ", "modelCheckpoint", "=", "torch", ".", "load", "(", "checkpoint", ")", "\n", "client_k", ".", "model", ".", "load_state_dict", "(", "modelCheckpoint", "[", "'state_dict'", "]", ")", "\n", "client_k", ".", "optimizer", ".", "load_state_dict", "(", "modelCheckpoint", "[", "'optimizer'", "]", ")", "\n", "", "params", "=", "client_k", ".", "model", ".", "state_dict", "(", ")", ".", "copy", "(", ")", "\n", "\n", "# logging metrics", "\n", "lossMIN", "=", "100000", "\n", "train_start", "=", "[", "]", "\n", "train_end", "=", "[", "]", "\n", "\n", "save_epoch", "=", "[", "]", "\n", "save_train_loss", "=", "[", "]", "\n", "save_val_loss", "=", "[", "]", "\n", "save_val_AUC", "=", "[", "]", "\n", "save_epsilon", "=", "[", "]", "\n", "save_alpha", "=", "[", "]", "\n", "save_delta", "=", "[", "]", "\n", "\n", "# train model for number of epochs", "\n", "for", "epochID", "in", "range", "(", "0", ",", "cfg", "[", "'max_epochs'", "]", ")", ":", "\n", "            ", "train_start", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "losst", "=", "Trainer", ".", "epochTrain", "(", "client_k", ".", "model", ",", "client_k", ".", "train_loader", ",", "client_k", ".", "optimizer", ",", "loss", ",", "use_gpu", ",", "freeze_mode", "=", "freeze_mode", ")", "\n", "train_end", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "\n", "# model validation", "\n", "if", "client_k", ".", "val_loader", "is", "not", "None", ":", "\n", "                ", "print", "(", "\"Validating model...\"", ")", "\n", "lossv", ",", "aurocMean", "=", "Trainer", ".", "epochVal", "(", "client_k", ".", "model", ",", "client_k", ".", "val_loader", ",", "loss", ",", "use_gpu", ")", "\n", "print", "(", "\"Training loss: {:.3f},\"", ".", "format", "(", "losst", ")", ",", "\"Valid loss: {:.3f}\"", ".", "format", "(", "lossv", ")", ")", "\n", "", "else", ":", "\n", "# if the client doesn't have validation data, add nan placeholders to metrics", "\n", "                ", "lossv", ",", "aurocMean", "=", "(", "np", ".", "nan", ",", "np", ".", "nan", ")", "\n", "# store model parameters regardless of validation", "\n", "params", "=", "client_k", ".", "model", ".", "state_dict", "(", ")", ".", "copy", "(", ")", "\n", "\n", "# save model to intermediate checkpoint file", "\n", "", "model_num", "=", "epochID", "+", "1", "\n", "torch", ".", "save", "(", "{", "'epoch'", ":", "model_num", ",", "'state_dict'", ":", "client_k", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "'loss'", ":", "lossMIN", ",", "'optimizer'", ":", "client_k", ".", "optimizer", ".", "state_dict", "(", ")", "}", ",", "\n", "f\"{client_k.output_path}{model_num}-epoch_FL.pth.tar\"", ")", "\n", "\n", "# keep parameters of best model", "\n", "if", "lossv", "<", "lossMIN", ":", "\n", "                ", "lossMIN", "=", "lossv", "\n", "print", "(", "'Epoch '", "+", "str", "(", "model_num", ")", "+", "' [++++] val loss decreased'", ")", "\n", "params", "=", "client_k", ".", "model", ".", "state_dict", "(", ")", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Epoch '", "+", "str", "(", "model_num", ")", "+", "' [----] val loss did not decrease or no val data available'", ")", "\n", "\n", "# track metrics", "\n", "", "save_epoch", ".", "append", "(", "model_num", ")", "\n", "save_train_loss", ".", "append", "(", "losst", ")", "\n", "save_val_loss", ".", "append", "(", "lossv", ")", "\n", "save_val_AUC", ".", "append", "(", "aurocMean", ")", "\n", "\n", "if", "cfg", "[", "'private'", "]", ":", "\n", "                ", "epsilon", ",", "best_alpha", "=", "client_k", ".", "optimizer", ".", "privacy_engine", ".", "get_privacy_spent", "(", ")", "\n", "print", "(", "f\"epsilon: {epsilon:.2f}, best alpha: {best_alpha}\"", ")", "\n", "save_epsilon", ".", "append", "(", "epsilon", ")", "\n", "save_alpha", ".", "append", "(", "best_alpha", ")", "\n", "save_delta", ".", "append", "(", "client_k", ".", "delta", ")", "\n", "\n", "", "if", "cfg", "[", "'track_norm'", "]", ":", "\n", "# follow L2 grad norm per parameter layer", "\n", "                ", "grad_norm", "=", "[", "]", "\n", "for", "p", "in", "list", "(", "filter", "(", "lambda", "p", ":", "p", ".", "grad", "is", "not", "None", ",", "client_k", ".", "model", ".", "parameters", "(", ")", ")", ")", ":", "\n", "                    ", "cur_norm", "=", "p", ".", "grad", ".", "data", ".", "norm", "(", "2", ")", ".", "item", "(", ")", "\n", "grad_norm", ".", "append", "(", "cur_norm", ")", "\n", "\n", "", "", "", "train_time", "=", "np", ".", "array", "(", "train_end", ")", "-", "np", ".", "array", "(", "train_start", ")", "\n", "print", "(", "\"Training time for each epoch: {} seconds\"", ".", "format", "(", "train_time", ".", "round", "(", "0", ")", ")", ")", "\n", "\n", "# save logging metrics in CSV", "\n", "all_metrics", "=", "[", "save_epoch", ",", "train_time", ",", "save_train_loss", ",", "save_val_loss", ",", "save_val_AUC", "]", "\n", "if", "cfg", "[", "'track_norm'", "]", ":", "\n", "            ", "all_metrics", "+=", "[", "[", "grad_norm", "]", "]", "\n", "", "if", "cfg", "[", "'private'", "]", ":", "\n", "            ", "all_metrics", "+=", "[", "save_epsilon", ",", "save_alpha", ",", "save_delta", "]", "\n", "\n", "", "with", "open", "(", "out_csv_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "header", "=", "[", "'epoch'", ",", "'time'", ",", "'train loss'", ",", "'val loss'", ",", "'val AUC'", "]", "\n", "if", "cfg", "[", "'track_norm'", "]", ":", "\n", "                ", "header", "+=", "[", "'track_norm'", "]", "\n", "", "if", "cfg", "[", "'private'", "]", ":", "\n", "                ", "header", "+=", "[", "'epsilon'", ",", "'best_alpha'", ",", "'delta'", "]", "\n", "", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "header", ")", "\n", "writer", ".", "writerows", "(", "zip", "(", "*", "all_metrics", ")", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Trainer.epochTrain": [[133, 177], ["model.train", "trainer.freeze_batchnorm", "trainer.freeze_all_but_last", "trainer.freeze_middle", "tqdm.tqdm.tqdm", "len", "model", "loss", "optimizer.zero_grad", "loss.backward", "optimizer.step", "loss.item", "tqdm_loader.set_postfix", "target.cuda.cuda.cuda", "varInput.cuda.cuda.cuda", "loss.item"], "methods", ["home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Trainer.train", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.freeze_batchnorm", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.freeze_all_but_last", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.freeze_middle"], ["", "def", "epochTrain", "(", "model", ",", "dataLoaderTrain", ",", "optimizer", ",", "loss", ",", "use_gpu", ",", "freeze_mode", "=", "'none'", ")", ":", "\n", "\n", "        ", "\"\"\"Train a model for one epoch.\n        Args:\n            model (model object): Model to train.\n            dataLoaderTrain (dataloader object): PyTorch ataloader with training data.\n            optimizer (optimizer object): Optimizer instance.\n            loss (function object): Loss function.\n            use_gpu (bool): Whether to train on GPU.\n            freeze_mode (str): Information about which layers to freeze.\n        Returns:\n            (float) Mean training loss over batches.\"\"\"", "\n", "\n", "losstrain", "=", "0", "\n", "model", ".", "train", "(", ")", "\n", "\n", "if", "freeze_mode", "==", "'batch_norm'", ":", "\n", "            ", "freeze_batchnorm", "(", "model", ")", "\n", "", "if", "freeze_mode", "==", "'all_but_last'", ":", "\n", "            ", "freeze_all_but_last", "(", "model", ")", "\n", "", "if", "freeze_mode", "==", "'middle'", ":", "\n", "            ", "freeze_middle", "(", "model", ")", "\n", "\n", "# usual training procedure", "\n", "", "with", "tqdm", "(", "dataLoaderTrain", ",", "unit", "=", "'batch'", ")", "as", "tqdm_loader", ":", "\n", "\n", "            ", "for", "varInput", ",", "target", "in", "tqdm_loader", ":", "\n", "\n", "                ", "if", "use_gpu", ":", "\n", "                    ", "target", "=", "target", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "varInput", "=", "varInput", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "\n", "", "varOutput", "=", "model", "(", "varInput", ")", "#forward pass", "\n", "lossvalue", "=", "loss", "(", "varOutput", ",", "target", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "#reset gradient", "\n", "lossvalue", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "losstrain", "+=", "lossvalue", ".", "item", "(", ")", "\n", "\n", "tqdm_loader", ".", "set_postfix", "(", "loss", "=", "lossvalue", ".", "item", "(", ")", ")", "\n", "\n", "", "", "return", "losstrain", "/", "len", "(", "dataLoaderTrain", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Trainer.epochVal": [[179, 222], ["model.eval", "trainer.Trainer.computeAUROC", "numpy.nanmean", "print", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor", "torch.FloatTensor", "torch.no_grad", "numpy.array", "model", "loss().item", "torch.cat", "torch.cat", "len", "torch.FloatTensor", "torch.FloatTensor", "target.cuda.cuda.cuda", "varInput.cuda.cuda.cuda", "loss"], "methods", ["home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Trainer.computeAUROC"], ["", "def", "epochVal", "(", "model", ",", "dataLoaderVal", ",", "loss", ",", "use_gpu", ")", ":", "\n", "\n", "        ", "\"\"\"Validate a model.\n        Args:\n            model (model object): Model to validate.\n            dataLoaderVal (dataloader object): PyTorch ataloader with validation data.\n            loss (function object): Loss function.\n            use_gpu (bool): Whether to train on GPU.\n        Returns:\n            (float): Mean validation loss over batches.\n            (float): Mean AUROC over all labels.\"\"\"", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "lossVal", "=", "0", "\n", "\n", "if", "use_gpu", ":", "\n", "            ", "outGT", "=", "torch", ".", "FloatTensor", "(", ")", ".", "cuda", "(", ")", "\n", "outPRED", "=", "torch", ".", "FloatTensor", "(", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "outGT", "=", "torch", ".", "FloatTensor", "(", ")", "\n", "outPRED", "=", "torch", ".", "FloatTensor", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "varInput", ",", "target", "in", "dataLoaderVal", ":", "\n", "\n", "                ", "if", "use_gpu", ":", "\n", "                    ", "target", "=", "target", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "varInput", "=", "varInput", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "\n", "", "varOutput", "=", "model", "(", "varInput", ")", "\n", "\n", "lossVal", "+=", "loss", "(", "varOutput", ",", "target", ")", ".", "item", "(", ")", "\n", "\n", "# collect predictions and ground truth for AUROC computation", "\n", "outGT", "=", "torch", ".", "cat", "(", "(", "outGT", ",", "target", ")", ",", "0", ")", "\n", "outPRED", "=", "torch", ".", "cat", "(", "(", "outPRED", ",", "varOutput", ")", ",", "0", ")", "\n", "\n", "# compute AUROC mean", "\n", "", "", "aurocIndividual", "=", "Trainer", ".", "computeAUROC", "(", "outGT", ",", "outPRED", ")", "\n", "aurocMean", "=", "np", ".", "nanmean", "(", "np", ".", "array", "(", "aurocIndividual", ")", ")", "\n", "print", "(", "'AUROC mean: {:.4f}'", ".", "format", "(", "aurocMean", ")", ")", "\n", "\n", "return", "lossVal", "/", "len", "(", "dataLoaderVal", ")", ",", "aurocMean", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Trainer.computeAUROC": [[224, 248], ["dataGT.cpu().numpy", "dataPRED.cpu().numpy", "range", "dataGT.cpu", "dataPRED.cpu", "outAUROC.append", "sklearn.metrics.roc_auc_score", "print", "outAUROC.append"], "methods", ["None"], ["", "def", "computeAUROC", "(", "dataGT", ",", "dataPRED", ")", ":", "\n", "\n", "        ", "\"\"\"Compute Area under Receiver Operating Characteristic curve.\n        Args:\n            dataGT (tensor): Ground truth labels.\n            dataPRED (tensor): Predicted labels.\n        Returns:\n            (list): AUROC for each label.\"\"\"", "\n", "\n", "outAUROC", "=", "[", "]", "\n", "datanpGT", "=", "dataGT", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "datanpPRED", "=", "dataPRED", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "nnClassCount", "=", "dataGT", ".", "shape", "[", "1", "]", "# [0] is the batch size", "\n", "\n", "for", "i", "in", "range", "(", "nnClassCount", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "outAUROC", ".", "append", "(", "roc_auc_score", "(", "datanpGT", "[", ":", ",", "i", "]", ",", "datanpPRED", "[", ":", ",", "i", "]", ")", ")", "\n", "# AUROC is not defined for a single data point", "\n", "# or there are labels which are negative in all data points", "\n", "", "except", "ValueError", ":", "\n", "                ", "print", "(", "f\"AUROC not defined for label {i}\"", ")", "\n", "outAUROC", ".", "append", "(", "np", ".", "nan", ")", "\n", "\n", "", "", "return", "outAUROC", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Trainer.test": [[250, 302], ["model.eval", "len", "trainer.Trainer.computeAUROC", "numpy.nanmean", "print", "range", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor", "torch.FloatTensor", "torch.load", "torch.no_grad", "enumerate", "numpy.array", "len", "print", "model.load_state_dict", "model.load_state_dict", "torch.cat", "model", "torch.cat", "torch.FloatTensor", "torch.FloatTensor", "target.cuda.cuda.cuda", "varInput.cuda.cuda.cuda"], "methods", ["home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Trainer.computeAUROC"], ["", "def", "test", "(", "model", ",", "dataLoaderTest", ",", "class_idx", ",", "use_gpu", ",", "checkpoint", "=", "None", ")", ":", "\n", "\n", "        ", "\"\"\"Stand-alone function for testing a model.\n        Args:\n            model (model object): Model to validate.\n            dataLoaderTest (dataloader object): PyTorch ataloader with test data.\n            class_idx (list): List of label indices with which the model has been trained.\n            use_gpu (bool): Whether to train on GPU.\n            checkpoint (str): A model checkpoint to load parameters from.\n        Returns:\n            (tensor): Ground truth labels.\n            (tensor): Predicted labels.\n            (float) Mean AUROC over all labels.\n            (list): Individual AUROC for each label.\"\"\"", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "nnClassCount", "=", "len", "(", "class_idx", ")", "\n", "class_names", "=", "dataLoaderTest", ".", "dataset", ".", "class_names", "\n", "\n", "if", "use_gpu", ":", "\n", "            ", "outGT", "=", "torch", ".", "FloatTensor", "(", ")", ".", "cuda", "(", ")", "\n", "outPRED", "=", "torch", ".", "FloatTensor", "(", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "outGT", "=", "torch", ".", "FloatTensor", "(", ")", "\n", "outPRED", "=", "torch", ".", "FloatTensor", "(", ")", "\n", "\n", "", "if", "checkpoint", "!=", "None", ":", "\n", "            ", "modelCheckpoint", "=", "torch", ".", "load", "(", "checkpoint", ")", "\n", "if", "'state_dict'", "in", "modelCheckpoint", ":", "\n", "                ", "model", ".", "load_state_dict", "(", "modelCheckpoint", "[", "'state_dict'", "]", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "load_state_dict", "(", "modelCheckpoint", ")", "\n", "\n", "", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", ",", "(", "varInput", ",", "target", ")", "in", "enumerate", "(", "dataLoaderTest", ")", ":", "\n", "\n", "                ", "if", "use_gpu", ":", "\n", "                    ", "target", "=", "target", ".", "cuda", "(", ")", "\n", "varInput", "=", "varInput", ".", "cuda", "(", ")", "\n", "", "outGT", "=", "torch", ".", "cat", "(", "(", "outGT", ",", "target", ")", ",", "0", ")", "\n", "\n", "out", "=", "model", "(", "varInput", ")", "\n", "outPRED", "=", "torch", ".", "cat", "(", "(", "outPRED", ",", "out", ")", ",", "0", ")", "\n", "\n", "", "", "aurocIndividual", "=", "Trainer", ".", "computeAUROC", "(", "outGT", ",", "outPRED", ")", "\n", "aurocMean", "=", "np", ".", "nanmean", "(", "np", ".", "array", "(", "aurocIndividual", ")", ")", "\n", "print", "(", "'AUROC mean: {:.4f}  '", ".", "format", "(", "aurocMean", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "aurocIndividual", ")", ")", ":", "\n", "            ", "print", "(", "class_names", "[", "class_idx", "[", "i", "]", "]", ",", "': {:.4f}  '", ".", "format", "(", "aurocIndividual", "[", "i", "]", ")", ")", "\n", "\n", "", "return", "outGT", ",", "outPRED", ",", "aurocMean", ",", "aurocIndividual", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.DenseNet121.__init__": [[309, 320], ["torch.nn.Module.__init__", "torchvision.models.densenet121", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Sigmoid", "trainer.DenseNet121.rgb_to_grey_input"], "methods", ["home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Client.__init__", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.ResNet50.rgb_to_grey_input"], ["def", "__init__", "(", "self", ",", "out_size", ",", "colour_input", "=", "'RGB'", ",", "pre_trained", "=", "False", ")", ":", "\n", "        ", "super", "(", "DenseNet121", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "densenet121", "=", "torchvision", ".", "models", ".", "densenet121", "(", "pretrained", "=", "pre_trained", ")", "\n", "num_ftrs", "=", "self", ".", "densenet121", ".", "classifier", ".", "in_features", "\n", "self", ".", "densenet121", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "num_ftrs", ",", "out_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n", "\n", "if", "colour_input", "==", "'L'", ":", "\n", "            ", "self", ".", "rgb_to_grey_input", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.DenseNet121.forward": [[321, 324], ["trainer.DenseNet121.densenet121"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "densenet121", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.DenseNet121.rgb_to_grey_input": [[325, 335], ["trainer.DenseNet121.densenet121.features.conv0.weight.clone", "torch.nn.Conv2d", "torch.no_grad", "torch.nn.Parameter", "trainer.DenseNet121.sum"], "methods", ["None"], ["", "def", "rgb_to_grey_input", "(", "self", ")", ":", "\n", "\n", "        ", "\"\"\"Replace the first convolutional layer that takes a 3-dimensional (RGB) input\n        with a 1-dimensional layer, adding the weights of each existing dimension\n        in order to retain pretrained parameters\"\"\"", "\n", "\n", "conv0_weight", "=", "self", ".", "densenet121", ".", "features", ".", "conv0", ".", "weight", ".", "clone", "(", ")", "\n", "self", ".", "densenet121", ".", "features", ".", "conv0", "=", "nn", ".", "Conv2d", "(", "1", ",", "64", ",", "kernel_size", "=", "(", "7", ",", "7", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "(", "3", ",", "3", ")", ",", "bias", "=", "False", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "densenet121", ".", "features", ".", "conv0", ".", "weight", "=", "nn", ".", "Parameter", "(", "conv0_weight", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "# way to keep pretrained weights", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.DenseNet121.get_n_params": [[336, 343], ["sum", "sum", "p.numel", "p.numel", "trainer.DenseNet121.parameters", "trainer.DenseNet121.parameters"], "methods", ["None"], ["", "", "def", "get_n_params", "(", "self", ",", "trainable", "=", "True", ")", ":", "\n", "        ", "\"\"\"Return number of (trainable) parameters.\"\"\"", "\n", "\n", "if", "trainable", ":", "\n", "            ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "", "else", ":", "\n", "            ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "parameters", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.ResNet50.__init__": [[351, 362], ["torch.nn.Module.__init__", "torchvision.models.resnet50", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Sigmoid", "trainer.ResNet50.rgb_to_grey_input"], "methods", ["home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Client.__init__", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.ResNet50.rgb_to_grey_input"], ["def", "__init__", "(", "self", ",", "out_size", ",", "colour_input", "=", "'RGB'", ",", "pre_trained", "=", "False", ")", ":", "\n", "        ", "super", "(", "ResNet50", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "resnet50", "=", "torchvision", ".", "models", ".", "resnet50", "(", "pretrained", "=", "pre_trained", ")", "\n", "num_ftrs", "=", "self", ".", "resnet50", ".", "fc", ".", "in_features", "\n", "self", ".", "resnet50", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "num_ftrs", ",", "out_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n", "\n", "if", "colour_input", "==", "'L'", ":", "\n", "            ", "self", ".", "rgb_to_grey_input", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.ResNet50.forward": [[363, 366], ["trainer.ResNet50.resnet50"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "resnet50", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.ResNet50.rgb_to_grey_input": [[367, 377], ["trainer.ResNet50.resnet50.conv1.weight.clone", "torch.nn.Conv2d", "torch.no_grad", "torch.nn.Parameter", "trainer.ResNet50.sum"], "methods", ["None"], ["", "def", "rgb_to_grey_input", "(", "self", ")", ":", "\n", "\n", "        ", "\"\"\"Replace the first convolutional layer that takes a 3-dimensional (RGB) input\n        with a 1-dimensional layer, adding the weights of each existing dimension\n        in order to retain pretrained parameters\"\"\"", "\n", "\n", "conv1_weight", "=", "self", ".", "resnet50", ".", "conv1", ".", "weight", ".", "clone", "(", ")", "\n", "self", ".", "resnet50", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "1", ",", "64", ",", "kernel_size", "=", "(", "7", ",", "7", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "(", "3", ",", "3", ")", ",", "bias", "=", "False", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "resnet50", ".", "conv1", ".", "weight", "=", "nn", ".", "Parameter", "(", "conv1_weight", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "# way to keep pretrained weights", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.ResNet50.get_n_params": [[378, 385], ["sum", "sum", "p.numel", "p.numel", "trainer.ResNet50.parameters", "trainer.ResNet50.parameters"], "methods", ["None"], ["", "", "def", "get_n_params", "(", "self", ",", "trainable", "=", "True", ")", ":", "\n", "        ", "\"\"\"Return number of (trainable) parameters.\"\"\"", "\n", "\n", "if", "trainable", ":", "\n", "            ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "", "else", ":", "\n", "            ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "parameters", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Client.__init__": [[429, 458], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", ")", ":", "\n", "\n", "        ", "\"\"\"Placeholders for attributes.\"\"\"", "\n", "\n", "self", ".", "name", "=", "name", "\n", "\n", "# datasets and loaders", "\n", "# dataloaders track changes in associated datasets", "\n", "# so we need to uniquely associate constant datasets with the client", "\n", "self", ".", "train_data", "=", "None", "\n", "self", ".", "train_loader", "=", "None", "\n", "self", ".", "val_data", "=", "None", "\n", "self", ".", "val_loader", "=", "None", "\n", "self", ".", "test_data", "=", "None", "\n", "self", ".", "test_loader", "=", "None", "\n", "\n", "self", ".", "n_data", "=", "None", "# size of training dataset", "\n", "self", ".", "output_path", "=", "None", "# name of output path for storing results", "\n", "self", ".", "selected_rounds", "=", "0", "# counter for rounds where client was selected", "\n", "\n", "# local model objects", "\n", "self", ".", "model_params", "=", "None", "# state dict of model", "\n", "self", ".", "model", "=", "None", "\n", "self", ".", "optimizer", "=", "None", "\n", "\n", "# individual privacy objects/parameters", "\n", "self", ".", "privacy_engine", "=", "None", "\n", "self", ".", "delta", "=", "None", "\n", "self", ".", "grad_norm", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Client.init_optimizer": [[459, 474], ["print", "torch.optim.Adam", "torch.optim.SGD", "trainer.Client.model.parameters", "trainer.Client.model.parameters", "tuple"], "methods", ["None"], ["", "def", "init_optimizer", "(", "self", ",", "cfg", ")", ":", "\n", "\n", "        ", "\"\"\"Initialize client optimizer and set it as client attribute.\n        Args:\n            cfg (dict): Training config dictionary with optimizer information.\n        Returns nothing.\"\"\"", "\n", "\n", "if", "self", ".", "model", "!=", "None", ":", "\n", "            ", "if", "cfg", "[", "'optim'", "]", "==", "\"Adam\"", ":", "\n", "                ", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "cfg", "[", "'lr'", "]", ",", "# setting optimizer & scheduler", "\n", "betas", "=", "tuple", "(", "cfg", "[", "'betas'", "]", ")", ",", "eps", "=", "cfg", "[", "'eps'", "]", ",", "weight_decay", "=", "cfg", "[", "'weight_decay'", "]", ")", "\n", "", "if", "cfg", "[", "'optim'", "]", "==", "\"SGD\"", ":", "\n", "                ", "self", ".", "optimizer", "=", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "cfg", "[", "'lr'", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "\"self.model is currently None. Optimizer cannot be initialized.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Client.get_data_len": [[475, 485], ["len"], "methods", ["None"], ["", "", "def", "get_data_len", "(", "self", ")", ":", "\n", "\n", "        ", "\"\"\"Return number of data points (int) currently held by client, all splits taken together.\"\"\"", "\n", "\n", "n_data", "=", "0", "\n", "for", "data", "in", "[", "self", ".", "train_data", ",", "self", ".", "val_data", ",", "self", ".", "test_data", "]", ":", "\n", "            ", "if", "data", "!=", "None", ":", "\n", "                ", "n_data", "+=", "len", "(", "data", ")", "\n", "\n", "", "", "return", "n_data", "\n", "", "", ""]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.freeze_batchnorm": [[386, 399], ["model.modules", "isinstance", "hasattr", "hasattr", "module.eval", "module.weight.requires_grad_", "module.bias.requires_grad_"], "function", ["None"], ["", "", "", "def", "freeze_batchnorm", "(", "model", ")", ":", "\n", "\n", "    ", "\"\"\"Modify model to not track gradients of batch norm layers\n    and set them to eval() mode (no running stats updated)\"\"\"", "\n", "\n", "for", "module", "in", "model", ".", "modules", "(", ")", ":", "\n", "# print(module)", "\n", "        ", "if", "isinstance", "(", "module", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "            ", "if", "hasattr", "(", "module", ",", "'weight'", ")", ":", "\n", "                ", "module", ".", "weight", ".", "requires_grad_", "(", "False", ")", "\n", "", "if", "hasattr", "(", "module", ",", "'bias'", ")", ":", "\n", "                ", "module", ".", "bias", ".", "requires_grad_", "(", "False", ")", "\n", "", "module", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.freeze_all_but_last": [[400, 410], ["model.named_parameters", "param.requires_grad_", "param.requires_grad_"], "function", ["None"], ["", "", "", "def", "freeze_all_but_last", "(", "model", ")", ":", "\n", "\n", "    ", "\"\"\"Modify model to not track gradients of all but the last classification layer.\n    Note: This is customized to the module naming of ResNet and DenseNet architectures.\"\"\"", "\n", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'fc'", "not", "in", "name", "and", "'classifier'", "not", "in", "name", ":", "\n", "            ", "param", ".", "requires_grad_", "(", "False", ")", "\n", "", "else", ":", "\n", "            ", "param", ".", "requires_grad_", "(", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.freeze_middle": [[411, 421], ["model.named_parameters", "any", "param.requires_grad_", "param.requires_grad_"], "function", ["None"], ["", "", "", "def", "freeze_middle", "(", "model", ")", ":", "\n", "\n", "    ", "\"\"\"Modify model to not track gradients of all but the first convolutional and last classification layer.\n    Note: This is customized to the module naming of ResNet and DenseNet architectures above.\"\"\"", "\n", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "not", "any", "(", "part", "in", "name", "for", "part", "in", "[", "'fc'", ",", "'classifier'", ",", "'resnet50.conv1.weight'", ",", "'densenet121.features.conv0.weight'", "]", ")", ":", "\n", "            ", "param", ".", "requires_grad_", "(", "False", ")", "\n", "", "else", ":", "\n", "            ", "param", ".", "requires_grad_", "(", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.split_chexpert.main": [[24, 75], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "utils.check_path", "pandas.read_csv", "split_chexpert.split_df", "range", "print", "len", "len", "open", "json.load", "print", "range", "print", "len", "split_data[].to_csv", "print", "len", "[].str.contains", "len"], "function", ["home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.split_chexpert.split_df"], ["def", "main", "(", ")", ":", "\n", "\n", "    ", "assert", "len", "(", "CSV_NAMES", ")", "==", "len", "(", "SPLIT_PERC", ")", ",", "\"Different number of file names provided than was splitted\"", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "'cfg_path'", ",", "type", "=", "str", ",", "help", "=", "'Path to the config file in json format.'", ")", "\n", "#set path to chexpert data", "\n", "parser", ".", "add_argument", "(", "'--chexpert'", ",", "'-d'", ",", "dest", "=", "'chexpert_path'", ",", "help", "=", "'Path to CheXpert data.'", ",", "default", "=", "'./'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "with", "open", "(", "args", ".", "cfg_path", ")", "as", "f", ":", "\n", "        ", "cfg", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "data_path", "=", "check_path", "(", "args", ".", "chexpert_path", ",", "warn_exists", "=", "False", ",", "require_exists", "=", "True", ")", "\n", "random_seed", "=", "cfg", "[", "'random_seed'", "]", "\n", "\n", "# Read from CSV files", "\n", "chex_data", "=", "pd", ".", "read_csv", "(", "data_path", "+", "'CheXpert-v1.0-small/'", "+", "ORIG_CSV", ")", "\n", "split_data", "=", "split_df", "(", "chex_data", ",", "random_seed", "=", "random_seed", ",", "split_perc", "=", "SPLIT_PERC", ")", "\n", "\n", "\n", "# Testdata = Traindata.head(500) # use first 500 training data as test data (obs ratio is almost same!)", "\n", "# Traindata = Traindata[500:2000]", "\n", "# Traindata = Traindata[1:4] #toy example for testing", "\n", "\n", "# Validdata = pd.read_csv(data_path+'CheXpert-v1.0-small/valid.csv')", "\n", "# Validdata = Validdata[1:3] #toy example for testing", "\n", "\n", "# Testdata = Validdata #use validation data for testing in this toy example, just to check the processing", "\n", "\n", "if", "cfg", "[", "'front_lat'", "]", "!=", "'both'", ":", "\n", "#use either only frontal or lateral images", "\n", "        ", "print", "(", "f\"Only using {cfg['front_lat']} images\"", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "split_data", ")", ")", ":", "\n", "            ", "split_data", "[", "i", "]", "=", "split_data", "[", "i", "]", "[", "split_data", "[", "i", "]", "[", "'Path'", "]", ".", "str", ".", "contains", "(", "cfg", "[", "'front_lat'", "]", ")", "]", "# use only frontal or lateral images", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "\"Using both frontal and lateral images\"", ")", "\n", "\n", "#create CSVs", "\n", "", "for", "i", "in", "range", "(", "len", "(", "SPLIT_PERC", ")", ")", ":", "\n", "        ", "split_data", "[", "i", "]", ".", "to_csv", "(", "data_path", "+", "'CheXpert-v1.0-small/'", "+", "CSV_NAMES", "[", "i", "]", ",", "index", "=", "False", ")", "\n", "print", "(", "f\"Split {i}: {len(split_data[i])} images\"", ")", "\n", "\n", "# print(f\"Train data length:\", len(Traindata))", "\n", "# Validdata.to_csv(data_path+'CheXpert-v1.0-small/valid_mod.csv', index = False)", "\n", "# print(f\"Valid data length:\", len(Validdata))", "\n", "# # Testdata = Validdata #for testing", "\n", "# Testdata.to_csv(data_path+'CheXpert-v1.0-small/test_mod.csv', index = False)", "\n", "# print(\"Test data length:\", len(Testdata))", "\n", "\n", "", "print", "(", "\"Modified CSVs saved\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.split_chexpert.unique_patients_list": [[77, 95], ["filenames.str.split", "patient_paths.apply.apply", "list", "list.sort", "random.seed", "random.shuffle", "set"], "function", ["None"], ["", "def", "unique_patients_list", "(", "chex_df", ",", "random_seed", ")", ":", "\n", "\n", "    ", "\"\"\"Return a list of paths leading to unique patients.\n    Takes a pandas dataframe as input, as read from an original CheXpert data CSV file.\n    Set random seed of random module for reproducibility.\"\"\"", "\n", "\n", "#process paths to cut after patient numbers", "\n", "filenames", "=", "chex_df", "[", "'Path'", "]", "\n", "patient_paths", "=", "filenames", ".", "str", ".", "split", "(", "'/'", ")", "\n", "patient_paths", "=", "patient_paths", ".", "apply", "(", "lambda", "x", ":", "'/'", ".", "join", "(", "x", "[", ":", "3", "]", ")", ")", "\n", "\n", "#get unique patients list and shuffle", "\n", "unique_patients", "=", "list", "(", "set", "(", "patient_paths", ")", ")", "\n", "unique_patients", ".", "sort", "(", ")", "# because set inserts unwanted randomness", "\n", "random", ".", "seed", "(", "random_seed", ")", "\n", "random", ".", "shuffle", "(", "unique_patients", ")", "\n", "\n", "return", "unique_patients", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.split_chexpert.split_df": [[96, 131], ["split_chexpert.unique_patients_list", "len", "print", "print", "round", "round", "num_split.append", "patient_splits.append", "sum", "len", "split_dfs.append", "sum", "len", "chex_df[].str.split().apply().isin", "len", "chex_df[].str.split().apply", "chex_df[].str.split"], "function", ["home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.split_chexpert.unique_patients_list"], ["", "def", "split_df", "(", "chex_df", ",", "random_seed", ",", "split_perc", ")", ":", "\n", "\n", "    ", "\"\"\"Take original CheXpert dataframe read from CSV, split it into a number of subsets.\n    split_perc is a list specifying the fraction of each split and should sum to one.\n    Returns a list with corresponding number of dataframes containing all original information.\n    Currently, patients are shuffled with a seed and then chunked into respective splits in the given order.\n    \"\"\"", "\n", "assert", "round", "(", "sum", "(", "split_perc", ")", ",", "3", ")", "==", "1", ",", "\"Split fractions don't sum to one\"", "\n", "\n", "#get list with unique patient paths, shuffled", "\n", "unique_patients", "=", "unique_patients_list", "(", "chex_df", ",", "random_seed", "=", "random_seed", ")", "\n", "num_patients", "=", "len", "(", "unique_patients", ")", "\n", "\n", "num_split", "=", "[", "]", "\n", "patient_splits", "=", "[", "]", "\n", "start", "=", "0", "\n", "end", "=", "0", "\n", "for", "perc", "in", "split_perc", ":", "\n", "#calculate number of samples per patient split", "\n", "        ", "cur_sample_size", "=", "round", "(", "num_patients", "*", "perc", ")", "\n", "num_split", ".", "append", "(", "cur_sample_size", ")", "\n", "end", "+=", "cur_sample_size", "\n", "patient_splits", ".", "append", "(", "unique_patients", "[", "start", ":", "end", "]", ")", "#split patients", "\n", "start", "+=", "cur_sample_size", "\n", "\n", "", "assert", "sum", "(", "[", "len", "(", "split", ")", "for", "split", "in", "patient_splits", "]", ")", "==", "len", "(", "unique_patients", ")", "\n", "print", "(", "f\"Number of patients in splits: {num_split}\"", ")", "\n", "\n", "#create dataframe subsets of original dataframe", "\n", "split_dfs", "=", "[", "]", "\n", "for", "split", "in", "patient_splits", ":", "\n", "        ", "split_dfs", ".", "append", "(", "chex_df", "[", "chex_df", "[", "'Path'", "]", ".", "str", ".", "split", "(", "'/'", ")", ".", "apply", "(", "lambda", "x", ":", "'/'", ".", "join", "(", "x", "[", ":", "3", "]", ")", ")", ".", "isin", "(", "split", ")", "]", ")", "\n", "", "print", "(", "f\"Number of images in splits: {[len(df) for df in split_dfs]}\"", ")", "\n", "\n", "return", "split_dfs", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.train_FL.main": [[36, 397], ["torch.cuda.is_available", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "len", "torchvision.Compose", "utils.check_path", "range", "utils.check_path", "torch.save", "time.time", "range", "print", "time.time", "print", "open", "json.load", "train_FL.check_gpu_usage", "print", "list", "list", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "random.seed", "numpy.mean", "numpy.mean", "torchvision.Compose", "torchvision.Compose", "trainer.Client", "print", "utils.check_path", "chexpert_data.CheXpertDataSet", "len", "print", "torch.utils.data.DataLoader", "os.path.exists", "net().cuda", "net", "torch.load", "print", "copy.deepcopy", "client_k.init_optimizer", "print", "print", "print", "net.load_state_dict", "torch.save", "print", "numpy.nanmean", "print", "global_auc.append", "print", "list", "open", "csv.writer", "csv.writer.writerow", "csv.writer.writerows", "utils.merge_eval_csv", "range", "range", "range", "round", "open", "json.load", "torchvision.Resize", "torchvision.ToTensor", "torchvision.Normalize", "range", "utils.check_path", "torch.Size", "torch.Size", "print", "chexpert_data.CheXpertDataSet", "chexpert_data.CheXpertDataSet", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "net.load_state_dict", "net.load_state_dict", "net.state_dict", "min", "print", "opacus.PrivacyEngine", "client_k.privacy_engine.attach", "random.sample", "len", "print", "utils.check_path", "print", "time.time", "trainer.Trainer.train", "client_k.model.state_dict().copy", "time.time", "round", "print", "net.state_dict", "numpy.array", "range", "zip", "print", "len", "len", "torchvision.Resize", "torchvision.ColorJitter", "torchvision.RandomHorizontalFlip", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Resize", "torchvision.ToTensor", "torchvision.Normalize", "utils.check_path", "net", "round", "torch.no_grad", "zip", "weights.append", "weightn.append", "sum", "sum", "trainer.Trainer.test", "aurocMean_global.append", "aurocMean_global.append", "print", "round", "utils.check_path", "len", "min", "client_pool.remove", "client_k.model.parameters", "net.parameters", "client_params.set_", "client_k.model.state_dict", "print", "copy.deepcopy"], "function", ["home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.train_FL.check_gpu_usage", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Client.init_optimizer", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.merge_eval_csv", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Trainer.train", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.trainer.Trainer.test", "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path"], ["def", "main", "(", ")", ":", "\n", "    ", "use_gpu", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "#parse config file", "\n", "parser", ".", "add_argument", "(", "'cfg_path'", ",", "type", "=", "str", ",", "help", "=", "'Path to the config file in json format.'", ")", "\n", "#parse privacy config file", "\n", "parser", ".", "add_argument", "(", "'--dp_path'", ",", "'-dp'", ",", "dest", "=", "'dp_path'", ",", "type", "=", "str", ",", "help", "=", "'Path to privacy config file in json format.'", ",", "default", "=", "'privacy_config.json'", ")", "\n", "#output path for storing results", "\n", "parser", ".", "add_argument", "(", "'--output_path'", ",", "'-o'", ",", "help", "=", "'Path to save results.'", ",", "default", "=", "'results/'", ")", "\n", "#turn off assertion of GPU usage", "\n", "parser", ".", "add_argument", "(", "'--no_gpu'", ",", "dest", "=", "'no_gpu'", ",", "help", "=", "'Don\\'t verify GPU usage.'", ",", "action", "=", "'store_true'", ")", "\n", "#set path to data (Chexpert and Mendeley)", "\n", "parser", ".", "add_argument", "(", "'--data'", ",", "'-d'", ",", "dest", "=", "'data_path'", ",", "help", "=", "'Path to data.'", ",", "default", "=", "'./'", ")", "\n", "#specify path to client files for data reading", "\n", "parser", ".", "add_argument", "(", "'--data_files'", ",", "'-df'", ",", "dest", "=", "'data_files'", ",", "help", "=", "'Path to data files.'", ",", "default", "=", "'./'", ")", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "'-m'", ",", "dest", "=", "'model'", ",", "help", "=", "'Model to load weights from.'", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--combine'", ",", "dest", "=", "'combine'", ",", "help", "=", "\"Combine CheXpert and Mendeley data.\"", ",", "action", "=", "'store_true'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "with", "open", "(", "args", ".", "cfg_path", ")", "as", "f", ":", "\n", "        ", "cfg", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "not", "args", ".", "no_gpu", ":", "\n", "        ", "check_gpu_usage", "(", "use_gpu", ")", "\n", "", "else", ":", "\n", "        ", "use_gpu", "=", "False", "\n", "\n", "", "if", "args", ".", "combine", ":", "# adjust this manually if needed", "\n", "        ", "print", "(", "\"Combining CheXpert and Mendeley clients\"", ")", "\n", "chexpert_client_n", "=", "list", "(", "range", "(", "14", ",", "36", ")", ")", "\n", "mendeley_client_n", "=", "list", "(", "range", "(", "0", ",", "14", ")", ")", "\n", "assert", "cfg", "[", "'num_clients'", "]", "==", "len", "(", "chexpert_client_n", ")", "+", "len", "(", "mendeley_client_n", ")", ",", "\"Check client combination\"", "\n", "\n", "\n", "#only use pytorch randomness for direct usage with pytorch", "\n", "#check for pitfalls when using other modules", "\n", "", "random_seed", "=", "cfg", "[", "'random_seed'", "]", "\n", "if", "random_seed", "!=", "None", ":", "\n", "        ", "torch", ".", "manual_seed", "(", "random_seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "random_seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "random_seed", ")", "# if use multi-GPU", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "random", ".", "seed", "(", "random_seed", ")", "\n", "\n", "\n", "# Parameters from config file, client training", "\n", "", "nnIsTrained", "=", "cfg", "[", "'pre_trained'", "]", "# pre-trained using ImageNet", "\n", "freeze_mode", "=", "cfg", "[", "'freeze_mode'", "]", "# what layers to freeze: 'none', 'batch_norm', 'all_but_last', 'middle'", "\n", "freeze_dict", "=", "{", "'batch_norm'", ":", "freeze_batchnorm", ",", "'all_but_last'", ":", "freeze_all_but_last", ",", "'middle'", ":", "freeze_middle", "}", "\n", "trBatchSize", "=", "cfg", "[", "'batch_size'", "]", "\n", "trMaxEpoch", "=", "cfg", "[", "'max_epochs'", "]", "\n", "\n", "if", "cfg", "[", "'net'", "]", "==", "'DenseNet121'", ":", "\n", "        ", "net", "=", "DenseNet121", "\n", "", "elif", "cfg", "[", "'net'", "]", "==", "'ResNet50'", ":", "\n", "        ", "net", "=", "ResNet50", "\n", "", "model_checkpoint", "=", "args", ".", "model", "\n", "\n", "# Parameters related to image transforms: size of the down-scaled image, cropped image", "\n", "imgtransResize", "=", "cfg", "[", "'imgtransResize'", "]", "\n", "# imgtransCrop = cfg['imgtransCrop']", "\n", "policy", "=", "cfg", "[", "'policy'", "]", "\n", "colour_input", "=", "cfg", "[", "'input'", "]", "\n", "augment", "=", "cfg", "[", "'augment'", "]", "\n", "\n", "class_idx", "=", "cfg", "[", "'class_idx'", "]", "#indices of classes used for classification", "\n", "nnClassCount", "=", "len", "(", "class_idx", ")", "# dimension of the output", "\n", "\n", "\n", "#federated learning parameters", "\n", "num_clients", "=", "cfg", "[", "'num_clients'", "]", "\n", "client_dirs", "=", "[", "f\"client{num}/\"", "for", "num", "in", "range", "(", "num_clients", ")", "]", "\n", "# assert num_clients == len(client_dirs), \"Number of clients doesn't correspond to number of directories specified\"", "\n", "fraction", "=", "cfg", "[", "'fraction'", "]", "\n", "sel_max_rounds", "=", "cfg", "[", "'sel_max_rounds'", "]", "\n", "com_rounds", "=", "cfg", "[", "'com_rounds'", "]", "\n", "assert", "num_clients", "*", "sel_max_rounds", ">=", "round", "(", "num_clients", "*", "fraction", ")", "*", "com_rounds", ",", "\"Client fraction or maximum rounds for client selection is not large enough.\"", "\n", "earl_stop_rounds", "=", "cfg", "[", "'earl_stop_rounds'", "]", "\n", "reduce_lr_rounds", "=", "cfg", "[", "'reduce_lr_rounds'", "]", "\n", "\n", "private", "=", "cfg", "[", "'private'", "]", "\n", "if", "private", ":", "\n", "        ", "assert", "freeze_mode", "==", "'batch_norm'", "or", "freeze_mode", "==", "'all_but_last'", ",", "\"Batch norm layers must be frozen for private training.\"", "\n", "with", "open", "(", "args", ".", "dp_path", ")", "as", "f", ":", "\n", "            ", "privacy_cfg", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "#define mean and std dependent on whether using a pretrained model", "\n", "", "", "if", "nnIsTrained", ":", "\n", "        ", "data_mean", "=", "IMAGENET_MEAN", "\n", "data_std", "=", "IMAGENET_STD", "\n", "", "else", ":", "\n", "        ", "data_mean", "=", "CHEXPERT_MEAN", "\n", "data_std", "=", "CHEXPERT_STD", "\n", "", "if", "colour_input", "==", "'L'", ":", "\n", "        ", "data_mean", "=", "np", ".", "mean", "(", "data_mean", ")", "\n", "data_std", "=", "np", ".", "mean", "(", "data_std", ")", "\n", "\n", "# define transforms", "\n", "# if using augmentation, use different transforms for training, test & val data", "\n", "", "if", "augment", ":", "\n", "        ", "train_transformSequence", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "Resize", "(", "(", "imgtransResize", ",", "imgtransResize", ")", ")", ",", "\n", "# transforms.RandomResizedCrop(imgtransResize),", "\n", "transforms", ".", "ColorJitter", "(", "brightness", "=", "0.5", ",", "contrast", "=", "0.5", ",", "saturation", "=", "0.5", ",", "hue", "=", "0.5", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "data_mean", ",", "data_std", ")", "\n", "]", ")", "\n", "", "else", ":", "\n", "#no augmentation for comparison with DP", "\n", "        ", "train_transformSequence", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "Resize", "(", "(", "imgtransResize", ",", "imgtransResize", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "data_mean", ",", "data_std", ")", "\n", "]", ")", "\n", "\n", "", "test_transformSequence", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "Resize", "(", "(", "imgtransResize", ",", "imgtransResize", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "data_mean", ",", "data_std", ")", "\n", "]", ")", "\n", "\n", "#initialize client instances and their datasets", "\n", "data_files", "=", "check_path", "(", "args", ".", "data_files", ",", "warn_exists", "=", "False", ",", "require_exists", "=", "True", ")", "\n", "clients", "=", "[", "Client", "(", "name", "=", "f'client{n}'", ")", "for", "n", "in", "range", "(", "num_clients", ")", "]", "\n", "for", "i", "in", "range", "(", "num_clients", ")", ":", "\n", "\n", "        ", "cur_client", "=", "clients", "[", "i", "]", "\n", "print", "(", "f\"Initializing {cur_client.name}\"", ")", "\n", "\n", "if", "args", ".", "combine", ":", "\n", "            ", "if", "i", "in", "chexpert_client_n", ":", "\n", "                ", "data_path", "=", "check_path", "(", "args", ".", "data_path", "+", "'ChestXrays/CheXpert/'", ",", "warn_exists", "=", "False", ",", "require_exists", "=", "True", ")", "\n", "", "elif", "i", "in", "mendeley_client_n", ":", "\n", "                ", "data_path", "=", "check_path", "(", "args", ".", "data_path", ",", "warn_exists", "=", "False", ",", "require_exists", "=", "True", ")", "\n", "", "", "else", ":", "\n", "            ", "data_path", "=", "check_path", "(", "args", ".", "data_path", ",", "warn_exists", "=", "False", ",", "require_exists", "=", "True", ")", "\n", "\n", "", "path_to_client", "=", "check_path", "(", "data_files", "+", "client_dirs", "[", "i", "]", ",", "warn_exists", "=", "False", ",", "require_exists", "=", "True", ")", "\n", "\n", "train_file", "=", "path_to_client", "+", "'client_train.csv'", "\n", "cur_client", ".", "train_data", "=", "CheXpertDataSet", "(", "data_path", ",", "train_file", ",", "class_idx", ",", "policy", ",", "colour_input", "=", "colour_input", ",", "transform", "=", "train_transformSequence", ")", "\n", "\n", "assert", "cur_client", ".", "train_data", "[", "0", "]", "[", "0", "]", ".", "shape", "==", "torch", ".", "Size", "(", "[", "len", "(", "colour_input", ")", ",", "imgtransResize", ",", "imgtransResize", "]", ")", "\n", "assert", "cur_client", ".", "train_data", "[", "0", "]", "[", "1", "]", ".", "shape", "==", "torch", ".", "Size", "(", "[", "nnClassCount", "]", ")", "\n", "\n", "cur_client", ".", "n_data", "=", "len", "(", "cur_client", ".", "train_data", ")", "\n", "print", "(", "f\"Holds {cur_client.n_data} data points\"", ")", "\n", "\n", "# drop last incomplete batch if dataset has at least one full batch, otherwise keep one incomplete batch", "\n", "if", "cur_client", ".", "n_data", ">", "trBatchSize", ":", "\n", "            ", "drop_last", "=", "True", "\n", "print", "(", "f\"Dropping incomplete batch of {cur_client.n_data%trBatchSize} data points\"", ")", "\n", "cur_client", ".", "n_data", "=", "cur_client", ".", "n_data", "-", "cur_client", ".", "n_data", "%", "trBatchSize", "\n", "", "else", ":", "\n", "            ", "drop_last", "=", "False", "\n", "\n", "", "cur_client", ".", "train_loader", "=", "DataLoader", "(", "dataset", "=", "cur_client", ".", "train_data", ",", "batch_size", "=", "trBatchSize", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ",", "drop_last", "=", "drop_last", ")", "\n", "\n", "val_file", "=", "path_to_client", "+", "'client_val.csv'", "\n", "test_file", "=", "path_to_client", "+", "'client_test.csv'", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "val_file", ")", ":", "\n", "            ", "cur_client", ".", "val_data", "=", "CheXpertDataSet", "(", "data_path", ",", "val_file", ",", "class_idx", ",", "policy", ",", "colour_input", "=", "colour_input", ",", "transform", "=", "test_transformSequence", ")", "\n", "cur_client", ".", "test_data", "=", "CheXpertDataSet", "(", "data_path", ",", "test_file", ",", "class_idx", ",", "policy", ",", "colour_input", "=", "colour_input", ",", "transform", "=", "test_transformSequence", ")", "\n", "\n", "cur_client", ".", "val_loader", "=", "DataLoader", "(", "dataset", "=", "cur_client", ".", "val_data", ",", "batch_size", "=", "trBatchSize", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "cur_client", ".", "test_loader", "=", "DataLoader", "(", "dataset", "=", "cur_client", ".", "test_data", ",", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "\n", "", "else", ":", "# clients that don't", "\n", "            ", "print", "(", "f\"No validation data for client{i}\"", ")", "\n", "cur_client", ".", "val_loader", "=", "None", "\n", "cur_client", ".", "test_loader", "=", "None", "\n", "\n", "# show images for testing", "\n", "# for batch in clients[0].train_loader:", "\n", "#     transforms.ToPILImage()(batch[0][0]).show()", "\n", "#     print(batch[1][0])", "\n", "#", "\n", "#  for batch in clients[1].val_loader:", "\n", "#     transforms.ToPILImage()(batch[0][0]).show()", "\n", "#     print(batch[1][0])", "\n", "\n", "# get labels and indices of data from dataloaders", "\n", "# modify chexpert_data dataloader to also return indices for this", "\n", "# for i in [12,13,14,15,16,17,18,19]:", "\n", "#     print(\"Client \", i)", "\n", "#     for batch in clients[i].train_loader:", "\n", "#         print(\"Labels: \", batch[1])", "\n", "#         print(\"Inidces: \", batch[2])", "\n", "\n", "\n", "#create global model", "\n", "", "", "if", "use_gpu", ":", "\n", "        ", "global_model", "=", "net", "(", "nnClassCount", ",", "colour_input", ",", "nnIsTrained", ")", ".", "cuda", "(", ")", "\n", "# model=torch.nn.DataParallel(model).cuda()", "\n", "", "else", ":", "\n", "        ", "global_model", "=", "net", "(", "nnClassCount", ",", "colour_input", ",", "nnIsTrained", ")", "\n", "\n", "", "if", "model_checkpoint", "is", "not", "None", ":", "# load weights if some model is specified", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "model_checkpoint", ")", "\n", "if", "'state_dict'", "in", "checkpoint", ":", "\n", "            ", "global_model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "", "else", ":", "\n", "            ", "global_model", ".", "load_state_dict", "(", "checkpoint", ")", "\n", "\n", "# freeze batch norm layers already so it passes the privacy engine checks", "\n", "", "", "if", "freeze_mode", "!=", "'none'", ":", "\n", "         ", "freeze_dict", "[", "freeze_mode", "]", "(", "global_model", ")", "\n", "\n", "#define path to store results in", "\n", "", "output_path", "=", "check_path", "(", "args", ".", "output_path", ",", "warn_exists", "=", "True", ")", "\n", "\n", "# save initial global model parameters", "\n", "torch", ".", "save", "(", "{", "'state_dict'", ":", "global_model", ".", "state_dict", "(", ")", "}", ",", "output_path", "+", "'global_init.pth.tar'", ")", "\n", "\n", "# initialize client models and optimizers", "\n", "for", "client_k", "in", "clients", ":", "\n", "        ", "print", "(", "f\"Initializing model and optimizer of {client_k.name}\"", ")", "\n", "client_k", ".", "model", "=", "copy", ".", "deepcopy", "(", "global_model", ")", "\n", "client_k", ".", "init_optimizer", "(", "cfg", ")", "\n", "\n", "if", "private", ":", "\n", "# compute personal delta dependent on client's dataset size, or choose min delta value allowed", "\n", "            ", "client_k", ".", "delta", "=", "min", "(", "privacy_cfg", "[", "'min_delta'", "]", ",", "1", "/", "client_k", ".", "n_data", "*", "0.9", ")", "\n", "print", "(", "f'Client delta: {client_k.delta}'", ")", "\n", "# attach DP privacy engine for private training", "\n", "client_k", ".", "privacy_engine", "=", "opacus", ".", "PrivacyEngine", "(", "client_k", ".", "model", ",", "\n", "target_epsilon", "=", "privacy_cfg", "[", "'epsilon'", "]", ",", "\n", "target_delta", "=", "client_k", ".", "delta", ",", "\n", "max_grad_norm", "=", "privacy_cfg", "[", "'max_grad_norm'", "]", ",", "\n", "epochs", "=", "sel_max_rounds", ",", "\n", "# noise_multiplier = privacy_cfg['noise_multiplier'],", "\n", "# get sample rate with respect to client's dataset", "\n", "sample_rate", "=", "min", "(", "1", ",", "trBatchSize", "/", "client_k", ".", "n_data", ")", ")", "\n", "client_k", ".", "privacy_engine", ".", "attach", "(", "client_k", ".", "optimizer", ")", "\n", "\n", "", "", "fed_start", "=", "time", ".", "time", "(", ")", "\n", "#FEDERATED LEARNING", "\n", "global_auc", "=", "[", "]", "\n", "best_global_auc", "=", "0", "\n", "track_no_improv", "=", "0", "\n", "client_pool", "=", "clients", "# clients that may be selected for training", "\n", "\n", "for", "i", "in", "range", "(", "com_rounds", ")", ":", "\n", "\n", "        ", "print", "(", "f\"[[[ Round {i} Start ]]]\"", ")", "\n", "\n", "# Step 1: select random fraction of clients", "\n", "if", "fraction", "<", "1", ":", "\n", "            ", "sel_clients", "=", "random", ".", "sample", "(", "client_pool", ",", "\n", "round", "(", "num_clients", "*", "fraction", ")", ")", "\n", "for", "sel_client", "in", "sel_clients", ":", "\n", "                ", "sel_client", ".", "selected_rounds", "+=", "1", "\n", "# check if clients have now exceeded the maximum number of rounds they can be selected", "\n", "# and drop them from the pool if so", "\n", "", "for", "cp", "in", "client_pool", ":", "\n", "                ", "if", "cp", ".", "selected_rounds", "==", "sel_max_rounds", ":", "\n", "                    ", "client_pool", ".", "remove", "(", "cp", ")", "\n", "\n", "", "", "", "else", ":", "\n", "            ", "sel_clients", "=", "clients", "\n", "", "print", "(", "\"Number of selected clients: \"", ",", "len", "(", "sel_clients", ")", ")", "\n", "print", "(", "f\"Clients selected: {[sel_cl.name for sel_cl in sel_clients]}\"", ")", "\n", "# Step 2: send global model to clients and train locally", "\n", "for", "client_k", "in", "sel_clients", ":", "\n", "\n", "# reset model at client's site", "\n", "            ", "client_k", ".", "model_params", "=", "None", "\n", "# https://blog.openmined.org/pysyft-opacus-federated-learning-with-differential-privacy/", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "for", "client_params", ",", "global_params", "in", "zip", "(", "client_k", ".", "model", ".", "parameters", "(", ")", ",", "global_model", ".", "parameters", "(", ")", ")", ":", "\n", "                    ", "client_params", ".", "set_", "(", "copy", ".", "deepcopy", "(", "global_params", ")", ")", "\n", "\n", "\n", "", "", "print", "(", "f\"<< {client_k.name} Training Start >>\"", ")", "\n", "# set output path for storing models and results", "\n", "client_k", ".", "output_path", "=", "output_path", "+", "f\"round{i}_{client_k.name}/\"", "\n", "client_k", ".", "output_path", "=", "check_path", "(", "client_k", ".", "output_path", ",", "warn_exists", "=", "False", ")", "\n", "print", "(", "client_k", ".", "output_path", ")", "\n", "\n", "train_valid_start", "=", "time", ".", "time", "(", ")", "\n", "# Step 3: Perform local computations", "\n", "# returns local best model", "\n", "Trainer", ".", "train", "(", "client_k", ",", "cfg", ",", "use_gpu", ",", "out_csv", "=", "f\"round{i}_{client_k.name}.csv\"", ",", "freeze_mode", "=", "freeze_mode", ")", "\n", "client_k", ".", "model_params", "=", "client_k", ".", "model", ".", "state_dict", "(", ")", ".", "copy", "(", ")", "\n", "\n", "train_valid_end", "=", "time", ".", "time", "(", ")", "\n", "client_time", "=", "round", "(", "train_valid_end", "-", "train_valid_start", ")", "\n", "print", "(", "f\"<< {client_k.name} Training Time: {client_time} seconds >>\"", ")", "\n", "\n", "", "first_cl", "=", "sel_clients", "[", "0", "]", "\n", "# Step 4: return updates to server", "\n", "for", "key", "in", "first_cl", ".", "model_params", ":", "#iterate through parameters layerwise", "\n", "            ", "weights", ",", "weightn", "=", "[", "]", ",", "[", "]", "\n", "\n", "for", "cl", "in", "sel_clients", ":", "\n", "                ", "weights", ".", "append", "(", "cl", ".", "model_params", "[", "key", "]", "*", "cl", ".", "n_data", ")", "\n", "weightn", ".", "append", "(", "cl", ".", "n_data", ")", "\n", "\n", "#store parameters with first client for convenience", "\n", "", "first_cl", ".", "model_params", "[", "key", "]", "=", "sum", "(", "weights", ")", "/", "sum", "(", "weightn", ")", "# weighted averaging model weights", "\n", "\n", "\n", "# Step 5: server updates global state", "\n", "", "global_model", ".", "load_state_dict", "(", "first_cl", ".", "model_params", ")", "\n", "\n", "# also save intermediate models", "\n", "torch", ".", "save", "(", "global_model", ".", "state_dict", "(", ")", ",", "\n", "output_path", "+", "f\"global_{i}rounds.pth.tar\"", ")", "\n", "\n", "#validate global model on client validation data", "\n", "print", "(", "\"Validating global model...\"", ")", "\n", "aurocMean_global", "=", "[", "]", "\n", "for", "cl", "in", "clients", ":", "\n", "            ", "if", "cl", ".", "val_loader", "is", "not", "None", ":", "\n", "                ", "GT", ",", "PRED", ",", "cl_aurocMean", ",", "_", "=", "Trainer", ".", "test", "(", "global_model", ",", "cl", ".", "val_loader", ",", "class_idx", ",", "use_gpu", ",", "checkpoint", "=", "None", ")", "\n", "aurocMean_global", ".", "append", "(", "cl_aurocMean", ")", "\n", "", "else", ":", "\n", "                ", "aurocMean_global", ".", "append", "(", "np", ".", "nan", ")", "\n", "#  print(GT)", "\n", "# print(PRED)", "\n", "", "", "cur_global_auc", "=", "np", ".", "nanmean", "(", "np", ".", "array", "(", "aurocMean_global", ")", ")", "\n", "print", "(", "\"AUC Mean: {:.3f}\"", ".", "format", "(", "cur_global_auc", ")", ")", "\n", "global_auc", ".", "append", "(", "cur_global_auc", ")", "\n", "\n", "# track early stopping & lr decay", "\n", "if", "cur_global_auc", ">", "best_global_auc", ":", "\n", "            ", "best_global_auc", "=", "cur_global_auc", "\n", "track_no_improv", "=", "0", "\n", "", "else", ":", "\n", "            ", "track_no_improv", "+=", "1", "\n", "if", "track_no_improv", "==", "reduce_lr_rounds", ":", "\n", "# decay lr", "\n", "                ", "cfg", "[", "'lr'", "]", "=", "cfg", "[", "'lr'", "]", "*", "0.1", "\n", "print", "(", "f\"Learning rate reduced to {cfg['lr']}\"", ")", "\n", "", "elif", "track_no_improv", "==", "earl_stop_rounds", ":", "\n", "                ", "print", "(", "f'Global AUC has not improved for {earl_stop_rounds} rounds. Stopping training.'", ")", "\n", "break", "\n", "\n", "", "", "print", "(", "f\"[[[ Round {i} End ]]]\\n\"", ")", "\n", "\n", "# save global AUC in CSV", "\n", "", "all_metrics", "=", "[", "list", "(", "range", "(", "com_rounds", ")", ")", ",", "global_auc", "]", "\n", "with", "open", "(", "output_path", "+", "'global_validation.csv'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "header", "=", "[", "'round'", ",", "'val AUC'", "]", "\n", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "header", ")", "\n", "writer", ".", "writerows", "(", "zip", "(", "*", "all_metrics", ")", ")", "\n", "\n", "", "print", "(", "\"Global model trained\"", ")", "\n", "fed_end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "f\"Total training time: {round(fed_end-fed_start,0)}\"", ")", "\n", "\n", "\n", "# merge local metrics to CSV", "\n", "try", ":", "\n", "        ", "merge_eval_csv", "(", "output_path", ",", "out_file", "=", "'train_results.csv'", ")", "\n", "", "except", ":", "\n", "        ", "print", "(", "\"Merging result CSVs failed. Try again manually.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.train_FL.check_gpu_usage": [[399, 408], ["print", "torch.cuda.device_count", "len", "torch.cuda.device_count"], "function", ["None"], ["", "", "def", "check_gpu_usage", "(", "use_gpu", ")", ":", "\n", "\n", "    ", "\"\"\"Give feedback to whether GPU is available and if the expected number of GPUs are visible to PyTorch.\n    \"\"\"", "\n", "assert", "use_gpu", "is", "True", ",", "\"GPU not used\"", "\n", "assert", "torch", ".", "cuda", ".", "device_count", "(", ")", "==", "len", "(", "selected_gpus", ")", ",", "\"Wrong number of GPUs available to Pytorch\"", "\n", "print", "(", "f\"{torch.cuda.device_count()} GPUs available\"", ")", "\n", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.split_mendeley.main": [[25, 78], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "utils.check_path", "random.seed", "pandas.read_csv", "len", "list", "random.shuffle", "len", "len", "range", "range", "zip", "zip", "len", "sub_df.to_csv", "print", "int", "sub_df.to_csv", "print", "data[].str.contains", "len", "len"], "function", ["home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path"], ["def", "main", "(", ")", ":", "\n", "\n", "    ", "assert", "len", "(", "CSV_NAMES", ")", "==", "len", "(", "SPLIT_NUM", ")", ",", "\"Number of splits must match number of file names\"", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "#set path to chexpert data", "\n", "parser", ".", "add_argument", "(", "'--data_path'", ",", "'-d'", ",", "dest", "=", "'data_path'", ",", "help", "=", "'Path to data.'", ",", "default", "=", "'./'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "data_path", "=", "check_path", "(", "args", ".", "data_path", ",", "warn_exists", "=", "False", ",", "require_exists", "=", "True", ")", "\n", "random", ".", "seed", "(", "random_seed", ")", "\n", "\n", "# Read from CSV files", "\n", "data", "=", "pd", ".", "read_csv", "(", "data_path", "+", "ORIG_CSV", ")", "\n", "\n", "# exclude_df_1 = pd.read_csv(SUB_DIR+'client37.csv')", "\n", "# exclude_df_2 = pd.read_csv(SUB_DIR+'client38.csv')", "\n", "# exclude_df_3 = pd.read_csv(SUB_DIR+'client39.csv')", "\n", "# exclude_df_4 = pd.read_csv(SUB_DIR+'client40.csv')", "\n", "#", "\n", "# data = pd.concat([data,exclude_df_1]).drop_duplicates(keep=False)", "\n", "# data = pd.concat([data,exclude_df_2]).drop_duplicates(keep=False)", "\n", "# data = pd.concat([data,exclude_df_3]).drop_duplicates(keep=False)", "\n", "# data = pd.concat([data,exclude_df_4]).drop_duplicates(keep=False)", "\n", "\n", "if", "filter_by", "is", "not", "None", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "            ", "data", "=", "data", "[", "data", "[", "'Path'", "]", ".", "str", ".", "contains", "(", "filter_by", ")", "]", "\n", "# data = data[data['Age'] >70]", "\n", "\n", "", "", "total_idx", "=", "len", "(", "data", ")", "\n", "idx_list", "=", "list", "(", "range", "(", "total_idx", ")", ")", "\n", "random", ".", "shuffle", "(", "idx_list", ")", "\n", "\n", "start", "=", "0", "\n", "if", "split_by", "==", "'int'", ":", "\n", "        ", "for", "csv_name", ",", "i", "in", "zip", "(", "CSV_NAMES", ",", "SPLIT_NUM", ")", ":", "\n", "            ", "sub_df", "=", "data", ".", "iloc", "[", "idx_list", "[", "start", ":", "start", "+", "i", "]", "]", "\n", "sub_df", ".", "to_csv", "(", "data_path", "+", "csv_name", ",", "index", "=", "False", ")", "\n", "print", "(", "f\"{len(sub_df)} images saved in {csv_name}\"", ")", "\n", "start", "+=", "i", "\n", "\n", "", "", "if", "split_by", "==", "'perc'", ":", "\n", "        ", "for", "csv_name", ",", "i", "in", "zip", "(", "CSV_NAMES", ",", "SPLIT_NUM", ")", ":", "\n", "            ", "split_int", "=", "int", "(", "total_idx", "*", "i", ")", "\n", "sub_df", "=", "data", ".", "iloc", "[", "idx_list", "[", "start", ":", "start", "+", "split_int", "]", "]", "\n", "sub_df", ".", "to_csv", "(", "data_path", "+", "csv_name", ",", "index", "=", "False", ")", "\n", "print", "(", "f\"{len(sub_df)} images saved in {csv_name}\"", ")", "\n", "start", "+=", "split_int", "\n", "\n", "\n", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.check_path": [[9, 44], ["os.path.exists", "os.mkdir", "print", "os.path.exists", "exit", "input", "exit", "print"], "function", ["None"], ["def", "check_path", "(", "path", ",", "warn_exists", "=", "True", ",", "require_exists", "=", "False", ")", ":", "\n", "\n", "    ", "\"\"\"Check path to directory.\n    Args:\n        warn_exists (bool): Warn and require validation by user to use the specified path if it already exists.\n        require_exists (bool): Abort if the path does not exist. \"\"\"", "\n", "\n", "if", "path", "[", "-", "1", "]", "!=", "'/'", ":", "\n", "        ", "path", "=", "path", "+", "'/'", "\n", "\n", "", "create_path", "=", "True", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "create_path", "=", "False", "\n", "if", "warn_exists", ":", "\n", "            ", "replace", "=", "''", "\n", "while", "replace", "not", "in", "[", "'y'", ",", "'n'", "]", ":", "\n", "                ", "replace", "=", "input", "(", "f\"Path {path} already exists. Files may be replaced. Continue? (y/n): \"", ")", "\n", "if", "replace", "==", "'y'", ":", "\n", "                    ", "pass", "\n", "", "elif", "replace", "==", "'n'", ":", "\n", "                    ", "exit", "(", "'Aborting, run again with a different path.'", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "\"Invalid input\"", ")", "\n", "\n", "\n", "", "", "", "", "if", "require_exists", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "            ", "exit", "(", "f\"{path} does not exist. Aborting\"", ")", "\n", "\n", "", "", "if", "create_path", ":", "\n", "        ", "os", ".", "mkdir", "(", "path", ")", "\n", "print", "(", "f\"Created {path}\"", ")", "\n", "\n", "", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.merge_eval_csv": [[45, 97], ["os.path.abspath", "pandas.DataFrame", "os.walk", "result_df.append.reset_index", "result_df.append.to_csv", "print", "os.getcwd", "os.chdir", "file.endswith", "os.path.realpath", "print", "pandas.read_csv", "cur_csv.split", "round_part.replace", "client_part.replace", "result_df.append.append", "os.path.join", "os.path.realpath.split", "pd.read_csv.insert", "pd.read_csv.insert", "print"], "function", ["None"], ["", "def", "merge_eval_csv", "(", "result_path", ",", "out_file", "=", "'train_results.csv'", ")", ":", "\n", "\n", "    ", "\"\"\"Create a merged CSV from CSVs in round-client-subdirectories for central storage of training results.\n    Assumes CSVs to be named like 'round{n}_client{n}.csv'. Returns the merged dataframe and saves it as CSV.\n    Args:\n        result_path (str): Absolute path to where subdirectories with training results are located.\n        out_file (str): Name of CSV file with merged results. Will be stored in result_path.\"\"\"", "\n", "\n", "# change path if necessary", "\n", "result_path", "=", "os", ".", "path", ".", "abspath", "(", "result_path", ")", "\n", "if", "result_path", "!=", "os", ".", "getcwd", "(", ")", ":", "\n", "        ", "os", ".", "chdir", "(", "result_path", ")", "\n", "\n", "", "out_path", "=", "result_path", "+", "'/'", "+", "out_file", "\n", "\n", "result_df", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "for", "root", ",", "_", ",", "files", "in", "os", ".", "walk", "(", "'.'", ")", ":", "\n", "        ", "for", "file", "in", "files", ":", "\n", "            ", "if", "file", ".", "endswith", "(", "'.csv'", ")", ":", "\n", "# exclude global validation file because it has a different structure", "\n", "                ", "if", "file", "!=", "'global_validation.csv'", ":", "\n", "\n", "                    ", "cur_csv_path", "=", "os", ".", "path", ".", "realpath", "(", "os", ".", "path", ".", "join", "(", "root", ",", "file", ")", ")", "# whole path to csv", "\n", "cur_csv", "=", "cur_csv_path", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "# name of csv", "\n", "print", "(", "f'Reading {cur_csv}'", ")", "\n", "\n", "cur_df", "=", "pd", ".", "read_csv", "(", "cur_csv_path", ")", "\n", "\n", "# extract round and client info from csv name", "\n", "parts", "=", "cur_csv", ".", "split", "(", "'_'", ")", "\n", "round_part", "=", "parts", "[", "0", "]", "\n", "client_part", "=", "parts", "[", "1", "]", "[", ":", "-", "4", "]", "# remove .csv", "\n", "n_round", "=", "round_part", ".", "replace", "(", "'round'", ",", "''", ")", "# only keep number", "\n", "n_client", "=", "client_part", ".", "replace", "(", "'client'", ",", "''", ")", "\n", "\n", "try", ":", "\n", "                        ", "cur_df", ".", "insert", "(", "0", ",", "'round'", ",", "n_round", ")", "\n", "cur_df", ".", "insert", "(", "1", ",", "'client'", ",", "n_client", ")", "\n", "", "except", "ValueError", ":", "# exit with error if a merged file is detected", "\n", "                        ", "print", "(", "f'{file} seems to already be a merged file. Delete or move to be able to create a new file.'", ")", "\n", "raise", "\n", "\n", "", "result_df", "=", "result_df", ".", "append", "(", "cur_df", ")", "\n", "\n", "", "", "", "", "result_df", ".", "reset_index", "(", "inplace", "=", "True", ",", "drop", "=", "True", ")", "\n", "\n", "\n", "result_df", ".", "to_csv", "(", "out_file", ",", "na_rep", "=", "'nan'", ")", "\n", "print", "(", "f\"Merged CSV saved in {out_path}\"", ")", "\n", "\n", "return", "result_df", "\n", "\n"]], "home.repos.pwc.inspect_result.linev8k_cxr-fl-privacy.None.utils.median_grad_norm": [[98, 123], ["pandas.read_csv", "numpy.array", "numpy.median", "numpy.median", "len", "ast.literal_eval"], "function", ["None"], ["", "def", "median_grad_norm", "(", "path_csv", ",", "max_rounds", "=", "10", ",", "n_clients", "=", "1", ")", ":", "\n", "\n", "    ", "\"\"\"Compute the median L2 grad norm from grad norm lists\n    saved in train_results.csv.\n    Args:\n        path_csv (str): Relative path to CSV with 'grad_norm' column containing parameter\n        layer wise L2 grad norms per client per round.\n        Grad norms are assumed to be a string representation of a list of values.\n\n        max_rounds (int): Number of rounds to consider for median computation. If the number\n        exceeds the total number of rounds, it will default to considering all.\n\n        n_clients (int): Number of clients for which training was recorded.\n    Returns:\n        (array): Per parameter layer median gradient norms computed over clients over rounds.\n        (float): Single median gradient norm over all gradient norm values.\"\"\"", "\n", "\n", "df", "=", "pd", ".", "read_csv", "(", "path_csv", ")", "\n", "norms", "=", "np", ".", "array", "(", "[", "ast", ".", "literal_eval", "(", "norms", ")", "for", "norms", "in", "df", "[", "'track_norm'", "]", "]", ")", "\n", "if", "len", "(", "norms", ")", ">", "max_rounds", ":", "\n", "        ", "norms", "=", "norms", "[", ":", "max_rounds", "*", "n_clients", "]", "# keep first n rounds", "\n", "", "median_norms_params", "=", "np", ".", "median", "(", "norms", ",", "axis", "=", "0", ")", "\n", "median_norms_single", "=", "np", ".", "median", "(", "norms", ")", "\n", "\n", "return", "norms", ",", "median_norms_params", ",", "median_norms_single", "\n", "", ""]]}