{"home.repos.pwc.inspect_result.xl2248_csa-nct.data_preprocess_code.preprocess_ende.readFileRows": [[8, 141], ["open", "csv.DictReader", "open", "open", "open", "open", "open", "open", "open", "open", "open", "Dialogue_ID.append", "range", "open.close", "open.close", "open.close", "open.close", "open.close", "open.close", "open.close", "print", "Source.append", "Speaker.append", "Emotion.append", "Target.append", "Dialogue_ID.append", "Utterance_ID.append", "len", "len", "set", "set", "str", "switch_context.append", "emotion.append", "enumerate", "English.append", "German.append", "Agent.append", "German.append", "English.append", "Agent.append", "open.write", "open.write", "list", "random.randint", "open.write", "list", "random.randint", "open.write", "range", "range", "open.write", "open.write", "open.write", "open.write", "open.write", "len", "open.write", "open.write", "list", "list", "open.write", "open.write", "list.append", "list.append", "list.append", "len", "open.write", "open.write", "open.write", "list", "list", "list", "open.write", "open.write", "open.write", "set", "set", "len", "set", "set", "len", "list.append", "list.append", "reversed", "reversed", "reversed", "reversed", "reversed", "list", "list"], "function", ["None"], ["def", "readFileRows", "(", "filepath", ",", "dimension_size", "=", "17", ")", ":", "\n", "#code.interact(local=locals())", "\n", "    ", "with", "open", "(", "filepath", ",", "'r'", ",", "encoding", "=", "'utf-8-sig'", ")", "as", "f", ":", "\n", "# file = csv.reader(f)", "\n", "# for line in file:", "\n", "#     print(line)", "\n", "        ", "reader", "=", "csv", ".", "DictReader", "(", "f", ")", "\n", "Source", "=", "[", "]", "\n", "Target", "=", "[", "]", "\n", "Speaker", "=", "[", "]", "\n", "Emotion", "=", "[", "]", "\n", "Sentiment", "=", "[", "]", "\n", "Dialogue_ID", "=", "[", "]", "\n", "Utterance_ID", "=", "[", "]", "\n", "for", "row", "in", "reader", ":", "\n", "            ", "Source", ".", "append", "(", "row", "[", "'Source'", "]", ")", "\n", "Speaker", ".", "append", "(", "row", "[", "'Speaker'", "]", ")", "\n", "Emotion", ".", "append", "(", "row", "[", "'Emotion'", "]", ")", "\n", "Target", ".", "append", "(", "row", "[", "'Target'", "]", ")", "\n", "Dialogue_ID", ".", "append", "(", "row", "[", "'Dialogue_ID'", "]", ")", "\n", "Utterance_ID", ".", "append", "(", "row", "[", "'Utterance_ID'", "]", ")", "\n", "", "English", "=", "[", "]", "\n", "German", "=", "[", "]", "\n", "emotion", "=", "[", "]", "\n", "switch_context", "=", "[", "]", "\n", "index", "=", "-", "1", "\n", "#        tk = MosesTokenizer()", "\n", "count", "=", "0", "\n", "f_en", "=", "open", "(", "filepath_w_en", ",", "'w'", ",", "encoding", "=", "'utf-8-sig'", ")", "\n", "f_de", "=", "open", "(", "filepath_w_de", ",", "'w'", ",", "encoding", "=", "'utf-8-sig'", ")", "\n", "f_en_ctx", "=", "open", "(", "filepath_w_en_ctx", ",", "'w'", ",", "encoding", "=", "'utf-8-sig'", ")", "\n", "f_de_ctx", "=", "open", "(", "filepath_w_de_ctx", ",", "'w'", ",", "encoding", "=", "'utf-8-sig'", ")", "\n", "f_en_sample", "=", "open", "(", "filepath_w_en_sample", ",", "'w'", ",", "encoding", "=", "'utf-8-sig'", ")", "\n", "f_de_sample", "=", "open", "(", "filepath_w_de_sample", ",", "'w'", ",", "encoding", "=", "'utf-8-sig'", ")", "\n", "f_ende_ctx", "=", "open", "(", "filepath_w_ende_ctx", ",", "'w'", ",", "encoding", "=", "'utf-8-sig'", ")", "\n", "f_peren_ctx", "=", "open", "(", "filepath_w_enper_ctx", ",", "'w'", ",", "encoding", "=", "'utf-8-sig'", ")", "\n", "f_perde_ctx", "=", "open", "(", "filepath_w_deper_ctx", ",", "'w'", ",", "encoding", "=", "'utf-8-sig'", ")", "\n", "Dialogue_ID", ".", "append", "(", "len", "(", "set", "(", "Dialogue_ID", ")", ")", "+", "1", ")", "\n", "Agent", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "set", "(", "Dialogue_ID", ")", ")", ")", ":", "\n", "            ", "for", "D_id", "in", "Dialogue_ID", ":", "\n", "#                code.interact(local=locals())", "\n", "                ", "if", "D_id", "==", "str", "(", "idx", ")", ":", "# idx-th dialogue.", "\n", "                    ", "index", "+=", "1", "\n", "switch_context", ".", "append", "(", "Source", "[", "index", "]", ")", "\n", "if", "Speaker", "[", "index", "]", "==", "\"agent\"", ":", "\n", "                        ", "English", ".", "append", "(", "Source", "[", "index", "]", ")", "\n", "German", ".", "append", "(", "Target", "[", "index", "]", ")", "\n", "Agent", ".", "append", "(", "\"agent\"", ")", "\n", "", "else", ":", "\n", "                        ", "German", ".", "append", "(", "Source", "[", "index", "]", ")", "\n", "English", ".", "append", "(", "Target", "[", "index", "]", ")", "\n", "Agent", ".", "append", "(", "\"customer\"", ")", "\n", "", "emotion", ".", "append", "(", "Emotion", "[", "index", "]", ")", "\n", "", "else", ":", "\n", "# if len(dialogue)", "\n", "#code.interact(local=locals())", "\n", "                    ", "for", "k", ",", "role", "in", "enumerate", "(", "Agent", ")", ":", "\n", "                        ", "if", "role", "==", "\"agent\"", ":", "# modify it to \"customer\" to generate corresponding de-en data", "\n", "#                    for k in range(len(English)):", "\n", "#f_q = open(filepath_w_query, 'w')", "\n", "#f_i = open(filepath_w_image, 'w')", "\n", "                            ", "f_en", ".", "write", "(", "English", "[", "k", "]", "+", "'\\n'", ")", "\n", "f_de", ".", "write", "(", "German", "[", "k", "]", "+", "'\\n'", ")", "\n", "# f_emotion.write(emotion[k]+'\\n')", "\n", "en_rest", "=", "list", "(", "set", "(", "English", ")", "-", "set", "(", "list", "(", "English", "[", "k", "]", ")", ")", ")", "\n", "sam_num", "=", "random", ".", "randint", "(", "0", ",", "(", "len", "(", "en_rest", ")", "-", "1", ")", ")", "\n", "f_en_sample", ".", "write", "(", "en_rest", "[", "sam_num", "]", "+", "'\\n'", ")", "\n", "\n", "de_rest", "=", "list", "(", "set", "(", "German", ")", "-", "set", "(", "list", "(", "German", "[", "k", "]", ")", ")", ")", "\n", "sam_num", "=", "random", ".", "randint", "(", "0", ",", "(", "len", "(", "de_rest", ")", "-", "1", ")", ")", "\n", "f_de_sample", ".", "write", "(", "de_rest", "[", "sam_num", "]", "+", "'\\n'", ")", "\n", "\n", "flag1", "=", "0", "\n", "deper", ",", "enper", "=", "[", "]", ",", "[", "]", "\n", "for", "m", "in", "range", "(", "k", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "#for m in range(0, k):", "\n", "                                ", "if", "Agent", "[", "m", "]", "==", "Agent", "[", "k", "]", ":", "\n", "                                    ", "enper", ".", "append", "(", "English", "[", "m", "]", ")", "\n", "deper", ".", "append", "(", "German", "[", "m", "]", ")", "\n", "flag1", "+=", "1", "\n", "", "if", "flag1", "==", "ctx_num", ":", "\n", "                                    ", "break", ";", "\n", "", "", "if", "len", "(", "enper", ")", "==", "0", ":", "\n", "                                ", "f_peren_ctx", ".", "write", "(", "'pad'", ")", "\n", "f_perde_ctx", ".", "write", "(", "'pad'", ")", "\n", "", "else", ":", "\n", "                                ", "enper", "=", "list", "(", "reversed", "(", "enper", ")", ")", "\n", "deper", "=", "list", "(", "reversed", "(", "deper", ")", ")", "\n", "f_peren_ctx", ".", "write", "(", "' @@@ '", ".", "join", "(", "enper", ")", ")", "\n", "f_perde_ctx", ".", "write", "(", "' @@@ '", ".", "join", "(", "deper", ")", ")", "#ctx_num = 10", "\n", "\n", "", "enctx", ",", "dectx", ",", "endectx", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "flag2", "=", "0", "\n", "for", "j", "in", "range", "(", "k", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "#                            for j in range(0, k):", "\n", "                                ", "dectx", ".", "append", "(", "German", "[", "j", "]", ")", "\n", "enctx", ".", "append", "(", "English", "[", "j", "]", ")", "\n", "endectx", ".", "append", "(", "switch_context", "[", "j", "]", ")", "\n", "flag2", "+=", "1", "\n", "if", "flag2", "==", "ctx_num", ":", "\n", "                                    ", "break", ";", "\n", "\n", "", "", "if", "len", "(", "enctx", ")", "==", "0", ":", "\n", "                                ", "f_en_ctx", ".", "write", "(", "'pad'", ")", "\n", "f_de_ctx", ".", "write", "(", "'pad'", ")", "\n", "f_ende_ctx", ".", "write", "(", "'pad'", ")", "\n", "", "else", ":", "\n", "                                ", "enctx", "=", "list", "(", "reversed", "(", "enctx", ")", ")", "\n", "dectx", "=", "list", "(", "reversed", "(", "dectx", ")", ")", "\n", "endectx", "=", "list", "(", "reversed", "(", "endectx", ")", ")", "\n", "f_en_ctx", ".", "write", "(", "' @@@ '", ".", "join", "(", "enctx", ")", ")", "\n", "f_de_ctx", ".", "write", "(", "' @@@ '", ".", "join", "(", "dectx", ")", ")", "\n", "f_ende_ctx", ".", "write", "(", "' @@@ '", ".", "join", "(", "endectx", ")", ")", "\n", "", "f_en_ctx", ".", "write", "(", "'\\n'", ")", "\n", "f_de_ctx", ".", "write", "(", "'\\n'", ")", "\n", "f_ende_ctx", ".", "write", "(", "'\\n'", ")", "\n", "f_perde_ctx", ".", "write", "(", "'\\n'", ")", "\n", "f_peren_ctx", ".", "write", "(", "'\\n'", ")", "\n", "", "", "English", "=", "[", "]", "\n", "German", "=", "[", "]", "\n", "emotion", "=", "[", "]", "\n", "Agent", "=", "[", "]", "\n", "switch_context", "=", "[", "]", "\n", "#code.interact(local=locals())", "\n", "", "", "", "f_en", ".", "close", "(", ")", "\n", "f_de", ".", "close", "(", ")", "\n", "f_en_ctx", ".", "close", "(", ")", "\n", "f_de_ctx", ".", "close", "(", ")", "\n", "f_en_sample", ".", "close", "(", ")", "\n", "f_de_sample", ".", "close", "(", ")", "\n", "f_ende_ctx", ".", "close", "(", ")", "\n", "print", "(", "'count='", ",", "count", ")", "# break;", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data_preprocess_code.preprocess_ench.replace_abbreviations": [[9, 13], ["pat_letter.sub().strip().lower", "pat_letter.sub().strip", "pat_letter.sub"], "function", ["None"], ["def", "replace_abbreviations", "(", "text", ")", ":", "\n", "    ", "new_text", "=", "text", "\n", "new_text", "=", "pat_letter", ".", "sub", "(", "' '", ",", "text", ")", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "return", "new_text", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data_preprocess_code.preprocess_ench.readFileRows": [[14, 160], ["open", "csv.DictReader", "enumerate", "open", "open", "open", "open", "open", "open", "open", "open", "open", "open", "Dialogue_ID.append", "D_ID_list.append", "open.close", "open.close", "open.close", "open.close", "open.close", "open.close", "open.close", "open.close", "print", "Source.append", "Speaker.append", "Emotion.append", "row[].decode().encode", "nlp.word_tokenize", "Target.append", "Dialogue_ID.append", "Utterance_ID.append", "row[].decode().encode", "token.encode", "int", "D_ID_list.append", "int", "int", "int", "row[].decode", "int", "str", "English.append", "Chinese.append", "emotion.append", "speaker.append", "enumerate", "row[].decode", "switch_context.append", "switch_context.append", "open.write", "open.write", "list", "random.randint", "open.write", "list", "random.randint", "open.write", "open.write", "range", "range", "open.write", "open.write", "open.write", "open.write", "open.write", "len", "open.write", "open.write", "list", "list", "open.write", "open.write", "list.append", "list.append", "list.append", "len", "open.write", "open.write", "open.write", "list", "list", "list", "open.write", "open.write", "open.write", "set", "set", "len", "set", "set", "len", "list.append", "list.append", "reversed", "reversed", "reversed", "reversed", "reversed", "list", "list"], "function", ["None"], ["", "def", "readFileRows", "(", "filepath", ",", "dimension_size", "=", "17", ")", ":", "\n", "#code.interact(local=locals())", "\n", "    ", "with", "open", "(", "filepath", ",", "'r'", ")", "as", "f", ":", "\n", "# file = csv.reader(f)", "\n", "# for line in file:", "\n", "#     print(line)", "\n", "        ", "reader", "=", "csv", ".", "DictReader", "(", "f", ")", "\n", "Source", "=", "[", "]", "\n", "Target", "=", "[", "]", "\n", "Speaker", "=", "[", "]", "\n", "Emotion", "=", "[", "]", "\n", "Sentiment", "=", "[", "]", "\n", "Dialogue_ID", "=", "[", "]", "\n", "Utterance_ID", "=", "[", "]", "\n", "D_ID_list", "=", "[", "]", "\n", "flag", "=", "-", "1", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "reader", ")", ":", "\n", "#            try:", "\n", "            ", "Source", ".", "append", "(", "row", "[", "'Utterance'", "]", ".", "decode", "(", "'utf-8'", ",", "errors", "=", "'ignore'", ")", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "Speaker", ".", "append", "(", "row", "[", "'Speaker'", "]", ")", "\n", "Emotion", ".", "append", "(", "row", "[", "'Emotion'", "]", ")", "\n", "sentence", "=", "row", "[", "'Target'", "]", ".", "decode", "(", "\"GB18030\"", ",", "errors", "=", "'ignore'", ")", ".", "encode", "(", "'utf-8'", ")", "\n", "seg_sentence", "=", "nlp", ".", "word_tokenize", "(", "sentence", ")", "\n", "seg_sent", "=", "[", "token", ".", "encode", "(", "'utf-8'", ")", "for", "token", "in", "seg_sentence", "]", "\n", "Target", ".", "append", "(", "\" \"", ".", "join", "(", "seg_sent", ")", ")", "\n", "Dialogue_ID", ".", "append", "(", "row", "[", "'Dialogue_ID'", "]", ")", "\n", "Utterance_ID", ".", "append", "(", "row", "[", "'Utterance_ID'", "]", ")", "\n", "if", "int", "(", "row", "[", "'Dialogue_ID'", "]", ")", ">", "flag", ":", "\n", "                ", "D_ID_list", ".", "append", "(", "int", "(", "row", "[", "'Dialogue_ID'", "]", ")", ")", "\n", "flag", "=", "int", "(", "row", "[", "'Dialogue_ID'", "]", ")", "\n", "", "", "English", "=", "[", "]", "\n", "Chinese", "=", "[", "]", "\n", "emotion", "=", "[", "]", "\n", "speaker", "=", "[", "]", "\n", "switch_context", "=", "[", "]", "\n", "index", "=", "-", "1", "\n", "#        tk = MosesTokenizer()", "\n", "count", "=", "0", "\n", "f_en", "=", "open", "(", "filepath_w_en", ",", "'w'", ")", "#, encoding='utf-8-sig')", "\n", "f_ch", "=", "open", "(", "filepath_w_ch", ",", "'w'", ")", "#, encoding='utf-8-sig')", "\n", "f_en_ctx", "=", "open", "(", "filepath_w_en_ctx", ",", "'w'", ")", "#, encoding='utf-8-sig')", "\n", "f_ch_ctx", "=", "open", "(", "filepath_w_ch_ctx", ",", "'w'", ")", "#, encoding='utf-8-sig')", "\n", "f_ende_ctx", "=", "open", "(", "filepath_w_chen_ctx", ",", "'w'", ")", "#, encoding='utf-8-sig')", "\n", "f_perch_ctx", "=", "open", "(", "filepath_w_chper_ctx", ",", "'w'", ")", "\n", "f_peren_ctx", "=", "open", "(", "filepath_w_enper_ctx", ",", "'w'", ")", "\n", "f_en_sample", "=", "open", "(", "filepath_w_en_sample", ",", "'w'", ")", "#, encoding='utf-8-sig')", "\n", "f_ch_sample", "=", "open", "(", "filepath_w_ch_sample", ",", "'w'", ")", "#, encoding='utf-8-sig')", "\n", "f_speaker", "=", "open", "(", "filepath_w_speaker", ",", "'w'", ")", "#, encoding='utf-8-sig')", "\n", "Dialogue_ID", ".", "append", "(", "int", "(", "Dialogue_ID", "[", "-", "1", "]", ")", "+", "1", ")", "\n", "D_ID_list", ".", "append", "(", "int", "(", "D_ID_list", "[", "-", "1", "]", ")", "+", "1", ")", "\n", "agent", ",", "custom", "=", "[", "]", ",", "[", "]", "\n", "for", "idx", "in", "D_ID_list", ":", "\n", "            ", "for", "D_id", "in", "Dialogue_ID", ":", "\n", "#                code.interact(local=locals())", "\n", "                ", "if", "D_id", "==", "str", "(", "idx", ")", ":", "# idx-th dialogue.", "\n", "                    ", "index", "+=", "1", "\n", "English", ".", "append", "(", "Source", "[", "index", "]", ")", "\n", "Chinese", ".", "append", "(", "Target", "[", "index", "]", ")", "\n", "emotion", ".", "append", "(", "Emotion", "[", "index", "]", ")", "\n", "speaker", ".", "append", "(", "Speaker", "[", "index", "]", ")", "\n", "if", "index", "/", "2", "==", "0", ":", "\n", "                        ", "switch_context", ".", "append", "(", "Source", "[", "index", "]", ")", "\n", "", "else", ":", "\n", "                        ", "switch_context", ".", "append", "(", "Target", "[", "index", "]", ")", "\n", "# dialogue.append(' '.join(tk.tokenize(Utterance[index])))", "\n", "", "", "else", ":", "\n", "                    ", "for", "k", ",", "role", "in", "enumerate", "(", "speaker", ")", ":", "# paired chandler/monica; ross/rachel; phoebe/joey", "\n", "                        ", "if", "role", "not", "in", "[", "\"Ross\"", ",", "\"Joey\"", ",", "\"Rachel\"", "]", ":", "\n", "#f_q = open(filepath_w_query, 'w')", "\n", "#f_i = open(filepath_w_image, 'w')", "\n", "                            ", "f_en", ".", "write", "(", "English", "[", "k", "]", "+", "'\\n'", ")", "\n", "f_ch", ".", "write", "(", "Chinese", "[", "k", "]", "+", "'\\n'", ")", "\n", "# if len(English) < 2:", "\n", "en_rest", "=", "list", "(", "set", "(", "English", ")", "-", "set", "(", "list", "(", "English", "[", "k", "]", ")", ")", ")", "\n", "sam_num", "=", "random", ".", "randint", "(", "0", ",", "(", "len", "(", "en_rest", ")", "-", "1", ")", ")", "\n", "f_en_sample", ".", "write", "(", "en_rest", "[", "sam_num", "]", "+", "'\\n'", ")", "\n", "\n", "ch_rest", "=", "list", "(", "set", "(", "Chinese", ")", "-", "set", "(", "list", "(", "Chinese", "[", "k", "]", ")", ")", ")", "\n", "sam_num", "=", "random", ".", "randint", "(", "0", ",", "(", "len", "(", "ch_rest", ")", "-", "1", ")", ")", "\n", "f_ch_sample", ".", "write", "(", "ch_rest", "[", "sam_num", "]", "+", "'\\n'", ")", "\n", "f_speaker", ".", "write", "(", "speaker", "[", "k", "]", "+", "'\\n'", ")", "\n", "flag1", "=", "0", "\n", "chper", ",", "enper", "=", "[", "]", ",", "[", "]", "\n", "#                        for m in range(k-1, -1, -1):", "\n", "#if k > ctx_num:", "\n", "\n", "for", "m", "in", "range", "(", "k", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "                                ", "if", "speaker", "[", "m", "]", "==", "speaker", "[", "k", "]", ":", "\n", "                                    ", "chper", ".", "append", "(", "Chinese", "[", "m", "]", ")", "\n", "enper", ".", "append", "(", "English", "[", "m", "]", ")", "\n", "flag1", "+=", "1", "\n", "", "if", "flag1", "==", "ctx_num", ":", "\n", "                                    ", "break", ";", "\n", "\n", "", "", "if", "len", "(", "chper", ")", "==", "0", ":", "\n", "                               ", "f_perch_ctx", ".", "write", "(", "'pad'", ")", "\n", "f_peren_ctx", ".", "write", "(", "'pad'", ")", "\n", "", "else", ":", "\n", "                               ", "chper", "=", "list", "(", "reversed", "(", "chper", ")", ")", "\n", "enper", "=", "list", "(", "reversed", "(", "enper", ")", ")", "\n", "f_perch_ctx", ".", "write", "(", "' ### '", ".", "join", "(", "chper", ")", ")", "\n", "f_peren_ctx", ".", "write", "(", "' @@@ '", ".", "join", "(", "enper", ")", ")", "\n", "\n", "", "enctx", ",", "chctx", ",", "enchctx", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "flag2", "=", "0", "\n", "for", "j", "in", "range", "(", "k", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "#                        for j in range(begin, k):", "\n", "                                ", "enctx", ".", "append", "(", "English", "[", "j", "]", ")", "\n", "chctx", ".", "append", "(", "Chinese", "[", "j", "]", ")", "\n", "enchctx", ".", "append", "(", "switch_context", "[", "j", "]", ")", "\n", "flag2", "+=", "1", "\n", "if", "flag2", "==", "ctx_num", ":", "\n", "                                    ", "break", ";", "\n", "", "", "if", "len", "(", "enctx", ")", "==", "0", ":", "\n", "                                ", "f_en_ctx", ".", "write", "(", "'pad'", ")", "\n", "f_ch_ctx", ".", "write", "(", "'pad'", ")", "\n", "f_ende_ctx", ".", "write", "(", "'pad'", ")", "\n", "", "else", ":", "\n", "                                ", "enctx", "=", "list", "(", "reversed", "(", "enctx", ")", ")", "\n", "chctx", "=", "list", "(", "reversed", "(", "chctx", ")", ")", "\n", "enchctx", "=", "list", "(", "reversed", "(", "enchctx", ")", ")", "\n", "f_en_ctx", ".", "write", "(", "' @@@ '", ".", "join", "(", "enctx", ")", ")", "\n", "f_ch_ctx", ".", "write", "(", "' ### '", ".", "join", "(", "chctx", ")", ")", "\n", "f_ende_ctx", ".", "write", "(", "' @@@ '", ".", "join", "(", "enchctx", ")", ")", "\n", "", "f_en_ctx", ".", "write", "(", "'\\n'", ")", "\n", "f_ch_ctx", ".", "write", "(", "'\\n'", ")", "\n", "f_ende_ctx", ".", "write", "(", "'\\n'", ")", "\n", "f_perch_ctx", ".", "write", "(", "'\\n'", ")", "\n", "f_peren_ctx", ".", "write", "(", "'\\n'", ")", "\n", "#   f_a.write('\\n')", "\n", "#code.interact(local=locals())", "\n", "", "", "English", "=", "[", "]", "\n", "Chinese", "=", "[", "]", "\n", "emotion", "=", "[", "]", "\n", "speaker", "=", "[", "]", "\n", "switch_context", "=", "[", "]", "\n", "#code.interact(local=locals())", "\n", "", "", "", "f_en", ".", "close", "(", ")", "\n", "f_ch", ".", "close", "(", ")", "\n", "f_en_ctx", ".", "close", "(", ")", "\n", "f_ch_ctx", ".", "close", "(", ")", "\n", "f_en_sample", ".", "close", "(", ")", "\n", "f_ch_sample", ".", "close", "(", ")", "\n", "f_speaker", ".", "close", "(", ")", "\n", "f_ende_ctx", ".", "close", "(", ")", "\n", "print", "(", "'count='", ",", "count", ")", "# break;", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ori._get_inference_fn": [[21, 68], ["zip", "tensorflow.pad", "tensorflow.fill", "tensorflow.add_n", "float", "model_fn", "outputs.append", "next_state.append", "model_fn", "outputs.append", "next_state.append", "len", "tensorflow.shape", "tensorflow.shape"], "function", ["None"], ["", "def", "_get_inference_fn", "(", "model_fns", ",", "features", ")", ":", "\n", "    ", "def", "inference_fn", "(", "inputs", ",", "state", ")", ":", "\n", "        ", "local_features", "=", "{", "\n", "\"source\"", ":", "features", "[", "\"source\"", "]", ",", "\n", "\"source_length\"", ":", "features", "[", "\"source_length\"", "]", ",", "\n", "\"context_dia_src\"", ":", "features", "[", "\"context_dia_src\"", "]", ",", "\n", "\"context_dia_tgt\"", ":", "features", "[", "\"context_dia_tgt\"", "]", ",", "\n", "\"context_sty_src\"", ":", "features", "[", "\"context_sty_src\"", "]", ",", "\n", "\"context_sty_tgt\"", ":", "features", "[", "\"context_sty_tgt\"", "]", ",", "\n", "\"context_source\"", ":", "features", "[", "\"context_source\"", "]", ",", "\n", "\"context_dia_src_length\"", ":", "features", "[", "\"context_dia_src_length\"", "]", ",", "\n", "\"context_dia_tgt_length\"", ":", "features", "[", "\"context_dia_tgt_length\"", "]", ",", "\n", "\"context_sty_src_length\"", ":", "features", "[", "\"context_sty_src_length\"", "]", ",", "\n", "\"context_sty_tgt_length\"", ":", "features", "[", "\"context_sty_tgt_length\"", "]", ",", "\n", "\"context_source_length\"", ":", "features", "[", "\"context_source_length\"", "]", ",", "\n", "\"position_dia_src\"", ":", "features", "[", "\"position_dia_src\"", "]", ",", "\n", "\"position_dia_tgt\"", ":", "features", "[", "\"position_dia_tgt\"", "]", ",", "\n", "\"position_sty_src\"", ":", "features", "[", "\"position_sty_src\"", "]", ",", "\n", "\"position_sty_tgt\"", ":", "features", "[", "\"position_sty_tgt\"", "]", ",", "\n", "\"position_ctx_src\"", ":", "features", "[", "\"position_ctx_src\"", "]", ",", "\n", "\"sample\"", ":", "features", "[", "\"sample\"", "]", ",", "\n", "\"sample_length\"", ":", "features", "[", "\"sample_length\"", "]", ",", "\n", "# [bos_id, ...] => [..., 0]", "\n", "\"target\"", ":", "tf", ".", "pad", "(", "inputs", "[", ":", ",", "1", ":", "]", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "1", "]", "]", ")", ",", "\n", "\"target_length\"", ":", "tf", ".", "fill", "(", "[", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "]", ",", "\n", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", ")", "\n", "}", "\n", "\n", "outputs", "=", "[", "]", "\n", "next_state", "=", "[", "]", "\n", "\n", "for", "(", "model_fn", ",", "model_state", ")", "in", "zip", "(", "model_fns", ",", "state", ")", ":", "\n", "            ", "if", "model_state", ":", "\n", "                ", "output", ",", "new_state", "=", "model_fn", "(", "local_features", ",", "model_state", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "next_state", ".", "append", "(", "new_state", ")", "\n", "", "else", ":", "\n", "                ", "output", "=", "model_fn", "(", "local_features", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "next_state", ".", "append", "(", "{", "}", ")", "\n", "\n", "# Ensemble", "\n", "", "", "log_prob", "=", "tf", ".", "add_n", "(", "outputs", ")", "/", "float", "(", "len", "(", "outputs", ")", ")", "\n", "\n", "return", "log_prob", ",", "next_state", "\n", "\n", "", "return", "inference_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ori._beam_search_step": [[70, 144], ["thumt.merge_first_two_dims", "tensorflow.python.util.nest.map_structure", "func", "thumt.split_first_two_dims", "tensorflow.python.util.nest.map_structure", "tensorflow.pow", "tensorflow.reshape", "tensorflow.nn.top_k", "thumt.gather_2d", "tensorflow.concat", "tensorflow.equal", "tensorflow.nn.top_k", "thumt.gather_2d", "thumt.gather_2d", "thumt.gather_2d", "tensorflow.concat", "tensorflow.python.util.nest.map_structure", "tensorflow.concat", "tensorflow.concat", "tensorflow.nn.top_k", "thumt.gather_2d", "tensorflow.fill", "tensorflow.concat", "tensorflow.concat", "thumt.gather_2d", "inference_ori.BeamSearchState", "tensorflow.expand_dims", "tensorflow.constant", "thumt.merge_first_two_dims", "thumt.split_first_two_dims", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.to_float", "tensorflow.expand_dims", "thumt.gather_2d", "tensorflow.to_float", "tensorflow.to_float"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.merge_first_two_dims", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.split_first_two_dims", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.merge_first_two_dims", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.split_first_two_dims", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d"], ["", "def", "_beam_search_step", "(", "time", ",", "func", ",", "state", ",", "batch_size", ",", "beam_size", ",", "alpha", ",", "\n", "pad_id", ",", "eos_id", ")", ":", "\n", "# Compute log probabilities", "\n", "    ", "seqs", ",", "log_probs", "=", "state", ".", "inputs", "[", ":", "2", "]", "\n", "flat_seqs", "=", "utils", ".", "merge_first_two_dims", "(", "seqs", ")", "\n", "flat_state", "=", "nest", ".", "map_structure", "(", "lambda", "x", ":", "utils", ".", "merge_first_two_dims", "(", "x", ")", ",", "\n", "state", ".", "state", ")", "\n", "step_log_probs", ",", "next_state", "=", "func", "(", "flat_seqs", ",", "flat_state", ")", "\n", "step_log_probs", "=", "utils", ".", "split_first_two_dims", "(", "step_log_probs", ",", "batch_size", ",", "\n", "beam_size", ")", "\n", "next_state", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "x", ":", "utils", ".", "split_first_two_dims", "(", "x", ",", "batch_size", ",", "beam_size", ")", ",", "\n", "next_state", ")", "\n", "curr_log_probs", "=", "tf", ".", "expand_dims", "(", "log_probs", ",", "2", ")", "+", "step_log_probs", "\n", "\n", "# Apply length penalty", "\n", "length_penalty", "=", "tf", ".", "pow", "(", "(", "5.0", "+", "tf", ".", "to_float", "(", "time", "+", "1", ")", ")", "/", "6.0", ",", "alpha", ")", "\n", "curr_scores", "=", "curr_log_probs", "/", "length_penalty", "\n", "vocab_size", "=", "curr_scores", ".", "shape", "[", "-", "1", "]", ".", "value", "or", "tf", ".", "shape", "(", "curr_scores", ")", "[", "-", "1", "]", "\n", "\n", "# Select top-k candidates", "\n", "# [batch_size, beam_size * vocab_size]", "\n", "curr_scores", "=", "tf", ".", "reshape", "(", "curr_scores", ",", "[", "-", "1", ",", "beam_size", "*", "vocab_size", "]", ")", "\n", "# [batch_size, 2 * beam_size]", "\n", "top_scores", ",", "top_indices", "=", "tf", ".", "nn", ".", "top_k", "(", "curr_scores", ",", "k", "=", "2", "*", "beam_size", ")", "\n", "# Shape: [batch_size, 2 * beam_size]", "\n", "beam_indices", "=", "top_indices", "//", "vocab_size", "\n", "symbol_indices", "=", "top_indices", "%", "vocab_size", "\n", "# Expand sequences", "\n", "# [batch_size, 2 * beam_size, time]", "\n", "candidate_seqs", "=", "utils", ".", "gather_2d", "(", "seqs", ",", "beam_indices", ")", "\n", "candidate_seqs", "=", "tf", ".", "concat", "(", "[", "candidate_seqs", ",", "\n", "tf", ".", "expand_dims", "(", "symbol_indices", ",", "2", ")", "]", ",", "2", ")", "\n", "\n", "# Expand sequences", "\n", "# Suppress finished sequences", "\n", "flags", "=", "tf", ".", "equal", "(", "symbol_indices", ",", "eos_id", ")", "\n", "# [batch, 2 * beam_size]", "\n", "alive_scores", "=", "top_scores", "+", "tf", ".", "to_float", "(", "flags", ")", "*", "tf", ".", "float32", ".", "min", "\n", "# [batch, beam_size]", "\n", "alive_scores", ",", "alive_indices", "=", "tf", ".", "nn", ".", "top_k", "(", "alive_scores", ",", "beam_size", ")", "\n", "alive_symbols", "=", "utils", ".", "gather_2d", "(", "symbol_indices", ",", "alive_indices", ")", "\n", "alive_indices", "=", "utils", ".", "gather_2d", "(", "beam_indices", ",", "alive_indices", ")", "\n", "alive_seqs", "=", "utils", ".", "gather_2d", "(", "seqs", ",", "alive_indices", ")", "\n", "# [batch_size, beam_size, time + 1]", "\n", "alive_seqs", "=", "tf", ".", "concat", "(", "[", "alive_seqs", ",", "tf", ".", "expand_dims", "(", "alive_symbols", ",", "2", ")", "]", ",", "2", ")", "\n", "alive_state", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "x", ":", "utils", ".", "gather_2d", "(", "x", ",", "alive_indices", ")", ",", "\n", "next_state", ")", "\n", "alive_log_probs", "=", "alive_scores", "*", "length_penalty", "\n", "\n", "# Select finished sequences", "\n", "prev_fin_flags", ",", "prev_fin_seqs", ",", "prev_fin_scores", "=", "state", ".", "finish", "\n", "# [batch, 2 * beam_size]", "\n", "step_fin_scores", "=", "top_scores", "+", "(", "1.0", "-", "tf", ".", "to_float", "(", "flags", ")", ")", "*", "tf", ".", "float32", ".", "min", "\n", "# [batch, 3 * beam_size]", "\n", "fin_flags", "=", "tf", ".", "concat", "(", "[", "prev_fin_flags", ",", "flags", "]", ",", "axis", "=", "1", ")", "\n", "fin_scores", "=", "tf", ".", "concat", "(", "[", "prev_fin_scores", ",", "step_fin_scores", "]", ",", "axis", "=", "1", ")", "\n", "# [batch, beam_size]", "\n", "fin_scores", ",", "fin_indices", "=", "tf", ".", "nn", ".", "top_k", "(", "fin_scores", ",", "beam_size", ")", "\n", "fin_flags", "=", "utils", ".", "gather_2d", "(", "fin_flags", ",", "fin_indices", ")", "\n", "pad_seqs", "=", "tf", ".", "fill", "(", "[", "batch_size", ",", "beam_size", ",", "1", "]", ",", "\n", "tf", ".", "constant", "(", "pad_id", ",", "tf", ".", "int32", ")", ")", "\n", "prev_fin_seqs", "=", "tf", ".", "concat", "(", "[", "prev_fin_seqs", ",", "pad_seqs", "]", ",", "axis", "=", "2", ")", "\n", "fin_seqs", "=", "tf", ".", "concat", "(", "[", "prev_fin_seqs", ",", "candidate_seqs", "]", ",", "axis", "=", "1", ")", "\n", "fin_seqs", "=", "utils", ".", "gather_2d", "(", "fin_seqs", ",", "fin_indices", ")", "\n", "\n", "new_state", "=", "BeamSearchState", "(", "\n", "inputs", "=", "(", "alive_seqs", ",", "alive_log_probs", ",", "alive_scores", ")", ",", "\n", "state", "=", "alive_state", ",", "\n", "finish", "=", "(", "fin_flags", ",", "fin_seqs", ",", "fin_scores", ")", ",", "\n", ")", "\n", "\n", "return", "time", "+", "1", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ori.beam_search": [[146, 219], ["tensorflow.fill", "tensorflow.constant", "tensorflow.tile", "tensorflow.zeros_like", "tensorflow.zeros", "tensorflow.fill", "tensorflow.zeros", "inference_ori.BeamSearchState", "tensorflow.reduce_max", "tensorflow.constant", "inference_ori.BeamSearchState", "tensorflow.while_loop", "alive_seqs.set_shape", "tf.where.set_shape", "tensorflow.where", "tensorflow.where", "tensorflow.pow", "tensorflow.reduce_min", "tensorflow.reduce_all", "tensorflow.logical_and", "inference_ori._beam_search_step", "tensorflow.reduce_any", "tensorflow.reduce_any", "tensorflow.to_float", "tensorflow.greater", "tensorflow.less", "tensorflow.logical_not", "tensorflow.python.util.nest.map_structure", "tensorflow.to_float", "tensorflow.reduce_any", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.to_float"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._beam_search_step"], ["", "def", "beam_search", "(", "func", ",", "state", ",", "batch_size", ",", "beam_size", ",", "max_length", ",", "alpha", ",", "\n", "pad_id", ",", "bos_id", ",", "eos_id", ")", ":", "\n", "    ", "init_seqs", "=", "tf", ".", "fill", "(", "[", "batch_size", ",", "beam_size", ",", "1", "]", ",", "bos_id", ")", "\n", "init_log_probs", "=", "tf", ".", "constant", "(", "[", "[", "0.", "]", "+", "[", "tf", ".", "float32", ".", "min", "]", "*", "(", "beam_size", "-", "1", ")", "]", ")", "\n", "init_log_probs", "=", "tf", ".", "tile", "(", "init_log_probs", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "init_scores", "=", "tf", ".", "zeros_like", "(", "init_log_probs", ")", "\n", "fin_seqs", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "beam_size", ",", "1", "]", ",", "tf", ".", "int32", ")", "\n", "fin_scores", "=", "tf", ".", "fill", "(", "[", "batch_size", ",", "beam_size", "]", ",", "tf", ".", "float32", ".", "min", ")", "\n", "fin_flags", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "beam_size", "]", ",", "tf", ".", "bool", ")", "\n", "\n", "state", "=", "BeamSearchState", "(", "\n", "inputs", "=", "(", "init_seqs", ",", "init_log_probs", ",", "init_scores", ")", ",", "\n", "state", "=", "state", ",", "\n", "finish", "=", "(", "fin_flags", ",", "fin_seqs", ",", "fin_scores", ")", ",", "\n", ")", "\n", "\n", "max_step", "=", "tf", ".", "reduce_max", "(", "max_length", ")", "\n", "\n", "def", "_is_finished", "(", "t", ",", "s", ")", ":", "\n", "        ", "log_probs", "=", "s", ".", "inputs", "[", "1", "]", "\n", "finished_flags", "=", "s", ".", "finish", "[", "0", "]", "\n", "finished_scores", "=", "s", ".", "finish", "[", "2", "]", "\n", "max_lp", "=", "tf", ".", "pow", "(", "(", "(", "5.0", "+", "tf", ".", "to_float", "(", "max_step", ")", ")", "/", "6.0", ")", ",", "alpha", ")", "\n", "best_alive_score", "=", "log_probs", "[", ":", ",", "0", "]", "/", "max_lp", "\n", "worst_finished_score", "=", "tf", ".", "reduce_min", "(", "\n", "finished_scores", "*", "tf", ".", "to_float", "(", "finished_flags", ")", ",", "axis", "=", "1", ")", "\n", "add_mask", "=", "1.0", "-", "tf", ".", "to_float", "(", "tf", ".", "reduce_any", "(", "finished_flags", ",", "1", ")", ")", "\n", "worst_finished_score", "+=", "tf", ".", "float32", ".", "min", "*", "add_mask", "\n", "bound_is_met", "=", "tf", ".", "reduce_all", "(", "tf", ".", "greater", "(", "worst_finished_score", ",", "\n", "best_alive_score", ")", ")", "\n", "\n", "cond", "=", "tf", ".", "logical_and", "(", "tf", ".", "less", "(", "t", ",", "max_step", ")", ",", "\n", "tf", ".", "logical_not", "(", "bound_is_met", ")", ")", "\n", "\n", "return", "cond", "\n", "\n", "", "def", "_loop_fn", "(", "t", ",", "s", ")", ":", "\n", "        ", "outs", "=", "_beam_search_step", "(", "t", ",", "func", ",", "s", ",", "batch_size", ",", "beam_size", ",", "alpha", ",", "\n", "pad_id", ",", "eos_id", ")", "\n", "return", "outs", "\n", "\n", "", "time", "=", "tf", ".", "constant", "(", "0", ",", "name", "=", "\"time\"", ")", "\n", "shape_invariants", "=", "BeamSearchState", "(", "\n", "inputs", "=", "(", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "None", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ")", ",", "\n", "state", "=", "nest", ".", "map_structure", "(", "utils", ".", "infer_shape_invariants", ",", "state", ".", "state", ")", ",", "\n", "finish", "=", "(", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "None", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ")", "\n", ")", "\n", "outputs", "=", "tf", ".", "while_loop", "(", "_is_finished", ",", "_loop_fn", ",", "[", "time", ",", "state", "]", ",", "\n", "shape_invariants", "=", "[", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "shape_invariants", "]", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "back_prop", "=", "False", ")", "\n", "\n", "final_state", "=", "outputs", "[", "1", "]", "\n", "alive_seqs", "=", "final_state", ".", "inputs", "[", "0", "]", "\n", "alive_scores", "=", "final_state", ".", "inputs", "[", "2", "]", "\n", "final_flags", "=", "final_state", ".", "finish", "[", "0", "]", "\n", "final_seqs", "=", "final_state", ".", "finish", "[", "1", "]", "\n", "final_scores", "=", "final_state", ".", "finish", "[", "2", "]", "\n", "\n", "alive_seqs", ".", "set_shape", "(", "[", "None", ",", "beam_size", ",", "None", "]", ")", "\n", "final_seqs", ".", "set_shape", "(", "[", "None", ",", "beam_size", ",", "None", "]", ")", "\n", "\n", "final_seqs", "=", "tf", ".", "where", "(", "tf", ".", "reduce_any", "(", "final_flags", ",", "1", ")", ",", "final_seqs", ",", "\n", "alive_seqs", ")", "\n", "final_scores", "=", "tf", ".", "where", "(", "tf", ".", "reduce_any", "(", "final_flags", ",", "1", ")", ",", "final_scores", ",", "\n", "alive_scores", ")", "\n", "\n", "return", "final_seqs", ",", "final_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ori.create_inference_graph": [[221, 284], ["copy.copy", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "inference_ori._get_inference_fn", "tensorflow.python.util.nest.map_structure", "inference_ori.beam_search", "print", "print", "isinstance", "ValueError", "model.get_inference_func", "callable", "tensorflow.shape", "nest.map_structure.append", "funcs.append", "nest.map_structure.append", "funcs.append", "thumt.tile_to_beam_size"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.sampling._get_inference_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.search.beam_search", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_inference_func", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.tile_to_beam_size"], ["", "def", "create_inference_graph", "(", "models", ",", "features", ",", "params", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "models", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"'models' must be a list or tuple\"", ")", "\n", "\n", "", "features", "=", "copy", ".", "copy", "(", "features", ")", "\n", "model_fns", "=", "[", "model", ".", "get_inference_func", "(", ")", "for", "model", "in", "models", "]", "\n", "\n", "decode_length", "=", "params", ".", "decode_length", "\n", "beam_size", "=", "params", ".", "beam_size", "\n", "top_beams", "=", "params", ".", "top_beams", "\n", "alpha", "=", "params", ".", "decode_alpha", "\n", "\n", "# Compute initial state if necessary", "\n", "states", "=", "[", "]", "\n", "funcs", "=", "[", "]", "\n", "\n", "for", "model_fn", "in", "model_fns", ":", "\n", "        ", "if", "callable", "(", "model_fn", ")", ":", "\n", "# For non-incremental decoding", "\n", "            ", "states", ".", "append", "(", "{", "}", ")", "\n", "funcs", ".", "append", "(", "model_fn", ")", "\n", "", "else", ":", "\n", "# For incremental decoding where model_fn is a tuple:", "\n", "# (encoding_fn, decoding_fn)", "\n", "            ", "states", ".", "append", "(", "model_fn", "[", "0", "]", "(", "features", ")", ")", "\n", "funcs", ".", "append", "(", "model_fn", "[", "1", "]", ")", "\n", "\n", "", "", "batch_size", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "0", "]", "\n", "pad_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "pad", "]", "\n", "bos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "bos", "]", "\n", "eos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "eos", "]", "\n", "\n", "# Expand the inputs", "\n", "# [batch, length] => [batch, beam_size, length]", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"source\"", "]", ",", "1", ")", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"source\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "# For source sequence length", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"source_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "[", "1", ",", "beam_size", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"source_length\"", "]", ")", "\n", "\n", "max_length", "=", "features", "[", "\"source_length\"", "]", "+", "decode_length", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "]", ")", "\n", "decoding_fn", "=", "_get_inference_fn", "(", "funcs", ",", "features", ")", "\n", "states", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "x", ":", "utils", ".", "tile_to_beam_size", "(", "x", ",", "beam_size", ")", ",", "\n", "states", ")", "\n", "\n", "seqs", ",", "scores", "=", "beam_search", "(", "decoding_fn", ",", "states", ",", "batch_size", ",", "beam_size", ",", "\n", "max_length", ",", "alpha", ",", "pad_id", ",", "bos_id", ",", "eos_id", ")", "\n", "print", "(", "\"seqs\"", ",", "seqs", "[", ":", ",", ":", "top_beams", ",", "1", ":", "]", ")", "\n", "print", "(", "\"scores\"", ",", "scores", "[", ":", ",", ":", "top_beams", "]", ")", "\n", "return", "seqs", "[", ":", ",", ":", "top_beams", ",", "1", ":", "]", ",", "scores", "[", ":", ",", ":", "top_beams", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.enable_distributed_training": [[13, 23], ["hvd.init", "sys.stderr.write", "exit"], "function", ["None"], ["def", "enable_distributed_training", "(", ")", ":", "\n", "    ", "global", "_ENGINE", "\n", "try", ":", "\n", "        ", "import", "horovod", ".", "tensorflow", "as", "hvd", "\n", "_ENGINE", "=", "hvd", "\n", "hvd", ".", "init", "(", ")", "\n", "", "except", "ImportError", ":", "\n", "        ", "sys", ".", "stderr", ".", "write", "(", "\"Error: You must install horovod first in order to\"", "\n", "\" enable distributed training.\\n\"", ")", "\n", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.is_distributed_training_mode": [[25, 27], ["None"], "function", ["None"], ["", "", "def", "is_distributed_training_mode", "(", ")", ":", "\n", "    ", "return", "_ENGINE", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.rank": [[29, 31], ["_ENGINE.rank"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.rank"], ["", "def", "rank", "(", ")", ":", "\n", "    ", "return", "_ENGINE", ".", "rank", "(", ")", "if", "_ENGINE", "is", "not", "None", "else", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.local_rank": [[33, 35], ["_ENGINE.local_rank"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.local_rank"], ["", "def", "local_rank", "(", ")", ":", "\n", "    ", "return", "_ENGINE", ".", "local_rank", "(", ")", "if", "_ENGINE", "is", "not", "None", "else", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.size": [[37, 39], ["_ENGINE.size"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.size"], ["", "def", "size", "(", ")", ":", "\n", "    ", "return", "_ENGINE", ".", "size", "(", ")", "if", "_ENGINE", "is", "not", "None", "else", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.all_reduce": [[41, 46], ["_ENGINE.allreduce"], "function", ["None"], ["", "def", "all_reduce", "(", "tensor", ")", ":", "\n", "    ", "if", "_ENGINE", "is", "None", ":", "\n", "        ", "return", "tensor", "\n", "\n", "", "return", "_ENGINE", ".", "allreduce", "(", "tensor", ",", "compression", "=", "_ENGINE", ".", "Compression", ".", "fp16", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.get_broadcast_hook": [[48, 52], ["_ENGINE.BroadcastGlobalVariablesHook"], "function", ["None"], ["", "def", "get_broadcast_hook", "(", ")", ":", "\n", "    ", "if", "not", "_ENGINE", ":", "\n", "        ", "return", "None", "\n", "", "return", "_ENGINE", ".", "BroadcastGlobalVariablesHook", "(", "0", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.infer_shape": [[11, 29], ["tensorflow.convert_to_tensor", "tf.convert_to_tensor.shape.as_list", "tensorflow.shape", "range", "tensorflow.shape", "len", "ret.append"], "function", ["None"], ["def", "infer_shape", "(", "x", ")", ":", "\n", "    ", "x", "=", "tf", ".", "convert_to_tensor", "(", "x", ")", "\n", "\n", "# If unknown rank, return dynamic shape", "\n", "if", "x", ".", "shape", ".", "dims", "is", "None", ":", "\n", "        ", "return", "tf", ".", "shape", "(", "x", ")", "\n", "\n", "", "static_shape", "=", "x", ".", "shape", ".", "as_list", "(", ")", "\n", "dynamic_shape", "=", "tf", ".", "shape", "(", "x", ")", "\n", "\n", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "static_shape", ")", ")", ":", "\n", "        ", "dim", "=", "static_shape", "[", "i", "]", "\n", "if", "dim", "is", "None", ":", "\n", "            ", "dim", "=", "dynamic_shape", "[", "i", "]", "\n", "", "ret", ".", "append", "(", "dim", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.infer_shape_invariants": [[31, 36], ["tensor.shape.as_list", "range", "tensorflow.TensorShape", "len"], "function", ["None"], ["", "def", "infer_shape_invariants", "(", "tensor", ")", ":", "\n", "    ", "shape", "=", "tensor", ".", "shape", ".", "as_list", "(", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "shape", ")", "-", "1", ")", ":", "\n", "        ", "shape", "[", "i", "]", "=", "None", "\n", "", "return", "tf", ".", "TensorShape", "(", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.merge_first_two_dims": [[38, 43], ["common.infer_shape", "infer_shape.pop", "tensorflow.reshape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.infer_shape"], ["", "def", "merge_first_two_dims", "(", "tensor", ")", ":", "\n", "    ", "shape", "=", "infer_shape", "(", "tensor", ")", "\n", "shape", "[", "0", "]", "*=", "shape", "[", "1", "]", "\n", "shape", ".", "pop", "(", "1", ")", "\n", "return", "tf", ".", "reshape", "(", "tensor", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.split_first_two_dims": [[45, 49], ["common.infer_shape", "tensorflow.reshape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.infer_shape"], ["", "def", "split_first_two_dims", "(", "tensor", ",", "dim_0", ",", "dim_1", ")", ":", "\n", "    ", "shape", "=", "infer_shape", "(", "tensor", ")", "\n", "new_shape", "=", "[", "dim_0", "]", "+", "[", "dim_1", "]", "+", "shape", "[", "1", ":", "]", "\n", "return", "tf", ".", "reshape", "(", "tensor", ",", "new_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.tile_to_beam_size": [[51, 58], ["tensorflow.expand_dims", "tensorflow.tile"], "function", ["None"], ["", "def", "tile_to_beam_size", "(", "tensor", ",", "beam_size", ")", ":", "\n", "    ", "\"\"\"Tiles a given tensor by beam_size. \"\"\"", "\n", "tensor", "=", "tf", ".", "expand_dims", "(", "tensor", ",", "axis", "=", "1", ")", "\n", "tile_dims", "=", "[", "1", "]", "*", "tensor", ".", "shape", ".", "ndims", "\n", "tile_dims", "[", "1", "]", "=", "beam_size", "\n", "\n", "return", "tf", ".", "tile", "(", "tensor", ",", "tile_dims", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.tile_batch": [[60, 69], ["common.infer_shape", "tensorflow.tile", "tensorflow.reshape", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.infer_shape"], ["", "def", "tile_batch", "(", "tensor", ",", "batch_size", ")", ":", "\n", "    ", "shape", "=", "infer_shape", "(", "tensor", ")", "\n", "tile_dims", "=", "[", "1", "]", "*", "(", "tensor", ".", "shape", ".", "ndims", "+", "1", ")", "\n", "tile_dims", "[", "1", "]", "=", "batch_size", "\n", "\n", "tensor", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tensor", ",", "axis", "=", "1", ")", ",", "tile_dims", ")", "\n", "shape", "[", "0", "]", "=", "shape", "[", "0", "]", "*", "batch_size", "\n", "\n", "return", "tf", ".", "reshape", "(", "tensor", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d": [[71, 86], ["tensorflow.reshape", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.shape", "tensorflow.shape", "tensorflow.range"], "function", ["None"], ["", "def", "gather_2d", "(", "params", ",", "indices", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\" Gather the 2nd dimension given indices\n    :param params: A tensor with shape [batch_size, M, ...]\n    :param indices: A tensor with shape [batch_size, N]\n    :param name: An optional string\n    :return: A tensor with shape [batch_size, N, ...]\n    \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "params", ")", "[", "0", "]", "\n", "range_size", "=", "tf", ".", "shape", "(", "indices", ")", "[", "1", "]", "\n", "batch_pos", "=", "tf", ".", "range", "(", "batch_size", "*", "range_size", ")", "//", "range_size", "\n", "batch_pos", "=", "tf", ".", "reshape", "(", "batch_pos", ",", "[", "batch_size", ",", "range_size", "]", ")", "\n", "indices", "=", "tf", ".", "stack", "(", "[", "batch_pos", ",", "indices", "]", ",", "axis", "=", "-", "1", ")", "\n", "output", "=", "tf", ".", "gather_nd", "(", "params", ",", "indices", ",", "name", "=", "name", ")", "\n", "\n", "return", "output", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference._get_inference_fn": [[21, 51], ["zip", "tensorflow.pad", "tensorflow.fill", "tensorflow.add_n", "float", "model_fn", "outputs.append", "next_state.append", "model_fn", "outputs.append", "next_state.append", "len", "tensorflow.shape", "tensorflow.shape"], "function", ["None"], ["", "def", "_get_inference_fn", "(", "model_fns", ",", "features", ")", ":", "\n", "    ", "def", "inference_fn", "(", "inputs", ",", "state", ")", ":", "\n", "        ", "local_features", "=", "{", "\n", "\"source\"", ":", "features", "[", "\"source\"", "]", ",", "\n", "\"source_length\"", ":", "features", "[", "\"source_length\"", "]", ",", "\n", "\"context_dia_src\"", ":", "features", "[", "\"context_dia_src\"", "]", ",", "\n", "\"context_dia_tgt\"", ":", "features", "[", "\"context_dia_tgt\"", "]", ",", "\n", "\"context_sty_src\"", ":", "features", "[", "\"context_sty_src\"", "]", ",", "\n", "\"context_sty_tgt\"", ":", "features", "[", "\"context_sty_tgt\"", "]", ",", "\n", "\"context_source\"", ":", "features", "[", "\"context_source\"", "]", ",", "\n", "\"context_dia_src_length\"", ":", "features", "[", "\"context_dia_src_length\"", "]", ",", "\n", "\"context_dia_tgt_length\"", ":", "features", "[", "\"context_dia_tgt_length\"", "]", ",", "\n", "\"context_sty_src_length\"", ":", "features", "[", "\"context_sty_src_length\"", "]", ",", "\n", "\"context_sty_tgt_length\"", ":", "features", "[", "\"context_sty_tgt_length\"", "]", ",", "\n", "\"context_source_length\"", ":", "features", "[", "\"context_source_length\"", "]", ",", "\n", "\"position_dia_src\"", ":", "features", "[", "\"position_dia_src\"", "]", ",", "\n", "\"position_dia_tgt\"", ":", "features", "[", "\"position_dia_tgt\"", "]", ",", "\n", "\"position_sty_src\"", ":", "features", "[", "\"position_sty_src\"", "]", ",", "\n", "\"position_sty_tgt\"", ":", "features", "[", "\"position_sty_tgt\"", "]", ",", "\n", "\"position_ctx_src\"", ":", "features", "[", "\"position_ctx_src\"", "]", ",", "\n", "\"sample\"", ":", "features", "[", "\"sample\"", "]", ",", "\n", "\"sample_length\"", ":", "features", "[", "\"sample_length\"", "]", ",", "\n", "# [bos_id, ...] => [..., 0]", "\n", "\"target\"", ":", "tf", ".", "pad", "(", "inputs", "[", ":", ",", "1", ":", "]", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "1", "]", "]", ")", ",", "\n", "\"target_length\"", ":", "tf", ".", "fill", "(", "[", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "]", ",", "\n", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", ")", "\n", "}", "\n", "\n", "outputs", "=", "[", "]", "\n", "next_state", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference._beam_search_step": [[53, 127], ["thumt.merge_first_two_dims", "tensorflow.python.util.nest.map_structure", "func", "thumt.split_first_two_dims", "tensorflow.python.util.nest.map_structure", "tensorflow.pow", "tensorflow.reshape", "tensorflow.nn.top_k", "thumt.gather_2d", "tensorflow.concat", "tensorflow.equal", "tensorflow.nn.top_k", "thumt.gather_2d", "thumt.gather_2d", "thumt.gather_2d", "tensorflow.concat", "tensorflow.python.util.nest.map_structure", "tensorflow.concat", "tensorflow.concat", "tensorflow.nn.top_k", "thumt.gather_2d", "tensorflow.fill", "tensorflow.concat", "tensorflow.concat", "thumt.gather_2d", "inference.BeamSearchState", "tensorflow.expand_dims", "tensorflow.constant", "thumt.merge_first_two_dims", "thumt.split_first_two_dims", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.to_float", "tensorflow.expand_dims", "thumt.gather_2d", "tensorflow.to_float", "tensorflow.to_float"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.merge_first_two_dims", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.split_first_two_dims", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.merge_first_two_dims", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.split_first_two_dims", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d"], ["            ", "if", "model_state", ":", "\n", "                ", "output", ",", "new_state", "=", "model_fn", "(", "local_features", ",", "model_state", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "next_state", ".", "append", "(", "new_state", ")", "\n", "", "else", ":", "\n", "                ", "output", "=", "model_fn", "(", "local_features", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "next_state", ".", "append", "(", "{", "}", ")", "\n", "\n", "# Ensemble", "\n", "", "", "log_prob", "=", "tf", ".", "add_n", "(", "outputs", ")", "/", "float", "(", "len", "(", "outputs", ")", ")", "\n", "\n", "return", "log_prob", ",", "next_state", "\n", "\n", "", "return", "inference_fn", "\n", "\n", "\n", "", "def", "_beam_search_step", "(", "time", ",", "func", ",", "state", ",", "batch_size", ",", "beam_size", ",", "alpha", ",", "\n", "pad_id", ",", "eos_id", ")", ":", "\n", "# Compute log probabilities", "\n", "    ", "seqs", ",", "log_probs", "=", "state", ".", "inputs", "[", ":", "2", "]", "\n", "flat_seqs", "=", "utils", ".", "merge_first_two_dims", "(", "seqs", ")", "\n", "flat_state", "=", "nest", ".", "map_structure", "(", "lambda", "x", ":", "utils", ".", "merge_first_two_dims", "(", "x", ")", ",", "\n", "state", ".", "state", ")", "\n", "step_log_probs", ",", "next_state", "=", "func", "(", "flat_seqs", ",", "flat_state", ")", "\n", "step_log_probs", "=", "utils", ".", "split_first_two_dims", "(", "step_log_probs", ",", "batch_size", ",", "\n", "beam_size", ")", "\n", "next_state", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "x", ":", "utils", ".", "split_first_two_dims", "(", "x", ",", "batch_size", ",", "beam_size", ")", ",", "\n", "next_state", ")", "\n", "curr_log_probs", "=", "tf", ".", "expand_dims", "(", "log_probs", ",", "2", ")", "+", "step_log_probs", "\n", "\n", "# Apply length penalty", "\n", "length_penalty", "=", "tf", ".", "pow", "(", "(", "5.0", "+", "tf", ".", "to_float", "(", "time", "+", "1", ")", ")", "/", "6.0", ",", "alpha", ")", "\n", "curr_scores", "=", "curr_log_probs", "/", "length_penalty", "\n", "vocab_size", "=", "curr_scores", ".", "shape", "[", "-", "1", "]", ".", "value", "or", "tf", ".", "shape", "(", "curr_scores", ")", "[", "-", "1", "]", "\n", "\n", "# Select top-k candidates", "\n", "# [batch_size, beam_size * vocab_size]", "\n", "curr_scores", "=", "tf", ".", "reshape", "(", "curr_scores", ",", "[", "-", "1", ",", "beam_size", "*", "vocab_size", "]", ")", "\n", "# [batch_size, 2 * beam_size]", "\n", "top_scores", ",", "top_indices", "=", "tf", ".", "nn", ".", "top_k", "(", "curr_scores", ",", "k", "=", "2", "*", "beam_size", ")", "\n", "# Shape: [batch_size, 2 * beam_size]", "\n", "beam_indices", "=", "top_indices", "//", "vocab_size", "\n", "symbol_indices", "=", "top_indices", "%", "vocab_size", "\n", "# Expand sequences", "\n", "# [batch_size, 2 * beam_size, time]", "\n", "candidate_seqs", "=", "utils", ".", "gather_2d", "(", "seqs", ",", "beam_indices", ")", "\n", "candidate_seqs", "=", "tf", ".", "concat", "(", "[", "candidate_seqs", ",", "\n", "tf", ".", "expand_dims", "(", "symbol_indices", ",", "2", ")", "]", ",", "2", ")", "\n", "\n", "# Expand sequences", "\n", "# Suppress finished sequences", "\n", "flags", "=", "tf", ".", "equal", "(", "symbol_indices", ",", "eos_id", ")", "\n", "# [batch, 2 * beam_size]", "\n", "alive_scores", "=", "top_scores", "+", "tf", ".", "to_float", "(", "flags", ")", "*", "tf", ".", "float32", ".", "min", "\n", "# [batch, beam_size]", "\n", "alive_scores", ",", "alive_indices", "=", "tf", ".", "nn", ".", "top_k", "(", "alive_scores", ",", "beam_size", ")", "\n", "alive_symbols", "=", "utils", ".", "gather_2d", "(", "symbol_indices", ",", "alive_indices", ")", "\n", "alive_indices", "=", "utils", ".", "gather_2d", "(", "beam_indices", ",", "alive_indices", ")", "\n", "alive_seqs", "=", "utils", ".", "gather_2d", "(", "seqs", ",", "alive_indices", ")", "\n", "# [batch_size, beam_size, time + 1]", "\n", "alive_seqs", "=", "tf", ".", "concat", "(", "[", "alive_seqs", ",", "tf", ".", "expand_dims", "(", "alive_symbols", ",", "2", ")", "]", ",", "2", ")", "\n", "alive_state", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "x", ":", "utils", ".", "gather_2d", "(", "x", ",", "alive_indices", ")", ",", "\n", "next_state", ")", "\n", "alive_log_probs", "=", "alive_scores", "*", "length_penalty", "\n", "\n", "# Select finished sequences", "\n", "prev_fin_flags", ",", "prev_fin_seqs", ",", "prev_fin_scores", "=", "state", ".", "finish", "\n", "# [batch, 2 * beam_size]", "\n", "step_fin_scores", "=", "top_scores", "+", "(", "1.0", "-", "tf", ".", "to_float", "(", "flags", ")", ")", "*", "tf", ".", "float32", ".", "min", "\n", "# [batch, 3 * beam_size]", "\n", "fin_flags", "=", "tf", ".", "concat", "(", "[", "prev_fin_flags", ",", "flags", "]", ",", "axis", "=", "1", ")", "\n", "fin_scores", "=", "tf", ".", "concat", "(", "[", "prev_fin_scores", ",", "step_fin_scores", "]", ",", "axis", "=", "1", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference.beam_search": [[129, 202], ["tensorflow.fill", "tensorflow.constant", "tensorflow.tile", "tensorflow.zeros_like", "tensorflow.zeros", "tensorflow.fill", "tensorflow.zeros", "inference.BeamSearchState", "tensorflow.reduce_max", "tensorflow.constant", "inference.BeamSearchState", "tensorflow.while_loop", "alive_seqs.set_shape", "tf.where.set_shape", "tensorflow.where", "tensorflow.where", "tensorflow.pow", "tensorflow.reduce_min", "tensorflow.reduce_all", "tensorflow.logical_and", "inference._beam_search_step", "tensorflow.reduce_any", "tensorflow.reduce_any", "tensorflow.to_float", "tensorflow.greater", "tensorflow.less", "tensorflow.logical_not", "tensorflow.python.util.nest.map_structure", "tensorflow.to_float", "tensorflow.reduce_any", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.to_float"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._beam_search_step"], ["fin_scores", ",", "fin_indices", "=", "tf", ".", "nn", ".", "top_k", "(", "fin_scores", ",", "beam_size", ")", "\n", "fin_flags", "=", "utils", ".", "gather_2d", "(", "fin_flags", ",", "fin_indices", ")", "\n", "pad_seqs", "=", "tf", ".", "fill", "(", "[", "batch_size", ",", "beam_size", ",", "1", "]", ",", "\n", "tf", ".", "constant", "(", "pad_id", ",", "tf", ".", "int32", ")", ")", "\n", "prev_fin_seqs", "=", "tf", ".", "concat", "(", "[", "prev_fin_seqs", ",", "pad_seqs", "]", ",", "axis", "=", "2", ")", "\n", "fin_seqs", "=", "tf", ".", "concat", "(", "[", "prev_fin_seqs", ",", "candidate_seqs", "]", ",", "axis", "=", "1", ")", "\n", "fin_seqs", "=", "utils", ".", "gather_2d", "(", "fin_seqs", ",", "fin_indices", ")", "\n", "\n", "new_state", "=", "BeamSearchState", "(", "\n", "inputs", "=", "(", "alive_seqs", ",", "alive_log_probs", ",", "alive_scores", ")", ",", "\n", "state", "=", "alive_state", ",", "\n", "finish", "=", "(", "fin_flags", ",", "fin_seqs", ",", "fin_scores", ")", ",", "\n", ")", "\n", "\n", "return", "time", "+", "1", ",", "new_state", "\n", "\n", "\n", "", "def", "beam_search", "(", "func", ",", "state", ",", "batch_size", ",", "beam_size", ",", "max_length", ",", "alpha", ",", "\n", "pad_id", ",", "bos_id", ",", "eos_id", ")", ":", "\n", "    ", "init_seqs", "=", "tf", ".", "fill", "(", "[", "batch_size", ",", "beam_size", ",", "1", "]", ",", "bos_id", ")", "\n", "init_log_probs", "=", "tf", ".", "constant", "(", "[", "[", "0.", "]", "+", "[", "tf", ".", "float32", ".", "min", "]", "*", "(", "beam_size", "-", "1", ")", "]", ")", "\n", "init_log_probs", "=", "tf", ".", "tile", "(", "init_log_probs", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "init_scores", "=", "tf", ".", "zeros_like", "(", "init_log_probs", ")", "\n", "fin_seqs", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "beam_size", ",", "1", "]", ",", "tf", ".", "int32", ")", "\n", "fin_scores", "=", "tf", ".", "fill", "(", "[", "batch_size", ",", "beam_size", "]", ",", "tf", ".", "float32", ".", "min", ")", "\n", "fin_flags", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "beam_size", "]", ",", "tf", ".", "bool", ")", "\n", "\n", "state", "=", "BeamSearchState", "(", "\n", "inputs", "=", "(", "init_seqs", ",", "init_log_probs", ",", "init_scores", ")", ",", "\n", "state", "=", "state", ",", "\n", "finish", "=", "(", "fin_flags", ",", "fin_seqs", ",", "fin_scores", ")", ",", "\n", ")", "\n", "\n", "max_step", "=", "tf", ".", "reduce_max", "(", "max_length", ")", "\n", "\n", "def", "_is_finished", "(", "t", ",", "s", ")", ":", "\n", "        ", "log_probs", "=", "s", ".", "inputs", "[", "1", "]", "\n", "finished_flags", "=", "s", ".", "finish", "[", "0", "]", "\n", "finished_scores", "=", "s", ".", "finish", "[", "2", "]", "\n", "max_lp", "=", "tf", ".", "pow", "(", "(", "(", "5.0", "+", "tf", ".", "to_float", "(", "max_step", ")", ")", "/", "6.0", ")", ",", "alpha", ")", "\n", "best_alive_score", "=", "log_probs", "[", ":", ",", "0", "]", "/", "max_lp", "\n", "worst_finished_score", "=", "tf", ".", "reduce_min", "(", "\n", "finished_scores", "*", "tf", ".", "to_float", "(", "finished_flags", ")", ",", "axis", "=", "1", ")", "\n", "add_mask", "=", "1.0", "-", "tf", ".", "to_float", "(", "tf", ".", "reduce_any", "(", "finished_flags", ",", "1", ")", ")", "\n", "worst_finished_score", "+=", "tf", ".", "float32", ".", "min", "*", "add_mask", "\n", "bound_is_met", "=", "tf", ".", "reduce_all", "(", "tf", ".", "greater", "(", "worst_finished_score", ",", "\n", "best_alive_score", ")", ")", "\n", "\n", "cond", "=", "tf", ".", "logical_and", "(", "tf", ".", "less", "(", "t", ",", "max_step", ")", ",", "\n", "tf", ".", "logical_not", "(", "bound_is_met", ")", ")", "\n", "\n", "return", "cond", "\n", "\n", "", "def", "_loop_fn", "(", "t", ",", "s", ")", ":", "\n", "        ", "outs", "=", "_beam_search_step", "(", "t", ",", "func", ",", "s", ",", "batch_size", ",", "beam_size", ",", "alpha", ",", "\n", "pad_id", ",", "eos_id", ")", "\n", "return", "outs", "\n", "\n", "", "time", "=", "tf", ".", "constant", "(", "0", ",", "name", "=", "\"time\"", ")", "\n", "shape_invariants", "=", "BeamSearchState", "(", "\n", "inputs", "=", "(", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "None", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ")", ",", "\n", "state", "=", "nest", ".", "map_structure", "(", "utils", ".", "infer_shape_invariants", ",", "state", ".", "state", ")", ",", "\n", "finish", "=", "(", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "None", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ")", "\n", ")", "\n", "outputs", "=", "tf", ".", "while_loop", "(", "_is_finished", ",", "_loop_fn", ",", "[", "time", ",", "state", "]", ",", "\n", "shape_invariants", "=", "[", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "shape_invariants", "]", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "back_prop", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference.create_inference_graph": [[204, 266], ["copy.copy", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "inference._get_inference_fn", "tensorflow.python.util.nest.map_structure", "inference.beam_search", "isinstance", "ValueError", "model.get_inference_func", "callable", "tensorflow.shape", "nest.map_structure.append", "funcs.append", "nest.map_structure.append", "funcs.append", "thumt.tile_to_beam_size"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.sampling._get_inference_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.search.beam_search", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_inference_func", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.tile_to_beam_size"], ["alive_seqs", "=", "final_state", ".", "inputs", "[", "0", "]", "\n", "alive_scores", "=", "final_state", ".", "inputs", "[", "2", "]", "\n", "final_flags", "=", "final_state", ".", "finish", "[", "0", "]", "\n", "final_seqs", "=", "final_state", ".", "finish", "[", "1", "]", "\n", "final_scores", "=", "final_state", ".", "finish", "[", "2", "]", "\n", "\n", "alive_seqs", ".", "set_shape", "(", "[", "None", ",", "beam_size", ",", "None", "]", ")", "\n", "final_seqs", ".", "set_shape", "(", "[", "None", ",", "beam_size", ",", "None", "]", ")", "\n", "\n", "final_seqs", "=", "tf", ".", "where", "(", "tf", ".", "reduce_any", "(", "final_flags", ",", "1", ")", ",", "final_seqs", ",", "\n", "alive_seqs", ")", "\n", "final_scores", "=", "tf", ".", "where", "(", "tf", ".", "reduce_any", "(", "final_flags", ",", "1", ")", ",", "final_scores", ",", "\n", "alive_scores", ")", "\n", "\n", "return", "final_seqs", ",", "final_scores", "\n", "\n", "\n", "", "def", "create_inference_graph", "(", "models", ",", "features", ",", "params", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "models", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"'models' must be a list or tuple\"", ")", "\n", "\n", "", "features", "=", "copy", ".", "copy", "(", "features", ")", "\n", "model_fns", "=", "[", "model", ".", "get_inference_func", "(", ")", "for", "model", "in", "models", "]", "\n", "\n", "decode_length", "=", "params", ".", "decode_length", "\n", "beam_size", "=", "params", ".", "beam_size", "\n", "top_beams", "=", "params", ".", "top_beams", "\n", "alpha", "=", "params", ".", "decode_alpha", "\n", "\n", "# Compute initial state if necessary", "\n", "states", "=", "[", "]", "\n", "funcs", "=", "[", "]", "\n", "\n", "for", "model_fn", "in", "model_fns", ":", "\n", "        ", "if", "callable", "(", "model_fn", ")", ":", "\n", "# For non-incremental decoding", "\n", "            ", "states", ".", "append", "(", "{", "}", ")", "\n", "funcs", ".", "append", "(", "model_fn", ")", "\n", "", "else", ":", "\n", "# For incremental decoding where model_fn is a tuple:", "\n", "# (encoding_fn, decoding_fn)", "\n", "            ", "states", ".", "append", "(", "model_fn", "[", "0", "]", "(", "features", ")", ")", "\n", "funcs", ".", "append", "(", "model_fn", "[", "1", "]", ")", "\n", "\n", "", "", "batch_size", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "0", "]", "\n", "pad_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "pad", "]", "\n", "bos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "bos", "]", "\n", "eos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "eos", "]", "\n", "\n", "# Expand the inputs", "\n", "# [batch, length] => [batch, beam_size, length]", "\n", "features", "[", "\"context_source\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"context_source\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_source\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"context_source\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"context_source\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"context_source\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"context_source\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "# For source sequence length", "\n", "features", "[", "\"context_source_length\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"context_source_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_source_length\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"context_source_length\"", "]", ",", "\n", "[", "1", ",", "beam_size", "]", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.bleu.closest_length": [[13, 29], ["len", "len", "abs"], "function", ["None"], ["def", "closest_length", "(", "candidate", ",", "references", ")", ":", "\n", "    ", "clen", "=", "len", "(", "candidate", ")", "\n", "closest_diff", "=", "9999", "\n", "closest_len", "=", "9999", "\n", "\n", "for", "reference", "in", "references", ":", "\n", "        ", "rlen", "=", "len", "(", "reference", ")", "\n", "diff", "=", "abs", "(", "rlen", "-", "clen", ")", "\n", "\n", "if", "diff", "<", "closest_diff", ":", "\n", "            ", "closest_diff", "=", "diff", "\n", "closest_len", "=", "rlen", "\n", "", "elif", "diff", "==", "closest_diff", ":", "\n", "            ", "closest_len", "=", "rlen", "if", "rlen", "<", "closest_len", "else", "closest_len", "\n", "\n", "", "", "return", "closest_len", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.bleu.shortest_length": [[31, 33], ["min", "len"], "function", ["None"], ["", "def", "shortest_length", "(", "references", ")", ":", "\n", "    ", "return", "min", "(", "[", "len", "(", "ref", ")", "for", "ref", "in", "references", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.bleu.modified_precision": [[35, 58], ["collections.Counter", "collections.Counter.items", "len", "collections.Counter", "min", "float", "float", "len", "tuple", "tuple", "max", "sum", "sum", "range", "len", "range", "clipped_counts.values", "collections.Counter.values"], "function", ["None"], ["", "def", "modified_precision", "(", "candidate", ",", "references", ",", "n", ")", ":", "\n", "    ", "tngrams", "=", "len", "(", "candidate", ")", "+", "1", "-", "n", "\n", "counts", "=", "Counter", "(", "[", "tuple", "(", "candidate", "[", "i", ":", "i", "+", "n", "]", ")", "for", "i", "in", "range", "(", "tngrams", ")", "]", ")", "\n", "\n", "if", "len", "(", "counts", ")", "==", "0", ":", "\n", "        ", "return", "0", ",", "0", "\n", "\n", "", "max_counts", "=", "{", "}", "\n", "for", "reference", "in", "references", ":", "\n", "        ", "rngrams", "=", "len", "(", "reference", ")", "+", "1", "-", "n", "\n", "ngrams", "=", "[", "tuple", "(", "reference", "[", "i", ":", "i", "+", "n", "]", ")", "for", "i", "in", "range", "(", "rngrams", ")", "]", "\n", "ref_counts", "=", "Counter", "(", "ngrams", ")", "\n", "for", "ngram", "in", "counts", ":", "\n", "            ", "mcount", "=", "0", "if", "ngram", "not", "in", "max_counts", "else", "max_counts", "[", "ngram", "]", "\n", "rcount", "=", "0", "if", "ngram", "not", "in", "ref_counts", "else", "ref_counts", "[", "ngram", "]", "\n", "max_counts", "[", "ngram", "]", "=", "max", "(", "mcount", ",", "rcount", ")", "\n", "\n", "", "", "clipped_counts", "=", "{", "}", "\n", "\n", "for", "ngram", ",", "count", "in", "counts", ".", "items", "(", ")", ":", "\n", "        ", "clipped_counts", "[", "ngram", "]", "=", "min", "(", "count", ",", "max_counts", "[", "ngram", "]", ")", "\n", "\n", "", "return", "float", "(", "sum", "(", "clipped_counts", ".", "values", "(", ")", ")", ")", ",", "float", "(", "sum", "(", "counts", ".", "values", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.bleu.brevity_penalty": [[60, 76], ["zip", "math.exp", "len", "min", "bleu.shortest_length", "bleu.closest_length"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.bleu.shortest_length", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.bleu.closest_length"], ["", "def", "brevity_penalty", "(", "trans", ",", "refs", ",", "mode", "=", "\"closest\"", ")", ":", "\n", "    ", "bp_c", "=", "0.0", "\n", "bp_r", "=", "0.0", "\n", "\n", "for", "candidate", ",", "references", "in", "zip", "(", "trans", ",", "refs", ")", ":", "\n", "        ", "bp_c", "+=", "len", "(", "candidate", ")", "\n", "\n", "if", "mode", "==", "\"shortest\"", ":", "\n", "            ", "bp_r", "+=", "shortest_length", "(", "references", ")", "\n", "", "else", ":", "\n", "            ", "bp_r", "+=", "closest_length", "(", "candidate", ",", "references", ")", "\n", "\n", "# Prevent zero divide", "\n", "", "", "bp_c", "=", "bp_c", "or", "1.0", "\n", "\n", "return", "math", ".", "exp", "(", "min", "(", "0", ",", "1.0", "-", "bp_r", "/", "bp_c", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.bleu.bleu": [[78, 113], ["zip", "range", "bleu.brevity_penalty", "range", "sum", "math.exp", "range", "range", "bleu.modified_precision", "range", "math.log", "len", "ValueError", "sum", "float", "float", "float", "range"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.bleu.brevity_penalty", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.bleu.modified_precision"], ["", "def", "bleu", "(", "trans", ",", "refs", ",", "bp", "=", "\"closest\"", ",", "smooth", "=", "False", ",", "n", "=", "4", ",", "weights", "=", "None", ")", ":", "\n", "    ", "p_norm", "=", "[", "0", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "p_denorm", "=", "[", "0", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "\n", "for", "candidate", ",", "references", "in", "zip", "(", "trans", ",", "refs", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "ccount", ",", "tcount", "=", "modified_precision", "(", "candidate", ",", "references", ",", "i", "+", "1", ")", "\n", "p_norm", "[", "i", "]", "+=", "ccount", "\n", "p_denorm", "[", "i", "]", "+=", "tcount", "\n", "\n", "", "", "bleu_n", "=", "[", "0", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "# add one smoothing", "\n", "        ", "if", "smooth", "and", "i", ">", "0", ":", "\n", "            ", "p_norm", "[", "i", "]", "+=", "1", "\n", "p_denorm", "[", "i", "]", "+=", "1", "\n", "\n", "", "if", "p_norm", "[", "i", "]", "==", "0", "or", "p_denorm", "[", "i", "]", "==", "0", ":", "\n", "            ", "bleu_n", "[", "i", "]", "=", "-", "9999", "\n", "", "else", ":", "\n", "            ", "bleu_n", "[", "i", "]", "=", "math", ".", "log", "(", "float", "(", "p_norm", "[", "i", "]", ")", "/", "float", "(", "p_denorm", "[", "i", "]", ")", ")", "\n", "\n", "", "", "if", "weights", ":", "\n", "        ", "if", "len", "(", "weights", ")", "!=", "n", ":", "\n", "            ", "raise", "ValueError", "(", "\"len(weights) != n: invalid weight number\"", ")", "\n", "", "log_precision", "=", "sum", "(", "[", "bleu_n", "[", "i", "]", "*", "weights", "[", "i", "]", "for", "i", "in", "range", "(", "n", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "log_precision", "=", "sum", "(", "bleu_n", ")", "/", "float", "(", "n", ")", "\n", "\n", "", "bp", "=", "brevity_penalty", "(", "trans", ",", "refs", ",", "bp", ")", "\n", "\n", "score", "=", "bp", "*", "math", ".", "exp", "(", "log_precision", ")", "\n", "\n", "return", "score", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.weight_ratio.create_diagonal": [[17, 28], ["tensorflow.diag", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.shape", "tensorflow.ones"], "function", ["None"], ["def", "create_diagonal", "(", "output", ")", ":", "\n", "    ", "'''\n        output: (batchsize, dim)\n        diagonal matrix (batchsize, length, length)\n    '''", "\n", "length", "=", "tf", ".", "shape", "(", "output", ")", "[", "1", "]", "\n", "batchsize", "=", "tf", ".", "shape", "(", "output", ")", "[", "0", "]", "\n", "result", "=", "tf", ".", "diag", "(", "tf", ".", "ones", "(", "[", "length", "]", ")", ")", "\n", "result", "=", "tf", ".", "expand_dims", "(", "result", ",", "0", ")", "\n", "result", "=", "tf", ".", "tile", "(", "result", ",", "[", "batchsize", ",", "1", ",", "1", "]", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.weight_ratio.weight_ratio_mean": [[30, 45], ["tensorflow.cast", "tensorflow.shape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "weight_ratio.stabilize", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.stabilize"], ["", "def", "weight_ratio_mean", "(", "input", ",", "output", ",", "stab", "=", "0", ")", ":", "\n", "    ", "'''\n        inputs: (..., dim)\n        output: (..., 1)\n        weight ratios: [(..., dim)]\n    '''", "\n", "dim", "=", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "input", ")", "[", "-", "1", "]", ",", "tf", ".", "float32", ")", "\n", "output_shape", "=", "tf", ".", "shape", "(", "input", ")", "\n", "# Flatten to 2D", "\n", "inputs", "=", "tf", ".", "reshape", "(", "input", ",", "[", "-", "1", ",", "input", ".", "shape", "[", "-", "1", "]", ".", "value", "]", ")", "\n", "output", "=", "tf", ".", "reshape", "(", "output", ",", "[", "-", "1", ",", "output", ".", "shape", "[", "-", "1", "]", ".", "value", "]", ")", "\n", "\n", "w", "=", "inputs", "/", "dim", "/", "stabilize", "(", "output", ",", "stab", ")", "\n", "\n", "return", "tf", ".", "reshape", "(", "w", ",", "output_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.weight_ratio.stabilize": [[47, 54], ["tensorflow.sign", "tensorflow.equal", "tensorflow.cast", "tensorflow.zeros", "tensorflow.shape"], "function", ["None"], ["", "def", "stabilize", "(", "matrix", ",", "stab", ")", ":", "\n", "    ", "sign", "=", "tf", ".", "sign", "(", "matrix", ")", "\n", "zero_pos", "=", "tf", ".", "equal", "(", "sign", ",", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "sign", ")", ")", ")", "\n", "zero_pos", "=", "tf", ".", "cast", "(", "zero_pos", ",", "tf", ".", "float32", ")", "\n", "sign", "+=", "zero_pos", "\n", "result", "=", "matrix", "+", "stab", "*", "sign", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.weight_ratio.weight_ratio_linear": [[56, 84], ["range", "tensorflow.reshape", "range", "len", "len", "len", "tensorflow.concat", "output_shape.append", "tensorflow.reshape", "len", "weight_ratios.append", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "zip", "tensorflow.shape", "weight_ratio.stabilize", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.stabilize"], ["", "def", "weight_ratio_linear", "(", "inputs", ",", "weights", ",", "output", ",", "bias", "=", "None", ",", "stab", "=", "0", ")", ":", "\n", "    ", "'''\n        inputs: [(..., dim_in_i)]\n        weights: [(dim_in_i, dim_out)]\n        bias: [(dim_out)]\n        output: (..., dim_out)\n        weight ratios: [(..., dim_in_i, dim_out)]\n    '''", "\n", "assert", "len", "(", "inputs", ")", "==", "len", "(", "weights", ")", "\n", "output_shape", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "inputs", ")", ")", ":", "\n", "        ", "os", "=", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "inputs", "[", "i", "]", ")", ",", "tf", ".", "shape", "(", "weights", "[", "i", "]", ")", "[", "-", "1", ":", "]", "]", ",", "-", "1", ")", "\n", "output_shape", ".", "append", "(", "os", ")", "\n", "# Flatten to 2D", "\n", "", "inputs", "=", "[", "tf", ".", "reshape", "(", "inp", ",", "[", "-", "1", ",", "inp", ".", "shape", "[", "-", "1", "]", ".", "value", "]", ")", "for", "inp", "in", "inputs", "]", "\n", "output", "=", "tf", ".", "reshape", "(", "output", ",", "[", "-", "1", ",", "output", ".", "shape", "[", "-", "1", "]", ".", "value", "]", ")", "\n", "\n", "weight_ratios", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "inputs", ")", ")", ":", "\n", "        ", "r", "=", "tf", ".", "expand_dims", "(", "inputs", "[", "i", "]", ",", "-", "1", ")", "*", "tf", ".", "expand_dims", "(", "weights", "[", "i", "]", ",", "-", "3", ")", "\n", "w", "=", "r", "/", "tf", ".", "expand_dims", "(", "stabilize", "(", "output", ",", "stab", ")", ",", "-", "2", ")", "\n", "weight_ratios", ".", "append", "(", "w", ")", "\n", "\n", "", "weight_ratios", "=", "[", "tf", ".", "reshape", "(", "wr", ",", "os", ")", "\n", "for", "os", ",", "wr", "in", "zip", "(", "output_shape", ",", "weight_ratios", ")", "]", "\n", "\n", "return", "weight_ratios", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.weight_ratio.weight_ratio_weighted_sum": [[86, 112], ["tensorflow.reshape", "weight_ratio.create_diagonal", "range", "len", "len", "tensorflow.shape", "tensorflow.concat", "tensorflow.reshape", "len", "weight_ratios.append", "tensorflow.reshape", "weight_ratio.stabilize", "tensorflow.shape", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.weight_ratio.create_diagonal", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.stabilize"], ["", "def", "weight_ratio_weighted_sum", "(", "inputs", ",", "weights", ",", "output", ",", "stab", "=", "0", ",", "flatten", "=", "False", ")", ":", "\n", "    ", "'''\n        inputs: [(..., dim)]\n        weights: [scalar]\n        output: (..., dim)\n        weight_ratios: [(..., dim, dim)]\n    '''", "\n", "assert", "len", "(", "inputs", ")", "==", "len", "(", "weights", ")", "\n", "if", "flatten", ":", "\n", "        ", "output_shape", "=", "tf", ".", "shape", "(", "output", ")", "\n", "", "else", ":", "\n", "        ", "output_shape", "=", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "output", ")", ",", "tf", ".", "shape", "(", "output", ")", "[", "-", "1", ":", "]", "]", ",", "-", "1", ")", "\n", "# Flatten to 2D", "\n", "", "inputs", "=", "[", "tf", ".", "reshape", "(", "inp", ",", "[", "-", "1", ",", "tf", ".", "shape", "(", "inp", ")", "[", "-", "1", "]", "]", ")", "for", "inp", "in", "inputs", "]", "\n", "output", "=", "tf", ".", "reshape", "(", "output", ",", "[", "-", "1", ",", "tf", ".", "shape", "(", "output", ")", "[", "-", "1", "]", "]", ")", "\n", "\n", "weight_ratios", "=", "[", "]", "\n", "diag", "=", "create_diagonal", "(", "output", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "inputs", ")", ")", ":", "\n", "        ", "wr", "=", "inputs", "[", "i", "]", "*", "weights", "[", "i", "]", "/", "stabilize", "(", "output", ",", "stab", ")", "\n", "if", "not", "flatten", ":", "\n", "            ", "wr", "=", "tf", ".", "expand_dims", "(", "wr", ",", "-", "1", ")", "*", "diag", "\n", "", "weight_ratios", ".", "append", "(", "wr", ")", "\n", "\n", "", "weight_ratios", "=", "[", "tf", ".", "reshape", "(", "wr", ",", "output_shape", ")", "for", "wr", "in", "weight_ratios", "]", "\n", "return", "weight_ratios", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.weight_ratio.weight_ratio_maxpool": [[114, 154], ["tensorflow.constant", "tensorflow.concat", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.shape", "tensorflow.concat", "tensorflow.reshape", "tensorflow.argmax", "tensorflow.cast", "tensorflow.reshape", "tensorflow.sparse_to_dense", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.reshape", "tensorflow.sparse_to_dense", "tensorflow.reshape", "tensorflow.shape", "tensorflow.ones", "tensorflow.range", "tensorflow.ones", "tensorflow.shape", "tensorflow.range", "tensorflow.shape", "tensorflow.range", "tensorflow.shape", "tensorflow.shape"], "function", ["None"], ["", "def", "weight_ratio_maxpool", "(", "input", ",", "output", ",", "maxnum", ",", "flatten", "=", "False", ")", ":", "\n", "    ", "'''\n        inputs: (..., dim)\n        output: (..., dim/maxpart)\n        weight_ratios: (..., dim, dim/maxnum)\n    '''", "\n", "# Flatten to 2D", "\n", "maxnum", "=", "tf", ".", "constant", "(", "maxnum", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "weight_shape", "=", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "input", ")", ",", "tf", ".", "shape", "(", "output", ")", "[", "-", "1", ":", "]", "]", ",", "axis", "=", "-", "1", ")", "\n", "input", "=", "tf", ".", "reshape", "(", "input", ",", "[", "-", "1", ",", "input", ".", "shape", "[", "-", "1", "]", ".", "value", "]", ")", "\n", "output", "=", "tf", ".", "reshape", "(", "output", ",", "[", "-", "1", ",", "output", ".", "shape", "[", "-", "1", "]", ".", "value", "]", ")", "\n", "\n", "shape_inp", "=", "tf", ".", "shape", "(", "input", ")", "\n", "batch", "=", "shape_inp", "[", "0", "]", "\n", "dim_in", "=", "shape_inp", "[", "-", "1", "]", "\n", "shape", "=", "tf", ".", "concat", "(", "[", "shape_inp", "[", ":", "-", "1", "]", ",", "[", "shape_inp", "[", "-", "1", "]", "//", "maxnum", ",", "maxnum", "]", "]", ",", "\n", "axis", "=", "0", ")", "\n", "dim_out", "=", "shape", "[", "-", "2", "]", "\n", "value", "=", "tf", ".", "reshape", "(", "input", ",", "shape", ")", "\n", "\n", "pos", "=", "tf", ".", "argmax", "(", "value", ",", "-", "1", ")", "\n", "pos", "=", "tf", ".", "cast", "(", "pos", ",", "tf", ".", "int32", ")", "\n", "pos", "=", "tf", ".", "reshape", "(", "pos", ",", "[", "-", "1", "]", ")", "\n", "if", "flatten", ":", "\n", "        ", "indices", "=", "tf", ".", "range", "(", "tf", ".", "shape", "(", "pos", ")", "[", "0", "]", ")", "*", "maxnum", "+", "pos", "\n", "weight_ratio", "=", "tf", ".", "sparse_to_dense", "(", "indices", ",", "[", "batch", "*", "dim_in", "]", ",", "\n", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "indices", ")", ")", ")", "\n", "weight_ratio", "=", "tf", ".", "reshape", "(", "weight_ratio", ",", "weight_shape", "[", ":", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "        ", "indices", "=", "dim_out", "*", "pos", "+", "dim_in", "*", "tf", ".", "range", "(", "batch", "*", "dim_out", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", "\n", "indices", "=", "tf", ".", "reshape", "(", "indices", ",", "[", "-", "1", ",", "dim_out", "]", ")", "\n", "indices", "+=", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "dim_out", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "0", ")", "\n", "indices", "=", "tf", ".", "reshape", "(", "indices", ",", "[", "-", "1", "]", ")", "\n", "\n", "weight_ratio", "=", "tf", ".", "sparse_to_dense", "(", "indices", ",", "[", "batch", "*", "dim_in", "*", "dim_out", "]", ",", "\n", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "indices", ")", ")", ")", "\n", "weight_ratio", "=", "tf", ".", "reshape", "(", "weight_ratio", ",", "weight_shape", ")", "\n", "\n", "", "return", "weight_ratio", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.half.custom_getter": [[11, 21], ["getter", "tensorflow.cast"], "function", ["None"], ["def", "custom_getter", "(", "getter", ",", "name", ",", "shape", "=", "None", ",", "dtype", "=", "None", ",", "initializer", "=", "None", ",", "\n", "regularizer", "=", "None", ",", "trainable", "=", "True", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "var_dtype", "=", "tf", ".", "float32", "if", "trainable", "else", "dtype", "\n", "variable", "=", "getter", "(", "name", ",", "shape", ",", "dtype", "=", "var_dtype", ",", "initializer", "=", "initializer", ",", "\n", "regularizer", "=", "regularizer", ",", "trainable", "=", "trainable", ",", "\n", "*", "args", ",", "**", "kwargs", ")", "\n", "if", "trainable", "and", "dtype", "!=", "tf", ".", "float32", ":", "\n", "        ", "variable", "=", "tf", ".", "cast", "(", "variable", ",", "dtype", ")", "\n", "\n", "", "return", "variable", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.loss.get_loss": [[8, 14], ["thumt.mrt_loss", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.mrt_loss"], ["def", "get_loss", "(", "features", ",", "params", ",", "ce", ",", "tgt_mask", ")", ":", "\n", "    ", "if", "params", ".", "use_mrt", ":", "\n", "        ", "loss", "=", "mrt_utils", ".", "mrt_loss", "(", "features", ",", "params", ",", "ce", ",", "tgt_mask", ")", "\n", "", "else", ":", "\n", "        ", "loss", "=", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ")", "/", "tf", ".", "reduce_sum", "(", "tgt_mask", ")", "\n", "", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.LegacyGRUCell_encoder_v2n.__init__": [[267, 270], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.train_word2vec.MySentences.__init__"], ["def", "__init__", "(", "self", ",", "num_units", ",", "reuse", "=", "None", ")", ":", "\n", "        ", "super", "(", "LegacyGRUCell_encoder_v2n", ",", "self", ")", ".", "__init__", "(", "_reuse", "=", "reuse", ")", "\n", "self", ".", "_num_units", "=", "num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.LegacyGRUCell_encoder_v2n.__call__": [[271, 318], ["tensorflow.variable_scope", "tensorflow.ones", "lrp.linear_v2n", "tensorflow.nn.sigmoid", "lrp.linear_v2n", "tensorflow.nn.sigmoid", "tensorflow.concat", "lrp.linear_v2n", "tensorflow.split", "lrp.stabilize", "isinstance", "tensorflow.shape", "tensorflow.shape", "list", "list", "tensorflow.tanh", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.linear_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.linear_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.linear_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.stabilize"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "w_x_h_last", ",", "params", ",", "scope", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"gru_cell\"", ",", "\n", "values", "=", "[", "inputs", ",", "state", "]", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "inputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "inputs", "=", "[", "inputs", "]", "\n", "\n", "", "bs", "=", "tf", ".", "shape", "(", "w_x_h_last", ")", "[", "0", "]", "\n", "emb", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "-", "1", "]", "\n", "w_x_x", "=", "tf", ".", "ones", "(", "[", "bs", ",", "1", ",", "emb", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "all_inputs", "=", "list", "(", "inputs", ")", "+", "[", "state", "]", "\n", "r_linear", "=", "linear_v2n", "(", "all_inputs", ",", "self", ".", "_num_units", ",", "False", ",", "\n", "[", "w_x_x", ",", "w_x_h_last", "]", ",", "params", ",", "False", ",", "\n", "scope", "=", "\"reset_gate\"", ",", "d2", "=", "True", ")", "\n", "w_x_r", ",", "w_xlast_r", "=", "r_linear", "[", "\"weight_ratios\"", "]", "\n", "r", "=", "tf", ".", "nn", ".", "sigmoid", "(", "r_linear", "[", "\"output\"", "]", ")", "\n", "u_linear", "=", "linear_v2n", "(", "all_inputs", ",", "self", ".", "_num_units", ",", "False", ",", "\n", "[", "w_x_x", ",", "w_x_h_last", "]", ",", "params", ",", "False", ",", "\n", "scope", "=", "\"update_gate\"", ",", "d2", "=", "True", ")", "\n", "w_x_u", ",", "w_xlast_u", "=", "u_linear", "[", "\"weight_ratios\"", "]", "\n", "u", "=", "tf", ".", "nn", ".", "sigmoid", "(", "u_linear", "[", "\"output\"", "]", ")", "\n", "\n", "reseted", "=", "r", "*", "state", "\n", "w_x_reseted", "=", "w_x_r", "\n", "w_xlast_reseted", "=", "w_xlast_r", "\n", "\n", "w_tx_reseted", "=", "tf", ".", "concat", "(", "[", "w_x_reseted", ",", "w_xlast_reseted", "]", ",", "1", ")", "\n", "all_inputs", "=", "list", "(", "inputs", ")", "+", "[", "reseted", "]", "\n", "c_linear", "=", "linear_v2n", "(", "all_inputs", ",", "self", ".", "_num_units", ",", "True", ",", "\n", "[", "w_x_x", ",", "w_tx_reseted", "]", ",", "params", ",", "False", ",", "\n", "scope", "=", "\"candidate\"", ",", "d2", "=", "True", ")", "\n", "w_x_c_direct", ",", "w_tx_reseted_c", "=", "c_linear", "[", "\"weight_ratios\"", "]", "\n", "w_x_reseted_c", ",", "w_xlast_c", "=", "tf", ".", "split", "(", "w_tx_reseted_c", ",", "\n", "[", "1", ",", "tf", ".", "shape", "(", "w_tx_reseted_c", ")", "[", "1", "]", "-", "1", "]", ",", "\n", "axis", "=", "1", ")", "\n", "w_x_c", "=", "w_x_c_direct", "+", "w_x_reseted_c", "\n", "c", "=", "c_linear", "[", "\"output\"", "]", "\n", "\n", "h1", "=", "u", "*", "tf", ".", "tanh", "(", "c", ")", "\n", "h2", "=", "(", "1.0", "-", "u", ")", "*", "state", "\n", "new_state", "=", "h1", "+", "h2", "\n", "new_state_stab", "=", "stabilize", "(", "new_state", ",", "params", ".", "stab", ")", "\n", "w_x_newh", "=", "w_x_c", "*", "tf", ".", "expand_dims", "(", "h1", "/", "new_state_stab", ",", "axis", "=", "1", ")", "\n", "w_xlast_newh", "=", "w_xlast_c", "*", "tf", ".", "expand_dims", "(", "h1", "/", "new_state_stab", ",", "axis", "=", "1", ")", "+", "w_x_h_last", "*", "tf", ".", "expand_dims", "(", "h2", "/", "new_state_stab", ",", "axis", "=", "1", ")", "\n", "\n", "", "return", "new_state", ",", "new_state", ",", "w_xlast_newh", ",", "w_x_newh", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.LegacyGRUCell_encoder_v2n.state_size": [[319, 322], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.LegacyGRUCell_encoder_v2n.output_size": [[323, 326], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.LegacyGRUCell_decoder_v2n.__init__": [[336, 339], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.train_word2vec.MySentences.__init__"], ["def", "__init__", "(", "self", ",", "num_units", ",", "reuse", "=", "None", ")", ":", "\n", "        ", "super", "(", "LegacyGRUCell_decoder_v2n", ",", "self", ")", ".", "__init__", "(", "_reuse", "=", "reuse", ")", "\n", "self", ".", "_num_units", "=", "num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.LegacyGRUCell_decoder_v2n.__call__": [[340, 390], ["tensorflow.variable_scope", "tensorflow.zeros", "lrp.linear_v2n", "tensorflow.nn.sigmoid", "lrp.linear_v2n", "tensorflow.nn.sigmoid", "lrp.linear_v2n", "lrp.weighted_sum", "tensorflow.expand_dims", "tensorflow.expand_dims", "isinstance", "tensorflow.shape", "tensorflow.shape", "list", "list", "tensorflow.tanh"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.linear_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.linear_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.linear_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.weighted_sum"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "w_x_h_last", ",", "w_x_c", ",", "params", ",", "scope", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"gru_cell\"", ",", "\n", "values", "=", "[", "inputs", ",", "state", "]", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "inputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "inputs", "=", "[", "inputs", "]", "\n", "\n", "", "bs", "=", "tf", ".", "shape", "(", "w_x_h_last", ")", "[", "0", "]", "\n", "emb", "=", "tf", ".", "shape", "(", "inputs", "[", "0", "]", ")", "[", "-", "1", "]", "\n", "w_x_y", "=", "tf", ".", "zeros", "(", "[", "bs", ",", "1", ",", "emb", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "all_inputs", "=", "list", "(", "inputs", ")", "+", "[", "state", "]", "\n", "w_x_h", "=", "w_x_h_last", "\n", "w_x_ctx", "=", "w_x_c", "\n", "r_linear", "=", "linear_v2n", "(", "all_inputs", ",", "self", ".", "_num_units", ",", "False", ",", "\n", "[", "w_x_y", ",", "w_x_c", ",", "w_x_h_last", "]", ",", "params", ",", "False", ",", "\n", "scope", "=", "\"reset_gate\"", ",", "d2", "=", "True", ")", "\n", "_", ",", "w_x_ctx_r", ",", "w_x_h_r", "=", "r_linear", "[", "\"weight_ratios\"", "]", "\n", "w_x_r", "=", "w_x_ctx_r", "+", "w_x_h_r", "\n", "r", "=", "tf", ".", "nn", ".", "sigmoid", "(", "r_linear", "[", "\"output\"", "]", ")", "\n", "\n", "u_linear", "=", "linear_v2n", "(", "all_inputs", ",", "self", ".", "_num_units", ",", "False", ",", "\n", "[", "w_x_y", ",", "w_x_c", ",", "w_x_h_last", "]", ",", "params", ",", "False", ",", "\n", "scope", "=", "\"update_gate\"", ",", "d2", "=", "True", ")", "\n", "_", ",", "w_x_ctx_u", ",", "w_x_h_u", "=", "u_linear", "[", "\"weight_ratios\"", "]", "\n", "w_x_u", "=", "w_x_ctx_u", "+", "w_x_h_u", "\n", "u", "=", "tf", ".", "nn", ".", "sigmoid", "(", "u_linear", "[", "\"output\"", "]", ")", "\n", "\n", "reseted", "=", "r", "*", "state", "\n", "w_x_reseted", "=", "0.5", "*", "w_x_r", "+", "0.5", "*", "w_x_h", "\n", "\n", "all_inputs", "=", "list", "(", "inputs", ")", "+", "[", "reseted", "]", "\n", "c_linear", "=", "linear_v2n", "(", "all_inputs", ",", "self", ".", "_num_units", ",", "True", ",", "\n", "[", "w_x_y", ",", "w_x_c", ",", "w_x_reseted", "]", ",", "params", ",", "False", ",", "\n", "scope", "=", "\"candidate\"", ",", "d2", "=", "True", ")", "\n", "_", ",", "w_x_c_state", ",", "w_x_resetes_state", "=", "c_linear", "[", "\"weight_ratios\"", "]", "\n", "w_x_state", "=", "w_x_c_state", "+", "w_x_resetes_state", "\n", "c", "=", "c_linear", "[", "\"output\"", "]", "\n", "\n", "h1", "=", "u", "*", "tf", ".", "tanh", "(", "c", ")", "\n", "h2", "=", "(", "1.0", "-", "u", ")", "*", "state", "\n", "w_x_h1", "=", "0.5", "*", "w_x_state", "+", "0.5", "*", "w_x_u", "\n", "w_x_h2", "=", "0.5", "*", "w_x_u", "+", "0.5", "*", "w_x_h", "\n", "\n", "newh_ws", "=", "weighted_sum", "(", "[", "h1", ",", "h2", "]", ",", "[", "1.", ",", "1.", "]", ",", "params", ",", "flatten", "=", "True", ")", "\n", "new_state", "=", "newh_ws", "[", "\"output\"", "]", "\n", "w_h1_newh", ",", "w_h2_newh", "=", "newh_ws", "[", "\"weight_ratios\"", "]", "\n", "w_h1_newh", "=", "tf", ".", "expand_dims", "(", "w_h1_newh", ",", "1", ")", "\n", "w_h2_newh", "=", "tf", ".", "expand_dims", "(", "w_h2_newh", ",", "1", ")", "\n", "w_x_newh", "=", "w_x_h1", "*", "w_h1_newh", "+", "w_x_h2", "*", "w_h2_newh", "\n", "\n", "", "return", "new_state", ",", "new_state", ",", "w_x_newh", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.LegacyGRUCell_decoder_v2n.state_size": [[391, 394], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.LegacyGRUCell_decoder_v2n.output_size": [[395, 398], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.reduce_reserve": [[23, 25], ["tensorflow.expand_dims", "tensorflow.reduce_sum"], "function", ["None"], ["def", "reduce_reserve", "(", "matrix", ",", "axis", ")", ":", "\n", "    ", "return", "tf", ".", "expand_dims", "(", "tf", ".", "reduce_sum", "(", "matrix", ",", "axis", ")", ",", "axis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.v2n_propagate_linear": [[27, 40], ["tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.matmul", "tensorflow.squeeze", "tensorflow.shape"], "function", ["None"], ["", "def", "v2n_propagate_linear", "(", "w_x_last", ",", "w_linear", ")", ":", "\n", "    ", "'''\n        w_x_last: [bs, len_src, len, d]\n        w_linear: [b, len, d, d]\n        return: [b, len_src, len, d]\n    '''", "\n", "len_src", "=", "tf", ".", "shape", "(", "w_x_last", ")", "[", "1", "]", "\n", "w_x_last", "=", "tf", ".", "expand_dims", "(", "w_x_last", ",", "-", "2", ")", "\n", "w_linear", "=", "tf", ".", "expand_dims", "(", "w_linear", ",", "1", ")", "\n", "w_linear", "=", "tf", ".", "tile", "(", "w_linear", ",", "[", "1", ",", "len_src", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "result", "=", "tf", ".", "matmul", "(", "w_x_last", ",", "w_linear", ")", "\n", "result", "=", "tf", ".", "squeeze", "(", "result", ",", "-", "2", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.create_diagonal_v2n": [[42, 52], ["tensorflow.diag", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.ones"], "function", ["None"], ["", "def", "create_diagonal_v2n", "(", "batchsize", ",", "length", ",", "dim", ")", ":", "\n", "    ", "'''\n        diagonal matrix (batchsize, len_src, len_src, dim)\n\tresult[bs, len_src, len_src, dim] = 1\n    '''", "\n", "result", "=", "tf", ".", "diag", "(", "tf", ".", "ones", "(", "[", "length", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "result", "=", "tf", ".", "expand_dims", "(", "result", ",", "0", ")", "\n", "result", "=", "tf", ".", "expand_dims", "(", "result", ",", "-", "1", ")", "\n", "result", "=", "tf", ".", "tile", "(", "result", ",", "[", "batchsize", ",", "1", ",", "1", ",", "dim", "]", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.stabilize": [[54, 61], ["tensorflow.sign", "tensorflow.equal", "tensorflow.cast", "tensorflow.zeros", "tensorflow.shape"], "function", ["None"], ["", "def", "stabilize", "(", "matrix", ",", "stab", ")", ":", "\n", "    ", "sign", "=", "tf", ".", "sign", "(", "matrix", ")", "\n", "zero_pos", "=", "tf", ".", "equal", "(", "sign", ",", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "sign", ")", ")", ")", "\n", "zero_pos", "=", "tf", ".", "cast", "(", "zero_pos", ",", "tf", ".", "float32", ")", "\n", "sign", "+=", "zero_pos", "\n", "result", "=", "matrix", "+", "stab", "*", "sign", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.normalize": [[63, 66], ["tensorflow.reduce_sum", "tensorflow.abs", "tensorflow.expand_dims"], "function", ["None"], ["", "def", "normalize", "(", "matrix", ")", ":", "\n", "    ", "total", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "abs", "(", "matrix", ")", ",", "axis", "=", "-", "1", ")", "\n", "return", "matrix", "/", "tf", ".", "expand_dims", "(", "total", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.dot_product": [[68, 76], ["tensorflow.identity", "range", "thumt.weight_ratio_dot_product", "len"], "function", ["None"], ["", "def", "dot_product", "(", "inputs", ",", "params", ")", ":", "\n", "    ", "output", "=", "tf", ".", "identity", "(", "inputs", "[", "0", "]", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "inputs", ")", ")", ":", "\n", "        ", "output", "*=", "inputs", "[", "i", "]", "\n", "\n", "", "weight_ratios", "=", "wr", ".", "weight_ratio_dot_product", "(", "inputs", ",", "output", ")", "\n", "\n", "return", "{", "\"output\"", ":", "output", ",", "\"weight_ratios\"", ":", "weight_ratios", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.weighted_sum": [[78, 87], ["tensorflow.add_n", "thumt.weight_ratio_weighted_sum", "len", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.weight_ratio.weight_ratio_weighted_sum"], ["", "def", "weighted_sum", "(", "inputs", ",", "weights", ",", "params", ",", "flatten", "=", "False", ")", ":", "\n", "    ", "assert", "len", "(", "inputs", ")", "==", "len", "(", "weights", ")", "\n", "output", "=", "tf", ".", "add_n", "(", "[", "inputs", "[", "i", "]", "*", "weights", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "inputs", ")", ")", "]", ")", "\n", "\n", "weight_ratios", "=", "wr", ".", "weight_ratio_weighted_sum", "(", "inputs", ",", "weights", ",", "output", ",", "\n", "stab", "=", "params", ".", "stab", ",", "\n", "flatten", "=", "flatten", ")", "\n", "\n", "return", "{", "\"output\"", ":", "output", ",", "\"weight_ratios\"", ":", "weight_ratios", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.maxpool": [[89, 97], ["tensorflow.concat", "tensorflow.reshape", "tensorflow.reduce_max", "thumt.weight_ratio_maxpool", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.weight_ratio.weight_ratio_maxpool"], ["", "def", "maxpool", "(", "input", ",", "output_size", ",", "params", ",", "flatten", "=", "False", ")", ":", "\n", "    ", "shape", "=", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "input", ")", "[", ":", "-", "1", "]", ",", "[", "output_size", ",", "params", ".", "maxnum", "]", "]", ",", "\n", "axis", "=", "0", ")", "\n", "value", "=", "tf", ".", "reshape", "(", "input", ",", "shape", ")", "\n", "output", "=", "tf", ".", "reduce_max", "(", "value", ",", "-", "1", ")", "\n", "weight_ratio", "=", "wr", ".", "weight_ratio_maxpool", "(", "input", ",", "output", ",", "params", ".", "maxnum", ",", "\n", "flatten", "=", "flatten", ")", "\n", "return", "{", "\"output\"", ":", "output", ",", "\"weight_ratio\"", ":", "weight_ratio", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.weight_ratio_linear_v2n_2d": [[99, 108], ["tensorflow.expand_dims", "lrp.weight_ratio_linear_v2n", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.squeeze"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.weight_ratio_linear_v2n"], ["", "def", "weight_ratio_linear_v2n_2d", "(", "inputs", ",", "weights", ",", "output", ",", "w_x_inp", ",", "bias", "=", "None", ",", "\n", "stab", "=", "0", ")", ":", "\n", "    ", "inputs_ex", "=", "[", "tf", ".", "expand_dims", "(", "inp", ",", "1", ")", "for", "inp", "in", "inputs", "]", "\n", "output_ex", "=", "tf", ".", "expand_dims", "(", "output", ",", "1", ")", "\n", "w_x_inp_ex", "=", "[", "tf", ".", "expand_dims", "(", "w", ",", "2", ")", "for", "w", "in", "w_x_inp", "]", "\n", "result", "=", "weight_ratio_linear_v2n", "(", "inputs_ex", ",", "weights", ",", "output_ex", ",", "\n", "w_x_inp_ex", ",", "bias", "=", "bias", ",", "stab", "=", "stab", ")", "\n", "result", "=", "[", "tf", ".", "squeeze", "(", "res", ",", "2", ")", "for", "res", "in", "result", "]", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.weight_ratio_linear_v2n": [[110, 139], ["tensorflow.expand_dims", "tensorflow.reshape", "range", "len", "len", "tensorflow.shape", "tensorflow.shape", "lrp.stabilize", "len", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "weight_ratios.append", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.stabilize"], ["", "def", "weight_ratio_linear_v2n", "(", "inputs", ",", "weights", ",", "output", ",", "w_x_inp", ",", "bias", "=", "None", ",", "\n", "stab", "=", "0", ")", ":", "\n", "    ", "'''\n        inputs: [(bs, lq, di)]\n        weights: [(di, do)]\n        bias: (do)\n        output: (bs, lq, do)\n        w_x_inp: [(bs, ls, lq, di)]\n        weight ratios: [(bs, ls, lq, do)]\n    '''", "\n", "assert", "len", "(", "inputs", ")", "==", "len", "(", "weights", ")", "\n", "weight_ratios", "=", "[", "]", "\n", "bs", "=", "tf", ".", "shape", "(", "w_x_inp", "[", "0", "]", ")", "[", "0", "]", "\n", "lq", "=", "tf", ".", "shape", "(", "w_x_inp", "[", "0", "]", ")", "[", "2", "]", "\n", "outp", "=", "tf", ".", "expand_dims", "(", "stabilize", "(", "output", ",", "stab", ")", ",", "1", ")", "\n", "outp", "=", "tf", ".", "reshape", "(", "outp", ",", "[", "bs", ",", "1", ",", "lq", ",", "-", "1", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "inputs", ")", ")", ":", "\n", "        ", "di", "=", "tf", ".", "shape", "(", "w_x_inp", "[", "i", "]", ")", "[", "3", "]", "\n", "ls", "=", "tf", ".", "shape", "(", "w_x_inp", "[", "i", "]", ")", "[", "1", "]", "\n", "inp", "=", "tf", ".", "reshape", "(", "inputs", "[", "i", "]", ",", "[", "bs", ",", "1", ",", "lq", ",", "-", "1", "]", ")", "\n", "w", "=", "w_x_inp", "[", "i", "]", "*", "inp", "\n", "w", "=", "tf", ".", "reshape", "(", "w", ",", "[", "-", "1", ",", "di", "]", ")", "\n", "w", "=", "tf", ".", "matmul", "(", "w", ",", "weights", "[", "i", "]", ")", "\n", "w", "=", "tf", ".", "reshape", "(", "w", ",", "[", "bs", ",", "ls", ",", "lq", ",", "-", "1", "]", ")", "\n", "w", "=", "w", "/", "outp", "\n", "weight_ratios", ".", "append", "(", "w", ")", "\n", "\n", "", "return", "weight_ratios", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.linear_v2n": [[141, 214], ["tensorflow.variable_scope", "tensorflow.concat", "tensorflow.add_n", "tensorflow.reshape", "isinstance", "tensorflow.shape", "len", "len", "RuntimeError", "tensorflow.reshape", "sum", "tensorflow.concat", "tensorflow.concat", "tensorflow.get_variable", "results.append", "range", "tensorflow.get_variable", "tensorflow.nn.bias_add", "operator", "operator", "tensorflow.matmul", "len", "weight_shapes.append", "tensorflow.get_variable", "matrixs.append", "results.append", "item.get_shape", "tensorflow.shape", "tensorflow.concat", "tensorflow.matmul"], "function", ["None"], ["", "def", "linear_v2n", "(", "inputs", ",", "output_size", ",", "bias", ",", "w_x_inp", ",", "params", ",", "concat", "=", "False", ",", "\n", "dtype", "=", "None", ",", "scope", "=", "None", ",", "d2", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Linear layer\n    :param inputs: A Tensor or a list of Tensors with shape [batch, input_size]\n    :param output_size: An integer specify the output size\n    :param bias: a boolean value indicate whether to use bias term\n    :param concat: a boolean value indicate whether to concatenate all inputs\n    :param dtype: an instance of tf.DType, the default value is ``tf.float32''\n    :param scope: the scope of this layer, the default value is ``linear''\n    :returns: a Tensor with shape [batch, output_size]\n    :raises RuntimeError: raises ``RuntimeError'' when input sizes do not\n                          compatible with each other\n    \"\"\"", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"linear\"", ",", "values", "=", "[", "inputs", "]", ")", ":", "\n", "#assert not concat", "\n", "        ", "if", "not", "isinstance", "(", "inputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "inputs", "=", "[", "inputs", "]", "\n", "\n", "", "batch_shape", "=", "tf", ".", "shape", "(", "inputs", "[", "0", "]", ")", "[", ":", "-", "1", "]", "\n", "input_size", "=", "[", "item", ".", "get_shape", "(", ")", "[", "-", "1", "]", ".", "value", "for", "item", "in", "inputs", "]", "\n", "\n", "if", "len", "(", "inputs", ")", "!=", "len", "(", "input_size", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"inputs and input_size unmatched!\"", ")", "\n", "\n", "", "output_shape", "=", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "inputs", "[", "0", "]", ")", "[", ":", "-", "1", "]", ",", "[", "output_size", "]", "]", ",", "\n", "axis", "=", "0", ")", "\n", "# Flatten to 2D", "\n", "inputs", "=", "[", "tf", ".", "reshape", "(", "inp", ",", "[", "-", "1", ",", "inp", ".", "shape", "[", "-", "1", "]", ".", "value", "]", ")", "for", "inp", "in", "inputs", "]", "\n", "\n", "results", "=", "[", "]", "\n", "weight_ratios", "=", "[", "]", "\n", "weight_shapes", "=", "[", "]", "\n", "matrixs", "=", "[", "]", "\n", "\n", "if", "concat", ":", "\n", "            ", "input_size", "=", "sum", "(", "input_size", ")", "\n", "inputs", "=", "tf", ".", "concat", "(", "inputs", ",", "1", ")", "\n", "shape", "=", "[", "input_size", ",", "output_size", "]", "\n", "weight_shape", "=", "tf", ".", "concat", "(", "[", "batch_shape", ",", "shape", "]", ",", "-", "1", ")", "\n", "matrix", "=", "tf", ".", "get_variable", "(", "\"matrix\"", ",", "shape", ",", "dtype", "=", "dtype", ")", "\n", "results", ".", "append", "(", "tf", ".", "matmul", "(", "inputs", ",", "matrix", ")", ")", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "input_size", ")", ")", ":", "\n", "                ", "shape", "=", "[", "input_size", "[", "i", "]", ",", "output_size", "]", "\n", "weight_shapes", ".", "append", "(", "tf", ".", "concat", "(", "[", "batch_shape", ",", "shape", "]", ",", "-", "1", ")", ")", "\n", "name", "=", "\"matrix_%d\"", "%", "i", "\n", "matrix", "=", "tf", ".", "get_variable", "(", "name", ",", "shape", ",", "dtype", "=", "dtype", ")", "\n", "matrixs", ".", "append", "(", "matrix", ")", "\n", "results", ".", "append", "(", "tf", ".", "matmul", "(", "inputs", "[", "i", "]", ",", "matrix", ")", ")", "\n", "\n", "", "", "output", "=", "tf", ".", "add_n", "(", "results", ")", "\n", "\n", "if", "bias", ":", "\n", "            ", "shape", "=", "[", "output_size", "]", "\n", "bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "shape", ",", "dtype", "=", "dtype", ")", "\n", "output", "=", "tf", ".", "nn", ".", "bias_add", "(", "output", ",", "bias", ")", "\n", "\n", "# calculate weight ratio", "\n", "", "operator", "=", "weight_ratio_linear_v2n", "\n", "if", "d2", ":", "\n", "            ", "operator", "=", "weight_ratio_linear_v2n_2d", "\n", "", "if", "concat", ":", "\n", "            ", "weight_ratios", "=", "operator", "(", "[", "inputs", "]", ",", "[", "matrix", "]", ",", "output", ",", "w_x_inp", ",", "\n", "bias", "=", "bias", ",", "stab", "=", "params", ".", "stab", ")", "\n", "", "else", ":", "\n", "            ", "weight_ratios", "=", "operator", "(", "inputs", ",", "matrixs", ",", "output", ",", "w_x_inp", ",", "\n", "bias", "=", "bias", ",", "stab", "=", "params", ".", "stab", ")", "\n", "\n", "", "output", "=", "tf", ".", "reshape", "(", "output", ",", "output_shape", ")", "\n", "\n", "return", "{", "\"output\"", ":", "output", ",", "\"weight_ratios\"", ":", "weight_ratios", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.maxout_v2n": [[216, 257], ["tensorflow.transpose", "tensorflow.transpose", "tensorflow.zeros", "lrp.linear_v2n", "tensorflow.transpose", "lrp.maxpool", "propagater", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.linear_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.maxpool"], ["", "", "def", "maxout_v2n", "(", "inputs", ",", "output_size", ",", "maxpart", ",", "w", ",", "params", ",", "use_bias", "=", "True", ",", "\n", "concat", "=", "True", ",", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Maxout layer\n    :param inputs: see the corresponding description of ``linear''\n    :param output_size: see the corresponding description of ``linear''\n    :param maxpart: an integer, the default value is 2\n    :param use_bias: a boolean value indicate whether to use bias term\n    :param concat: concat all tensors if inputs is a list of tensors\n    :param dtype: an optional instance of tf.Dtype\n    :param scope: the scope of this layer, the default value is ``maxout''\n    :returns: a Tensor with shape [batch, output_size]\n    :raises RuntimeError: see the corresponding description of ``linear''\n    \"\"\"", "\n", "\n", "w_x_dec", ",", "w_x_ctx", "=", "w", "\n", "w_x_dec", "=", "tf", ".", "transpose", "(", "w_x_dec", ",", "[", "1", ",", "2", ",", "0", ",", "3", "]", ")", "\n", "w_x_ctx", "=", "tf", ".", "transpose", "(", "w_x_ctx", ",", "[", "1", ",", "2", ",", "0", ",", "3", "]", ")", "\n", "w_x_y", "=", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "w_x_dec", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "candidate_linear", "=", "linear_v2n", "(", "inputs", ",", "output_size", "*", "maxpart", ",", "use_bias", ",", "\n", "[", "w_x_y", ",", "w_x_dec", ",", "w_x_ctx", "]", ",", "params", ",", "concat", ",", "\n", "dtype", "=", "dtype", ",", "scope", "=", "scope", "or", "\"maxout\"", ")", "\n", "candidate", "=", "candidate_linear", "[", "\"output\"", "]", "\n", "_", ",", "w_x_dec_readout", ",", "w_x_ctx_readout", "=", "candidate_linear", "[", "\"weight_ratios\"", "]", "\n", "w_x_readout", "=", "w_x_dec_readout", "+", "w_x_ctx_readout", "\n", "w_x_readout", "=", "tf", ".", "transpose", "(", "w_x_readout", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "\n", "output_maxout", "=", "maxpool", "(", "candidate", ",", "output_size", ",", "params", ")", "\n", "output", "=", "output_maxout", "[", "\"output\"", "]", "\n", "\n", "# direct", "\n", "w_readout_maxout", "=", "output_maxout", "[", "\"weight_ratio\"", "]", "\n", "\n", "#propagate", "\n", "propagater", "=", "tf", ".", "matmul", "\n", "\n", "w_x_maxout", "=", "propagater", "(", "w_x_readout", ",", "w_readout_maxout", ")", "\n", "\n", "weight_ratios", "=", "[", "w_x_maxout", "]", "\n", "\n", "return", "{", "\"output\"", ":", "output", ",", "\"weight_ratios\"", ":", "weight_ratios", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.combine_heads_v2n": [[400, 411], ["tensorflow.name_scope", "tensorflow.transpose", "tensorflow.reshape", "tf.reshape.set_shape", "tf.reshape.get_shape", "tensorflow.concat", "tensorflow.shape"], "function", ["None"], ["", "", "def", "combine_heads_v2n", "(", "inputs", ",", "name", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "name", ",", "default_name", "=", "\"combine_heads\"", ",", "values", "=", "[", "inputs", "]", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "x", "=", "tf", ".", "transpose", "(", "x", ",", "[", "0", ",", "2", ",", "3", ",", "1", ",", "4", "]", ")", "\n", "old_shape", "=", "x", ".", "get_shape", "(", ")", ".", "dims", "\n", "a", ",", "b", "=", "old_shape", "[", "-", "2", ":", "]", "\n", "new_shape", "=", "old_shape", "[", ":", "-", "2", "]", "+", "[", "a", "*", "b", "if", "a", "and", "b", "else", "None", "]", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "x", ")", "[", ":", "-", "2", "]", ",", "[", "-", "1", "]", "]", ",", "0", ")", ")", "\n", "x", ".", "set_shape", "(", "new_shape", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.split_heads": [[413, 424], ["tensorflow.name_scope", "tensorflow.reshape", "tf.reshape.set_shape", "tensorflow.transpose", "x.get_shape", "tensorflow.concat", "tensorflow.shape"], "function", ["None"], ["", "", "def", "split_heads", "(", "inputs", ",", "num_heads", ",", "name", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "name", ",", "default_name", "=", "\"split_heads\"", ",", "values", "=", "[", "inputs", "]", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "n", "=", "num_heads", "\n", "old_shape", "=", "x", ".", "get_shape", "(", ")", ".", "dims", "\n", "\n", "last", "=", "old_shape", "[", "-", "1", "]", "\n", "new_shape", "=", "old_shape", "[", ":", "-", "1", "]", "+", "[", "n", "]", "+", "[", "last", "//", "n", "if", "last", "else", "None", "]", "\n", "ret", "=", "tf", ".", "reshape", "(", "x", ",", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "x", ")", "[", ":", "-", "1", "]", ",", "[", "n", ",", "-", "1", "]", "]", ",", "0", ")", ")", "\n", "ret", ".", "set_shape", "(", "new_shape", ")", "\n", "return", "tf", ".", "transpose", "(", "ret", ",", "[", "0", ",", "3", ",", "1", ",", "2", ",", "4", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.combine_heads": [[425, 436], ["tensorflow.name_scope", "tensorflow.transpose", "tensorflow.reshape", "tf.reshape.set_shape", "tf.reshape.get_shape", "tensorflow.concat", "tensorflow.shape"], "function", ["None"], ["", "", "def", "combine_heads", "(", "inputs", ",", "name", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "name", ",", "default_name", "=", "\"combine_heads\"", ",", "values", "=", "[", "inputs", "]", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "x", "=", "tf", ".", "transpose", "(", "x", ",", "[", "0", ",", "2", ",", "3", ",", "4", ",", "1", ",", "5", "]", ")", "\n", "old_shape", "=", "x", ".", "get_shape", "(", ")", ".", "dims", "\n", "a", ",", "b", "=", "old_shape", "[", "-", "2", ":", "]", "\n", "new_shape", "=", "old_shape", "[", ":", "-", "2", "]", "+", "[", "a", "*", "b", "if", "a", "and", "b", "else", "None", "]", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "x", ")", "[", ":", "-", "2", "]", ",", "[", "-", "1", "]", "]", ",", "0", ")", ")", "\n", "x", ".", "set_shape", "(", "new_shape", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.layer_process": [[438, 446], ["lrp.layer_norm", "ValueError"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.layer_norm"], ["", "", "def", "layer_process", "(", "x", ",", "mode", ",", "w_x_inp", ",", "params", ")", ":", "\n", "    ", "if", "not", "mode", "or", "mode", "==", "\"none\"", ":", "\n", "        ", "return", "{", "\"outputs\"", ":", "x", ",", "\"weight_ratios\"", ":", "w_x_inp", "}", "\n", "", "elif", "mode", "==", "\"layer_norm\"", ":", "\n", "        ", "norm", "=", "layer_norm", "(", "x", ",", "w_x_inp", ",", "params", ")", "\n", "return", "norm", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown mode %s\"", "%", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.layer_norm": [[448, 490], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "thumt.weight_ratio_mean", "thumt.weight_ratio_weighted_sum", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.expand_dims", "inputs.get_shape().as_list", "tensorflow.square", "tensorflow.rsqrt", "tensorflow.expand_dims", "tensorflow.ones_initializer", "tensorflow.zeros_initializer", "tensorflow.expand_dims", "inputs.get_shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.weight_ratio.weight_ratio_mean", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.weight_ratio.weight_ratio_weighted_sum"], ["", "", "def", "layer_norm", "(", "inputs", ",", "w_x_inp", ",", "params", ",", "epsilon", "=", "1e-6", ",", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Layer Normalization\n    :param inputs: A Tensor of shape [..., channel_size]\n    :param epsilon: A floating number\n    :param dtype: An optional instance of tf.DType\n    :param scope: An optional string\n    :returns: A Tensor with the same shape as inputs\n\n    w_x_inp: [bs, len_src, len, dim]\n    \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"layer_norm\"", ",", "values", "=", "[", "inputs", "]", ",", "\n", "dtype", "=", "dtype", ")", ":", "\n", "        ", "channel_size", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "\n", "scale", "=", "tf", ".", "get_variable", "(", "\"scale\"", ",", "shape", "=", "[", "channel_size", "]", ",", "\n", "initializer", "=", "tf", ".", "ones_initializer", "(", ")", ")", "\n", "\n", "offset", "=", "tf", ".", "get_variable", "(", "\"offset\"", ",", "shape", "=", "[", "channel_size", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "\n", "mean", "=", "tf", ".", "reduce_mean", "(", "inputs", ",", "axis", "=", "-", "1", ",", "keep_dims", "=", "True", ")", "\n", "variance", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "inputs", "-", "mean", ")", ",", "axis", "=", "-", "1", ",", "\n", "keep_dims", "=", "True", ")", "\n", "\n", "averaged", "=", "(", "inputs", "-", "mean", ")", "\n", "norm_inputs", "=", "averaged", "*", "tf", ".", "rsqrt", "(", "variance", "+", "epsilon", ")", "\n", "\n", "w_inp_mean", "=", "wr", ".", "weight_ratio_mean", "(", "inputs", ",", "mean", ",", "stab", "=", "params", ".", "stab", ")", "\n", "w_inp_out", ",", "w_mean_out", "=", "wr", ".", "weight_ratio_weighted_sum", "(", "[", "inputs", ",", "mean", "]", ",", "\n", "[", "1.", ",", "-", "1.", "]", ",", "\n", "averaged", ",", "\n", "stab", "=", "params", ".", "stab", ",", "\n", "flatten", "=", "True", ")", "\n", "w_x_mean", "=", "tf", ".", "reduce_sum", "(", "w_x_inp", "*", "tf", ".", "expand_dims", "(", "w_inp_mean", ",", "1", ")", ",", "-", "1", ")", "\n", "w_inp_out", "=", "tf", ".", "expand_dims", "(", "w_inp_out", ",", "1", ")", "\n", "w_mean_out", "=", "tf", ".", "expand_dims", "(", "w_mean_out", ",", "1", ")", "\n", "w_x_out", "=", "w_x_inp", "*", "w_inp_out", "\n", "w_x_out", "+=", "tf", ".", "expand_dims", "(", "w_x_mean", ",", "-", "1", ")", "*", "w_mean_out", "\n", "\n", "return", "{", "\"outputs\"", ":", "norm_inputs", "*", "scale", "+", "offset", ",", "\n", "\"weight_ratios\"", ":", "w_x_out", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.multihead_attention_v2n": [[491, 593], ["ValueError", "ValueError", "tensorflow.variable_scope", "thumt.split_heads", "thumt.split_heads", "thumt.split_heads", "lrp.split_heads", "thumt.multiplicative_attention", "thumt.combine_heads", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.transpose", "lrp.combine_heads_v2n", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "lrp.linear_v2n", "tensorflow.split", "tensorflow.split", "thumt.linear", "lrp.linear_v2n", "tensorflow.split", "tensorflow.split", "lrp.linear_v2n", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.split_heads", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.split_heads", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.split_heads", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.split_heads", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multiplicative_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.combine_heads", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.combine_heads_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.linear_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.linear_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.linear_v2n"], ["", "", "def", "multihead_attention_v2n", "(", "queries", ",", "memories", ",", "bias", ",", "w_x_inp", ",", "num_heads", ",", "\n", "key_size", ",", "value_size", ",", "output_size", ",", "params", ",", "\n", "keep_prob", "=", "None", ",", "output", "=", "True", ",", "dtype", "=", "None", ",", "\n", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\" Multi-head scaled-dot-product attention with input/output\n        transformations.\n\n    :param queries: A tensor with shape [batch, length_q, depth_q] if\n    :param memories: A tensor with shape [batch, length_m, depth_m]\n    :param bias: A tensor (see attention_bias)\n    :param num_heads: An integer dividing key_size and value_size\n    :param key_size: An integer\n    :param value_size: An integer\n    :param output_size: An integer\n    :param keep_prob: A floating point number in (0, 1]\n    :param output: Whether to use output transformation\n    :param dtype: An optional instance of tf.DType\n    :param scope: An optional string\n\n\n    :returns: A dict with the following keys:\n        weights: A tensor with shape [batch, heads, length_q, length_v]\n        outputs: A tensor with shape [batch, length_q, depth_v]\n        weight_ratio: [batch. length_q, d, length_v, d]\n\n        w_x_inp: [batch, len_src, len_src, d] or [batch, len_trg, len_trg, d]\n    \"\"\"", "\n", "\n", "if", "key_size", "%", "num_heads", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"Key size (%d) must be divisible by the number of \"", "\n", "\"attention heads (%d).\"", "%", "(", "key_size", ",", "num_heads", ")", ")", "\n", "\n", "", "if", "value_size", "%", "num_heads", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"Value size (%d) must be divisible by the number of \"", "\n", "\"attention heads (%d).\"", "%", "(", "value_size", ",", "num_heads", ")", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"multihead_attention\"", ",", "\n", "values", "=", "[", "queries", ",", "memories", "]", ",", "dtype", "=", "dtype", ")", ":", "\n", "        ", "bs", "=", "tf", ".", "shape", "(", "w_x_inp", ")", "[", "0", "]", "\n", "len_q", "=", "tf", ".", "shape", "(", "queries", ")", "[", "1", "]", "\n", "len_src", "=", "tf", ".", "shape", "(", "w_x_inp", ")", "[", "1", "]", "\n", "dim", "=", "tf", ".", "shape", "(", "w_x_inp", ")", "[", "3", "]", "\n", "if", "memories", "is", "None", ":", "\n", "# self attention", "\n", "            ", "size", "=", "key_size", "*", "2", "+", "value_size", "\n", "combined_linear", "=", "linear_v2n", "(", "queries", ",", "size", ",", "True", ",", "[", "w_x_inp", "]", ",", "\n", "params", ",", "True", ",", "scope", "=", "\"qkv_transform\"", ")", "\n", "combined", "=", "combined_linear", "[", "\"output\"", "]", "\n", "q", ",", "k", ",", "v", "=", "tf", ".", "split", "(", "combined", ",", "[", "key_size", ",", "key_size", ",", "value_size", "]", ",", "\n", "axis", "=", "-", "1", ")", "\n", "w_x_combined", "=", "combined_linear", "[", "\"weight_ratios\"", "]", "[", "0", "]", "\n", "w_x_q", ",", "w_x_k", ",", "w_x_v", "=", "tf", ".", "split", "(", "w_x_combined", ",", "\n", "[", "key_size", ",", "key_size", ",", "value_size", "]", ",", "\n", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "nn", ".", "linear", "(", "queries", ",", "key_size", ",", "True", ",", "params", ",", "True", ",", "\n", "scope", "=", "\"q_transform\"", ")", "\n", "combined_linear", "=", "linear_v2n", "(", "memories", ",", "key_size", "+", "value_size", ",", "True", ",", "\n", "[", "w_x_inp", "]", ",", "params", ",", "True", ",", "\n", "scope", "=", "\"kv_transform\"", ")", "\n", "combined", "=", "combined_linear", "[", "\"output\"", "]", "\n", "k", ",", "v", "=", "tf", ".", "split", "(", "combined", ",", "[", "key_size", ",", "value_size", "]", ",", "axis", "=", "-", "1", ")", "\n", "w_x_combined", "=", "combined_linear", "[", "\"weight_ratios\"", "]", "[", "0", "]", "\n", "w_x_k", ",", "w_x_v", "=", "tf", ".", "split", "(", "w_x_combined", ",", "[", "key_size", ",", "value_size", "]", ",", "\n", "axis", "=", "-", "1", ")", "\n", "\n", "# split heads", "\n", "", "q", "=", "attention", ".", "split_heads", "(", "q", ",", "num_heads", ")", "\n", "k", "=", "attention", ".", "split_heads", "(", "k", ",", "num_heads", ")", "\n", "v", "=", "attention", ".", "split_heads", "(", "v", ",", "num_heads", ")", "\n", "w_x_v", "=", "split_heads", "(", "w_x_v", ",", "num_heads", ")", "\n", "\n", "# scale query", "\n", "key_depth_per_head", "=", "key_size", "//", "num_heads", "\n", "q", "*=", "key_depth_per_head", "**", "-", "0.5", "\n", "\n", "# attention", "\n", "results", "=", "attention", ".", "multiplicative_attention", "(", "q", ",", "k", ",", "v", ",", "bias", ",", "keep_prob", ")", "\n", "\n", "# combine heads", "\n", "weights", "=", "results", "[", "\"weights\"", "]", "\n", "x", "=", "attention", ".", "combine_heads", "(", "results", "[", "\"outputs\"", "]", ")", "\n", "\n", "w_x_v", "=", "tf", ".", "transpose", "(", "w_x_v", ",", "[", "0", ",", "1", ",", "3", ",", "2", ",", "4", "]", ")", "\n", "w_x_v", "=", "tf", ".", "reshape", "(", "w_x_v", ",", "[", "bs", ",", "num_heads", ",", "tf", ".", "shape", "(", "w_x_v", ")", "[", "2", "]", ",", "-", "1", "]", ")", "\n", "w_x_att", "=", "tf", ".", "matmul", "(", "weights", ",", "w_x_v", ")", "\n", "w_x_att", "=", "tf", ".", "reshape", "(", "w_x_att", ",", "\n", "[", "bs", ",", "num_heads", ",", "len_q", ",", "len_src", ",", "key_depth_per_head", "]", ")", "\n", "w_x_att", "=", "tf", ".", "transpose", "(", "w_x_att", ",", "[", "0", ",", "1", ",", "3", ",", "2", ",", "4", "]", ")", "\n", "w_x_att", "=", "combine_heads_v2n", "(", "w_x_att", ")", "\n", "\n", "if", "output", ":", "\n", "            ", "outputs_linear", "=", "linear_v2n", "(", "x", ",", "output_size", ",", "True", ",", "[", "w_x_att", "]", ",", "\n", "params", ",", "True", ",", "\n", "scope", "=", "\"output_transform\"", ")", "\n", "outputs", "=", "outputs_linear", "[", "\"output\"", "]", "\n", "w_x_out", "=", "outputs_linear", "[", "\"weight_ratios\"", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "x", "\n", "w_x_out", "=", "w_x_att", "\n", "\n", "", "return", "{", "\"weights\"", ":", "weights", ",", "\"outputs\"", ":", "outputs", ",", "\"weight_ratio\"", ":", "w_x_out", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel._maybe_repeat": [[14, 20], ["isinstance", "len"], "function", ["None"], ["def", "_maybe_repeat", "(", "x", ",", "n", ")", ":", "\n", "    ", "if", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "        ", "assert", "len", "(", "x", ")", "==", "n", "\n", "return", "x", "\n", "", "else", ":", "\n", "        ", "return", "[", "x", "]", "*", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel.data_parallelism": [[23, 55], ["len", "six.iteritems", "parallel._maybe_repeat", "range", "parallel._maybe_repeat", "range", "parallel._maybe_repeat", "list", "range", "tensorflow.variable_scope", "zip", "range", "tensorflow.get_variable_scope", "tensorflow.name_scope", "tensorflow.device", "outputs.append"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo._maybe_repeat", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo._maybe_repeat", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo._maybe_repeat"], ["", "", "def", "data_parallelism", "(", "devices", ",", "fn", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "num_worker", "=", "len", "(", "devices", ")", "\n", "devices", "=", "[", "\"gpu:%d\"", "%", "d", "for", "d", "in", "devices", "]", "\n", "\n", "# Replicate args and kwargs", "\n", "if", "args", ":", "\n", "        ", "new_args", "=", "[", "_maybe_repeat", "(", "arg", ",", "num_worker", ")", "for", "arg", "in", "args", "]", "\n", "# Transpose", "\n", "new_args", "=", "[", "list", "(", "x", ")", "for", "x", "in", "zip", "(", "*", "new_args", ")", "]", "\n", "", "else", ":", "\n", "        ", "new_args", "=", "[", "[", "]", "for", "_", "in", "range", "(", "num_worker", ")", "]", "\n", "\n", "", "new_kwargs", "=", "[", "{", "}", "for", "_", "in", "range", "(", "num_worker", ")", "]", "\n", "\n", "for", "k", ",", "v", "in", "six", ".", "iteritems", "(", "kwargs", ")", ":", "\n", "        ", "vals", "=", "_maybe_repeat", "(", "v", ",", "num_worker", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_worker", ")", ":", "\n", "            ", "new_kwargs", "[", "i", "]", "[", "k", "]", "=", "vals", "[", "i", "]", "\n", "\n", "", "", "fns", "=", "_maybe_repeat", "(", "fn", ",", "num_worker", ")", "\n", "\n", "# Now make the parallel call.", "\n", "outputs", "=", "[", "]", "\n", "kl_outputs", "=", "[", "]", "\n", "bow_outputs", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_worker", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "(", "i", "!=", "0", ")", ")", ":", "\n", "            ", "with", "tf", ".", "name_scope", "(", "\"parallel_%d\"", "%", "i", ")", ":", "\n", "                ", "with", "tf", ".", "device", "(", "devices", "[", "i", "]", ")", ":", "\n", "#loss, kl_loss = fns[i](*new_args[i], **new_kwargs[i])", "\n", "#outputs.append(loss)", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel.shard_features": [[57, 90], ["len", "range", "tensorflow.device", "six.iteritems", "datashard_to_features.append", "tensorflow.convert_to_tensor", "range", "tensorflow.split", "tf.tile.shape.as_list", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "size_splits.append", "six.iteritems", "tensorflow.cond", "tensorflow.greater", "tensorflow.mod"], "function", ["None"], ["#                    bow_outputs.append(bow_loss)", "\n", "                    ", "outputs", ".", "append", "(", "fns", "[", "i", "]", "(", "*", "new_args", "[", "i", "]", ",", "**", "new_kwargs", "[", "i", "]", ")", ")", "\n", "\n", "", "", "", "", "return", "outputs", "#, kl_outputs#, bow_outputs", "\n", "\n", "\n", "", "def", "shard_features", "(", "features", ",", "device_list", ")", ":", "\n", "    ", "num_datashards", "=", "len", "(", "device_list", ")", "\n", "sharded_features", "=", "{", "}", "\n", "\n", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "six", ".", "iteritems", "(", "features", ")", ":", "\n", "            ", "v", "=", "tf", ".", "convert_to_tensor", "(", "v", ")", "\n", "\n", "if", "not", "v", ".", "shape", ".", "as_list", "(", ")", ":", "\n", "                ", "v", "=", "tf", ".", "expand_dims", "(", "v", ",", "axis", "=", "-", "1", ")", "\n", "v", "=", "tf", ".", "tile", "(", "v", ",", "[", "num_datashards", "]", ")", "\n", "\n", "", "batch_size", "=", "tf", ".", "shape", "(", "v", ")", "[", "0", "]", "\n", "size_splits", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_datashards", ")", ":", "\n", "                ", "size_splits", ".", "append", "(", "\n", "tf", ".", "cond", "(", "tf", ".", "greater", "(", "tf", ".", "mod", "(", "batch_size", ",", "num_datashards", ")", ",", "i", ")", ",", "\n", "lambda", ":", "batch_size", "//", "num_datashards", "+", "1", ",", "\n", "lambda", ":", "batch_size", "//", "num_datashards", ")", "\n", ")", "\n", "\n", "", "sharded_features", "[", "k", "]", "=", "tf", ".", "split", "(", "v", ",", "size_splits", ",", "0", ")", "\n", "\n", "", "", "datashard_to_features", "=", "[", "]", "\n", "\n", "for", "d", "in", "range", "(", "num_datashards", ")", ":", "\n", "        ", "feat", "=", "{", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel.parallel_model": [[92, 100], ["parallel.shard_features", "parallel.data_parallelism", "len", "model_fn"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_bak.shard_features", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo.data_parallelism"], ["}", "\n", "datashard_to_features", ".", "append", "(", "feat", ")", "\n", "\n", "", "return", "datashard_to_features", "\n", "\n", "\n", "", "def", "parallel_model", "(", "model_fn", ",", "features", ",", "devices", ")", ":", "\n", "    ", "if", "len", "(", "devices", ")", "==", "1", ":", "\n", "        ", "outputs", "=", "model_fn", "(", "features", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks.EvaluationHook.__init__": [[221, 259], ["tensorflow.logging.info", "base_dir.rstrip", "isinstance", "os.path.join", "os.path.join", "os.path.join", "tensorflow.train.SecondOrStepTimer", "ValueError"], "methods", ["None"], ["session_config", ",", "max_to_keep", "=", "5", ",", "eval_secs", "=", "None", ",", "\n", "eval_steps", "=", "None", ",", "metric", "=", "\"BLEU\"", ")", ":", "\n", "        ", "\"\"\" Initializes a `EvaluationHook`.\n        :param eval_fn: A function with signature (feature)\n        :param eval_input_fn: A function with signature ()\n        :param eval_decode_fn: A function with signature (inputs)\n        :param base_dir: A string. Base directory for the checkpoint files.\n        :param session_config: An instance of tf.ConfigProto\n        :param max_to_keep: An integer. The maximum of checkpoints to save\n        :param eval_secs: An integer, eval every N secs.\n        :param eval_steps: An integer, eval every N steps.\n        :param checkpoint_basename: `str`, base name for the checkpoint files.\n        :raises ValueError: One of `save_steps` or `save_secs` should be set.\n        :raises ValueError: At most one of saver or scaffold should be set.\n        \"\"\"", "\n", "tf", ".", "logging", ".", "info", "(", "\"Create EvaluationHook.\"", ")", "\n", "\n", "if", "metric", "!=", "\"BLEU\"", ":", "\n", "            ", "raise", "ValueError", "(", "\"Currently, EvaluationHook only support BLEU\"", ")", "\n", "\n", "", "self", ".", "_base_dir", "=", "base_dir", ".", "rstrip", "(", "\"/\"", ")", "\n", "self", ".", "_session_config", "=", "session_config", "\n", "self", ".", "_save_path", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "\"eval\"", ")", "\n", "self", ".", "_record_name", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_save_path", ",", "\"record\"", ")", "\n", "self", ".", "_log_name", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_save_path", ",", "\"log\"", ")", "\n", "self", ".", "_eval_fn", "=", "eval_fn", "\n", "self", ".", "_eval_input_fn", "=", "eval_input_fn", "\n", "self", ".", "_eval_decode_fn", "=", "eval_decode_fn", "\n", "self", ".", "_max_to_keep", "=", "max_to_keep", "\n", "self", ".", "_metric", "=", "metric", "\n", "self", ".", "_global_step", "=", "None", "\n", "self", ".", "_timer", "=", "tf", ".", "train", ".", "SecondOrStepTimer", "(", "\n", "every_secs", "=", "eval_secs", "or", "None", ",", "every_steps", "=", "eval_steps", "or", "None", "\n", ")", "\n", "\n", "", "def", "begin", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_timer", ".", "last_triggered_step", "(", ")", "is", "None", ":", "\n", "            ", "self", ".", "_timer", ".", "update_last_triggered_step", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks.EvaluationHook.begin": [[261, 282], ["tensorflow.train.get_global_step", "os.path.join", "tensorflow.gfile.Glob", "hooks.EvaluationHook._timer.last_triggered_step", "hooks.EvaluationHook._timer.update_last_triggered_step", "tensorflow.gfile.Exists", "tensorflow.logging.info", "tensorflow.gfile.MakeDirs", "name.replace", "tensorflow.gfile.Copy", "RuntimeError"], "methods", ["None"], ["\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "self", ".", "_save_path", ")", ":", "\n", "            ", "tf", ".", "logging", ".", "info", "(", "\"Making dir: %s\"", "%", "self", ".", "_save_path", ")", "\n", "tf", ".", "gfile", ".", "MakeDirs", "(", "self", ".", "_save_path", ")", "\n", "\n", "", "params_pattern", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_base_dir", ",", "\"*.json\"", ")", "\n", "params_files", "=", "tf", ".", "gfile", ".", "Glob", "(", "params_pattern", ")", "\n", "\n", "for", "name", "in", "params_files", ":", "\n", "            ", "new_name", "=", "name", ".", "replace", "(", "self", ".", "_base_dir", ",", "self", ".", "_save_path", ")", "\n", "tf", ".", "gfile", ".", "Copy", "(", "name", ",", "new_name", ",", "overwrite", "=", "True", ")", "\n", "\n", "", "if", "global_step", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Global step should be created first\"", ")", "\n", "\n", "", "self", ".", "_global_step", "=", "global_step", "\n", "\n", "", "def", "before_run", "(", "self", ",", "run_context", ")", ":", "\n", "        ", "args", "=", "tf", ".", "train", ".", "SessionRunArgs", "(", "self", ".", "_global_step", ")", "\n", "return", "args", "\n", "\n", "", "def", "after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks.EvaluationHook.before_run": [[283, 286], ["tensorflow.train.SessionRunArgs"], "methods", ["None"], ["        ", "stale_global_step", "=", "run_values", ".", "results", "\n", "\n", "if", "self", ".", "_timer", ".", "should_trigger_for_step", "(", "stale_global_step", "+", "1", ")", ":", "\n", "            ", "global_step", "=", "run_context", ".", "session", ".", "run", "(", "self", ".", "_global_step", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks.EvaluationHook.after_run": [[287, 353], ["hooks.EvaluationHook._timer.should_trigger_for_step", "run_context.session.run", "hooks.EvaluationHook._timer.should_trigger_for_step", "hooks.EvaluationHook._timer.update_last_triggered_step", "os.path.join", "hooks._get_saver", "tensorflow.logging.info", "_get_saver.save", "tensorflow.logging.info", "hooks._evaluate", "tensorflow.logging.info", "hooks._save_log", "os.path.join", "hooks._read_checkpoint_def", "hooks._read_score_record", "hooks._add_to_record", "hooks._save_score_record", "checkpoint_filename.replace.replace.replace", "hooks._save_checkpoint_def", "tensorflow.logging.info", "os.path.join", "os.path.join", "tensorflow.gfile.Glob", "tensorflow.logging.info", "os.path.join", "tensorflow.logging.info", "tensorflow.gfile.Glob", "o_file.replace", "tensorflow.gfile.Copy", "tensorflow.gfile.Remove"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._get_saver", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._evaluate", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._save_log", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._read_checkpoint_def", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._read_score_record", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._add_to_record", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._save_score_record", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._save_checkpoint_def"], ["\n", "# Get the real value", "\n", "if", "self", ".", "_timer", ".", "should_trigger_for_step", "(", "global_step", ")", ":", "\n", "                ", "self", ".", "_timer", ".", "update_last_triggered_step", "(", "global_step", ")", "\n", "# Save model", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_base_dir", ",", "\"model.ckpt\"", ")", "\n", "saver", "=", "_get_saver", "(", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"Saving checkpoints for %d into %s.\"", "%", "\n", "(", "global_step", ",", "save_path", ")", ")", "\n", "saver", ".", "save", "(", "run_context", ".", "session", ",", "\n", "save_path", ",", "\n", "global_step", "=", "global_step", ")", "\n", "# Do validation here", "\n", "tf", ".", "logging", ".", "info", "(", "\"Validating model at step %d\"", "%", "global_step", ")", "\n", "score", "=", "_evaluate", "(", "self", ".", "_eval_fn", ",", "self", ".", "_eval_input_fn", ",", "\n", "self", ".", "_eval_decode_fn", ",", "\n", "self", ".", "_base_dir", ",", "\n", "self", ".", "_session_config", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"%s at step %d: %f\"", "%", "\n", "(", "self", ".", "_metric", ",", "global_step", ",", "score", ")", ")", "\n", "\n", "_save_log", "(", "self", ".", "_log_name", ",", "(", "self", ".", "_metric", ",", "global_step", ",", "score", ")", ")", "\n", "\n", "checkpoint_filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_base_dir", ",", "\n", "\"checkpoint\"", ")", "\n", "all_checkpoints", "=", "_read_checkpoint_def", "(", "checkpoint_filename", ")", "\n", "records", "=", "_read_score_record", "(", "self", ".", "_record_name", ")", "\n", "latest_checkpoint", "=", "all_checkpoints", "[", "-", "1", "]", "\n", "record", "=", "[", "latest_checkpoint", ",", "score", "]", "\n", "added", ",", "removed", ",", "records", "=", "_add_to_record", "(", "records", ",", "record", ",", "\n", "self", ".", "_max_to_keep", ")", "\n", "\n", "if", "added", "is", "not", "None", ":", "\n", "                    ", "old_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_base_dir", ",", "added", ")", "\n", "new_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_save_path", ",", "added", ")", "\n", "old_files", "=", "tf", ".", "gfile", ".", "Glob", "(", "old_path", "+", "\"*\"", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"Copying %s to %s\"", "%", "(", "old_path", ",", "new_path", ")", ")", "\n", "\n", "for", "o_file", "in", "old_files", ":", "\n", "                        ", "n_file", "=", "o_file", ".", "replace", "(", "old_path", ",", "new_path", ")", "\n", "tf", ".", "gfile", ".", "Copy", "(", "o_file", ",", "n_file", ",", "overwrite", "=", "True", ")", "\n", "\n", "", "", "if", "removed", "is", "not", "None", ":", "\n", "                    ", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_save_path", ",", "removed", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"Removing %s\"", "%", "filename", ")", "\n", "files", "=", "tf", ".", "gfile", ".", "Glob", "(", "filename", "+", "\"*\"", ")", "\n", "\n", "for", "name", "in", "files", ":", "\n", "                        ", "tf", ".", "gfile", ".", "Remove", "(", "name", ")", "\n", "\n", "", "", "_save_score_record", "(", "self", ".", "_record_name", ",", "records", ")", "\n", "checkpoint_filename", "=", "checkpoint_filename", ".", "replace", "(", "\n", "self", ".", "_base_dir", ",", "self", ".", "_save_path", "\n", ")", "\n", "_save_checkpoint_def", "(", "checkpoint_filename", ",", "\n", "[", "item", "[", "0", "]", "for", "item", "in", "records", "]", ")", "\n", "\n", "best_score", "=", "records", "[", "0", "]", "[", "1", "]", "\n", "tf", ".", "logging", ".", "info", "(", "\"Best score at step %d: %f\"", "%", "\n", "(", "global_step", ",", "best_score", ")", ")", "\n", "\n", "", "", "", "def", "end", "(", "self", ",", "session", ")", ":", "\n", "        ", "last_step", "=", "session", ".", "run", "(", "self", ".", "_global_step", ")", "\n", "\n", "if", "last_step", "!=", "self", ".", "_timer", ".", "last_triggered_step", "(", ")", ":", "\n", "            ", "global_step", "=", "last_step", "\n", "tf", ".", "logging", ".", "info", "(", "\"Validating model at step %d\"", "%", "global_step", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks.EvaluationHook.end": [[354, 404], ["session.run", "hooks.EvaluationHook._timer.last_triggered_step", "tensorflow.logging.info", "hooks._evaluate", "tensorflow.logging.info", "os.path.join", "hooks._read_checkpoint_def", "hooks._read_score_record", "hooks._add_to_record", "hooks._save_score_record", "checkpoint_filename.replace.replace.replace", "hooks._save_checkpoint_def", "tensorflow.logging.info", "os.path.join", "os.path.join", "tensorflow.gfile.Glob", "tensorflow.logging.info", "os.path.join", "tensorflow.logging.info", "tensorflow.gfile.Glob", "o_file.replace", "tensorflow.gfile.Copy", "tensorflow.gfile.Remove"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._evaluate", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._read_checkpoint_def", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._read_score_record", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._add_to_record", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._save_score_record", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._save_checkpoint_def"], ["score", "=", "_evaluate", "(", "self", ".", "_eval_fn", ",", "self", ".", "_eval_input_fn", ",", "\n", "self", ".", "_eval_decode_fn", ",", "\n", "self", ".", "_base_dir", ",", "\n", "self", ".", "_session_config", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"%s at step %d: %f\"", "%", "\n", "(", "self", ".", "_metric", ",", "global_step", ",", "score", ")", ")", "\n", "\n", "checkpoint_filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_base_dir", ",", "\n", "\"checkpoint\"", ")", "\n", "all_checkpoints", "=", "_read_checkpoint_def", "(", "checkpoint_filename", ")", "\n", "records", "=", "_read_score_record", "(", "self", ".", "_record_name", ")", "\n", "latest_checkpoint", "=", "all_checkpoints", "[", "-", "1", "]", "\n", "record", "=", "[", "latest_checkpoint", ",", "score", "]", "\n", "added", ",", "removed", ",", "records", "=", "_add_to_record", "(", "records", ",", "record", ",", "\n", "self", ".", "_max_to_keep", ")", "\n", "\n", "if", "added", "is", "not", "None", ":", "\n", "                ", "old_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_base_dir", ",", "added", ")", "\n", "new_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_save_path", ",", "added", ")", "\n", "old_files", "=", "tf", ".", "gfile", ".", "Glob", "(", "old_path", "+", "\"*\"", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"Copying %s to %s\"", "%", "(", "old_path", ",", "new_path", ")", ")", "\n", "\n", "for", "o_file", "in", "old_files", ":", "\n", "                    ", "n_file", "=", "o_file", ".", "replace", "(", "old_path", ",", "new_path", ")", "\n", "tf", ".", "gfile", ".", "Copy", "(", "o_file", ",", "n_file", ",", "overwrite", "=", "True", ")", "\n", "\n", "", "", "if", "removed", "is", "not", "None", ":", "\n", "                ", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_save_path", ",", "removed", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"Removing %s\"", "%", "filename", ")", "\n", "files", "=", "tf", ".", "gfile", ".", "Glob", "(", "filename", "+", "\"*\"", ")", "\n", "\n", "for", "name", "in", "files", ":", "\n", "                    ", "tf", ".", "gfile", ".", "Remove", "(", "name", ")", "\n", "\n", "", "", "_save_score_record", "(", "self", ".", "_record_name", ",", "records", ")", "\n", "checkpoint_filename", "=", "checkpoint_filename", ".", "replace", "(", "\n", "self", ".", "_base_dir", ",", "self", ".", "_save_path", "\n", ")", "\n", "_save_checkpoint_def", "(", "checkpoint_filename", ",", "\n", "[", "item", "[", "0", "]", "for", "item", "in", "records", "]", ")", "\n", "\n", "best_score", "=", "records", "[", "0", "]", "[", "1", "]", "\n", "tf", ".", "logging", ".", "info", "(", "\"Best score: %f\"", "%", "best_score", ")", "\n", "\n", "\n", "", "", "", "class", "MultiStepHook", "(", "tf", ".", "train", ".", "SessionRunHook", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "hook", ",", "step", "=", "1", ")", ":", "\n", "        ", "self", ".", "_hook", "=", "hook", "\n", "self", ".", "_step", "=", "step", "\n", "self", ".", "_iter", "=", "0", "if", "step", "==", "1", "else", "1", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks.MultiStepHook.__init__": [[408, 412], ["None"], "methods", ["None"], ["\n", "", "def", "after_create_session", "(", "self", ",", "session", ",", "coord", ")", ":", "\n", "        ", "self", ".", "_hook", ".", "after_create_session", "(", "session", ",", "coord", ")", "\n", "\n", "", "def", "before_run", "(", "self", ",", "run_context", ")", ":", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks.MultiStepHook.begin": [[413, 415], ["hooks.MultiStepHook._hook.begin"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks.MultiStepHook.begin"], ["        ", "return", "self", ".", "_hook", ".", "before_run", "(", "run_context", ")", "\n", "\n", "", "def", "after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks.MultiStepHook.after_create_session": [[416, 418], ["hooks.MultiStepHook._hook.after_create_session"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks.MultiStepHook.after_create_session"], ["        ", "if", "self", ".", "_iter", "%", "self", ".", "_step", "==", "0", ":", "\n", "            ", "self", ".", "_hook", ".", "after_run", "(", "run_context", ",", "run_values", ")", "\n", "", "self", ".", "_iter", "=", "(", "self", ".", "_iter", "+", "1", ")", "%", "self", ".", "_step", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks.MultiStepHook.before_run": [[419, 421], ["hooks.MultiStepHook._hook.before_run"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks.MultiStepHook.before_run"], ["\n", "", "def", "end", "(", "self", ",", "session", ")", ":", "\n", "        ", "self", ".", "_hook", ".", "end", "(", "session", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks.MultiStepHook.after_run": [[422, 426], ["hooks.MultiStepHook._hook.after_run"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks.MultiStepHook.after_run"], ["", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks.MultiStepHook.end": [[427, 429], ["hooks.MultiStepHook._hook.end"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks.MultiStepHook.end"], []], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._get_saver": [[17, 29], ["tensorflow.get_collection", "RuntimeError", "len", "RuntimeError"], "function", ["None"], ["# Get saver from the SAVERS collection if present.", "\n", "    ", "collection_key", "=", "tf", ".", "GraphKeys", ".", "SAVERS", "\n", "savers", "=", "tf", ".", "get_collection", "(", "collection_key", ")", "\n", "\n", "if", "not", "savers", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"No items in collection {}. \"", "\n", "\"Please add a saver to the collection \"", ")", "\n", "", "elif", "len", "(", "savers", ")", ">", "1", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"More than one item in collection\"", ")", "\n", "\n", "", "return", "savers", "[", "0", "]", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._save_log": [[31, 38], ["open", "datetime.datetime.now", "fd.write"], "function", ["None"], ["    ", "metric", ",", "global_step", ",", "score", "=", "result", "\n", "\n", "with", "open", "(", "filename", ",", "\"a\"", ")", "as", "fd", ":", "\n", "        ", "time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "msg", "=", "\"%s: %s at step %d: %f\\n\"", "%", "(", "time", ",", "metric", ",", "global_step", ",", "score", ")", "\n", "fd", ".", "write", "(", "msg", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._read_checkpoint_def": [[40, 50], ["tensorflow.gfile.GFile", "fd.readline", "records.append", "[].split", "[].strip", "line.strip().split", "line.strip"], "function", ["None"], ["    ", "records", "=", "[", "]", "\n", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "filename", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "readline", "(", ")", "\n", "\n", "for", "line", "in", "fd", ":", "\n", "            ", "records", ".", "append", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "\":\"", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "[", "1", ":", "-", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ")", "\n", "\n", "", "", "return", "records", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._save_checkpoint_def": [[52, 68], ["sorted", "int", "keys.append", "tensorflow.gfile.GFile", "fd.write", "operator.itemgetter", "fd.write", "checkpoint_name.strip().split", "checkpoint_name.strip"], "function", ["None"], ["    ", "keys", "=", "[", "]", "\n", "\n", "for", "checkpoint_name", "in", "checkpoint_names", ":", "\n", "        ", "step", "=", "int", "(", "checkpoint_name", ".", "strip", "(", ")", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ")", "\n", "keys", ".", "append", "(", "(", "step", ",", "checkpoint_name", ")", ")", "\n", "\n", "", "sorted_names", "=", "sorted", "(", "keys", ",", "key", "=", "operator", ".", "itemgetter", "(", "0", ")", ",", "\n", "reverse", "=", "True", ")", "\n", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "filename", ",", "\"w\"", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "\"model_checkpoint_path: \\\"%s\\\"\\n\"", "%", "checkpoint_names", "[", "0", "]", ")", "\n", "\n", "for", "checkpoint_name", "in", "sorted_names", ":", "\n", "            ", "checkpoint_name", "=", "checkpoint_name", "[", "1", "]", "\n", "fd", ".", "write", "(", "\"all_model_checkpoint_paths: \\\"%s\\\"\\n\"", "%", "checkpoint_name", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._read_score_record": [[70, 85], ["tensorflow.gfile.Exists", "tensorflow.gfile.GFile", "line.strip().split", "float", "records.append", "name.strip", "line.strip"], "function", ["None"], ["# \"checkpoint_name\": score", "\n", "    ", "records", "=", "[", "]", "\n", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "filename", ")", ":", "\n", "        ", "return", "records", "\n", "\n", "", "with", "tf", ".", "gfile", ".", "GFile", "(", "filename", ")", "as", "fd", ":", "\n", "        ", "for", "line", "in", "fd", ":", "\n", "            ", "name", ",", "score", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\":\"", ")", "\n", "name", "=", "name", ".", "strip", "(", ")", "[", "1", ":", "-", "1", "]", "\n", "score", "=", "float", "(", "score", ")", "\n", "records", ".", "append", "(", "[", "name", ",", "score", "]", ")", "\n", "\n", "", "", "return", "records", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._save_score_record": [[87, 103], ["sorted", "int", "keys.append", "tensorflow.gfile.GFile", "operator.itemgetter", "fd.write", "checkpoint_name.strip().split", "checkpoint_name.strip"], "function", ["None"], ["    ", "keys", "=", "[", "]", "\n", "\n", "for", "record", "in", "records", ":", "\n", "        ", "checkpoint_name", "=", "record", "[", "0", "]", "\n", "step", "=", "int", "(", "checkpoint_name", ".", "strip", "(", ")", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ")", "\n", "keys", ".", "append", "(", "(", "step", ",", "record", ")", ")", "\n", "\n", "", "sorted_keys", "=", "sorted", "(", "keys", ",", "key", "=", "operator", ".", "itemgetter", "(", "0", ")", ",", "\n", "reverse", "=", "True", ")", "\n", "sorted_records", "=", "[", "item", "[", "1", "]", "for", "item", "in", "sorted_keys", "]", "\n", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "filename", ",", "\"w\"", ")", "as", "fd", ":", "\n", "        ", "for", "record", "in", "sorted_records", ":", "\n", "            ", "checkpoint_name", ",", "score", "=", "record", "\n", "fd", ".", "write", "(", "\"\\\"%s\\\": %f\\n\"", "%", "(", "checkpoint_name", ",", "score", ")", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._add_to_record": [[105, 132], ["sorted", "len", "sorted", "sorted.append"], "function", ["None"], ["    ", "added", "=", "None", "\n", "removed", "=", "None", "\n", "models", "=", "{", "}", "\n", "\n", "for", "(", "name", ",", "score", ")", "in", "records", ":", "\n", "        ", "models", "[", "name", "]", "=", "score", "\n", "\n", "", "if", "len", "(", "records", ")", "<", "max_to_keep", ":", "\n", "        ", "if", "record", "[", "0", "]", "not", "in", "models", ":", "\n", "            ", "added", "=", "record", "[", "0", "]", "\n", "records", ".", "append", "(", "record", ")", "\n", "", "", "else", ":", "\n", "        ", "sorted_records", "=", "sorted", "(", "records", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", "\n", "worst_score", "=", "sorted_records", "[", "-", "1", "]", "[", "1", "]", "\n", "current_score", "=", "record", "[", "1", "]", "\n", "\n", "if", "current_score", ">=", "worst_score", ":", "\n", "            ", "if", "record", "[", "0", "]", "not", "in", "models", ":", "\n", "                ", "added", "=", "record", "[", "0", "]", "\n", "removed", "=", "sorted_records", "[", "-", "1", "]", "[", "0", "]", "\n", "records", "=", "sorted_records", "[", ":", "-", "1", "]", "+", "[", "record", "]", "\n", "\n", "# Sort", "\n", "", "", "", "records", "=", "sorted", "(", "records", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", "\n", "\n", "return", "added", ",", "removed", ",", "records", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._evaluate": [[159, 214], ["tensorflow.Graph", "tf.Graph.as_default", "input_fn", "range", "thumt.data_parallelism", "tensorflow.train.ChiefSessionCreator", "decode_fn", "enumerate", "thumt.bleu", "len", "placeholders.append", "tensorflow.train.MonitoredSession", "decode_fn", "list", "range", "sess.should_stop", "sess.run", "hooks._shard_features", "sess.run", "range", "zip", "tensorflow.placeholder", "tensorflow.placeholder", "len", "all_outputs.extend", "item.tolist", "len", "all_refs[].extend", "shard.tolist"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo.data_parallelism", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.bleu.bleu", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._shard_features"], ["predictions", "=", "eval_fn", "(", "placeholders", ")", "\n", "predictions", "=", "predictions", "[", "0", "]", "[", ":", ",", "0", ",", ":", "]", "\n", "\n", "all_refs", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "refs", ")", ")", "]", "\n", "all_outputs", "=", "[", "]", "\n", "\n", "sess_creator", "=", "tf", ".", "train", ".", "ChiefSessionCreator", "(", "\n", "checkpoint_dir", "=", "path", ",", "\n", "config", "=", "config", "\n", ")", "\n", "\n", "with", "tf", ".", "train", ".", "MonitoredSession", "(", "session_creator", "=", "sess_creator", ")", "as", "sess", ":", "\n", "            ", "while", "not", "sess", ".", "should_stop", "(", ")", ":", "\n", "                ", "feats", "=", "sess", ".", "run", "(", "features", ")", "\n", "outputs", "=", "sess", ".", "run", "(", "predictions", ",", "feed_dict", "=", "{", "\n", "placeholders", "[", "\"source\"", "]", ":", "feats", "[", "\"source\"", "]", ",", "\n", "placeholders", "[", "\"source_length\"", "]", ":", "feats", "[", "\"source_length\"", "]", ",", "\n", "placeholders", "[", "\"context_dia_src\"", "]", ":", "feats", "[", "\"context_dia_src\"", "]", ",", "\n", "placeholders", "[", "\"context_dia_tgt\"", "]", ":", "feats", "[", "\"context_dia_tgt\"", "]", ",", "\n", "placeholders", "[", "\"context_sty_src\"", "]", ":", "feats", "[", "\"context_sty_src\"", "]", ",", "\n", "placeholders", "[", "\"context_sty_tgt\"", "]", ":", "feats", "[", "\"context_sty_tgt\"", "]", ",", "\n", "placeholders", "[", "\"context_source\"", "]", ":", "feats", "[", "\"context_source\"", "]", ",", "\n", "placeholders", "[", "\"context_dia_src_length\"", "]", ":", "feats", "[", "\"context_dia_src_length\"", "]", ",", "\n", "placeholders", "[", "\"context_dia_tgt_length\"", "]", ":", "feats", "[", "\"context_dia_tgt_length\"", "]", ",", "\n", "placeholders", "[", "\"context_sty_src_length\"", "]", ":", "feats", "[", "\"context_sty_src_length\"", "]", ",", "\n", "placeholders", "[", "\"context_sty_tgt_length\"", "]", ":", "feats", "[", "\"context_sty_tgt_length\"", "]", ",", "\n", "placeholders", "[", "\"context_source_length\"", "]", ":", "feats", "[", "\"context_source_length\"", "]", ",", "\n", "placeholders", "[", "\"position_dia_src\"", "]", ":", "feats", "[", "\"position_dia_src\"", "]", ",", "\n", "placeholders", "[", "\"position_dia_tgt\"", "]", ":", "feats", "[", "\"position_dia_tgt\"", "]", ",", "\n", "placeholders", "[", "\"position_sty_src\"", "]", ":", "feats", "[", "\"position_sty_src\"", "]", ",", "\n", "placeholders", "[", "\"position_sty_tgt\"", "]", ":", "feats", "[", "\"position_sty_tgt\"", "]", ",", "\n", "placeholders", "[", "\"position_ctx_src\"", "]", ":", "feats", "[", "\"position_ctx_src\"", "]", ",", "\n", "placeholders", "[", "\"sample\"", "]", ":", "feats", "[", "\"sample\"", "]", ",", "\n", "placeholders", "[", "\"sample_length\"", "]", ":", "feats", "[", "\"sample_length\"", "]", "\n", "}", ")", "\n", "# shape: [batch, len]", "\n", "outputs", "=", "outputs", ".", "tolist", "(", ")", "\n", "# shape: ([batch, len], ..., [batch, len])", "\n", "references", "=", "[", "item", ".", "tolist", "(", ")", "for", "item", "in", "feats", "[", "\"references\"", "]", "]", "\n", "\n", "all_outputs", ".", "extend", "(", "outputs", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "refs", ")", ")", ":", "\n", "                    ", "all_refs", "[", "i", "]", ".", "extend", "(", "references", "[", "i", "]", ")", "\n", "\n", "", "", "", "decoded_symbols", "=", "decode_fn", "(", "all_outputs", ")", "\n", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "decoded_symbols", ")", ":", "\n", "            ", "decoded_symbols", "[", "i", "]", "=", "\" \"", ".", "join", "(", "l", ")", ".", "replace", "(", "\"@@ \"", ",", "\"\"", ")", ".", "split", "(", ")", "\n", "\n", "", "decoded_refs", "=", "[", "decode_fn", "(", "refs", ")", "for", "refs", "in", "all_refs", "]", "\n", "decoded_refs", "=", "[", "list", "(", "x", ")", "for", "x", "in", "zip", "(", "*", "decoded_refs", ")", "]", "\n", "\n", "return", "bleu", ".", "bleu", "(", "decoded_symbols", ",", "decoded_refs", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo._maybe_repeat": [[14, 20], ["isinstance", "len"], "function", ["None"], ["def", "_maybe_repeat", "(", "x", ",", "n", ")", ":", "\n", "    ", "if", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "        ", "assert", "len", "(", "x", ")", "==", "n", "\n", "return", "x", "\n", "", "else", ":", "\n", "        ", "return", "[", "x", "]", "*", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo.data_parallelism": [[23, 61], ["len", "six.iteritems", "parallel_emo._maybe_repeat", "range", "parallel_emo._maybe_repeat", "range", "parallel_emo._maybe_repeat", "list", "range", "tensorflow.variable_scope", "zip", "range", "tensorflow.get_variable_scope", "tensorflow.name_scope", "tensorflow.device", "outputs.append"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo._maybe_repeat", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo._maybe_repeat", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo._maybe_repeat"], ["", "", "def", "data_parallelism", "(", "devices", ",", "fn", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "num_worker", "=", "len", "(", "devices", ")", "\n", "devices", "=", "[", "\"gpu:%d\"", "%", "d", "for", "d", "in", "devices", "]", "\n", "\n", "# Replicate args and kwargs", "\n", "if", "args", ":", "\n", "        ", "new_args", "=", "[", "_maybe_repeat", "(", "arg", ",", "num_worker", ")", "for", "arg", "in", "args", "]", "\n", "# Transpose", "\n", "new_args", "=", "[", "list", "(", "x", ")", "for", "x", "in", "zip", "(", "*", "new_args", ")", "]", "\n", "", "else", ":", "\n", "        ", "new_args", "=", "[", "[", "]", "for", "_", "in", "range", "(", "num_worker", ")", "]", "\n", "\n", "", "new_kwargs", "=", "[", "{", "}", "for", "_", "in", "range", "(", "num_worker", ")", "]", "\n", "\n", "for", "k", ",", "v", "in", "six", ".", "iteritems", "(", "kwargs", ")", ":", "\n", "        ", "vals", "=", "_maybe_repeat", "(", "v", ",", "num_worker", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_worker", ")", ":", "\n", "            ", "new_kwargs", "[", "i", "]", "[", "k", "]", "=", "vals", "[", "i", "]", "\n", "\n", "", "", "fns", "=", "_maybe_repeat", "(", "fn", ",", "num_worker", ")", "\n", "\n", "# Now make the parallel call.", "\n", "outputs", "=", "[", "]", "\n", "kl_outputs", "=", "[", "]", "\n", "bow_outputs", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_worker", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "(", "i", "!=", "0", ")", ")", ":", "\n", "            ", "with", "tf", ".", "name_scope", "(", "\"parallel_%d\"", "%", "i", ")", ":", "\n", "                ", "with", "tf", ".", "device", "(", "devices", "[", "i", "]", ")", ":", "\n", "                    ", "loss", "=", "fns", "[", "i", "]", "(", "*", "new_args", "[", "i", "]", ",", "**", "new_kwargs", "[", "i", "]", ")", "\n", "outputs", ".", "append", "(", "loss", ")", "\n", "#kl_outputs.append(kl_loss)", "\n", "#bow_outputs.append(bow_loss)", "\n", "#                outputs.append(fns[i](*new_args[i], **new_kwargs[i]))", "\n", "\n", "", "", "", "", "return", "outputs", "#, kl_outputs, bow_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo.shard_features": [[63, 96], ["len", "range", "tensorflow.device", "six.iteritems", "datashard_to_features.append", "tensorflow.convert_to_tensor", "range", "tensorflow.split", "tf.tile.shape.as_list", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "size_splits.append", "six.iteritems", "tensorflow.cond", "tensorflow.greater", "tensorflow.mod"], "function", ["None"], ["", "def", "shard_features", "(", "features", ",", "device_list", ")", ":", "\n", "    ", "num_datashards", "=", "len", "(", "device_list", ")", "\n", "sharded_features", "=", "{", "}", "\n", "\n", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "six", ".", "iteritems", "(", "features", ")", ":", "\n", "            ", "v", "=", "tf", ".", "convert_to_tensor", "(", "v", ")", "\n", "\n", "if", "not", "v", ".", "shape", ".", "as_list", "(", ")", ":", "\n", "                ", "v", "=", "tf", ".", "expand_dims", "(", "v", ",", "axis", "=", "-", "1", ")", "\n", "v", "=", "tf", ".", "tile", "(", "v", ",", "[", "num_datashards", "]", ")", "\n", "\n", "", "batch_size", "=", "tf", ".", "shape", "(", "v", ")", "[", "0", "]", "\n", "size_splits", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_datashards", ")", ":", "\n", "                ", "size_splits", ".", "append", "(", "\n", "tf", ".", "cond", "(", "tf", ".", "greater", "(", "tf", ".", "mod", "(", "batch_size", ",", "num_datashards", ")", ",", "i", ")", ",", "\n", "lambda", ":", "batch_size", "//", "num_datashards", "+", "1", ",", "\n", "lambda", ":", "batch_size", "//", "num_datashards", ")", "\n", ")", "\n", "\n", "", "sharded_features", "[", "k", "]", "=", "tf", ".", "split", "(", "v", ",", "size_splits", ",", "0", ")", "\n", "\n", "", "", "datashard_to_features", "=", "[", "]", "\n", "\n", "for", "d", "in", "range", "(", "num_datashards", ")", ":", "\n", "        ", "feat", "=", "{", "\n", "k", ":", "v", "[", "d", "]", "for", "k", ",", "v", "in", "six", ".", "iteritems", "(", "sharded_features", ")", "\n", "}", "\n", "datashard_to_features", ".", "append", "(", "feat", ")", "\n", "\n", "", "return", "datashard_to_features", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo.parallel_model": [[98, 108], ["parallel_emo.shard_features", "parallel_emo.data_parallelism", "len", "model_fn"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_bak.shard_features", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo.data_parallelism"], ["", "def", "parallel_model", "(", "model_fn", ",", "features", ",", "devices", ")", ":", "\n", "    ", "if", "len", "(", "devices", ")", "==", "1", ":", "\n", "        ", "outputs", ",", "kl_outputs", "=", "model_fn", "(", "features", ")", "\n", "return", "[", "outputs", "]", ",", "[", "kl_outputs", "]", "\n", "#        return [model_fn(features)]", "\n", "\n", "", "features", "=", "shard_features", "(", "features", ",", "devices", ")", "\n", "\n", "outputs", "=", "data_parallelism", "(", "devices", ",", "model_fn", ",", "features", ")", "\n", "return", "outputs", "#, kl_outputs, bow_outputs", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._get_inference_fn": [[20, 69], ["zip", "tensorflow.pad", "tensorflow.fill", "tensorflow.add_n", "float", "model_fn", "outputs.append", "next_state.append", "model_fn", "outputs.append", "next_state.append", "len", "tensorflow.shape", "tensorflow.shape"], "function", ["None"], ["", "def", "_get_inference_fn", "(", "model_fns", ",", "features", ")", ":", "\n", "    ", "def", "inference_fn", "(", "inputs", ",", "state", ")", ":", "\n", "        ", "local_features", "=", "{", "\n", "\"source\"", ":", "features", "[", "\"source\"", "]", ",", "\n", "\"source_length\"", ":", "features", "[", "\"source_length\"", "]", ",", "\n", "\"context_dia_src\"", ":", "features", "[", "\"context_dia_src\"", "]", ",", "\n", "\"context_dia_tgt\"", ":", "features", "[", "\"context_dia_tgt\"", "]", ",", "\n", "\"context_sty_src\"", ":", "features", "[", "\"context_sty_src\"", "]", ",", "\n", "\"context_sty_tgt\"", ":", "features", "[", "\"context_sty_tgt\"", "]", ",", "\n", "\"context_lan_src\"", ":", "features", "[", "\"context_lan_src\"", "]", ",", "\n", "\"context_lan_tgt\"", ":", "features", "[", "\"context_lan_tgt\"", "]", ",", "\n", "\"context_dia_src_length\"", ":", "features", "[", "\"context_dia_src_length\"", "]", ",", "\n", "\"context_dia_tgt_length\"", ":", "features", "[", "\"context_dia_tgt_length\"", "]", ",", "\n", "\"context_sty_src_length\"", ":", "features", "[", "\"context_sty_src_length\"", "]", ",", "\n", "\"context_sty_tgt_length\"", ":", "features", "[", "\"context_sty_tgt_length\"", "]", ",", "\n", "\"context_lan_src_length\"", ":", "features", "[", "\"context_lan_src_length\"", "]", ",", "\n", "\"context_lan_tgt_length\"", ":", "features", "[", "\"context_lan_tgt_length\"", "]", ",", "\n", "\"emotion\"", ":", "features", "[", "\"emotion\"", "]", ",", "\n", "\"position_dia_src\"", ":", "features", "[", "\"position_dia_src\"", "]", ",", "\n", "\"position_dia_tgt\"", ":", "features", "[", "\"position_dia_tgt\"", "]", ",", "\n", "\"position_sty_src\"", ":", "features", "[", "\"position_sty_src\"", "]", ",", "\n", "\"position_sty_tgt\"", ":", "features", "[", "\"position_sty_tgt\"", "]", ",", "\n", "\"position_lan_src\"", ":", "features", "[", "\"position_lan_src\"", "]", ",", "\n", "\"position_lan_tgt\"", ":", "features", "[", "\"position_lan_tgt\"", "]", ",", "\n", "# [bos_id, ...] => [..., 0]", "\n", "\"target\"", ":", "tf", ".", "pad", "(", "inputs", "[", ":", ",", "1", ":", "]", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "1", "]", "]", ")", ",", "\n", "\"target_length\"", ":", "tf", ".", "fill", "(", "[", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "]", ",", "\n", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", ")", "\n", "}", "\n", "\n", "outputs", "=", "[", "]", "\n", "next_state", "=", "[", "]", "\n", "\n", "for", "(", "model_fn", ",", "model_state", ")", "in", "zip", "(", "model_fns", ",", "state", ")", ":", "\n", "            ", "if", "model_state", ":", "\n", "                ", "output", ",", "new_state", "=", "model_fn", "(", "local_features", ",", "model_state", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "next_state", ".", "append", "(", "new_state", ")", "\n", "", "else", ":", "\n", "                ", "output", "=", "model_fn", "(", "local_features", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "next_state", ".", "append", "(", "{", "}", ")", "\n", "\n", "# Ensemble", "\n", "", "", "log_prob", "=", "tf", ".", "add_n", "(", "outputs", ")", "/", "float", "(", "len", "(", "outputs", ")", ")", "\n", "\n", "return", "log_prob", ",", "next_state", "\n", "\n", "", "return", "inference_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._infer_shape": [[71, 89], ["tensorflow.convert_to_tensor", "tf.convert_to_tensor.shape.as_list", "tensorflow.shape", "range", "tensorflow.shape", "len", "ret.append"], "function", ["None"], ["", "def", "_infer_shape", "(", "x", ")", ":", "\n", "    ", "x", "=", "tf", ".", "convert_to_tensor", "(", "x", ")", "\n", "\n", "# If unknown rank, return dynamic shape", "\n", "if", "x", ".", "shape", ".", "dims", "is", "None", ":", "\n", "        ", "return", "tf", ".", "shape", "(", "x", ")", "\n", "\n", "", "static_shape", "=", "x", ".", "shape", ".", "as_list", "(", ")", "\n", "dynamic_shape", "=", "tf", ".", "shape", "(", "x", ")", "\n", "\n", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "static_shape", ")", ")", ":", "\n", "        ", "dim", "=", "static_shape", "[", "i", "]", "\n", "if", "dim", "is", "None", ":", "\n", "            ", "dim", "=", "dynamic_shape", "[", "i", "]", "\n", "", "ret", ".", "append", "(", "dim", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._infer_shape_invariants": [[91, 96], ["tensor.shape.as_list", "range", "tensorflow.TensorShape", "len"], "function", ["None"], ["", "def", "_infer_shape_invariants", "(", "tensor", ")", ":", "\n", "    ", "shape", "=", "tensor", ".", "shape", ".", "as_list", "(", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "shape", ")", "-", "1", ")", ":", "\n", "        ", "shape", "[", "i", "]", "=", "None", "\n", "", "return", "tf", ".", "TensorShape", "(", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._merge_first_two_dims": [[98, 103], ["inference_ctx._infer_shape", "_infer_shape.pop", "tensorflow.reshape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._infer_shape"], ["", "def", "_merge_first_two_dims", "(", "tensor", ")", ":", "\n", "    ", "shape", "=", "_infer_shape", "(", "tensor", ")", "\n", "shape", "[", "0", "]", "*=", "shape", "[", "1", "]", "\n", "shape", ".", "pop", "(", "1", ")", "\n", "return", "tf", ".", "reshape", "(", "tensor", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._split_first_two_dims": [[105, 109], ["inference_ctx._infer_shape", "tensorflow.reshape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._infer_shape"], ["", "def", "_split_first_two_dims", "(", "tensor", ",", "dim_0", ",", "dim_1", ")", ":", "\n", "    ", "shape", "=", "_infer_shape", "(", "tensor", ")", "\n", "new_shape", "=", "[", "dim_0", "]", "+", "[", "dim_1", "]", "+", "shape", "[", "1", ":", "]", "\n", "return", "tf", ".", "reshape", "(", "tensor", ",", "new_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._tile_to_beam_size": [[111, 118], ["tensorflow.expand_dims", "tensorflow.tile"], "function", ["None"], ["", "def", "_tile_to_beam_size", "(", "tensor", ",", "beam_size", ")", ":", "\n", "    ", "\"\"\"Tiles a given tensor by beam_size. \"\"\"", "\n", "tensor", "=", "tf", ".", "expand_dims", "(", "tensor", ",", "axis", "=", "1", ")", "\n", "tile_dims", "=", "[", "1", "]", "*", "tensor", ".", "shape", ".", "ndims", "\n", "tile_dims", "[", "1", "]", "=", "beam_size", "\n", "\n", "return", "tf", ".", "tile", "(", "tensor", ",", "tile_dims", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._gather_2d": [[120, 134], ["tensorflow.reshape", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.shape", "tensorflow.shape", "tensorflow.range"], "function", ["None"], ["", "def", "_gather_2d", "(", "params", ",", "indices", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\" Gather the 2nd dimension given indices\n    :param params: A tensor with shape [batch_size, M, ...]\n    :param indices: A tensor with shape [batch_size, N]\n    :return: A tensor with shape [batch_size, N, ...]\n    \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "params", ")", "[", "0", "]", "\n", "range_size", "=", "tf", ".", "shape", "(", "indices", ")", "[", "1", "]", "\n", "batch_pos", "=", "tf", ".", "range", "(", "batch_size", "*", "range_size", ")", "//", "range_size", "\n", "batch_pos", "=", "tf", ".", "reshape", "(", "batch_pos", ",", "[", "batch_size", ",", "range_size", "]", ")", "\n", "indices", "=", "tf", ".", "stack", "(", "[", "batch_pos", ",", "indices", "]", ",", "axis", "=", "-", "1", ")", "\n", "output", "=", "tf", ".", "gather_nd", "(", "params", ",", "indices", ",", "name", "=", "name", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._beam_search_step": [[136, 212], ["print", "inference_ctx._merge_first_two_dims", "tensorflow.python.util.nest.map_structure", "print", "func", "inference_ctx._split_first_two_dims", "print", "tensorflow.python.util.nest.map_structure", "tensorflow.pow", "tensorflow.reshape", "tensorflow.nn.top_k", "inference_ctx._gather_2d", "tensorflow.concat", "tensorflow.equal", "tensorflow.nn.top_k", "inference_ctx._gather_2d", "inference_ctx._gather_2d", "inference_ctx._gather_2d", "tensorflow.concat", "tensorflow.python.util.nest.map_structure", "print", "tensorflow.concat", "tensorflow.concat", "tensorflow.nn.top_k", "inference_ctx._gather_2d", "tensorflow.fill", "tensorflow.concat", "tensorflow.concat", "inference_ctx._gather_2d", "inference_ctx.BeamSearchState", "tensorflow.expand_dims", "tensorflow.constant", "inference_ctx._merge_first_two_dims", "inference_ctx._split_first_two_dims", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.to_float", "tensorflow.expand_dims", "inference_ctx._gather_2d", "tensorflow.to_float", "tensorflow.to_float"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._merge_first_two_dims", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._split_first_two_dims", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._merge_first_two_dims", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._split_first_two_dims", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._gather_2d"], ["", "def", "_beam_search_step", "(", "time", ",", "func", ",", "state", ",", "batch_size", ",", "beam_size", ",", "alpha", ",", "\n", "pad_id", ",", "eos_id", ")", ":", "\n", "# Compute log probabilities", "\n", "    ", "print", "(", "'st2'", ",", "state", ")", "\n", "seqs", ",", "log_probs", "=", "state", ".", "inputs", "[", ":", "2", "]", "\n", "flat_seqs", "=", "_merge_first_two_dims", "(", "seqs", ")", "\n", "flat_state", "=", "nest", ".", "map_structure", "(", "lambda", "x", ":", "_merge_first_two_dims", "(", "x", ")", ",", "\n", "state", ".", "state", ")", "\n", "print", "(", "'st3'", ",", "flat_state", ")", "\n", "step_log_probs", ",", "next_state", "=", "func", "(", "flat_seqs", ",", "flat_state", ")", "\n", "step_log_probs", "=", "_split_first_two_dims", "(", "step_log_probs", ",", "batch_size", ",", "\n", "beam_size", ")", "\n", "print", "(", "'st4'", ",", "next_state", ")", "\n", "next_state", "=", "nest", ".", "map_structure", "(", "\n", "lambda", "x", ":", "_split_first_two_dims", "(", "x", ",", "batch_size", ",", "beam_size", ")", ",", "next_state", ")", "\n", "curr_log_probs", "=", "tf", ".", "expand_dims", "(", "log_probs", ",", "2", ")", "+", "step_log_probs", "\n", "\n", "# Apply length penalty", "\n", "length_penalty", "=", "tf", ".", "pow", "(", "(", "5.0", "+", "tf", ".", "to_float", "(", "time", "+", "1", ")", ")", "/", "6.0", ",", "alpha", ")", "\n", "curr_scores", "=", "curr_log_probs", "/", "length_penalty", "\n", "vocab_size", "=", "curr_scores", ".", "shape", "[", "-", "1", "]", ".", "value", "or", "tf", ".", "shape", "(", "curr_scores", ")", "[", "-", "1", "]", "\n", "\n", "# Select top-k candidates", "\n", "# [batch_size, beam_size * vocab_size]", "\n", "curr_scores", "=", "tf", ".", "reshape", "(", "curr_scores", ",", "[", "-", "1", ",", "beam_size", "*", "vocab_size", "]", ")", "\n", "# [batch_size, 2 * beam_size]", "\n", "top_scores", ",", "top_indices", "=", "tf", ".", "nn", ".", "top_k", "(", "curr_scores", ",", "k", "=", "2", "*", "beam_size", ")", "\n", "# Shape: [batch_size, 2 * beam_size]", "\n", "beam_indices", "=", "top_indices", "//", "vocab_size", "\n", "symbol_indices", "=", "top_indices", "%", "vocab_size", "\n", "# Expand sequences", "\n", "# [batch_size, 2 * beam_size, time]", "\n", "candidate_seqs", "=", "_gather_2d", "(", "seqs", ",", "beam_indices", ")", "\n", "candidate_seqs", "=", "tf", ".", "concat", "(", "[", "candidate_seqs", ",", "\n", "tf", ".", "expand_dims", "(", "symbol_indices", ",", "2", ")", "]", ",", "2", ")", "\n", "\n", "# Expand sequences", "\n", "# Suppress finished sequences", "\n", "flags", "=", "tf", ".", "equal", "(", "symbol_indices", ",", "eos_id", ")", "\n", "# [batch, 2 * beam_size]", "\n", "alive_scores", "=", "top_scores", "+", "tf", ".", "to_float", "(", "flags", ")", "*", "tf", ".", "float32", ".", "min", "\n", "# [batch, beam_size]", "\n", "alive_scores", ",", "alive_indices", "=", "tf", ".", "nn", ".", "top_k", "(", "alive_scores", ",", "beam_size", ")", "\n", "alive_symbols", "=", "_gather_2d", "(", "symbol_indices", ",", "alive_indices", ")", "\n", "alive_indices", "=", "_gather_2d", "(", "beam_indices", ",", "alive_indices", ")", "\n", "alive_seqs", "=", "_gather_2d", "(", "seqs", ",", "alive_indices", ")", "\n", "# [batch_size, beam_size, time + 1]", "\n", "alive_seqs", "=", "tf", ".", "concat", "(", "[", "alive_seqs", ",", "tf", ".", "expand_dims", "(", "alive_symbols", ",", "2", ")", "]", ",", "2", ")", "\n", "alive_state", "=", "nest", ".", "map_structure", "(", "lambda", "x", ":", "_gather_2d", "(", "x", ",", "alive_indices", ")", ",", "\n", "next_state", ")", "\n", "print", "(", "'st5'", ",", "alive_state", ")", "\n", "alive_log_probs", "=", "alive_scores", "*", "length_penalty", "\n", "\n", "# Select finished sequences", "\n", "prev_fin_flags", ",", "prev_fin_seqs", ",", "prev_fin_scores", "=", "state", ".", "finish", "\n", "# [batch, 2 * beam_size]", "\n", "step_fin_scores", "=", "top_scores", "+", "(", "1.0", "-", "tf", ".", "to_float", "(", "flags", ")", ")", "*", "tf", ".", "float32", ".", "min", "\n", "# [batch, 3 * beam_size]", "\n", "fin_flags", "=", "tf", ".", "concat", "(", "[", "prev_fin_flags", ",", "flags", "]", ",", "axis", "=", "1", ")", "\n", "fin_scores", "=", "tf", ".", "concat", "(", "[", "prev_fin_scores", ",", "step_fin_scores", "]", ",", "axis", "=", "1", ")", "\n", "# [batch, beam_size]", "\n", "fin_scores", ",", "fin_indices", "=", "tf", ".", "nn", ".", "top_k", "(", "fin_scores", ",", "beam_size", ")", "\n", "fin_flags", "=", "_gather_2d", "(", "fin_flags", ",", "fin_indices", ")", "\n", "pad_seqs", "=", "tf", ".", "fill", "(", "[", "batch_size", ",", "beam_size", ",", "1", "]", ",", "\n", "tf", ".", "constant", "(", "pad_id", ",", "tf", ".", "int32", ")", ")", "\n", "prev_fin_seqs", "=", "tf", ".", "concat", "(", "[", "prev_fin_seqs", ",", "pad_seqs", "]", ",", "axis", "=", "2", ")", "\n", "fin_seqs", "=", "tf", ".", "concat", "(", "[", "prev_fin_seqs", ",", "candidate_seqs", "]", ",", "axis", "=", "1", ")", "\n", "fin_seqs", "=", "_gather_2d", "(", "fin_seqs", ",", "fin_indices", ")", "\n", "\n", "new_state", "=", "BeamSearchState", "(", "\n", "inputs", "=", "(", "alive_seqs", ",", "alive_log_probs", ",", "alive_scores", ")", ",", "\n", "state", "=", "alive_state", ",", "\n", "finish", "=", "(", "fin_flags", ",", "fin_seqs", ",", "fin_scores", ")", ",", "\n", ")", "\n", "\n", "return", "time", "+", "1", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx.beam_search": [[214, 288], ["tensorflow.fill", "tensorflow.constant", "tensorflow.tile", "tensorflow.zeros_like", "tensorflow.zeros", "tensorflow.fill", "tensorflow.zeros", "inference_ctx.BeamSearchState", "print", "tensorflow.reduce_max", "tensorflow.constant", "inference_ctx.BeamSearchState", "tensorflow.while_loop", "alive_seqs.set_shape", "tf.where.set_shape", "tensorflow.where", "tensorflow.where", "tensorflow.pow", "tensorflow.reduce_min", "tensorflow.reduce_all", "tensorflow.logical_and", "inference_ctx._beam_search_step", "tensorflow.reduce_any", "tensorflow.reduce_any", "tensorflow.to_float", "tensorflow.greater", "tensorflow.less", "tensorflow.logical_not", "tensorflow.python.util.nest.map_structure", "tensorflow.to_float", "tensorflow.reduce_any", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.to_float"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._beam_search_step"], ["", "def", "beam_search", "(", "func", ",", "state", ",", "batch_size", ",", "beam_size", ",", "max_length", ",", "alpha", ",", "\n", "pad_id", ",", "bos_id", ",", "eos_id", ")", ":", "\n", "    ", "init_seqs", "=", "tf", ".", "fill", "(", "[", "batch_size", ",", "beam_size", ",", "1", "]", ",", "bos_id", ")", "\n", "init_log_probs", "=", "tf", ".", "constant", "(", "[", "[", "0.", "]", "+", "[", "tf", ".", "float32", ".", "min", "]", "*", "(", "beam_size", "-", "1", ")", "]", ")", "\n", "init_log_probs", "=", "tf", ".", "tile", "(", "init_log_probs", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "init_scores", "=", "tf", ".", "zeros_like", "(", "init_log_probs", ")", "\n", "fin_seqs", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "beam_size", ",", "1", "]", ",", "tf", ".", "int32", ")", "\n", "fin_scores", "=", "tf", ".", "fill", "(", "[", "batch_size", ",", "beam_size", "]", ",", "tf", ".", "float32", ".", "min", ")", "\n", "fin_flags", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "beam_size", "]", ",", "tf", ".", "bool", ")", "\n", "\n", "state", "=", "BeamSearchState", "(", "\n", "inputs", "=", "(", "init_seqs", ",", "init_log_probs", ",", "init_scores", ")", ",", "\n", "state", "=", "state", ",", "\n", "finish", "=", "(", "fin_flags", ",", "fin_seqs", ",", "fin_scores", ")", ",", "\n", ")", "\n", "print", "(", "'st1'", ",", "state", ")", "\n", "\n", "max_step", "=", "tf", ".", "reduce_max", "(", "max_length", ")", "\n", "\n", "def", "_is_finished", "(", "t", ",", "s", ")", ":", "\n", "        ", "log_probs", "=", "s", ".", "inputs", "[", "1", "]", "\n", "finished_flags", "=", "s", ".", "finish", "[", "0", "]", "\n", "finished_scores", "=", "s", ".", "finish", "[", "2", "]", "\n", "max_lp", "=", "tf", ".", "pow", "(", "(", "(", "5.0", "+", "tf", ".", "to_float", "(", "max_step", ")", ")", "/", "6.0", ")", ",", "alpha", ")", "\n", "best_alive_score", "=", "log_probs", "[", ":", ",", "0", "]", "/", "max_lp", "\n", "worst_finished_score", "=", "tf", ".", "reduce_min", "(", "\n", "finished_scores", "*", "tf", ".", "to_float", "(", "finished_flags", ")", ",", "axis", "=", "1", ")", "\n", "add_mask", "=", "1.0", "-", "tf", ".", "to_float", "(", "tf", ".", "reduce_any", "(", "finished_flags", ",", "1", ")", ")", "\n", "worst_finished_score", "+=", "tf", ".", "float32", ".", "min", "*", "add_mask", "\n", "bound_is_met", "=", "tf", ".", "reduce_all", "(", "tf", ".", "greater", "(", "worst_finished_score", ",", "\n", "best_alive_score", ")", ")", "\n", "\n", "cond", "=", "tf", ".", "logical_and", "(", "tf", ".", "less", "(", "t", ",", "max_step", ")", ",", "\n", "tf", ".", "logical_not", "(", "bound_is_met", ")", ")", "\n", "\n", "return", "cond", "\n", "\n", "", "def", "_loop_fn", "(", "t", ",", "s", ")", ":", "\n", "        ", "outs", "=", "_beam_search_step", "(", "t", ",", "func", ",", "s", ",", "batch_size", ",", "beam_size", ",", "alpha", ",", "\n", "pad_id", ",", "eos_id", ")", "\n", "return", "outs", "\n", "\n", "", "time", "=", "tf", ".", "constant", "(", "0", ",", "name", "=", "\"time\"", ")", "\n", "shape_invariants", "=", "BeamSearchState", "(", "\n", "inputs", "=", "(", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "None", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ")", ",", "\n", "state", "=", "nest", ".", "map_structure", "(", "_infer_shape_invariants", ",", "state", ".", "state", ")", ",", "\n", "finish", "=", "(", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "None", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ")", "\n", ")", "\n", "outputs", "=", "tf", ".", "while_loop", "(", "_is_finished", ",", "_loop_fn", ",", "[", "time", ",", "state", "]", ",", "\n", "shape_invariants", "=", "[", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "shape_invariants", "]", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "back_prop", "=", "False", ")", "\n", "\n", "final_state", "=", "outputs", "[", "1", "]", "\n", "alive_seqs", "=", "final_state", ".", "inputs", "[", "0", "]", "\n", "alive_scores", "=", "final_state", ".", "inputs", "[", "2", "]", "\n", "final_flags", "=", "final_state", ".", "finish", "[", "0", "]", "\n", "final_seqs", "=", "final_state", ".", "finish", "[", "1", "]", "\n", "final_scores", "=", "final_state", ".", "finish", "[", "2", "]", "\n", "\n", "alive_seqs", ".", "set_shape", "(", "[", "None", ",", "beam_size", ",", "None", "]", ")", "\n", "final_seqs", ".", "set_shape", "(", "(", "None", ",", "beam_size", ",", "None", ")", ")", "\n", "\n", "final_seqs", "=", "tf", ".", "where", "(", "tf", ".", "reduce_any", "(", "final_flags", ",", "1", ")", ",", "final_seqs", ",", "\n", "alive_seqs", ")", "\n", "final_scores", "=", "tf", ".", "where", "(", "tf", ".", "reduce_any", "(", "final_flags", ",", "1", ")", ",", "final_scores", ",", "\n", "alive_scores", ")", "\n", "\n", "return", "final_seqs", ",", "final_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx.create_inference_graph": [[290, 551], ["copy.copy", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "inference_ctx._get_inference_fn", "tensorflow.python.util.nest.map_structure", "inference_ctx.beam_search", "isinstance", "ValueError", "callable", "tensorflow.shape", "nest.map_structure.append", "funcs.append", "nest.map_structure.append", "funcs.append", "inference_ctx._tile_to_beam_size"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.sampling._get_inference_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.search.beam_search", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.inference_ctx._tile_to_beam_size"], ["", "def", "create_inference_graph", "(", "model_fns", ",", "features", ",", "params", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "model_fns", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"mode_fns must be a list or tuple\"", ")", "\n", "\n", "", "features", "=", "copy", ".", "copy", "(", "features", ")", "\n", "\n", "decode_length", "=", "params", ".", "decode_length", "\n", "beam_size", "=", "params", ".", "beam_size", "\n", "top_beams", "=", "params", ".", "top_beams", "\n", "alpha", "=", "params", ".", "decode_alpha", "\n", "\n", "# Compute initial state if necessary", "\n", "states", "=", "[", "]", "\n", "funcs", "=", "[", "]", "\n", "\n", "for", "model_fn", "in", "model_fns", ":", "\n", "        ", "if", "callable", "(", "model_fn", ")", ":", "\n", "# For non-incremental decoding", "\n", "            ", "states", ".", "append", "(", "{", "}", ")", "\n", "funcs", ".", "append", "(", "model_fn", ")", "\n", "", "else", ":", "\n", "# For incremental decoding where model_fn is a tuple:", "\n", "# (encoding_fn, decoding_fn)", "\n", "            ", "states", ".", "append", "(", "model_fn", "[", "0", "]", "(", "features", ")", ")", "\n", "funcs", ".", "append", "(", "model_fn", "[", "1", "]", ")", "\n", "\n", "", "", "batch_size", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "0", "]", "\n", "pad_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "pad", "]", "\n", "bos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "bos", "]", "\n", "eos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "eos", "]", "\n", "\n", "# Expand the inputs in to the beam size", "\n", "# [batch, length] => [batch, beam_size, length]", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"source\"", "]", ",", "1", ")", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"source\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "# For source sequence length", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"source_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "[", "1", ",", "beam_size", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"source_length\"", "]", ")", "\n", "\n", "max_length", "=", "features", "[", "\"source_length\"", "]", "+", "decode_length", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "]", ")", "\n", "\n", "######", "\n", "# Expand the inputs in to the beam size", "\n", "# [batch, length] => [batch, beam_size, length]", "\n", "\n", "features", "[", "\"context_dia_src\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"context_dia_src\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_dia_src\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"context_dia_src\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"context_dia_src\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"context_dia_src\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"context_dia_src\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "# For context sequence length", "\n", "features", "[", "\"context_dia_src_length\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"context_dia_src_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_dia_src_length\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"context_dia_src_length\"", "]", ",", "\n", "[", "1", ",", "beam_size", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"context_dia_src_length\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"context_dia_src_length\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"context_dia_src_length\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "]", ")", "\n", "\n", "######", "\n", "# Expand the inputs in to the beam size", "\n", "# [batch, length] => [batch, beam_size, length]", "\n", "\n", "features", "[", "\"context_dia_tgt\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"context_dia_tgt\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_dia_tgt\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"context_dia_tgt\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"context_dia_tgt\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"context_dia_tgt\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"context_dia_tgt\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "# For context sequence length", "\n", "features", "[", "\"context_dia_tgt_length\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"context_dia_tgt_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_dia_tgt_length\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"context_dia_tgt_length\"", "]", ",", "\n", "[", "1", ",", "beam_size", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"context_dia_tgt_length\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"context_dia_tgt_length\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"context_dia_tgt_length\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "]", ")", "\n", "\n", "######", "\n", "# Expand the inputs in to the beam size", "\n", "# [batch, length] => [batch, beam_size, length]", "\n", "\n", "features", "[", "\"context_sty_src\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"context_sty_src\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_sty_src\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"context_sty_src\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"context_sty_src\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"context_sty_src\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"context_sty_src\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "# For context sequence length", "\n", "features", "[", "\"context_sty_src_length\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"context_sty_src_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_sty_src_length\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"context_sty_src_length\"", "]", ",", "\n", "[", "1", ",", "beam_size", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"context_sty_src_length\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"context_sty_src_length\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"context_sty_src_length\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "]", ")", "\n", "\n", "######", "\n", "# Expand the inputs in to the beam size", "\n", "# [batch, length] => [batch, beam_size, length]", "\n", "\n", "features", "[", "\"context_sty_tgt\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"context_sty_tgt\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_sty_tgt\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"context_sty_tgt\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"context_sty_tgt\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"context_sty_tgt\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"context_sty_tgt\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "# For context sequence length", "\n", "features", "[", "\"context_sty_tgt_length\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"context_sty_tgt_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_sty_tgt_length\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"context_sty_tgt_length\"", "]", ",", "\n", "[", "1", ",", "beam_size", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"context_sty_tgt_length\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"context_sty_tgt_length\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"context_sty_tgt_length\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "]", ")", "\n", "\n", "######", "\n", "# Expand the inputs in to the beam size", "\n", "# [batch, length] => [batch, beam_size, length]", "\n", "\n", "features", "[", "\"context_lan_src\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"context_lan_src\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_lan_src\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"context_lan_src\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"context_lan_src\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"context_lan_src\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"context_lan_src\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "# For context sequence length", "\n", "features", "[", "\"context_lan_src_length\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"context_lan_src_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_lan_src_length\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"context_lan_src_length\"", "]", ",", "\n", "[", "1", ",", "beam_size", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"context_lan_src_length\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"context_lan_src_length\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"context_lan_src_length\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "]", ")", "\n", "\n", "######", "\n", "# Expand the inputs in to the beam size", "\n", "# [batch, length] => [batch, beam_size, length]", "\n", "\n", "features", "[", "\"context_lan_tgt\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"context_lan_tgt\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_lan_tgt\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"context_lan_tgt\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"context_lan_tgt\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"context_lan_tgt\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"context_lan_tgt\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "# For context sequence length", "\n", "features", "[", "\"context_lan_tgt_length\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"context_lan_tgt_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_lan_tgt_length\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"context_lan_tgt_length\"", "]", ",", "\n", "[", "1", ",", "beam_size", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"context_lan_tgt_length\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"context_lan_tgt_length\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"context_lan_tgt_length\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "]", ")", "\n", "\n", "######", "\n", "# Expand the inputs in to the beam size", "\n", "# [batch, length] => [batch, beam_size, length]", "\n", "\n", "features", "[", "\"position_dia_src\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"position_dia_src\"", "]", ",", "1", ")", "\n", "features", "[", "\"position_dia_src\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"position_dia_src\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"position_dia_src\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"position_dia_src\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"position_dia_src\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "######", "\n", "# Expand the inputs in to the beam size", "\n", "# [batch, length] => [batch, beam_size, length]", "\n", "\n", "features", "[", "\"position_dia_tgt\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"position_dia_tgt\"", "]", ",", "1", ")", "\n", "features", "[", "\"position_dia_tgt\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"position_dia_tgt\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"position_dia_tgt\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"position_dia_tgt\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"position_dia_tgt\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "######", "\n", "features", "[", "\"position_sty_src\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"position_sty_src\"", "]", ",", "1", ")", "\n", "features", "[", "\"position_sty_src\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"position_sty_src\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"position_sty_src\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"position_sty_src\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"position_sty_src\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "######", "\n", "features", "[", "\"position_sty_tgt\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"position_sty_tgt\"", "]", ",", "1", ")", "\n", "features", "[", "\"position_sty_tgt\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"position_sty_tgt\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"position_sty_tgt\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"position_sty_tgt\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"position_sty_tgt\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "######", "\n", "features", "[", "\"position_lan_src\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"position_lan_src\"", "]", ",", "1", ")", "\n", "features", "[", "\"position_lan_src\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"position_lan_src\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"position_lan_src\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"position_lan_src\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"position_lan_src\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "######", "\n", "features", "[", "\"position_lan_tgt\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"position_lan_tgt\"", "]", ",", "1", ")", "\n", "features", "[", "\"position_lan_tgt\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"position_lan_tgt\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"position_lan_tgt\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"position_lan_tgt\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"position_lan_tgt\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "######", "\n", "features", "[", "\"emotion\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"emotion\"", "]", ",", "1", ")", "\n", "features", "[", "\"emotion\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"emotion\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"emotion\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"emotion\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"emotion\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "decoding_fn", "=", "_get_inference_fn", "(", "funcs", ",", "features", ")", "\n", "states", "=", "nest", ".", "map_structure", "(", "lambda", "x", ":", "_tile_to_beam_size", "(", "x", ",", "beam_size", ")", ",", "\n", "states", ")", "\n", "\n", "seqs", ",", "scores", "=", "beam_search", "(", "decoding_fn", ",", "states", ",", "batch_size", ",", "beam_size", ",", "\n", "max_length", ",", "alpha", ",", "pad_id", ",", "bos_id", ",", "eos_id", ")", "\n", "\n", "return", "seqs", "[", ":", ",", ":", "top_beams", ",", "1", ":", "]", ",", "scores", "[", ":", ",", ":", "top_beams", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.search.log_prob_from_logits": [[16, 18], ["tensorflow.reduce_logsumexp"], "function", ["None"], ["def", "log_prob_from_logits", "(", "logits", ")", ":", "\n", "    ", "return", "logits", "-", "tf", ".", "reduce_logsumexp", "(", "logits", ",", "axis", "=", "2", ",", "keep_dims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.search.compute_batch_indices": [[20, 34], ["tensorflow.reshape", "tensorflow.range"], "function", ["None"], ["", "def", "compute_batch_indices", "(", "batch_size", ",", "beam_size", ")", ":", "\n", "    ", "\"\"\"Computes the i'th coordinate that contains the batch index for gathers.\n\n    Batch pos is a tensor like [[0,0,0,0,],[1,1,1,1],..]. It says which\n    batch the beam item is in. This will create the i of the i,j coordinate\n    needed for the gather.\n\n    :param batch_size: Batch size\n    :param beam_size: Size of the beam.\n    :returns: batch_pos: [batch_size, beam_size] tensor of ids\n    \"\"\"", "\n", "batch_pos", "=", "tf", ".", "range", "(", "batch_size", "*", "beam_size", ")", "//", "beam_size", "\n", "batch_pos", "=", "tf", ".", "reshape", "(", "batch_pos", ",", "[", "batch_size", ",", "beam_size", "]", ")", "\n", "return", "batch_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.search.compute_topk_scores_and_seq": [[36, 79], ["tensorflow.nn.top_k", "search.compute_batch_indices", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.gather_nd", "tensorflow.gather_nd"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.search.compute_batch_indices"], ["", "def", "compute_topk_scores_and_seq", "(", "sequences", ",", "scores", ",", "scores_to_gather", ",", "flags", ",", "\n", "beam_size", ",", "batch_size", ")", ":", "\n", "    ", "\"\"\"Given sequences and scores, will gather the top k=beam size sequences.\n\n    This function is used to grow alive, and finished. It takes sequences,\n    scores, and flags, and returns the top k from sequences, scores_to_gather,\n    and flags based on the values in scores.\n\n    :param sequences: Tensor of sequences that we need to gather from.\n        [batch_size, beam_size, seq_length]\n    :param scores: Tensor of scores for each sequence in sequences.\n        [batch_size, beam_size]. We will use these to compute the topk.\n    :param scores_to_gather: Tensor of scores for each sequence in sequences.\n        [batch_size, beam_size]. We will return the gathered scores from\n        here. Scores to gather is different from scores because for\n        grow_alive, we will need to return log_probs, while for\n        grow_finished, we will need to return the length penalized scors.\n    :param flags: Tensor of bools for sequences that say whether a sequence has\n        reached EOS or not\n    :param beam_size: int\n    :param batch_size: int\n    :returns: Tuple of (topk_seq [batch_size, beam_size, decode_length],\n        topk_gathered_scores [batch_size, beam_size],\n        topk_finished_flags[batch_size, beam_size])\n    \"\"\"", "\n", "_", ",", "topk_indexes", "=", "tf", ".", "nn", ".", "top_k", "(", "scores", ",", "k", "=", "beam_size", ")", "\n", "# The next three steps are to create coordinates for tf.gather_nd to pull", "\n", "# out the top-k sequences from sequences based on scores.", "\n", "# batch pos is a tensor like [[0,0,0,0,],[1,1,1,1],..]. It says which", "\n", "# batch the beam item is in. This will create the i of the i,j coordinate", "\n", "# needed for the gather", "\n", "batch_pos", "=", "compute_batch_indices", "(", "batch_size", ",", "beam_size", ")", "\n", "\n", "# top coordinates will give us the actual coordinates to do the gather.", "\n", "# stacking will create a tensor of dimension batch * beam * 2, where the", "\n", "# last dimension contains the i,j gathering coordinates.", "\n", "top_coordinates", "=", "tf", ".", "stack", "(", "[", "batch_pos", ",", "topk_indexes", "]", ",", "axis", "=", "2", ")", "\n", "\n", "# Gather up the highest scoring sequences", "\n", "topk_seq", "=", "tf", ".", "gather_nd", "(", "sequences", ",", "top_coordinates", ")", "\n", "topk_flags", "=", "tf", ".", "gather_nd", "(", "flags", ",", "top_coordinates", ")", "\n", "topk_gathered_scores", "=", "tf", ".", "gather_nd", "(", "scores_to_gather", ",", "top_coordinates", ")", "\n", "return", "topk_seq", ",", "topk_gathered_scores", ",", "topk_flags", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.search.beam_search": [[81, 428], ["tensorflow.constant", "tensorflow.tile", "tensorflow.tile", "tensorflow.expand_dims", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.while_loop", "tf.expand_dims.set_shape", "tf.concat.set_shape", "tensorflow.where", "tensorflow.where", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.ones", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "search.compute_topk_scores_and_seq", "search.compute_topk_scores_and_seq", "tensorflow.reshape", "search.create_inference_graph.symbols_to_logits_fn", "len", "tensorflow.pow", "tensorflow.reshape", "tensorflow.nn.top_k", "search.compute_batch_indices", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.concat", "tensorflow.equal", "search.beam_search.grow_topk"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.search.compute_topk_scores_and_seq", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.search.compute_topk_scores_and_seq", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.search.compute_batch_indices"], ["", "def", "beam_search", "(", "symbols_to_logits_fn", ",", "initial_ids", ",", "beam_size", ",", "decode_length", ",", "\n", "vocab_size", ",", "alpha", ",", "eos_id", ",", "lp_constant", "=", "5.0", ")", ":", "\n", "    ", "\"\"\"Beam search with length penalties.\n\n    Uses an interface specific to the sequence cnn models;\n    Requires a function that can take the currently decoded symbols and return\n    the logits for the next symbol. The implementation is inspired by\n    https://arxiv.org/abs/1609.08144.\n\n    :param symbols_to_logits_fn: Interface to the model, to provide logits.\n        Should take [batch_size, decoded_ids] and return [\n        batch_size, vocab_size]\n    :param initial_ids: Ids to start off the decoding, this will be the first\n        thing handed to symbols_to_logits_fn\n        (after expanding to beam size) [batch_size]\n    :param beam_size: Size of the beam.\n    :param decode_length: Number of steps to decode for.\n    :param vocab_size: Size of the vocab, must equal the size of the logits\n        returned by symbols_to_logits_fn\n    :param alpha: alpha for length penalty.\n    :param eos_id: ID for end of sentence.\n    :param lp_constant: A floating number used in length penalty\n    :returns: Tuple of (decoded beams [batch_size, beam_size, decode_length]\n        decoding probabilities [batch_size, beam_size])\n    \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "initial_ids", ")", "[", "0", "]", "\n", "\n", "# Assume initial_ids are prob 1.0", "\n", "initial_log_probs", "=", "tf", ".", "constant", "(", "[", "[", "0.", "]", "+", "[", "-", "float", "(", "\"inf\"", ")", "]", "*", "(", "beam_size", "-", "1", ")", "]", ")", "\n", "# Expand to beam_size (batch_size, beam_size)", "\n", "alive_log_probs", "=", "tf", ".", "tile", "(", "initial_log_probs", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "\n", "# Expand each batch to beam_size", "\n", "alive_seq", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "initial_ids", ",", "1", ")", ",", "[", "1", ",", "beam_size", "]", ")", "\n", "alive_seq", "=", "tf", ".", "expand_dims", "(", "alive_seq", ",", "2", ")", "# (batch_size, beam_size, 1)", "\n", "\n", "# Finished will keep track of all the sequences that have finished so far", "\n", "# Finished log probs will be negative infinity in the beginning", "\n", "# finished_flags will keep track of booleans", "\n", "finished_seq", "=", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "alive_seq", ")", ",", "tf", ".", "int32", ")", "\n", "# Setting the scores of the initial to negative infinity.", "\n", "finished_scores", "=", "tf", ".", "ones", "(", "[", "batch_size", ",", "beam_size", "]", ")", "*", "-", "INF", "\n", "finished_flags", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "beam_size", "]", ",", "tf", ".", "bool", ")", "\n", "\n", "def", "grow_finished", "(", "finished_seq", ",", "finished_scores", ",", "finished_flags", ",", "curr_seq", ",", "\n", "curr_scores", ",", "curr_finished", ")", ":", "\n", "        ", "\"\"\"Given sequences and scores, will gather the top k=beam size\n           sequences.\n\n        :param finished_seq: Current finished sequences.\n            [batch_size, beam_size, current_decoded_length]\n        :param finished_scores: scores for each of these sequences.\n            [batch_size, beam_size]\n        :param finished_flags: finished bools for each of these sequences.\n            [batch_size, beam_size]\n        :param curr_seq: current topk sequence that has been grown by one\n            position. [batch_size, beam_size, current_decoded_length]\n        :param curr_scores: scores for each of these sequences.\n            [batch_size, beam_size]\n        :param curr_finished: Finished flags for each of these sequences.\n            [batch_size, beam_size]\n        :returns:\n            Tuple of\n                (Top-k sequences based on scores,\n                log probs of these sequences,\n                Finished flags of these sequences)\n        \"\"\"", "\n", "# First append a column of 0'ids to finished to make the same length", "\n", "# with finished scores", "\n", "finished_seq", "=", "tf", ".", "concat", "(", "\n", "[", "finished_seq", ",", "tf", ".", "zeros", "(", "[", "batch_size", ",", "beam_size", ",", "1", "]", ",", "tf", ".", "int32", ")", "]", ",", "\n", "axis", "=", "2", "\n", ")", "\n", "\n", "# Set the scores of the unfinished seq in curr_seq to large negative", "\n", "# values", "\n", "curr_scores", "+=", "(", "1.", "-", "tf", ".", "to_float", "(", "curr_finished", ")", ")", "*", "-", "INF", "\n", "# concatenating the sequences and scores along beam axis", "\n", "curr_finished_seq", "=", "tf", ".", "concat", "(", "[", "finished_seq", ",", "curr_seq", "]", ",", "axis", "=", "1", ")", "\n", "curr_finished_scores", "=", "tf", ".", "concat", "(", "[", "finished_scores", ",", "curr_scores", "]", ",", "\n", "axis", "=", "1", ")", "\n", "curr_finished_flags", "=", "tf", ".", "concat", "(", "[", "finished_flags", ",", "curr_finished", "]", ",", "\n", "axis", "=", "1", ")", "\n", "return", "compute_topk_scores_and_seq", "(", "\n", "curr_finished_seq", ",", "curr_finished_scores", ",", "curr_finished_scores", ",", "\n", "curr_finished_flags", ",", "beam_size", ",", "batch_size", ")", "\n", "\n", "", "def", "grow_alive", "(", "curr_seq", ",", "curr_scores", ",", "curr_log_probs", ",", "curr_finished", ")", ":", "\n", "        ", "\"\"\"Given sequences and scores, will gather the top k=beam size\n           sequences.\n\n        :param curr_seq: current topk sequence that has been grown by one\n            position. [batch_size, beam_size, i+1]\n        :param curr_scores: scores for each of these sequences.\n            [batch_size, beam_size]\n        :param curr_log_probs: log probs for each of these sequences.\n            [batch_size, beam_size]\n        :param curr_finished: Finished flags for each of these sequences.\n            [batch_size, beam_size]\n        :returns:\n            Tuple of\n                (Top-k sequences based on scores,\n                log probs of these sequences,\n                Finished flags of these sequences)\n        \"\"\"", "\n", "# Set the scores of the finished seq in curr_seq to large negative", "\n", "# values", "\n", "curr_scores", "+=", "tf", ".", "to_float", "(", "curr_finished", ")", "*", "-", "INF", "\n", "return", "compute_topk_scores_and_seq", "(", "curr_seq", ",", "curr_scores", ",", "\n", "curr_log_probs", ",", "curr_finished", ",", "\n", "beam_size", ",", "batch_size", ")", "\n", "\n", "", "def", "grow_topk", "(", "i", ",", "alive_seq", ",", "alive_log_probs", ")", ":", "\n", "        ", "r\"\"\"Inner beam search loop.\n\n        This function takes the current alive sequences, and grows them to\n        topk sequences where k = 2*beam. We use 2*beam because, we could have\n        beam_size number of sequences that might hit <eos> and there will be\n        no alive sequences to continue. With 2*beam_size, this will not happen.\n        This relies on the assumption the vocab size is > beam size.\n        If this is true, we'll have at least beam_size non <eos> extensions if\n        we extract the next top 2*beam words.\n        Length penalty is given by = (5+len(decode)/6) ^ -\\alpha. Pls refer to\n        https://arxiv.org/abs/1609.08144.\n\n        :param i: loop index\n        :param alive_seq: Topk sequences decoded so far\n            [batch_size, beam_size, i+1]\n        :param alive_log_probs: probabilities of these sequences.\n            [batch_size, beam_size]\n        :returns:\n            Tuple of\n                (Top-k sequences extended by the next word,\n                The log probs of these sequences,\n                The scores with length penalty of these sequences,\n                Flags indicating which of these sequences have finished\n                decoding)\n        \"\"\"", "\n", "# Get the logits for all the possible next symbols", "\n", "flat_ids", "=", "tf", ".", "reshape", "(", "alive_seq", ",", "[", "batch_size", "*", "beam_size", ",", "-", "1", "]", ")", "\n", "\n", "# (batch_size * beam_size, decoded_length)", "\n", "flat_logits_list", "=", "symbols_to_logits_fn", "(", "flat_ids", ")", "\n", "logits_list", "=", "[", "\n", "tf", ".", "reshape", "(", "flat_logits", ",", "(", "batch_size", ",", "beam_size", ",", "-", "1", ")", ")", "\n", "for", "flat_logits", "in", "flat_logits_list", "\n", "]", "\n", "\n", "# Convert logits to normalized log probs", "\n", "candidate_log_probs", "=", "[", "\n", "log_prob_from_logits", "(", "logits", ")", "\n", "for", "logits", "in", "logits_list", "\n", "]", "\n", "\n", "n_models", "=", "len", "(", "candidate_log_probs", ")", "\n", "candidate_log_probs", "=", "tf", ".", "add_n", "(", "candidate_log_probs", ")", "/", "float", "(", "n_models", ")", "\n", "\n", "# Multiply the probabilities by the current probabilities of the beam.", "\n", "# (batch_size, beam_size, vocab_size) + (batch_size, beam_size, 1)", "\n", "log_probs", "=", "candidate_log_probs", "+", "tf", ".", "expand_dims", "(", "alive_log_probs", ",", "\n", "axis", "=", "2", ")", "\n", "\n", "length_penalty", "=", "tf", ".", "pow", "(", "\n", "(", "(", "lp_constant", "+", "tf", ".", "to_float", "(", "i", "+", "1", ")", ")", "/", "(", "1.0", "+", "lp_constant", ")", ")", ",", "alpha", "\n", ")", "\n", "\n", "curr_scores", "=", "log_probs", "/", "length_penalty", "\n", "# Flatten out (beam_size, vocab_size) probs in to a list of", "\n", "# possibilities", "\n", "flat_curr_scores", "=", "tf", ".", "reshape", "(", "curr_scores", ",", "\n", "[", "-", "1", ",", "beam_size", "*", "vocab_size", "]", ")", "\n", "\n", "topk_scores", ",", "topk_ids", "=", "tf", ".", "nn", ".", "top_k", "(", "flat_curr_scores", ",", "k", "=", "beam_size", "*", "2", ")", "\n", "\n", "# Recovering the log probs because we will need to send them back", "\n", "topk_log_probs", "=", "topk_scores", "*", "length_penalty", "\n", "\n", "# Work out what beam the top probs are in.", "\n", "topk_beam_index", "=", "topk_ids", "//", "vocab_size", "\n", "topk_ids", "%=", "vocab_size", "# Unflatten the ids", "\n", "\n", "# The next three steps are to create coordinates for tf.gather_nd to", "\n", "# pull", "\n", "# out the correct sequences from id's that we need to grow.", "\n", "# We will also use the coordinates to gather the booleans of the beam", "\n", "# items that survived.", "\n", "batch_pos", "=", "compute_batch_indices", "(", "batch_size", ",", "beam_size", "*", "2", ")", "\n", "\n", "# top beams will give us the actual coordinates to do the gather.", "\n", "# stacking will create a tensor of dimension batch * beam * 2, where", "\n", "# the last dimension contains the i,j gathering coordinates.", "\n", "topk_coordinates", "=", "tf", ".", "stack", "(", "[", "batch_pos", ",", "topk_beam_index", "]", ",", "axis", "=", "2", ")", "\n", "\n", "# Gather up the most probable 2*beams both for the ids and", "\n", "# finished_in_alive bools", "\n", "topk_seq", "=", "tf", ".", "gather_nd", "(", "alive_seq", ",", "topk_coordinates", ")", "\n", "\n", "# Append the most probable alive", "\n", "topk_seq", "=", "tf", ".", "concat", "(", "[", "topk_seq", ",", "tf", ".", "expand_dims", "(", "topk_ids", ",", "axis", "=", "2", ")", "]", ",", "\n", "axis", "=", "2", ")", "\n", "\n", "topk_finished", "=", "tf", ".", "equal", "(", "topk_ids", ",", "eos_id", ")", "\n", "\n", "return", "topk_seq", ",", "topk_log_probs", ",", "topk_scores", ",", "topk_finished", "\n", "\n", "", "def", "inner_loop", "(", "i", ",", "alive_seq", ",", "alive_log_probs", ",", "finished_seq", ",", "\n", "finished_scores", ",", "finished_flags", ")", ":", "\n", "        ", "\"\"\"Inner beam search loop.\n\n        There are three groups of tensors, alive, finished, and topk.\n        The alive group contains information about the current alive sequences\n        The top-k group contains information about alive + topk current decoded\n        words the finished group contains information about finished sentences,\n        that is, the ones that have decoded to <EOS>. These are what we return.\n        The general beam search algorithm is as follows:\n        While we haven't terminated (pls look at termination condition)\n            1. Grow the current alive to get beam*2 top-k sequences\n            2. Among the top-k, keep the top beam_size ones that haven't\n            reached <eos> into alive\n            3. Among the top-k, keep the top beam_size ones have reached <eos>\n            into finished\n        Repeat\n        To make things simple with using fixed size tensors, we will end\n        up inserting unfinished sequences into finished in the beginning. To\n        stop that we add -ve INF to the score of the unfinished sequence so\n        that when a true finished sequence does appear, it will have a higher\n        score than all the unfinished ones.\n\n        :param i: loop index\n        :param alive_seq: Topk sequences decoded so far\n            [batch_size, beam_size, i+1]\n        :param alive_log_probs: probabilities of the beams.\n            [batch_size, beam_size]\n        :param finished_seq: Current finished sequences.\n            [batch_size, beam_size, i+1]\n        :param finished_scores: scores for each of these sequences.\n            [batch_size, beam_size]\n        :param finished_flags: finished bools for each of these sequences.\n            [batch_size, beam_size]\n\n        :returns:\n            Tuple of\n                (Incremented loop index\n                New alive sequences,\n                Log probs of the alive sequences,\n                New finished sequences,\n                Scores of the new finished sequences,\n                Flags indicating which sequence in finished as reached EOS)\n        \"\"\"", "\n", "\n", "# Each inner loop, we carry out three steps:", "\n", "# 1. Get the current topk items.", "\n", "# 2. Extract the ones that have finished and haven't finished", "\n", "# 3. Recompute the contents of finished based on scores.", "\n", "topk_seq", ",", "topk_log_probs", ",", "topk_scores", ",", "topk_finished", "=", "grow_topk", "(", "\n", "i", ",", "alive_seq", ",", "alive_log_probs", "\n", ")", "\n", "alive_seq", ",", "alive_log_probs", ",", "_", "=", "grow_alive", "(", "topk_seq", ",", "topk_scores", ",", "\n", "topk_log_probs", ",", "\n", "topk_finished", ")", "\n", "finished_seq", ",", "finished_scores", ",", "finished_flags", "=", "grow_finished", "(", "\n", "finished_seq", ",", "finished_scores", ",", "finished_flags", ",", "topk_seq", ",", "\n", "topk_scores", ",", "topk_finished", "\n", ")", "\n", "\n", "return", "(", "i", "+", "1", ",", "alive_seq", ",", "alive_log_probs", ",", "finished_seq", ",", "\n", "finished_scores", ",", "finished_flags", ")", "\n", "\n", "", "def", "_is_finished", "(", "i", ",", "unused_alive_seq", ",", "alive_log_probs", ",", "unused_finished_seq", ",", "\n", "finished_scores", ",", "finished_in_finished", ")", ":", "\n", "        ", "\"\"\"Checking termination condition.\n\n        We terminate when we decoded up to decode_length or the lowest scoring\n        item in finished has a greater score that the highest prob item in\n        alive divided by the max length penalty\n\n        :param i: loop index\n        :param alive_log_probs: probabilities of the beams.\n            [batch_size, beam_size]\n        :param finished_scores: scores for each of these sequences.\n            [batch_size, beam_size]\n        :param finished_in_finished: finished bools for each of these\n            sequences. [batch_size, beam_size]\n\n        :returns: Bool.\n        \"\"\"", "\n", "max_length_penalty", "=", "tf", ".", "pow", "(", "(", "(", "5.", "+", "tf", ".", "to_float", "(", "decode_length", ")", ")", "/", "6.", ")", ",", "\n", "alpha", ")", "\n", "# The best possible score of the most likley alive sequence", "\n", "lower_bound_alive_scores", "=", "alive_log_probs", "[", ":", ",", "0", "]", "/", "max_length_penalty", "\n", "\n", "# Now to compute the lowest score of a finished sequence in finished", "\n", "# If the sequence isn't finished, we multiply it's score by 0. since", "\n", "# scores are all -ve, taking the min will give us the score of the", "\n", "# lowest finished item.", "\n", "lowest_score_of_finished_in_finished", "=", "tf", ".", "reduce_min", "(", "\n", "finished_scores", "*", "tf", ".", "to_float", "(", "finished_in_finished", ")", ",", "axis", "=", "1", "\n", ")", "\n", "# If none of the sequences have finished, then the min will be 0 and", "\n", "# we have to replace it by -ve INF if it is. The score of any seq in", "\n", "# alive will be much higher than -ve INF and the termination condition", "\n", "# will not be met.", "\n", "lowest_score_of_finished_in_finished", "+=", "(", "\n", "(", "1.", "-", "tf", ".", "to_float", "(", "tf", ".", "reduce_any", "(", "finished_in_finished", ",", "1", ")", ")", ")", "*", "-", "INF", "\n", ")", "\n", "\n", "bound_is_met", "=", "tf", ".", "reduce_all", "(", "\n", "tf", ".", "greater", "(", "lowest_score_of_finished_in_finished", ",", "\n", "lower_bound_alive_scores", ")", "\n", ")", "\n", "\n", "return", "tf", ".", "logical_and", "(", "tf", ".", "less", "(", "i", ",", "decode_length", ")", ",", "\n", "tf", ".", "logical_not", "(", "bound_is_met", ")", ")", "\n", "\n", "", "(", "_", ",", "alive_seq", ",", "alive_log_probs", ",", "finished_seq", ",", "finished_scores", ",", "\n", "finished_flags", ")", "=", "tf", ".", "while_loop", "(", "\n", "_is_finished", ",", "\n", "inner_loop", ",", "[", "\n", "tf", ".", "constant", "(", "0", ")", ",", "alive_seq", ",", "alive_log_probs", ",", "finished_seq", ",", "\n", "finished_scores", ",", "finished_flags", "\n", "]", ",", "\n", "shape_invariants", "=", "[", "\n", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "None", "]", ")", ",", "\n", "alive_log_probs", ".", "get_shape", "(", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "None", "]", ")", ",", "\n", "finished_scores", ".", "get_shape", "(", ")", ",", "\n", "finished_flags", ".", "get_shape", "(", ")", "\n", "]", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "back_prop", "=", "False", "\n", ")", "\n", "\n", "alive_seq", ".", "set_shape", "(", "(", "None", ",", "beam_size", ",", "None", ")", ")", "\n", "finished_seq", ".", "set_shape", "(", "(", "None", ",", "beam_size", ",", "None", ")", ")", "\n", "\n", "# Accounting for corner case: It's possible that no sequence in alive for", "\n", "# a particular batch item ever reached <eos>. In that case, we should just", "\n", "# copy the contents of alive for that batch item.", "\n", "# tf.reduce_any(finished_flags, 1) if 0, means that no sequence for that", "\n", "# batch index had reached EOS. We need to do the same for the scores as", "\n", "# well.", "\n", "finished_seq", "=", "tf", ".", "where", "(", "\n", "tf", ".", "reduce_any", "(", "finished_flags", ",", "1", ")", ",", "finished_seq", ",", "alive_seq", ")", "\n", "finished_scores", "=", "tf", ".", "where", "(", "\n", "tf", ".", "reduce_any", "(", "finished_flags", ",", "1", ")", ",", "finished_scores", ",", "alive_log_probs", ")", "\n", "return", "finished_seq", ",", "finished_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.search.create_inference_graph": [[430, 506], ["tensorflow.fill", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "len", "search.beam_search", "isinstance", "tensorflow.pad", "tensorflow.fill", "enumerate", "tensorflow.shape", "tensorflow.constant", "results.append", "tensorflow.shape", "tensorflow.shape", "model_fn", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.search.beam_search"], ["", "def", "create_inference_graph", "(", "model_fns", ",", "features", ",", "params", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "model_fns", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "model_fns", "=", "[", "model_fns", "]", "\n", "\n", "", "decode_length", "=", "params", ".", "decode_length", "\n", "beam_size", "=", "params", ".", "beam_size", "\n", "top_beams", "=", "params", ".", "top_beams", "\n", "alpha", "=", "params", ".", "decode_alpha", "\n", "\n", "# [batch, decoded_ids] => [batch, vocab_size]", "\n", "def", "symbols_to_logits_fn", "(", "decoded_ids", ")", ":", "\n", "        ", "features", "[", "\"target\"", "]", "=", "tf", ".", "pad", "(", "decoded_ids", "[", ":", ",", "1", ":", "]", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "1", "]", "]", ")", "\n", "features", "[", "\"target_length\"", "]", "=", "tf", ".", "fill", "(", "[", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "0", "]", "]", ",", "\n", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", ")", "\n", "\n", "results", "=", "[", "]", "\n", "\n", "for", "i", ",", "model_fn", "in", "enumerate", "(", "model_fns", ")", ":", "\n", "            ", "results", ".", "append", "(", "model_fn", "(", "features", ")", ")", "\n", "\n", "", "return", "results", "\n", "\n", "", "batch_size", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "0", "]", "\n", "# Prepend <bos> symbol", "\n", "bos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "bos", "]", "\n", "initial_ids", "=", "tf", ".", "fill", "(", "[", "batch_size", "]", ",", "tf", ".", "constant", "(", "bos_id", ",", "dtype", "=", "tf", ".", "int32", ")", ")", "\n", "\n", "inputs_old", "=", "features", "[", "\"source\"", "]", "\n", "inputs_length_old", "=", "features", "[", "\"source_length\"", "]", "\n", "\n", "# Expand the inputs in to the beam size", "\n", "# [batch, length] => [batch, beam_size, length]", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"source\"", "]", ",", "1", ")", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"source\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "# For source sequence length", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"source_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "[", "1", ",", "beam_size", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"source_length\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "]", ")", "\n", "\n", "vocab_size", "=", "len", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", "\n", "# Setting decode length to input length + decode_length", "\n", "decode_length", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "1", "]", "+", "decode_length", "\n", "\n", "ids", ",", "scores", "=", "beam_search", "(", "symbols_to_logits_fn", ",", "initial_ids", ",", "\n", "beam_size", ",", "decode_length", ",", "vocab_size", ",", "\n", "alpha", ",", "\n", "eos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "eos", "]", ",", "\n", "lp_constant", "=", "params", ".", "decode_constant", ")", "\n", "\n", "# Set inputs back to the unexpanded inputs to not to confuse the Estimator", "\n", "features", "[", "\"source\"", "]", "=", "inputs_old", "\n", "features", "[", "\"source_length\"", "]", "=", "inputs_length_old", "\n", "\n", "# Return `top_beams` decoding", "\n", "# (also remove initial id from the beam search)", "\n", "if", "not", "params", ".", "decode_normalize", ":", "\n", "        ", "if", "top_beams", "==", "1", ":", "\n", "            ", "return", "ids", "[", ":", ",", "0", ",", "1", ":", "]", "\n", "", "else", ":", "\n", "            ", "return", "ids", "[", ":", ",", ":", "top_beams", ",", "1", ":", "]", "\n", "", "", "else", ":", "\n", "        ", "if", "top_beams", "==", "1", ":", "\n", "            ", "return", "ids", "[", ":", ",", "0", ",", "1", ":", "]", ",", "scores", "[", ":", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "ids", "[", ":", ",", ":", "top_beams", ",", "1", ":", "]", ",", "scores", "[", ":", ",", ":", "top_beams", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize._get_loss_variable": [[11, 27], ["tensorflow.get_collection", "tensorflow.get_default_graph", "len", "tensorflow.logging.error", "graph.get_tensor_by_name"], "function", ["None"], ["def", "_get_loss_variable", "(", "graph", "=", "None", ")", ":", "\n", "    ", "graph", "=", "graph", "or", "tf", ".", "get_default_graph", "(", ")", "\n", "loss_tensors", "=", "tf", ".", "get_collection", "(", "\"loss\"", ")", "\n", "\n", "if", "len", "(", "loss_tensors", ")", "==", "1", ":", "\n", "        ", "loss_tensor", "=", "loss_tensors", "[", "0", "]", "\n", "", "elif", "not", "loss_tensors", ":", "\n", "        ", "try", ":", "\n", "            ", "loss_tensor", "=", "graph", ".", "get_tensor_by_name", "(", "\"loss_tensor:0\"", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "return", "None", "\n", "", "", "else", ":", "\n", "        ", "tf", ".", "logging", ".", "error", "(", "\"Multiple tensors in loss collection.\"", ")", "\n", "return", "None", "\n", "\n", "", "return", "loss_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize._create_loss_variable": [[29, 43], ["tensorflow.get_default_graph", "optimize._get_loss_variable", "ValueError", "graph.as_default", "g.name_scope", "tensorflow.get_variable", "tensorflow.zeros_initializer"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize._get_loss_variable"], ["", "def", "_create_loss_variable", "(", "graph", "=", "None", ")", ":", "\n", "    ", "graph", "=", "graph", "or", "tf", ".", "get_default_graph", "(", ")", "\n", "if", "_get_loss_variable", "(", "graph", ")", "is", "not", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"'loss' already exists.\"", ")", "\n", "\n", "# Create in proper graph and base name_scope.", "\n", "", "with", "graph", ".", "as_default", "(", ")", "as", "g", ",", "g", ".", "name_scope", "(", "None", ")", ":", "\n", "        ", "tensor", "=", "tf", ".", "get_variable", "(", "\"loss\"", ",", "shape", "=", "[", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ",", "\n", "collections", "=", "[", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "\n", "\"loss\"", "]", ")", "\n", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize._get_or_create_loss_variable": [[45, 51], ["optimize._get_loss_variable", "tensorflow.get_default_graph", "optimize._create_loss_variable"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize._get_loss_variable", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize._create_loss_variable"], ["", "def", "_get_or_create_loss_variable", "(", "graph", "=", "None", ")", ":", "\n", "    ", "graph", "=", "graph", "or", "tf", ".", "get_default_graph", "(", ")", "\n", "loss_tensor", "=", "_get_loss_variable", "(", "graph", ")", "\n", "if", "loss_tensor", "is", "None", ":", "\n", "        ", "loss_tensor", "=", "_create_loss_variable", "(", "graph", ")", "\n", "", "return", "loss_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize._zero_variables": [[53, 62], ["tensorflow.group", "ops.append", "tensorflow.device", "var.assign", "tensorflow.zeros", "var.shape.as_list"], "function", ["None"], ["", "def", "_zero_variables", "(", "variables", ",", "name", "=", "None", ")", ":", "\n", "    ", "ops", "=", "[", "]", "\n", "\n", "for", "var", "in", "variables", ":", "\n", "        ", "with", "tf", ".", "device", "(", "var", ".", "device", ")", ":", "\n", "            ", "op", "=", "var", ".", "assign", "(", "tf", ".", "zeros", "(", "var", ".", "shape", ".", "as_list", "(", ")", ")", ")", "\n", "", "ops", ".", "append", "(", "op", ")", "\n", "\n", "", "return", "tf", ".", "group", "(", "*", "ops", ",", "name", "=", "name", "or", "\"zero_variables\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize._replicate_variables": [[64, 75], ["tensorflow.device", "new_vars.append", "[].rstrip", "tensorflow.Variable", "tensorflow.zeros", "var.shape.as_list", "var.name.split"], "function", ["None"], ["", "def", "_replicate_variables", "(", "variables", ",", "device", "=", "None", ")", ":", "\n", "    ", "new_vars", "=", "[", "]", "\n", "\n", "for", "var", "in", "variables", ":", "\n", "        ", "device", "=", "device", "or", "var", ".", "device", "\n", "with", "tf", ".", "device", "(", "device", ")", ":", "\n", "            ", "name", "=", "var", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ".", "rstrip", "(", "\"/\"", ")", "+", "\"/replica\"", "\n", "new_vars", ".", "append", "(", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "var", ".", "shape", ".", "as_list", "(", ")", ")", ",", "\n", "name", "=", "name", ",", "trainable", "=", "False", ")", ")", "\n", "\n", "", "", "return", "new_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize._collect_gradients": [[77, 87], ["zip", "tensorflow.group", "isinstance", "ops.append", "ops.append", "tensorflow.assign_add", "tensorflow.scatter_add"], "function", ["None"], ["", "def", "_collect_gradients", "(", "gradients", ",", "variables", ")", ":", "\n", "    ", "ops", "=", "[", "]", "\n", "\n", "for", "grad", ",", "var", "in", "zip", "(", "gradients", ",", "variables", ")", ":", "\n", "        ", "if", "isinstance", "(", "grad", ",", "tf", ".", "Tensor", ")", ":", "\n", "            ", "ops", ".", "append", "(", "tf", ".", "assign_add", "(", "var", ",", "grad", ")", ")", "\n", "", "else", ":", "\n", "            ", "ops", ".", "append", "(", "tf", ".", "scatter_add", "(", "var", ",", "grad", ".", "indices", ",", "grad", ".", "values", ")", ")", "\n", "\n", "", "", "return", "tf", ".", "group", "(", "*", "ops", ",", "name", "=", "\"collect_gradients\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize._scale_variables": [[89, 99], ["tensorflow.group", "isinstance", "tensorflow.assign", "ops.append", "tensorflow.assign"], "function", ["None"], ["", "def", "_scale_variables", "(", "variables", ",", "scale", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "variables", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "return", "tf", ".", "assign", "(", "variables", ",", "scale", "*", "variables", ")", "\n", "\n", "", "ops", "=", "[", "]", "\n", "\n", "for", "var", "in", "variables", ":", "\n", "        ", "ops", ".", "append", "(", "tf", ".", "assign", "(", "var", ",", "scale", "*", "var", ")", ")", "\n", "\n", "", "return", "tf", ".", "group", "(", "*", "ops", ",", "name", "=", "\"scale_variables\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize.create_train_op": [[101, 163], ["tensorflow.name_scope", "optimizer.compute_gradients", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "zip", "isinstance", "list", "optimizer.apply_gradients", "tensorflow.no_op", "tensorflow.no_op", "tensorflow.no_op", "optimize._get_or_create_loss_variable", "optimize._replicate_variables", "optimize._zero_variables", "optimize._collect_gradients", "tensorflow.assign_add", "tensorflow.group", "optimize._scale_variables", "optimize._scale_variables", "tensorflow.group", "tensorflow.convert_to_tensor", "tensorflow.global_norm", "isinstance", "tensorflow.clip_by_global_norm", "zip", "variable.name.replace", "tensorflow.summary.histogram", "tensorflow.summary.scalar", "tensorflow.trainable_variables", "tensorflow.global_norm"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.StaticLossScalingOptimizer.compute_gradients", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.StaticLossScalingOptimizer.apply_gradients", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize._get_or_create_loss_variable", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize._replicate_variables", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize._zero_variables", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize._collect_gradients", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize._scale_variables", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimize._scale_variables"], ["", "def", "create_train_op", "(", "loss", ",", "optimizer", ",", "global_step", ",", "params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"create_train_op\"", ")", ":", "\n", "        ", "grads_and_vars", "=", "optimizer", ".", "compute_gradients", "(", "\n", "loss", ",", "colocate_gradients_with_ops", "=", "True", ")", "\n", "gradients", "=", "[", "item", "[", "0", "]", "for", "item", "in", "grads_and_vars", "]", "\n", "variables", "=", "[", "item", "[", "1", "]", "for", "item", "in", "grads_and_vars", "]", "\n", "\n", "if", "params", ".", "update_cycle", "==", "1", ":", "\n", "            ", "zero_variables_op", "=", "tf", ".", "no_op", "(", "\"zero_variables\"", ")", "\n", "collect_op", "=", "tf", ".", "no_op", "(", "\"collect_op\"", ")", "\n", "scale_op", "=", "tf", ".", "no_op", "(", "\"scale_op\"", ")", "\n", "", "else", ":", "\n", "# collect", "\n", "            ", "loss_tensor", "=", "_get_or_create_loss_variable", "(", ")", "\n", "slot_variables", "=", "_replicate_variables", "(", "variables", ")", "\n", "zero_variables_op", "=", "_zero_variables", "(", "slot_variables", "+", "[", "loss_tensor", "]", ")", "\n", "collect_grads_op", "=", "_collect_gradients", "(", "gradients", ",", "slot_variables", ")", "\n", "collect_loss_op", "=", "tf", ".", "assign_add", "(", "loss_tensor", ",", "loss", ")", "\n", "collect_op", "=", "tf", ".", "group", "(", "collect_loss_op", ",", "collect_grads_op", ",", "\n", "name", "=", "\"collect_op\"", ")", "\n", "# scale", "\n", "scale", "=", "1.0", "/", "params", ".", "update_cycle", "\n", "scale_grads_op", "=", "_scale_variables", "(", "slot_variables", ",", "scale", ")", "\n", "scale_loss_op", "=", "_scale_variables", "(", "loss_tensor", ",", "scale", ")", "\n", "scale_op", "=", "tf", ".", "group", "(", "scale_grads_op", ",", "scale_loss_op", ",", "name", "=", "\"scale_op\"", ")", "\n", "gradients", "=", "slot_variables", "\n", "loss", "=", "tf", ".", "convert_to_tensor", "(", "loss_tensor", ")", "\n", "\n", "# Add summaries", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"loss\"", ",", "loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"global_norm/gradient_norm\"", ",", "\n", "tf", ".", "global_norm", "(", "gradients", ")", ")", "\n", "\n", "for", "gradient", ",", "variable", "in", "zip", "(", "gradients", ",", "variables", ")", ":", "\n", "            ", "if", "isinstance", "(", "gradient", ",", "tf", ".", "IndexedSlices", ")", ":", "\n", "                ", "grad_values", "=", "gradient", ".", "values", "\n", "", "else", ":", "\n", "                ", "grad_values", "=", "gradient", "\n", "\n", "", "if", "grad_values", "is", "not", "None", ":", "\n", "                ", "var_name", "=", "variable", ".", "name", ".", "replace", "(", "\":\"", ",", "\"_\"", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"gradients/%s\"", "%", "var_name", ",", "grad_values", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"gradient_norm/%s\"", "%", "var_name", ",", "\n", "tf", ".", "global_norm", "(", "[", "grad_values", "]", ")", ")", "\n", "\n", "# Gradient clipping", "\n", "", "", "if", "isinstance", "(", "params", ".", "clip_grad_norm", "or", "None", ",", "float", ")", ":", "\n", "            ", "gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "\n", "params", ".", "clip_grad_norm", ")", "\n", "\n", "# Update variables", "\n", "", "grads_and_vars", "=", "list", "(", "zip", "(", "gradients", ",", "tf", ".", "trainable_variables", "(", ")", ")", ")", "\n", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "grads_and_vars", ",", "global_step", ")", "\n", "\n", "ops", "=", "{", "\n", "\"zero_op\"", ":", "zero_variables_op", ",", "\n", "\"collect_op\"", ":", "collect_op", ",", "\n", "\"scale_op\"", ":", "scale_op", ",", "\n", "\"train_op\"", ":", "train_op", "\n", "}", "\n", "\n", "return", "loss", ",", "ops", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.get_mrt_features": [[15, 59], ["mrt_utils.create_sampling_graph", "tensorflow.shape", "tensorflow.to_int32", "tensorflow.concat", "tensorflow.zeros", "tensorflow.concat", "tensorflow.concat", "tensorflow.py_func", "features[].set_shape", "tensorflow.shape", "mrt_utils.get_len", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.tile", "tensorflow.tile", "tensorflow.map_fn", "features[].set_shape", "model.get_inference_func", "tensorflow.ones", "mrt_utils.bleu_tensor", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.sampling.create_sampling_graph", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.get_len", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_inference_func", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.bleu_tensor"], ["def", "get_mrt_features", "(", "features", ",", "params", ",", "model", ")", ":", "\n", "# Generate samples", "\n", "    ", "samples", "=", "create_sampling_graph", "(", "model", ".", "get_inference_func", "(", ")", ",", "features", ",", "\n", "params", ",", "training", "=", "True", ")", "\n", "\n", "eos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "eos", "]", "\n", "features", "[", "\"samples\"", "]", "=", "samples", "\n", "# Delete bos & add eos", "\n", "features", "[", "\"samples\"", "]", "=", "features", "[", "\"samples\"", "]", "[", ":", ",", "1", ":", "]", "\n", "sample_shape", "=", "tf", ".", "shape", "(", "features", "[", "\"samples\"", "]", ")", "\n", "eos_seq", "=", "tf", ".", "ones", "(", "[", "sample_shape", "[", "0", "]", ",", "1", "]", ")", "*", "eos_id", "\n", "eos_seq", "=", "tf", ".", "to_int32", "(", "eos_seq", ")", "\n", "features", "[", "\"samples\"", "]", "=", "tf", ".", "concat", "(", "[", "features", "[", "\"samples\"", "]", ",", "eos_seq", "]", ",", "1", ")", "\n", "\n", "# Add the gold reference", "\n", "pad_num", "=", "(", "tf", ".", "shape", "(", "features", "[", "\"samples\"", "]", ")", "[", "1", "]", "-", "\n", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", ")", "\n", "padding", "=", "tf", ".", "zeros", "(", "(", "1", ",", "pad_num", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "target_pad", "=", "tf", ".", "concat", "(", "[", "features", "[", "\"target\"", "]", ",", "padding", "]", ",", "axis", "=", "1", ")", "\n", "features", "[", "\"samples\"", "]", "=", "tf", ".", "concat", "(", "[", "features", "[", "\"samples\"", "]", ",", "target_pad", "]", ",", "\n", "axis", "=", "0", ")", "\n", "# Delete repetition", "\n", "features", "[", "\"samples\"", "]", "=", "tf", ".", "py_func", "(", "get_unique", ",", "[", "features", "[", "\"samples\"", "]", ",", "eos_id", "]", ",", "\n", "tf", ".", "int32", ")", "\n", "features", "[", "\"samples\"", "]", ".", "set_shape", "(", "[", "None", ",", "None", "]", ")", "\n", "sample_shape", "=", "tf", ".", "shape", "(", "features", "[", "\"samples\"", "]", ")", "\n", "# Get sentence length", "\n", "features", "[", "\"sample_length\"", "]", "=", "get_len", "(", "features", "[", "\"samples\"", "]", ",", "eos_id", ")", "\n", "# Transform to int32", "\n", "features", "[", "\"samples\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"samples\"", "]", ")", "\n", "features", "[", "\"sample_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"sample_length\"", "]", ")", "\n", "# Repeat source sentences", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source\"", "]", ",", "[", "sample_shape", "[", "0", "]", ",", "1", "]", ")", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "[", "sample_shape", "[", "0", "]", "]", ")", "\n", "# Calculate BLEU", "\n", "bleu_fn", "=", "lambda", "x", ":", "bleu_tensor", "(", "x", ",", "features", "[", "\"target\"", "]", ",", "eos_id", ")", "\n", "features", "[", "\"BLEU\"", "]", "=", "tf", ".", "map_fn", "(", "bleu_fn", ",", "features", "[", "\"samples\"", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "features", "[", "\"BLEU\"", "]", ".", "set_shape", "(", "(", "None", ",", ")", ")", "\n", "# Set target", "\n", "features", "[", "\"target\"", "]", "=", "features", "[", "\"samples\"", "]", "\n", "features", "[", "\"target_length\"", "]", "=", "features", "[", "\"sample_length\"", "]", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.cut_sen": [[61, 67], ["sen.index"], "function", ["None"], ["", "def", "cut_sen", "(", "sen", ",", "eos", ")", ":", "\n", "    ", "if", "not", "eos", "in", "sen", ":", "\n", "        ", "return", "sen", "\n", "", "else", ":", "\n", "        ", "pos_eos", "=", "sen", ".", "index", "(", "eos", ")", "\n", "return", "sen", "[", ":", "pos_eos", "+", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.get_unique": [[69, 83], ["sens.tolist.tolist", "numpy.asarray", "mrt_utils.cut_sen", "numpy.asarray.append", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.cut_sen"], ["", "", "def", "get_unique", "(", "sens", ",", "eos", ")", ":", "\n", "    ", "sens", "=", "sens", ".", "tolist", "(", ")", "\n", "result", "=", "[", "]", "\n", "maxlen", "=", "-", "1", "\n", "# remove repetition", "\n", "for", "sen", "in", "sens", ":", "\n", "        ", "tmp", "=", "cut_sen", "(", "sen", ",", "eos", ")", "\n", "if", "tmp", "not", "in", "result", ":", "\n", "            ", "result", ".", "append", "(", "tmp", ")", "\n", "if", "len", "(", "tmp", ")", ">", "maxlen", ":", "\n", "                ", "maxlen", "=", "len", "(", "tmp", ")", "\n", "", "", "", "result", "=", "[", "sen", "+", "[", "eos", "]", "*", "(", "maxlen", "-", "len", "(", "sen", ")", ")", "for", "sen", "in", "result", "]", "\n", "result", "=", "numpy", ".", "asarray", "(", "result", ",", "dtype", "=", "numpy", ".", "int32", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.get_len": [[85, 89], ["tensorflow.where", "tensorflow.segment_min", "tensorflow.equal"], "function", ["None"], ["", "def", "get_len", "(", "sen", ",", "eos", ")", ":", "\n", "    ", "indices", "=", "tf", ".", "where", "(", "tf", ".", "equal", "(", "sen", ",", "eos", ")", ")", "\n", "result", "=", "tf", ".", "segment_min", "(", "indices", "[", ":", ",", "1", "]", ",", "indices", "[", ":", ",", "0", "]", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.log_prob_from_logits": [[91, 93], ["tensorflow.reduce_logsumexp"], "function", ["None"], ["", "def", "log_prob_from_logits", "(", "logits", ")", ":", "\n", "    ", "return", "logits", "-", "tf", ".", "reduce_logsumexp", "(", "logits", ",", "axis", "=", "2", ",", "keep_dims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.sampler": [[95, 130], ["tensorflow.constant", "tensorflow.tile", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.reshape", "tensorflow.while_loop", "tf.concat.set_shape", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.multinomial", "tensorflow.to_int32", "tensorflow.concat", "mrt_utils.create_sampling_graph.symbols_to_logits_fn", "tensorflow.TensorShape", "tensorflow.TensorShape"], "function", ["None"], ["", "def", "sampler", "(", "symbols_to_logits_fn", ",", "initial_ids", ",", "sample_num", ",", "decode_length", ",", "\n", "vocab_size", ",", "eos_id", ",", "features", "=", "None", ")", ":", "\n", "    ", "batch_size", "=", "tf", ".", "shape", "(", "initial_ids", ")", "[", "0", "]", "\n", "\n", "# Expand each batch to sample_num", "\n", "seqlen", "=", "tf", ".", "constant", "(", "0", ")", "\n", "alive_seq", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "initial_ids", ",", "1", ")", ",", "[", "1", ",", "sample_num", "]", ")", "\n", "alive_seq", "=", "tf", ".", "expand_dims", "(", "alive_seq", ",", "2", ")", "# (batch_size, sample_num, 1)", "\n", "sa", "=", "tf", ".", "shape", "(", "alive_seq", ")", "\n", "alive_seq", "=", "tf", ".", "reshape", "(", "alive_seq", ",", "[", "sa", "[", "0", "]", "*", "sa", "[", "1", "]", ",", "1", "]", ")", "\n", "\n", "def", "_is_finished", "(", "i", ",", "alive_seq", ")", ":", "\n", "        ", "return", "i", "<", "decode_length", "\n", "\n", "", "def", "inner_loop", "(", "i", ",", "alive_seq", ")", ":", "\n", "        ", "logit", "=", "symbols_to_logits_fn", "(", "alive_seq", ")", "[", "0", "]", "\n", "new_samples", "=", "tf", ".", "multinomial", "(", "logit", ",", "1", ")", "\n", "new_samples", "=", "tf", ".", "to_int32", "(", "new_samples", ")", "\n", "alive_seq", "=", "tf", ".", "concat", "(", "[", "alive_seq", ",", "new_samples", "]", ",", "1", ")", "\n", "return", "(", "i", "+", "1", ",", "alive_seq", ")", "\n", "\n", "", "(", "_", ",", "alive_seq", ")", "=", "tf", ".", "while_loop", "(", "\n", "_is_finished", ",", "\n", "inner_loop", ",", "\n", "[", "seqlen", ",", "alive_seq", "]", ",", "\n", "shape_invariants", "=", "[", "\n", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", "\n", "]", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "back_prop", "=", "False", "\n", ")", "\n", "alive_seq", ".", "set_shape", "(", "(", "sample_num", ",", "None", ")", ")", "\n", "\n", "return", "alive_seq", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.create_sampling_graph": [[132, 211], ["isinstance", "tensorflow.fill", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "len", "tensorflow.to_int32", "mrt_utils.sampler", "isinstance", "tensorflow.pad", "tensorflow.fill", "enumerate", "tensorflow.shape", "tensorflow.constant", "tensorflow.to_float", "tensorflow.constant", "results.append", "tensorflow.shape", "model_fn", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.sampler"], ["", "def", "create_sampling_graph", "(", "model_fns", ",", "features", ",", "params", ",", "training", "=", "False", ")", ":", "\n", "    ", "if", "isinstance", "(", "params", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "params_list", "=", "params", "\n", "params", "=", "params_list", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "params_list", "=", "[", "params", "]", "\n", "\n", "", "if", "not", "isinstance", "(", "model_fns", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "model_fns", "=", "[", "model_fns", "]", "\n", "\n", "", "decode_length", "=", "params", ".", "decode_length", "\n", "sample_num", "=", "params", ".", "mrt_sample", "\n", "top_beams", "=", "params", ".", "top_beams", "\n", "\n", "# [batch, decoded_ids] => [batch, vocab_size]", "\n", "def", "symbols_to_logits_fn", "(", "decoded_ids", ")", ":", "\n", "        ", "features", "[", "\"target\"", "]", "=", "tf", ".", "pad", "(", "decoded_ids", "[", ":", ",", "1", ":", "]", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "1", "]", "]", ")", "\n", "features", "[", "\"target_length\"", "]", "=", "tf", ".", "fill", "(", "[", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "0", "]", "]", ",", "\n", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", ")", "\n", "\n", "results", "=", "[", "]", "\n", "\n", "for", "i", ",", "model_fn", "in", "enumerate", "(", "model_fns", ")", ":", "\n", "            ", "results", ".", "append", "(", "model_fn", "(", "features", ",", "params_list", "[", "i", "]", ")", ")", "\n", "\n", "", "return", "results", "\n", "\n", "", "batch_size", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "0", "]", "\n", "# append <bos> symbol", "\n", "bos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "bos", "]", "\n", "initial_ids", "=", "tf", ".", "fill", "(", "[", "batch_size", "]", ",", "tf", ".", "constant", "(", "bos_id", ",", "dtype", "=", "tf", ".", "int32", ")", ")", "\n", "\n", "inputs_old", "=", "features", "[", "\"source\"", "]", "\n", "inputs_length_old", "=", "features", "[", "\"source_length\"", "]", "\n", "if", "training", ":", "\n", "        ", "outputs_old", "=", "features", "[", "\"target\"", "]", "\n", "outputs_length_old", "=", "features", "[", "\"target_length\"", "]", "\n", "\n", "#return", "\n", "# Expand the inputs in to the number of samples", "\n", "# [batch, length] => [batch, sample_num, length]", "\n", "", "features", "[", "\"source\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"source\"", "]", ",", "1", ")", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source\"", "]", ",", "[", "1", ",", "sample_num", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "\n", "\n", "# [batch, sample_num, length] => [batch * sample_num, length]", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"source\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "#return", "\n", "# For source sequence length", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"source_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "[", "1", ",", "sample_num", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"source_length\"", "]", ")", "\n", "\n", "# [batch, sample_num, length] => [batch * sample_num, length]", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "]", ")", "\n", "\n", "vocab_size", "=", "len", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", "\n", "# Setting decode length to input length + decode_length", "\n", "decode_length", "=", "tf", ".", "to_float", "(", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", ")", "*", "tf", ".", "constant", "(", "params", ".", "mrt_length_ratio", ")", "\n", "decode_length", "=", "tf", ".", "to_int32", "(", "decode_length", ")", "\n", "\n", "ids", "=", "sampler", "(", "symbols_to_logits_fn", ",", "initial_ids", ",", "params", ".", "mrt_sample", ",", "\n", "decode_length", ",", "vocab_size", ",", "\n", "eos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "eos", "]", ",", "\n", "features", "=", "features", ")", "\n", "\n", "# Set inputs back to the unexpanded inputs to not to confuse the Estimator", "\n", "features", "[", "\"source\"", "]", "=", "inputs_old", "\n", "features", "[", "\"source_length\"", "]", "=", "inputs_length_old", "\n", "if", "training", ":", "\n", "        ", "features", "[", "\"target\"", "]", "=", "outputs_old", "\n", "features", "[", "\"target_length\"", "]", "=", "outputs_length_old", "\n", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.mrt_loss": [[213, 223], ["tensorflow.reduce_sum", "tensorflow.reduce_min", "tensorflow.exp", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["None"], ["", "def", "mrt_loss", "(", "features", ",", "params", ",", "ce", ",", "tgt_mask", ")", ":", "\n", "    ", "logprobs", "=", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ",", "axis", "=", "1", ")", "\n", "logprobs", "*=", "params", ".", "mrt_alpha", "\n", "logprobs", "-=", "tf", ".", "reduce_min", "(", "logprobs", ")", "\n", "probs", "=", "tf", ".", "exp", "(", "-", "logprobs", ")", "\n", "probs", "/=", "tf", ".", "reduce_sum", "(", "probs", ")", "\n", "ave_bleu", "=", "probs", "*", "features", "[", "\"BLEU\"", "]", "\n", "loss", "=", "-", "tf", ".", "reduce_sum", "(", "ave_bleu", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.bleu_tensor": [[225, 228], ["tensorflow.py_func", "mrt_utils.bleu_numpy"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.bleu_numpy"], ["", "def", "bleu_tensor", "(", "trans", ",", "ref", ",", "eos", ")", ":", "\n", "    ", "return", "tf", ".", "py_func", "(", "lambda", "x", ",", "y", ":", "bleu_numpy", "(", "x", ",", "y", ",", "eos", ",", "smooth", "=", "True", ")", ",", "\n", "[", "trans", ",", "ref", "]", ",", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.bleu_numpy": [[230, 275], ["cut_sen.tolist", "cut_sen.tolist", "mrt_utils.cut_sen", "mrt_utils.cut_sen", "zip", "range", "thumt.brevity_penalty", "numpy.float32", "range", "sum", "math.exp", "range", "range", "thumt.modified_precision", "range", "math.log", "len", "ValueError", "sum", "float", "float", "float", "range"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.cut_sen", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.mrt_utils.cut_sen", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.bleu.brevity_penalty", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.bleu.modified_precision"], ["", "def", "bleu_numpy", "(", "trans", ",", "refs", ",", "eos", ",", "bp", "=", "\"closest\"", ",", "smooth", "=", "False", ",", "n", "=", "4", ",", "\n", "weights", "=", "None", ")", ":", "\n", "    ", "trans", "=", "trans", ".", "tolist", "(", ")", "\n", "refs", "=", "refs", ".", "tolist", "(", ")", "\n", "# cut sentence", "\n", "trans", "=", "cut_sen", "(", "trans", ",", "eos", ")", "\n", "refs", "=", "cut_sen", "(", "refs", ",", "eos", ")", "\n", "# wrap", "\n", "trans", "=", "[", "trans", "]", "\n", "refs", "=", "[", "refs", "]", "\n", "p_norm", "=", "[", "0", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "p_denorm", "=", "[", "0", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "\n", "for", "candidate", ",", "references", "in", "zip", "(", "trans", ",", "refs", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "ccount", ",", "tcount", "=", "bleu", ".", "modified_precision", "(", "candidate", ",", "references", ",", "\n", "i", "+", "1", ")", "\n", "p_norm", "[", "i", "]", "+=", "ccount", "\n", "p_denorm", "[", "i", "]", "+=", "tcount", "\n", "\n", "", "", "bleu_n", "=", "[", "0", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "# add one smoothing", "\n", "        ", "if", "smooth", "and", "i", ">", "0", ":", "\n", "            ", "p_norm", "[", "i", "]", "+=", "1", "\n", "p_denorm", "[", "i", "]", "+=", "1", "\n", "\n", "", "if", "p_norm", "[", "i", "]", "==", "0", "or", "p_denorm", "[", "i", "]", "==", "0", ":", "\n", "            ", "bleu_n", "[", "i", "]", "=", "-", "9999", "\n", "", "else", ":", "\n", "            ", "bleu_n", "[", "i", "]", "=", "math", ".", "log", "(", "float", "(", "p_norm", "[", "i", "]", ")", "/", "float", "(", "p_denorm", "[", "i", "]", ")", ")", "\n", "\n", "", "", "if", "weights", ":", "\n", "        ", "if", "len", "(", "weights", ")", "!=", "n", ":", "\n", "            ", "raise", "ValueError", "(", "\"len(weights) != n: invalid weight number\"", ")", "\n", "", "log_precision", "=", "sum", "(", "[", "bleu_n", "[", "i", "]", "*", "weights", "[", "i", "]", "for", "i", "in", "range", "(", "n", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "log_precision", "=", "sum", "(", "bleu_n", ")", "/", "float", "(", "n", ")", "\n", "\n", "", "bp", "=", "bleu", ".", "brevity_penalty", "(", "trans", ",", "refs", ",", "bp", ")", "\n", "\n", "score", "=", "bp", "*", "math", ".", "exp", "(", "log_precision", ")", "\n", "\n", "return", "numpy", ".", "float32", "(", "score", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.utils.session_run": [[11, 14], ["monitored_session._tf_sess().run", "monitored_session._tf_sess"], "function", ["None"], ["def", "session_run", "(", "monitored_session", ",", "args", ")", ":", "\n", "# Call raw TF session directly", "\n", "    ", "return", "monitored_session", ".", "_tf_sess", "(", ")", ".", "run", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.utils.zero_variables": [[16, 25], ["tensorflow.group", "ops.append", "tensorflow.device", "var.assign", "tensorflow.zeros", "var.shape.as_list"], "function", ["None"], ["", "def", "zero_variables", "(", "variables", ",", "name", "=", "None", ")", ":", "\n", "    ", "ops", "=", "[", "]", "\n", "\n", "for", "var", "in", "variables", ":", "\n", "        ", "with", "tf", ".", "device", "(", "var", ".", "device", ")", ":", "\n", "            ", "op", "=", "var", ".", "assign", "(", "tf", ".", "zeros", "(", "var", ".", "shape", ".", "as_list", "(", ")", ")", ")", "\n", "", "ops", ".", "append", "(", "op", ")", "\n", "\n", "", "return", "tf", ".", "group", "(", "*", "ops", ",", "name", "=", "name", "or", "\"zero_op\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.utils.replicate_variables": [[27, 38], ["tensorflow.device", "new_vars.append", "tensorflow.Variable", "var.name.split", "tensorflow.zeros", "var.shape.as_list"], "function", ["None"], ["", "def", "replicate_variables", "(", "variables", ",", "device", "=", "None", ")", ":", "\n", "    ", "new_vars", "=", "[", "]", "\n", "\n", "for", "var", "in", "variables", ":", "\n", "        ", "device", "=", "device", "or", "var", ".", "device", "\n", "with", "tf", ".", "device", "(", "device", ")", ":", "\n", "            ", "name", "=", "\"replicate/\"", "+", "var", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", "\n", "new_vars", ".", "append", "(", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "var", ".", "shape", ".", "as_list", "(", ")", ")", ",", "\n", "name", "=", "name", ",", "trainable", "=", "False", ")", ")", "\n", "\n", "", "", "return", "new_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.utils.collect_gradients": [[40, 50], ["zip", "tensorflow.group", "isinstance", "ops.append", "ops.append", "tensorflow.assign_add", "tensorflow.scatter_add"], "function", ["None"], ["", "def", "collect_gradients", "(", "gradients", ",", "variables", ")", ":", "\n", "    ", "ops", "=", "[", "]", "\n", "\n", "for", "grad", ",", "var", "in", "zip", "(", "gradients", ",", "variables", ")", ":", "\n", "        ", "if", "isinstance", "(", "grad", ",", "tf", ".", "Tensor", ")", ":", "\n", "            ", "ops", ".", "append", "(", "tf", ".", "assign_add", "(", "var", ",", "grad", ")", ")", "\n", "", "else", ":", "\n", "            ", "ops", ".", "append", "(", "tf", ".", "scatter_add", "(", "var", ",", "grad", ".", "indices", ",", "grad", ".", "values", ")", ")", "\n", "\n", "", "", "return", "tf", ".", "group", "(", "*", "ops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.utils.scale_gradients": [[52, 63], ["tuple", "isinstance", "tensorflow.IndexedSlices", "scaled_gradients.append", "scaled_gradients.append"], "function", ["None"], ["", "def", "scale_gradients", "(", "gradients", ",", "scale", ")", ":", "\n", "    ", "scaled_gradients", "=", "[", "]", "\n", "\n", "for", "grad", "in", "gradients", ":", "\n", "        ", "if", "isinstance", "(", "grad", ",", "tf", ".", "IndexedSlices", ")", ":", "\n", "            ", "slices", "=", "tf", ".", "IndexedSlices", "(", "scale", "*", "grad", ".", "values", ",", "grad", ".", "indices", ")", "\n", "scaled_gradients", ".", "append", "(", "slices", ")", "\n", "", "else", ":", "\n", "            ", "scaled_gradients", ".", "append", "(", "scale", "*", "grad", ")", "\n", "\n", "", "", "return", "tuple", "(", "scaled_gradients", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.sampling._get_inference_fn": [[21, 51], ["zip", "tensorflow.pad", "tensorflow.fill", "tensorflow.add_n", "float", "model_fn", "outputs.append", "next_state.append", "model_fn", "outputs.append", "next_state.append", "len", "tensorflow.shape", "tensorflow.shape"], "function", ["None"], ["", "def", "_get_inference_fn", "(", "model_fns", ",", "features", ")", ":", "\n", "    ", "def", "inference_fn", "(", "inputs", ",", "state", ")", ":", "\n", "        ", "local_features", "=", "{", "\n", "\"source\"", ":", "features", "[", "\"source\"", "]", ",", "\n", "\"source_length\"", ":", "features", "[", "\"source_length\"", "]", ",", "\n", "# [bos_id, ...] => [..., 0]", "\n", "\"target\"", ":", "tf", ".", "pad", "(", "inputs", "[", ":", ",", "1", ":", "]", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "1", "]", "]", ")", ",", "\n", "\"target_length\"", ":", "tf", ".", "fill", "(", "[", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "]", ",", "\n", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", ")", "\n", "}", "\n", "\n", "outputs", "=", "[", "]", "\n", "next_state", "=", "[", "]", "\n", "\n", "for", "(", "model_fn", ",", "model_state", ")", "in", "zip", "(", "model_fns", ",", "state", ")", ":", "\n", "            ", "if", "model_state", ":", "\n", "                ", "output", ",", "new_state", "=", "model_fn", "(", "local_features", ",", "model_state", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "next_state", ".", "append", "(", "new_state", ")", "\n", "", "else", ":", "\n", "                ", "output", "=", "model_fn", "(", "local_features", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "next_state", ".", "append", "(", "{", "}", ")", "\n", "\n", "# Ensemble", "\n", "", "", "log_prob", "=", "tf", ".", "add_n", "(", "outputs", ")", "/", "float", "(", "len", "(", "outputs", ")", ")", "\n", "\n", "return", "log_prob", ",", "next_state", "\n", "\n", "", "return", "inference_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.sampling._sampling_step": [[53, 102], ["func", "tensorflow.one_hot", "thumt.tile_batch", "tensorflow.where", "tensorflow.multinomial", "tensorflow.squeeze", "tensorflow.squeeze", "tensorflow.logical_or", "tensorflow.where", "tensorflow.where", "tensorflow.where", "tensorflow.squeeze", "tensorflow.fill", "tensorflow.logical_and", "tensorflow.logical_or", "tensorflow.where", "tensorflow.where", "sampling.SamplerState", "tensorflow.shape", "tensorflow.reshape", "tensorflow.zeros_like", "thumt.gather_2d", "tensorflow.equal", "tensorflow.fill", "tensorflow.zeros", "tensorflow.ones", "tensorflow.zeros", "thumt.gather_2d", "tensorflow.logical_not", "tensorflow.shape", "tensorflow.fill", "tensorflow.concat"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.tile_batch", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.gather_2d"], ["", "def", "_sampling_step", "(", "time", ",", "func", ",", "state", ",", "min_length", ",", "max_length", ",", "pad_id", ",", "eos_id", ")", ":", "\n", "# Compute log probabilities", "\n", "    ", "seqs", "=", "state", ".", "inputs", "\n", "# [batch_size * num_samples, vocab_size]", "\n", "step_log_probs", ",", "next_state", "=", "func", "(", "seqs", ",", "state", ".", "state", ")", "\n", "\n", "# Suppress <eos> if needed", "\n", "batch_size", "=", "tf", ".", "shape", "(", "step_log_probs", ")", "[", "0", "]", "\n", "vocab_size", "=", "step_log_probs", ".", "shape", "[", "-", "1", "]", ".", "value", "or", "tf", ".", "shape", "(", "step_log_probs", ")", "[", "1", "]", "\n", "add_mask", "=", "tf", ".", "one_hot", "(", "eos_id", ",", "vocab_size", ",", "dtype", "=", "step_log_probs", ".", "dtype", ",", "\n", "on_value", "=", "step_log_probs", ".", "dtype", ".", "min", ",", "\n", "off_value", "=", "0.0", ")", "\n", "add_mask", "=", "utils", ".", "tile_batch", "(", "tf", ".", "reshape", "(", "add_mask", ",", "[", "1", ",", "-", "1", "]", ")", ",", "batch_size", ")", "\n", "add_mask", "=", "tf", ".", "where", "(", "time", "<", "min_length", ",", "add_mask", ",", "tf", ".", "zeros_like", "(", "add_mask", ")", ")", "\n", "step_log_probs", "=", "step_log_probs", "+", "add_mask", "\n", "\n", "# sample from distribution", "\n", "symbol_indices", "=", "tf", ".", "multinomial", "(", "step_log_probs", ",", "1", ",", "output_dtype", "=", "tf", ".", "int32", ")", "\n", "symbol_scores", "=", "tf", ".", "squeeze", "(", "utils", ".", "gather_2d", "(", "step_log_probs", ",", "symbol_indices", ")", ",", "\n", "axis", "=", "1", ")", "\n", "curr_flags", "=", "tf", ".", "squeeze", "(", "tf", ".", "equal", "(", "symbol_indices", ",", "eos_id", ")", ",", "axis", "=", "1", ")", "\n", "curr_flags", "=", "tf", ".", "logical_or", "(", "state", ".", "flags", ",", "curr_flags", ")", "\n", "\n", "# Append <pad> to finished samples", "\n", "symbol_indices", "=", "tf", ".", "where", "(", "state", ".", "flags", ",", "tf", ".", "fill", "(", "[", "batch_size", ",", "1", "]", ",", "pad_id", ")", ",", "\n", "symbol_indices", ")", "\n", "symbol_scores", "=", "tf", ".", "where", "(", "state", ".", "flags", ",", "tf", ".", "zeros", "(", "[", "batch_size", "]", ")", ",", "\n", "symbol_scores", ")", "\n", "\n", "# Force sampler to generate <eos> if length exceed max_length", "\n", "eos_flags", "=", "tf", ".", "where", "(", "time", ">", "max_length", ",", "tf", ".", "ones", "(", "[", "batch_size", "]", ",", "tf", ".", "bool", ")", ",", "\n", "tf", ".", "zeros", "(", "[", "batch_size", "]", ",", "tf", ".", "bool", ")", ")", "\n", "eos_scores", "=", "tf", ".", "squeeze", "(", "utils", ".", "gather_2d", "(", "step_log_probs", ",", "\n", "tf", ".", "fill", "(", "[", "batch_size", ",", "1", "]", ",", "eos_id", ")", ")", ",", "\n", "axis", "=", "1", ")", "\n", "eos_indices", "=", "tf", ".", "fill", "(", "[", "batch_size", ",", "1", "]", ",", "eos_id", ")", "\n", "cond", "=", "tf", ".", "logical_and", "(", "tf", ".", "logical_not", "(", "curr_flags", ")", ",", "eos_flags", ")", "\n", "curr_flags", "=", "tf", ".", "logical_or", "(", "curr_flags", ",", "eos_flags", ")", "\n", "symbol_indices", "=", "tf", ".", "where", "(", "cond", ",", "eos_indices", ",", "symbol_indices", ")", "\n", "symbol_scores", "=", "tf", ".", "where", "(", "cond", ",", "eos_scores", ",", "symbol_scores", ")", "\n", "\n", "new_state", "=", "SamplerState", "(", "\n", "inputs", "=", "tf", ".", "concat", "(", "[", "seqs", ",", "symbol_indices", "]", ",", "axis", "=", "1", ")", ",", "\n", "state", "=", "next_state", ",", "\n", "scores", "=", "state", ".", "scores", "+", "symbol_scores", ",", "\n", "flags", "=", "curr_flags", "\n", ")", "\n", "\n", "return", "time", "+", "1", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.sampling.random_sample": [[104, 149], ["tensorflow.fill", "tensorflow.zeros", "tensorflow.zeros", "sampling.SamplerState", "tensorflow.reduce_max", "tensorflow.constant", "sampling.SamplerState", "tensorflow.while_loop", "tensorflow.reduce_all", "tensorflow.logical_and", "sampling._sampling_step", "tensorflow.less", "tensorflow.logical_not", "tensorflow.TensorShape", "tensorflow.python.util.nest.map_structure", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.sampling._sampling_step"], ["", "def", "random_sample", "(", "func", ",", "state", ",", "batch_size", ",", "min_length", ",", "max_length", ",", "pad_id", ",", "\n", "bos_id", ",", "eos_id", ")", ":", "\n", "    ", "init_seqs", "=", "tf", ".", "fill", "(", "[", "batch_size", ",", "1", "]", ",", "bos_id", ")", "\n", "init_scores", "=", "tf", ".", "zeros", "(", "[", "batch_size", "]", ")", "\n", "init_flags", "=", "tf", ".", "zeros", "(", "[", "batch_size", "]", ",", "tf", ".", "bool", ")", "\n", "\n", "state", "=", "SamplerState", "(", "\n", "inputs", "=", "init_seqs", ",", "\n", "state", "=", "state", ",", "\n", "scores", "=", "init_scores", ",", "\n", "flags", "=", "init_flags", "\n", ")", "\n", "\n", "max_step", "=", "tf", ".", "reduce_max", "(", "max_length", ")", "\n", "\n", "def", "_is_finished", "(", "t", ",", "s", ")", ":", "\n", "        ", "all_finished", "=", "tf", ".", "reduce_all", "(", "s", ".", "flags", ")", "\n", "cond", "=", "tf", ".", "logical_and", "(", "tf", ".", "less", "(", "t", ",", "max_step", ")", ",", "\n", "tf", ".", "logical_not", "(", "all_finished", ")", ")", "\n", "\n", "return", "cond", "\n", "\n", "", "def", "_loop_fn", "(", "t", ",", "s", ")", ":", "\n", "        ", "outs", "=", "_sampling_step", "(", "t", ",", "func", ",", "s", ",", "min_length", ",", "max_length", ",", "pad_id", ",", "\n", "eos_id", ")", "\n", "return", "outs", "\n", "\n", "", "time", "=", "tf", ".", "constant", "(", "0", ",", "name", "=", "\"time\"", ")", "\n", "shape_invariants", "=", "SamplerState", "(", "\n", "inputs", "=", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ",", "\n", "state", "=", "nest", ".", "map_structure", "(", "utils", ".", "infer_shape_invariants", ",", "state", ".", "state", ")", ",", "\n", "scores", "=", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "flags", "=", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", "\n", ")", "\n", "outputs", "=", "tf", ".", "while_loop", "(", "_is_finished", ",", "_loop_fn", ",", "[", "time", ",", "state", "]", ",", "\n", "shape_invariants", "=", "[", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "shape_invariants", "]", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "back_prop", "=", "False", ")", "\n", "\n", "final_state", "=", "outputs", "[", "1", "]", "\n", "final_seqs", "=", "final_state", ".", "inputs", "\n", "final_scores", "=", "final_state", ".", "scores", "\n", "\n", "return", "final_seqs", ",", "final_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.sampling.create_sampling_graph": [[151, 215], ["copy.copy", "thumt.tile_batch", "thumt.tile_batch", "tensorflow.to_float", "tensorflow.to_float", "tensorflow.to_int32", "tensorflow.to_int32", "sampling._get_inference_fn", "tensorflow.python.util.nest.map_structure", "sampling.random_sample", "tensorflow.reshape", "tensorflow.reshape", "isinstance", "ValueError", "model.get_inference_func", "callable", "tensorflow.shape", "nest.map_structure.append", "funcs.append", "nest.map_structure.append", "funcs.append", "thumt.tile_batch"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.tile_batch", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.tile_batch", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.sampling._get_inference_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.sampling.random_sample", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_inference_func", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.common.tile_batch"], ["", "def", "create_sampling_graph", "(", "models", ",", "features", ",", "params", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "models", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"'models' must be a list or tuple\"", ")", "\n", "\n", "", "features", "=", "copy", ".", "copy", "(", "features", ")", "\n", "model_fns", "=", "[", "model", ".", "get_inference_func", "(", ")", "for", "model", "in", "models", "]", "\n", "\n", "num_samples", "=", "params", ".", "num_samples", "\n", "\n", "# Compute initial state if necessary", "\n", "states", "=", "[", "]", "\n", "funcs", "=", "[", "]", "\n", "\n", "for", "model_fn", "in", "model_fns", ":", "\n", "        ", "if", "callable", "(", "model_fn", ")", ":", "\n", "# For non-incremental decoding", "\n", "            ", "states", ".", "append", "(", "{", "}", ")", "\n", "funcs", ".", "append", "(", "model_fn", ")", "\n", "", "else", ":", "\n", "# For incremental decoding where model_fn is a tuple:", "\n", "# (encoding_fn, decoding_fn)", "\n", "            ", "states", ".", "append", "(", "model_fn", "[", "0", "]", "(", "features", ")", ")", "\n", "funcs", ".", "append", "(", "model_fn", "[", "1", "]", ")", "\n", "\n", "", "", "batch_size", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "0", "]", "\n", "pad_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "pad", "]", "\n", "bos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "bos", "]", "\n", "eos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "eos", "]", "\n", "\n", "# Expand the inputs", "\n", "features", "[", "\"source\"", "]", "=", "utils", ".", "tile_batch", "(", "features", "[", "\"source\"", "]", ",", "num_samples", ")", "\n", "features", "[", "\"source_length\"", "]", "=", "utils", ".", "tile_batch", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "num_samples", ")", "\n", "\n", "min_length", "=", "tf", ".", "to_float", "(", "features", "[", "\"source_length\"", "]", ")", "\n", "max_length", "=", "tf", ".", "to_float", "(", "features", "[", "\"source_length\"", "]", ")", "\n", "\n", "if", "params", ".", "min_length_ratio", ":", "\n", "        ", "min_length", "=", "min_length", "*", "params", ".", "min_length_ratio", "\n", "\n", "", "if", "params", ".", "max_length_ratio", ":", "\n", "        ", "max_length", "=", "max_length", "*", "params", ".", "max_length_ratio", "\n", "\n", "", "if", "params", ".", "min_sample_length", ":", "\n", "        ", "min_length", "=", "min_length", "-", "params", ".", "min_sample_length", "\n", "\n", "", "if", "params", ".", "max_sample_length", ":", "\n", "        ", "max_length", "=", "max_length", "+", "params", ".", "max_sample_length", "\n", "\n", "", "min_length", "=", "tf", ".", "to_int32", "(", "min_length", ")", "\n", "max_length", "=", "tf", ".", "to_int32", "(", "max_length", ")", "\n", "\n", "decoding_fn", "=", "_get_inference_fn", "(", "funcs", ",", "features", ")", "\n", "states", "=", "nest", ".", "map_structure", "(", "lambda", "x", ":", "utils", ".", "tile_batch", "(", "x", ",", "num_samples", ")", ",", "\n", "states", ")", "\n", "\n", "seqs", ",", "scores", "=", "random_sample", "(", "decoding_fn", ",", "states", ",", "batch_size", "*", "num_samples", ",", "\n", "min_length", ",", "max_length", ",", "pad_id", ",", "bos_id", ",", "\n", "eos_id", ")", "\n", "\n", "seqs", "=", "tf", ".", "reshape", "(", "seqs", ",", "[", "batch_size", ",", "num_samples", ",", "-", "1", "]", ")", "\n", "scores", "=", "tf", ".", "reshape", "(", "scores", ",", "[", "batch_size", ",", "num_samples", "]", ")", "\n", "\n", "return", "seqs", "[", ":", ",", ":", ",", "1", ":", "]", ",", "scores", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.LossScalingOptimizer.__init__": [[50, 68], ["super().__init__", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.train_word2vec.MySentences.__init__"], ["    ", "def", "__init__", "(", "self", ",", "optimizer", ",", "step", "=", "1", ",", "use_locking", "=", "False", ",", "\n", "name", "=", "\"MultiStepOptimizer\"", ")", ":", "\n", "        ", "super", "(", "MultiStepOptimizer", ",", "self", ")", ".", "__init__", "(", "use_locking", ",", "name", ")", "\n", "self", ".", "_optimizer", "=", "optimizer", "\n", "self", ".", "_step", "=", "step", "\n", "\n", "", "def", "_all_reduce", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "self", ".", "_name", "+", "\"_Allreduce\"", ")", ":", "\n", "            ", "if", "tensor", "is", "None", ":", "\n", "                ", "return", "tensor", "\n", "\n", "", "if", "isinstance", "(", "tensor", ",", "tf", ".", "IndexedSlices", ")", ":", "\n", "                ", "tensor", "=", "tf", ".", "convert_to_tensor", "(", "tensor", ")", "\n", "\n", "", "return", "all_reduce", "(", "tensor", ")", "\n", "\n", "", "", "def", "compute_gradients", "(", "self", ",", "loss", ",", "var_list", "=", "None", ",", "\n", "gate_gradients", "=", "tf", ".", "train", ".", "Optimizer", ".", "GATE_OP", ",", "\n", "aggregation_method", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.LossScalingOptimizer.compute_gradients": [[69, 93], ["optimizers.LossScalingOptimizer._create_non_slot_variable", "optimizers.LossScalingOptimizer._optimizer.compute_gradients", "isinstance", "scaled_grads_and_vars.append", "tensorflow.IndexedSlices", "isinstance"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.StaticLossScalingOptimizer.compute_gradients"], ["colocate_gradients_with_ops", "=", "False", ",", "\n", "grad_loss", "=", "None", ")", ":", "\n", "        ", "grads_and_vars", "=", "self", ".", "_optimizer", ".", "compute_gradients", "(", "loss", ",", "var_list", ",", "\n", "gate_gradients", ",", "aggregation_method", ",", "colocate_gradients_with_ops", ",", "\n", "grad_loss", ")", "\n", "\n", "grads", ",", "var_list", "=", "list", "(", "zip", "(", "*", "grads_and_vars", ")", ")", "\n", "\n", "# Do not create extra variables when step is 1", "\n", "if", "self", ".", "_step", "==", "1", ":", "\n", "            ", "grads", "=", "[", "self", ".", "_all_reduce", "(", "t", ")", "for", "t", "in", "grads", "]", "\n", "return", "list", "(", "zip", "(", "grads", ",", "var_list", ")", ")", "\n", "\n", "", "first_var", "=", "min", "(", "var_list", ",", "key", "=", "lambda", "x", ":", "x", ".", "name", ")", "\n", "iter_var", "=", "self", ".", "_create_non_slot_variable", "(", "\n", "initial_value", "=", "0", "if", "self", ".", "_step", "==", "1", "else", "1", ",", "name", "=", "\"iter\"", ",", "\n", "colocate_with", "=", "first_var", ")", "\n", "\n", "new_grads", "=", "[", "]", "\n", "\n", "for", "grad", ",", "var", "in", "zip", "(", "grads", ",", "var_list", ")", ":", "\n", "            ", "grad_acc", "=", "self", ".", "_zeros_slot", "(", "var", ",", "\"grad_acc\"", ",", "self", ".", "_name", ")", "\n", "\n", "if", "isinstance", "(", "grad", ",", "tf", ".", "IndexedSlices", ")", ":", "\n", "                ", "grad_acc", "=", "tf", ".", "scatter_add", "(", "grad_acc", ",", "grad", ".", "indices", ",", "grad", ".", "values", ",", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.LossScalingOptimizer.apply_gradients": [[94, 173], ["list", "tensorflow.global_norm", "tensorflow.logical_not", "list", "optimizers.LossScalingOptimizer._optimizer.apply_gradients", "min", "optimizers.LossScalingOptimizer._create_non_slot_variable", "optimizers.LossScalingOptimizer._create_non_slot_variable", "optimizers.LossScalingOptimizer._create_non_slot_variable", "optimizers.LossScalingOptimizer._create_non_slot_variable", "optimizers.LossScalingOptimizer._get_non_slot_variable", "tensorflow.assign_add", "tensorflow.cond", "tensorflow.cond", "tensorflow.group", "zip", "tensorflow.is_finite", "new_grads.append", "zip", "tensorflow.get_default_graph", "tensorflow.assign", "tensorflow.assign", "tensorflow.group", "tensorflow.assign", "tensorflow.assign", "tensorflow.assign", "tensorflow.group", "tensorflow.control_dependencies", "tensorflow.div", "tensorflow.cond", "tensorflow.cond", "tensorflow.cond", "tensorflow.assign_add", "tensorflow.assign", "tensorflow.assign", "tensorflow.cast", "tensorflow.cast", "tensorflow.logical_and", "tensorflow.logical_and", "tensorflow.maximum", "tensorflow.greater", "tensorflow.no_op", "tensorflow.logical_not", "tensorflow.equal", "tensorflow.no_op", "tensorflow.zeros_like"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.StaticLossScalingOptimizer.apply_gradients"], ["use_locking", "=", "self", ".", "_use_locking", ")", "\n", "", "else", ":", "\n", "                ", "grad_acc", "=", "tf", ".", "assign_add", "(", "grad_acc", ",", "grad", ",", "\n", "use_locking", "=", "self", ".", "_use_locking", ")", "\n", "\n", "", "def", "_acc_grad", "(", ")", ":", "\n", "                ", "return", "grad_acc", "\n", "\n", "", "def", "_avg_grad", "(", ")", ":", "\n", "                ", "return", "self", ".", "_all_reduce", "(", "grad_acc", "/", "self", ".", "_step", ")", "\n", "\n", "", "grad", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "iter_var", ",", "0", ")", ",", "_avg_grad", ",", "_acc_grad", ")", "\n", "new_grads", ".", "append", "(", "grad", ")", "\n", "\n", "", "return", "list", "(", "zip", "(", "new_grads", ",", "var_list", ")", ")", "\n", "\n", "", "def", "apply_gradients", "(", "self", ",", "grads_and_vars", ",", "global_step", "=", "None", ",", "name", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "_step", "==", "1", ":", "\n", "            ", "return", "self", ".", "_optimizer", ".", "apply_gradients", "(", "grads_and_vars", ",", "global_step", ",", "\n", "name", "=", "name", ")", "\n", "\n", "", "grads", ",", "var_list", "=", "list", "(", "zip", "(", "*", "grads_and_vars", ")", ")", "\n", "\n", "step_t", "=", "tf", ".", "convert_to_tensor", "(", "self", ".", "_step", ",", "name", "=", "\"step\"", ")", "\n", "\n", "# Create slots for gradient accumulators", "\n", "for", "v", "in", "var_list", ":", "\n", "            ", "self", ".", "_zeros_slot", "(", "v", ",", "\"grad_acc\"", ",", "self", ".", "_name", ")", "\n", "\n", "", "def", "_pass_gradients", "(", ")", ":", "\n", "            ", "return", "tf", ".", "group", "(", "*", "grads", ")", "\n", "\n", "", "def", "_apply_gradients", "(", ")", ":", "\n", "            ", "op", "=", "self", ".", "_optimizer", ".", "apply_gradients", "(", "zip", "(", "grads", ",", "var_list", ")", ",", "\n", "global_step", ",", "name", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "op", "]", ")", ":", "\n", "                ", "zero_ops", "=", "[", "]", "\n", "for", "var", "in", "var_list", ":", "\n", "                    ", "grad_acc", "=", "self", ".", "get_slot", "(", "var", ",", "\"grad_acc\"", ")", "\n", "zero_ops", ".", "append", "(", "\n", "grad_acc", ".", "assign", "(", "tf", ".", "zeros_like", "(", "grad_acc", ")", ",", "\n", "use_locking", "=", "self", ".", "_use_locking", ")", ")", "\n", "", "zero_op", "=", "tf", ".", "group", "(", "*", "zero_ops", ")", "\n", "", "return", "tf", ".", "group", "(", "*", "[", "op", ",", "zero_op", "]", ")", "\n", "\n", "", "iter_var", "=", "self", ".", "_get_non_slot_variable", "(", "\"iter\"", ",", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "update_op", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "iter_var", ",", "0", ")", ",", "_apply_gradients", ",", "\n", "_pass_gradients", ")", "\n", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "update_op", "]", ")", ":", "\n", "            ", "iter_op", "=", "iter_var", ".", "assign", "(", "tf", ".", "mod", "(", "iter_var", "+", "1", ",", "step_t", ")", ",", "\n", "use_locking", "=", "self", ".", "_use_locking", ")", "\n", "\n", "", "return", "tf", ".", "group", "(", "*", "[", "update_op", ",", "iter_op", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.MultiStepOptimizer.__init__": [[177, 183], ["super().__init__", "tensorflow.convert_to_tensor"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.train_word2vec.MySentences.__init__"], []], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.MultiStepOptimizer._all_reduce": [[184, 193], ["tensorflow.name_scope", "isinstance", "thumt.utils.distribute.all_reduce", "tensorflow.convert_to_tensor"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.all_reduce"], []], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.MultiStepOptimizer.compute_gradients": [[194, 237], ["optimizers.MultiStepOptimizer._optimizer.compute_gradients", "list", "min", "optimizers.MultiStepOptimizer._create_non_slot_variable", "zip", "list", "zip", "list", "optimizers.MultiStepOptimizer._zeros_slot", "isinstance", "tensorflow.cond", "new_grads.append", "zip", "optimizers.MultiStepOptimizer._all_reduce", "zip", "tensorflow.scatter_add", "tensorflow.assign_add", "optimizers.MultiStepOptimizer._all_reduce", "tensorflow.equal"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.StaticLossScalingOptimizer.compute_gradients", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.MultiStepOptimizer._all_reduce", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.MultiStepOptimizer._all_reduce"], []], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.MultiStepOptimizer.apply_gradients": [[238, 270], ["list", "optimizers.MultiStepOptimizer._get_non_slot_variable", "tensorflow.cond", "tensorflow.group", "optimizers.MultiStepOptimizer._optimizer.apply_gradients", "zip", "tensorflow.group", "optimizers.MultiStepOptimizer._optimizer.apply_gradients", "tensorflow.group", "tensorflow.get_default_graph", "tensorflow.equal", "tensorflow.control_dependencies", "optimizers.MultiStepOptimizer.assign", "zip", "tensorflow.control_dependencies", "tensorflow.group", "tensorflow.mod", "optimizers.MultiStepOptimizer.get_slot", "zero_ops.append", "optimizers.MultiStepOptimizer.assign", "tensorflow.zeros_like"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.StaticLossScalingOptimizer.apply_gradients", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.StaticLossScalingOptimizer.apply_gradients"], []], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.hooks._shard_features": [[134, 157], ["len", "isinstance", "range"], "function", ["None"], ["    ", "graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "graph", ".", "as_default", "(", ")", ":", "\n", "        ", "features", "=", "input_fn", "(", ")", "\n", "refs", "=", "features", "[", "\"references\"", "]", "\n", "placeholders", "=", "{", "\n", "\"source\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"source\"", ")", ",", "\n", "\"source_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"source_length\"", ")", ",", "\n", "\"context_dia_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_dia_src\"", ")", ",", "\n", "\"context_dia_src_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_dia_src_length\"", ")", ",", "\n", "\"context_dia_tgt\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_dia_tgt\"", ")", ",", "\n", "\"context_dia_tgt_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_dia_tgt_length\"", ")", ",", "\n", "\"context_sty_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_sty_src\"", ")", ",", "\n", "\"context_sty_src_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_sty_src_length\"", ")", ",", "\n", "\"context_sty_tgt\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_sty_tgt\"", ")", ",", "\n", "\"context_sty_tgt_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_sty_tgt_length\"", ")", ",", "\n", "\"context_source\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_source\"", ")", ",", "\n", "\"context_source_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_source_length\"", ")", ",", "\n", "\"position_dia_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_dia_src\"", ")", ",", "\n", "\"position_dia_tgt\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_dia_tgt\"", ")", ",", "\n", "\"position_sty_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_sty_src\"", ")", ",", "\n", "\"position_sty_tgt\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_sty_tgt\"", ")", ",", "\n", "\"position_ctx_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_ctx_src\"", ")", ",", "\n", "\"sample\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"sample\"", ")", ",", "\n", "\"sample_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"sample_length\"", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.StaticLossScalingOptimizer.__init__": [[15, 20], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.train_word2vec.MySentences.__init__"], ["    ", "def", "__init__", "(", "self", ",", "optimizer", ",", "scale", "=", "128.0", ",", "use_locking", "=", "False", ",", "\n", "name", "=", "\"LossScalingOptimizer\"", ")", ":", "\n", "        ", "super", "(", "LossScalingOptimizer", ",", "self", ")", ".", "__init__", "(", "use_locking", ",", "name", ")", "\n", "self", ".", "_optimizer", "=", "optimizer", "\n", "self", ".", "_scale", "=", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.StaticLossScalingOptimizer.compute_gradients": [[21, 42], ["optimizers.StaticLossScalingOptimizer._optimizer.compute_gradients", "isinstance", "scaled_grads_and_vars.append", "tensorflow.IndexedSlices", "isinstance"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.StaticLossScalingOptimizer.compute_gradients"], ["", "def", "compute_gradients", "(", "self", ",", "loss", ",", "var_list", "=", "None", ",", "\n", "gate_gradients", "=", "tf", ".", "train", ".", "Optimizer", ".", "GATE_OP", ",", "\n", "aggregation_method", "=", "None", ",", "\n", "colocate_gradients_with_ops", "=", "False", ",", "\n", "grad_loss", "=", "None", ")", ":", "\n", "        ", "grads_and_vars", "=", "self", ".", "_optimizer", ".", "compute_gradients", "(", "\n", "loss", "*", "self", ".", "_scale", ",", "var_list", ",", "gate_gradients", ",", "\n", "aggregation_method", ",", "colocate_gradients_with_ops", ",", "grad_loss", ")", "\n", "\n", "scaled_grads_and_vars", "=", "[", "]", "\n", "\n", "for", "grad", ",", "var", "in", "grads_and_vars", ":", "\n", "            ", "if", "isinstance", "(", "grad", ",", "tf", ".", "IndexedSlices", ")", ":", "\n", "                ", "grad", "=", "tf", ".", "IndexedSlices", "(", "grad", ".", "values", "/", "self", ".", "_scale", ",", "\n", "grad", ".", "indices", ",", "grad", ".", "dense_shape", ")", "\n", "", "elif", "isinstance", "(", "grad", ",", "tf", ".", "Tensor", ")", ":", "\n", "                ", "grad", "=", "grad", "/", "self", ".", "_scale", "\n", "\n", "", "scaled_grads_and_vars", ".", "append", "(", "(", "grad", ",", "var", ")", ")", "\n", "\n", "", "return", "scaled_grads_and_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.StaticLossScalingOptimizer.apply_gradients": [[43, 46], ["optimizers.StaticLossScalingOptimizer._optimizer.apply_gradients"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.StaticLossScalingOptimizer.apply_gradients"], ["", "def", "apply_gradients", "(", "self", ",", "grads_and_vars", ",", "global_step", "=", "None", ",", "name", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "_optimizer", ".", "apply_gradients", "(", "grads_and_vars", ",", "global_step", ",", "\n", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.get_relevance.to_text": [[25, 34], ["decoded.append"], "function", ["None"], ["def", "to_text", "(", "vocab", ",", "mapping", ",", "indice", ",", "params", ")", ":", "\n", "    ", "decoded", "=", "[", "]", "\n", "for", "idx", "in", "indice", ":", "\n", "        ", "if", "idx", "==", "mapping", "[", "params", ".", "eos", "]", ":", "\n", "            ", "break", "\n", "", "decoded", ".", "append", "(", "vocab", "[", "idx", "]", ")", "\n", "\n", "", "decoded", "=", "\" \"", ".", "join", "(", "decoded", ")", "\n", "return", "decoded", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.get_relevance.parse_args": [[36, 61], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Translate using existing NMT models\"", ",", "\n", "usage", "=", "\"translator.py [<args>] [-h | --help]\"", "\n", ")", "\n", "\n", "# input files", "\n", "parser", ".", "add_argument", "(", "\"--input\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of input file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of output file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--relevances\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of relevance result\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoints\"", ",", "type", "=", "str", ",", "nargs", "=", "\"+\"", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of trained models\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocabulary\"", ",", "type", "=", "str", ",", "nargs", "=", "2", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of source and target vocabulary\"", ")", "\n", "\n", "# model and configuration", "\n", "parser", ".", "add_argument", "(", "\"--models\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"Name of the model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--parameters\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Additional hyper parameters\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.get_relevance.default_parameters": [[63, 90], ["tensorflow.contrib.training.HParams"], "function", ["None"], ["", "def", "default_parameters", "(", ")", ":", "\n", "    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "input", "=", "None", ",", "\n", "output", "=", "None", ",", "\n", "vocabulary", "=", "None", ",", "\n", "model", "=", "None", ",", "\n", "# vocabulary specific", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "bos", "=", "\"<bos>\"", ",", "\n", "eos", "=", "\"<eos>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "mapping", "=", "None", ",", "\n", "append_eos", "=", "False", ",", "\n", "# decoding", "\n", "top_beams", "=", "1", ",", "\n", "beam_size", "=", "4", ",", "\n", "decode_alpha", "=", "0.6", ",", "\n", "decode_beta", "=", "0.2", ",", "\n", "decode_length", "=", "50", ",", "\n", "decode_batch_size", "=", "1", ",", "\n", "decode_constant", "=", "5.0", ",", "\n", "decode_normalize", "=", "False", ",", "\n", "device_list", "=", "[", "0", "]", ",", "\n", "num_threads", "=", "6", "\n", ")", "\n", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.get_relevance.merge_parameters": [[92, 108], ["tensorflow.contrib.training.HParams", "six.iteritems", "tf.contrib.training.HParams.values", "six.iteritems", "params1.values", "tf.contrib.training.HParams.add_hparam", "params2.values", "setattr", "tf.contrib.training.HParams.add_hparam"], "function", ["None"], ["", "def", "merge_parameters", "(", "params1", ",", "params2", ")", ":", "\n", "    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", ")", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "params1", ".", "values", "(", ")", ")", ":", "\n", "        ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "params_dict", "=", "params", ".", "values", "(", ")", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "params2", ".", "values", "(", ")", ")", ":", "\n", "        ", "if", "k", "in", "params_dict", ":", "\n", "# Override", "\n", "            ", "setattr", "(", "params", ",", "k", ",", "v", ")", "\n", "", "else", ":", "\n", "            ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.get_relevance.import_params": [[110, 123], ["os.path.abspath", "os.path.join", "tensorflow.gfile.Exists", "tensorflow.gfile.Open", "tensorflow.logging.info", "fd.readline", "params.parse_json"], "function", ["None"], ["", "def", "import_params", "(", "model_dir", ",", "model_name", ",", "params", ")", ":", "\n", "    ", "model_dir", "=", "os", ".", "path", ".", "abspath", "(", "model_dir", ")", "\n", "m_name", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "model_name", "+", "\".json\"", ")", "\n", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "m_name", ")", ":", "\n", "        ", "return", "params", "\n", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "m_name", ")", "as", "fd", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "\"Restoring model parameters from %s\"", "%", "m_name", ")", "\n", "json_str", "=", "fd", ".", "readline", "(", ")", "\n", "params", ".", "parse_json", "(", "json_str", ")", "\n", "\n", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.get_relevance.override_parameters": [[125, 154], ["thumt.process_vocabulary", "thumt.process_vocabulary", "params.parse", "thumt.load_vocabulary", "thumt.load_vocabulary", "thumt.get_control_mapping", "thumt.get_control_mapping"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.get_control_mapping", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.get_control_mapping"], ["", "def", "override_parameters", "(", "params", ",", "args", ")", ":", "\n", "    ", "if", "args", ".", "parameters", ":", "\n", "        ", "params", ".", "parse", "(", "args", ".", "parameters", ")", "\n", "\n", "", "params", ".", "vocabulary", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "load_vocabulary", "(", "args", ".", "vocabulary", "[", "0", "]", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "load_vocabulary", "(", "args", ".", "vocabulary", "[", "1", "]", ")", "\n", "}", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "params", "\n", ")", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "params", "\n", ")", "\n", "\n", "control_symbols", "=", "[", "params", ".", "pad", ",", "params", ".", "bos", ",", "params", ".", "eos", ",", "params", ".", "unk", "]", "\n", "\n", "params", ".", "mapping", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "\n", "control_symbols", "\n", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "\n", "control_symbols", "\n", ")", "\n", "}", "\n", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.get_relevance.session_config": [[156, 169], ["tensorflow.OptimizerOptions", "tensorflow.GraphOptions", "tensorflow.ConfigProto", "str"], "function", ["None"], ["", "def", "session_config", "(", "params", ")", ":", "\n", "    ", "optimizer_options", "=", "tf", ".", "OptimizerOptions", "(", "opt_level", "=", "tf", ".", "OptimizerOptions", ".", "L1", ",", "\n", "do_function_inlining", "=", "False", ")", "\n", "graph_options", "=", "tf", ".", "GraphOptions", "(", "optimizer_options", "=", "optimizer_options", ")", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ",", "\n", "graph_options", "=", "graph_options", ",", "\n", "intra_op_parallelism_threads", "=", "16", ",", "\n", "inter_op_parallelism_threads", "=", "16", ")", "\n", "if", "params", ".", "device_list", ":", "\n", "        ", "device_str", "=", "\",\"", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "params", ".", "device_list", "]", ")", "\n", "config", ".", "gpu_options", ".", "visible_device_list", "=", "device_str", "\n", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.get_relevance.set_variables": [[171, 185], ["tensorflow.logging.info", "list", "tensorflow.device", "tensorflow.assign", "ops.append", "name.split"], "function", ["None"], ["", "def", "set_variables", "(", "var_list", ",", "value_dict", ",", "prefix", ")", ":", "\n", "    ", "ops", "=", "[", "]", "\n", "for", "var", "in", "var_list", ":", "\n", "        ", "for", "name", "in", "value_dict", ":", "\n", "            ", "var_name", "=", "\"/\"", ".", "join", "(", "[", "prefix", "]", "+", "list", "(", "name", ".", "split", "(", "\"/\"", ")", "[", "1", ":", "]", ")", ")", "\n", "\n", "if", "var", ".", "name", "[", ":", "-", "2", "]", "==", "var_name", ":", "\n", "                ", "tf", ".", "logging", ".", "info", "(", "\"restoring %s -> %s\"", "%", "(", "name", ",", "var", ".", "name", ")", ")", "\n", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "                    ", "op", "=", "tf", ".", "assign", "(", "var", ",", "value_dict", "[", "name", "]", ")", "\n", "ops", ".", "append", "(", "op", ")", "\n", "", "break", "\n", "\n", "", "", "", "return", "ops", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.get_relevance.main": [[187, 295], ["tensorflow.logging.set_verbosity", "thumt.get_model", "get_relevance.default_parameters", "get_relevance.merge_parameters", "get_relevance.import_params", "get_relevance.override_parameters", "tensorflow.Graph().as_default", "enumerate", "range", "thumt.get_relevance_input", "tensorflow.trainable_variables", "range", "tensorflow.group", "params.add_hparam", "params.add_hparam", "tensorflow.train.ChiefSessionCreator", "range", "model_cls.get_parameters", "zip", "range", "range", "print", "tensorflow.train.list_variables", "tensorflow.train.load_checkpoint", "model_var_lists.append", "len", "model_cls_list[].get_name", "model.get_relevance_func", "model_fns.append", "tensorflow.gfile.Open", "tensorflow.gfile.Open", "len", "model_cls_list[].get_name", "get_relevance.set_variables", "assign_ops.extend", "tensorflow.train.MonitoredSession", "sess.run", "len", "len", "len", "tensorflow.Graph", "tf.train.load_checkpoint.get_tensor", "line.strip", "line.strip", "v.name.startswith", "get_relevance.session_config", "os.path.exists", "os.makedirs", "sess.should_stop", "sess.run", "range", "tensorflow.logging.log", "model_cls_list[].get_name.startswith", "model_cls_list[].get_name.find", "un_init_var_list.append", "get_relevance.to_text", "get_relevance.to_text", "open", "open.write", "open.write", "open.write", "model_cls_list[].get_name", "str", "str"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.__init__.get_model", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.default_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.merge_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.import_params", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.override_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_relevance_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_name", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_relevance_func", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_name", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.set_variables", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.session_config", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.get_relevance.to_text", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.get_relevance.to_text", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_name"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "# Load configs", "\n", "model_cls_list", "=", "[", "models", ".", "get_model", "(", "model", ",", "lrp", "=", "True", ")", "\n", "for", "model", "in", "args", ".", "models", "]", "\n", "params_list", "=", "[", "default_parameters", "(", ")", "for", "_", "in", "range", "(", "len", "(", "model_cls_list", ")", ")", "]", "\n", "params_list", "=", "[", "\n", "merge_parameters", "(", "params", ",", "model_cls", ".", "get_parameters", "(", ")", ")", "\n", "for", "params", ",", "model_cls", "in", "zip", "(", "params_list", ",", "model_cls_list", ")", "\n", "]", "\n", "params_list", "=", "[", "\n", "import_params", "(", "args", ".", "checkpoints", "[", "i", "]", ",", "args", ".", "models", "[", "i", "]", ",", "params_list", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "args", ".", "checkpoints", ")", ")", "\n", "]", "\n", "params_list", "=", "[", "\n", "override_parameters", "(", "params_list", "[", "i", "]", ",", "args", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "model_cls_list", ")", ")", "\n", "]", "\n", "\n", "# Build Graph", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "model_var_lists", "=", "[", "]", "\n", "\n", "# Load checkpoints", "\n", "for", "i", ",", "checkpoint", "in", "enumerate", "(", "args", ".", "checkpoints", ")", ":", "\n", "            ", "print", "(", "\"Loading %s\"", "%", "checkpoint", ")", "\n", "var_list", "=", "tf", ".", "train", ".", "list_variables", "(", "checkpoint", ")", "\n", "values", "=", "{", "}", "\n", "reader", "=", "tf", ".", "train", ".", "load_checkpoint", "(", "checkpoint", ")", "\n", "\n", "for", "(", "name", ",", "shape", ")", "in", "var_list", ":", "\n", "                ", "if", "not", "name", ".", "startswith", "(", "model_cls_list", "[", "i", "]", ".", "get_name", "(", ")", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "name", ".", "find", "(", "\"losses_avg\"", ")", ">=", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "tensor", "=", "reader", ".", "get_tensor", "(", "name", ")", "\n", "values", "[", "name", "]", "=", "tensor", "\n", "\n", "", "model_var_lists", ".", "append", "(", "values", ")", "\n", "\n", "# Build models", "\n", "", "model_fns", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "args", ".", "checkpoints", ")", ")", ":", "\n", "            ", "name", "=", "model_cls_list", "[", "i", "]", ".", "get_name", "(", ")", "\n", "model", "=", "model_cls_list", "[", "i", "]", "(", "params_list", "[", "i", "]", ",", "name", "+", "\"_%d\"", "%", "i", ")", "\n", "model_fn", "=", "model", ".", "get_relevance_func", "(", ")", "\n", "model_fns", ".", "append", "(", "model_fn", ")", "\n", "\n", "", "params", "=", "params_list", "[", "0", "]", "\n", "# Read input file", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "args", ".", "input", ")", "as", "fd", ":", "\n", "            ", "inputs", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fd", "]", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "args", ".", "output", ")", "as", "fd", ":", "\n", "            ", "outputs", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fd", "]", "\n", "# Build input queue", "\n", "", "features", "=", "dataset", ".", "get_relevance_input", "(", "inputs", ",", "outputs", ",", "params", ")", "\n", "relevances", "=", "model_fns", "[", "0", "]", "(", "features", ",", "params", ")", "\n", "\n", "assign_ops", "=", "[", "]", "\n", "\n", "all_var_list", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "args", ".", "checkpoints", ")", ")", ":", "\n", "            ", "un_init_var_list", "=", "[", "]", "\n", "name", "=", "model_cls_list", "[", "i", "]", ".", "get_name", "(", ")", "\n", "\n", "for", "v", "in", "all_var_list", ":", "\n", "                ", "if", "v", ".", "name", ".", "startswith", "(", "name", "+", "\"_%d\"", "%", "i", ")", ":", "\n", "                    ", "un_init_var_list", ".", "append", "(", "v", ")", "\n", "\n", "", "", "ops", "=", "set_variables", "(", "un_init_var_list", ",", "model_var_lists", "[", "i", "]", ",", "\n", "name", "+", "\"_%d\"", "%", "i", ")", "\n", "assign_ops", ".", "extend", "(", "ops", ")", "\n", "\n", "", "assign_op", "=", "tf", ".", "group", "(", "*", "assign_ops", ")", "\n", "\n", "params", ".", "add_hparam", "(", "\"intra_op_parallelism_threads\"", ",", "1", ")", "\n", "params", ".", "add_hparam", "(", "\"inter_op_parallelism_threads\"", ",", "1", ")", "\n", "sess_creator", "=", "tf", ".", "train", ".", "ChiefSessionCreator", "(", "\n", "config", "=", "session_config", "(", "params", ")", "\n", ")", "\n", "\n", "results", "=", "[", "]", "\n", "\n", "# Create session", "\n", "with", "tf", ".", "train", ".", "MonitoredSession", "(", "session_creator", "=", "sess_creator", ")", "as", "sess", ":", "\n", "# Restore variables", "\n", "            ", "sess", ".", "run", "(", "assign_op", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "relevances", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "args", ".", "relevances", ")", "\n", "", "count", "=", "0", "\n", "while", "not", "sess", ".", "should_stop", "(", ")", ":", "\n", "                ", "src_seq", ",", "trg_seq", ",", "rlv_info", ",", "loss", "=", "sess", ".", "run", "(", "relevances", ")", "\n", "message", "=", "\"Finished batch\"", "\" %d\"", "%", "count", "\n", "for", "i", "in", "range", "(", "src_seq", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "count", "+=", "1", "\n", "src", "=", "to_text", "(", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "\n", "params", ".", "mapping", "[", "\"source\"", "]", ",", "src_seq", "[", "i", "]", ",", "params", ")", "\n", "trg", "=", "to_text", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "\n", "params", ".", "mapping", "[", "\"target\"", "]", ",", "trg_seq", "[", "i", "]", ",", "params", ")", "\n", "output", "=", "open", "(", "args", ".", "relevances", "+", "\"/\"", "+", "str", "(", "count", ")", ",", "\"w\"", ")", "\n", "output", ".", "write", "(", "\"src: \"", "+", "src", "+", "\"\\n\"", ")", "\n", "output", ".", "write", "(", "\"trg: \"", "+", "trg", "+", "\"\\n\"", ")", "\n", "output", ".", "write", "(", "\"result: %s\\n\"", "%", "str", "(", "rlv_info", "[", "\"result\"", "]", "[", "i", "]", ")", ")", "\n", "", "tf", ".", "logging", ".", "log", "(", "tf", ".", "logging", ".", "INFO", ",", "message", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator.parse_args": [[25, 50], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Translate using existing NMT models\"", ",", "\n", "usage", "=", "\"translator.py [<args>] [-h | --help]\"", "\n", ")", "\n", "\n", "# input files", "\n", "parser", ".", "add_argument", "(", "\"--input\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of input file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of output file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoints\"", ",", "type", "=", "str", ",", "nargs", "=", "\"+\"", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of trained models\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocabulary\"", ",", "type", "=", "str", ",", "nargs", "=", "3", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of source and target vocabulary\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dev_dialog_src_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_dialog_tgt_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_style_src_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_style_tgt_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dev_sample\"", ",", "type", "=", "str", ",", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator.default_parameters": [[52, 83], ["tensorflow.contrib.training.HParams"], "function", ["None"], ["\n", "parser", ".", "add_argument", "(", "\"--dev_context_source\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of sample corpus\"", ")", "\n", "\n", "# model and configuration", "\n", "parser", ".", "add_argument", "(", "\"--models\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"Name of the model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--parameters\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Additional hyper parameters\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--verbose\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Enable verbose output\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n", "\n", "", "def", "default_parameters", "(", ")", ":", "\n", "    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "input", "=", "None", ",", "\n", "output", "=", "None", ",", "\n", "vocabulary", "=", "None", ",", "\n", "# vocabulary specific", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "bos", "=", "\"<bos>\"", ",", "\n", "eos", "=", "\"<eos>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "mapping", "=", "None", ",", "\n", "append_eos", "=", "False", ",", "\n", "device_list", "=", "[", "0", "]", ",", "\n", "num_threads", "=", "1", ",", "\n", "# decoding", "\n", "top_beams", "=", "1", ",", "\n", "beam_size", "=", "4", ",", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator.merge_parameters": [[85, 101], ["tensorflow.contrib.training.HParams", "six.iteritems", "tf.contrib.training.HParams.values", "six.iteritems", "params1.values", "tf.contrib.training.HParams.add_hparam", "params2.values", "setattr", "tf.contrib.training.HParams.add_hparam"], "function", ["None"], ["decode_length", "=", "50", ",", "\n", "start_steps", "=", "0", ",", "\n", "kl_annealing_steps", "=", "10000", ",", "\n", "decode_batch_size", "=", "32", ",", "\n", "# sampling", "\n", "generate_samples", "=", "False", ",", "\n", "num_samples", "=", "1", ",", "\n", "min_length_ratio", "=", "0.0", ",", "\n", "max_length_ratio", "=", "1.5", ",", "\n", "min_sample_length", "=", "0", ",", "\n", "max_sample_length", "=", "0", ",", "\n", "sample_batch_size", "=", "32", "\n", ")", "\n", "\n", "return", "params", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator.import_params": [[103, 119], ["model_name.startswith", "os.path.abspath", "os.path.join", "tensorflow.gfile.Exists", "tensorflow.gfile.Open", "tensorflow.logging.info", "fd.readline", "params.parse_json"], "function", ["None"], ["    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", ")", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "params1", ".", "values", "(", ")", ")", ":", "\n", "        ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "params_dict", "=", "params", ".", "values", "(", ")", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "params2", ".", "values", "(", ")", ")", ":", "\n", "        ", "if", "k", "in", "params_dict", ":", "\n", "# Override", "\n", "            ", "setattr", "(", "params", ",", "k", ",", "v", ")", "\n", "", "else", ":", "\n", "            ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "", "return", "params", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator.override_parameters": [[121, 150], ["thumt.process_vocabulary", "thumt.process_vocabulary", "params.parse", "thumt.load_vocabulary", "thumt.load_vocabulary", "thumt.get_control_mapping", "thumt.get_control_mapping"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.get_control_mapping", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.get_control_mapping"], ["    ", "if", "model_name", ".", "startswith", "(", "\"experimental_\"", ")", ":", "\n", "        ", "model_name", "=", "model_name", "[", "13", ":", "]", "\n", "\n", "", "model_dir", "=", "os", ".", "path", ".", "abspath", "(", "model_dir", ")", "\n", "m_name", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "model_name", "+", "\".json\"", ")", "\n", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "m_name", ")", ":", "\n", "        ", "return", "params", "\n", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "m_name", ")", "as", "fd", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "\"Restoring model parameters from %s\"", "%", "m_name", ")", "\n", "json_str", "=", "fd", ".", "readline", "(", ")", "\n", "params", ".", "parse_json", "(", "json_str", ")", "\n", "\n", "", "return", "params", "\n", "\n", "\n", "", "def", "override_parameters", "(", "params", ",", "args", ")", ":", "\n", "    ", "if", "args", ".", "parameters", ":", "\n", "        ", "params", ".", "parse", "(", "args", ".", "parameters", ")", "\n", "\n", "\n", "", "params", ".", "dev_context_source", "=", "args", ".", "dev_context_source", "\n", "\n", "params", ".", "dev_dialog_src_context", "=", "args", ".", "dev_dialog_src_context", "#or params.dev_dialog_src_context", "\n", "params", ".", "dev_dialog_tgt_context", "=", "args", ".", "dev_dialog_tgt_context", "#or params.dev_dialog_tgt_context", "\n", "params", ".", "dev_style_src_context", "=", "args", ".", "dev_style_src_context", "\n", "params", ".", "dev_style_tgt_context", "=", "args", ".", "dev_style_tgt_context", "\n", "\n", "params", ".", "dev_sample", "=", "args", ".", "dev_sample", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator.session_config": [[152, 163], ["tensorflow.OptimizerOptions", "tensorflow.GraphOptions", "tensorflow.ConfigProto", "str"], "function", ["None"], ["params", ".", "vocabulary", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "load_vocabulary", "(", "args", ".", "vocabulary", "[", "0", "]", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "load_vocabulary", "(", "args", ".", "vocabulary", "[", "1", "]", ")", ",", "\n", "\"position\"", ":", "vocabulary", ".", "load_vocabulary", "(", "args", ".", "vocabulary", "[", "2", "]", ")", "\n", "}", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "params", "\n", ")", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "params", "\n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator.set_variables": [[165, 182], ["tensorflow.logging.debug", "tensorflow.placeholder", "list", "tensorflow.device", "tensorflow.assign", "ops.append", "name.split"], "function", ["None"], ["\n", "params", ".", "mapping", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "\n", "control_symbols", "\n", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "\n", "control_symbols", "\n", ")", "\n", "}", "\n", "\n", "return", "params", "\n", "\n", "\n", "", "def", "session_config", "(", "params", ")", ":", "\n", "    ", "optimizer_options", "=", "tf", ".", "OptimizerOptions", "(", "opt_level", "=", "tf", ".", "OptimizerOptions", ".", "L1", ",", "\n", "do_function_inlining", "=", "False", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator.get_turn_position_eos": [[211, 254], ["open", "fr.readlines", "turn_position.append", "mask.append", "file1.split", "os.path.exists", "os.path.exists", "open", "open", "line.strip", "lines.strip().split", "tmp.append", "mask_tmp.append", "len", "len", "print", "file1.split", "os.path.getsize", "os.path.getsize", "sorted", "fw.write", "sorted", "fw.write", "str", "str", "lines.strip().split", "lines.strip", "lines.strip"], "function", ["None"], ["", "def", "get_turn_position_eos", "(", "file1", ")", ":", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "content", "=", "fr", ".", "readlines", "(", ")", "\n", "", "turn_position", "=", "[", "]", "\n", "mask", "=", "[", "]", "\n", "for", "line", "in", "content", ":", "\n", "        ", "tmp", "=", "[", "]", "\n", "mask_tmp", "=", "[", "]", "\n", "index", "=", "0", "\n", "lines", "=", "line", ".", "strip", "(", ")", "+", "\" <eos>\"", "\n", "flag", "=", "0", "\n", "for", "i", "in", "lines", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "#tmp.append(str(index))", "\n", "#            flag = 0", "\n", "            ", "if", "i", "==", "'[SEP]'", ":", "\n", "                ", "index", "+=", "1", "\n", "flag", "=", "1", "\n", "", "tmp", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "mask_tmp", ".", "append", "(", "str", "(", "flag", ")", ")", "\n", "#        if len(lines.split()) != len(tmp):", "\n", "", "if", "len", "(", "lines", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", ")", "!=", "len", "(", "tmp", ")", ":", "\n", "            ", "print", "(", "line", ")", "\n", "", "turn_position", ".", "append", "(", "tmp", ")", "\n", "mask", ".", "append", "(", "mask_tmp", ")", "\n", "\n", "", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.turn_position'", "\n", "mask_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.mask'", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "position_file", ")", "and", "os", ".", "path", ".", "exists", "(", "mask_file", ")", "and", "not", "os", ".", "path", ".", "getsize", "(", "position_file", ")", "and", "not", "os", ".", "path", ".", "getsize", "(", "mask_file", ")", ":", "\n", "        ", "return", "position_file", ",", "mask_file", "\n", "\n", "", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "", "", "with", "open", "(", "mask_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_mask", "in", "mask", ":", "\n", "            ", "line_mask", "=", "sorted", "(", "line_mask", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_mask", ")", "+", "'\\n'", ")", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", ",", "mask_file", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator.shard_features": [[184, 207], ["len", "isinstance", "range"], "function", ["None"], ["config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ",", "\n", "graph_options", "=", "graph_options", ")", "\n", "if", "params", ".", "device_list", ":", "\n", "        ", "device_str", "=", "\",\"", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "params", ".", "device_list", "]", ")", "\n", "config", ".", "gpu_options", ".", "visible_device_list", "=", "device_str", "\n", "\n", "", "return", "config", "\n", "\n", "\n", "", "def", "set_variables", "(", "var_list", ",", "value_dict", ",", "prefix", ",", "feed_dict", ")", ":", "\n", "    ", "ops", "=", "[", "]", "\n", "for", "var", "in", "var_list", ":", "\n", "        ", "for", "name", "in", "value_dict", ":", "\n", "            ", "var_name", "=", "\"/\"", ".", "join", "(", "[", "prefix", "]", "+", "list", "(", "name", ".", "split", "(", "\"/\"", ")", "[", "1", ":", "]", ")", ")", "\n", "\n", "if", "var", ".", "name", "[", ":", "-", "2", "]", "==", "var_name", ":", "\n", "                ", "tf", ".", "logging", ".", "debug", "(", "\"restoring %s -> %s\"", "%", "(", "name", ",", "var", ".", "name", ")", ")", "\n", "placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "\n", "name", "=", "\"placeholder/\"", "+", "var_name", ")", "\n", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "                    ", "op", "=", "tf", ".", "assign", "(", "var", ",", "placeholder", ")", "\n", "ops", ".", "append", "(", "op", ")", "\n", "", "feed_dict", "[", "placeholder", "]", "=", "value_dict", "[", "name", "]", "\n", "break", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator.get_turn_position": [[236, 260], ["open", "fr.readlines", "turn_position.append", "file1.split", "open", "line.split", "tmp.append", "file1.split", "sorted", "fw.write", "str"], "function", ["None"], ["", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.turn_position'", "\n", "mask_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.mask'", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "position_file", ")", "and", "os", ".", "path", ".", "exists", "(", "mask_file", ")", "and", "not", "os", ".", "path", ".", "getsize", "(", "position_file", ")", "and", "not", "os", ".", "path", ".", "getsize", "(", "mask_file", ")", ":", "\n", "        ", "return", "position_file", ",", "mask_file", "\n", "\n", "", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "", "", "with", "open", "(", "mask_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_mask", "in", "mask", ":", "\n", "            ", "line_mask", "=", "sorted", "(", "line_mask", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_mask", ")", "+", "'\\n'", ")", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", ",", "mask_file", "\n", "\n", "", "def", "shard_features", "(", "features", ",", "placeholders", ",", "predictions", ")", ":", "\n", "    ", "num_shards", "=", "len", "(", "placeholders", ")", "\n", "feed_dict", "=", "{", "}", "\n", "n", "=", "0", "\n", "\n", "for", "name", "in", "features", ":", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator.main": [[209, 375], ["tensorflow.logging.set_verbosity", "thumt.get_model", "translator.default_parameters", "translator.merge_parameters", "translator.import_params", "translator.override_parameters", "tensorflow.Graph().as_default", "enumerate", "range", "thumt.sort_input_file", "thumt.get_inference_input", "range", "thumt.data_parallelism", "tensorflow.trainable_variables", "range", "tensorflow.group", "tensorflow.tables_initializer", "tensorflow.get_default_graph().finalize", "range", "zip", "open.close", "range", "model_cls.get_parameters", "zip", "range", "range", "tensorflow.logging.info", "tensorflow.train.list_variables", "tensorflow.train.load_checkpoint", "model_var_lists.append", "len", "model_cls_list[].get_name", "model_list.append", "len", "placeholders.append", "len", "model_cls_list[].get_name", "translator.set_variables", "assign_ops.extend", "tensorflow.Session", "sess.run", "sess.run", "len", "restored_inputs.append", "restored_outputs.append", "restored_scores.append", "open", "zip", "len", "len", "len", "tensorflow.Graph", "tf.train.load_checkpoint.get_tensor", "inference_fn", "v.name.startswith", "tensorflow.get_default_graph", "open", "ValueError", "model_cls_list[].get_name.startswith", "model_cls_list[].get_name.find", "tensorflow.placeholder", "tensorflow.placeholder", "un_init_var_list.append", "translator.session_config", "sess.run", "translator.shard_features", "results.append", "tensorflow.logging.log", "outputs.append", "scores.append", "decoded.append", "open.write", "open.write", "model_cls_list[].get_name", "sess.run", "len", "item.tolist", "item.tolist"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.__init__.get_model", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.default_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.merge_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.import_params", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.override_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.sort_input_file", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo.data_parallelism", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_name", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_name", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.set_variables", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.session_config", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_bak.shard_features", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_name"], ["", "", "", "return", "ops", "\n", "\n", "", "def", "get_turn_position_eos", "(", "file1", ")", ":", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "content", "=", "fr", ".", "readlines", "(", ")", "\n", "", "turn_position", "=", "[", "]", "\n", "mask", "=", "[", "]", "\n", "for", "line", "in", "content", ":", "\n", "        ", "tmp", "=", "[", "]", "\n", "mask_tmp", "=", "[", "]", "\n", "index", "=", "0", "\n", "lines", "=", "line", ".", "strip", "(", ")", "+", "\" <eos>\"", "\n", "flag", "=", "0", "\n", "for", "i", "in", "lines", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "#tmp.append(str(index))", "\n", "#            flag = 0", "\n", "            ", "if", "i", "==", "'[SEP]'", ":", "\n", "                ", "index", "+=", "1", "\n", "flag", "=", "1", "\n", "", "tmp", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "mask_tmp", ".", "append", "(", "str", "(", "flag", ")", ")", "\n", "#        if len(lines.split()) != len(tmp):", "\n", "", "if", "len", "(", "lines", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", ")", "!=", "len", "(", "tmp", ")", ":", "\n", "            ", "print", "(", "line", ")", "\n", "", "turn_position", ".", "append", "(", "tmp", ")", "\n", "mask", ".", "append", "(", "mask_tmp", ")", "\n", "\n", "", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.turn_position'", "\n", "mask_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.mask'", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "position_file", ")", "and", "os", ".", "path", ".", "exists", "(", "mask_file", ")", "and", "not", "os", ".", "path", ".", "getsize", "(", "position_file", ")", "and", "not", "os", ".", "path", ".", "getsize", "(", "mask_file", ")", ":", "\n", "        ", "return", "position_file", ",", "mask_file", "\n", "\n", "", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "", "", "with", "open", "(", "mask_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_mask", "in", "mask", ":", "\n", "            ", "line_mask", "=", "sorted", "(", "line_mask", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_mask", ")", "+", "'\\n'", ")", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", ",", "mask_file", "\n", "\n", "", "def", "shard_features", "(", "features", ",", "placeholders", ",", "predictions", ")", ":", "\n", "    ", "num_shards", "=", "len", "(", "placeholders", ")", "\n", "feed_dict", "=", "{", "}", "\n", "n", "=", "0", "\n", "\n", "for", "name", "in", "features", ":", "\n", "        ", "feat", "=", "features", "[", "name", "]", "\n", "batch", "=", "feat", ".", "shape", "[", "0", "]", "\n", "shard_size", "=", "(", "batch", "+", "num_shards", "-", "1", ")", "//", "num_shards", "\n", "\n", "for", "i", "in", "range", "(", "num_shards", ")", ":", "\n", "            ", "shard_feat", "=", "feat", "[", "i", "*", "shard_size", ":", "(", "i", "+", "1", ")", "*", "shard_size", "]", "\n", "\n", "if", "shard_feat", ".", "shape", "[", "0", "]", "!=", "0", ":", "\n", "                ", "feed_dict", "[", "placeholders", "[", "i", "]", "[", "name", "]", "]", "=", "shard_feat", "\n", "n", "=", "i", "+", "1", "\n", "", "else", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "if", "isinstance", "(", "predictions", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "predictions", "=", "predictions", "[", ":", "n", "]", "\n", "\n", "", "return", "predictions", ",", "feed_dict", "\n", "", "def", "get_turn_position", "(", "file1", ")", ":", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "content", "=", "fr", ".", "readlines", "(", ")", "\n", "", "turn_position", "=", "[", "]", "\n", "for", "line", "in", "content", ":", "\n", "        ", "tmp", "=", "[", "]", "\n", "index", "=", "0", "\n", "for", "i", "in", "line", ".", "split", "(", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "#tmp.append(str(index))", "\n", "            ", "if", "i", "==", "'[SEP]'", ":", "\n", "                ", "index", "+=", "1", "\n", "", "tmp", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "", "turn_position", ".", "append", "(", "tmp", ")", "\n", "", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.turn_position'", "\n", "if", "os", ".", "path", ".", "exists", "(", "position_file", ")", "and", "not", "os", ".", "path", ".", "getsize", "(", "position_file", ")", ":", "\n", "        ", "return", "position_file", "\n", "", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", "\n", "\n", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "# Load configs", "\n", "model_cls_list", "=", "[", "models", ".", "get_model", "(", "model", ")", "for", "model", "in", "args", ".", "models", "]", "\n", "params_list", "=", "[", "default_parameters", "(", ")", "for", "_", "in", "range", "(", "len", "(", "model_cls_list", ")", ")", "]", "\n", "params_list", "=", "[", "\n", "merge_parameters", "(", "params", ",", "model_cls", ".", "get_parameters", "(", ")", ")", "\n", "for", "params", ",", "model_cls", "in", "zip", "(", "params_list", ",", "model_cls_list", ")", "\n", "]", "\n", "params_list", "=", "[", "\n", "import_params", "(", "args", ".", "checkpoints", "[", "i", "]", ",", "args", ".", "models", "[", "i", "]", ",", "params_list", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "args", ".", "checkpoints", ")", ")", "\n", "]", "\n", "params_list", "=", "[", "\n", "override_parameters", "(", "params_list", "[", "i", "]", ",", "args", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "model_cls_list", ")", ")", "\n", "]", "\n", "\n", "# Build Graph", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "model_var_lists", "=", "[", "]", "\n", "\n", "# Load checkpoints", "\n", "for", "i", ",", "checkpoint", "in", "enumerate", "(", "args", ".", "checkpoints", ")", ":", "\n", "            ", "tf", ".", "logging", ".", "info", "(", "\"Loading %s\"", "%", "checkpoint", ")", "\n", "var_list", "=", "tf", ".", "train", ".", "list_variables", "(", "checkpoint", ")", "\n", "values", "=", "{", "}", "\n", "reader", "=", "tf", ".", "train", ".", "load_checkpoint", "(", "checkpoint", ")", "\n", "\n", "for", "(", "name", ",", "shape", ")", "in", "var_list", ":", "\n", "                ", "if", "not", "name", ".", "startswith", "(", "model_cls_list", "[", "i", "]", ".", "get_name", "(", ")", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "name", ".", "find", "(", "\"losses_avg\"", ")", ">=", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "tensor", "=", "reader", ".", "get_tensor", "(", "name", ")", "\n", "values", "[", "name", "]", "=", "tensor", "\n", "\n", "", "model_var_lists", ".", "append", "(", "values", ")", "\n", "\n", "# Build models", "\n", "", "model_list", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "args", ".", "checkpoints", ")", ")", ":", "\n", "            ", "name", "=", "model_cls_list", "[", "i", "]", ".", "get_name", "(", ")", "\n", "model", "=", "model_cls_list", "[", "i", "]", "(", "params_list", "[", "i", "]", ",", "name", "+", "\"_%d\"", "%", "i", ")", "\n", "model_list", ".", "append", "(", "model", ")", "\n", "\n", "", "params", "=", "params_list", "[", "0", "]", "\n", "# Read input file", "\n", "# Build input queue", "\n", "#        features = dataset.get_inference_input(sorted_inputs, params)", "\n", "position_file_src_dia", "=", "get_turn_position", "(", "params", ".", "dev_dialog_src_context", ")", "\n", "#            position_file_src_dia, dialog_file = get_turn_position_src(params.validation, params.dialog_src_context)", "\n", "position_file_tgt_dia", "=", "get_turn_position", "(", "params", ".", "dev_dialog_tgt_context", ")", "\n", "#            position_file_ctx_src, mask_file = get_turn_position_eos(params.dev_context_source)", "\n", "position_file_src_sty", "=", "get_turn_position", "(", "params", ".", "dev_style_src_context", ")", "\n", "position_file_tgt_sty", "=", "get_turn_position", "(", "params", ".", "dev_style_tgt_context", ")", "\n", "position_file_ctx_src", "=", "get_turn_position", "(", "params", ".", "dev_context_source", ")", "\n", "\n", "sorted_keys", ",", "sorted_inputs", ",", "dialog_src_context", ",", "pos_src_dia", ",", "dialog_tgt_context", ",", "pos_tgt_dia", ",", "dialog_context_source", ",", "pos_ctx_src", ",", "style_src_context", ",", "pos_src_sty", ",", "style_tgt_context", ",", "pos_tgt_sty", "=", "dataset", ".", "sort_input_file_ctx", "(", "args", ".", "input", ",", "params", ".", "dev_dialog_src_context", ",", "position_file_src_dia", ",", "params", ".", "dev_dialog_tgt_context", ",", "position_file_tgt_dia", ",", "params", ".", "dev_context_source", ",", "position_file_ctx_src", ",", "params", ".", "dev_style_src_context", ",", "position_file_src_sty", ",", "params", ".", "dev_style_tgt_context", ",", "position_file_tgt_sty", ")", "\n", "# Build input queue", "\n", "features", "=", "dataset", ".", "get_inference_input", "(", "sorted_inputs", ",", "\"x\"", ",", "params", ")", "\n", "#        features_ctx = dataset.get_inference_input(sorted_ctxs, params)", "\n", "\n", "features_ctx1", "=", "dataset", ".", "get_inference_input", "(", "dialog_src_context", ",", "\"ctx\"", ",", "params", ")", "\n", "features_ctx2", "=", "dataset", ".", "get_inference_input", "(", "pos_src_dia", ",", "\"pos\"", ",", "params", ")", "\n", "features_ctx3", "=", "dataset", ".", "get_inference_input", "(", "dialog_tgt_context", ",", "\"ctx\"", ",", "params", ")", "\n", "features_ctx4", "=", "dataset", ".", "get_inference_input", "(", "pos_tgt_dia", ",", "\"pos\"", ",", "params", ")", "\n", "features_ctxs1", "=", "dataset", ".", "get_inference_input", "(", "style_src_context", ",", "\"ctx\"", ",", "params", ")", "\n", "features_ctxs2", "=", "dataset", ".", "get_inference_input", "(", "pos_src_sty", ",", "\"pos\"", ",", "params", ")", "\n", "features_ctxs3", "=", "dataset", ".", "get_inference_input", "(", "style_tgt_context", ",", "\"ctx\"", ",", "params", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer_ctx.parse_args": [[27, 62], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["def", "parse_args", "(", "args", "=", "None", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Training neural machine translation models\"", ",", "\n", "usage", "=", "\"trainer.py [<args>] [-h | --help]\"", "\n", ")", "\n", "\n", "# input files", "\n", "parser", ".", "add_argument", "(", "\"--input\"", ",", "type", "=", "str", ",", "nargs", "=", "2", ",", "\n", "help", "=", "\"Path of source and target corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--record\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to tf.Record data\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "default", "=", "\"train\"", ",", "\n", "help", "=", "\"Path to saved models\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocabulary\"", ",", "type", "=", "str", ",", "nargs", "=", "2", ",", "\n", "help", "=", "\"Path of source and target vocabulary\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--validation\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of validation file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--references\"", ",", "type", "=", "str", ",", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"Path of reference files\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to pre-trained checkpoint\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--half\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Enable FP16 training\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--distribute\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Enable distributed training\"", ")", "\n", "\n", "# model and configuration", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Name of the model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--parameters\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Additional hyper parameters\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer_ctx.default_parameters": [[64, 119], ["tensorflow.contrib.training.HParams"], "function", ["None"], ["", "def", "default_parameters", "(", ")", ":", "\n", "    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "input", "=", "[", "\"\"", ",", "\"\"", "]", ",", "\n", "output", "=", "\"\"", ",", "\n", "context", "=", "\"\"", ",", "\n", "record", "=", "\"\"", ",", "\n", "model", "=", "\"transformer\"", ",", "\n", "vocab", "=", "[", "\"\"", ",", "\"\"", "]", ",", "\n", "# Default training hyper parameters", "\n", "latent_dim", "=", "64", ",", "\n", "num_threads", "=", "6", ",", "\n", "batch_size", "=", "4096", ",", "\n", "max_length", "=", "256", ",", "\n", "length_multiplier", "=", "1", ",", "\n", "mantissa_bits", "=", "2", ",", "\n", "warmup_steps", "=", "4000", ",", "\n", "train_steps", "=", "200000", ",", "\n", "buffer_size", "=", "10000", ",", "\n", "constant_batch_size", "=", "False", ",", "\n", "device_list", "=", "[", "0", "]", ",", "\n", "update_cycle", "=", "1", ",", "\n", "initializer", "=", "\"uniform_unit_scaling\"", ",", "\n", "initializer_gain", "=", "1.0", ",", "\n", "loss_scale", "=", "128", ",", "\n", "scale_l1", "=", "0.0", ",", "\n", "scale_l2", "=", "0.0", ",", "\n", "optimizer", "=", "\"Adam\"", ",", "\n", "adam_beta1", "=", "0.9", ",", "\n", "adam_beta2", "=", "0.999", ",", "\n", "adam_epsilon", "=", "1e-8", ",", "\n", "clip_grad_norm", "=", "5.0", ",", "\n", "learning_rate", "=", "1.0", ",", "\n", "learning_rate_decay", "=", "\"linear_warmup_rsqrt_decay\"", ",", "\n", "learning_rate_boundaries", "=", "[", "0", "]", ",", "\n", "learning_rate_values", "=", "[", "0.0", "]", ",", "\n", "keep_checkpoint_max", "=", "1", ",", "\n", "keep_top_checkpoint_max", "=", "5", ",", "\n", "# Validation", "\n", "eval_steps", "=", "2000", ",", "\n", "eval_secs", "=", "0", ",", "\n", "eval_batch_size", "=", "32", ",", "\n", "top_beams", "=", "1", ",", "\n", "beam_size", "=", "4", ",", "\n", "decode_alpha", "=", "0.6", ",", "\n", "decode_length", "=", "50", ",", "\n", "validation", "=", "\"\"", ",", "\n", "references", "=", "[", "\"\"", "]", ",", "\n", "save_checkpoint_secs", "=", "0", ",", "\n", "save_checkpoint_steps", "=", "1000", ",", "\n", "# Setting this to True can save disk spaces, but cannot restore", "\n", "# training using the saved checkpoint", "\n", "only_save_trainable", "=", "False", "\n", ")", "\n", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer_ctx.import_params": [[121, 140], ["os.path.abspath", "os.path.join", "os.path.join", "tensorflow.gfile.Open", "tensorflow.logging.info", "fd.readline", "params.parse_json", "tensorflow.gfile.Open", "tensorflow.logging.info", "fd.readline", "params.parse_json", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists"], "function", ["None"], ["", "def", "import_params", "(", "model_dir", ",", "model_name", ",", "params", ")", ":", "\n", "    ", "model_dir", "=", "os", ".", "path", ".", "abspath", "(", "model_dir", ")", "\n", "p_name", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"params.json\"", ")", "\n", "m_name", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "model_name", "+", "\".json\"", ")", "\n", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "p_name", ")", "or", "not", "tf", ".", "gfile", ".", "Exists", "(", "m_name", ")", ":", "\n", "        ", "return", "params", "\n", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "p_name", ")", "as", "fd", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "\"Restoring hyper parameters from %s\"", "%", "p_name", ")", "\n", "json_str", "=", "fd", ".", "readline", "(", ")", "\n", "params", ".", "parse_json", "(", "json_str", ")", "\n", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "m_name", ")", "as", "fd", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "\"Restoring model parameters from %s\"", "%", "m_name", ")", "\n", "json_str", "=", "fd", ".", "readline", "(", ")", "\n", "params", ".", "parse_json", "(", "json_str", ")", "\n", "\n", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer_ctx.export_params": [[142, 150], ["os.path.join", "tensorflow.gfile.Exists", "tensorflow.gfile.MkDir", "tensorflow.gfile.Open", "fd.write", "params.to_json"], "function", ["None"], ["", "def", "export_params", "(", "output_dir", ",", "name", ",", "params", ")", ":", "\n", "    ", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "output_dir", ")", ":", "\n", "        ", "tf", ".", "gfile", ".", "MkDir", "(", "output_dir", ")", "\n", "\n", "# Save params as params.json", "\n", "", "filename", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "name", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "filename", ",", "\"w\"", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "params", ".", "to_json", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer_ctx.collect_params": [[152, 159], ["tensorflow.contrib.training.HParams", "six.iterkeys", "params.values", "tf.contrib.training.HParams.add_hparam", "getattr"], "function", ["None"], ["", "", "def", "collect_params", "(", "all_params", ",", "params", ")", ":", "\n", "    ", "collected", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", ")", "\n", "\n", "for", "k", "in", "six", ".", "iterkeys", "(", "params", ".", "values", "(", ")", ")", ":", "\n", "        ", "collected", ".", "add_hparam", "(", "k", ",", "getattr", "(", "all_params", ",", "k", ")", ")", "\n", "\n", "", "return", "collected", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer_ctx.merge_parameters": [[161, 177], ["tensorflow.contrib.training.HParams", "six.iteritems", "tf.contrib.training.HParams.values", "six.iteritems", "params1.values", "tf.contrib.training.HParams.add_hparam", "params2.values", "setattr", "tf.contrib.training.HParams.add_hparam"], "function", ["None"], ["", "def", "merge_parameters", "(", "params1", ",", "params2", ")", ":", "\n", "    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", ")", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "params1", ".", "values", "(", ")", ")", ":", "\n", "        ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "params_dict", "=", "params", ".", "values", "(", ")", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "params2", ".", "values", "(", ")", ")", ":", "\n", "        ", "if", "k", "in", "params_dict", ":", "\n", "# Override", "\n", "            ", "setattr", "(", "params", ",", "k", ",", "v", ")", "\n", "", "else", ":", "\n", "            ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer_ctx.override_parameters": [[179, 215], ["params.parse", "thumt.process_vocabulary", "thumt.process_vocabulary", "thumt.load_vocabulary", "thumt.load_vocabulary", "thumt.get_control_mapping", "thumt.get_control_mapping"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.get_control_mapping", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.get_control_mapping"], ["", "def", "override_parameters", "(", "params", ",", "args", ")", ":", "\n", "    ", "params", ".", "model", "=", "args", ".", "model", "\n", "params", ".", "input", "=", "args", ".", "input", "or", "params", ".", "input", "\n", "params", ".", "output", "=", "args", ".", "output", "or", "params", ".", "output", "\n", "params", ".", "context", "=", "args", ".", "context", "or", "params", ".", "context", "\n", "params", ".", "record", "=", "args", ".", "record", "or", "params", ".", "record", "\n", "params", ".", "vocab", "=", "args", ".", "vocabulary", "or", "params", ".", "vocab", "\n", "params", ".", "validation", "=", "args", ".", "validation", "or", "params", ".", "validation", "\n", "params", ".", "references", "=", "args", ".", "references", "or", "params", ".", "references", "\n", "params", ".", "parse", "(", "args", ".", "parameters", ")", "\n", "\n", "params", ".", "vocabulary", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "load_vocabulary", "(", "params", ".", "vocab", "[", "0", "]", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "load_vocabulary", "(", "params", ".", "vocab", "[", "1", "]", ")", "\n", "}", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "params", "\n", ")", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "params", "\n", ")", "\n", "\n", "control_symbols", "=", "[", "params", ".", "pad", ",", "params", ".", "bos", ",", "params", ".", "eos", ",", "params", ".", "unk", "]", "\n", "\n", "params", ".", "mapping", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "\n", "control_symbols", "\n", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "\n", "control_symbols", "\n", ")", "\n", "}", "\n", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer_ctx.get_initializer": [[217, 233], ["tensorflow.random_uniform_initializer", "tensorflow.random_normal_initializer", "tensorflow.variance_scaling_initializer", "tensorflow.variance_scaling_initializer", "ValueError"], "function", ["None"], ["", "def", "get_initializer", "(", "params", ")", ":", "\n", "    ", "if", "params", ".", "initializer", "==", "\"uniform\"", ":", "\n", "        ", "max_val", "=", "params", ".", "initializer_gain", "\n", "return", "tf", ".", "random_uniform_initializer", "(", "-", "max_val", ",", "max_val", ")", "\n", "", "elif", "params", ".", "initializer", "==", "\"normal\"", ":", "\n", "        ", "return", "tf", ".", "random_normal_initializer", "(", "0.0", ",", "params", ".", "initializer_gain", ")", "\n", "", "elif", "params", ".", "initializer", "==", "\"normal_unit_scaling\"", ":", "\n", "        ", "return", "tf", ".", "variance_scaling_initializer", "(", "params", ".", "initializer_gain", ",", "\n", "mode", "=", "\"fan_avg\"", ",", "\n", "distribution", "=", "\"normal\"", ")", "\n", "", "elif", "params", ".", "initializer", "==", "\"uniform_unit_scaling\"", ":", "\n", "        ", "return", "tf", ".", "variance_scaling_initializer", "(", "params", ".", "initializer_gain", ",", "\n", "mode", "=", "\"fan_avg\"", ",", "\n", "distribution", "=", "\"uniform\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unrecognized initializer: %s\"", "%", "params", ".", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer_ctx.get_learning_rate_decay": [[235, 252], ["tensorflow.to_float", "tensorflow.to_float", "tensorflow.minimum", "tensorflow.train.piecewise_constant", "tensorflow.to_int32", "ValueError"], "function", ["None"], ["", "", "def", "get_learning_rate_decay", "(", "learning_rate", ",", "global_step", ",", "params", ")", ":", "\n", "    ", "if", "params", ".", "learning_rate_decay", "in", "[", "\"linear_warmup_rsqrt_decay\"", ",", "\"noam\"", "]", ":", "\n", "        ", "step", "=", "tf", ".", "to_float", "(", "global_step", ")", "\n", "warmup_steps", "=", "tf", ".", "to_float", "(", "params", ".", "warmup_steps", ")", "\n", "multiplier", "=", "params", ".", "hidden_size", "**", "-", "0.5", "\n", "decay", "=", "multiplier", "*", "tf", ".", "minimum", "(", "(", "step", "+", "1", ")", "*", "(", "warmup_steps", "**", "-", "1.5", ")", ",", "\n", "(", "step", "+", "1", ")", "**", "-", "0.5", ")", "\n", "\n", "return", "learning_rate", "*", "decay", "\n", "", "elif", "params", ".", "learning_rate_decay", "==", "\"piecewise_constant\"", ":", "\n", "        ", "return", "tf", ".", "train", ".", "piecewise_constant", "(", "tf", ".", "to_int32", "(", "global_step", ")", ",", "\n", "params", ".", "learning_rate_boundaries", ",", "\n", "params", ".", "learning_rate_values", ")", "\n", "", "elif", "params", ".", "learning_rate_decay", "==", "\"none\"", ":", "\n", "        ", "return", "learning_rate", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown learning_rate_decay\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer_ctx.session_config": [[254, 268], ["tensorflow.OptimizerOptions", "tensorflow.GraphOptions", "tensorflow.ConfigProto", "thumt.is_distributed_training_mode", "str", "thumt.local_rank", "str"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.is_distributed_training_mode", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.local_rank"], ["", "", "def", "session_config", "(", "params", ")", ":", "\n", "    ", "optimizer_options", "=", "tf", ".", "OptimizerOptions", "(", "opt_level", "=", "tf", ".", "OptimizerOptions", ".", "L1", ",", "\n", "do_function_inlining", "=", "True", ")", "\n", "graph_options", "=", "tf", ".", "GraphOptions", "(", "optimizer_options", "=", "optimizer_options", ")", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ",", "\n", "graph_options", "=", "graph_options", ")", "\n", "\n", "if", "distribute", ".", "is_distributed_training_mode", "(", ")", ":", "\n", "        ", "config", ".", "gpu_options", ".", "visible_device_list", "=", "str", "(", "distribute", ".", "local_rank", "(", ")", ")", "\n", "", "elif", "params", ".", "device_list", ":", "\n", "        ", "device_str", "=", "\",\"", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "params", ".", "device_list", "]", ")", "\n", "config", ".", "gpu_options", ".", "visible_device_list", "=", "device_str", "\n", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer_ctx.decode_target_ids": [[270, 294], ["decoded.append", "isinstance", "syms.append", "isinstance", "sym.decode.decode"], "function", ["None"], ["", "def", "decode_target_ids", "(", "inputs", ",", "params", ")", ":", "\n", "    ", "decoded", "=", "[", "]", "\n", "vocab", "=", "params", ".", "vocabulary", "[", "\"target\"", "]", "\n", "\n", "for", "item", "in", "inputs", ":", "\n", "        ", "syms", "=", "[", "]", "\n", "for", "idx", "in", "item", ":", "\n", "            ", "if", "isinstance", "(", "idx", ",", "six", ".", "integer_types", ")", ":", "\n", "                ", "sym", "=", "vocab", "[", "idx", "]", "\n", "", "else", ":", "\n", "                ", "sym", "=", "idx", "\n", "if", "not", "isinstance", "(", "sym", ",", "six", ".", "string_types", ")", ":", "\n", "                    ", "sym", "=", "sym", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n", "", "", "if", "sym", "==", "params", ".", "eos", ":", "\n", "                ", "break", "\n", "\n", "", "if", "sym", "==", "params", ".", "pad", ":", "\n", "                ", "break", "\n", "\n", "", "syms", ".", "append", "(", "sym", ")", "\n", "", "decoded", ".", "append", "(", "syms", ")", "\n", "\n", "", "return", "decoded", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer_ctx.restore_variables": [[296, 322], ["tensorflow.logging.info", "tensorflow.train.list_variables", "tensorflow.train.load_checkpoint", "tensorflow.trainable_variables", "tensorflow.group", "tensorflow.no_op", "tf.train.load_checkpoint.get_tensor", "name.split", "var.name.split", "tensorflow.logging.info", "ops.append", "tensorflow.assign"], "function", ["None"], ["", "def", "restore_variables", "(", "checkpoint", ")", ":", "\n", "    ", "if", "not", "checkpoint", ":", "\n", "        ", "return", "tf", ".", "no_op", "(", "\"restore_op\"", ")", "\n", "\n", "# Load checkpoints", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Loading %s\"", "%", "checkpoint", ")", "\n", "var_list", "=", "tf", ".", "train", ".", "list_variables", "(", "checkpoint", ")", "\n", "reader", "=", "tf", ".", "train", ".", "load_checkpoint", "(", "checkpoint", ")", "\n", "values", "=", "{", "}", "\n", "\n", "for", "(", "name", ",", "shape", ")", "in", "var_list", ":", "\n", "        ", "tensor", "=", "reader", ".", "get_tensor", "(", "name", ")", "\n", "name", "=", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", "\n", "values", "[", "name", "]", "=", "tensor", "\n", "\n", "", "var_list", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "ops", "=", "[", "]", "\n", "\n", "for", "var", "in", "var_list", ":", "\n", "        ", "name", "=", "var", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", "\n", "\n", "if", "name", "in", "values", ":", "\n", "            ", "tf", ".", "logging", ".", "info", "(", "\"Restore %s\"", "%", "var", ".", "name", ")", "\n", "ops", ".", "append", "(", "tf", ".", "assign", "(", "var", ",", "values", "[", "name", "]", ")", ")", "\n", "\n", "", "", "return", "tf", ".", "group", "(", "*", "ops", ",", "name", "=", "\"restore_op\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer_ctx.print_variables": [[324, 335], ["sorted", "tensorflow.logging.info", "list", "tensorflow.logging.info", "numpy.prod().tolist", "tensorflow.trainable_variables", "v.name[].ljust", "str().ljust", "numpy.prod", "str", "numpy.array", "v.shape.as_list"], "function", ["None"], ["", "def", "print_variables", "(", ")", ":", "\n", "    ", "all_weights", "=", "{", "v", ".", "name", ":", "v", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "}", "\n", "total_size", "=", "0", "\n", "\n", "for", "v_name", "in", "sorted", "(", "list", "(", "all_weights", ")", ")", ":", "\n", "        ", "v", "=", "all_weights", "[", "v_name", "]", "\n", "tf", ".", "logging", ".", "info", "(", "\"%s\\tshape    %s\"", ",", "v", ".", "name", "[", ":", "-", "2", "]", ".", "ljust", "(", "80", ")", ",", "\n", "str", "(", "v", ".", "shape", ")", ".", "ljust", "(", "20", ")", ")", "\n", "v_size", "=", "np", ".", "prod", "(", "np", ".", "array", "(", "v", ".", "shape", ".", "as_list", "(", ")", ")", ")", ".", "tolist", "(", ")", "\n", "total_size", "+=", "v_size", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Total trainable variables size: %d\"", ",", "total_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer_ctx.main": [[337, 515], ["tensorflow.logging.set_verbosity", "thumt.get_model", "trainer_ctx.default_parameters", "trainer_ctx.merge_parameters", "trainer_ctx.import_params", "trainer_ctx.override_parameters", "thumt.enable_distributed_training", "models.get_model.get_parameters", "thumt.rank", "trainer_ctx.export_params", "trainer_ctx.export_params", "tensorflow.Graph().as_default", "trainer_ctx.get_initializer", "tensorflow.contrib.layers.l1_l2_regularizer", "models.get_model.", "tensorflow.train.get_or_create_global_step", "thumt.parallel_model", "trainer_ctx.get_learning_rate_decay", "tensorflow.convert_to_tensor", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "thumt.MultiStepOptimizer", "tf.contrib.opt.LazyAdamOptimizer.compute_gradients", "tf.contrib.opt.LazyAdamOptimizer.apply_gradients", "thumt.get_broadcast_hook", "trainer_ctx.restore_variables", "trainer_ctx.collect_params", "thumt.get_training_input_contextual", "thumt.get_input_features", "model_cls.get_training_func", "tensorflow.add_n", "len", "tensorflow.losses.get_regularization_loss", "thumt.rank", "trainer_ctx.print_variables", "tensorflow.train.AdamOptimizer", "thumt.LossScalingOptimizer", "list", "tensorflow.clip_by_global_norm", "zip", "thumt.sort_and_zip_files", "tensorflow.train.StopAtStepHook", "tensorflow.train.NanTensorHook", "tensorflow.train.LoggingTensorHook", "train_hooks.append", "thumt.rank", "tensorflow.train.Saver", "tensorflow.add_to_collection", "train_hooks.append", "step_context.session.run", "tensorflow.train.MonitoredTrainingSession", "sess.run_step_fn", "models.get_model.get_parameters", "tensorflow.Graph", "os.path.join", "tensorflow.contrib.opt.LazyAdamOptimizer", "RuntimeError", "zip", "list", "tensorflow.trainable_variables", "thumt.MultiStepHook", "train_hooks.append", "sess.should_stop", "sess.run", "tensorflow.shape", "tensorflow.train.CheckpointSaverHook", "thumt.MultiStepHook", "trainer_ctx.session_config", "thumt.EvaluationHook", "trainer_ctx.session_config", "thumt.create_inference_graph", "eval_input_fn", "trainer_ctx.decode_target_ids"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.__init__.get_model", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.default_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.merge_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.import_params", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.override_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.enable_distributed_training", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.rank", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.export_params", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.export_params", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.get_initializer", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo.parallel_model", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.get_learning_rate_decay", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.StaticLossScalingOptimizer.compute_gradients", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.StaticLossScalingOptimizer.apply_gradients", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.get_broadcast_hook", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.restore_variables", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.collect_params", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_training_input_contextual", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.record.get_input_features", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_training_func", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.rank", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.print_variables", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.sort_and_zip_files", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.rank", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.session_config", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.session_config", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.search.create_inference_graph", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.decode_target_ids"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "distribute", ":", "\n", "        ", "distribute", ".", "enable_distributed_training", "(", ")", "\n", "\n", "", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "model_cls", "=", "models", ".", "get_model", "(", "args", ".", "model", ")", "\n", "params", "=", "default_parameters", "(", ")", "\n", "\n", "# Import and override parameters", "\n", "# Priorities (low -> high):", "\n", "# default -> saved -> command", "\n", "params", "=", "merge_parameters", "(", "params", ",", "model_cls", ".", "get_parameters", "(", ")", ")", "\n", "params", "=", "import_params", "(", "args", ".", "output", ",", "args", ".", "model", ",", "params", ")", "\n", "override_parameters", "(", "params", ",", "args", ")", "\n", "\n", "# Export all parameters and model specific parameters", "\n", "if", "distribute", ".", "rank", "(", ")", "==", "0", ":", "\n", "        ", "export_params", "(", "params", ".", "output", ",", "\"params.json\"", ",", "params", ")", "\n", "export_params", "(", "\n", "params", ".", "output", ",", "\n", "\"%s.json\"", "%", "args", ".", "model", ",", "\n", "collect_params", "(", "params", ",", "model_cls", ".", "get_parameters", "(", ")", ")", "\n", ")", "\n", "\n", "# Build Graph", "\n", "", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "if", "not", "params", ".", "record", ":", "\n", "# Build input queue", "\n", "#features = dataset.get_training_input(params.input, params)", "\n", "            ", "features", "=", "dataset", ".", "get_training_input_contextual", "(", "params", ".", "input", ",", "params", ".", "context", ",", "params", ")", "\n", "", "else", ":", "\n", "            ", "features", "=", "record", ".", "get_input_features", "(", "\n", "os", ".", "path", ".", "join", "(", "params", ".", "record", ",", "\"*train*\"", ")", ",", "\"train\"", ",", "params", "\n", ")", "\n", "\n", "# Build model", "\n", "", "initializer", "=", "get_initializer", "(", "params", ")", "\n", "regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l1_l2_regularizer", "(", "\n", "scale_l1", "=", "params", ".", "scale_l1", ",", "scale_l2", "=", "params", ".", "scale_l2", ")", "\n", "model", "=", "model_cls", "(", "params", ")", "\n", "# Create global step", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "dtype", "=", "tf", ".", "float16", "if", "args", ".", "half", "else", "None", "\n", "\n", "# Multi-GPU setting", "\n", "sharded_losses", "=", "parallel", ".", "parallel_model", "(", "\n", "model", ".", "get_training_func", "(", "initializer", ",", "regularizer", ",", "dtype", ")", ",", "\n", "features", ",", "\n", "params", ".", "device_list", "\n", ")", "\n", "loss", "=", "tf", ".", "add_n", "(", "sharded_losses", ")", "/", "len", "(", "sharded_losses", ")", "\n", "loss", "=", "loss", "+", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "\n", "if", "distribute", ".", "rank", "(", ")", "==", "0", ":", "\n", "            ", "print_variables", "(", ")", "\n", "\n", "", "learning_rate", "=", "get_learning_rate_decay", "(", "params", ".", "learning_rate", ",", "\n", "global_step", ",", "params", ")", "\n", "learning_rate", "=", "tf", ".", "convert_to_tensor", "(", "learning_rate", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"loss\"", ",", "loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"learning_rate\"", ",", "learning_rate", ")", "\n", "\n", "# Create optimizer", "\n", "if", "params", ".", "optimizer", "==", "\"Adam\"", ":", "\n", "            ", "opt", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", ",", "\n", "beta1", "=", "params", ".", "adam_beta1", ",", "\n", "beta2", "=", "params", ".", "adam_beta2", ",", "\n", "epsilon", "=", "params", ".", "adam_epsilon", ")", "\n", "", "elif", "params", ".", "optimizer", "==", "\"LazyAdam\"", ":", "\n", "            ", "opt", "=", "tf", ".", "contrib", ".", "opt", ".", "LazyAdamOptimizer", "(", "learning_rate", ",", "\n", "beta1", "=", "params", ".", "adam_beta1", ",", "\n", "beta2", "=", "params", ".", "adam_beta2", ",", "\n", "epsilon", "=", "params", ".", "adam_epsilon", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Optimizer %s not supported\"", "%", "params", ".", "optimizer", ")", "\n", "\n", "", "opt", "=", "optimizers", ".", "MultiStepOptimizer", "(", "opt", ",", "params", ".", "update_cycle", ")", "\n", "\n", "if", "args", ".", "half", ":", "\n", "            ", "opt", "=", "optimizers", ".", "LossScalingOptimizer", "(", "opt", ",", "params", ".", "loss_scale", ")", "\n", "\n", "# Optimization", "\n", "", "grads_and_vars", "=", "opt", ".", "compute_gradients", "(", "\n", "loss", ",", "colocate_gradients_with_ops", "=", "True", ")", "\n", "\n", "if", "params", ".", "clip_grad_norm", ":", "\n", "            ", "grads", ",", "var_list", "=", "list", "(", "zip", "(", "*", "grads_and_vars", ")", ")", "\n", "grads", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "grads", ",", "params", ".", "clip_grad_norm", ")", "\n", "grads_and_vars", "=", "zip", "(", "grads", ",", "var_list", ")", "\n", "\n", "", "train_op", "=", "opt", ".", "apply_gradients", "(", "grads_and_vars", ",", "\n", "global_step", "=", "global_step", ")", "\n", "\n", "# Validation", "\n", "if", "params", ".", "validation", "and", "params", ".", "references", "[", "0", "]", ":", "\n", "            ", "files", "=", "[", "params", ".", "validation", "]", "+", "list", "(", "params", ".", "references", ")", "\n", "eval_inputs", "=", "dataset", ".", "sort_and_zip_files", "(", "files", ")", "\n", "eval_input_fn", "=", "dataset", ".", "get_evaluation_input", "\n", "", "else", ":", "\n", "            ", "eval_input_fn", "=", "None", "\n", "\n", "# Hooks", "\n", "", "train_hooks", "=", "[", "\n", "tf", ".", "train", ".", "StopAtStepHook", "(", "last_step", "=", "params", ".", "train_steps", ")", ",", "\n", "tf", ".", "train", ".", "NanTensorHook", "(", "loss", ")", ",", "\n", "tf", ".", "train", ".", "LoggingTensorHook", "(", "\n", "{", "\n", "\"step\"", ":", "global_step", ",", "\n", "\"lr\"", ":", "learning_rate", ",", "\n", "\"loss\"", ":", "loss", ",", "\n", "\"source\"", ":", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", ",", "\n", "}", ",", "\n", "every_n_iter", "=", "1", "\n", ")", "\n", "]", "\n", "\n", "broadcast_hook", "=", "distribute", ".", "get_broadcast_hook", "(", ")", "\n", "\n", "if", "broadcast_hook", ":", "\n", "            ", "train_hooks", ".", "append", "(", "broadcast_hook", ")", "\n", "\n", "", "if", "distribute", ".", "rank", "(", ")", "==", "0", ":", "\n", "# Add hooks", "\n", "            ", "save_vars", "=", "tf", ".", "trainable_variables", "(", ")", "+", "[", "global_step", "]", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "\n", "var_list", "=", "save_vars", "if", "params", ".", "only_save_trainable", "else", "None", ",", "\n", "max_to_keep", "=", "params", ".", "keep_checkpoint_max", ",", "\n", "sharded", "=", "False", "\n", ")", "\n", "tf", ".", "add_to_collection", "(", "tf", ".", "GraphKeys", ".", "SAVERS", ",", "saver", ")", "\n", "train_hooks", ".", "append", "(", "\n", "hooks", ".", "MultiStepHook", "(", "\n", "tf", ".", "train", ".", "CheckpointSaverHook", "(", "\n", "checkpoint_dir", "=", "params", ".", "output", ",", "\n", "save_secs", "=", "params", ".", "save_checkpoint_secs", "or", "None", ",", "\n", "save_steps", "=", "params", ".", "save_checkpoint_steps", "or", "None", ",", "\n", "saver", "=", "saver", ")", ",", "\n", "step", "=", "params", ".", "update_cycle", ")", "\n", ")", "\n", "\n", "if", "eval_input_fn", "is", "not", "None", ":", "\n", "                ", "train_hooks", ".", "append", "(", "\n", "hooks", ".", "MultiStepHook", "(", "\n", "hooks", ".", "EvaluationHook", "(", "\n", "lambda", "f", ":", "inference", ".", "create_inference_graph", "(", "\n", "[", "model", "]", ",", "f", ",", "params", "\n", ")", ",", "\n", "lambda", ":", "eval_input_fn", "(", "eval_inputs", ",", "params", ")", ",", "\n", "lambda", "x", ":", "decode_target_ids", "(", "x", ",", "params", ")", ",", "\n", "params", ".", "output", ",", "\n", "session_config", "(", "params", ")", ",", "\n", "params", ".", "keep_top_checkpoint_max", ",", "\n", "eval_secs", "=", "params", ".", "eval_secs", ",", "\n", "eval_steps", "=", "params", ".", "eval_steps", "\n", ")", ",", "\n", "step", "=", "params", ".", "update_cycle", "\n", ")", "\n", ")", "\n", "", "checkpoint_dir", "=", "params", ".", "output", "\n", "", "else", ":", "\n", "            ", "checkpoint_dir", "=", "None", "\n", "\n", "", "restore_op", "=", "restore_variables", "(", "args", ".", "checkpoint", ")", "\n", "\n", "def", "restore_fn", "(", "step_context", ")", ":", "\n", "            ", "step_context", ".", "session", ".", "run", "(", "restore_op", ")", "\n", "\n", "# Create session, do not use default CheckpointSaverHook", "\n", "", "with", "tf", ".", "train", ".", "MonitoredTrainingSession", "(", "\n", "checkpoint_dir", "=", "checkpoint_dir", ",", "hooks", "=", "train_hooks", ",", "\n", "save_checkpoint_secs", "=", "None", ",", "\n", "config", "=", "session_config", "(", "params", ")", ")", "as", "sess", ":", "\n", "# Restore pre-trained variables", "\n", "            ", "sess", ".", "run_step_fn", "(", "restore_fn", ")", "\n", "\n", "while", "not", "sess", ".", "should_stop", "(", ")", ":", "\n", "                ", "sess", ".", "run", "(", "train_op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_ctx.parse_args": [[22, 64], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Translate using existing NMT models\"", ",", "\n", "usage", "=", "\"translator.py [<args>] [-h | --help]\"", "\n", ")", "\n", "\n", "# input files", "\n", "parser", ".", "add_argument", "(", "\"--input\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of input file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of output file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoints\"", ",", "type", "=", "str", ",", "nargs", "=", "\"+\"", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of trained models\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocabulary\"", ",", "type", "=", "str", ",", "nargs", "=", "2", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of source and target vocabulary\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dev_dialog_src_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_dialog_tgt_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_style_src_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_style_tgt_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_language_src_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_language_tgt_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--emotion\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to emotion file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_emotion\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to dev_emotion file\"", ")", "\n", "# model and configuration", "\n", "parser", ".", "add_argument", "(", "\"--models\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"Name of the model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--parameters\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Additional hyper parameters\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--verbose\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Enable verbose output\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_ctx.default_parameters": [[66, 92], ["tensorflow.contrib.training.HParams"], "function", ["None"], ["", "def", "default_parameters", "(", ")", ":", "\n", "    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "input", "=", "None", ",", "\n", "output", "=", "None", ",", "\n", "vocabulary", "=", "None", ",", "\n", "# vocabulary specific", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "bos", "=", "\"<bos>\"", ",", "\n", "eos", "=", "\"<eos>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "mapping", "=", "None", ",", "\n", "embedding_path", "=", "\"/mnt/yardcephfs/mmyard/g_wxg_td_prc/yunlonliang/4.sa/embedding/glove.840B.300d.emotion.txt\"", ",", "\n", "start_steps", "=", "0", ",", "\n", "kl_annealing_steps", "=", "10000", ",", "\n", "append_eos", "=", "False", ",", "\n", "# decoding", "\n", "top_beams", "=", "1", ",", "\n", "beam_size", "=", "4", ",", "\n", "decode_alpha", "=", "0.6", ",", "\n", "decode_length", "=", "50", ",", "\n", "decode_batch_size", "=", "32", ",", "\n", "device_list", "=", "[", "0", "]", ",", "\n", "num_threads", "=", "1", "\n", ")", "\n", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_ctx.merge_parameters": [[94, 112], ["tensorflow.contrib.training.HParams", "six.iteritems", "tf.contrib.training.HParams.values", "six.iteritems", "params1.values", "tf.contrib.training.HParams.add_hparam", "params2.values", "setattr", "tf.contrib.training.HParams.add_hparam"], "function", ["None"], ["", "def", "merge_parameters", "(", "params1", ",", "params2", ")", ":", "\n", "    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", ")", "\n", "\n", "#    for (k, v) in params1.values().iteritems():", "\n", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "params1", ".", "values", "(", ")", ")", ":", "\n", "        ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "params_dict", "=", "params", ".", "values", "(", ")", "\n", "\n", "#    for (k, v) in params2.values().iteritems():", "\n", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "params2", ".", "values", "(", ")", ")", ":", "\n", "        ", "if", "k", "in", "params_dict", ":", "\n", "# Override", "\n", "            ", "setattr", "(", "params", ",", "k", ",", "v", ")", "\n", "", "else", ":", "\n", "            ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_ctx.import_params": [[114, 130], ["model_name.startswith", "os.path.abspath", "os.path.join", "tensorflow.gfile.Exists", "tensorflow.gfile.Open", "tensorflow.logging.info", "fd.readline", "params.parse_json"], "function", ["None"], ["", "def", "import_params", "(", "model_dir", ",", "model_name", ",", "params", ")", ":", "\n", "    ", "if", "model_name", ".", "startswith", "(", "\"experimental_\"", ")", ":", "\n", "        ", "model_name", "=", "model_name", "[", "13", ":", "]", "\n", "\n", "", "model_dir", "=", "os", ".", "path", ".", "abspath", "(", "model_dir", ")", "\n", "m_name", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "model_name", "+", "\".json\"", ")", "\n", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "m_name", ")", ":", "\n", "        ", "return", "params", "\n", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "m_name", ")", "as", "fd", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "\"Restoring model parameters from %s\"", "%", "m_name", ")", "\n", "json_str", "=", "fd", ".", "readline", "(", ")", "\n", "params", ".", "parse_json", "(", "json_str", ")", "\n", "\n", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_ctx.override_parameters": [[132, 170], ["thumt.process_vocabulary", "thumt.process_vocabulary", "params.parse", "thumt.load_vocabulary", "thumt.load_vocabulary", "thumt.get_control_mapping", "thumt.get_control_mapping"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.get_control_mapping", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.get_control_mapping"], ["", "def", "override_parameters", "(", "params", ",", "args", ")", ":", "\n", "    ", "if", "args", ".", "parameters", ":", "\n", "        ", "params", ".", "parse", "(", "args", ".", "parameters", ")", "\n", "\n", "", "params", ".", "dev_dialog_src_context", "=", "args", ".", "dev_dialog_src_context", "#or params.dev_dialog_src_context", "\n", "params", ".", "dev_dialog_tgt_context", "=", "args", ".", "dev_dialog_tgt_context", "#or params.dev_dialog_tgt_context", "\n", "params", ".", "dev_style_src_context", "=", "args", ".", "dev_style_src_context", "#or params.dev_style_src_context", "\n", "params", ".", "dev_style_tgt_context", "=", "args", ".", "dev_style_tgt_context", "#or params.dev_style_tgt_context", "\n", "params", ".", "dev_language_src_context", "=", "args", ".", "dev_language_src_context", "#or params.dev_language_src_context", "\n", "params", ".", "dev_language_tgt_context", "=", "args", ".", "dev_language_tgt_context", "#or params.dev_language_tgt_context", "\n", "params", ".", "dev_emotion", "=", "args", ".", "dev_emotion", "or", "params", ".", "dev_emotion", "\n", "params", ".", "vocabulary", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "load_vocabulary", "(", "args", ".", "vocabulary", "[", "0", "]", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "load_vocabulary", "(", "args", ".", "vocabulary", "[", "1", "]", ")", ",", "\n", "\"emotion\"", ":", "[", "'neutral'", ",", "'joy'", ",", "'anger'", ",", "'surprise'", ",", "'sadness'", ",", "'fear'", ",", "'disgust'", ",", "'happiness'", ",", "'happy'", ",", "'other'", "]", ",", "\n", "\"position\"", ":", "[", "'0'", ",", "'1'", ",", "'2'", ",", "'3'", ",", "'4'", ",", "'5'", ",", "'6'", ",", "'7'", ",", "'8'", ",", "'9'", ",", "'10'", "]", "\n", "}", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "params", "\n", ")", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "params", "\n", ")", "\n", "\n", "control_symbols", "=", "[", "params", ".", "pad", ",", "params", ".", "bos", ",", "params", ".", "eos", ",", "params", ".", "unk", "]", "\n", "\n", "params", ".", "mapping", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "\n", "control_symbols", "\n", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "\n", "control_symbols", "\n", ")", "\n", "}", "\n", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_ctx.session_config": [[172, 183], ["tensorflow.OptimizerOptions", "tensorflow.GraphOptions", "tensorflow.ConfigProto", "str"], "function", ["None"], ["", "def", "session_config", "(", "params", ")", ":", "\n", "    ", "optimizer_options", "=", "tf", ".", "OptimizerOptions", "(", "opt_level", "=", "tf", ".", "OptimizerOptions", ".", "L1", ",", "\n", "do_function_inlining", "=", "False", ")", "\n", "graph_options", "=", "tf", ".", "GraphOptions", "(", "optimizer_options", "=", "optimizer_options", ")", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ",", "\n", "graph_options", "=", "graph_options", ")", "\n", "if", "params", ".", "device_list", ":", "\n", "        ", "device_str", "=", "\",\"", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "params", ".", "device_list", "]", ")", "\n", "config", ".", "gpu_options", ".", "visible_device_list", "=", "device_str", "\n", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_ctx.set_variables": [[185, 199], ["tensorflow.logging.debug", "list", "tensorflow.device", "tensorflow.assign", "ops.append", "name.split"], "function", ["None"], ["", "def", "set_variables", "(", "var_list", ",", "value_dict", ",", "prefix", ")", ":", "\n", "    ", "ops", "=", "[", "]", "\n", "for", "var", "in", "var_list", ":", "\n", "        ", "for", "name", "in", "value_dict", ":", "\n", "            ", "var_name", "=", "\"/\"", ".", "join", "(", "[", "prefix", "]", "+", "list", "(", "name", ".", "split", "(", "\"/\"", ")", "[", "1", ":", "]", ")", ")", "\n", "\n", "if", "var", ".", "name", "[", ":", "-", "2", "]", "==", "var_name", ":", "\n", "                ", "tf", ".", "logging", ".", "debug", "(", "\"restoring %s -> %s\"", "%", "(", "name", ",", "var", ".", "name", ")", ")", "\n", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "                    ", "op", "=", "tf", ".", "assign", "(", "var", ",", "value_dict", "[", "name", "]", ")", "\n", "ops", ".", "append", "(", "op", ")", "\n", "", "break", "\n", "\n", "", "", "", "return", "ops", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_ctx.shard_features": [[201, 222], ["len", "range"], "function", ["None"], ["", "def", "shard_features", "(", "features", ",", "placeholders", ",", "predictions", ")", ":", "\n", "    ", "num_shards", "=", "len", "(", "placeholders", ")", "\n", "feed_dict", "=", "{", "}", "\n", "n", "=", "0", "\n", "\n", "for", "name", "in", "features", ":", "\n", "        ", "feat", "=", "features", "[", "name", "]", "\n", "batch", "=", "feat", ".", "shape", "[", "0", "]", "\n", "\n", "if", "batch", "<", "num_shards", ":", "\n", "            ", "feed_dict", "[", "placeholders", "[", "0", "]", "[", "name", "]", "]", "=", "feat", "\n", "n", "=", "1", "\n", "", "else", ":", "\n", "            ", "shard_size", "=", "(", "batch", "+", "num_shards", "-", "1", ")", "//", "num_shards", "\n", "\n", "for", "i", "in", "range", "(", "num_shards", ")", ":", "\n", "                ", "shard_feat", "=", "feat", "[", "i", "*", "shard_size", ":", "(", "i", "+", "1", ")", "*", "shard_size", "]", "\n", "feed_dict", "[", "placeholders", "[", "i", "]", "[", "name", "]", "]", "=", "shard_feat", "\n", "n", "=", "num_shards", "\n", "\n", "", "", "", "return", "predictions", "[", ":", "n", "]", ",", "feed_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_ctx.get_turn_position": [[223, 245], ["open", "fr.readlines", "turn_position.append", "file1.split", "open", "line.split", "tmp.append", "file1.split", "sorted", "fw.write", "str"], "function", ["None"], ["", "def", "get_turn_position", "(", "file1", ")", ":", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "content", "=", "fr", ".", "readlines", "(", ")", "\n", "", "turn_position", "=", "[", "]", "\n", "for", "line", "in", "content", ":", "\n", "        ", "tmp", "=", "[", "]", "\n", "index", "=", "1", "\n", "for", "i", "in", "line", ".", "split", "(", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "#tmp.append(str(index))", "\n", "            ", "if", "i", "==", "'[SEP]'", ":", "\n", "                ", "index", "+=", "1", "\n", "", "tmp", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "", "turn_position", ".", "append", "(", "tmp", ")", "\n", "", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.turn_position'", "\n", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_ctx.get_turn_position_src": [[246, 296], ["zip", "open", "fr.readlines", "open", "fr.readlines", "dialog.append", "turn_position.append", "mask.append", "file1.split", "open", "open", "line.split", "len", "len", "print", "file1.split", "sorted", "fw.write", "fw.write", "ctx.replace", "src.replace", "mask_sent.append", "tmp.append", "tmp.append", "line.split", "str", "str", "str"], "function", ["None"], ["", "def", "get_turn_position_src", "(", "file1", ",", "file2", ")", ":", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "sentence", "=", "fr", ".", "readlines", "(", ")", "\n", "", "with", "open", "(", "file2", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "content", "=", "fr", ".", "readlines", "(", ")", "\n", "\n", "", "turn_position", "=", "[", "]", "\n", "mask", "=", "[", "]", "\n", "dialog", "=", "[", "]", "\n", "for", "src", ",", "ctx", "in", "zip", "(", "sentence", ",", "content", ")", ":", "\n", "        ", "line", "=", "ctx", ".", "replace", "(", "'\\n'", ",", "' '", ")", "+", "src", ".", "replace", "(", "'\\n'", ",", "' '", ")", "+", "'<eos> '", "\n", "dialog", ".", "append", "(", "line", ")", "\n", "tmp", "=", "[", "]", "\n", "mask_sent", "=", "[", "]", "\n", "index", "=", "1", "\n", "flag", "=", "0", "\n", "for", "i", "in", "line", ".", "split", "(", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "if", "flag", "==", "0", ":", "\n", "                ", "mask_sent", ".", "append", "(", "str", "(", "1", ")", ")", "\n", "tmp", ".", "append", "(", "str", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "#mask_sent.append(str(0))", "\n", "                ", "tmp", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "if", "i", "==", "'[SEP]'", ":", "\n", "                    ", "index", "+=", "1", "\n", "\n", "", "", "if", "i", "==", "'<eos>'", ":", "\n", "                ", "flag", "=", "1", "\n", "\n", "", "", "if", "len", "(", "line", ".", "split", "(", ")", ")", "!=", "len", "(", "tmp", ")", ":", "\n", "            ", "print", "(", "line", ")", "\n", "", "turn_position", ".", "append", "(", "tmp", ")", "\n", "mask", ".", "append", "(", "mask_sent", ")", "\n", "\n", "", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.src_dia_turn_position'", "\n", "dialog_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.src.dialog'", "\n", "\n", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "with", "open", "(", "dialog_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "sub_mask", "in", "dialog", ":", "\n", "            ", "fw", ".", "write", "(", "sub_mask", ")", "\n", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", ",", "dialog_file", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_ctx.main": [[297, 527], ["tensorflow.logging.set_verbosity", "thumt.get_model", "translator_ctx.default_parameters", "translator_ctx.merge_parameters", "translator_ctx.import_params", "translator_ctx.override_parameters", "tensorflow.Graph().as_default", "enumerate", "range", "translator_ctx.get_turn_position", "translator_ctx.get_turn_position", "translator_ctx.get_turn_position", "translator_ctx.get_turn_position", "translator_ctx.get_turn_position", "translator_ctx.get_turn_position", "thumt.sort_input_file_ctx", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "range", "thumt.data_parallelism", "tensorflow.all_variables", "range", "tensorflow.group", "list", "list", "range", "range", "model_cls.get_parameters", "zip", "range", "range", "tensorflow.logging.info", "tensorflow.train.list_variables", "tensorflow.train.load_checkpoint", "model_var_lists.append", "len", "model_cls_list[].get_name", "model.get_inference_func", "model_fns.append", "len", "placeholders.append", "len", "model_cls_list[].get_name", "translator_ctx.set_variables", "assign_ops.extend", "tensorflow.Session", "sess.run", "sess.run", "itertools.chain", "itertools.chain", "len", "restored_inputs.append", "restored_outputs.append", "restored_scores.append", "open", "zip", "len", "len", "len", "tensorflow.Graph", "tf.train.load_checkpoint.get_tensor", "thumt.create_inference_graph", "v.name.startswith", "tensorflow.tables_initializer", "list.append", "list.append", "zip", "model_cls_list[].get_name.startswith", "model_cls_list[].get_name.find", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "un_init_var_list.append", "translator_ctx.session_config", "sess.run", "translator_ctx.shard_features", "sess.run", "results.append", "print", "tensorflow.logging.log", "item.tolist", "item.tolist", "model_cls_list[].get_name", "len", "decoded.append", "outfile.write", "outfile.write"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.__init__.get_model", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.default_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.merge_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.import_params", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.override_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.sort_input_file_ctx", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo.data_parallelism", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_name", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_inference_func", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_name", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.set_variables", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.search.create_inference_graph", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.session_config", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_bak.shard_features", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_name"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "# Load configs", "\n", "model_cls_list", "=", "[", "models", ".", "get_model", "(", "model", ")", "for", "model", "in", "args", ".", "models", "]", "\n", "params_list", "=", "[", "default_parameters", "(", ")", "for", "_", "in", "range", "(", "len", "(", "model_cls_list", ")", ")", "]", "\n", "params_list", "=", "[", "\n", "merge_parameters", "(", "params", ",", "model_cls", ".", "get_parameters", "(", ")", ")", "\n", "for", "params", ",", "model_cls", "in", "zip", "(", "params_list", ",", "model_cls_list", ")", "\n", "]", "\n", "params_list", "=", "[", "\n", "import_params", "(", "args", ".", "checkpoints", "[", "i", "]", ",", "args", ".", "models", "[", "i", "]", ",", "params_list", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "args", ".", "checkpoints", ")", ")", "\n", "]", "\n", "params_list", "=", "[", "\n", "override_parameters", "(", "params_list", "[", "i", "]", ",", "args", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "model_cls_list", ")", ")", "\n", "]", "\n", "\n", "# Build Graph", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "model_var_lists", "=", "[", "]", "\n", "\n", "# Load checkpoints", "\n", "for", "i", ",", "checkpoint", "in", "enumerate", "(", "args", ".", "checkpoints", ")", ":", "\n", "            ", "tf", ".", "logging", ".", "info", "(", "\"Loading %s\"", "%", "checkpoint", ")", "\n", "var_list", "=", "tf", ".", "train", ".", "list_variables", "(", "checkpoint", ")", "\n", "values", "=", "{", "}", "\n", "reader", "=", "tf", ".", "train", ".", "load_checkpoint", "(", "checkpoint", ")", "\n", "\n", "for", "(", "name", ",", "shape", ")", "in", "var_list", ":", "\n", "                ", "if", "not", "name", ".", "startswith", "(", "model_cls_list", "[", "i", "]", ".", "get_name", "(", ")", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "name", ".", "find", "(", "\"losses_avg\"", ")", ">=", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "tensor", "=", "reader", ".", "get_tensor", "(", "name", ")", "\n", "values", "[", "name", "]", "=", "tensor", "\n", "\n", "", "model_var_lists", ".", "append", "(", "values", ")", "\n", "\n", "# Build models", "\n", "", "model_fns", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "args", ".", "checkpoints", ")", ")", ":", "\n", "            ", "name", "=", "model_cls_list", "[", "i", "]", ".", "get_name", "(", ")", "\n", "model", "=", "model_cls_list", "[", "i", "]", "(", "params_list", "[", "i", "]", ",", "name", "+", "\"_%d\"", "%", "i", ")", "\n", "model_fn", "=", "model", ".", "get_inference_func", "(", ")", "\n", "model_fns", ".", "append", "(", "model_fn", ")", "\n", "\n", "", "params", "=", "params_list", "[", "0", "]", "\n", "# Read input file", "\n", "position_file_src_dia", "=", "get_turn_position", "(", "params", ".", "dev_dialog_src_context", ")", "\n", "#            position_file_src_dia, dialog_file = get_turn_position_src(params.validation, params.dialog_src_context)", "\n", "\n", "position_file_tgt_dia", "=", "get_turn_position", "(", "params", ".", "dev_dialog_tgt_context", ")", "\n", "position_file_src_sty", "=", "get_turn_position", "(", "params", ".", "dev_style_src_context", ")", "\n", "position_file_tgt_sty", "=", "get_turn_position", "(", "params", ".", "dev_style_tgt_context", ")", "\n", "position_file_src_lan", "=", "get_turn_position", "(", "params", ".", "dev_language_src_context", ")", "\n", "position_file_tgt_lan", "=", "get_turn_position", "(", "params", ".", "dev_language_tgt_context", ")", "\n", "\n", "sorted_keys", ",", "sorted_inputs", ",", "dialog_src_context", ",", "pos_src_dia", ",", "dialog_tgt_context", ",", "pos_tgt_dia", ",", "style_src_context", ",", "pos_src_sty", ",", "style_tgt_context", ",", "pos_tgt_sty", ",", "language_src_context", ",", "pos_src_lan", ",", "language_tgt_context", ",", "pos_tgt_lan", ",", "emo", "=", "dataset", ".", "sort_input_file_ctx", "(", "args", ".", "input", ",", "params", ".", "dev_dialog_src_context", ",", "position_file_src_dia", ",", "params", ".", "dev_dialog_tgt_context", ",", "position_file_tgt_dia", ",", "params", ".", "dev_style_src_context", ",", "position_file_src_sty", ",", "params", ".", "dev_style_tgt_context", ",", "position_file_tgt_sty", ",", "params", ".", "dev_language_src_context", ",", "position_file_src_lan", ",", "params", ".", "dev_language_tgt_context", ",", "position_file_tgt_lan", ",", "params", ".", "dev_emotion", ")", "\n", "# Build input queue", "\n", "features", "=", "dataset", ".", "get_inference_input", "(", "sorted_inputs", ",", "\"x\"", ",", "params", ")", "\n", "#        features_ctx = dataset.get_inference_input(sorted_ctxs, params)", "\n", "\n", "features_ctx1", "=", "dataset", ".", "get_inference_input", "(", "dialog_src_context", ",", "\"ctx\"", ",", "params", ")", "\n", "features_ctx2", "=", "dataset", ".", "get_inference_input", "(", "pos_src_dia", ",", "\"pos\"", ",", "params", ")", "\n", "features_ctx3", "=", "dataset", ".", "get_inference_input", "(", "dialog_tgt_context", ",", "\"ctx\"", ",", "params", ")", "\n", "features_ctx4", "=", "dataset", ".", "get_inference_input", "(", "pos_tgt_dia", ",", "\"pos\"", ",", "params", ")", "\n", "features_ctx5", "=", "dataset", ".", "get_inference_input", "(", "style_src_context", ",", "\"ctx\"", ",", "params", ")", "\n", "features_ctx6", "=", "dataset", ".", "get_inference_input", "(", "pos_src_sty", ",", "\"pos\"", ",", "params", ")", "\n", "features_ctx7", "=", "dataset", ".", "get_inference_input", "(", "style_tgt_context", ",", "\"ctx\"", ",", "params", ")", "\n", "features_ctx8", "=", "dataset", ".", "get_inference_input", "(", "pos_tgt_sty", ",", "\"pos\"", ",", "params", ")", "\n", "features_ctx9", "=", "dataset", ".", "get_inference_input", "(", "language_src_context", ",", "\"ctx\"", ",", "params", ")", "\n", "features_ctx10", "=", "dataset", ".", "get_inference_input", "(", "pos_src_lan", ",", "\"pos\"", ",", "params", ")", "\n", "features_ctx11", "=", "dataset", ".", "get_inference_input", "(", "language_tgt_context", ",", "\"ctx\"", ",", "params", ")", "\n", "features_ctx12", "=", "dataset", ".", "get_inference_input", "(", "pos_tgt_lan", ",", "\"pos\"", ",", "params", ")", "\n", "features_ctx13", "=", "dataset", ".", "get_inference_input", "(", "emo", ",", "\"emo\"", ",", "params", ")", "\n", "\n", "#        features[\"context\"] = features_ctx[\"source\"]", "\n", "#        features[\"context_length\"] = features_ctx[\"source_length\"]", "\n", "\n", "features", "[", "\"context_dia_src\"", "]", "=", "features_ctx1", "[", "\"source\"", "]", "\n", "features", "[", "\"context_dia_src_length\"", "]", "=", "features_ctx1", "[", "\"source_length\"", "]", "\n", "features", "[", "\"position_dia_src\"", "]", "=", "features_ctx2", "[", "\"source\"", "]", "\n", "#        features[\"\"] = features_ctx2[\"source_length\"]", "\n", "features", "[", "\"context_dia_tgt\"", "]", "=", "features_ctx3", "[", "\"source\"", "]", "\n", "features", "[", "\"context_dia_tgt_length\"", "]", "=", "features_ctx3", "[", "\"source_length\"", "]", "\n", "features", "[", "\"position_dia_tgt\"", "]", "=", "features_ctx4", "[", "\"source\"", "]", "\n", "#       features[\"\"] = features_ctx4[\"source_length\"]", "\n", "features", "[", "\"context_sty_src\"", "]", "=", "features_ctx5", "[", "\"source\"", "]", "\n", "features", "[", "\"context_sty_src_length\"", "]", "=", "features_ctx5", "[", "\"source_length\"", "]", "\n", "features", "[", "\"position_sty_src\"", "]", "=", "features_ctx6", "[", "\"source\"", "]", "\n", "#        features[\"\"] = features_ctx6[\"source_length\"]", "\n", "features", "[", "\"context_sty_tgt\"", "]", "=", "features_ctx7", "[", "\"source\"", "]", "\n", "features", "[", "\"context_sty_tgt_length\"", "]", "=", "features_ctx7", "[", "\"source_length\"", "]", "\n", "features", "[", "\"position_sty_tgt\"", "]", "=", "features_ctx8", "[", "\"source\"", "]", "\n", "#        features[\"\"] = features_ctx8[\"source_length\"]", "\n", "features", "[", "\"context_lan_src\"", "]", "=", "features_ctx9", "[", "\"source\"", "]", "\n", "features", "[", "\"context_lan_src_length\"", "]", "=", "features_ctx9", "[", "\"source_length\"", "]", "\n", "features", "[", "\"position_lan_src\"", "]", "=", "features_ctx10", "[", "\"source\"", "]", "\n", "#        features[\"\"] = features_ctx10[\"source_length\"]", "\n", "features", "[", "\"context_lan_tgt\"", "]", "=", "features_ctx11", "[", "\"source\"", "]", "\n", "features", "[", "\"context_lan_tgt_length\"", "]", "=", "features_ctx11", "[", "\"source_length\"", "]", "\n", "features", "[", "\"position_lan_tgt\"", "]", "=", "features_ctx12", "[", "\"source\"", "]", "\n", "#        features[\"\"] = features_ctx12[\"source_length\"]", "\n", "features", "[", "\"emotion\"", "]", "=", "features_ctx13", "[", "\"source\"", "]", "\n", "#        features[\"\"] = features_ctx13[\"source_length\"]", "\n", "# Create placeholders", "\n", "placeholders", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "params", ".", "device_list", ")", ")", ":", "\n", "            ", "placeholders", ".", "append", "(", "{", "\n", "\"source\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\n", "\"source_%d\"", "%", "i", ")", ",", "\n", "\"source_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\n", "\"source_length_%d\"", "%", "i", ")", ",", "\n", "\"context_dia_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_dia_src_%d\"", "%", "i", ")", ",", "\n", "\"context_dia_src_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_dia_src_length_%d\"", "%", "i", ")", ",", "\n", "\"context_dia_tgt\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_dia_tgt_%d\"", "%", "i", ")", ",", "\n", "\"context_dia_tgt_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_dia_tgt_length_%d\"", "%", "i", ")", ",", "\n", "\"context_sty_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_sty_src_%d\"", "%", "i", ")", ",", "\n", "\"context_sty_src_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_sty_src_length_%d\"", "%", "i", ")", ",", "\n", "\"context_sty_tgt\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_sty_tgt_%d\"", "%", "i", ")", ",", "\n", "\"context_sty_tgt_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_sty_tgt_length_%d\"", "%", "i", ")", ",", "\n", "\"context_lan_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_lan_src_%d\"", "%", "i", ")", ",", "\n", "\"context_lan_src_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_lan_src_length_%d\"", "%", "i", ")", ",", "\n", "\"context_lan_tgt\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_lan_tgt_%d\"", "%", "i", ")", ",", "\n", "\"context_lan_tgt_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_lan_tgt_length_%d\"", "%", "i", ")", ",", "\n", "\"emotion\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"emotion_%d\"", "%", "i", ")", ",", "\n", "\"position_dia_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_dia_src_%d\"", "%", "i", ")", ",", "\n", "\"position_dia_tgt\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_dia_tgt_%d\"", "%", "i", ")", ",", "\n", "\"position_sty_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_sty_src_%d\"", "%", "i", ")", ",", "\n", "\"position_sty_tgt\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_sty_tgt_%d\"", "%", "i", ")", ",", "\n", "\"position_lan_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_lan_src_%d\"", "%", "i", ")", ",", "\n", "\"position_lan_tgt\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_lan_tgt_%d\"", "%", "i", ")", "\n", "}", ")", "\n", "\n", "# A list of outputs", "\n", "", "predictions", "=", "parallel", ".", "data_parallelism", "(", "\n", "params", ".", "device_list", ",", "\n", "lambda", "f", ":", "inference", ".", "create_inference_graph", "(", "model_fns", ",", "f", ",", "params", ")", ",", "\n", "placeholders", ")", "\n", "\n", "# Create assign ops", "\n", "assign_ops", "=", "[", "]", "\n", "\n", "all_var_list", "=", "tf", ".", "all_variables", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "args", ".", "checkpoints", ")", ")", ":", "\n", "            ", "un_init_var_list", "=", "[", "]", "\n", "name", "=", "model_cls_list", "[", "i", "]", ".", "get_name", "(", ")", "\n", "\n", "for", "v", "in", "all_var_list", ":", "\n", "                ", "if", "v", ".", "name", ".", "startswith", "(", "name", "+", "\"_%d\"", "%", "i", ")", ":", "\n", "                    ", "un_init_var_list", ".", "append", "(", "v", ")", "\n", "\n", "", "", "ops", "=", "set_variables", "(", "un_init_var_list", ",", "model_var_lists", "[", "i", "]", ",", "\n", "name", "+", "\"_%d\"", "%", "i", ")", "\n", "assign_ops", ".", "extend", "(", "ops", ")", "\n", "\n", "", "assign_op", "=", "tf", ".", "group", "(", "*", "assign_ops", ")", "\n", "results", "=", "[", "]", "\n", "\n", "# Create session", "\n", "with", "tf", ".", "Session", "(", "config", "=", "session_config", "(", "params", ")", ")", "as", "sess", ":", "\n", "# Restore variables", "\n", "            ", "sess", ".", "run", "(", "assign_op", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "                    ", "feats", "=", "sess", ".", "run", "(", "features", ")", "\n", "op", ",", "feed_dict", "=", "shard_features", "(", "feats", ",", "placeholders", ",", "\n", "predictions", ")", "\n", "res", "=", "sess", ".", "run", "(", "predictions", ",", "feed_dict", "=", "feed_dict", ")", "\n", "results", ".", "append", "(", "res", ")", "\n", "print", "(", "\"res:\"", ",", "res", ")", "\n", "message", "=", "\"Finished batch %d\"", "%", "len", "(", "results", ")", "\n", "tf", ".", "logging", ".", "log", "(", "tf", ".", "logging", ".", "INFO", ",", "message", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "break", "\n", "\n", "# Convert to plain text", "\n", "", "", "", "vocab", "=", "params", ".", "vocabulary", "[", "\"target\"", "]", "\n", "outputs", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "\n", "for", "result", "in", "results", ":", "\n", "            ", "for", "item", "in", "result", "[", "0", "]", ":", "\n", "                ", "outputs", ".", "append", "(", "item", ".", "tolist", "(", ")", ")", "\n", "", "for", "item", "in", "result", "[", "1", "]", ":", "\n", "                ", "scores", ".", "append", "(", "item", ".", "tolist", "(", ")", ")", "\n", "\n", "", "", "outputs", "=", "list", "(", "itertools", ".", "chain", "(", "*", "outputs", ")", ")", "\n", "scores", "=", "list", "(", "itertools", ".", "chain", "(", "*", "scores", ")", ")", "\n", "\n", "restored_inputs", "=", "[", "]", "\n", "restored_outputs", "=", "[", "]", "\n", "restored_scores", "=", "[", "]", "\n", "\n", "for", "index", "in", "range", "(", "len", "(", "sorted_inputs", ")", ")", ":", "\n", "            ", "restored_inputs", ".", "append", "(", "sorted_inputs", "[", "sorted_keys", "[", "index", "]", "]", ")", "\n", "restored_outputs", ".", "append", "(", "outputs", "[", "sorted_keys", "[", "index", "]", "]", ")", "\n", "restored_scores", ".", "append", "(", "scores", "[", "sorted_keys", "[", "index", "]", "]", ")", "\n", "\n", "# Write to file", "\n", "", "with", "open", "(", "args", ".", "output", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "            ", "count", "=", "0", "\n", "for", "outputs", ",", "scores", "in", "zip", "(", "restored_outputs", ",", "restored_scores", ")", ":", "\n", "                ", "for", "output", ",", "score", "in", "zip", "(", "outputs", ",", "scores", ")", ":", "\n", "                    ", "decoded", "=", "[", "]", "\n", "for", "idx", "in", "output", ":", "\n", "                        ", "if", "idx", "==", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "eos", "]", ":", "\n", "                            ", "break", "\n", "", "decoded", ".", "append", "(", "vocab", "[", "idx", "]", ")", "\n", "\n", "", "decoded", "=", "\" \"", ".", "join", "(", "decoded", ")", "\n", "\n", "if", "not", "args", ".", "verbose", ":", "\n", "                        ", "outfile", ".", "write", "(", "\"%s\\n\"", "%", "decoded", ")", "\n", "break", "\n", "", "else", ":", "\n", "                        ", "pattern", "=", "\"%d ||| %s ||| %s ||| %f\\n\"", "\n", "source", "=", "restored_inputs", "[", "count", "]", "\n", "values", "=", "(", "count", ",", "source", ",", "decoded", ",", "score", ")", "\n", "outfile", ".", "write", "(", "pattern", "%", "values", ")", "\n", "\n", "", "", "count", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_bak.parse_args": [[25, 65], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Translate using existing NMT models\"", ",", "\n", "usage", "=", "\"translator.py [<args>] [-h | --help]\"", "\n", ")", "\n", "\n", "# input files", "\n", "parser", ".", "add_argument", "(", "\"--input\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of input file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of output file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoints\"", ",", "type", "=", "str", ",", "nargs", "=", "\"+\"", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of trained models\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocabulary\"", ",", "type", "=", "str", ",", "nargs", "=", "2", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of source and target vocabulary\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dev_dialog_src_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_dialog_tgt_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_style_src_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_style_tgt_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_language_src_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_language_tgt_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dev_emotion\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to dev_emotion file\"", ")", "\n", "# model and configuration", "\n", "parser", ".", "add_argument", "(", "\"--models\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"Name of the model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--parameters\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Additional hyper parameters\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--verbose\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Enable verbose output\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_bak.default_parameters": [[67, 101], ["tensorflow.contrib.training.HParams"], "function", ["None"], ["", "def", "default_parameters", "(", ")", ":", "\n", "    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "input", "=", "None", ",", "\n", "output", "=", "None", ",", "\n", "vocabulary", "=", "None", ",", "\n", "# vocabulary specific", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "bos", "=", "\"<bos>\"", ",", "\n", "eos", "=", "\"<eos>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "mapping", "=", "None", ",", "\n", "append_eos", "=", "False", ",", "\n", "device_list", "=", "[", "0", "]", ",", "\n", "num_threads", "=", "1", ",", "\n", "# decoding", "\n", "top_beams", "=", "1", ",", "\n", "beam_size", "=", "4", ",", "\n", "decode_alpha", "=", "0.6", ",", "\n", "decode_length", "=", "50", ",", "\n", "embedding_path", "=", "\"/mnt/yardcephfs/mmyard/g_wxg_td_prc/yunlonliang/4.sa/embedding/glove.840B.300d.emotion.txt\"", ",", "\n", "start_steps", "=", "0", ",", "\n", "kl_annealing_steps", "=", "10000", ",", "\n", "decode_batch_size", "=", "32", ",", "\n", "# sampling", "\n", "generate_samples", "=", "False", ",", "\n", "num_samples", "=", "1", ",", "\n", "min_length_ratio", "=", "0.0", ",", "\n", "max_length_ratio", "=", "1.5", ",", "\n", "min_sample_length", "=", "0", ",", "\n", "max_sample_length", "=", "0", ",", "\n", "sample_batch_size", "=", "32", "\n", ")", "\n", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_bak.merge_parameters": [[103, 119], ["tensorflow.contrib.training.HParams", "six.iteritems", "tf.contrib.training.HParams.values", "six.iteritems", "params1.values", "tf.contrib.training.HParams.add_hparam", "params2.values", "setattr", "tf.contrib.training.HParams.add_hparam"], "function", ["None"], ["", "def", "merge_parameters", "(", "params1", ",", "params2", ")", ":", "\n", "    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", ")", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "params1", ".", "values", "(", ")", ")", ":", "\n", "        ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "params_dict", "=", "params", ".", "values", "(", ")", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "params2", ".", "values", "(", ")", ")", ":", "\n", "        ", "if", "k", "in", "params_dict", ":", "\n", "# Override", "\n", "            ", "setattr", "(", "params", ",", "k", ",", "v", ")", "\n", "", "else", ":", "\n", "            ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_bak.import_params": [[121, 137], ["model_name.startswith", "os.path.abspath", "os.path.join", "tensorflow.gfile.Exists", "tensorflow.gfile.Open", "tensorflow.logging.info", "fd.readline", "params.parse_json"], "function", ["None"], ["", "def", "import_params", "(", "model_dir", ",", "model_name", ",", "params", ")", ":", "\n", "    ", "if", "model_name", ".", "startswith", "(", "\"experimental_\"", ")", ":", "\n", "        ", "model_name", "=", "model_name", "[", "13", ":", "]", "\n", "\n", "", "model_dir", "=", "os", ".", "path", ".", "abspath", "(", "model_dir", ")", "\n", "m_name", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "model_name", "+", "\".json\"", ")", "\n", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "m_name", ")", ":", "\n", "        ", "return", "params", "\n", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "m_name", ")", "as", "fd", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "\"Restoring model parameters from %s\"", "%", "m_name", ")", "\n", "json_str", "=", "fd", ".", "readline", "(", ")", "\n", "params", ".", "parse_json", "(", "json_str", ")", "\n", "\n", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_bak.override_parameters": [[139, 179], ["thumt.process_vocabulary", "thumt.process_vocabulary", "params.parse", "thumt.load_vocabulary", "thumt.load_vocabulary", "thumt.get_control_mapping", "thumt.get_control_mapping"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.get_control_mapping", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.get_control_mapping"], ["", "def", "override_parameters", "(", "params", ",", "args", ")", ":", "\n", "    ", "if", "args", ".", "parameters", ":", "\n", "        ", "params", ".", "parse", "(", "args", ".", "parameters", ")", "\n", "\n", "\n", "", "params", ".", "dev_dialog_src_context", "=", "args", ".", "dev_dialog_src_context", "#or params.dev_dialog_src_context", "\n", "params", ".", "dev_dialog_tgt_context", "=", "args", ".", "dev_dialog_tgt_context", "#or params.dev_dialog_tgt_context", "\n", "params", ".", "dev_style_src_context", "=", "args", ".", "dev_style_src_context", "#or params.dev_style_src_context", "\n", "params", ".", "dev_style_tgt_context", "=", "args", ".", "dev_style_tgt_context", "#or params.dev_style_tgt_context", "\n", "params", ".", "dev_language_src_context", "=", "args", ".", "dev_language_src_context", "#or params.dev_language_src_context", "\n", "params", ".", "dev_language_tgt_context", "=", "args", ".", "dev_language_tgt_context", "#or params.dev_language_tgt_context", "\n", "params", ".", "dev_emotion", "=", "args", ".", "dev_emotion", "or", "params", ".", "dev_emotion", "\n", "\n", "params", ".", "vocabulary", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "load_vocabulary", "(", "args", ".", "vocabulary", "[", "0", "]", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "load_vocabulary", "(", "args", ".", "vocabulary", "[", "1", "]", ")", ",", "\n", "\"emotion\"", ":", "[", "'neutral'", ",", "'joy'", ",", "'anger'", ",", "'surprise'", ",", "'sadness'", ",", "'fear'", ",", "'disgust'", ",", "'happiness'", ",", "'happy'", ",", "'other'", "]", ",", "\n", "\"position\"", ":", "[", "'0'", ",", "'1'", ",", "'2'", ",", "'3'", ",", "'4'", ",", "'5'", ",", "'6'", ",", "'7'", ",", "'8'", ",", "'9'", ",", "'10'", "]", "\n", "}", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "params", "\n", ")", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "params", "\n", ")", "\n", "\n", "control_symbols", "=", "[", "params", ".", "pad", ",", "params", ".", "bos", ",", "params", ".", "eos", ",", "params", ".", "unk", "]", "\n", "\n", "params", ".", "mapping", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "\n", "control_symbols", "\n", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "\n", "control_symbols", "\n", ")", "\n", "}", "\n", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_bak.session_config": [[181, 192], ["tensorflow.OptimizerOptions", "tensorflow.GraphOptions", "tensorflow.ConfigProto", "str"], "function", ["None"], ["", "def", "session_config", "(", "params", ")", ":", "\n", "    ", "optimizer_options", "=", "tf", ".", "OptimizerOptions", "(", "opt_level", "=", "tf", ".", "OptimizerOptions", ".", "L1", ",", "\n", "do_function_inlining", "=", "False", ")", "\n", "graph_options", "=", "tf", ".", "GraphOptions", "(", "optimizer_options", "=", "optimizer_options", ")", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ",", "\n", "graph_options", "=", "graph_options", ")", "\n", "if", "params", ".", "device_list", ":", "\n", "        ", "device_str", "=", "\",\"", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "params", ".", "device_list", "]", ")", "\n", "config", ".", "gpu_options", ".", "visible_device_list", "=", "device_str", "\n", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_bak.set_variables": [[194, 211], ["tensorflow.logging.debug", "tensorflow.placeholder", "list", "tensorflow.device", "tensorflow.assign", "ops.append", "name.split"], "function", ["None"], ["", "def", "set_variables", "(", "var_list", ",", "value_dict", ",", "prefix", ",", "feed_dict", ")", ":", "\n", "    ", "ops", "=", "[", "]", "\n", "for", "var", "in", "var_list", ":", "\n", "        ", "for", "name", "in", "value_dict", ":", "\n", "            ", "var_name", "=", "\"/\"", ".", "join", "(", "[", "prefix", "]", "+", "list", "(", "name", ".", "split", "(", "\"/\"", ")", "[", "1", ":", "]", ")", ")", "\n", "\n", "if", "var", ".", "name", "[", ":", "-", "2", "]", "==", "var_name", ":", "\n", "                ", "tf", ".", "logging", ".", "debug", "(", "\"restoring %s -> %s\"", "%", "(", "name", ",", "var", ".", "name", ")", ")", "\n", "placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "\n", "name", "=", "\"placeholder/\"", "+", "var_name", ")", "\n", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "                    ", "op", "=", "tf", ".", "assign", "(", "var", ",", "placeholder", ")", "\n", "ops", ".", "append", "(", "op", ")", "\n", "", "feed_dict", "[", "placeholder", "]", "=", "value_dict", "[", "name", "]", "\n", "break", "\n", "\n", "", "", "", "return", "ops", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_bak.shard_features": [[213, 236], ["len", "isinstance", "range"], "function", ["None"], ["", "def", "shard_features", "(", "features", ",", "placeholders", ",", "predictions", ")", ":", "\n", "    ", "num_shards", "=", "len", "(", "placeholders", ")", "\n", "feed_dict", "=", "{", "}", "\n", "n", "=", "0", "\n", "\n", "for", "name", "in", "features", ":", "\n", "        ", "feat", "=", "features", "[", "name", "]", "\n", "batch", "=", "feat", ".", "shape", "[", "0", "]", "\n", "shard_size", "=", "(", "batch", "+", "num_shards", "-", "1", ")", "//", "num_shards", "\n", "\n", "for", "i", "in", "range", "(", "num_shards", ")", ":", "\n", "            ", "shard_feat", "=", "feat", "[", "i", "*", "shard_size", ":", "(", "i", "+", "1", ")", "*", "shard_size", "]", "\n", "\n", "if", "shard_feat", ".", "shape", "[", "0", "]", "!=", "0", ":", "\n", "                ", "feed_dict", "[", "placeholders", "[", "i", "]", "[", "name", "]", "]", "=", "shard_feat", "\n", "n", "=", "i", "+", "1", "\n", "", "else", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "if", "isinstance", "(", "predictions", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "predictions", "=", "predictions", "[", ":", "n", "]", "\n", "\n", "", "return", "predictions", ",", "feed_dict", "\n", "", "def", "get_turn_position", "(", "file1", ")", ":", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_bak.get_turn_position": [[236, 258], ["open", "fr.readlines", "turn_position.append", "file1.split", "open", "line.split", "tmp.append", "file1.split", "sorted", "fw.write", "str"], "function", ["None"], ["", "def", "get_turn_position", "(", "file1", ")", ":", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "content", "=", "fr", ".", "readlines", "(", ")", "\n", "", "turn_position", "=", "[", "]", "\n", "for", "line", "in", "content", ":", "\n", "        ", "tmp", "=", "[", "]", "\n", "index", "=", "1", "\n", "for", "i", "in", "line", ".", "split", "(", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "#tmp.append(str(index))", "\n", "            ", "if", "i", "==", "'[SEP]'", ":", "\n", "                ", "index", "+=", "1", "\n", "", "tmp", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "", "turn_position", ".", "append", "(", "tmp", ")", "\n", "", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.turn_position'", "\n", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_bak.main": [[259, 500], ["tensorflow.logging.set_verbosity", "thumt.get_model", "translator_bak.default_parameters", "translator_bak.merge_parameters", "translator_bak.import_params", "translator_bak.override_parameters", "tensorflow.Graph().as_default", "enumerate", "range", "translator_bak.get_turn_position", "translator_bak.get_turn_position", "translator_bak.get_turn_position", "translator_bak.get_turn_position", "translator_bak.get_turn_position", "translator_bak.get_turn_position", "thumt.sort_input_file_ctx", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "thumt.get_inference_input", "range", "thumt.data_parallelism", "tensorflow.trainable_variables", "range", "tensorflow.group", "tensorflow.tables_initializer", "tensorflow.get_default_graph().finalize", "range", "zip", "open.close", "range", "model_cls.get_parameters", "zip", "range", "range", "tensorflow.logging.info", "tensorflow.train.list_variables", "tensorflow.train.load_checkpoint", "model_var_lists.append", "len", "model_cls_list[].get_name", "model_list.append", "len", "placeholders.append", "len", "model_cls_list[].get_name", "translator_bak.set_variables", "assign_ops.extend", "tensorflow.Session", "sess.run", "sess.run", "len", "restored_inputs.append", "restored_outputs.append", "restored_scores.append", "open", "zip", "len", "len", "len", "tensorflow.Graph", "tf.train.load_checkpoint.get_tensor", "inference_fn", "v.name.startswith", "tensorflow.get_default_graph", "open", "ValueError", "model_cls_list[].get_name.startswith", "model_cls_list[].get_name.find", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "un_init_var_list.append", "translator_bak.session_config", "sess.run", "translator_bak.shard_features", "sess.run", "results.append", "tensorflow.logging.log", "outputs.append", "scores.append", "decoded.append", "open.write", "open.write", "model_cls_list[].get_name", "len", "item.tolist", "item.tolist"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.__init__.get_model", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.default_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.merge_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.import_params", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.override_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.sort_input_file_ctx", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo.data_parallelism", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_name", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_name", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.set_variables", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.session_config", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.translator_bak.shard_features", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_name"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "# Load configs", "\n", "model_cls_list", "=", "[", "models", ".", "get_model", "(", "model", ")", "for", "model", "in", "args", ".", "models", "]", "\n", "params_list", "=", "[", "default_parameters", "(", ")", "for", "_", "in", "range", "(", "len", "(", "model_cls_list", ")", ")", "]", "\n", "params_list", "=", "[", "\n", "merge_parameters", "(", "params", ",", "model_cls", ".", "get_parameters", "(", ")", ")", "\n", "for", "params", ",", "model_cls", "in", "zip", "(", "params_list", ",", "model_cls_list", ")", "\n", "]", "\n", "params_list", "=", "[", "\n", "import_params", "(", "args", ".", "checkpoints", "[", "i", "]", ",", "args", ".", "models", "[", "i", "]", ",", "params_list", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "args", ".", "checkpoints", ")", ")", "\n", "]", "\n", "params_list", "=", "[", "\n", "override_parameters", "(", "params_list", "[", "i", "]", ",", "args", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "model_cls_list", ")", ")", "\n", "]", "\n", "\n", "# Build Graph", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "model_var_lists", "=", "[", "]", "\n", "\n", "# Load checkpoints", "\n", "for", "i", ",", "checkpoint", "in", "enumerate", "(", "args", ".", "checkpoints", ")", ":", "\n", "            ", "tf", ".", "logging", ".", "info", "(", "\"Loading %s\"", "%", "checkpoint", ")", "\n", "var_list", "=", "tf", ".", "train", ".", "list_variables", "(", "checkpoint", ")", "\n", "values", "=", "{", "}", "\n", "reader", "=", "tf", ".", "train", ".", "load_checkpoint", "(", "checkpoint", ")", "\n", "\n", "for", "(", "name", ",", "shape", ")", "in", "var_list", ":", "\n", "                ", "if", "not", "name", ".", "startswith", "(", "model_cls_list", "[", "i", "]", ".", "get_name", "(", ")", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "name", ".", "find", "(", "\"losses_avg\"", ")", ">=", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "tensor", "=", "reader", ".", "get_tensor", "(", "name", ")", "\n", "values", "[", "name", "]", "=", "tensor", "\n", "\n", "", "model_var_lists", ".", "append", "(", "values", ")", "\n", "\n", "# Build models", "\n", "", "model_list", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "args", ".", "checkpoints", ")", ")", ":", "\n", "            ", "name", "=", "model_cls_list", "[", "i", "]", ".", "get_name", "(", ")", "\n", "model", "=", "model_cls_list", "[", "i", "]", "(", "params_list", "[", "i", "]", ",", "name", "+", "\"_%d\"", "%", "i", ")", "\n", "model_list", ".", "append", "(", "model", ")", "\n", "\n", "", "params", "=", "params_list", "[", "0", "]", "\n", "# Read input file", "\n", "#        sorted_keys, sorted_inputs = dataset.sort_input_file(args.input)", "\n", "# Build input queue", "\n", "#        features = dataset.get_inference_input(sorted_inputs, params)", "\n", "position_file_src_dia", "=", "get_turn_position", "(", "params", ".", "dev_dialog_src_context", ")", "\n", "#            position_file_src_dia, dialog_file = get_turn_position_src(params.validation, params.dialog_src_context)", "\n", "\n", "position_file_tgt_dia", "=", "get_turn_position", "(", "params", ".", "dev_dialog_tgt_context", ")", "\n", "position_file_src_sty", "=", "get_turn_position", "(", "params", ".", "dev_style_src_context", ")", "\n", "position_file_tgt_sty", "=", "get_turn_position", "(", "params", ".", "dev_style_tgt_context", ")", "\n", "position_file_src_lan", "=", "get_turn_position", "(", "params", ".", "dev_language_src_context", ")", "\n", "position_file_tgt_lan", "=", "get_turn_position", "(", "params", ".", "dev_language_tgt_context", ")", "\n", "\n", "sorted_keys", ",", "sorted_inputs", ",", "dialog_src_context", ",", "pos_src_dia", ",", "dialog_tgt_context", ",", "pos_tgt_dia", ",", "style_src_context", ",", "pos_src_sty", ",", "style_tgt_context", ",", "pos_tgt_sty", ",", "language_src_context", ",", "pos_src_lan", ",", "language_tgt_context", ",", "pos_tgt_lan", ",", "emo", "=", "dataset", ".", "sort_input_file_ctx", "(", "args", ".", "input", ",", "params", ".", "dev_dialog_src_context", ",", "position_file_src_dia", ",", "params", ".", "dev_dialog_tgt_context", ",", "position_file_tgt_dia", ",", "params", ".", "dev_style_src_context", ",", "position_file_src_sty", ",", "params", ".", "dev_style_tgt_context", ",", "position_file_tgt_sty", ",", "params", ".", "dev_language_src_context", ",", "position_file_src_lan", ",", "params", ".", "dev_language_tgt_context", ",", "position_file_tgt_lan", ",", "params", ".", "dev_emotion", ")", "\n", "# Build input queue", "\n", "features", "=", "dataset", ".", "get_inference_input", "(", "sorted_inputs", ",", "\"x\"", ",", "params", ")", "\n", "#        features_ctx = dataset.get_inference_input(sorted_ctxs, params)", "\n", "\n", "features_ctx1", "=", "dataset", ".", "get_inference_input", "(", "dialog_src_context", ",", "\"ctx\"", ",", "params", ")", "\n", "features_ctx2", "=", "dataset", ".", "get_inference_input", "(", "pos_src_dia", ",", "\"pos\"", ",", "params", ")", "\n", "features_ctx3", "=", "dataset", ".", "get_inference_input", "(", "dialog_tgt_context", ",", "\"ctx\"", ",", "params", ")", "\n", "features_ctx4", "=", "dataset", ".", "get_inference_input", "(", "pos_tgt_dia", ",", "\"pos\"", ",", "params", ")", "\n", "features_ctx5", "=", "dataset", ".", "get_inference_input", "(", "style_src_context", ",", "\"ctx\"", ",", "params", ")", "\n", "features_ctx6", "=", "dataset", ".", "get_inference_input", "(", "pos_src_sty", ",", "\"pos\"", ",", "params", ")", "\n", "features_ctx7", "=", "dataset", ".", "get_inference_input", "(", "style_tgt_context", ",", "\"ctx\"", ",", "params", ")", "\n", "features_ctx8", "=", "dataset", ".", "get_inference_input", "(", "pos_tgt_sty", ",", "\"pos\"", ",", "params", ")", "\n", "features_ctx9", "=", "dataset", ".", "get_inference_input", "(", "language_src_context", ",", "\"ctx\"", ",", "params", ")", "\n", "features_ctx10", "=", "dataset", ".", "get_inference_input", "(", "pos_src_lan", ",", "\"pos\"", ",", "params", ")", "\n", "features_ctx11", "=", "dataset", ".", "get_inference_input", "(", "language_tgt_context", ",", "\"ctx\"", ",", "params", ")", "\n", "features_ctx12", "=", "dataset", ".", "get_inference_input", "(", "pos_tgt_lan", ",", "\"pos\"", ",", "params", ")", "\n", "features_ctx13", "=", "dataset", ".", "get_inference_input", "(", "emo", ",", "\"emo\"", ",", "params", ")", "\n", "# Create placeholders", "\n", "placeholders", "=", "[", "]", "\n", "\n", "features", "[", "\"context_dia_src\"", "]", "=", "features_ctx1", "[", "\"source\"", "]", "\n", "features", "[", "\"context_dia_src_length\"", "]", "=", "features_ctx1", "[", "\"source_length\"", "]", "\n", "features", "[", "\"position_dia_src\"", "]", "=", "features_ctx2", "[", "\"source\"", "]", "\n", "#        features[\"\"] = features_ctx2[\"source_length\"]", "\n", "features", "[", "\"context_dia_tgt\"", "]", "=", "features_ctx3", "[", "\"source\"", "]", "\n", "features", "[", "\"context_dia_tgt_length\"", "]", "=", "features_ctx3", "[", "\"source_length\"", "]", "\n", "features", "[", "\"position_dia_tgt\"", "]", "=", "features_ctx4", "[", "\"source\"", "]", "\n", "#       features[\"\"] = features_ctx4[\"source_length\"]", "\n", "features", "[", "\"context_sty_src\"", "]", "=", "features_ctx5", "[", "\"source\"", "]", "\n", "features", "[", "\"context_sty_src_length\"", "]", "=", "features_ctx5", "[", "\"source_length\"", "]", "\n", "features", "[", "\"position_sty_src\"", "]", "=", "features_ctx6", "[", "\"source\"", "]", "\n", "#        features[\"\"] = features_ctx6[\"source_length\"]", "\n", "features", "[", "\"context_sty_tgt\"", "]", "=", "features_ctx7", "[", "\"source\"", "]", "\n", "features", "[", "\"context_sty_tgt_length\"", "]", "=", "features_ctx7", "[", "\"source_length\"", "]", "\n", "features", "[", "\"position_sty_tgt\"", "]", "=", "features_ctx8", "[", "\"source\"", "]", "\n", "#        features[\"\"] = features_ctx8[\"source_length\"]", "\n", "features", "[", "\"context_lan_src\"", "]", "=", "features_ctx9", "[", "\"source\"", "]", "\n", "features", "[", "\"context_lan_src_length\"", "]", "=", "features_ctx9", "[", "\"source_length\"", "]", "\n", "features", "[", "\"position_lan_src\"", "]", "=", "features_ctx10", "[", "\"source\"", "]", "\n", "#        features[\"\"] = features_ctx10[\"source_length\"]", "\n", "features", "[", "\"context_lan_tgt\"", "]", "=", "features_ctx11", "[", "\"source\"", "]", "\n", "features", "[", "\"context_lan_tgt_length\"", "]", "=", "features_ctx11", "[", "\"source_length\"", "]", "\n", "features", "[", "\"position_lan_tgt\"", "]", "=", "features_ctx12", "[", "\"source\"", "]", "\n", "#        features[\"\"] = features_ctx12[\"source_length\"]", "\n", "features", "[", "\"emotion\"", "]", "=", "features_ctx13", "[", "\"source\"", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "params", ".", "device_list", ")", ")", ":", "\n", "            ", "placeholders", ".", "append", "(", "{", "\n", "\"source\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\n", "\"source_%d\"", "%", "i", ")", ",", "\n", "\"source_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\n", "\"source_length_%d\"", "%", "i", ")", ",", "\n", "\"context_dia_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_dia_src_%d\"", "%", "i", ")", ",", "\n", "\"context_dia_src_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_dia_src_length_%d\"", "%", "i", ")", ",", "\n", "\"context_dia_tgt\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_dia_tgt_%d\"", "%", "i", ")", ",", "\n", "\"context_dia_tgt_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_dia_tgt_length_%d\"", "%", "i", ")", ",", "\n", "\"context_sty_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_sty_src_%d\"", "%", "i", ")", ",", "\n", "\"context_sty_src_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_sty_src_length_%d\"", "%", "i", ")", ",", "\n", "\"context_sty_tgt\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_sty_tgt_%d\"", "%", "i", ")", ",", "\n", "\"context_sty_tgt_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_sty_tgt_length_%d\"", "%", "i", ")", ",", "\n", "\"context_lan_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_lan_src_%d\"", "%", "i", ")", ",", "\n", "\"context_lan_src_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_lan_src_length_%d\"", "%", "i", ")", ",", "\n", "\"context_lan_tgt\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"context_lan_tgt_%d\"", "%", "i", ")", ",", "\n", "\"context_lan_tgt_length\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\"context_lan_tgt_length_%d\"", "%", "i", ")", ",", "\n", "\"emotion\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"emotion_%d\"", "%", "i", ")", ",", "\n", "\"position_dia_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_dia_src_%d\"", "%", "i", ")", ",", "\n", "\"position_dia_tgt\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_dia_tgt_%d\"", "%", "i", ")", ",", "\n", "\"position_sty_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_sty_src_%d\"", "%", "i", ")", ",", "\n", "\"position_sty_tgt\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_sty_tgt_%d\"", "%", "i", ")", ",", "\n", "\"position_lan_src\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_lan_src_%d\"", "%", "i", ")", ",", "\n", "\"position_lan_tgt\"", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", "]", ",", "\"position_lan_tgt_%d\"", "%", "i", ")", "\n", "}", ")", "\n", "\n", "# A list of outputs", "\n", "", "if", "params", ".", "generate_samples", ":", "\n", "            ", "inference_fn", "=", "sampling", ".", "create_sampling_graph", "\n", "", "else", ":", "\n", "            ", "inference_fn", "=", "inference", ".", "create_inference_graph", "\n", "\n", "", "predictions", "=", "parallel", ".", "data_parallelism", "(", "\n", "params", ".", "device_list", ",", "lambda", "f", ":", "inference_fn", "(", "model_list", ",", "f", ",", "params", ")", ",", "\n", "placeholders", ")", "\n", "\n", "# Create assign ops", "\n", "assign_ops", "=", "[", "]", "\n", "feed_dict", "=", "{", "}", "\n", "\n", "all_var_list", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "args", ".", "checkpoints", ")", ")", ":", "\n", "            ", "un_init_var_list", "=", "[", "]", "\n", "name", "=", "model_cls_list", "[", "i", "]", ".", "get_name", "(", ")", "\n", "\n", "for", "v", "in", "all_var_list", ":", "\n", "                ", "if", "v", ".", "name", ".", "startswith", "(", "name", "+", "\"_%d\"", "%", "i", ")", ":", "\n", "                    ", "un_init_var_list", ".", "append", "(", "v", ")", "\n", "\n", "", "", "ops", "=", "set_variables", "(", "un_init_var_list", ",", "model_var_lists", "[", "i", "]", ",", "\n", "name", "+", "\"_%d\"", "%", "i", ",", "feed_dict", ")", "\n", "assign_ops", ".", "extend", "(", "ops", ")", "\n", "\n", "", "assign_op", "=", "tf", ".", "group", "(", "*", "assign_ops", ")", "\n", "init_op", "=", "tf", ".", "tables_initializer", "(", ")", "\n", "results", "=", "[", "]", "\n", "\n", "tf", ".", "get_default_graph", "(", ")", ".", "finalize", "(", ")", "\n", "\n", "# Create session", "\n", "with", "tf", ".", "Session", "(", "config", "=", "session_config", "(", "params", ")", ")", "as", "sess", ":", "\n", "# Restore variables", "\n", "            ", "sess", ".", "run", "(", "assign_op", ",", "feed_dict", "=", "feed_dict", ")", "\n", "sess", ".", "run", "(", "init_op", ")", "\n", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "                    ", "feats", "=", "sess", ".", "run", "(", "features", ")", "\n", "op", ",", "feed_dict", "=", "shard_features", "(", "feats", ",", "placeholders", ",", "\n", "predictions", ")", "\n", "res", "=", "sess", ".", "run", "(", "predictions", ",", "feed_dict", "=", "feed_dict", ")", "\n", "results", ".", "append", "(", "res", ")", "\n", "#                    code.interact(local=locals())#print(\"res:\", res)", "\n", "#                    results.append(sess.run(op, feed_dict=feed_dict))", "\n", "message", "=", "\"Finished batch %d\"", "%", "len", "(", "results", ")", "\n", "tf", ".", "logging", ".", "log", "(", "tf", ".", "logging", ".", "INFO", ",", "message", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "break", "\n", "\n", "# Convert to plain text", "\n", "", "", "", "vocab", "=", "params", ".", "vocabulary", "[", "\"target\"", "]", "\n", "outputs", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "\n", "for", "result", "in", "results", ":", "\n", "            ", "for", "shard", "in", "result", ":", "\n", "                ", "for", "item", "in", "shard", "[", "0", "]", ":", "\n", "                    ", "outputs", ".", "append", "(", "item", ".", "tolist", "(", ")", ")", "\n", "", "for", "item", "in", "shard", "[", "1", "]", ":", "\n", "                    ", "scores", ".", "append", "(", "item", ".", "tolist", "(", ")", ")", "\n", "\n", "", "", "", "restored_inputs", "=", "[", "]", "\n", "restored_outputs", "=", "[", "]", "\n", "restored_scores", "=", "[", "]", "\n", "\n", "for", "index", "in", "range", "(", "len", "(", "sorted_inputs", ")", ")", ":", "\n", "            ", "restored_inputs", ".", "append", "(", "sorted_inputs", "[", "sorted_keys", "[", "index", "]", "]", ")", "\n", "restored_outputs", ".", "append", "(", "outputs", "[", "sorted_keys", "[", "index", "]", "]", ")", "\n", "restored_scores", ".", "append", "(", "scores", "[", "sorted_keys", "[", "index", "]", "]", ")", "\n", "\n", "# Write to file", "\n", "", "if", "sys", ".", "version_info", ".", "major", "==", "2", ":", "\n", "            ", "outfile", "=", "open", "(", "args", ".", "output", ",", "\"w\"", ")", "\n", "", "elif", "sys", ".", "version_info", ".", "major", "==", "3", ":", "\n", "            ", "outfile", "=", "open", "(", "args", ".", "output", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unkown python running environment!\"", ")", "\n", "\n", "", "count", "=", "0", "\n", "for", "outputs", ",", "scores", "in", "zip", "(", "restored_outputs", ",", "restored_scores", ")", ":", "\n", "            ", "for", "output", ",", "score", "in", "zip", "(", "outputs", ",", "scores", ")", ":", "\n", "                ", "decoded", "=", "[", "]", "\n", "for", "idx", "in", "output", ":", "\n", "                    ", "if", "idx", "==", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "eos", "]", ":", "\n", "                        ", "break", "\n", "", "decoded", ".", "append", "(", "vocab", "[", "idx", "]", ")", "\n", "\n", "", "decoded", "=", "\" \"", ".", "join", "(", "decoded", ")", "\n", "\n", "if", "not", "args", ".", "verbose", ":", "\n", "                    ", "outfile", ".", "write", "(", "\"%s\\n\"", "%", "decoded", ")", "\n", "", "else", ":", "\n", "                    ", "pattern", "=", "\"%d ||| %s ||| %s ||| %f\\n\"", "\n", "source", "=", "restored_inputs", "[", "count", "]", "\n", "values", "=", "(", "count", ",", "source", ",", "decoded", ",", "score", ")", "\n", "outfile", ".", "write", "(", "pattern", "%", "values", ")", "\n", "\n", "", "", "count", "+=", "1", "\n", "", "outfile", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.parse_args": [[26, 59], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["def", "parse_args", "(", "args", "=", "None", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Training neural machine translation models\"", ",", "\n", "usage", "=", "\"trainer.py [<args>] [-h | --help]\"", "\n", ")", "\n", "\n", "# input files", "\n", "parser", ".", "add_argument", "(", "\"--input\"", ",", "type", "=", "str", ",", "nargs", "=", "2", ",", "\n", "help", "=", "\"Path of source and target corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--record\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to tf.Record data\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "default", "=", "\"train\"", ",", "\n", "help", "=", "\"Path to saved models\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dialog_src_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dialog_tgt_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--style_src_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--style_tgt_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--sample\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of sample corpus\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--context_source\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of sample corpus\"", ")", "\n", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dev_dialog_src_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_dialog_tgt_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_style_src_context\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of dev_context corpus\"", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.default_parameters": [[61, 114], ["tensorflow.contrib.training.HParams"], "function", ["None"], ["help", "=", "\"Path of dev_context corpus\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dev_sample\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of sample corpus\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dev_context_source\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of sample corpus\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--vocabulary\"", ",", "type", "=", "str", ",", "nargs", "=", "3", ",", "\n", "help", "=", "\"Path of source and target vocabulary\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--validation\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of validation file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--references\"", ",", "type", "=", "str", ",", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"Path of reference files\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to pre-trained checkpoint\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--half\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Enable FP16 training\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--distribute\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Enable distributed training\"", ")", "\n", "\n", "# model and configuration", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Name of the model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--parameters\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Additional hyper parameters\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", "args", ")", "\n", "\n", "\n", "", "def", "default_parameters", "(", ")", ":", "\n", "    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "input", "=", "[", "\"\"", ",", "\"\"", "]", ",", "\n", "output", "=", "\"\"", ",", "\n", "record", "=", "\"\"", ",", "\n", "model", "=", "\"transformer\"", ",", "\n", "vocab", "=", "[", "\"\"", ",", "\"\"", "]", ",", "\n", "# Default training hyper parameters", "\n", "num_threads", "=", "6", ",", "\n", "batch_size", "=", "4096", ",", "\n", "max_length", "=", "256", ",", "\n", "length_multiplier", "=", "1", ",", "\n", "mantissa_bits", "=", "2", ",", "\n", "start_steps", "=", "0", ",", "\n", "kl_annealing_steps", "=", "0.1", ",", "\n", "kl_annealing_steps2", "=", "0.1", ",", "\n", "warmup_steps", "=", "4000", ",", "\n", "train_steps", "=", "200000", ",", "\n", "buffer_size", "=", "10000", ",", "\n", "constant_batch_size", "=", "False", ",", "\n", "device_list", "=", "[", "0", "]", ",", "\n", "update_cycle", "=", "1", ",", "\n", "initializer", "=", "\"uniform_unit_scaling\"", ",", "\n", "initializer_gain", "=", "1.0", ",", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.import_params": [[116, 135], ["os.path.abspath", "os.path.join", "os.path.join", "tensorflow.gfile.Open", "tensorflow.logging.info", "fd.readline", "params.parse_json", "tensorflow.gfile.Open", "tensorflow.logging.info", "fd.readline", "params.parse_json", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists"], "function", ["None"], ["scale_l1", "=", "0.0", ",", "\n", "scale_l2", "=", "0.0", ",", "\n", "optimizer", "=", "\"Adam\"", ",", "\n", "adam_beta1", "=", "0.9", ",", "\n", "adam_beta2", "=", "0.999", ",", "\n", "adam_epsilon", "=", "1e-8", ",", "\n", "clip_grad_norm", "=", "5.0", ",", "\n", "learning_rate", "=", "1.0", ",", "\n", "learning_rate_decay", "=", "\"linear_warmup_rsqrt_decay\"", ",", "\n", "learning_rate_boundaries", "=", "[", "0", "]", ",", "\n", "learning_rate_values", "=", "[", "0.0", "]", ",", "\n", "keep_checkpoint_max", "=", "1", ",", "\n", "keep_top_checkpoint_max", "=", "2", ",", "\n", "# Validation", "\n", "eval_steps", "=", "2000", ",", "\n", "eval_secs", "=", "0", ",", "\n", "eval_batch_size", "=", "32", ",", "\n", "top_beams", "=", "1", ",", "\n", "beam_size", "=", "4", ",", "\n", "decode_alpha", "=", "0.6", ",", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.export_params": [[137, 145], ["os.path.join", "tensorflow.gfile.Exists", "tensorflow.gfile.MkDir", "tensorflow.gfile.Open", "fd.write", "params.to_json"], "function", ["None"], ["validation", "=", "\"\"", ",", "\n", "references", "=", "[", "\"\"", "]", ",", "\n", "save_checkpoint_secs", "=", "0", ",", "\n", "save_checkpoint_steps", "=", "5000", ",", "\n", "# Setting this to True can save disk spaces, but cannot restore", "\n", "# training using the saved checkpoint", "\n", "only_save_trainable", "=", "False", "\n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.collect_params": [[147, 154], ["tensorflow.contrib.training.HParams", "six.iterkeys", "params.values", "tf.contrib.training.HParams.add_hparam", "getattr"], "function", ["None"], ["\n", "\n", "", "def", "import_params", "(", "model_dir", ",", "model_name", ",", "params", ")", ":", "\n", "    ", "model_dir", "=", "os", ".", "path", ".", "abspath", "(", "model_dir", ")", "\n", "p_name", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"params.json\"", ")", "\n", "m_name", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "model_name", "+", "\".json\"", ")", "\n", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "p_name", ")", "or", "not", "tf", ".", "gfile", ".", "Exists", "(", "m_name", ")", ":", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.merge_parameters": [[156, 172], ["tensorflow.contrib.training.HParams", "six.iteritems", "tf.contrib.training.HParams.values", "six.iteritems", "params1.values", "tf.contrib.training.HParams.add_hparam", "params2.values", "setattr", "tf.contrib.training.HParams.add_hparam"], "function", ["None"], ["\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "p_name", ")", "as", "fd", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "\"Restoring hyper parameters from %s\"", "%", "p_name", ")", "\n", "json_str", "=", "fd", ".", "readline", "(", ")", "\n", "params", ".", "parse_json", "(", "json_str", ")", "\n", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "m_name", ")", "as", "fd", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "\"Restoring model parameters from %s\"", "%", "m_name", ")", "\n", "json_str", "=", "fd", ".", "readline", "(", ")", "\n", "params", ".", "parse_json", "(", "json_str", ")", "\n", "\n", "", "return", "params", "\n", "\n", "\n", "", "def", "export_params", "(", "output_dir", ",", "name", ",", "params", ")", ":", "\n", "    ", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "output_dir", ")", ":", "\n", "        ", "tf", ".", "gfile", ".", "MkDir", "(", "output_dir", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.override_parameters": [[174, 209], ["params.parse", "thumt.process_vocabulary", "thumt.process_vocabulary", "thumt.load_vocabulary", "thumt.load_vocabulary", "thumt.get_control_mapping", "thumt.get_control_mapping"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.get_control_mapping", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.get_control_mapping"], ["# Save params as params.json", "\n", "", "filename", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "name", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "filename", ",", "\"w\"", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "params", ".", "to_json", "(", ")", ")", "\n", "\n", "\n", "", "", "def", "collect_params", "(", "all_params", ",", "params", ")", ":", "\n", "    ", "collected", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", ")", "\n", "\n", "for", "k", "in", "six", ".", "iterkeys", "(", "params", ".", "values", "(", ")", ")", ":", "\n", "        ", "collected", ".", "add_hparam", "(", "k", ",", "getattr", "(", "all_params", ",", "k", ")", ")", "\n", "\n", "", "return", "collected", "\n", "\n", "\n", "", "def", "merge_parameters", "(", "params1", ",", "params2", ")", ":", "\n", "    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", ")", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "params1", ".", "values", "(", ")", ")", ":", "\n", "        ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "params_dict", "=", "params", ".", "values", "(", ")", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "params2", ".", "values", "(", ")", ")", ":", "\n", "        ", "if", "k", "in", "params_dict", ":", "\n", "# Override", "\n", "            ", "setattr", "(", "params", ",", "k", ",", "v", ")", "\n", "", "else", ":", "\n", "            ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "", "return", "params", "\n", "\n", "\n", "", "def", "override_parameters", "(", "params", ",", "args", ")", ":", "\n", "    ", "params", ".", "model", "=", "args", ".", "model", "\n", "params", ".", "input", "=", "args", ".", "input", "or", "params", ".", "input", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.get_initializer": [[211, 227], ["tensorflow.random_uniform_initializer", "tensorflow.random_normal_initializer", "tensorflow.variance_scaling_initializer", "tensorflow.variance_scaling_initializer", "ValueError"], "function", ["None"], ["params", ".", "dialog_src_context", "=", "args", ".", "dialog_src_context", "# or params.dialog_src_context", "\n", "params", ".", "dialog_tgt_context", "=", "args", ".", "dialog_tgt_context", "#or params.dialog_tgt_context", "\n", "params", ".", "style_src_context", "=", "args", ".", "style_src_context", "\n", "params", ".", "style_tgt_context", "=", "args", ".", "style_tgt_context", "\n", "params", ".", "sample", "=", "args", ".", "sample", "\n", "params", ".", "context_source", "=", "args", ".", "context_source", "\n", "params", ".", "dev_context_source", "=", "args", ".", "dev_context_source", "\n", "\n", "params", ".", "dev_dialog_src_context", "=", "args", ".", "dev_dialog_src_context", "#or params.dev_dialog_src_context", "\n", "params", ".", "dev_dialog_tgt_context", "=", "args", ".", "dev_dialog_tgt_context", "#or params.dev_dialog_tgt_context", "\n", "params", ".", "dev_style_src_context", "=", "args", ".", "dev_style_src_context", "#or params.dev_style_src_context", "\n", "params", ".", "dev_style_tgt_context", "=", "args", ".", "dev_style_tgt_context", "\n", "\n", "params", ".", "dev_sample", "=", "args", ".", "dev_sample", "\n", "params", ".", "record", "=", "args", ".", "record", "or", "params", ".", "record", "\n", "params", ".", "vocab", "=", "args", ".", "vocabulary", "or", "params", ".", "vocab", "\n", "params", ".", "validation", "=", "args", ".", "validation", "or", "params", ".", "validation", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.get_learning_rate_decay": [[229, 246], ["tensorflow.to_float", "tensorflow.to_float", "tensorflow.minimum", "tensorflow.train.piecewise_constant", "tensorflow.to_int32", "ValueError"], "function", ["None"], ["params", ".", "parse", "(", "args", ".", "parameters", ")", "\n", "\n", "params", ".", "vocabulary", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "load_vocabulary", "(", "params", ".", "vocab", "[", "0", "]", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "load_vocabulary", "(", "params", ".", "vocab", "[", "1", "]", ")", ",", "\n", "#        \"position\": ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']", "\n", "\"position\"", ":", "vocabulary", ".", "load_vocabulary", "(", "params", ".", "vocab", "[", "2", "]", ")", "\n", "}", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "params", "\n", ")", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "params", "\n", ")", "\n", "params", ".", "vocabulary", "[", "\"position\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"position\"", "]", ",", "params", "\n", ")", "\n", "control_symbols", "=", "[", "params", ".", "pad", ",", "params", ".", "bos", ",", "params", ".", "eos", ",", "params", ".", "unk", "]", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.session_config": [[248, 262], ["tensorflow.OptimizerOptions", "tensorflow.GraphOptions", "tensorflow.ConfigProto", "thumt.is_distributed_training_mode", "str", "thumt.local_rank", "str"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.is_distributed_training_mode", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.local_rank"], ["params", ".", "mapping", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "\n", "control_symbols", "\n", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "\n", "control_symbols", "\n", ")", "\n", "}", "\n", "\n", "return", "params", "\n", "\n", "\n", "", "def", "get_initializer", "(", "params", ")", ":", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.decode_target_ids": [[264, 288], ["decoded.append", "isinstance", "syms.append", "isinstance", "sym.decode.decode"], "function", ["None"], ["        ", "max_val", "=", "params", ".", "initializer_gain", "\n", "return", "tf", ".", "random_uniform_initializer", "(", "-", "max_val", ",", "max_val", ")", "\n", "", "elif", "params", ".", "initializer", "==", "\"normal\"", ":", "\n", "        ", "return", "tf", ".", "random_normal_initializer", "(", "0.0", ",", "params", ".", "initializer_gain", ")", "\n", "", "elif", "params", ".", "initializer", "==", "\"normal_unit_scaling\"", ":", "\n", "        ", "return", "tf", ".", "variance_scaling_initializer", "(", "params", ".", "initializer_gain", ",", "\n", "mode", "=", "\"fan_avg\"", ",", "\n", "distribution", "=", "\"normal\"", ")", "\n", "", "elif", "params", ".", "initializer", "==", "\"uniform_unit_scaling\"", ":", "\n", "        ", "return", "tf", ".", "variance_scaling_initializer", "(", "params", ".", "initializer_gain", ",", "\n", "mode", "=", "\"fan_avg\"", ",", "\n", "distribution", "=", "\"uniform\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unrecognized initializer: %s\"", "%", "params", ".", "initializer", ")", "\n", "\n", "\n", "", "", "def", "get_learning_rate_decay", "(", "learning_rate", ",", "global_step", ",", "params", ")", ":", "\n", "    ", "if", "params", ".", "learning_rate_decay", "in", "[", "\"linear_warmup_rsqrt_decay\"", ",", "\"noam\"", "]", ":", "\n", "        ", "step", "=", "tf", ".", "to_float", "(", "global_step", ")", "\n", "warmup_steps", "=", "tf", ".", "to_float", "(", "params", ".", "warmup_steps", ")", "\n", "multiplier", "=", "params", ".", "hidden_size", "**", "-", "0.5", "\n", "decay", "=", "multiplier", "*", "tf", ".", "minimum", "(", "(", "step", "+", "1", ")", "*", "(", "warmup_steps", "**", "-", "1.5", ")", ",", "\n", "(", "step", "+", "1", ")", "**", "-", "0.5", ")", "\n", "\n", "return", "learning_rate", "*", "decay", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.restore_variables": [[290, 316], ["tensorflow.logging.info", "tensorflow.train.list_variables", "tensorflow.train.load_checkpoint", "tensorflow.trainable_variables", "tensorflow.group", "tensorflow.no_op", "tf.train.load_checkpoint.get_tensor", "name.split", "var.name.split", "tensorflow.logging.info", "ops.append", "tensorflow.assign"], "function", ["None"], ["        ", "return", "tf", ".", "train", ".", "piecewise_constant", "(", "tf", ".", "to_int32", "(", "global_step", ")", ",", "\n", "params", ".", "learning_rate_boundaries", ",", "\n", "params", ".", "learning_rate_values", ")", "\n", "", "elif", "params", ".", "learning_rate_decay", "==", "\"none\"", ":", "\n", "        ", "return", "learning_rate", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown learning_rate_decay\"", ")", "\n", "\n", "\n", "", "", "def", "session_config", "(", "params", ")", ":", "\n", "    ", "optimizer_options", "=", "tf", ".", "OptimizerOptions", "(", "opt_level", "=", "tf", ".", "OptimizerOptions", ".", "L1", ",", "\n", "do_function_inlining", "=", "True", ")", "\n", "graph_options", "=", "tf", ".", "GraphOptions", "(", "optimizer_options", "=", "optimizer_options", ")", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ",", "\n", "graph_options", "=", "graph_options", ")", "\n", "\n", "if", "distribute", ".", "is_distributed_training_mode", "(", ")", ":", "\n", "        ", "config", ".", "gpu_options", ".", "visible_device_list", "=", "str", "(", "distribute", ".", "local_rank", "(", ")", ")", "\n", "", "elif", "params", ".", "device_list", ":", "\n", "        ", "device_str", "=", "\",\"", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "params", ".", "device_list", "]", ")", "\n", "config", ".", "gpu_options", ".", "visible_device_list", "=", "device_str", "\n", "\n", "", "return", "config", "\n", "\n", "\n", "", "def", "decode_target_ids", "(", "inputs", ",", "params", ")", ":", "\n", "    ", "decoded", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.print_variables": [[318, 329], ["sorted", "tensorflow.logging.info", "list", "tensorflow.logging.info", "numpy.prod().tolist", "tensorflow.trainable_variables", "v.name[].ljust", "str().ljust", "numpy.prod", "str", "numpy.array", "v.shape.as_list"], "function", ["None"], ["\n", "for", "item", "in", "inputs", ":", "\n", "        ", "syms", "=", "[", "]", "\n", "for", "idx", "in", "item", ":", "\n", "            ", "if", "isinstance", "(", "idx", ",", "six", ".", "integer_types", ")", ":", "\n", "                ", "sym", "=", "vocab", "[", "idx", "]", "\n", "", "else", ":", "\n", "                ", "sym", "=", "idx", "\n", "if", "not", "isinstance", "(", "sym", ",", "six", ".", "string_types", ")", ":", "\n", "                    ", "sym", "=", "sym", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n", "", "", "if", "sym", "==", "params", ".", "eos", ":", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.get_turn_position_eos": [[381, 425], ["open", "fr.readlines", "turn_position.append", "mask.append", "file1.split", "os.path.exists", "os.path.exists", "open", "open", "line.strip", "lines.strip().split", "tmp.append", "mask_tmp.append", "len", "len", "print", "file1.split", "os.path.getsize", "os.path.getsize", "sorted", "fw.write", "sorted", "fw.write", "str", "str", "lines.strip().split", "lines.strip", "lines.strip"], "function", ["None"], ["", "def", "get_turn_position_eos", "(", "file1", ")", ":", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "content", "=", "fr", ".", "readlines", "(", ")", "\n", "", "turn_position", "=", "[", "]", "\n", "mask", "=", "[", "]", "\n", "for", "line", "in", "content", ":", "\n", "        ", "tmp", "=", "[", "]", "\n", "mask_tmp", "=", "[", "]", "\n", "index", "=", "0", "\n", "lines", "=", "line", ".", "strip", "(", ")", "+", "\" <eos>\"", "\n", "flag", "=", "0", "\n", "for", "i", "in", "lines", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "#tmp.append(str(index))", "\n", "#            flag = 0", "\n", "            ", "if", "i", "==", "'[SEP]'", ":", "\n", "                ", "index", "+=", "1", "\n", "flag", "=", "1", "\n", "", "tmp", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "mask_tmp", ".", "append", "(", "str", "(", "flag", ")", ")", "\n", "#        if len(lines.split()) != len(tmp):", "\n", "", "if", "len", "(", "lines", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", ")", "!=", "len", "(", "tmp", ")", ":", "\n", "            ", "print", "(", "line", ")", "\n", "", "turn_position", ".", "append", "(", "tmp", ")", "\n", "mask", ".", "append", "(", "mask_tmp", ")", "\n", "\n", "", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.turn_position'", "\n", "mask_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.mask'", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "position_file", ")", "and", "os", ".", "path", ".", "exists", "(", "mask_file", ")", "and", "not", "os", ".", "path", ".", "getsize", "(", "position_file", ")", "and", "not", "os", ".", "path", ".", "getsize", "(", "mask_file", ")", ":", "\n", "        ", "return", "position_file", ",", "mask_file", "\n", "\n", "", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "with", "open", "(", "mask_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_mask", "in", "mask", ":", "\n", "            ", "line_mask", "=", "sorted", "(", "line_mask", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_mask", ")", "+", "'\\n'", ")", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", ",", "mask_file", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.get_turn_position": [[426, 450], ["os.path.exists", "open", "fr.readlines", "turn_position.append", "file1.split", "open", "line.strip().split", "tmp.append", "file1.split", "sorted", "fw.write", "str", "line.strip"], "function", ["None"], ["", "def", "get_turn_position", "(", "file1", ")", ":", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "content", "=", "fr", ".", "readlines", "(", ")", "\n", "", "turn_position", "=", "[", "]", "\n", "for", "line", "in", "content", ":", "\n", "        ", "tmp", "=", "[", "]", "\n", "index", "=", "0", "\n", "for", "i", "in", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "#tmp.append(str(index))", "\n", "            ", "if", "i", "==", "'[SEP]'", ":", "\n", "                ", "index", "+=", "1", "\n", "", "tmp", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "", "turn_position", ".", "append", "(", "tmp", ")", "\n", "", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.turn_position'", "\n", "if", "os", ".", "path", ".", "exists", "(", "position_file", ")", ":", "\n", "        ", "return", "position_file", "\n", "", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.get_turn_position_src": [[451, 501], ["zip", "open", "fr.readlines", "open", "fr.readlines", "dialog.append", "turn_position.append", "mask.append", "file1.split", "open", "open", "line.split", "len", "len", "print", "file1.split", "sorted", "fw.write", "fw.write", "ctx.replace", "src.replace", "mask_sent.append", "tmp.append", "tmp.append", "line.split", "str", "str", "str"], "function", ["None"], ["", "def", "get_turn_position_src", "(", "file1", ",", "file2", ")", ":", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "sentence", "=", "fr", ".", "readlines", "(", ")", "\n", "", "with", "open", "(", "file2", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "content", "=", "fr", ".", "readlines", "(", ")", "\n", "\n", "", "turn_position", "=", "[", "]", "\n", "mask", "=", "[", "]", "\n", "dialog", "=", "[", "]", "\n", "for", "src", ",", "ctx", "in", "zip", "(", "sentence", ",", "content", ")", ":", "\n", "        ", "line", "=", "ctx", ".", "replace", "(", "'\\n'", ",", "' '", ")", "+", "src", ".", "replace", "(", "'\\n'", ",", "' '", ")", "+", "'<eos> '", "\n", "dialog", ".", "append", "(", "line", ")", "\n", "tmp", "=", "[", "]", "\n", "mask_sent", "=", "[", "]", "\n", "index", "=", "1", "\n", "flag", "=", "0", "\n", "for", "i", "in", "line", ".", "split", "(", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "if", "flag", "==", "0", ":", "\n", "                ", "mask_sent", ".", "append", "(", "str", "(", "1", ")", ")", "\n", "tmp", ".", "append", "(", "str", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "#mask_sent.append(str(0))", "\n", "                ", "tmp", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "if", "i", "==", "'[SEP]'", ":", "\n", "                    ", "index", "+=", "1", "\n", "\n", "", "", "if", "i", "==", "'<eos>'", ":", "\n", "                ", "flag", "=", "1", "\n", "\n", "", "", "if", "len", "(", "line", ".", "split", "(", ")", ")", "!=", "len", "(", "tmp", ")", ":", "\n", "            ", "print", "(", "line", ")", "\n", "", "turn_position", ".", "append", "(", "tmp", ")", "\n", "mask", ".", "append", "(", "mask_sent", ")", "\n", "\n", "", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.src_dia_turn_position'", "\n", "dialog_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.src.dialog'", "\n", "\n", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "with", "open", "(", "dialog_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "sub_mask", "in", "dialog", ":", "\n", "            ", "fw", ".", "write", "(", "sub_mask", ")", "\n", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", ",", "dialog_file", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.get_turn_position1": [[502, 507], ["[].split", "file1.split", "file1.split"], "function", ["None"], ["", "def", "get_turn_position1", "(", "file1", ")", ":", "\n", "    ", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.turn_position'", "\n", "return", "position_file", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.get_sampled_file": [[508, 520], ["random.shuffle", "open", "fr.readlines", "file1.split", "open", "file1.split", "fw.write", "sa.strip().split", "sa.strip"], "function", ["None"], ["", "def", "get_sampled_file", "(", "file1", ")", ":", "\n", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "sentence", "=", "fr", ".", "readlines", "(", ")", "\n", "", "random", ".", "shuffle", "(", "sentence", ")", "\n", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "sample_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.sample'", "\n", "with", "open", "(", "sample_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "sa", "in", "sentence", ":", "\n", "            ", "fw", ".", "write", "(", "' '", ".", "join", "(", "sa", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "+", "'\\n'", ")", "\n", "", "", "return", "sample_file", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.main": [[331, 509], ["tensorflow.logging.set_verbosity", "thumt.get_model", "trainer.default_parameters", "trainer.merge_parameters", "trainer.import_params", "trainer.override_parameters", "thumt.enable_distributed_training", "models.get_model.get_parameters", "thumt.rank", "trainer.export_params", "trainer.export_params", "tensorflow.Graph().as_default", "trainer.get_initializer", "tensorflow.contrib.layers.l1_l2_regularizer", "models.get_model.", "tensorflow.train.get_or_create_global_step", "thumt.parallel_model", "trainer.get_learning_rate_decay", "tensorflow.convert_to_tensor", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "thumt.MultiStepOptimizer", "tf.contrib.opt.LazyAdamOptimizer.compute_gradients", "tf.contrib.opt.LazyAdamOptimizer.apply_gradients", "thumt.get_broadcast_hook", "trainer.restore_variables", "trainer.collect_params", "thumt.get_training_input", "thumt.get_input_features", "model_cls.get_training_func", "tensorflow.add_n", "len", "tensorflow.losses.get_regularization_loss", "thumt.rank", "trainer.print_variables", "tensorflow.train.AdamOptimizer", "thumt.LossScalingOptimizer", "list", "tensorflow.clip_by_global_norm", "zip", "thumt.sort_and_zip_files", "tensorflow.train.StopAtStepHook", "tensorflow.train.NanTensorHook", "tensorflow.train.LoggingTensorHook", "train_hooks.append", "thumt.rank", "tensorflow.train.Saver", "tensorflow.add_to_collection", "train_hooks.append", "step_context.session.run", "tensorflow.train.MonitoredTrainingSession", "sess.run_step_fn", "models.get_model.get_parameters", "tensorflow.Graph", "os.path.join", "tensorflow.contrib.opt.LazyAdamOptimizer", "RuntimeError", "zip", "list", "tensorflow.trainable_variables", "thumt.MultiStepHook", "train_hooks.append", "sess.should_stop", "sess.run", "tensorflow.shape", "tensorflow.shape", "tensorflow.train.CheckpointSaverHook", "thumt.MultiStepHook", "trainer.session_config", "thumt.EvaluationHook", "trainer.session_config", "thumt.create_inference_graph", "eval_input_fn", "trainer.decode_target_ids"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.__init__.get_model", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.default_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.merge_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.import_params", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.override_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.enable_distributed_training", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.rank", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.export_params", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.export_params", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.get_initializer", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.parallel_emo.parallel_model", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.get_learning_rate_decay", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.StaticLossScalingOptimizer.compute_gradients", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.optimizers.StaticLossScalingOptimizer.apply_gradients", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.get_broadcast_hook", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.restore_variables", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.collect_params", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_training_input", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.record.get_input_features", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_training_func", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.rank", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.print_variables", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.sort_and_zip_files", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.rank", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.session_config", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.session_config", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.search.create_inference_graph", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.trainer.decode_target_ids"], ["\n", "", "if", "sym", "==", "params", ".", "pad", ":", "\n", "                ", "break", "\n", "\n", "", "syms", ".", "append", "(", "sym", ")", "\n", "", "decoded", ".", "append", "(", "syms", ")", "\n", "\n", "", "return", "decoded", "\n", "\n", "\n", "", "def", "restore_variables", "(", "checkpoint", ")", ":", "\n", "    ", "if", "not", "checkpoint", ":", "\n", "        ", "return", "tf", ".", "no_op", "(", "\"restore_op\"", ")", "\n", "\n", "# Load checkpoints", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Loading %s\"", "%", "checkpoint", ")", "\n", "var_list", "=", "tf", ".", "train", ".", "list_variables", "(", "checkpoint", ")", "\n", "reader", "=", "tf", ".", "train", ".", "load_checkpoint", "(", "checkpoint", ")", "\n", "values", "=", "{", "}", "\n", "\n", "for", "(", "name", ",", "shape", ")", "in", "var_list", ":", "\n", "        ", "tensor", "=", "reader", ".", "get_tensor", "(", "name", ")", "\n", "name", "=", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", "\n", "values", "[", "name", "]", "=", "tensor", "\n", "\n", "", "var_list", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "ops", "=", "[", "]", "\n", "\n", "for", "var", "in", "var_list", ":", "\n", "        ", "name", "=", "var", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", "\n", "\n", "if", "name", "in", "values", ":", "\n", "            ", "tf", ".", "logging", ".", "info", "(", "\"Restore %s\"", "%", "var", ".", "name", ")", "\n", "ops", ".", "append", "(", "tf", ".", "assign", "(", "var", ",", "values", "[", "name", "]", ")", ")", "\n", "\n", "", "", "return", "tf", ".", "group", "(", "*", "ops", ",", "name", "=", "\"restore_op\"", ")", "\n", "\n", "\n", "", "def", "print_variables", "(", ")", ":", "\n", "    ", "all_weights", "=", "{", "v", ".", "name", ":", "v", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "}", "\n", "total_size", "=", "0", "\n", "\n", "for", "v_name", "in", "sorted", "(", "list", "(", "all_weights", ")", ")", ":", "\n", "        ", "v", "=", "all_weights", "[", "v_name", "]", "\n", "tf", ".", "logging", ".", "info", "(", "\"%s\\tshape    %s\"", ",", "v", ".", "name", "[", ":", "-", "2", "]", ".", "ljust", "(", "80", ")", ",", "\n", "str", "(", "v", ".", "shape", ")", ".", "ljust", "(", "20", ")", ")", "\n", "v_size", "=", "np", ".", "prod", "(", "np", ".", "array", "(", "v", ".", "shape", ".", "as_list", "(", ")", ")", ")", ".", "tolist", "(", ")", "\n", "total_size", "+=", "v_size", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Total trainable variables size: %d\"", ",", "total_size", ")", "\n", "\n", "", "def", "get_turn_position_eos", "(", "file1", ")", ":", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "content", "=", "fr", ".", "readlines", "(", ")", "\n", "", "turn_position", "=", "[", "]", "\n", "mask", "=", "[", "]", "\n", "for", "line", "in", "content", ":", "\n", "        ", "tmp", "=", "[", "]", "\n", "mask_tmp", "=", "[", "]", "\n", "index", "=", "0", "\n", "lines", "=", "line", ".", "strip", "(", ")", "+", "\" <eos>\"", "\n", "flag", "=", "0", "\n", "for", "i", "in", "lines", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "#tmp.append(str(index))", "\n", "#            flag = 0", "\n", "            ", "if", "i", "==", "'[SEP]'", ":", "\n", "                ", "index", "+=", "1", "\n", "flag", "=", "1", "\n", "", "tmp", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "mask_tmp", ".", "append", "(", "str", "(", "flag", ")", ")", "\n", "#        if len(lines.split()) != len(tmp):", "\n", "", "if", "len", "(", "lines", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", ")", "!=", "len", "(", "tmp", ")", ":", "\n", "            ", "print", "(", "line", ")", "\n", "", "turn_position", ".", "append", "(", "tmp", ")", "\n", "mask", ".", "append", "(", "mask_tmp", ")", "\n", "\n", "", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.turn_position'", "\n", "mask_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.mask'", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "position_file", ")", "and", "os", ".", "path", ".", "exists", "(", "mask_file", ")", "and", "not", "os", ".", "path", ".", "getsize", "(", "position_file", ")", "and", "not", "os", ".", "path", ".", "getsize", "(", "mask_file", ")", ":", "\n", "        ", "return", "position_file", ",", "mask_file", "\n", "\n", "", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "with", "open", "(", "mask_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_mask", "in", "mask", ":", "\n", "            ", "line_mask", "=", "sorted", "(", "line_mask", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_mask", ")", "+", "'\\n'", ")", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", ",", "mask_file", "\n", "\n", "", "def", "get_turn_position", "(", "file1", ")", ":", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "content", "=", "fr", ".", "readlines", "(", ")", "\n", "", "turn_position", "=", "[", "]", "\n", "for", "line", "in", "content", ":", "\n", "        ", "tmp", "=", "[", "]", "\n", "index", "=", "0", "\n", "for", "i", "in", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "#tmp.append(str(index))", "\n", "            ", "if", "i", "==", "'[SEP]'", ":", "\n", "                ", "index", "+=", "1", "\n", "", "tmp", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "", "turn_position", ".", "append", "(", "tmp", ")", "\n", "", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.turn_position'", "\n", "if", "os", ".", "path", ".", "exists", "(", "position_file", ")", ":", "\n", "        ", "return", "position_file", "\n", "", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", "\n", "\n", "", "def", "get_turn_position_src", "(", "file1", ",", "file2", ")", ":", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "sentence", "=", "fr", ".", "readlines", "(", ")", "\n", "", "with", "open", "(", "file2", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "content", "=", "fr", ".", "readlines", "(", ")", "\n", "\n", "", "turn_position", "=", "[", "]", "\n", "mask", "=", "[", "]", "\n", "dialog", "=", "[", "]", "\n", "for", "src", ",", "ctx", "in", "zip", "(", "sentence", ",", "content", ")", ":", "\n", "        ", "line", "=", "ctx", ".", "replace", "(", "'\\n'", ",", "' '", ")", "+", "src", ".", "replace", "(", "'\\n'", ",", "' '", ")", "+", "'<eos> '", "\n", "dialog", ".", "append", "(", "line", ")", "\n", "tmp", "=", "[", "]", "\n", "mask_sent", "=", "[", "]", "\n", "index", "=", "1", "\n", "flag", "=", "0", "\n", "for", "i", "in", "line", ".", "split", "(", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "if", "flag", "==", "0", ":", "\n", "                ", "mask_sent", ".", "append", "(", "str", "(", "1", ")", ")", "\n", "tmp", ".", "append", "(", "str", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "#mask_sent.append(str(0))", "\n", "                ", "tmp", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "if", "i", "==", "'[SEP]'", ":", "\n", "                    ", "index", "+=", "1", "\n", "\n", "", "", "if", "i", "==", "'<eos>'", ":", "\n", "                ", "flag", "=", "1", "\n", "\n", "", "", "if", "len", "(", "line", ".", "split", "(", ")", ")", "!=", "len", "(", "tmp", ")", ":", "\n", "            ", "print", "(", "line", ")", "\n", "", "turn_position", ".", "append", "(", "tmp", ")", "\n", "mask", ".", "append", "(", "mask_sent", ")", "\n", "\n", "", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.src_dia_turn_position'", "\n", "dialog_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.src.dialog'", "\n", "\n", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "with", "open", "(", "dialog_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "sub_mask", "in", "dialog", ":", "\n", "            ", "fw", ".", "write", "(", "sub_mask", ")", "\n", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", ",", "dialog_file", "\n", "\n", "", "def", "get_turn_position1", "(", "file1", ")", ":", "\n", "    ", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.turn_position'", "\n", "return", "position_file", "\n", "\n", "", "def", "get_sampled_file", "(", "file1", ")", ":", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.parse_args": [[19, 42], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Translate using existing NMT models\"", ",", "\n", "usage", "=", "\"translator.py [<args>] [-h | --help]\"", "\n", ")", "\n", "\n", "# input files", "\n", "parser", ".", "add_argument", "(", "\"--input\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "nargs", "=", "2", ",", "\n", "help", "=", "\"Path of input file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of output file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of trained models\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocabulary\"", ",", "type", "=", "str", ",", "nargs", "=", "2", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of source and target vocabulary\"", ")", "\n", "\n", "# model and configuration", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Name of the model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--parameters\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Additional hyper parameters\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.default_parameters": [[44, 63], ["tensorflow.contrib.training.HParams"], "function", ["None"], ["    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "input", "=", "None", ",", "\n", "output", "=", "None", ",", "\n", "vocabulary", "=", "None", ",", "\n", "model", "=", "None", ",", "\n", "# vocabulary specific", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "bos", "=", "\"<bos>\"", ",", "\n", "eos", "=", "\"<eos>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "mapping", "=", "None", ",", "\n", "append_eos", "=", "False", ",", "\n", "device_list", "=", "[", "0", "]", ",", "\n", "num_threads", "=", "6", ",", "\n", "eval_batch_size", "=", "32", "\n", ")", "\n", "\n", "return", "params", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.merge_parameters": [[65, 81], ["tensorflow.contrib.training.HParams", "six.iteritems", "tf.contrib.training.HParams.values", "six.iteritems", "params1.values", "tf.contrib.training.HParams.add_hparam", "params2.values", "setattr", "tf.contrib.training.HParams.add_hparam"], "function", ["None"], ["    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", ")", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "params1", ".", "values", "(", ")", ")", ":", "\n", "        ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "params_dict", "=", "params", ".", "values", "(", ")", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "params2", ".", "values", "(", ")", ")", ":", "\n", "        ", "if", "k", "in", "params_dict", ":", "\n", "# Override", "\n", "            ", "setattr", "(", "params", ",", "k", ",", "v", ")", "\n", "", "else", ":", "\n", "            ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "", "return", "params", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.import_params": [[83, 96], ["os.path.abspath", "os.path.join", "tensorflow.gfile.Exists", "tensorflow.gfile.Open", "tensorflow.logging.info", "fd.readline", "params.parse_json"], "function", ["None"], ["    ", "model_dir", "=", "os", ".", "path", ".", "abspath", "(", "model_dir", ")", "\n", "m_name", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "model_name", "+", "\".json\"", ")", "\n", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "m_name", ")", ":", "\n", "        ", "return", "params", "\n", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "m_name", ")", "as", "fd", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "\"Restoring model parameters from %s\"", "%", "m_name", ")", "\n", "json_str", "=", "fd", ".", "readline", "(", ")", "\n", "params", ".", "parse_json", "(", "json_str", ")", "\n", "\n", "", "return", "params", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.override_parameters": [[98, 127], ["thumt.process_vocabulary", "thumt.process_vocabulary", "params.parse", "thumt.load_vocabulary", "thumt.load_vocabulary", "thumt.get_control_mapping", "thumt.get_control_mapping"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.get_control_mapping", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.get_control_mapping"], ["    ", "if", "args", ".", "parameters", ":", "\n", "        ", "params", ".", "parse", "(", "args", ".", "parameters", ")", "\n", "\n", "", "params", ".", "vocabulary", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "load_vocabulary", "(", "args", ".", "vocabulary", "[", "0", "]", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "load_vocabulary", "(", "args", ".", "vocabulary", "[", "1", "]", ")", "\n", "}", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "params", "\n", ")", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "params", "\n", ")", "\n", "\n", "control_symbols", "=", "[", "params", ".", "pad", ",", "params", ".", "bos", ",", "params", ".", "eos", ",", "params", ".", "unk", "]", "\n", "\n", "params", ".", "mapping", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "\n", "control_symbols", "\n", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "\n", "control_symbols", "\n", ")", "\n", "}", "\n", "\n", "return", "params", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.session_config": [[129, 140], ["tensorflow.OptimizerOptions", "tensorflow.GraphOptions", "tensorflow.ConfigProto", "str"], "function", ["None"], ["    ", "optimizer_options", "=", "tf", ".", "OptimizerOptions", "(", "opt_level", "=", "tf", ".", "OptimizerOptions", ".", "L1", ",", "\n", "do_function_inlining", "=", "False", ")", "\n", "graph_options", "=", "tf", ".", "GraphOptions", "(", "optimizer_options", "=", "optimizer_options", ")", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ",", "\n", "graph_options", "=", "graph_options", ")", "\n", "if", "params", ".", "device_list", ":", "\n", "        ", "device_str", "=", "\",\"", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "params", ".", "device_list", "]", ")", "\n", "config", ".", "gpu_options", ".", "visible_device_list", "=", "device_str", "\n", "\n", "", "return", "config", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.set_variables": [[142, 156], ["tensorflow.logging.debug", "list", "tensorflow.device", "tensorflow.assign", "ops.append", "name.split"], "function", ["None"], ["    ", "ops", "=", "[", "]", "\n", "for", "var", "in", "var_list", ":", "\n", "        ", "for", "name", "in", "value_dict", ":", "\n", "            ", "var_name", "=", "\"/\"", ".", "join", "(", "[", "prefix", "]", "+", "list", "(", "name", ".", "split", "(", "\"/\"", ")", "[", "1", ":", "]", ")", ")", "\n", "\n", "if", "var", ".", "name", "[", ":", "-", "2", "]", "==", "var_name", ":", "\n", "                ", "tf", ".", "logging", ".", "debug", "(", "\"restoring %s -> %s\"", "%", "(", "name", ",", "var", ".", "name", ")", ")", "\n", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "                    ", "op", "=", "tf", ".", "assign", "(", "var", ",", "value_dict", "[", "name", "]", ")", "\n", "ops", ".", "append", "(", "op", ")", "\n", "", "break", "\n", "\n", "", "", "", "return", "ops", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.read_files": [[158, 177], ["zip", "tensorflow.gfile.GFile", "enumerate", "fd.close", "range", "line.strip", "inputs[].append", "len"], "function", ["None"], ["    ", "inputs", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "names", ")", ")", "]", "\n", "files", "=", "[", "tf", ".", "gfile", ".", "GFile", "(", "name", ")", "for", "name", "in", "names", "]", "\n", "\n", "count", "=", "0", "\n", "\n", "for", "lines", "in", "zip", "(", "*", "files", ")", ":", "\n", "        ", "lines", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "lines", "]", "\n", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "inputs", "[", "i", "]", ".", "append", "(", "line", ")", "\n", "\n", "", "count", "+=", "1", "\n", "\n", "# Close files", "\n", "", "for", "fd", "in", "files", ":", "\n", "        ", "fd", ".", "close", "(", ")", "\n", "\n", "", "return", "inputs", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.get_features": [[179, 240], ["tensorflow.device", "tensorflow.data.Dataset.zip", "dataset.map.map", "dataset.map.padded_batch", "dataset.map.make_one_shot_iterator", "dataset.make_one_shot_iterator.get_next", "tensorflow.contrib.lookup.index_table_from_tensor", "tensorflow.contrib.lookup.index_table_from_tensor", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tensorflow.data.Dataset.from_tensor_slices", "dataset.map.map", "dataset.map.map", "datasets.append", "tuple", "tensorflow.constant", "tensorflow.constant", "tensorflow.concat", "tensorflow.Dimension", "tensorflow.Dimension", "tensorflow.string_split", "tensorflow.shape", "tensorflow.shape", "tensorflow.constant"], "function", ["None"], ["    ", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "# Create datasets", "\n", "        ", "datasets", "=", "[", "]", "\n", "\n", "for", "data", "in", "inputs", ":", "\n", "            ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "data", ")", "\n", "# Split string", "\n", "dataset", "=", "dataset", ".", "map", "(", "lambda", "x", ":", "tf", ".", "string_split", "(", "[", "x", "]", ")", ".", "values", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", ")", "\n", "# Append <eos>", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "x", ":", "tf", ".", "concat", "(", "[", "x", ",", "[", "tf", ".", "constant", "(", "params", ".", "eos", ")", "]", "]", ",", "axis", "=", "0", ")", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "datasets", ".", "append", "(", "dataset", ")", "\n", "\n", "", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "zip", "(", "tuple", "(", "datasets", ")", ")", "\n", "\n", "# Convert tuple to dictionary", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "*", "x", ":", "{", "\n", "\"source\"", ":", "x", "[", "0", "]", ",", "\n", "\"source_length\"", ":", "tf", ".", "shape", "(", "x", "[", "0", "]", ")", "[", "0", "]", ",", "\n", "\"target\"", ":", "x", "[", "1", "]", ",", "\n", "\"target_length\"", ":", "tf", ".", "shape", "(", "x", "[", "1", "]", ")", "[", "0", "]", "\n", "}", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "\n", "dataset", "=", "dataset", ".", "padded_batch", "(", "\n", "params", ".", "eval_batch_size", ",", "\n", "{", "\n", "\"source\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\n", "\"source_length\"", ":", "[", "]", ",", "\n", "\"target\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\n", "\"target_length\"", ":", "[", "]", "\n", "}", ",", "\n", "{", "\n", "\"source\"", ":", "params", ".", "pad", ",", "\n", "\"source_length\"", ":", "0", ",", "\n", "\"target\"", ":", "params", ".", "pad", ",", "\n", "\"target_length\"", ":", "0", "\n", "}", "\n", ")", "\n", "\n", "iterator", "=", "dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "features", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "src_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"source\"", "]", ")", ",", "\n", "default_value", "=", "params", ".", "mapping", "[", "\"source\"", "]", "[", "params", ".", "unk", "]", "\n", ")", "\n", "tgt_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", ",", "\n", "default_value", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "unk", "]", "\n", ")", "\n", "features", "[", "\"source\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"source\"", "]", ")", "\n", "features", "[", "\"target\"", "]", "=", "tgt_table", ".", "lookup", "(", "features", "[", "\"target\"", "]", ")", "\n", "\n", "", "return", "features", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.main": [[242, 295], ["tensorflow.logging.set_verbosity", "thumt.get_model", "scorer.default_parameters", "scorer.merge_parameters", "scorer.import_params", "scorer.override_parameters", "models.get_model.get_parameters", "tensorflow.Graph().as_default", "models.get_model.", "scorer.read_files", "scorer.get_features", "model_cls.get_evaluation_func", "model.get_evaluation_func.", "tensorflow.train.ChiefSessionCreator", "tensorflow.logging.info", "tensorflow.train.list_variables", "tensorflow.train.load_checkpoint", "scorer.set_variables", "tensorflow.group", "tf.train.load_checkpoint.get_tensor", "tensorflow.trainable_variables", "models.get_model.get_name", "tensorflow.train.MonitoredSession", "sess.run", "tensorflow.gfile.Open", "tf.gfile.Open.close", "tensorflow.Graph", "scorer.session_config", "name.startswith", "sess.should_stop", "sess.run", "models.get_model.get_name", "tf.gfile.Open.write"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.__init__.get_model", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.default_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.merge_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.import_params", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.override_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_parameters", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.read_files", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.get_features", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_evaluation_func", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.set_variables", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_name", "home.repos.pwc.inspect_result.xl2248_csa-nct.bin.scorer.session_config", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_name"], ["    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "model_cls", "=", "models", ".", "get_model", "(", "args", ".", "model", ")", "\n", "params", "=", "default_parameters", "(", ")", "\n", "\n", "# Import and override parameters", "\n", "# Priorities (low -> high):", "\n", "# default -> saved -> command", "\n", "params", "=", "merge_parameters", "(", "params", ",", "model_cls", ".", "get_parameters", "(", ")", ")", "\n", "params", "=", "import_params", "(", "args", ".", "checkpoint", ",", "args", ".", "model", ",", "params", ")", "\n", "override_parameters", "(", "params", ",", "args", ")", "\n", "\n", "# Build Graph", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "model", "=", "model_cls", "(", "params", ")", "\n", "inputs", "=", "read_files", "(", "args", ".", "input", ")", "\n", "features", "=", "get_features", "(", "inputs", ",", "params", ")", "\n", "score_fn", "=", "model", ".", "get_evaluation_func", "(", ")", "\n", "scores", "=", "score_fn", "(", "features", ",", "params", ")", "\n", "\n", "sess_creator", "=", "tf", ".", "train", ".", "ChiefSessionCreator", "(", "\n", "config", "=", "session_config", "(", "params", ")", "\n", ")", "\n", "\n", "# Load checkpoint", "\n", "tf", ".", "logging", ".", "info", "(", "\"Loading %s\"", "%", "args", ".", "checkpoint", ")", "\n", "var_list", "=", "tf", ".", "train", ".", "list_variables", "(", "args", ".", "checkpoint", ")", "\n", "values", "=", "{", "}", "\n", "reader", "=", "tf", ".", "train", ".", "load_checkpoint", "(", "args", ".", "checkpoint", ")", "\n", "\n", "for", "(", "name", ",", "shape", ")", "in", "var_list", ":", "\n", "            ", "if", "not", "name", ".", "startswith", "(", "model_cls", ".", "get_name", "(", ")", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "tensor", "=", "reader", ".", "get_tensor", "(", "name", ")", "\n", "values", "[", "name", "]", "=", "tensor", "\n", "\n", "", "ops", "=", "set_variables", "(", "tf", ".", "trainable_variables", "(", ")", ",", "values", ",", "\n", "model_cls", ".", "get_name", "(", ")", ")", "\n", "assign_op", "=", "tf", ".", "group", "(", "*", "ops", ")", "\n", "\n", "# Create session", "\n", "with", "tf", ".", "train", ".", "MonitoredSession", "(", "session_creator", "=", "sess_creator", ")", "as", "sess", ":", "\n", "# Restore variables", "\n", "            ", "sess", ".", "run", "(", "assign_op", ")", "\n", "fd", "=", "tf", ".", "gfile", ".", "Open", "(", "args", ".", "output", ",", "\"w\"", ")", "\n", "\n", "while", "not", "sess", ".", "should_stop", "(", ")", ":", "\n", "                ", "results", "=", "sess", ".", "run", "(", "scores", ")", "\n", "for", "value", "in", "results", ":", "\n", "                    ", "fd", ".", "write", "(", "\"%f\\n\"", "%", "value", ")", "\n", "\n", "", "", "fd", ".", "close", "(", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.interface.model.NMTModel.__init__": [[11, 14], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "scope", ")", ":", "\n", "        ", "self", ".", "_scope", "=", "scope", "\n", "self", ".", "_params", "=", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.interface.model.NMTModel.get_training_func": [[15, 17], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_training_func", "(", "self", ",", "initializer", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Not implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.interface.model.NMTModel.get_evaluation_func": [[18, 20], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_evaluation_func", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Not implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.interface.model.NMTModel.get_inference_func": [[21, 23], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_inference_func", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Not implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.interface.model.NMTModel.get_name": [[24, 27], ["NotImplementedError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_name", "(", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Not implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.interface.model.NMTModel.get_parameters": [[28, 31], ["NotImplementedError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_parameters", "(", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Not implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.interface.model.NMTModel.parameters": [[32, 35], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.rnn_cell.LegacyGRUCell.__init__": [[22, 25], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.train_word2vec.MySentences.__init__"], ["def", "__init__", "(", "self", ",", "num_units", ",", "reuse", "=", "None", ")", ":", "\n", "        ", "super", "(", "LegacyGRUCell", ",", "self", ")", ".", "__init__", "(", "_reuse", "=", "reuse", ")", "\n", "self", ".", "_num_units", "=", "num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.rnn_cell.LegacyGRUCell.__call__": [[26, 44], ["tensorflow.variable_scope", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "thumt.layers.nn.linear", "isinstance", "list", "thumt.layers.nn.linear", "thumt.layers.nn.linear", "list", "tensorflow.tanh"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"gru_cell\"", ",", "\n", "values", "=", "[", "inputs", ",", "state", "]", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "inputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "inputs", "=", "[", "inputs", "]", "\n", "\n", "", "all_inputs", "=", "list", "(", "inputs", ")", "+", "[", "state", "]", "\n", "r", "=", "tf", ".", "nn", ".", "sigmoid", "(", "linear", "(", "all_inputs", ",", "self", ".", "_num_units", ",", "False", ",", "False", ",", "\n", "scope", "=", "\"reset_gate\"", ")", ")", "\n", "u", "=", "tf", ".", "nn", ".", "sigmoid", "(", "linear", "(", "all_inputs", ",", "self", ".", "_num_units", ",", "False", ",", "False", ",", "\n", "scope", "=", "\"update_gate\"", ")", ")", "\n", "all_inputs", "=", "list", "(", "inputs", ")", "+", "[", "r", "*", "state", "]", "\n", "c", "=", "linear", "(", "all_inputs", ",", "self", ".", "_num_units", ",", "True", ",", "False", ",", "\n", "scope", "=", "\"candidate\"", ")", "\n", "\n", "new_state", "=", "(", "1.0", "-", "u", ")", "*", "state", "+", "u", "*", "tf", ".", "tanh", "(", "c", ")", "\n", "\n", "", "return", "new_state", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.rnn_cell.LegacyGRUCell.state_size": [[45, 48], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.rnn_cell.LegacyGRUCell.output_size": [[49, 52], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_units", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.add_timing_signal": [[14, 48], ["tensorflow.name_scope", "tensorflow.to_float", "tensorflow.concat", "tensorflow.pad", "tensorflow.reshape", "tensorflow.shape", "tensorflow.shape", "tensorflow.range", "math.log", "tensorflow.exp", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.cast", "tensorflow.to_float", "tensorflow.sin", "tensorflow.cos", "float", "float", "tensorflow.to_float", "tensorflow.mod", "tensorflow.range"], "function", ["None"], ["def", "add_timing_signal", "(", "x", ",", "min_timescale", "=", "1.0", ",", "max_timescale", "=", "1.0e4", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    This function adds a bunch of sinusoids of different frequencies to a\n    Tensor. See paper: `Attention is all you need'\n\n    :param x: A tensor with shape [batch, length, channels]\n    :param min_timescale: A floating point number\n    :param max_timescale: A floating point number\n    :param name: An optional string\n\n    :returns: a Tensor the same shape as x.\n    \"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "name", ",", "default_name", "=", "\"add_timing_signal\"", ",", "values", "=", "[", "x", "]", ")", ":", "\n", "        ", "length", "=", "tf", ".", "shape", "(", "x", ")", "[", "1", "]", "\n", "channels", "=", "tf", ".", "shape", "(", "x", ")", "[", "2", "]", "\n", "position", "=", "tf", ".", "to_float", "(", "tf", ".", "range", "(", "length", ")", ")", "\n", "num_timescales", "=", "channels", "//", "2", "\n", "\n", "log_timescale_increment", "=", "(", "\n", "math", ".", "log", "(", "float", "(", "max_timescale", ")", "/", "float", "(", "min_timescale", ")", ")", "/", "\n", "(", "tf", ".", "to_float", "(", "num_timescales", ")", "-", "1", ")", "\n", ")", "\n", "inv_timescales", "=", "min_timescale", "*", "tf", ".", "exp", "(", "\n", "tf", ".", "to_float", "(", "tf", ".", "range", "(", "num_timescales", ")", ")", "*", "-", "log_timescale_increment", "\n", ")", "\n", "\n", "scaled_time", "=", "(", "tf", ".", "expand_dims", "(", "position", ",", "1", ")", "*", "\n", "tf", ".", "expand_dims", "(", "inv_timescales", ",", "0", ")", ")", "\n", "signal", "=", "tf", ".", "concat", "(", "[", "tf", ".", "sin", "(", "scaled_time", ")", ",", "tf", ".", "cos", "(", "scaled_time", ")", "]", ",", "axis", "=", "1", ")", "\n", "signal", "=", "tf", ".", "pad", "(", "signal", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "tf", ".", "mod", "(", "channels", ",", "2", ")", "]", "]", ")", "\n", "signal", "=", "tf", ".", "reshape", "(", "signal", ",", "[", "1", ",", "length", ",", "channels", "]", ")", "\n", "\n", "return", "x", "+", "tf", ".", "cast", "(", "signal", ",", "x", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.split_heads": [[50, 70], ["tensorflow.name_scope", "tensorflow.reshape", "tf.reshape.set_shape", "tensorflow.transpose", "x.get_shape", "tensorflow.concat", "tensorflow.shape", "range"], "function", ["None"], ["", "", "def", "split_heads", "(", "inputs", ",", "num_heads", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\" Split heads\n    :param inputs: A tensor with shape [batch, ..., channels]\n    :param num_heads: An integer\n    :param name: An optional string\n    :returns: A tensor with shape [batch, heads, ..., channels / heads]\n    \"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "name", ",", "default_name", "=", "\"split_heads\"", ",", "values", "=", "[", "inputs", "]", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "n", "=", "num_heads", "\n", "old_shape", "=", "x", ".", "get_shape", "(", ")", ".", "dims", "\n", "ndims", "=", "x", ".", "shape", ".", "ndims", "\n", "\n", "last", "=", "old_shape", "[", "-", "1", "]", "\n", "new_shape", "=", "old_shape", "[", ":", "-", "1", "]", "+", "[", "n", "]", "+", "[", "last", "//", "n", "if", "last", "else", "None", "]", "\n", "ret", "=", "tf", ".", "reshape", "(", "x", ",", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "x", ")", "[", ":", "-", "1", "]", ",", "[", "n", ",", "-", "1", "]", "]", ",", "0", ")", ")", "\n", "ret", ".", "set_shape", "(", "new_shape", ")", "\n", "perm", "=", "[", "0", ",", "ndims", "-", "1", "]", "+", "[", "i", "for", "i", "in", "range", "(", "1", ",", "ndims", "-", "1", ")", "]", "+", "[", "ndims", "]", "\n", "return", "tf", ".", "transpose", "(", "ret", ",", "perm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.combine_heads": [[72, 89], ["tensorflow.name_scope", "tensorflow.transpose", "tensorflow.reshape", "tf.reshape.set_shape", "tf.reshape.get_shape", "tensorflow.concat", "tensorflow.shape"], "function", ["None"], ["", "", "def", "combine_heads", "(", "inputs", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\" Combine heads\n    :param inputs: A tensor with shape [batch, heads, length, channels]\n    :param name: An optional string\n    :returns: A tensor with shape [batch, length, heads * channels]\n    \"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "name", ",", "default_name", "=", "\"combine_heads\"", ",", "values", "=", "[", "inputs", "]", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "x", "=", "tf", ".", "transpose", "(", "x", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "old_shape", "=", "x", ".", "get_shape", "(", ")", ".", "dims", "\n", "a", ",", "b", "=", "old_shape", "[", "-", "2", ":", "]", "\n", "new_shape", "=", "old_shape", "[", ":", "-", "2", "]", "+", "[", "a", "*", "b", "if", "a", "and", "b", "else", "None", "]", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "x", ")", "[", ":", "-", "2", "]", ",", "[", "-", "1", "]", "]", ",", "0", ")", ")", "\n", "x", ".", "set_shape", "(", "new_shape", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.create_rpr": [[91, 110], ["tensorflow.name_scope", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.maximum", "tensorflow.minimum", "tensorflow.gather", "tensorflow.range", "tensorflow.range"], "function", ["None"], ["", "", "def", "create_rpr", "(", "orginal_var", ",", "length_q", ",", "length_kv", ",", "max_relative_dis", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\" Create relative positional representation \n    :param orginal_var: A tensor with shape [2*max_relative_dis+1, depth]\n    :param length_q: An integer\n    :param length_kv: An integer\n    :param max_relative_dis: An integer\n    :returns: A tensor with shape [length_q, length_kv, depth]\n    \"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "name", ",", "default_name", "=", "\"create_rpr\"", ",", "values", "=", "[", "orginal_var", "]", ")", ":", "\n", "        ", "idxs", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "length_kv", ")", ",", "[", "-", "1", ",", "1", "]", ")", "# only self-attention", "\n", "idys", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "length_kv", ")", ",", "[", "1", ",", "-", "1", "]", ")", "\n", "ids", "=", "idxs", "-", "idys", "\n", "ids", "=", "ids", "+", "max_relative_dis", "\n", "ids", "=", "tf", ".", "maximum", "(", "ids", ",", "0", ")", "\n", "ids", "=", "tf", ".", "minimum", "(", "ids", ",", "2", "*", "max_relative_dis", ")", "\n", "ids", "=", "ids", "[", "-", "length_q", ":", ",", ":", "]", "\n", "rpr", "=", "tf", ".", "gather", "(", "orginal_var", ",", "ids", ")", "\n", "return", "rpr", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias": [[112, 162], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.matrix_band_part", "tensorflow.reshape", "tensorflow.ones", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.to_float", "tensorflow.expand_dims", "tensorflow.range", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.where", "tensorflow.cast", "tensorflow.matrix_band_part", "tensorflow.reshape", "ValueError", "tensorflow.ones", "tensorflow.matrix_band_part", "tensorflow.log", "tensorflow.ones", "tensorflow.abs"], "function", ["None"], ["", "", "def", "attention_bias", "(", "inputs", ",", "mode", ",", "inf", "=", "-", "1e9", ",", "dtype", "=", "None", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\" A bias tensor used in attention mechanism\n    :param inputs: A tensor\n    :param mode: one of \"causal\", \"masking\", \"proximal\" or \"distance\"\n    :param inf: A floating value\n    :param dtype: An instance of tf.DType\n    :param name: optional string\n    :returns: A 4D tensor with shape [batch, heads, queries, memories]\n    \"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "name", ",", "default_name", "=", "\"attention_bias\"", ",", "values", "=", "[", "inputs", "]", ")", ":", "\n", "        ", "if", "dtype", "is", "None", ":", "\n", "            ", "dtype", "=", "tf", ".", "float32", "\n", "\n", "", "if", "dtype", "!=", "tf", ".", "float32", ":", "\n", "            ", "inf", "=", "dtype", ".", "min", "\n", "\n", "", "if", "mode", "==", "\"causal\"", ":", "\n", "            ", "length", "=", "inputs", "\n", "lower_triangle", "=", "tf", ".", "matrix_band_part", "(", "\n", "tf", ".", "ones", "(", "[", "length", ",", "length", "]", ")", ",", "-", "1", ",", "0", "\n", ")", "\n", "ret", "=", "inf", "*", "(", "1.0", "-", "lower_triangle", ")", "\n", "ret", "=", "tf", ".", "reshape", "(", "ret", ",", "[", "1", ",", "1", ",", "length", ",", "length", "]", ")", "\n", "", "elif", "mode", "==", "\"masking\"", ":", "\n", "            ", "mask", "=", "inputs", "\n", "ret", "=", "(", "1.0", "-", "mask", ")", "*", "inf", "\n", "ret", "=", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "ret", ",", "1", ")", ",", "1", ")", "\n", "", "elif", "mode", "==", "\"proximal\"", ":", "\n", "            ", "length", "=", "inputs", "\n", "r", "=", "tf", ".", "to_float", "(", "tf", ".", "range", "(", "length", ")", ")", "\n", "diff", "=", "tf", ".", "expand_dims", "(", "r", ",", "0", ")", "-", "tf", ".", "expand_dims", "(", "r", ",", "1", ")", "\n", "ret", "=", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "-", "tf", ".", "log", "(", "1", "+", "tf", ".", "abs", "(", "diff", ")", ")", ",", "0", ")", ",", "\n", "0", ")", "\n", "", "elif", "mode", "==", "\"distance\"", ":", "\n", "            ", "length", ",", "distance", "=", "inputs", "\n", "distance", "=", "tf", ".", "where", "(", "distance", ">", "length", ",", "0", ",", "distance", ")", "\n", "distance", "=", "tf", ".", "cast", "(", "distance", ",", "tf", ".", "int64", ")", "\n", "lower_triangle", "=", "tf", ".", "matrix_band_part", "(", "\n", "tf", ".", "ones", "(", "[", "length", ",", "length", "]", ")", ",", "-", "1", ",", "0", "\n", ")", "\n", "mask_triangle", "=", "1.0", "-", "tf", ".", "matrix_band_part", "(", "\n", "tf", ".", "ones", "(", "[", "length", ",", "length", "]", ")", ",", "distance", "-", "1", ",", "0", "\n", ")", "\n", "ret", "=", "inf", "*", "(", "1.0", "-", "lower_triangle", "+", "mask_triangle", ")", "\n", "ret", "=", "tf", ".", "reshape", "(", "ret", ",", "[", "1", ",", "1", ",", "length", ",", "length", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown mode %s\"", "%", "mode", ")", "\n", "\n", "", "return", "tf", ".", "cast", "(", "ret", ",", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.should_generate_summaries": [[164, 173], ["tensorflow.contrib.framework.get_name_scope", "tensorflow.get_variable_scope"], "function", ["None"], ["", "", "def", "should_generate_summaries", "(", ")", ":", "\n", "    ", "\"\"\"Is this an appropriate context to generate summaries.\n    :returns: a boolean\n    \"\"\"", "\n", "if", "\"while/\"", "in", "tf", ".", "contrib", ".", "framework", ".", "get_name_scope", "(", ")", ":", "\n", "        ", "return", "False", "\n", "", "if", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_image_summary": [[175, 204], ["tensorflow.shape", "tensorflow.summary.image", "tensorflow.transpose", "tensorflow.pow", "tensorflow.pad", "tensorflow.shape", "tensorflow.reshape", "tensorflow.reduce_max", "tensorflow.reshape", "tensorflow.mod"], "function", ["None"], ["", "def", "attention_image_summary", "(", "weights", ",", "rgb", "=", "True", ")", ":", "\n", "    ", "\"\"\"Compute attention image summary.\n    :param weights: a Tensor with shape [batch, heads, queries, memories]\n    :param rgb: use RGB color to represent a head\n    \"\"\"", "\n", "shape", "=", "tf", ".", "shape", "(", "weights", ")", "\n", "batch_size", "=", "shape", "[", "0", "]", "\n", "num_heads", "=", "shape", "[", "1", "]", "\n", "num_queries", "=", "shape", "[", "2", "]", "\n", "num_memories", "=", "shape", "[", "3", "]", "\n", "\n", "if", "rgb", ":", "\n", "# [batch, queries, memories, heads]", "\n", "        ", "image", "=", "tf", ".", "transpose", "(", "weights", ",", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "# for high-dynamic-range", "\n", "image", "=", "tf", ".", "pow", "(", "image", ",", "0.2", ")", "\n", "# Each head will correspond to one of RGB", "\n", "image", "=", "tf", ".", "pad", "(", "image", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "tf", ".", "mod", "(", "-", "num_heads", ",", "3", ")", "]", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "image", ")", "\n", "# [batch, queries, memories, 3, heads]", "\n", "image", "=", "tf", ".", "reshape", "(", "image", ",", "[", "batch_size", ",", "num_queries", ",", "num_memories", ",", "\n", "3", ",", "shape", "[", "-", "1", "]", "//", "3", "]", ")", "\n", "image", "=", "tf", ".", "reduce_max", "(", "image", ",", "4", ")", "\n", "", "else", ":", "\n", "        ", "image", "=", "tf", ".", "reshape", "(", "weights", ",", "[", "-", "1", ",", "num_queries", ",", "num_memories", ",", "1", "]", ")", "\n", "\n", "# [batch, height, width, channel]", "\n", "", "tf", ".", "summary", ".", "image", "(", "\"attention\"", ",", "image", ",", "max_outputs", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention": [[206, 257], ["tensorflow.variable_scope", "tensorflow.shape", "thumt.layers.nn.linear", "tensorflow.reshape", "tensorflow.tanh", "tensorflow.reshape", "thumt.layers.nn.linear", "tensorflow.reshape", "tensorflow.nn.softmax", "memories.get_shape().as_list", "tensorflow.reshape", "thumt.layers.nn.linear", "tensorflow.reduce_sum", "memories.get_shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear"], ["", "def", "attention", "(", "query", ",", "memories", ",", "bias", ",", "hidden_size", ",", "cache", "=", "None", ",", "reuse", "=", "None", ",", "\n", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\" Standard attention layer\n\n    :param query: A tensor with shape [batch, key_size]\n    :param memories: A tensor with shape [batch, memory_size, key_size]\n    :param bias: A tensor with shape [batch, memory_size]\n    :param hidden_size: An integer\n    :param cache: A dictionary of precomputed value\n    :param reuse: A boolean value, whether to reuse the scope\n    :param dtype: An optional instance of tf.DType\n    :param scope: An optional string, the scope of this layer\n    :return: A tensor with shape [batch, value_size] and\n        a Tensor with shape [batch, memory_size]\n    \"\"\"", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"attention\"", ",", "reuse", "=", "reuse", ",", "\n", "values", "=", "[", "query", ",", "memories", ",", "bias", "]", ",", "dtype", "=", "dtype", ")", ":", "\n", "        ", "mem_shape", "=", "tf", ".", "shape", "(", "memories", ")", "\n", "key_size", "=", "memories", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "\n", "if", "cache", "is", "None", ":", "\n", "            ", "k", "=", "tf", ".", "reshape", "(", "memories", ",", "[", "-", "1", ",", "key_size", "]", ")", "\n", "k", "=", "linear", "(", "k", ",", "hidden_size", ",", "False", ",", "False", ",", "scope", "=", "\"k_transform\"", ")", "\n", "\n", "if", "query", "is", "None", ":", "\n", "                ", "return", "{", "\"key\"", ":", "k", "}", "\n", "", "", "else", ":", "\n", "            ", "k", "=", "cache", "[", "\"key\"", "]", "\n", "\n", "", "q", "=", "linear", "(", "query", ",", "hidden_size", ",", "False", ",", "False", ",", "scope", "=", "\"q_transform\"", ")", "\n", "k", "=", "tf", ".", "reshape", "(", "k", ",", "[", "mem_shape", "[", "0", "]", ",", "mem_shape", "[", "1", "]", ",", "hidden_size", "]", ")", "\n", "\n", "hidden", "=", "tf", ".", "tanh", "(", "q", "[", ":", ",", "None", ",", ":", "]", "+", "k", ")", "\n", "hidden", "=", "tf", ".", "reshape", "(", "hidden", ",", "[", "-", "1", ",", "hidden_size", "]", ")", "\n", "\n", "# Shape: [batch, mem_size, 1]", "\n", "logits", "=", "linear", "(", "hidden", ",", "1", ",", "False", ",", "False", ",", "scope", "=", "\"logits\"", ")", "\n", "logits", "=", "tf", ".", "reshape", "(", "logits", ",", "[", "-", "1", ",", "mem_shape", "[", "1", "]", "]", ")", "\n", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "logits", "=", "logits", "+", "bias", "\n", "\n", "", "alpha", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "\n", "outputs", "=", "{", "\n", "\"value\"", ":", "tf", ".", "reduce_sum", "(", "alpha", "[", ":", ",", ":", ",", "None", "]", "*", "memories", ",", "axis", "=", "1", ")", ",", "\n", "\"weight\"", ":", "alpha", "\n", "}", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.additive_attention": [[259, 312], ["tensorflow.variable_scope", "tensorflow.tile", "tensorflow.tile", "tensorflow.squeeze", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.shape", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.tanh", "thumt.layers.nn.linear", "thumt.layers.nn.linear", "tensorflow.tanh", "thumt.layers.nn.linear", "tensorflow.nn.dropout", "thumt.layers.nn.linear", "tensorflow.concat"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear"], ["", "def", "additive_attention", "(", "queries", ",", "keys", ",", "values", ",", "bias", ",", "hidden_size", ",", "concat", "=", "False", ",", "\n", "keep_prob", "=", "None", ",", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\" Additive attention mechanism. This layer is implemented using a\n        one layer feed forward neural network\n\n    :param queries: A tensor with shape [batch, heads, length_q, depth_k]\n    :param keys: A tensor with shape [batch, heads, length_kv, depth_k]\n    :param values: A tensor with shape [batch, heads, length_kv, depth_v]\n    :param bias: A tensor\n    :param hidden_size: An integer\n    :param concat: A boolean value. If ``concat'' is set to True, then\n        the computation of attention mechanism is following $tanh(W[q, k])$.\n        When ``concat'' is set to False, the computation is following\n        $tanh(Wq + Vk)$\n    :param keep_prob: a scalar in [0, 1]\n    :param dtype: An optional instance of tf.DType\n    :param scope: An optional string, the scope of this layer\n\n    :returns: A dict with the following keys:\n        weights: A tensor with shape [batch, length_q]\n        outputs: A tensor with shape [batch, length_q, depth_v]\n    \"\"\"", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"additive_attention\"", ",", "\n", "values", "=", "[", "queries", ",", "keys", ",", "values", ",", "bias", "]", ",", "dtype", "=", "dtype", ")", ":", "\n", "        ", "length_q", "=", "tf", ".", "shape", "(", "queries", ")", "[", "2", "]", "\n", "length_kv", "=", "tf", ".", "shape", "(", "keys", ")", "[", "2", "]", "\n", "q", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "queries", ",", "3", ")", ",", "[", "1", ",", "1", ",", "1", ",", "length_kv", ",", "1", "]", ")", "\n", "k", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "keys", ",", "2", ")", ",", "[", "1", ",", "1", ",", "length_q", ",", "1", ",", "1", "]", ")", "\n", "\n", "if", "concat", ":", "\n", "            ", "combined", "=", "tf", ".", "tanh", "(", "linear", "(", "tf", ".", "concat", "(", "[", "q", ",", "k", "]", ",", "axis", "=", "-", "1", ")", ",", "hidden_size", ",", "\n", "True", ",", "True", ",", "name", "=", "\"qk_transform\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "linear", "(", "queries", ",", "hidden_size", ",", "True", ",", "True", ",", "name", "=", "\"q_transform\"", ")", "\n", "k", "=", "linear", "(", "keys", ",", "hidden_size", ",", "True", ",", "True", ",", "name", "=", "\"key_transform\"", ")", "\n", "combined", "=", "tf", ".", "tanh", "(", "q", "+", "k", ")", "\n", "\n", "# shape: [batch, heads, length_q, length_kv]", "\n", "", "logits", "=", "tf", ".", "squeeze", "(", "linear", "(", "combined", ",", "1", ",", "True", ",", "True", ",", "name", "=", "\"logits\"", ")", ",", "\n", "axis", "=", "-", "1", ")", "\n", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "logits", "+=", "bias", "\n", "\n", "", "if", "dia_mask", "is", "not", "None", ":", "\n", "            ", "logits", "+=", "dia_mask", "\n", "\n", "", "weights", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ",", "name", "=", "\"attention_weights\"", ")", "\n", "\n", "if", "keep_prob", "or", "keep_prob", "<", "1.0", ":", "\n", "            ", "weights", "=", "tf", ".", "nn", ".", "dropout", "(", "weights", ",", "keep_prob", ")", "\n", "\n", "", "outputs", "=", "tf", ".", "matmul", "(", "weights", ",", "values", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multiplicative_attention": [[314, 376], ["tensorflow.name_scope", "tensorflow.shape", "tensorflow.nn.softmax", "tensorflow.shape", "tensorflow.shape", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.nn.dropout", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose"], "function", ["None"], ["return", "{", "\"weights\"", ":", "weights", ",", "\"outputs\"", ":", "outputs", "}", "\n", "\n", "\n", "", "", "def", "multiplicative_attention", "(", "queries", ",", "keys", ",", "values", ",", "bias", ",", "keep_prob", "=", "None", ",", "\n", "name", "=", "None", ",", "rpr", "=", "None", ",", "dia_mask", "=", "None", ")", ":", "\n", "    ", "\"\"\" Multiplicative attention mechanism. This layer is implemented using\n        dot-product operation.\n\n    :param queries: A tensor with shape [batch, heads, length_q, depth_k]\n    :param keys: A tensor with shape [batch, heads, length_kv, depth_k]\n    :param values: A tensor with shape [batch, heads, length_kv, depth_v]\n    :param bias: A tensor\n    :param keep_prob: a scalar in (0, 1]\n    :param name: the name of this operation\n    :param rpr: the name of this operation\n\n    :returns: A dict with the following keys:\n        weights: A tensor with shape [batch, heads, length_q, length_kv]\n        outputs: A tensor with shape [batch, heads, length_q, depth_v]\n    \"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "name", ",", "default_name", "=", "\"multiplicative_attention\"", ",", "\n", "values", "=", "[", "queries", ",", "keys", ",", "values", ",", "bias", "]", ")", ":", "\n", "\n", "        ", "q_shape", "=", "tf", ".", "shape", "(", "queries", ")", "\n", "bs", ",", "hd", ",", "lq", ",", "dk", "=", "q_shape", "[", "0", "]", ",", "q_shape", "[", "1", "]", ",", "q_shape", "[", "2", "]", ",", "q_shape", "[", "3", "]", "\n", "lk", "=", "tf", ".", "shape", "(", "keys", ")", "[", "2", "]", "\n", "dv", "=", "tf", ".", "shape", "(", "values", ")", "[", "3", "]", "\n", "\n", "if", "rpr", "is", "not", "None", ":", "\n", "            ", "rpr_k", ",", "rpr_v", "=", "rpr", "[", "'rpr_k'", "]", ",", "rpr", "[", "'rpr_v'", "]", "# (lq, lk, dk), (lq, lk, dv)", "\n", "\n", "", "if", "rpr", "is", "None", ":", "\n", "            ", "logits", "=", "tf", ".", "matmul", "(", "queries", ",", "keys", ",", "transpose_b", "=", "True", ")", "\n", "", "else", ":", "# self-attention with relative position representaion", "\n", "            ", "logits_part1", "=", "tf", ".", "matmul", "(", "queries", ",", "keys", ",", "transpose_b", "=", "True", ")", "# bs, hd, lq, lk", "\n", "\n", "queries", "=", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "queries", ",", "[", "2", ",", "0", ",", "1", ",", "3", "]", ")", ",", "[", "lq", ",", "bs", "*", "hd", ",", "dk", "]", ")", "# lq, bs*hd, dk", "\n", "logits_part2", "=", "tf", ".", "matmul", "(", "queries", ",", "tf", ".", "transpose", "(", "rpr_k", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", "# lq, bs*hd, lk", "\n", "logits_part2", "=", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "logits_part2", ",", "[", "1", ",", "0", ",", "2", "]", ")", ",", "[", "bs", ",", "hd", ",", "lq", ",", "lk", "]", ")", "\n", "\n", "logits", "=", "logits_part1", "+", "logits_part2", "# bs, hd, lq, lk", "\n", "\n", "# shape: [batch, heads, length_q, length_kv]", "\n", "", "if", "bias", "is", "not", "None", ":", "\n", "            ", "logits", "+=", "bias", "\n", "\n", "", "if", "dia_mask", "is", "not", "None", ":", "\n", "#            print(\"dia_mask\", logits, dia_mask)", "\n", "#            dia_mask = tf.expand_dims(dia_mask, 0)", "\n", "#            dia_mask = tf.tile(dia_mask, [hd, 1, 1, 1])", "\n", "#            dia_mask = tf.transpose(dia_mask, [1, 0, 2, 3])", "\n", "            ", "logits", "+=", "dia_mask", "\n", "#            print(\"test_dia_mask\", logits, dia_mask)", "\n", "#code.interact(local=locals())", "\n", "", "weights", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ",", "name", "=", "\"attention_weights\"", ")", "\n", "\n", "if", "keep_prob", "is", "not", "None", "and", "keep_prob", "<", "1.0", ":", "\n", "            ", "weights", "=", "tf", ".", "nn", ".", "dropout", "(", "weights", ",", "keep_prob", ")", "\n", "\n", "", "if", "rpr", "is", "None", ":", "\n", "            ", "outputs", "=", "tf", ".", "matmul", "(", "weights", ",", "values", ")", "# bs, hd, lq, dv", "\n", "", "else", ":", "# self-attention with relative position representaion", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multihead_attention": [[378, 480], ["ValueError", "ValueError", "tensorflow.variable_scope", "attention.split_heads", "attention.split_heads", "attention.split_heads", "attention.combine_heads", "thumt.layers.nn.linear", "tensorflow.split", "thumt.layers.nn.linear", "thumt.layers.nn.linear", "tensorflow.split", "tensorflow.shape", "tensorflow.shape", "tensorflow.get_variable", "tensorflow.get_variable", "attention.create_rpr", "attention.create_rpr", "attention.multiplicative_attention", "attention.multiplicative_attention", "thumt.layers.nn.linear", "attention.should_generate_summaries", "attention.attention_image_summary", "tensorflow.concat", "tensorflow.concat"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.split_heads", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.split_heads", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.split_heads", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.combine_heads", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.create_rpr", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.create_rpr", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multiplicative_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multiplicative_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.should_generate_summaries", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_image_summary"], ["\n", "weights", "=", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "weights", ",", "[", "2", ",", "0", ",", "1", ",", "3", "]", ")", ",", "[", "lq", ",", "bs", "*", "hd", ",", "lk", "]", ")", "# lq, bs*hd, lk", "\n", "outputs_part2", "=", "tf", ".", "matmul", "(", "weights", ",", "rpr_v", ")", "# lq, bs*hd, dv", "\n", "outputs_part2", "=", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "outputs_part2", ",", "[", "1", ",", "0", ",", "2", "]", ")", ",", "[", "bs", ",", "hd", ",", "lq", ",", "dv", "]", ")", "\n", "\n", "outputs", "=", "outputs_part1", "+", "outputs_part2", "# bs, hd, lq, dv", "\n", "weights", "=", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "weights", ",", "[", "1", ",", "0", ",", "2", "]", ")", ",", "[", "bs", ",", "hd", ",", "lq", ",", "lk", "]", ")", "# bs, hd, lq, lk", "\n", "\n", "", "return", "{", "\"weights\"", ":", "weights", ",", "\"outputs\"", ":", "outputs", "}", "\n", "\n", "\n", "", "", "def", "multihead_attention", "(", "queries", ",", "memories", ",", "bias", ",", "num_heads", ",", "key_size", ",", "\n", "value_size", ",", "output_size", ",", "keep_prob", "=", "None", ",", "output", "=", "True", ",", "\n", "state", "=", "None", ",", "summary", "=", "True", ",", "dtype", "=", "None", ",", "scope", "=", "None", ",", "\n", "max_relative_dis", "=", "None", ",", "trainable", "=", "True", ",", "dia_mask", "=", "None", ")", ":", "\n", "    ", "\"\"\" Multi-head scaled-dot-product attention with input/output\n        transformations.\n\n    :param queries: A tensor with shape [batch, length_q, depth_q]\n    :param memories: A tensor with shape [batch, length_m, depth_m]\n    :param bias: A tensor (see attention_bias)\n    :param num_heads: An integer dividing key_size and value_size\n    :param key_size: An integer\n    :param value_size: An integer\n    :param output_size: An integer\n    :param keep_prob: A floating point number in (0, 1]\n    :param output: Whether to use output transformation\n    :param state: An optional dictionary used for incremental decoding\n    :param summary: Use image summary\n    :param dtype: An optional instance of tf.DType\n    :param scope: An optional string\n    :param max_relative_dis: An integer\n\n    :returns: A dict with the following keys:\n        weights: A tensor with shape [batch, heads, length_q, length_kv]\n        outputs: A tensor with shape [batch, length_q, depth_v]\n    \"\"\"", "\n", "\n", "if", "key_size", "%", "num_heads", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"Key size (%d) must be divisible by the number of \"", "\n", "\"attention heads (%d).\"", "%", "(", "key_size", ",", "num_heads", ")", ")", "\n", "\n", "", "if", "value_size", "%", "num_heads", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"Value size (%d) must be divisible by the number of \"", "\n", "\"attention heads (%d).\"", "%", "(", "value_size", ",", "num_heads", ")", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"multihead_attention\"", ",", "\n", "values", "=", "[", "queries", ",", "memories", "]", ",", "dtype", "=", "dtype", ")", ":", "\n", "        ", "next_state", "=", "{", "}", "\n", "\n", "if", "memories", "is", "None", ":", "\n", "# self attention", "\n", "            ", "size", "=", "key_size", "*", "2", "+", "value_size", "\n", "combined", "=", "linear", "(", "queries", ",", "size", ",", "True", ",", "True", ",", "scope", "=", "\"qkv_transform\"", ",", "trainable", "=", "trainable", ")", "\n", "q", ",", "k", ",", "v", "=", "tf", ".", "split", "(", "combined", ",", "[", "key_size", ",", "key_size", ",", "value_size", "]", ",", "\n", "axis", "=", "-", "1", ")", "\n", "\n", "if", "state", "is", "not", "None", ":", "\n", "                ", "k", "=", "tf", ".", "concat", "(", "[", "state", "[", "\"key\"", "]", ",", "k", "]", ",", "axis", "=", "1", ")", "\n", "v", "=", "tf", ".", "concat", "(", "[", "state", "[", "\"value\"", "]", ",", "v", "]", ",", "axis", "=", "1", ")", "\n", "next_state", "[", "\"key\"", "]", "=", "k", "\n", "next_state", "[", "\"value\"", "]", "=", "v", "\n", "", "", "else", ":", "\n", "            ", "q", "=", "linear", "(", "queries", ",", "key_size", ",", "True", ",", "True", ",", "scope", "=", "\"q_transform\"", ",", "trainable", "=", "trainable", ")", "\n", "combined", "=", "linear", "(", "memories", ",", "key_size", "+", "value_size", ",", "True", ",", "\n", "scope", "=", "\"kv_transform\"", ",", "trainable", "=", "trainable", ")", "\n", "k", ",", "v", "=", "tf", ".", "split", "(", "combined", ",", "[", "key_size", ",", "value_size", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# split heads", "\n", "", "q", "=", "split_heads", "(", "q", ",", "num_heads", ")", "\n", "k", "=", "split_heads", "(", "k", ",", "num_heads", ")", "\n", "v", "=", "split_heads", "(", "v", ",", "num_heads", ")", "\n", "\n", "# get length", "\n", "length_q", "=", "tf", ".", "shape", "(", "q", ")", "[", "2", "]", "\n", "length_kv", "=", "tf", ".", "shape", "(", "k", ")", "[", "2", "]", "\n", "\n", "# scale query", "\n", "key_depth_per_head", "=", "key_size", "//", "num_heads", "\n", "q", "*=", "key_depth_per_head", "**", "-", "0.5", "\n", "\n", "# relative position representation (only in self-attention)", "\n", "if", "max_relative_dis", "and", "memories", "is", "None", ":", "\n", "            ", "rpr_k", "=", "tf", ".", "get_variable", "(", "'rpr_k'", ",", "[", "2", "*", "max_relative_dis", "+", "1", ",", "key_size", "//", "num_heads", "]", ",", "trainable", "=", "trainable", ")", "\n", "rpr_v", "=", "tf", ".", "get_variable", "(", "'rpr_v'", ",", "[", "2", "*", "max_relative_dis", "+", "1", ",", "value_size", "//", "num_heads", "]", ",", "trainable", "=", "trainable", ")", "\n", "rpr_k", "=", "create_rpr", "(", "rpr_k", ",", "length_q", ",", "length_kv", ",", "max_relative_dis", ")", "\n", "rpr_v", "=", "create_rpr", "(", "rpr_v", ",", "length_q", ",", "length_kv", ",", "max_relative_dis", ")", "\n", "rpr", "=", "{", "'rpr_k'", ":", "rpr_k", ",", "'rpr_v'", ":", "rpr_v", "}", "\n", "# attention", "\n", "results", "=", "multiplicative_attention", "(", "q", ",", "k", ",", "v", ",", "bias", ",", "keep_prob", ",", "rpr", "=", "rpr", ",", "dia_mask", "=", "dia_mask", ")", "\n", "", "else", ":", "\n", "# attention", "\n", "            ", "results", "=", "multiplicative_attention", "(", "q", ",", "k", ",", "v", ",", "bias", ",", "keep_prob", ",", "dia_mask", "=", "dia_mask", ")", "\n", "\n", "# combine heads", "\n", "", "weights", "=", "results", "[", "\"weights\"", "]", "\n", "x", "=", "combine_heads", "(", "results", "[", "\"outputs\"", "]", ")", "\n", "\n", "if", "output", ":", "\n", "            ", "outputs", "=", "linear", "(", "x", ",", "output_size", ",", "True", ",", "True", ",", "\n", "scope", "=", "\"output_transform\"", ",", "trainable", "=", "trainable", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "x", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear": [[11, 66], ["tensorflow.variable_scope", "tensorflow.concat", "tensorflow.add_n", "tensorflow.reshape", "isinstance", "len", "len", "RuntimeError", "tensorflow.reshape", "sum", "tensorflow.concat", "tensorflow.get_variable", "results.append", "range", "tensorflow.get_variable", "tensorflow.nn.bias_add", "tensorflow.matmul", "len", "tensorflow.get_variable", "results.append", "item.get_shape", "tensorflow.shape", "tensorflow.matmul"], "function", ["None"], ["def", "linear", "(", "inputs", ",", "output_size", ",", "bias", ",", "concat", "=", "True", ",", "dtype", "=", "None", ",", "scope", "=", "None", ",", "trainable", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Linear layer\n    :param inputs: A Tensor or a list of Tensors with shape [batch, input_size]\n    :param output_size: An integer specify the output size\n    :param bias: a boolean value indicate whether to use bias term\n    :param concat: a boolean value indicate whether to concatenate all inputs\n    :param dtype: an instance of tf.DType\n    :param scope: the scope of this layer, the default value is ``linear''\n    :returns: a Tensor with shape [batch, output_size]\n    :raises RuntimeError: raises ``RuntimeError'' when input sizes do not\n                          compatible with each other\n    \"\"\"", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"linear\"", ",", "values", "=", "[", "inputs", "]", ",", "\n", "dtype", "=", "dtype", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "inputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "inputs", "=", "[", "inputs", "]", "\n", "\n", "", "input_size", "=", "[", "item", ".", "get_shape", "(", ")", "[", "-", "1", "]", ".", "value", "for", "item", "in", "inputs", "]", "\n", "\n", "if", "len", "(", "inputs", ")", "!=", "len", "(", "input_size", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"inputs and input_size unmatched!\"", ")", "\n", "\n", "", "output_shape", "=", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "inputs", "[", "0", "]", ")", "[", ":", "-", "1", "]", ",", "[", "output_size", "]", "]", ",", "\n", "axis", "=", "0", ")", "\n", "# Flatten to 2D", "\n", "inputs", "=", "[", "tf", ".", "reshape", "(", "inp", ",", "[", "-", "1", ",", "inp", ".", "shape", "[", "-", "1", "]", ".", "value", "]", ")", "for", "inp", "in", "inputs", "]", "\n", "\n", "results", "=", "[", "]", "\n", "\n", "if", "concat", ":", "\n", "            ", "input_size", "=", "sum", "(", "input_size", ")", "\n", "inputs", "=", "tf", ".", "concat", "(", "inputs", ",", "1", ")", "\n", "\n", "shape", "=", "[", "input_size", ",", "output_size", "]", "\n", "matrix", "=", "tf", ".", "get_variable", "(", "\"matrix\"", ",", "shape", ",", "trainable", "=", "trainable", ")", "\n", "results", ".", "append", "(", "tf", ".", "matmul", "(", "inputs", ",", "matrix", ")", ")", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "input_size", ")", ")", ":", "\n", "                ", "shape", "=", "[", "input_size", "[", "i", "]", ",", "output_size", "]", "\n", "name", "=", "\"matrix_%d\"", "%", "i", "\n", "matrix", "=", "tf", ".", "get_variable", "(", "name", ",", "shape", ",", "trainable", "=", "trainable", ")", "\n", "results", ".", "append", "(", "tf", ".", "matmul", "(", "inputs", "[", "i", "]", ",", "matrix", ")", ")", "\n", "\n", "", "", "output", "=", "tf", ".", "add_n", "(", "results", ")", "\n", "\n", "if", "bias", ":", "\n", "            ", "shape", "=", "[", "output_size", "]", "\n", "bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "shape", ",", "trainable", "=", "trainable", ")", "\n", "output", "=", "tf", ".", "nn", ".", "bias_add", "(", "output", ",", "bias", ")", "\n", "\n", "", "output", "=", "tf", ".", "reshape", "(", "output", ",", "output_shape", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.maxout": [[68, 91], ["nn.linear", "tensorflow.concat", "tensorflow.reshape", "tensorflow.reduce_max", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear"], ["", "", "def", "maxout", "(", "inputs", ",", "output_size", ",", "maxpart", "=", "2", ",", "use_bias", "=", "True", ",", "concat", "=", "True", ",", "\n", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Maxout layer\n    :param inputs: see the corresponding description of ``linear''\n    :param output_size: see the corresponding description of ``linear''\n    :param maxpart: an integer, the default value is 2\n    :param use_bias: a boolean value indicate whether to use bias term\n    :param concat: concat all tensors if inputs is a list of tensors\n    :param dtype: an optional instance of tf.Dtype\n    :param scope: the scope of this layer, the default value is ``maxout''\n    :returns: a Tensor with shape [batch, output_size]\n    :raises RuntimeError: see the corresponding description of ``linear''\n    \"\"\"", "\n", "\n", "candidate", "=", "linear", "(", "inputs", ",", "output_size", "*", "maxpart", ",", "use_bias", ",", "concat", ",", "\n", "dtype", "=", "dtype", ",", "scope", "=", "scope", "or", "\"maxout\"", ")", "\n", "shape", "=", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "candidate", ")", "[", ":", "-", "1", "]", ",", "[", "output_size", ",", "maxpart", "]", "]", ",", "\n", "axis", "=", "0", ")", "\n", "value", "=", "tf", ".", "reshape", "(", "candidate", ",", "shape", ")", "\n", "output", "=", "tf", ".", "reduce_max", "(", "value", ",", "-", "1", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.layer_norm": [[93, 118], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "inputs.get_shape().as_list", "tensorflow.square", "tensorflow.rsqrt", "tensorflow.ones_initializer", "tensorflow.zeros_initializer", "inputs.get_shape"], "function", ["None"], ["", "def", "layer_norm", "(", "inputs", ",", "epsilon", "=", "1e-6", ",", "dtype", "=", "None", ",", "scope", "=", "None", ",", "trainable", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Layer Normalization\n    :param inputs: A Tensor of shape [..., channel_size]\n    :param epsilon: A floating number\n    :param dtype: An optional instance of tf.DType\n    :param scope: An optional string\n    :returns: A Tensor with the same shape as inputs\n    \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"layer_norm\"", ",", "values", "=", "[", "inputs", "]", ",", "\n", "dtype", "=", "dtype", ")", ":", "\n", "        ", "channel_size", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "\n", "scale", "=", "tf", ".", "get_variable", "(", "\"scale\"", ",", "shape", "=", "[", "channel_size", "]", ",", "\n", "initializer", "=", "tf", ".", "ones_initializer", "(", ")", ",", "trainable", "=", "trainable", ")", "\n", "\n", "offset", "=", "tf", ".", "get_variable", "(", "\"offset\"", ",", "shape", "=", "[", "channel_size", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "trainable", "=", "trainable", ")", "\n", "\n", "mean", "=", "tf", ".", "reduce_mean", "(", "inputs", ",", "-", "1", ",", "True", ")", "\n", "variance", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "inputs", "-", "mean", ")", ",", "-", "1", ",", "True", ")", "\n", "\n", "norm_inputs", "=", "(", "inputs", "-", "mean", ")", "*", "tf", ".", "rsqrt", "(", "variance", "+", "epsilon", ")", "\n", "\n", "return", "norm_inputs", "*", "scale", "+", "offset", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.convert_old_model.parseargs": [[15, 24], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["def", "parseargs", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Convert old models\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--input\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of old model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of output checkpoint\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.convert_old_model.old_keys": [[26, 71], ["None"], "function", ["None"], ["", "def", "old_keys", "(", ")", ":", "\n", "    ", "keys", "=", "[", "\n", "\"GRU_dec_attcontext\"", ",", "\n", "\"GRU_dec_att\"", ",", "\n", "\"GRU_dec_atthidden\"", ",", "\n", "\"GRU_dec_inputoffset\"", ",", "\n", "\"GRU_dec_inputemb\"", ",", "\n", "\"GRU_dec_inputcontext\"", ",", "\n", "\"GRU_dec_inputhidden\"", ",", "\n", "\"GRU_dec_resetemb\"", ",", "\n", "\"GRU_dec_resetcontext\"", ",", "\n", "\"GRU_dec_resethidden\"", ",", "\n", "\"GRU_dec_gateemb\"", ",", "\n", "\"GRU_dec_gatecontext\"", ",", "\n", "\"GRU_dec_gatehidden\"", ",", "\n", "\"initer_b\"", ",", "\n", "\"initer_W\"", ",", "\n", "\"GRU_dec_probsemb\"", ",", "\n", "\"GRU_enc_back_inputoffset\"", ",", "\n", "\"GRU_enc_back_inputemb\"", ",", "\n", "\"GRU_enc_back_inputhidden\"", ",", "\n", "\"GRU_enc_back_resetemb\"", ",", "\n", "\"GRU_enc_back_resethidden\"", ",", "\n", "\"GRU_enc_back_gateemb\"", ",", "\n", "\"GRU_enc_back_gatehidden\"", ",", "\n", "\"GRU_enc_inputoffset\"", ",", "\n", "\"GRU_enc_inputemb\"", ",", "\n", "\"GRU_enc_inputhidden\"", ",", "\n", "\"GRU_enc_resetemb\"", ",", "\n", "\"GRU_enc_resethidden\"", ",", "\n", "\"GRU_enc_gateemb\"", ",", "\n", "\"GRU_enc_gatehidden\"", ",", "\n", "\"GRU_dec_readoutoffset\"", ",", "\n", "\"GRU_dec_readoutemb\"", ",", "\n", "\"GRU_dec_readouthidden\"", ",", "\n", "\"GRU_dec_readoutcontext\"", ",", "\n", "\"GRU_dec_probsoffset\"", ",", "\n", "\"GRU_dec_probs\"", ",", "\n", "\"emb_src_b\"", ",", "\n", "\"emb_src_emb\"", ",", "\n", "\"emb_trg_b\"", ",", "\n", "\"emb_trg_emb\"", "\n", "]", "\n", "\n", "return", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.convert_old_model.new_keys": [[73, 118], ["None"], "function", ["None"], ["", "def", "new_keys", "(", ")", ":", "\n", "    ", "keys", "=", "[", "\n", "\"rnnsearch/decoder/attention/k_transform/matrix_0\"", ",", "\n", "\"rnnsearch/decoder/attention/logits/matrix_0\"", ",", "\n", "\"rnnsearch/decoder/attention/q_transform/matrix_0\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/candidate/bias\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/candidate/matrix_0\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/candidate/matrix_1\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/candidate/matrix_2\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/reset_gate/matrix_0\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/reset_gate/matrix_1\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/reset_gate/matrix_2\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/update_gate/matrix_0\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/update_gate/matrix_1\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/update_gate/matrix_2\"", ",", "\n", "\"rnnsearch/decoder/s_transform/bias\"", ",", "\n", "\"rnnsearch/decoder/s_transform/matrix_0\"", ",", "\n", "\"rnnsearch/deepout/matrix_0\"", ",", "\n", "\"rnnsearch/encoder/backward/gru_cell/candidate/bias\"", ",", "\n", "\"rnnsearch/encoder/backward/gru_cell/candidate/matrix_0\"", ",", "\n", "\"rnnsearch/encoder/backward/gru_cell/candidate/matrix_1\"", ",", "\n", "\"rnnsearch/encoder/backward/gru_cell/reset_gate/matrix_0\"", ",", "\n", "\"rnnsearch/encoder/backward/gru_cell/reset_gate/matrix_1\"", ",", "\n", "\"rnnsearch/encoder/backward/gru_cell/update_gate/matrix_0\"", ",", "\n", "\"rnnsearch/encoder/backward/gru_cell/update_gate/matrix_1\"", ",", "\n", "\"rnnsearch/encoder/forward/gru_cell/candidate/bias\"", ",", "\n", "\"rnnsearch/encoder/forward/gru_cell/candidate/matrix_0\"", ",", "\n", "\"rnnsearch/encoder/forward/gru_cell/candidate/matrix_1\"", ",", "\n", "\"rnnsearch/encoder/forward/gru_cell/reset_gate/matrix_0\"", ",", "\n", "\"rnnsearch/encoder/forward/gru_cell/reset_gate/matrix_1\"", ",", "\n", "\"rnnsearch/encoder/forward/gru_cell/update_gate/matrix_0\"", ",", "\n", "\"rnnsearch/encoder/forward/gru_cell/update_gate/matrix_1\"", ",", "\n", "\"rnnsearch/maxout/bias\"", ",", "\n", "\"rnnsearch/maxout/matrix_0\"", ",", "\n", "\"rnnsearch/maxout/matrix_1\"", ",", "\n", "\"rnnsearch/maxout/matrix_2\"", ",", "\n", "\"rnnsearch/softmax/bias\"", ",", "\n", "\"rnnsearch/softmax/matrix_0\"", ",", "\n", "\"rnnsearch/source_embedding/bias\"", ",", "\n", "\"rnnsearch/source_embedding/embedding\"", ",", "\n", "\"rnnsearch/target_embedding/bias\"", ",", "\n", "\"rnnsearch/target_embedding/embedding\"", ",", "\n", "]", "\n", "\n", "return", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.convert_old_model.main": [[120, 144], ["dict", "convert_old_model.old_keys", "convert_old_model.new_keys", "enumerate", "numpy.load", "tensorflow.Graph().as_default", "tensorflow.train.Saver", "tensorflow.device", "tensorflow.Variable", "tensorflow.Session", "sess.run", "tf.train.Saver.save", "tensorflow.Graph", "tensorflow.get_variable", "tensorflow.global_variables_initializer"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.convert_old_model.old_keys", "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.convert_old_model.new_keys"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "values", "=", "dict", "(", "np", ".", "load", "(", "args", ".", "input", ")", ")", "\n", "variables", "=", "{", "}", "\n", "o_keys", "=", "old_keys", "(", ")", "\n", "n_keys", "=", "new_keys", "(", ")", "\n", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "o_keys", ")", ":", "\n", "        ", "v", "=", "values", "[", "key", "]", "\n", "variables", "[", "n_keys", "[", "i", "]", "]", "=", "v", "\n", "\n", "", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "            ", "tf_vars", "=", "[", "\n", "tf", ".", "get_variable", "(", "v", ",", "initializer", "=", "variables", "[", "v", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "for", "v", "in", "variables", "\n", "]", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "\"global_step\"", ",", "trainable", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "int64", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf_vars", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "saver", ".", "save", "(", "sess", ",", "args", ".", "output", ",", "global_step", "=", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.shuffle_corpus.parseargs": [[22, 34], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n", "\n", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "name", "=", "args", ".", "corpus", "\n", "suffix", "=", "\".\"", "+", "args", ".", "suffix", "\n", "stream", "=", "[", "open", "(", "item", ",", "\"r\"", ")", "for", "item", "in", "name", "]", "\n", "data", "=", "[", "fd", ".", "readlines", "(", ")", "for", "fd", "in", "stream", "]", "\n", "minlen", "=", "min", "(", "[", "len", "(", "lines", ")", "for", "lines", "in", "data", "]", ")", "\n", "count", "=", "0", "\n", "\n", "if", "args", ".", "seed", ":", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.shuffle_corpus.main": [[36, 70], ["min", "numpy.arange", "numpy.random.shuffle", "numpy.arange.tolist", "shuffle_corpus._open", "fd.readlines", "numpy.random.seed", "zip", "fdr.close", "len", "fd.write", "fd.close", "shuffle_corpus._open", "shuffle_corpus._open", "range"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.visualize._open", "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.visualize._open", "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.visualize._open"], ["\n", "", "indices", "=", "numpy", ".", "arange", "(", "minlen", ")", "\n", "numpy", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "\n", "if", "args", ".", "num_shards", "==", "1", ":", "\n", "        ", "newstream", "=", "[", "[", "open", "(", "item", "+", "suffix", ",", "\"w\"", ")", "for", "item", "in", "name", "]", "]", "\n", "", "else", ":", "\n", "        ", "newstream", "=", "[", "[", "open", "(", "item", "+", "\"-%s-of-%s\"", "%", "(", "i", ",", "args", ".", "num_shards", ")", ",", "\"w\"", ")", "\n", "for", "item", "in", "name", "]", "for", "i", "in", "range", "(", "args", ".", "num_shards", ")", "]", "\n", "\n", "", "for", "idx", "in", "indices", ".", "tolist", "(", ")", ":", "\n", "        ", "lines", "=", "[", "item", "[", "idx", "]", "for", "item", "in", "data", "]", "\n", "\n", "for", "line", ",", "fd", "in", "zip", "(", "lines", ",", "newstream", "[", "count", "%", "args", ".", "num_shards", "]", ")", ":", "\n", "            ", "fd", ".", "write", "(", "line", ")", "\n", "\n", "", "count", "+=", "1", "\n", "\n", "", "for", "fdr", "in", "stream", ":", "\n", "        ", "fdr", ".", "close", "(", ")", "\n", "\n", "", "for", "fds", "in", "newstream", ":", "\n", "        ", "for", "fd", "in", "fds", ":", "\n", "            ", "fd", ".", "close", "(", ")", "\n", "\n", "\n", "", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "parsed_args", "=", "parseargs", "(", ")", "\n", "main", "(", "parsed_args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.combine.parseargs": [[17, 29], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["def", "parseargs", "(", ")", ":", "\n", "    ", "msg", "=", "\"Average checkpoints\"", "\n", "usage", "=", "\"average.py [<args>] [-h | --help]\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "msg", ",", "usage", "=", "usage", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"checkpoint dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--part\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"partial model dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "help", "=", "\"output path\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.combine.main": [[30, 78], ["tensorflow.logging.set_verbosity", "tensorflow.contrib.framework.list_variables", "tensorflow.contrib.framework.list_variables", "tensorflow.contrib.framework.load_checkpoint", "tensorflow.contrib.framework.load_checkpoint", "tensorflow.logging.info", "tensorflow.Variable", "tensorflow.train.Saver", "tensorflow.logging.info", "numpy.zeros", "tensorflow.get_variable", "tensorflow.placeholder", "tensorflow.assign", "tensorflow.global_variables", "tensorflow.Session", "sess.run", "zip", "os.path.join", "tf.train.Saver.save", "numpy.zeros", "tf.contrib.framework.load_checkpoint.get_tensor", "print", "tf.contrib.framework.load_checkpoint.get_tensor", "print", "zip", "tensorflow.global_variables_initializer", "var_values.iteritems", "sess.run"], "function", ["None"], ["", "def", "main", "(", "_", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "var_list", "=", "tf", ".", "contrib", ".", "framework", ".", "list_variables", "(", "FLAGS", ".", "model", ")", "\n", "var_part", "=", "tf", ".", "contrib", ".", "framework", ".", "list_variables", "(", "FLAGS", ".", "part", ")", "\n", "var_values", ",", "var_dtypes", "=", "{", "}", ",", "{", "}", "\n", "var_values_part", "=", "{", "}", "\n", "\n", "for", "(", "name", ",", "shape", ")", "in", "var_list", ":", "\n", "        ", "if", "True", ":", "#not name.startswith(\"global_step\") and not 'Adam' in name:", "\n", "            ", "var_values", "[", "name", "]", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "", "", "for", "(", "name", ",", "shape", ")", "in", "var_part", ":", "\n", "        ", "var_values_part", "[", "name", "]", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "\n", "", "reader", "=", "tf", ".", "contrib", ".", "framework", ".", "load_checkpoint", "(", "FLAGS", ".", "model", ")", "\n", "reader_part", "=", "tf", ".", "contrib", ".", "framework", ".", "load_checkpoint", "(", "FLAGS", ".", "part", ")", "\n", "for", "name", "in", "var_values", ":", "\n", "        ", "if", "name", "in", "var_values_part", ":", "\n", "            ", "tensor", "=", "reader_part", ".", "get_tensor", "(", "name", ")", "\n", "var_dtypes", "[", "name", "]", "=", "tensor", ".", "dtype", "\n", "var_values", "[", "name", "]", "+=", "tensor", "\n", "print", "(", "name", "+", "' in part'", ")", "\n", "", "else", ":", "\n", "            ", "tensor", "=", "reader", ".", "get_tensor", "(", "name", ")", "\n", "var_dtypes", "[", "name", "]", "=", "tensor", ".", "dtype", "\n", "var_values", "[", "name", "]", "+=", "tensor", "\n", "print", "(", "name", "+", "' is new'", ")", "\n", "", "", "tf", ".", "logging", ".", "info", "(", "\"Read from %s and %s\"", ",", "FLAGS", ".", "model", ",", "FLAGS", ".", "part", ")", "\n", "\n", "tf_vars", "=", "[", "\n", "tf", ".", "get_variable", "(", "name", ",", "shape", "=", "var_values", "[", "name", "]", ".", "shape", ",", "\n", "dtype", "=", "var_dtypes", "[", "name", "]", ")", "for", "name", "in", "var_values", "\n", "]", "\n", "placeholders", "=", "[", "tf", ".", "placeholder", "(", "v", ".", "dtype", ",", "shape", "=", "v", ".", "shape", ")", "for", "v", "in", "tf_vars", "]", "\n", "assign_ops", "=", "[", "tf", ".", "assign", "(", "v", ",", "p", ")", "for", "(", "v", ",", "p", ")", "in", "zip", "(", "tf_vars", ",", "placeholders", ")", "]", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "\"global_step\"", ",", "trainable", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "int64", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "global_variables", "(", ")", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "for", "p", ",", "assign_op", ",", "(", "name", ",", "value", ")", "in", "zip", "(", "placeholders", ",", "assign_ops", ",", "\n", "var_values", ".", "iteritems", "(", ")", ")", ":", "\n", "            ", "sess", ".", "run", "(", "assign_op", ",", "{", "p", ":", "value", "}", ")", "\n", "", "saved_name", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "output", ",", "\"new\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "saved_name", ",", "global_step", "=", "global_step", ")", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Averaged checkpoints saved in %s\"", ",", "saved_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.checkpoint_averaging.parseargs": [[18, 30], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["    ", "msg", "=", "\"Average checkpoints\"", "\n", "usage", "=", "\"average.py [<args>] [-h | --help]\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "msg", ",", "usage", "=", "usage", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--path\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"checkpoint dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoints\"", ",", "type", "=", "int", ",", "required", "=", "True", ",", "\n", "help", "=", "\"number of checkpoints to use\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "help", "=", "\"output path\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.checkpoint_averaging.get_checkpoints": [[32, 50], ["sorted", "tensorflow.gfile.Exists", "ValueError", "tensorflow.gfile.GFile", "fd.readline", "os.path.join", "os.path.join", "int", "checkpoint_names.append", "operator.itemgetter", "[].strip", "name.split", "os.path.join", "line.strip().split", "line.strip"], "function", ["None"], ["    ", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"checkpoint\"", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Cannot find checkpoints in %s\"", "%", "path", ")", "\n", "\n", "", "checkpoint_names", "=", "[", "]", "\n", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"checkpoint\"", ")", ")", "as", "fd", ":", "\n", "# Skip the first line", "\n", "        ", "fd", ".", "readline", "(", ")", "\n", "for", "line", "in", "fd", ":", "\n", "            ", "name", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\":\"", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "[", "1", ":", "-", "1", "]", "\n", "key", "=", "int", "(", "name", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ")", "\n", "checkpoint_names", ".", "append", "(", "(", "key", ",", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", ")", ")", "\n", "\n", "", "", "sorted_names", "=", "sorted", "(", "checkpoint_names", ",", "key", "=", "operator", ".", "itemgetter", "(", "0", ")", ",", "\n", "reverse", "=", "True", ")", "\n", "\n", "return", "[", "item", "[", "-", "1", "]", "for", "item", "in", "sorted_names", "]", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.checkpoint_averaging.checkpoint_exists": [[52, 55], ["tensorflow.gfile.Exists", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists"], "function", ["None"], ["    ", "return", "(", "tf", ".", "gfile", ".", "Exists", "(", "path", ")", "or", "tf", ".", "gfile", ".", "Exists", "(", "path", "+", "\".meta\"", ")", "or", "\n", "tf", ".", "gfile", ".", "Exists", "(", "path", "+", "\".index\"", ")", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.checkpoint_averaging.main": [[57, 118], ["tensorflow.logging.set_verbosity", "checkpoint_averaging.get_checkpoints", "tensorflow.contrib.framework.list_variables", "tensorflow.Variable", "tensorflow.train.Saver", "tensorflow.logging.info", "os.path.join", "tensorflow.gfile.Glob", "ValueError", "ValueError", "tensorflow.contrib.framework.load_checkpoint", "tensorflow.logging.info", "len", "tensorflow.get_variable", "tensorflow.placeholder", "tensorflow.assign", "tensorflow.global_variables", "tensorflow.Session", "sess.run", "zip", "os.path.join", "tf.train.Saver.save", "name.replace", "tensorflow.gfile.Copy", "checkpoint_averaging.checkpoint_exists", "name.startswith", "numpy.zeros", "tf.contrib.framework.load_checkpoint.get_tensor", "zip", "tensorflow.global_variables_initializer", "six.iteritems", "sess.run", "FLAGS.path.rstrip", "FLAGS.output.rstrip"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.checkpoint_averaging.get_checkpoints", "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.checkpoint_averaging.checkpoint_exists"], ["    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "checkpoints", "=", "get_checkpoints", "(", "FLAGS", ".", "path", ")", "\n", "checkpoints", "=", "checkpoints", "[", ":", "FLAGS", ".", "checkpoints", "]", "\n", "\n", "if", "not", "checkpoints", ":", "\n", "        ", "raise", "ValueError", "(", "\"No checkpoints provided for averaging.\"", ")", "\n", "\n", "", "checkpoints", "=", "[", "c", "for", "c", "in", "checkpoints", "if", "checkpoint_exists", "(", "c", ")", "]", "\n", "\n", "if", "not", "checkpoints", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"None of the provided checkpoints exist. %s\"", "%", "FLAGS", ".", "checkpoints", "\n", ")", "\n", "\n", "", "var_list", "=", "tf", ".", "contrib", ".", "framework", ".", "list_variables", "(", "checkpoints", "[", "0", "]", ")", "\n", "var_values", ",", "var_dtypes", "=", "{", "}", ",", "{", "}", "\n", "\n", "for", "(", "name", ",", "shape", ")", "in", "var_list", ":", "\n", "        ", "if", "not", "name", ".", "startswith", "(", "\"global_step\"", ")", ":", "\n", "            ", "var_values", "[", "name", "]", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "\n", "", "", "for", "checkpoint", "in", "checkpoints", ":", "\n", "        ", "reader", "=", "tf", ".", "contrib", ".", "framework", ".", "load_checkpoint", "(", "checkpoint", ")", "\n", "for", "name", "in", "var_values", ":", "\n", "            ", "tensor", "=", "reader", ".", "get_tensor", "(", "name", ")", "\n", "var_dtypes", "[", "name", "]", "=", "tensor", ".", "dtype", "\n", "var_values", "[", "name", "]", "+=", "tensor", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Read from checkpoint %s\"", ",", "checkpoint", ")", "\n", "\n", "# Average checkpoints", "\n", "", "for", "name", "in", "var_values", ":", "\n", "        ", "var_values", "[", "name", "]", "/=", "len", "(", "checkpoints", ")", "\n", "\n", "", "tf_vars", "=", "[", "\n", "tf", ".", "get_variable", "(", "name", ",", "shape", "=", "var_values", "[", "name", "]", ".", "shape", ",", "\n", "dtype", "=", "var_dtypes", "[", "name", "]", ")", "for", "name", "in", "var_values", "\n", "]", "\n", "placeholders", "=", "[", "tf", ".", "placeholder", "(", "v", ".", "dtype", ",", "shape", "=", "v", ".", "shape", ")", "for", "v", "in", "tf_vars", "]", "\n", "assign_ops", "=", "[", "tf", ".", "assign", "(", "v", ",", "p", ")", "for", "(", "v", ",", "p", ")", "in", "zip", "(", "tf_vars", ",", "placeholders", ")", "]", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "\"global_step\"", ",", "trainable", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "int64", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "global_variables", "(", ")", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "for", "p", ",", "assign_op", ",", "(", "name", ",", "value", ")", "in", "zip", "(", "placeholders", ",", "assign_ops", ",", "\n", "var_values", ".", "items", "(", ")", ")", ":", "\n", "            ", "sess", ".", "run", "(", "assign_op", ",", "{", "p", ":", "value", "}", ")", "\n", "", "saved_name", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "output", ",", "\"average\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "saved_name", ",", "global_step", "=", "global_step", ")", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Averaged checkpoints saved in %s\"", ",", "saved_name", ")", "\n", "\n", "params_pattern", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "path", ",", "\"*.json\"", ")", "\n", "params_files", "=", "tf", ".", "gfile", ".", "Glob", "(", "params_pattern", ")", "\n", "\n", "for", "name", "in", "params_files", ":", "\n", "        ", "new_name", "=", "name", ".", "replace", "(", "FLAGS", ".", "path", ".", "rstrip", "(", "\"/\"", ")", ",", "\n", "FLAGS", ".", "output", ".", "rstrip", "(", "\"/\"", ")", ")", "\n", "tf", ".", "gfile", ".", "Copy", "(", "name", ",", "new_name", ",", "overwrite", "=", "True", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.compare.parseargs": [[17, 28], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["def", "parseargs", "(", ")", ":", "\n", "    ", "msg", "=", "\"Average checkpoints\"", "\n", "usage", "=", "\"average.py [<args>] [-h | --help]\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "msg", ",", "usage", "=", "usage", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"checkpoint dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--part\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"partial model dir\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.compare.main": [[29, 54], ["tensorflow.logging.set_verbosity", "tensorflow.contrib.framework.list_variables", "tensorflow.contrib.framework.list_variables", "tensorflow.contrib.framework.load_checkpoint", "tensorflow.contrib.framework.load_checkpoint", "tensorflow.logging.info", "numpy.zeros", "numpy.zeros", "tf.contrib.framework.load_checkpoint.get_tensor", "tf.contrib.framework.load_checkpoint.get_tensor", "print", "reader.get_tensor.equal", "type", "print", "print"], "function", ["None"], ["", "def", "main", "(", "_", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "var_list", "=", "tf", ".", "contrib", ".", "framework", ".", "list_variables", "(", "FLAGS", ".", "model", ")", "\n", "var_part", "=", "tf", ".", "contrib", ".", "framework", ".", "list_variables", "(", "FLAGS", ".", "part", ")", "\n", "var_values", ",", "var_dtypes", "=", "{", "}", ",", "{", "}", "\n", "var_values_part", "=", "{", "}", "\n", "\n", "for", "(", "name", ",", "shape", ")", "in", "var_list", ":", "\n", "        ", "var_values", "[", "name", "]", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "", "for", "(", "name", ",", "shape", ")", "in", "var_part", ":", "\n", "        ", "var_values_part", "[", "name", "]", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "\n", "", "reader", "=", "tf", ".", "contrib", ".", "framework", ".", "load_checkpoint", "(", "FLAGS", ".", "model", ")", "\n", "reader_part", "=", "tf", ".", "contrib", ".", "framework", ".", "load_checkpoint", "(", "FLAGS", ".", "part", ")", "\n", "for", "name", "in", "var_values", ":", "\n", "        ", "if", "name", "in", "var_values_part", ":", "\n", "            ", "tensor_part", "=", "reader_part", ".", "get_tensor", "(", "name", ")", "\n", "tensor", "=", "reader", ".", "get_tensor", "(", "name", ")", "\n", "print", "(", "type", "(", "tensor", ")", ")", "\n", "if", "tensor", ".", "equal", "(", "tensor_part", ")", ":", "\n", "                ", "print", "(", "'name '", "+", "name", "+", "' equals'", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'name '", "+", "name", "+", "' is different'", ")", "\n", "", "", "", "tf", ".", "logging", ".", "info", "(", "\"Read from %s and %s\"", ",", "FLAGS", ".", "model", ",", "FLAGS", ".", "part", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.check_param.parseargs": [[17, 26], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["def", "parseargs", "(", ")", ":", "\n", "    ", "msg", "=", "\"Average checkpoints\"", "\n", "usage", "=", "\"average.py [<args>] [-h | --help]\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "msg", ",", "usage", "=", "usage", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"checkpoint dir\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.check_param.main": [[27, 44], ["tensorflow.logging.set_verbosity", "tensorflow.contrib.framework.list_variables", "print", "print", "len", "print", "name.replace.replace", "numpy.zeros"], "function", ["None"], ["", "def", "main", "(", "_", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "var_list", "=", "tf", ".", "contrib", ".", "framework", ".", "list_variables", "(", "FLAGS", ".", "model", ")", "\n", "var_values", ",", "var_dtypes", "=", "{", "}", ",", "{", "}", "\n", "model_from", "=", "\"transformer_cov\"", "\n", "model_to", "=", "\"transformer_lrp\"", "\n", "\n", "count", "=", "0", "\n", "for", "(", "name", ",", "shape", ")", "in", "var_list", ":", "\n", "        ", "if", "True", ":", "#not name.startswith(\"global_step\") and not 'Adam' in name:", "\n", "            ", "count", "+=", "1", "\n", "print", "(", "name", ",", "shape", ")", "\n", "name", "=", "name", ".", "replace", "(", "model_from", ",", "model_to", ")", "\n", "var_values", "[", "name", "]", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "", "", "print", "(", "len", "(", "var_list", ")", ")", "\n", "print", "(", "count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.combine_add.parseargs": [[17, 29], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["def", "parseargs", "(", ")", ":", "\n", "    ", "msg", "=", "\"Average checkpoints\"", "\n", "usage", "=", "\"average.py [<args>] [-h | --help]\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "msg", ",", "usage", "=", "usage", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"checkpoint dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--part\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"partial model dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "help", "=", "\"output path\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.combine_add.main": [[30, 79], ["tensorflow.logging.set_verbosity", "tensorflow.contrib.framework.list_variables", "tensorflow.contrib.framework.list_variables", "tensorflow.contrib.framework.load_checkpoint", "tensorflow.contrib.framework.load_checkpoint", "tensorflow.logging.info", "tensorflow.Variable", "tensorflow.train.Saver", "tensorflow.logging.info", "numpy.zeros", "numpy.zeros", "tensorflow.get_variable", "tensorflow.placeholder", "tensorflow.assign", "tensorflow.global_variables", "tensorflow.Session", "sess.run", "zip", "os.path.join", "tf.train.Saver.save", "numpy.zeros", "tf.contrib.framework.load_checkpoint.get_tensor", "print", "tf.contrib.framework.load_checkpoint.get_tensor", "print", "zip", "tensorflow.global_variables_initializer", "six.iteritems", "sess.run"], "function", ["None"], ["", "def", "main", "(", "_", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "var_list", "=", "tf", ".", "contrib", ".", "framework", ".", "list_variables", "(", "FLAGS", ".", "model", ")", "\n", "var_part", "=", "tf", ".", "contrib", ".", "framework", ".", "list_variables", "(", "FLAGS", ".", "part", ")", "\n", "var_values", ",", "var_dtypes", "=", "{", "}", ",", "{", "}", "\n", "var_values_part", "=", "{", "}", "\n", "\n", "for", "(", "name", ",", "shape", ")", "in", "var_list", ":", "\n", "        ", "if", "True", ":", "#not name.startswith(\"global_step\") and not 'Adam' in name:", "\n", "            ", "var_values", "[", "name", "]", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "", "", "for", "(", "name", ",", "shape", ")", "in", "var_part", ":", "\n", "        ", "var_values", "[", "name", "]", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "var_values_part", "[", "name", "]", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "\n", "", "reader", "=", "tf", ".", "contrib", ".", "framework", ".", "load_checkpoint", "(", "FLAGS", ".", "model", ")", "\n", "reader_part", "=", "tf", ".", "contrib", ".", "framework", ".", "load_checkpoint", "(", "FLAGS", ".", "part", ")", "\n", "for", "name", "in", "var_values", ":", "\n", "        ", "if", "name", "in", "var_values_part", ":", "\n", "            ", "tensor", "=", "reader_part", ".", "get_tensor", "(", "name", ")", "\n", "var_dtypes", "[", "name", "]", "=", "tensor", ".", "dtype", "\n", "var_values", "[", "name", "]", "+=", "tensor", "\n", "print", "(", "name", "+", "' in part'", ")", "\n", "", "else", ":", "\n", "            ", "tensor", "=", "reader", ".", "get_tensor", "(", "name", ")", "\n", "var_dtypes", "[", "name", "]", "=", "tensor", ".", "dtype", "\n", "var_values", "[", "name", "]", "+=", "tensor", "\n", "print", "(", "name", "+", "' is new'", ")", "\n", "", "", "tf", ".", "logging", ".", "info", "(", "\"Read from %s and %s\"", ",", "FLAGS", ".", "model", ",", "FLAGS", ".", "part", ")", "\n", "\n", "tf_vars", "=", "[", "\n", "tf", ".", "get_variable", "(", "name", ",", "shape", "=", "var_values", "[", "name", "]", ".", "shape", ",", "\n", "dtype", "=", "var_dtypes", "[", "name", "]", ")", "for", "name", "in", "var_values", "\n", "]", "\n", "placeholders", "=", "[", "tf", ".", "placeholder", "(", "v", ".", "dtype", ",", "shape", "=", "v", ".", "shape", ")", "for", "v", "in", "tf_vars", "]", "\n", "assign_ops", "=", "[", "tf", ".", "assign", "(", "v", ",", "p", ")", "for", "(", "v", ",", "p", ")", "in", "zip", "(", "tf_vars", ",", "placeholders", ")", "]", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "\"global_step\"", ",", "trainable", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "int64", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "global_variables", "(", ")", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "for", "p", ",", "assign_op", ",", "(", "name", ",", "value", ")", "in", "zip", "(", "placeholders", ",", "assign_ops", ",", "\n", "six", ".", "iteritems", "(", "var_values", ")", ")", ":", "#var_values.iteritems()):", "\n", "            ", "sess", ".", "run", "(", "assign_op", ",", "{", "p", ":", "value", "}", ")", "\n", "", "saved_name", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "output", ",", "\"new\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "saved_name", ",", "global_step", "=", "global_step", ")", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Averaged checkpoints saved in %s\"", ",", "saved_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.input_converter.load_vocab": [[16, 26], ["tensorflow.gfile.Open", "line.strip"], "function", ["None"], ["def", "load_vocab", "(", "filename", ")", ":", "\n", "    ", "with", "tf", ".", "gfile", ".", "Open", "(", "filename", ")", "as", "fd", ":", "\n", "        ", "count", "=", "0", "\n", "vocab", "=", "{", "}", "\n", "for", "line", "in", "fd", ":", "\n", "            ", "word", "=", "line", ".", "strip", "(", ")", "\n", "vocab", "[", "word", "]", "=", "count", "\n", "count", "+=", "1", "\n", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.input_converter.to_example": [[28, 50], ["six.iteritems", "tensorflow.train.Example", "isinstance", "ValueError", "tensorflow.train.Int64List", "tensorflow.train.Feature", "isinstance", "tensorflow.train.Features", "str", "tensorflow.train.FloatList", "tensorflow.train.Feature", "isinstance", "tensorflow.train.BytesList", "tensorflow.train.Feature", "ValueError", "str", "str", "type"], "function", ["None"], ["", "def", "to_example", "(", "dictionary", ")", ":", "\n", "    ", "\"\"\" Convert python dictionary to tf.train.Example \"\"\"", "\n", "features", "=", "{", "}", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "dictionary", ")", ":", "\n", "        ", "if", "not", "v", ":", "\n", "            ", "raise", "ValueError", "(", "\"Empty generated field: %s\"", ",", "str", "(", "(", "k", ",", "v", ")", ")", ")", "\n", "\n", "", "if", "isinstance", "(", "v", "[", "0", "]", ",", "six", ".", "integer_types", ")", ":", "\n", "            ", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "v", ")", "\n", "features", "[", "k", "]", "=", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "int64_list", ")", "\n", "", "elif", "isinstance", "(", "v", "[", "0", "]", ",", "float", ")", ":", "\n", "            ", "float_list", "=", "tf", ".", "train", ".", "FloatList", "(", "value", "=", "v", ")", "\n", "features", "[", "k", "]", "=", "tf", ".", "train", ".", "Feature", "(", "float_list", "=", "float_list", ")", "\n", "", "elif", "isinstance", "(", "v", "[", "0", "]", ",", "six", ".", "string_types", ")", ":", "\n", "            ", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "v", ")", "\n", "features", "[", "k", "]", "=", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "bytes_list", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Value is neither an int nor a float; \"", "\n", "\"v: %s type: %s\"", "%", "(", "str", "(", "v", "[", "0", "]", ")", ",", "str", "(", "type", "(", "v", "[", "0", "]", ")", ")", ")", ")", "\n", "\n", "", "", "return", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "features", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.input_converter.write_records": [[52, 62], ["tensorflow.python_io.TFRecordWriter", "enumerate", "tf.python_io.TFRecordWriter.close", "tf.python_io.TFRecordWriter.write", "tensorflow.logging.info"], "function", ["None"], ["", "def", "write_records", "(", "records", ",", "out_filename", ")", ":", "\n", "    ", "\"\"\" Write to TensorFlow record \"\"\"", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "out_filename", ")", "\n", "\n", "for", "count", ",", "record", "in", "enumerate", "(", "records", ")", ":", "\n", "        ", "writer", ".", "write", "(", "record", ")", "\n", "if", "count", "%", "10000", "==", "0", ":", "\n", "            ", "tf", ".", "logging", ".", "info", "(", "\"write: %d\"", ",", "count", ")", "\n", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.input_converter.convert_to_record": [[64, 111], ["xrange", "tensorflow.gfile.Open", "os.path.join", "output_files.append", "writers.append", "random.shuffle", "input_converter.to_example", "writers[].write", "writer.close", "tensorflow.gfile.Open", "zip", "tensorflow.python_io.TFRecordWriter", "to_example.SerializeToString", "sline.strip().split.strip().split", "tline.strip().split.strip().split", "records.append", "sline.strip().split.strip", "tline.strip().split.strip", "len", "len"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.input_converter.to_example"], ["", "def", "convert_to_record", "(", "inputs", ",", "vocab", ",", "output_name", ",", "output_dir", ",", "num_shards", ",", "\n", "shuffle", "=", "False", ")", ":", "\n", "    ", "\"\"\" Convert plain parallel text to TensorFlow record \"\"\"", "\n", "source", ",", "target", "=", "inputs", "\n", "svocab", ",", "tvocab", "=", "vocab", "\n", "records", "=", "[", "]", "\n", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "source", ")", "as", "src", ":", "\n", "        ", "with", "tf", ".", "gfile", ".", "Open", "(", "target", ")", "as", "tgt", ":", "\n", "            ", "for", "sline", ",", "tline", "in", "zip", "(", "src", ",", "tgt", ")", ":", "\n", "                ", "sline", "=", "sline", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "sline", "=", "[", "svocab", "[", "item", "]", "if", "item", "in", "svocab", "else", "svocab", "[", "FLAGS", ".", "unk", "]", "\n", "for", "item", "in", "sline", "]", "+", "[", "svocab", "[", "FLAGS", ".", "eos", "]", "]", "\n", "tline", "=", "tline", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "tline", "=", "[", "tvocab", "[", "item", "]", "if", "item", "in", "tvocab", "else", "tvocab", "[", "FLAGS", ".", "unk", "]", "\n", "for", "item", "in", "tline", "]", "+", "[", "tvocab", "[", "FLAGS", ".", "eos", "]", "]", "\n", "\n", "feature", "=", "{", "\n", "\"source\"", ":", "sline", ",", "\n", "\"target\"", ":", "tline", ",", "\n", "\"source_length\"", ":", "[", "len", "(", "sline", ")", "]", ",", "\n", "\"target_length\"", ":", "[", "len", "(", "tline", ")", "]", "\n", "}", "\n", "records", ".", "append", "(", "feature", ")", "\n", "\n", "", "", "", "output_files", "=", "[", "]", "\n", "writers", "=", "[", "]", "\n", "\n", "for", "shard", "in", "xrange", "(", "num_shards", ")", ":", "\n", "        ", "output_filename", "=", "\"%s-%.5d-of-%.5d\"", "%", "(", "output_name", ",", "shard", ",", "num_shards", ")", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "output_filename", ")", "\n", "output_files", ".", "append", "(", "output_file", ")", "\n", "writers", ".", "append", "(", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "output_file", ")", ")", "\n", "\n", "", "counter", ",", "shard", "=", "0", ",", "0", "\n", "\n", "if", "shuffle", ":", "\n", "        ", "random", ".", "shuffle", "(", "records", ")", "\n", "\n", "", "for", "record", "in", "records", ":", "\n", "        ", "counter", "+=", "1", "\n", "example", "=", "to_example", "(", "record", ")", "\n", "writers", "[", "shard", "]", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "shard", "=", "(", "shard", "+", "1", ")", "%", "num_shards", "\n", "\n", "", "for", "writer", "in", "writers", ":", "\n", "        ", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.input_converter.parse_args": [[113, 136], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "msg", "=", "\"convert inputs to tf.Record format\"", "\n", "usage", "=", "\"input_converter.py [<args>] [-h | --help]\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "msg", ",", "usage", "=", "usage", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--input\"", ",", "required", "=", "True", ",", "type", "=", "str", ",", "nargs", "=", "2", ",", "\n", "help", "=", "\"Path of input file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_name\"", ",", "required", "=", "True", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Output name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "required", "=", "True", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocab\"", ",", "nargs", "=", "2", ",", "required", "=", "True", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of vocabulary\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_shards\"", ",", "default", "=", "100", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Number of output shards\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--shuffle\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Shuffle inputs\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--unk\"", ",", "default", "=", "\"<unk>\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Unknown word symbol\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eos\"", ",", "default", "=", "\"<eos>\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"End of sentence symbol\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.input_converter.main": [[138, 145], ["input_converter.load_vocab", "input_converter.load_vocab", "input_converter.convert_to_record"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.input_converter.load_vocab", "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.input_converter.load_vocab", "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.input_converter.convert_to_record"], ["", "def", "main", "(", "_", ")", ":", "\n", "    ", "svocab", "=", "load_vocab", "(", "FLAGS", ".", "vocab", "[", "0", "]", ")", "\n", "tvocab", "=", "load_vocab", "(", "FLAGS", ".", "vocab", "[", "1", "]", ")", "\n", "\n", "# convert data", "\n", "convert_to_record", "(", "FLAGS", ".", "input", ",", "[", "svocab", ",", "tvocab", "]", ",", "FLAGS", ".", "output_name", ",", "\n", "FLAGS", ".", "output_dir", ",", "FLAGS", ".", "num_shards", ",", "FLAGS", ".", "shuffle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.change.parseargs": [[17, 27], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["def", "parseargs", "(", ")", ":", "\n", "    ", "msg", "=", "\"Average checkpoints\"", "\n", "usage", "=", "\"average.py [<args>] [-h | --help]\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "msg", ",", "usage", "=", "usage", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"checkpoint dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "help", "=", "\"output path\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.change.main": [[28, 69], ["tensorflow.logging.set_verbosity", "tensorflow.contrib.framework.list_variables", "tensorflow.contrib.framework.load_checkpoint", "tensorflow.logging.info", "tensorflow.Variable", "tensorflow.train.Saver", "tensorflow.logging.info", "name.replace.replace", "tf.contrib.framework.load_checkpoint.get_tensor", "tensorflow.get_variable", "tensorflow.placeholder", "tensorflow.assign", "tensorflow.global_variables", "tensorflow.Session", "sess.run", "zip", "os.path.join", "tf.train.Saver.save", "name.replace.replace", "numpy.zeros", "print", "zip", "tensorflow.global_variables_initializer", "var_values.iteritems", "sess.run"], "function", ["None"], ["", "def", "main", "(", "_", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "var_list", "=", "tf", ".", "contrib", ".", "framework", ".", "list_variables", "(", "FLAGS", ".", "model", ")", "\n", "var_values", ",", "var_dtypes", "=", "{", "}", ",", "{", "}", "\n", "model_from", "=", "\"transformer\"", "\n", "model_to", "=", "\"contextual_transformer\"", "\n", "\n", "for", "(", "name", ",", "shape", ")", "in", "var_list", ":", "\n", "        ", "if", "True", ":", "#not name.startswith(\"global_step\") and not 'Adam' in name:", "\n", "            ", "name", "=", "name", ".", "replace", "(", "model_from", ",", "model_to", ")", "\n", "var_values", "[", "name", "]", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "print", "(", "name", ")", "\n", "\n", "", "", "reader", "=", "tf", ".", "contrib", ".", "framework", ".", "load_checkpoint", "(", "FLAGS", ".", "model", ")", "\n", "for", "name", "in", "var_values", ":", "\n", "        ", "name_ori", "=", "name", ".", "replace", "(", "model_to", ",", "model_from", ")", "\n", "tensor", "=", "reader", ".", "get_tensor", "(", "name_ori", ")", "\n", "var_dtypes", "[", "name", "]", "=", "tensor", ".", "dtype", "\n", "var_values", "[", "name", "]", "+=", "tensor", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Read from %s\"", ",", "FLAGS", ".", "model", ")", "\n", "\n", "tf_vars", "=", "[", "\n", "tf", ".", "get_variable", "(", "name", ",", "shape", "=", "var_values", "[", "name", "]", ".", "shape", ",", "\n", "dtype", "=", "var_dtypes", "[", "name", "]", ")", "for", "name", "in", "var_values", "\n", "]", "\n", "placeholders", "=", "[", "tf", ".", "placeholder", "(", "v", ".", "dtype", ",", "shape", "=", "v", ".", "shape", ")", "for", "v", "in", "tf_vars", "]", "\n", "assign_ops", "=", "[", "tf", ".", "assign", "(", "v", ",", "p", ")", "for", "(", "v", ",", "p", ")", "in", "zip", "(", "tf_vars", ",", "placeholders", ")", "]", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "\"global_step\"", ",", "trainable", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "int64", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "global_variables", "(", ")", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "for", "p", ",", "assign_op", ",", "(", "name", ",", "value", ")", "in", "zip", "(", "placeholders", ",", "assign_ops", ",", "\n", "var_values", ".", "iteritems", "(", ")", ")", ":", "\n", "            ", "sess", ".", "run", "(", "assign_op", ",", "{", "p", ":", "value", "}", ")", "\n", "", "saved_name", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "output", ",", "\"new\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "saved_name", ",", "global_step", "=", "global_step", ")", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Averaged checkpoints saved in %s\"", ",", "saved_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.count_words": [[23, 35], ["collections.Counter", "sorted", "list", "build_vocab._open", "collections.Counter.items", "zip", "line.strip().split", "collections.Counter.update", "line.strip"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.visualize._open"], ["\n", "return", "words", ",", "counts", "\n", "\n", "\n", "", "def", "control_symbols", "(", "string", ")", ":", "\n", "    ", "if", "not", "string", ":", "\n", "        ", "return", "[", "]", "\n", "", "else", ":", "\n", "        ", "return", "string", ".", "strip", "(", ")", ".", "split", "(", "\",\"", ")", "\n", "\n", "\n", "", "", "def", "save_vocab", "(", "name", ",", "vocab", ")", ":", "\n", "    ", "if", "name", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "!=", "\"txt\"", ":", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.control_symbols": [[37, 42], ["string.strip().split", "string.strip"], "function", ["None"], ["\n", "", "pairs", "=", "sorted", "(", "vocab", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "(", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ")", "\n", "words", ",", "ids", "=", "list", "(", "zip", "(", "*", "pairs", ")", ")", "\n", "\n", "with", "open", "(", "name", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "word", "in", "words", ":", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.save_vocab": [[44, 54], ["sorted", "list", "vocab.items", "zip", "build_vocab._open", "name.split", "f.write"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.visualize._open"], ["\n", "\n", "", "", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Create vocabulary\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"corpus\"", ",", "help", "=", "\"input corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"output\"", ",", "default", "=", "\"vocab.txt\"", ",", "\n", "help", "=", "\"Output vocabulary name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--limit\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Vocabulary size\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--control\"", ",", "type", "=", "str", ",", "default", "=", "\"<pad>,<eos>,<unk>\"", ",", "\n", "help", "=", "\"Add control symbols to vocabulary. \"", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args": [[56, 68], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.parse_args"], ["\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n", "\n", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "vocab", "=", "{", "}", "\n", "limit", "=", "args", ".", "limit", "\n", "count", "=", "0", "\n", "\n", "words", ",", "counts", "=", "count_words", "(", "args", ".", "corpus", ")", "\n", "ctrl_symbols", "=", "control_symbols", "(", "args", ".", "control", ")", "\n", "\n", "for", "sym", "in", "ctrl_symbols", ":", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.main": [[70, 97], ["build_vocab.count_words", "build_vocab.control_symbols", "zip", "build_vocab.save_vocab", "print", "print", "print", "len", "len", "print", "sum", "len", "len", "sum"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.count_words", "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.control_symbols", "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab.save_vocab"], ["\n", "", "for", "word", ",", "freq", "in", "zip", "(", "words", ",", "counts", ")", ":", "\n", "        ", "if", "limit", "and", "len", "(", "vocab", ")", ">=", "limit", ":", "\n", "            ", "break", "\n", "\n", "", "if", "word", "in", "vocab", ":", "\n", "            ", "print", "(", "\"Warning: found duplicate token %s, ignored\"", "%", "word", ")", "\n", "continue", "\n", "\n", "", "vocab", "[", "word", "]", "=", "len", "(", "vocab", ")", "\n", "count", "+=", "freq", "\n", "\n", "", "save_vocab", "(", "args", ".", "output", ",", "vocab", ")", "\n", "\n", "print", "(", "\"Total words: %d\"", "%", "sum", "(", "counts", ")", ")", "\n", "print", "(", "\"Unique words: %d\"", "%", "len", "(", "words", ")", ")", "\n", "print", "(", "\"Vocabulary coverage: %4.2f%%\"", "%", "(", "100.0", "*", "count", "/", "sum", "(", "counts", ")", ")", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "main", "(", "parse_args", "(", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.visualize.parse_numpy": [[19, 24], ["re.sub.replace().replace().replace", "re.sub", "numpy.fromstring", "re.sub.replace().replace", "re.sub.replace"], "function", ["None"], ["fontP", ".", "set_size", "(", "14", ")", "\n", "\n", "# parse from text", "\n", "result", "=", "open", "(", "sys", ".", "argv", "[", "1", "]", ",", "'r'", ")", ".", "read", "(", ")", "\n", "src", "=", "re", ".", "findall", "(", "'src: (.*?)\\n'", ",", "result", ")", "[", "0", "]", "\n", "src", "=", "src", ".", "decode", "(", "'utf-8'", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.convert_vocab._open": [[13, 20], ["open", "open", "RuntimeError"], "function", ["None"], ["    ", "with", "open", "(", "sys", ".", "argv", "[", "1", "]", ")", "as", "fd", ":", "\n", "        ", "voc", "=", "pickle", ".", "load", "(", "fd", ")", "\n", "\n", "", "ivoc", "=", "{", "}", "\n", "\n", "for", "key", "in", "voc", ":", "\n", "        ", "ivoc", "[", "voc", "[", "key", "]", "]", "=", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.shuffle_corpus._open": [[13, 20], ["open", "open", "RuntimeError"], "function", ["None"], ["    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Shuffle corpus\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--corpus\"", ",", "nargs", "=", "\"+\"", ",", "required", "=", "True", ",", "\n", "help", "=", "\"input corpora\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--suffix\"", ",", "type", "=", "str", ",", "default", "=", "\"shuf\"", ",", "\n", "help", "=", "\"Suffix of output files\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "help", "=", "\"Random seed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_shards\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.build_vocab._open": [[14, 21], ["open", "open", "RuntimeError"], "function", ["None"], ["    ", "counter", "=", "collections", ".", "Counter", "(", ")", "\n", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "fd", ":", "\n", "        ", "for", "line", "in", "fd", ":", "\n", "            ", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "counter", ".", "update", "(", "words", ")", "\n", "\n", "", "", "count_pairs", "=", "sorted", "(", "counter", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "(", "-", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.scripts.visualize._open": [[10, 17], ["open", "open", "RuntimeError"], "function", ["None"], ["def", "parse_numpy", "(", "string", ")", ":", "\n", "    ", "string", "=", "string", ".", "replace", "(", "'['", ",", "' '", ")", ".", "replace", "(", "']'", ",", "' '", ")", ".", "replace", "(", "','", ",", "' '", ")", "\n", "string", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "string", ")", "\n", "result", "=", "numpy", ".", "fromstring", "(", "string", ",", "sep", "=", "' '", ")", "\n", "return", "result", "\n", "\n", "# set font", "\n", "", "fontP", "=", "font_manager", ".", "FontProperties", "(", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch.RNNsearch.__init__": [[338, 340], ["thumt.models.model.NMTModel.__init__"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.train_word2vec.MySentences.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "scope", "=", "\"rnnsearch\"", ")", ":", "\n", "        ", "super", "(", "RNNsearch", ",", "self", ")", ".", "__init__", "(", "params", "=", "params", ",", "scope", "=", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch.RNNsearch.get_training_func": [[341, 355], ["tensorflow.variable_scope", "rnnsearch.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_training_func", "(", "self", ",", "initializer", ",", "regularizer", "=", "None", ",", "dtype", "=", "None", ")", ":", "\n", "        ", "def", "training_fn", "(", "features", ",", "params", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "self", ".", "parameters", "\n", "\n", "", "custom_getter", "=", "utils", ".", "custom_getter", "if", "dtype", "else", "None", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ",", "initializer", "=", "initializer", ",", "\n", "regularizer", "=", "regularizer", ",", "reuse", "=", "reuse", ",", "\n", "custom_getter", "=", "custom_getter", ",", "dtype", "=", "dtype", ")", ":", "\n", "                ", "loss", "=", "model_graph", "(", "features", ",", "\"train\"", ",", "params", ")", "\n", "return", "loss", "\n", "\n", "", "", "return", "training_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch.RNNsearch.get_evaluation_func": [[356, 373], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "rnnsearch.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_evaluation_func", "(", "self", ")", ":", "\n", "        ", "def", "evaluation_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "params", ".", "dropout", "=", "0.0", "\n", "params", ".", "use_variational_dropout", "=", "False", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "score", "=", "model_graph", "(", "features", ",", "\"eval\"", ",", "params", ")", "\n", "\n", "", "return", "score", "\n", "\n", "", "return", "evaluation_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch.RNNsearch.get_inference_func": [[374, 391], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "rnnsearch.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_inference_func", "(", "self", ")", ":", "\n", "        ", "def", "inference_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "params", ".", "dropout", "=", "0.0", "\n", "params", ".", "use_variational_dropout", "=", "False", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "log_prob", "=", "model_graph", "(", "features", ",", "\"infer\"", ",", "params", ")", "\n", "\n", "", "return", "log_prob", "\n", "\n", "", "return", "inference_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch.RNNsearch.get_name": [[392, 395], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_name", "(", ")", ":", "\n", "        ", "return", "\"rnnsearch\"", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch.RNNsearch.get_parameters": [[396, 421], ["tensorflow.contrib.training.HParams"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_parameters", "(", ")", ":", "\n", "        ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "# vocabulary", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "eos", "=", "\"<eos>\"", ",", "\n", "bos", "=", "\"<eos>\"", ",", "\n", "append_eos", "=", "False", ",", "\n", "# model", "\n", "rnn_cell", "=", "\"LegacyGRUCell\"", ",", "\n", "embedding_size", "=", "620", ",", "\n", "hidden_size", "=", "1000", ",", "\n", "maxnum", "=", "2", ",", "\n", "# regularization", "\n", "dropout", "=", "0.2", ",", "\n", "use_variational_dropout", "=", "False", ",", "\n", "label_smoothing", "=", "0.1", ",", "\n", "constant_batch_size", "=", "True", ",", "\n", "batch_size", "=", "128", ",", "\n", "max_length", "=", "60", ",", "\n", "clip_grad_norm", "=", "5.0", "\n", ")", "\n", "\n", "return", "params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch._copy_through": [[18, 21], ["tensorflow.where"], "function", ["None"], ["def", "_copy_through", "(", "time", ",", "length", ",", "output", ",", "new_output", ")", ":", "\n", "    ", "copy_cond", "=", "(", "time", ">=", "length", ")", "\n", "return", "tf", ".", "where", "(", "copy_cond", ",", "output", ",", "new_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch._gru_encoder": [[23, 66], ["tensorflow.zeros", "tensorflow.TensorArray", "tensorflow.TensorArray", "input_ta.unstack.unstack", "tensorflow.constant", "tensorflow.while_loop", "output_final_ta.stack", "tf.transpose.set_shape", "tensorflow.transpose", "tensorflow.shape", "tensorflow.shape", "cell.zero_state", "tensorflow.transpose", "input_ta.unstack.read", "cell", "rnnsearch._copy_through", "rnnsearch._copy_through", "out_ta.write.write"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._copy_through", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._copy_through"], ["", "def", "_gru_encoder", "(", "cell", ",", "inputs", ",", "sequence_length", ",", "initial_state", ",", "dtype", "=", "None", ")", ":", "\n", "# Assume that the underlying cell is GRUCell-like", "\n", "    ", "output_size", "=", "cell", ".", "output_size", "\n", "dtype", "=", "dtype", "or", "inputs", ".", "dtype", "\n", "\n", "batch", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "time_steps", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", "\n", "\n", "zero_output", "=", "tf", ".", "zeros", "(", "[", "batch", ",", "output_size", "]", ",", "dtype", ")", "\n", "\n", "if", "initial_state", "is", "None", ":", "\n", "        ", "initial_state", "=", "cell", ".", "zero_state", "(", "batch", ",", "dtype", ")", "\n", "\n", "", "input_ta", "=", "tf", ".", "TensorArray", "(", "dtype", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"input_array\"", ")", "\n", "output_ta", "=", "tf", ".", "TensorArray", "(", "dtype", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"output_array\"", ")", "\n", "input_ta", "=", "input_ta", ".", "unstack", "(", "tf", ".", "transpose", "(", "inputs", ",", "[", "1", ",", "0", ",", "2", "]", ")", ")", "\n", "\n", "def", "loop_func", "(", "t", ",", "out_ta", ",", "state", ")", ":", "\n", "        ", "inp_t", "=", "input_ta", ".", "read", "(", "t", ")", "\n", "cell_output", ",", "new_state", "=", "cell", "(", "inp_t", ",", "state", ")", "\n", "cell_output", "=", "_copy_through", "(", "t", ",", "sequence_length", ",", "zero_output", ",", "\n", "cell_output", ")", "\n", "new_state", "=", "_copy_through", "(", "t", ",", "sequence_length", ",", "state", ",", "new_state", ")", "\n", "out_ta", "=", "out_ta", ".", "write", "(", "t", ",", "cell_output", ")", "\n", "return", "t", "+", "1", ",", "out_ta", ",", "new_state", "\n", "\n", "", "time", "=", "tf", ".", "constant", "(", "0", ",", "dtype", "=", "tf", ".", "int32", ",", "name", "=", "\"time\"", ")", "\n", "loop_vars", "=", "(", "time", ",", "output_ta", ",", "initial_state", ")", "\n", "\n", "outputs", "=", "tf", ".", "while_loop", "(", "lambda", "t", ",", "*", "_", ":", "t", "<", "time_steps", ",", "loop_func", ",", "\n", "loop_vars", ",", "parallel_iterations", "=", "32", ",", "\n", "swap_memory", "=", "True", ")", "\n", "\n", "output_final_ta", "=", "outputs", "[", "1", "]", "\n", "final_state", "=", "outputs", "[", "2", "]", "\n", "\n", "all_output", "=", "output_final_ta", ".", "stack", "(", ")", "\n", "all_output", ".", "set_shape", "(", "[", "None", ",", "None", ",", "output_size", "]", ")", "\n", "all_output", "=", "tf", ".", "transpose", "(", "all_output", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "return", "all_output", ",", "final_state", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch._encoder": [[68, 101], ["tensorflow.variable_scope", "tensorflow.reverse_sequence", "tensorflow.variable_scope", "rnnsearch._gru_encoder", "tensorflow.variable_scope", "rnnsearch._gru_encoder", "tensorflow.reverse_sequence", "tensorflow.concat"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._gru_encoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._gru_encoder"], ["", "def", "_encoder", "(", "cell_fw", ",", "cell_bw", ",", "inputs", ",", "sequence_length", ",", "dtype", "=", "None", ",", "\n", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"encoder\"", ",", "\n", "values", "=", "[", "inputs", ",", "sequence_length", "]", ")", ":", "\n", "        ", "inputs_fw", "=", "inputs", "\n", "inputs_bw", "=", "tf", ".", "reverse_sequence", "(", "inputs", ",", "sequence_length", ",", "\n", "batch_axis", "=", "0", ",", "seq_axis", "=", "1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"forward\"", ")", ":", "\n", "            ", "output_fw", ",", "state_fw", "=", "_gru_encoder", "(", "cell_fw", ",", "inputs_fw", ",", "\n", "sequence_length", ",", "None", ",", "\n", "dtype", "=", "dtype", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"backward\"", ")", ":", "\n", "            ", "output_bw", ",", "state_bw", "=", "_gru_encoder", "(", "cell_bw", ",", "inputs_bw", ",", "\n", "sequence_length", ",", "None", ",", "\n", "dtype", "=", "dtype", ")", "\n", "output_bw", "=", "tf", ".", "reverse_sequence", "(", "output_bw", ",", "sequence_length", ",", "\n", "batch_axis", "=", "0", ",", "seq_axis", "=", "1", ")", "\n", "\n", "", "results", "=", "{", "\n", "\"annotation\"", ":", "tf", ".", "concat", "(", "[", "output_fw", ",", "output_bw", "]", ",", "axis", "=", "2", ")", ",", "\n", "\"outputs\"", ":", "{", "\n", "\"forward\"", ":", "output_fw", ",", "\n", "\"backward\"", ":", "output_bw", "\n", "}", ",", "\n", "\"final_states\"", ":", "{", "\n", "\"forward\"", ":", "state_fw", ",", "\n", "\"backward\"", ":", "state_bw", "\n", "}", "\n", "}", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch._decoder": [[103, 185], ["tensorflow.zeros", "tensorflow.zeros", "tensorflow.shape", "tensorflow.shape", "tensorflow.variable_scope", "tensorflow.transpose", "tensorflow.sequence_mask", "thumt.attention.attention_bias", "tensorflow.squeeze", "thumt.attention.attention", "tensorflow.TensorArray", "tensorflow.TensorArray", "tensorflow.TensorArray", "tensorflow.TensorArray", "input_ta.unstack.unstack", "thumt.nn.linear", "tensorflow.tanh", "tensorflow.constant", "tensorflow.while_loop", "output_final_ta.stack", "tf.transpose.set_shape", "tensorflow.transpose", "value_final_ta.stack", "tf.transpose.set_shape", "tensorflow.transpose", "input_ta.unstack.read", "thumt.attention.attention", "cell", "rnnsearch._copy_through", "rnnsearch._copy_through", "rnnsearch._copy_through", "out_ta.write.write", "att_ta.write.write", "val_ta.write.write", "tensorflow.identity", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._copy_through", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._copy_through", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._copy_through"], ["", "", "def", "_decoder", "(", "cell", ",", "inputs", ",", "memory", ",", "sequence_length", ",", "initial_state", ",", "dtype", "=", "None", ",", "\n", "scope", "=", "None", ")", ":", "\n", "# Assume that the underlying cell is GRUCell-like", "\n", "    ", "batch", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "time_steps", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", "\n", "dtype", "=", "dtype", "or", "inputs", ".", "dtype", "\n", "output_size", "=", "cell", ".", "output_size", "\n", "zero_output", "=", "tf", ".", "zeros", "(", "[", "batch", ",", "output_size", "]", ",", "dtype", ")", "\n", "zero_value", "=", "tf", ".", "zeros", "(", "[", "batch", ",", "memory", ".", "shape", "[", "-", "1", "]", ".", "value", "]", ",", "dtype", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"decoder\"", ",", "dtype", "=", "dtype", ")", ":", "\n", "        ", "inputs", "=", "tf", ".", "transpose", "(", "inputs", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "mem_mask", "=", "tf", ".", "sequence_mask", "(", "sequence_length", "[", "\"source\"", "]", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "memory", ")", "[", "1", "]", ",", "\n", "dtype", "=", "dtype", ")", "\n", "bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "mem_mask", ",", "\"masking\"", ",", "\n", "dtype", "=", "dtype", ")", "\n", "bias", "=", "tf", ".", "squeeze", "(", "bias", ",", "axis", "=", "[", "1", ",", "2", "]", ")", "\n", "cache", "=", "layers", ".", "attention", ".", "attention", "(", "None", ",", "memory", ",", "None", ",", "output_size", ")", "\n", "\n", "input_ta", "=", "tf", ".", "TensorArray", "(", "dtype", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"input_array\"", ")", "\n", "output_ta", "=", "tf", ".", "TensorArray", "(", "dtype", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"output_array\"", ")", "\n", "value_ta", "=", "tf", ".", "TensorArray", "(", "dtype", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"value_array\"", ")", "\n", "alpha_ta", "=", "tf", ".", "TensorArray", "(", "dtype", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"alpha_array\"", ")", "\n", "input_ta", "=", "input_ta", ".", "unstack", "(", "inputs", ")", "\n", "initial_state", "=", "layers", ".", "nn", ".", "linear", "(", "initial_state", ",", "output_size", ",", "True", ",", "\n", "False", ",", "scope", "=", "\"s_transform\"", ")", "\n", "initial_state", "=", "tf", ".", "tanh", "(", "initial_state", ")", "\n", "\n", "def", "loop_func", "(", "t", ",", "out_ta", ",", "att_ta", ",", "val_ta", ",", "state", ",", "cache_key", ")", ":", "\n", "            ", "inp_t", "=", "input_ta", ".", "read", "(", "t", ")", "\n", "results", "=", "layers", ".", "attention", ".", "attention", "(", "state", ",", "memory", ",", "bias", ",", "\n", "output_size", ",", "\n", "cache", "=", "{", "\"key\"", ":", "cache_key", "}", ")", "\n", "alpha", "=", "results", "[", "\"weight\"", "]", "\n", "context", "=", "results", "[", "\"value\"", "]", "\n", "cell_input", "=", "[", "inp_t", ",", "context", "]", "\n", "cell_output", ",", "new_state", "=", "cell", "(", "cell_input", ",", "state", ")", "\n", "cell_output", "=", "_copy_through", "(", "t", ",", "sequence_length", "[", "\"target\"", "]", ",", "\n", "zero_output", ",", "cell_output", ")", "\n", "new_state", "=", "_copy_through", "(", "t", ",", "sequence_length", "[", "\"target\"", "]", ",", "state", ",", "\n", "new_state", ")", "\n", "new_value", "=", "_copy_through", "(", "t", ",", "sequence_length", "[", "\"target\"", "]", ",", "zero_value", ",", "\n", "context", ")", "\n", "\n", "out_ta", "=", "out_ta", ".", "write", "(", "t", ",", "cell_output", ")", "\n", "att_ta", "=", "att_ta", ".", "write", "(", "t", ",", "alpha", ")", "\n", "val_ta", "=", "val_ta", ".", "write", "(", "t", ",", "new_value", ")", "\n", "cache_key", "=", "tf", ".", "identity", "(", "cache_key", ")", "\n", "return", "t", "+", "1", ",", "out_ta", ",", "att_ta", ",", "val_ta", ",", "new_state", ",", "cache_key", "\n", "\n", "", "time", "=", "tf", ".", "constant", "(", "0", ",", "dtype", "=", "tf", ".", "int32", ",", "name", "=", "\"time\"", ")", "\n", "loop_vars", "=", "(", "time", ",", "output_ta", ",", "alpha_ta", ",", "value_ta", ",", "initial_state", ",", "\n", "cache", "[", "\"key\"", "]", ")", "\n", "\n", "outputs", "=", "tf", ".", "while_loop", "(", "lambda", "t", ",", "*", "_", ":", "t", "<", "time_steps", ",", "\n", "loop_func", ",", "loop_vars", ",", "\n", "parallel_iterations", "=", "32", ",", "\n", "swap_memory", "=", "True", ")", "\n", "\n", "output_final_ta", "=", "outputs", "[", "1", "]", "\n", "value_final_ta", "=", "outputs", "[", "3", "]", "\n", "\n", "final_output", "=", "output_final_ta", ".", "stack", "(", ")", "\n", "final_output", ".", "set_shape", "(", "[", "None", ",", "None", ",", "output_size", "]", ")", "\n", "final_output", "=", "tf", ".", "transpose", "(", "final_output", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "final_value", "=", "value_final_ta", ".", "stack", "(", ")", "\n", "final_value", ".", "set_shape", "(", "[", "None", ",", "None", ",", "memory", ".", "shape", "[", "-", "1", "]", ".", "value", "]", ")", "\n", "final_value", "=", "tf", ".", "transpose", "(", "final_value", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "result", "=", "{", "\n", "\"outputs\"", ":", "final_output", ",", "\n", "\"values\"", ":", "final_value", ",", "\n", "\"initial_state\"", ":", "initial_state", "\n", "}", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch.model_graph": [[187, 334], ["len", "len", "tensorflow.nn.bias_add", "tensorflow.nn.bias_add", "thumt.rnn_cell.LegacyGRUCell", "thumt.rnn_cell.LegacyGRUCell", "rnnsearch._encoder", "thumt.rnn_cell.LegacyGRUCell", "rnnsearch._decoder", "tensorflow.pad", "tensorflow.concat", "thumt.nn.maxout", "thumt.nn.linear", "thumt.nn.linear", "tensorflow.reshape", "thumt.smoothed_softmax_cross_entropy_with_logits", "tensorflow.reshape", "tensorflow.to_float", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.rnn_cell.DropoutWrapper", "tensorflow.nn.rnn_cell.DropoutWrapper", "tensorflow.nn.rnn_cell.DropoutWrapper", "thumt.nn.maxout", "thumt.nn.linear", "thumt.nn.linear", "tensorflow.nn.log_softmax", "tensorflow.nn.dropout", "tensorflow.shape", "tensorflow.sequence_mask", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._encoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._decoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.maxout", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.losses.losses.smoothed_softmax_cross_entropy_with_logits", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.maxout", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear"], ["", "def", "model_graph", "(", "features", ",", "mode", ",", "params", ")", ":", "\n", "    ", "src_vocab_size", "=", "len", "(", "params", ".", "vocabulary", "[", "\"source\"", "]", ")", "\n", "tgt_vocab_size", "=", "len", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", "\n", "dtype", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "dtype", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"source_embedding\"", ")", ":", "\n", "        ", "src_emb", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ",", "\n", "[", "src_vocab_size", ",", "params", ".", "embedding_size", "]", ")", "\n", "src_bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "params", ".", "embedding_size", "]", ")", "\n", "src_inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "src_emb", ",", "features", "[", "\"source\"", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"target_embedding\"", ")", ":", "\n", "        ", "tgt_emb", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ",", "\n", "[", "tgt_vocab_size", ",", "params", ".", "embedding_size", "]", ")", "\n", "tgt_bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "params", ".", "embedding_size", "]", ")", "\n", "tgt_inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "tgt_emb", ",", "features", "[", "\"target\"", "]", ")", "\n", "\n", "", "src_inputs", "=", "tf", ".", "nn", ".", "bias_add", "(", "src_inputs", ",", "src_bias", ")", "\n", "tgt_inputs", "=", "tf", ".", "nn", ".", "bias_add", "(", "tgt_inputs", ",", "tgt_bias", ")", "\n", "\n", "if", "params", ".", "dropout", "and", "not", "params", ".", "use_variational_dropout", ":", "\n", "        ", "src_inputs", "=", "tf", ".", "nn", ".", "dropout", "(", "src_inputs", ",", "1.0", "-", "params", ".", "dropout", ")", "\n", "tgt_inputs", "=", "tf", ".", "nn", ".", "dropout", "(", "tgt_inputs", ",", "1.0", "-", "params", ".", "dropout", ")", "\n", "\n", "# encoder", "\n", "", "cell_fw", "=", "layers", ".", "rnn_cell", ".", "LegacyGRUCell", "(", "params", ".", "hidden_size", ")", "\n", "cell_bw", "=", "layers", ".", "rnn_cell", ".", "LegacyGRUCell", "(", "params", ".", "hidden_size", ")", "\n", "\n", "if", "params", ".", "use_variational_dropout", ":", "\n", "        ", "cell_fw", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell_fw", ",", "\n", "input_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "output_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "state_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "variational_recurrent", "=", "True", ",", "\n", "input_size", "=", "params", ".", "embedding_size", ",", "\n", "dtype", "=", "dtype", "\n", ")", "\n", "cell_bw", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell_bw", ",", "\n", "input_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "output_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "state_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "variational_recurrent", "=", "True", ",", "\n", "input_size", "=", "params", ".", "embedding_size", ",", "\n", "dtype", "=", "dtype", "\n", ")", "\n", "\n", "", "encoder_output", "=", "_encoder", "(", "cell_fw", ",", "cell_bw", ",", "src_inputs", ",", "\n", "features", "[", "\"source_length\"", "]", ",", "dtype", "=", "dtype", ")", "\n", "\n", "# decoder", "\n", "cell", "=", "layers", ".", "rnn_cell", ".", "LegacyGRUCell", "(", "params", ".", "hidden_size", ")", "\n", "\n", "if", "params", ".", "use_variational_dropout", ":", "\n", "        ", "cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell", ",", "\n", "input_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "output_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "state_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "variational_recurrent", "=", "True", ",", "\n", "# input + context", "\n", "input_size", "=", "params", ".", "embedding_size", "+", "2", "*", "params", ".", "hidden_size", ",", "\n", "dtype", "=", "dtype", "\n", ")", "\n", "\n", "", "length", "=", "{", "\n", "\"source\"", ":", "features", "[", "\"source_length\"", "]", ",", "\n", "\"target\"", ":", "features", "[", "\"target_length\"", "]", "\n", "}", "\n", "initial_state", "=", "encoder_output", "[", "\"final_states\"", "]", "[", "\"backward\"", "]", "\n", "decoder_output", "=", "_decoder", "(", "cell", ",", "tgt_inputs", ",", "encoder_output", "[", "\"annotation\"", "]", ",", "\n", "length", ",", "initial_state", ",", "dtype", "=", "dtype", ")", "\n", "\n", "# Shift left", "\n", "shifted_tgt_inputs", "=", "tf", ".", "pad", "(", "tgt_inputs", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "shifted_tgt_inputs", "=", "shifted_tgt_inputs", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "\n", "all_outputs", "=", "tf", ".", "concat", "(", "\n", "[", "\n", "tf", ".", "expand_dims", "(", "decoder_output", "[", "\"initial_state\"", "]", ",", "axis", "=", "1", ")", ",", "\n", "decoder_output", "[", "\"outputs\"", "]", ",", "\n", "]", ",", "\n", "axis", "=", "1", "\n", ")", "\n", "shifted_outputs", "=", "all_outputs", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "\n", "maxout_features", "=", "[", "\n", "shifted_tgt_inputs", ",", "\n", "shifted_outputs", ",", "\n", "decoder_output", "[", "\"values\"", "]", "\n", "]", "\n", "maxout_size", "=", "params", ".", "hidden_size", "//", "params", ".", "maxnum", "\n", "\n", "if", "mode", "==", "\"infer\"", ":", "\n", "# Special case for non-incremental decoding", "\n", "        ", "maxout_features", "=", "[", "\n", "shifted_tgt_inputs", "[", ":", ",", "-", "1", ",", ":", "]", ",", "\n", "shifted_outputs", "[", ":", ",", "-", "1", ",", ":", "]", ",", "\n", "decoder_output", "[", "\"values\"", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "]", "\n", "maxhid", "=", "layers", ".", "nn", ".", "maxout", "(", "maxout_features", ",", "maxout_size", ",", "params", ".", "maxnum", ",", "\n", "concat", "=", "False", ")", "\n", "readout", "=", "layers", ".", "nn", ".", "linear", "(", "maxhid", ",", "params", ".", "embedding_size", ",", "False", ",", "\n", "False", ",", "scope", "=", "\"deepout\"", ")", "\n", "\n", "# Prediction", "\n", "logits", "=", "layers", ".", "nn", ".", "linear", "(", "readout", ",", "tgt_vocab_size", ",", "True", ",", "False", ",", "\n", "scope", "=", "\"softmax\"", ")", "\n", "\n", "return", "tf", ".", "nn", ".", "log_softmax", "(", "logits", ")", "\n", "\n", "", "maxhid", "=", "layers", ".", "nn", ".", "maxout", "(", "maxout_features", ",", "maxout_size", ",", "params", ".", "maxnum", ",", "\n", "concat", "=", "False", ")", "\n", "readout", "=", "layers", ".", "nn", ".", "linear", "(", "maxhid", ",", "params", ".", "embedding_size", ",", "False", ",", "False", ",", "\n", "scope", "=", "\"deepout\"", ")", "\n", "\n", "if", "params", ".", "dropout", "and", "not", "params", ".", "use_variational_dropout", ":", "\n", "        ", "readout", "=", "tf", ".", "nn", ".", "dropout", "(", "readout", ",", "1.0", "-", "params", ".", "dropout", ")", "\n", "\n", "# Prediction", "\n", "", "logits", "=", "layers", ".", "nn", ".", "linear", "(", "readout", ",", "tgt_vocab_size", ",", "True", ",", "False", ",", "\n", "scope", "=", "\"softmax\"", ")", "\n", "logits", "=", "tf", ".", "reshape", "(", "logits", ",", "[", "-", "1", ",", "tgt_vocab_size", "]", ")", "\n", "labels", "=", "features", "[", "\"target\"", "]", "\n", "\n", "ce", "=", "losses", ".", "smoothed_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "\n", "labels", "=", "labels", ",", "\n", "smoothing", "=", "params", ".", "label_smoothing", ",", "\n", "normalize", "=", "True", "\n", ")", "\n", "\n", "ce", "=", "tf", ".", "reshape", "(", "ce", ",", "tf", ".", "shape", "(", "labels", ")", ")", "\n", "tgt_mask", "=", "tf", ".", "to_float", "(", "\n", "tf", ".", "sequence_mask", "(", "\n", "features", "[", "\"target_length\"", "]", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", "\n", ")", "\n", ")", "\n", "\n", "if", "mode", "==", "\"eval\"", ":", "\n", "        ", "return", "-", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ",", "axis", "=", "1", ")", "\n", "\n", "", "loss", "=", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ")", "/", "tf", ".", "reduce_sum", "(", "tgt_mask", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.seq2seq.Seq2Seq.__init__": [[141, 143], ["thumt.models.model.NMTModel.__init__"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.train_word2vec.MySentences.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "scope", "=", "\"seq2seq\"", ")", ":", "\n", "        ", "super", "(", "Seq2Seq", ",", "self", ")", ".", "__init__", "(", "params", "=", "params", ",", "scope", "=", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.seq2seq.Seq2Seq.get_training_func": [[144, 158], ["tensorflow.variable_scope", "seq2seq.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_training_func", "(", "self", ",", "initializer", ",", "regularizer", "=", "None", ",", "dtype", "=", "None", ")", ":", "\n", "        ", "def", "training_fn", "(", "features", ",", "params", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "self", ".", "parameters", "\n", "\n", "", "custom_getter", "=", "utils", ".", "custom_getter", "if", "dtype", "else", "None", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ",", "initializer", "=", "initializer", ",", "\n", "regularizer", "=", "regularizer", ",", "reuse", "=", "reuse", ",", "\n", "custom_getter", "=", "custom_getter", ",", "dtype", "=", "dtype", ")", ":", "\n", "                ", "loss", "=", "model_graph", "(", "features", ",", "\"train\"", ",", "params", ")", "\n", "return", "loss", "\n", "\n", "", "", "return", "training_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.seq2seq.Seq2Seq.get_evaluation_func": [[159, 175], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "seq2seq.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_evaluation_func", "(", "self", ")", ":", "\n", "        ", "def", "evaluation_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "", "params", ".", "dropout", "=", "0.0", "\n", "params", ".", "use_variational_dropout", "=", "False", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "score", "=", "model_graph", "(", "features", ",", "\"eval\"", ",", "params", ")", "\n", "\n", "", "return", "score", "\n", "\n", "", "return", "evaluation_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.seq2seq.Seq2Seq.get_inference_func": [[176, 192], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "seq2seq.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_inference_func", "(", "self", ")", ":", "\n", "        ", "def", "inference_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "", "params", ".", "dropout", "=", "0.0", "\n", "params", ".", "use_variational_dropout", "=", "False", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "logits", "=", "model_graph", "(", "features", ",", "\"infer\"", ",", "params", ")", "\n", "\n", "", "return", "logits", "\n", "\n", "", "return", "inference_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.seq2seq.Seq2Seq.get_name": [[193, 196], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_name", "(", ")", ":", "\n", "        ", "return", "\"seq2seq\"", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.seq2seq.Seq2Seq.get_parameters": [[197, 224], ["tensorflow.contrib.training.HParams"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_parameters", "(", ")", ":", "\n", "        ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "# vocabulary", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "bos", "=", "\"<eos>\"", ",", "\n", "eos", "=", "\"<eos>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "append_eos", "=", "False", ",", "\n", "# model", "\n", "rnn_cell", "=", "\"LSTMCell\"", ",", "\n", "embedding_size", "=", "1000", ",", "\n", "hidden_size", "=", "1000", ",", "\n", "num_hidden_layers", "=", "4", ",", "\n", "# regularization", "\n", "dropout", "=", "0.2", ",", "\n", "use_variational_dropout", "=", "False", ",", "\n", "label_smoothing", "=", "0.1", ",", "\n", "constant_batch_size", "=", "True", ",", "\n", "batch_size", "=", "128", ",", "\n", "max_length", "=", "80", ",", "\n", "reverse_source", "=", "True", ",", "\n", "use_residual", "=", "True", ",", "\n", "clip_grad_norm", "=", "5.0", "\n", ")", "\n", "\n", "return", "params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.seq2seq.model_graph": [[18, 137], ["len", "len", "tensorflow.nn.bias_add", "tensorflow.nn.bias_add", "range", "tensorflow.nn.rnn_cell.MultiRNNCell", "tensorflow.nn.rnn_cell.MultiRNNCell", "tensorflow.pad", "thumt.nn.linear", "tensorflow.reshape", "thumt.smoothed_softmax_cross_entropy_with_logits", "tensorflow.reshape", "tensorflow.to_float", "tensorflow.get_variable_scope", "tensorflow.reverse_sequence", "tensorflow.device", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.rnn_cell.DropoutWrapper", "tensorflow.nn.rnn_cell.DropoutWrapper", "tf.nn.rnn_cell.MultiRNNCell.append", "tf.nn.rnn_cell.MultiRNNCell.append", "tensorflow.variable_scope", "tensorflow.nn.dynamic_rnn", "tensorflow.variable_scope", "tensorflow.nn.dynamic_rnn", "tensorflow.nn.dropout", "thumt.nn.linear", "tensorflow.nn.log_softmax", "tensorflow.shape", "tensorflow.sequence_mask", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.nn.rnn_cell.BasicLSTMCell", "tensorflow.nn.rnn_cell.BasicLSTMCell", "tensorflow.nn.rnn_cell.ResidualWrapper", "tensorflow.nn.rnn_cell.ResidualWrapper", "tensorflow.reduce_sum", "tensorflow.nn.rnn_cell.GRUCell", "tensorflow.nn.rnn_cell.GRUCell", "ValueError", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.losses.losses.smoothed_softmax_cross_entropy_with_logits", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear"], ["def", "model_graph", "(", "features", ",", "mode", ",", "params", ")", ":", "\n", "    ", "src_vocab_size", "=", "len", "(", "params", ".", "vocabulary", "[", "\"source\"", "]", ")", "\n", "tgt_vocab_size", "=", "len", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", "\n", "dtype", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "dtype", "\n", "\n", "src_seq", "=", "features", "[", "\"source\"", "]", "\n", "tgt_seq", "=", "features", "[", "\"target\"", "]", "\n", "\n", "if", "params", ".", "reverse_source", ":", "\n", "        ", "src_seq", "=", "tf", ".", "reverse_sequence", "(", "src_seq", ",", "seq_dim", "=", "1", ",", "\n", "seq_lengths", "=", "features", "[", "\"source_length\"", "]", ")", "\n", "\n", "", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"source_embedding\"", ")", ":", "\n", "            ", "src_emb", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ",", "\n", "[", "src_vocab_size", ",", "params", ".", "embedding_size", "]", ")", "\n", "src_bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "params", ".", "embedding_size", "]", ")", "\n", "src_inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "src_emb", ",", "src_seq", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"target_embedding\"", ")", ":", "\n", "            ", "tgt_emb", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ",", "\n", "[", "tgt_vocab_size", ",", "params", ".", "embedding_size", "]", ")", "\n", "tgt_bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "params", ".", "embedding_size", "]", ")", "\n", "tgt_inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "tgt_emb", ",", "tgt_seq", ")", "\n", "\n", "", "", "src_inputs", "=", "tf", ".", "nn", ".", "bias_add", "(", "src_inputs", ",", "src_bias", ")", "\n", "tgt_inputs", "=", "tf", ".", "nn", ".", "bias_add", "(", "tgt_inputs", ",", "tgt_bias", ")", "\n", "\n", "if", "params", ".", "dropout", "and", "not", "params", ".", "use_variational_dropout", ":", "\n", "        ", "src_inputs", "=", "tf", ".", "nn", ".", "dropout", "(", "src_inputs", ",", "1.0", "-", "params", ".", "dropout", ")", "\n", "tgt_inputs", "=", "tf", ".", "nn", ".", "dropout", "(", "tgt_inputs", ",", "1.0", "-", "params", ".", "dropout", ")", "\n", "\n", "", "cell_enc", "=", "[", "]", "\n", "cell_dec", "=", "[", "]", "\n", "\n", "for", "_", "in", "range", "(", "params", ".", "num_hidden_layers", ")", ":", "\n", "        ", "if", "params", ".", "rnn_cell", "==", "\"LSTMCell\"", ":", "\n", "            ", "cell_e", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "BasicLSTMCell", "(", "params", ".", "hidden_size", ")", "\n", "cell_d", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "BasicLSTMCell", "(", "params", ".", "hidden_size", ")", "\n", "", "elif", "params", ".", "rnn_cell", "==", "\"GRUCell\"", ":", "\n", "            ", "cell_e", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "params", ".", "hidden_size", ")", "\n", "cell_d", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "params", ".", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"%s not supported\"", "%", "params", ".", "rnn_cell", ")", "\n", "\n", "", "cell_e", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell_e", ",", "\n", "output_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "variational_recurrent", "=", "params", ".", "use_variational_dropout", ",", "\n", "input_size", "=", "params", ".", "embedding_size", ",", "\n", "dtype", "=", "dtype", "\n", ")", "\n", "cell_d", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell_d", ",", "\n", "output_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "variational_recurrent", "=", "params", ".", "use_variational_dropout", ",", "\n", "input_size", "=", "params", ".", "embedding_size", ",", "\n", "dtype", "=", "dtype", "\n", ")", "\n", "\n", "if", "params", ".", "use_residual", ":", "\n", "            ", "cell_e", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "ResidualWrapper", "(", "cell_e", ")", "\n", "cell_d", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "ResidualWrapper", "(", "cell_d", ")", "\n", "\n", "", "cell_enc", ".", "append", "(", "cell_e", ")", "\n", "cell_dec", ".", "append", "(", "cell_d", ")", "\n", "\n", "", "cell_enc", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "cell_enc", ")", "\n", "cell_dec", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "cell_dec", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder\"", ")", ":", "\n", "        ", "_", ",", "final_state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "cell_enc", ",", "src_inputs", ",", "\n", "features", "[", "\"source_length\"", "]", ",", "\n", "dtype", "=", "dtype", ")", "\n", "# Shift left", "\n", "", "shifted_tgt_inputs", "=", "tf", ".", "pad", "(", "tgt_inputs", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "shifted_tgt_inputs", "=", "shifted_tgt_inputs", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder\"", ")", ":", "\n", "        ", "outputs", ",", "_", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "cell_dec", ",", "shifted_tgt_inputs", ",", "\n", "features", "[", "\"target_length\"", "]", ",", "\n", "initial_state", "=", "final_state", ")", "\n", "\n", "", "if", "params", ".", "dropout", ":", "\n", "        ", "outputs", "=", "tf", ".", "nn", ".", "dropout", "(", "outputs", ",", "1.0", "-", "params", ".", "dropout", ")", "\n", "\n", "", "if", "mode", "==", "\"infer\"", ":", "\n", "# Prediction", "\n", "        ", "logits", "=", "layers", ".", "nn", ".", "linear", "(", "outputs", "[", ":", ",", "-", "1", ",", ":", "]", ",", "tgt_vocab_size", ",", "True", ",", "\n", "scope", "=", "\"softmax\"", ")", "\n", "\n", "return", "tf", ".", "nn", ".", "log_softmax", "(", "logits", ")", "\n", "\n", "# Prediction", "\n", "", "logits", "=", "layers", ".", "nn", ".", "linear", "(", "outputs", ",", "tgt_vocab_size", ",", "True", ",", "scope", "=", "\"softmax\"", ")", "\n", "logits", "=", "tf", ".", "reshape", "(", "logits", ",", "[", "-", "1", ",", "tgt_vocab_size", "]", ")", "\n", "labels", "=", "features", "[", "\"target\"", "]", "\n", "\n", "ce", "=", "losses", ".", "smoothed_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "\n", "labels", "=", "labels", ",", "\n", "smoothing", "=", "params", ".", "label_smoothing", ",", "\n", "normalize", "=", "True", "\n", ")", "\n", "\n", "ce", "=", "tf", ".", "reshape", "(", "ce", ",", "tf", ".", "shape", "(", "labels", ")", ")", "\n", "tgt_mask", "=", "tf", ".", "to_float", "(", "\n", "tf", ".", "sequence_mask", "(", "\n", "features", "[", "\"target_length\"", "]", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", "\n", ")", "\n", ")", "\n", "\n", "if", "mode", "==", "\"eval\"", ":", "\n", "        ", "return", "-", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ",", "axis", "=", "1", ")", "\n", "\n", "", "loss", "=", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ")", "/", "tf", ".", "reduce_sum", "(", "tgt_mask", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx.ctx_Transformer.__init__": [[525, 527], ["thumt.models.model.NMTModel.__init__"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.train_word2vec.MySentences.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "scope", "=", "\"transformer\"", ")", ":", "\n", "        ", "super", "(", "ctx_Transformer", ",", "self", ")", ".", "__init__", "(", "params", "=", "params", ",", "scope", "=", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx.ctx_Transformer.get_training_func": [[528, 544], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "transformer_ctx.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_training_func", "(", "self", ",", "initializer", ",", "regularizer", "=", "None", ",", "dtype", "=", "None", ")", ":", "\n", "        ", "def", "training_fn", "(", "features", ",", "params", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "custom_getter", "=", "utils", ".", "custom_getter", "if", "dtype", "else", "None", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ",", "initializer", "=", "initializer", ",", "\n", "regularizer", "=", "regularizer", ",", "reuse", "=", "reuse", ",", "\n", "custom_getter", "=", "custom_getter", ",", "dtype", "=", "dtype", ")", ":", "\n", "                ", "loss", "=", "model_graph", "(", "features", ",", "\"train\"", ",", "params", ")", "\n", "return", "loss", "\n", "\n", "", "", "return", "training_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx.ctx_Transformer.get_evaluation_func": [[545, 558], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "transformer_ctx.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_evaluation_func", "(", "self", ")", ":", "\n", "        ", "def", "evaluation_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "score", "=", "model_graph", "(", "features", ",", "\"eval\"", ",", "params", ")", "\n", "\n", "", "return", "score", "\n", "\n", "", "return", "evaluation_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx.ctx_Transformer.get_inference_func": [[559, 596], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "transformer_ctx.encoding_graph", "copy.copy", "copy.copy", "tensorflow.variable_scope", "transformer_ctx.decoding_graph", "tensorflow.shape", "tensorflow.zeros", "tensorflow.zeros", "range"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.encoding_graph", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.decoding_graph"], ["", "def", "get_inference_func", "(", "self", ")", ":", "\n", "        ", "def", "encoding_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "encoder_output", "=", "encoding_graph", "(", "features", ",", "\"infer\"", ",", "params", ")", "\n", "batch", "=", "tf", ".", "shape", "(", "encoder_output", ")", "[", "0", "]", "\n", "\n", "state", "=", "{", "\n", "\"encoder\"", ":", "encoder_output", ",", "\n", "\"context\"", ":", "context_output", ",", "\n", "\"decoder\"", ":", "{", "\n", "\"layer_%d\"", "%", "i", ":", "{", "\n", "\"key\"", ":", "tf", ".", "zeros", "(", "[", "batch", ",", "0", ",", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", "]", ")", ",", "\n", "\"value\"", ":", "tf", ".", "zeros", "(", "[", "batch", ",", "0", ",", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", "]", ")", "\n", "}", "\n", "for", "i", "in", "range", "(", "params", ".", "num_decoder_layers", ")", "\n", "}", "\n", "}", "\n", "", "return", "state", "\n", "\n", "", "def", "decoding_fn", "(", "features", ",", "state", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "log_prob", ",", "new_state", "=", "decoding_graph", "(", "features", ",", "state", ",", "\"infer\"", ",", "\n", "params", ")", "\n", "\n", "", "return", "log_prob", ",", "new_state", "\n", "\n", "", "return", "encoding_fn", ",", "decoding_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx.ctx_Transformer.get_name": [[597, 600], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_name", "(", ")", ":", "\n", "        ", "return", "\"transformer\"", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx.ctx_Transformer.get_parameters": [[601, 645], ["tensorflow.contrib.training.HParams"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_parameters", "(", ")", ":", "\n", "        ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "bos", "=", "\"<eos>\"", ",", "\n", "eos", "=", "\"<eos>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "append_eos", "=", "False", ",", "\n", "hidden_size", "=", "512", ",", "\n", "num_units", "=", "512", ",", "\n", "filter_size", "=", "2048", ",", "\n", "num_heads", "=", "8", ",", "\n", "num_encoder_layers", "=", "6", ",", "\n", "num_decoder_layers", "=", "6", ",", "\n", "attention_dropout", "=", "0.0", ",", "\n", "residual_dropout", "=", "0.5", ",", "\n", "relu_dropout", "=", "0.0", ",", "\n", "label_smoothing", "=", "0.1", ",", "\n", "attention_key_channels", "=", "0", ",", "\n", "attention_value_channels", "=", "0", ",", "\n", "layer_preprocess", "=", "\"none\"", ",", "\n", "layer_postprocess", "=", "\"layer_norm\"", ",", "\n", "multiply_embedding_mode", "=", "\"sqrt_depth\"", ",", "\n", "shared_embedding_and_softmax_weights", "=", "False", ",", "\n", "shared_source_target_embedding", "=", "False", ",", "\n", "context_representation", "=", "\"self_attention\"", ",", "\n", "# Override default parameters", "\n", "learning_rate_decay", "=", "\"linear_warmup_rsqrt_decay\"", ",", "\n", "initializer", "=", "\"uniform_unit_scaling\"", ",", "\n", "initializer_gain", "=", "1.0", ",", "\n", "learning_rate", "=", "1.0", ",", "\n", "batch_size", "=", "4096", ",", "\n", "constant_batch_size", "=", "False", ",", "\n", "adam_beta1", "=", "0.9", ",", "\n", "adam_beta2", "=", "0.98", ",", "\n", "adam_epsilon", "=", "1e-9", ",", "\n", "clip_grad_norm", "=", "0.0", ",", "\n", "# \"absolute\" or \"relative\"", "\n", "position_info_type", "=", "\"relative\"", ",", "\n", "# 8 for big model, 16 for base model, see (Shaw et al., 2018)", "\n", "max_relative_dis", "=", "16", "\n", ")", "\n", "\n", "return", "params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx._layer_process": [[18, 25], ["thumt.nn.layer_norm", "ValueError"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.layer_norm"], ["def", "_layer_process", "(", "x", ",", "mode", ")", ":", "\n", "    ", "if", "not", "mode", "or", "mode", "==", "\"none\"", ":", "\n", "        ", "return", "x", "\n", "", "elif", "mode", "==", "\"layer_norm\"", ":", "\n", "        ", "return", "layers", ".", "nn", ".", "layer_norm", "(", "x", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown mode %s\"", "%", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx._residual_fn": [[27, 31], ["tensorflow.nn.dropout"], "function", ["None"], ["", "", "def", "_residual_fn", "(", "x", ",", "y", ",", "keep_prob", "=", "None", ")", ":", "\n", "    ", "if", "keep_prob", "and", "keep_prob", "<", "1.0", ":", "\n", "        ", "y", "=", "tf", ".", "nn", ".", "dropout", "(", "y", ",", "keep_prob", ")", "\n", "", "return", "x", "+", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx._ffn_layer": [[33, 48], ["tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.nn.linear", "tensorflow.nn.relu", "tensorflow.nn.dropout", "tensorflow.variable_scope", "thumt.nn.linear"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear"], ["", "def", "_ffn_layer", "(", "inputs", ",", "hidden_size", ",", "output_size", ",", "keep_prob", "=", "None", ",", "\n", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"ffn_layer\"", ",", "values", "=", "[", "inputs", "]", ",", "\n", "dtype", "=", "dtype", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"input_layer\"", ")", ":", "\n", "            ", "hidden", "=", "layers", ".", "nn", ".", "linear", "(", "inputs", ",", "hidden_size", ",", "True", ",", "True", ")", "\n", "hidden", "=", "tf", ".", "nn", ".", "relu", "(", "hidden", ")", "\n", "\n", "", "if", "keep_prob", "and", "keep_prob", "<", "1.0", ":", "\n", "            ", "hidden", "=", "tf", ".", "nn", ".", "dropout", "(", "hidden", ",", "keep_prob", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"output_layer\"", ")", ":", "\n", "            ", "output", "=", "layers", ".", "nn", ".", "linear", "(", "hidden", ",", "output_size", ",", "True", ",", "True", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx.gaussian_kld": [[49, 54], ["tensorflow.reduce_sum", "tensorflow.div", "tensorflow.div", "tensorflow.exp", "tensorflow.exp", "tensorflow.pow", "tensorflow.exp"], "function", ["None"], ["", "", "def", "gaussian_kld", "(", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ")", ":", "\n", "    ", "kld", "=", "-", "0.5", "*", "tf", ".", "reduce_sum", "(", "1", "+", "(", "recog_logvar", "-", "prior_logvar", ")", "\n", "-", "tf", ".", "div", "(", "tf", ".", "pow", "(", "prior_mu", "-", "recog_mu", ",", "2", ")", ",", "tf", ".", "exp", "(", "prior_logvar", ")", ")", "\n", "-", "tf", ".", "div", "(", "tf", ".", "exp", "(", "recog_logvar", ")", ",", "tf", ".", "exp", "(", "prior_logvar", ")", ")", ",", "reduction_indices", "=", "1", ")", "\n", "return", "kld", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx.sample_gaussian": [[55, 60], ["tensorflow.random_normal", "tensorflow.exp", "tensorflow.shape", "tensorflow.multiply"], "function", ["None"], ["", "def", "sample_gaussian", "(", "mu", ",", "logvar", ")", ":", "\n", "    ", "epsilon", "=", "tf", ".", "random_normal", "(", "tf", ".", "shape", "(", "logvar", ")", ",", "name", "=", "\"epsilon\"", ")", "\n", "std", "=", "tf", ".", "exp", "(", "0.5", "*", "logvar", ")", "\n", "z", "=", "mu", "+", "tf", ".", "multiply", "(", "std", ",", "epsilon", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx.w_encoder_attention": [[61, 125], ["tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.where", "tensorflow.nn.softmax", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.layers.dense", "tensorflow.layers.dropout", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.sequence_mask", "tensorflow.reshape", "tensorflow.ones_like", "tensorflow.equal", "tensorflow.reshape", "int", "tensorflow.tile", "tensorflow.tile", "int", "tensorflow.reduce_sum", "tensorflow.convert_to_tensor", "queries.get_shape", "tensorflow.shape", "tensorflow.shape", "tf.layers.dense.get_shape().as_list", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.expand_dims", "tf.layers.dense.get_shape"], "function", ["None"], ["", "def", "w_encoder_attention", "(", "queries", ",", "\n", "keys", ",", "\n", "sequence_length", ",", "\n", "num_units", "=", "None", ",", "\n", "num_heads", "=", "8", ",", "\n", "dropout_rate", "=", "0", ",", "\n", "is_training", "=", "True", ",", "\n", "using_mask", "=", "False", ",", "\n", "mymasks", "=", "None", ",", "\n", "scope", "=", "\"w_encoder_attention\"", ",", "\n", "reuse", "=", "None", ")", ":", "\n", "    ", "'''Applies multihead attention.\n\n    Args:\n      queries: A 3d tensor with shape of [N, T_q, C_q].\n      keys: A 3d tensor with shape of [N, T_k, C_k].\n      num_units: A scalar. Attention size.\n      dropout_rate: A floating point number.\n      is_training: Boolean. Controller of mechanism for dropout.\n      causality: Boolean. If true, units that reference the future are masked.\n      num_heads: An int. Number of heads.\n      scope: Optional scope for `variable_scope`.\n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n\n    Returns\n      A 3d tensor with shape of (N, T_q, C)\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "# Set the fall back option for num_units", "\n", "# print(queries)", "\n", "# print(queries.get_shape().as_list)", "\n", "        ", "if", "num_units", "is", "None", ":", "\n", "            ", "num_units", "=", "queries", ".", "get_shape", "(", ")", ".", "as_list", "[", "-", "1", "]", "\n", "# Linear projections", "\n", "\n", "", "Q", "=", "tf", ".", "layers", ".", "dense", "(", "queries", ",", "num_units", ",", "activation", "=", "None", ",", "use_bias", "=", "False", ")", "# (N, T_q, C)", "\n", "K", "=", "tf", ".", "layers", ".", "dense", "(", "keys", ",", "num_units", ",", "activation", "=", "None", ",", "use_bias", "=", "False", ")", "# (N, T_k, C)", "\n", "V", "=", "tf", ".", "layers", ".", "dense", "(", "keys", ",", "num_units", ",", "activation", "=", "None", ",", "use_bias", "=", "False", ")", "# (N, T_k, C)", "\n", "\n", "x", "=", "K", "*", "Q", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "x", ")", "[", "1", "]", ",", "num_heads", ",", "int", "(", "num_units", "/", "num_heads", ")", "]", ")", "\n", "outputs", "=", "tf", ".", "transpose", "(", "tf", ".", "reduce_sum", "(", "x", ",", "3", ")", ",", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "outputs", "=", "outputs", "/", "(", "K", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "**", "0.5", ")", "\n", "\n", "if", "using_mask", ":", "\n", "            ", "key_masks", "=", "mymasks", "\n", "key_masks", "=", "tf", ".", "reshape", "(", "tf", ".", "tile", "(", "key_masks", ",", "[", "1", ",", "num_heads", "]", ")", ",", "\n", "[", "tf", ".", "shape", "(", "key_masks", ")", "[", "0", "]", ",", "num_heads", ",", "tf", ".", "shape", "(", "key_masks", ")", "[", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "key_masks", "=", "tf", ".", "sequence_mask", "(", "sequence_length", ",", "tf", ".", "shape", "(", "keys", ")", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "key_masks", "=", "tf", ".", "reshape", "(", "tf", ".", "tile", "(", "key_masks", ",", "[", "1", ",", "num_heads", "]", ")", ",", "[", "tf", ".", "shape", "(", "key_masks", ")", "[", "0", "]", ",", "num_heads", ",", "tf", ".", "shape", "(", "key_masks", ")", "[", "1", "]", "]", ")", "\n", "\n", "", "paddings", "=", "tf", ".", "ones_like", "(", "outputs", ")", "*", "(", "-", "2", "**", "32", "+", "1", ")", "\n", "outputs", "=", "tf", ".", "where", "(", "tf", ".", "equal", "(", "key_masks", ",", "0", ")", ",", "paddings", ",", "outputs", ")", "\n", "outputs", "=", "tf", ".", "nn", ".", "softmax", "(", "outputs", ",", "2", ")", "\n", "V_", "=", "tf", ".", "reshape", "(", "V", ",", "[", "tf", ".", "shape", "(", "V", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "V", ")", "[", "1", "]", ",", "num_heads", ",", "int", "(", "num_units", "/", "num_heads", ")", "]", ")", "\n", "V_", "=", "tf", ".", "transpose", "(", "V_", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "outputs", "=", "tf", ".", "layers", ".", "dense", "(", "tf", ".", "reshape", "(", "tf", ".", "reduce_sum", "(", "V_", "*", "tf", ".", "expand_dims", "(", "outputs", ",", "-", "1", ")", ",", "2", ")", ",", "[", "-", "1", ",", "num_units", "]", ")", ",", "\n", "num_units", ",", "activation", "=", "None", ",", "use_bias", "=", "False", ")", "\n", "weight", "=", "outputs", "\n", "outputs", "=", "tf", ".", "layers", ".", "dropout", "(", "outputs", ",", "rate", "=", "dropout_rate", ",", "training", "=", "tf", ".", "convert_to_tensor", "(", "is_training", ")", ")", "\n", "\n", "", "return", "outputs", ",", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx.transformer_context": [[126, 162], ["tensorflow.variable_scope", "range", "transformer_ctx._layer_process", "tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.attention.multihead_attention", "transformer_ctx._residual_fn", "transformer_ctx._layer_process", "tensorflow.variable_scope", "transformer_ctx._ffn_layer", "transformer_ctx._residual_fn", "transformer_ctx._layer_process", "transformer_ctx._layer_process", "transformer_ctx._layer_process"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multihead_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._ffn_layer", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process"], ["", "def", "transformer_context", "(", "inputs", ",", "bias", ",", "params", ",", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"context\"", ",", "dtype", "=", "dtype", ",", "\n", "values", "=", "[", "inputs", ",", "bias", "]", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "for", "layer", "in", "range", "(", "params", ".", "num_context_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "layer", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"self_attention\"", ")", ":", "\n", "                    ", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "None", ",", "\n", "bias", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", "trainable", "=", "True", "\n", ")", "\n", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"feed_forward\"", ")", ":", "\n", "                    ", "y", "=", "_ffn_layer", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "params", ".", "filter_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "relu_dropout", ",", "\n", "trainable", "=", "True", "\n", ")", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "\n", "", "", "", "outputs", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx.transformer_encoder": [[163, 203], ["tensorflow.variable_scope", "range", "transformer_ctx._layer_process", "tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.attention.multihead_attention", "transformer_ctx._residual_fn", "transformer_ctx._layer_process", "tensorflow.variable_scope", "transformer_ctx._ffn_layer", "transformer_ctx._residual_fn", "transformer_ctx._layer_process", "transformer_ctx._layer_process", "transformer_ctx._layer_process"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multihead_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._ffn_layer", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process"], ["", "", "def", "transformer_encoder", "(", "inputs", ",", "bias", ",", "params", ",", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"encoder\"", ",", "dtype", "=", "dtype", ",", "\n", "values", "=", "[", "inputs", ",", "bias", "]", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "for", "layer", "in", "range", "(", "params", ".", "num_encoder_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "layer", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"self_attention\"", ")", ":", "\n", "                    ", "max_relative_dis", "=", "params", ".", "max_relative_dis", "if", "params", ".", "position_info_type", "==", "'relative'", "else", "None", "\n", "\n", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "None", ",", "\n", "bias", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", "max_relative_dis", "=", "max_relative_dis", ",", "\n", "trainable", "=", "False", "\n", ")", "\n", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "False", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"feed_forward\"", ")", ":", "\n", "                    ", "y", "=", "_ffn_layer", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "params", ".", "filter_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "relu_dropout", ",", "\n", "trainable", "=", "False", "\n", ")", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "False", ")", "\n", "\n", "", "", "", "outputs", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx.transformer_decoder": [[205, 274], ["tensorflow.variable_scope", "range", "transformer_ctx._layer_process", "tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.attention.multihead_attention", "transformer_ctx._residual_fn", "transformer_ctx._layer_process", "tensorflow.variable_scope", "thumt.attention.multihead_attention", "transformer_ctx._residual_fn", "transformer_ctx._layer_process", "tensorflow.variable_scope", "transformer_ctx._ffn_layer", "transformer_ctx._residual_fn", "transformer_ctx._layer_process", "transformer_ctx._layer_process", "transformer_ctx._layer_process", "transformer_ctx._layer_process"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multihead_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multihead_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._ffn_layer", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process"], ["", "", "def", "transformer_decoder", "(", "inputs", ",", "memory", ",", "bias", ",", "mem_bias", ",", "params", ",", "state", "=", "None", ",", "\n", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"decoder\"", ",", "dtype", "=", "dtype", ",", "\n", "values", "=", "[", "inputs", ",", "memory", ",", "bias", ",", "mem_bias", "]", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "next_state", "=", "{", "}", "\n", "for", "layer", "in", "range", "(", "params", ".", "num_decoder_layers", ")", ":", "\n", "            ", "layer_name", "=", "\"layer_%d\"", "%", "layer", "\n", "with", "tf", ".", "variable_scope", "(", "layer_name", ")", ":", "\n", "                ", "layer_state", "=", "state", "[", "layer_name", "]", "if", "state", "is", "not", "None", "else", "None", "\n", "max_relative_dis", "=", "params", ".", "max_relative_dis", "if", "params", ".", "position_info_type", "==", "'relative'", "else", "None", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"self_attention\"", ")", ":", "\n", "                    ", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "None", ",", "\n", "bias", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", "state", "=", "layer_state", ",", "\n", "max_relative_dis", "=", "max_relative_dis", ",", "\n", "trainable", "=", "False", "\n", ")", "\n", "\n", "if", "layer_state", "is", "not", "None", ":", "\n", "                        ", "next_state", "[", "layer_name", "]", "=", "y", "[", "\"state\"", "]", "\n", "\n", "", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "False", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"encdec_attention\"", ")", ":", "\n", "                    ", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "memory", ",", "\n", "mem_bias", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", "max_relative_dis", "=", "max_relative_dis", ",", "\n", "trainable", "=", "False", "\n", ")", "\n", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "False", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"feed_forward\"", ")", ":", "\n", "                    ", "y", "=", "_ffn_layer", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "params", ".", "filter_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "relu_dropout", ",", "\n", "trainable", "=", "False", "\n", ")", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "False", ")", "\n", "\n", "", "", "", "outputs", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", "\n", "\n", "if", "state", "is", "not", "None", ":", "\n", "            ", "return", "outputs", ",", "next_state", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx.encoding_graph": [[276, 366], ["tensorflow.sequence_mask", "tensorflow.sequence_mask", "len", "tensorflow.random_normal_initializer", "tensorflow.get_variable", "print", "print", "tensorflow.gather", "tensorflow.nn.bias_add", "thumt.attention.attention_bias", "transformer_ctx.transformer_encoder", "tensorflow.get_variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "print", "tensorflow.nn.bias_add", "thumt.attention.add_timing_signal", "thumt.attention.attention_bias", "transformer_ctx.transformer_encoder", "tensorflow.expand_dims", "thumt.attention.add_timing_signal", "tensorflow.nn.dropout", "tensorflow.gather", "tensorflow.expand_dims", "print", "tensorflow.nn.bias_add", "thumt.attention.attention_bias", "tensorflow.shape", "tensorflow.shape", "tensorflow.gather", "tensorflow.expand_dims", "print", "tensorflow.nn.bias_add", "thumt.attention.attention_bias", "birnn", "tensorflow.gather", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.transformer_encoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.add_timing_signal", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.transformer_encoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.add_timing_signal", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.birnn"], ["", "", "def", "encoding_graph", "(", "features", ",", "mode", ",", "params", ")", ":", "\n", "    ", "if", "mode", "!=", "\"train\"", ":", "\n", "        ", "params", ".", "residual_dropout", "=", "0.0", "\n", "params", ".", "attention_dropout", "=", "0.0", "\n", "params", ".", "relu_dropout", "=", "0.0", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "", "dtype", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "dtype", "\n", "hidden_size", "=", "params", ".", "hidden_size", "\n", "src_seq", "=", "features", "[", "\"source\"", "]", "\n", "ctx_seq", "=", "features", "[", "\"context\"", "]", "\n", "src_len", "=", "features", "[", "\"source_length\"", "]", "\n", "ctx_len", "=", "features", "[", "\"context_length\"", "]", "\n", "src_mask", "=", "tf", ".", "sequence_mask", "(", "src_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "dtype", "or", "tf", ".", "float32", ")", "\n", "\n", "ctx_mask", "=", "tf", ".", "sequence_mask", "(", "ctx_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"context\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "svocab", "=", "params", ".", "vocabulary", "[", "\"source\"", "]", "\n", "src_vocab_size", "=", "len", "(", "svocab", ")", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.0", ",", "params", ".", "hidden_size", "**", "-", "0.5", ")", "\n", "\n", "if", "params", ".", "shared_source_target_embedding", ":", "\n", "        ", "src_embedding", "=", "tf", ".", "get_variable", "(", "\"weights\"", ",", "\n", "[", "src_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "src_embedding", "=", "tf", ".", "get_variable", "(", "\"source_embedding\"", ",", "\n", "[", "src_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ")", "\n", "\n", "", "bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "hidden_size", "]", ")", "\n", "\n", "## context", "\n", "# ctx_seq: [batch, max_ctx_length]", "\n", "print", "(", "\"building context graph\"", ")", "\n", "if", "params", ".", "context_representation", "==", "\"self_attention\"", ":", "\n", "        ", "print", "(", "'use self attention'", ")", "\n", "ctx_inputs", "=", "tf", ".", "gather", "(", "src_embedding", ",", "ctx_seq", ")", "*", "(", "hidden_size", "**", "0.5", ")", "\n", "ctx_inputs", "=", "ctx_inputs", "*", "tf", ".", "expand_dims", "(", "ctx_mask", ",", "-", "1", ")", "\n", "\n", "context_input", "=", "tf", ".", "nn", ".", "bias_add", "(", "ctx_inputs", ",", "bias", ")", "\n", "context_input", "=", "layers", ".", "attention", ".", "add_timing_signal", "(", "context_input", ")", "\n", "ctx_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "ctx_mask", ",", "\"masking\"", ")", "\n", "\n", "#context_output = transformer_context(context_input, ctx_attn_bias, params)", "\n", "context_output", "=", "transformer_encoder", "(", "context_input", ",", "ctx_attn_bias", ",", "params", ")", "\n", "", "elif", "params", ".", "context_representation", "==", "\"embedding\"", ":", "\n", "        ", "print", "(", "'use embedding'", ")", "\n", "ctx_inputs", "=", "tf", ".", "gather", "(", "src_embedding", ",", "ctx_seq", ")", "*", "(", "hidden_size", "**", "0.5", ")", "\n", "ctx_inputs", "=", "ctx_inputs", "*", "tf", ".", "expand_dims", "(", "ctx_mask", ",", "-", "1", ")", "\n", "context_input", "=", "tf", ".", "nn", ".", "bias_add", "(", "ctx_inputs", ",", "bias", ")", "\n", "ctx_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "ctx_mask", ",", "\"masking\"", ")", "\n", "context_output", "=", "context_input", "\n", "", "elif", "params", ".", "context_representation", "==", "\"bilstm\"", ":", "\n", "        ", "print", "(", "'use bilstm'", ")", "\n", "ctx_inputs", "=", "tf", ".", "gather", "(", "src_embedding", ",", "ctx_seq", ")", "*", "(", "hidden_size", "**", "0.5", ")", "\n", "ctx_inputs", "=", "ctx_inputs", "*", "tf", ".", "expand_dims", "(", "ctx_mask", ",", "-", "1", ")", "\n", "context_input", "=", "tf", ".", "nn", ".", "bias_add", "(", "ctx_inputs", ",", "bias", ")", "\n", "ctx_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "ctx_mask", ",", "\"masking\"", ")", "\n", "context_output", "=", "birnn", "(", "context_input", ",", "ctx_len", ",", "params", ")", "\n", "\n", "## encoder", "\n", "\n", "# id => embedding", "\n", "# src_seq: [batch, max_src_length]", "\n", "", "print", "(", "\"building encoder graph\"", ")", "\n", "inputs", "=", "tf", ".", "gather", "(", "src_embedding", ",", "src_seq", ")", "\n", "\n", "if", "params", ".", "multiply_embedding_mode", "==", "\"sqrt_depth\"", ":", "\n", "        ", "inputs", "=", "inputs", "*", "(", "hidden_size", "**", "0.5", ")", "\n", "\n", "", "inputs", "=", "inputs", "*", "tf", ".", "expand_dims", "(", "src_mask", ",", "-", "1", ")", "\n", "\n", "encoder_input", "=", "tf", ".", "nn", ".", "bias_add", "(", "inputs", ",", "bias", ")", "\n", "enc_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "src_mask", ",", "\"masking\"", ",", "\n", "dtype", "=", "dtype", ")", "\n", "if", "params", ".", "position_info_type", "==", "'absolute'", ":", "\n", "        ", "encoder_input", "=", "layers", ".", "attention", ".", "add_timing_signal", "(", "encoder_input", ")", "\n", "\n", "", "if", "params", ".", "residual_dropout", ":", "\n", "        ", "keep_prob", "=", "1.0", "-", "params", ".", "residual_dropout", "\n", "encoder_input", "=", "tf", ".", "nn", ".", "dropout", "(", "encoder_input", ",", "keep_prob", ")", "\n", "\n", "", "encoder_output", "=", "transformer_encoder", "(", "encoder_input", ",", "enc_attn_bias", ",", "params", ")", "\n", "\n", "return", "encoder_output", ",", "context_output", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx.decoding_graph": [[368, 510], ["tensorflow.sequence_mask", "tensorflow.sequence_mask", "len", "tensorflow.random_normal_initializer", "tensorflow.gather", "thumt.attention.attention_bias", "thumt.attention.attention_bias", "tensorflow.get_variable", "tensorflow.tile", "tensorflow.reshape", "tensorflow.matmul", "thumt.smoothed_softmax_cross_entropy_with_logits", "tensorflow.cast", "tensorflow.reshape", "tensorflow.minimum", "transformer_ctx.gaussian_kld", "tensorflow.get_variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.expand_dims", "tensorflow.pad", "thumt.attention.add_timing_signal", "tensorflow.nn.dropout", "transformer_ctx.transformer_decoder", "transformer_ctx.w_encoder_attention", "transformer_ctx.w_encoder_attention", "tensorflow.layers.dense", "tensorflow.split", "tensorflow.layers.dense", "tensorflow.split", "transformer_ctx.sample_gaussian", "transformer_ctx.sample_gaussian", "transformer_ctx.transformer_decoder", "tensorflow.matmul", "tensorflow.nn.log_softmax", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.shape", "tensorflow.layers.dense", "tensorflow.reduce_sum", "tensorflow.to_float", "tensorflow.shape", "tensorflow.shape", "tensorflow.get_variable_scope"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.losses.losses.smoothed_softmax_cross_entropy_with_logits", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.gaussian_kld", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.add_timing_signal", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.transformer_decoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.w_encoder_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.w_encoder_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.sample_gaussian", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.sample_gaussian", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.transformer_decoder"], ["", "def", "decoding_graph", "(", "features", ",", "state", ",", "mode", ",", "params", ")", ":", "\n", "    ", "if", "mode", "!=", "\"train\"", ":", "\n", "        ", "params", ".", "residual_dropout", "=", "0.0", "\n", "params", ".", "attention_dropout", "=", "0.0", "\n", "params", ".", "relu_dropout", "=", "0.0", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "", "dtype", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "dtype", "\n", "tgt_seq", "=", "features", "[", "\"target\"", "]", "\n", "src_len", "=", "features", "[", "\"source_length\"", "]", "\n", "tgt_len", "=", "features", "[", "\"target_length\"", "]", "\n", "src_mask", "=", "tf", ".", "sequence_mask", "(", "src_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "dtype", "or", "tf", ".", "float32", ")", "\n", "tgt_mask", "=", "tf", ".", "sequence_mask", "(", "tgt_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "dtype", "or", "tf", ".", "float32", ")", "\n", "\n", "hidden_size", "=", "params", ".", "hidden_size", "\n", "tvocab", "=", "params", ".", "vocabulary", "[", "\"target\"", "]", "\n", "tgt_vocab_size", "=", "len", "(", "tvocab", ")", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.0", ",", "params", ".", "hidden_size", "**", "-", "0.5", ")", "\n", "\n", "if", "params", ".", "shared_source_target_embedding", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "True", ")", ":", "\n", "            ", "tgt_embedding", "=", "tf", ".", "get_variable", "(", "\"weights\"", ",", "\n", "[", "tgt_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ")", "\n", "", "", "else", ":", "\n", "        ", "tgt_embedding", "=", "tf", ".", "get_variable", "(", "\"target_embedding\"", ",", "\n", "[", "tgt_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ")", "\n", "\n", "", "if", "params", ".", "shared_embedding_and_softmax_weights", ":", "\n", "        ", "weights", "=", "tgt_embedding", "\n", "", "else", ":", "\n", "        ", "weights", "=", "tf", ".", "get_variable", "(", "\"softmax\"", ",", "[", "tgt_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ")", "\n", "\n", "", "targets", "=", "tf", ".", "gather", "(", "tgt_embedding", ",", "tgt_seq", ")", "\n", "\n", "if", "params", ".", "multiply_embedding_mode", "==", "\"sqrt_depth\"", ":", "\n", "        ", "targets", "=", "targets", "*", "(", "hidden_size", "**", "0.5", ")", "\n", "\n", "", "targets", "=", "targets", "*", "tf", ".", "expand_dims", "(", "tgt_mask", ",", "-", "1", ")", "\n", "\n", "enc_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "src_mask", ",", "\"masking\"", ",", "\n", "dtype", "=", "dtype", ")", "\n", "dec_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "tf", ".", "shape", "(", "targets", ")", "[", "1", "]", ",", "\n", "\"causal\"", ",", "dtype", "=", "dtype", ")", "\n", "# Shift left", "\n", "decoder_input", "=", "tf", ".", "pad", "(", "targets", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "if", "params", ".", "position_info_type", "==", "'absolute'", ":", "\n", "        ", "decoder_input", "=", "layers", ".", "attention", ".", "add_timing_signal", "(", "decoder_input", ")", "\n", "\n", "", "if", "params", ".", "residual_dropout", ":", "\n", "        ", "keep_prob", "=", "1.0", "-", "params", ".", "residual_dropout", "\n", "decoder_input", "=", "tf", ".", "nn", ".", "dropout", "(", "decoder_input", ",", "keep_prob", ")", "\n", "\n", "", "encoder_output", "=", "state", "[", "\"encoder\"", "]", "\n", "context_output", "=", "state", "[", "\"context\"", "]", "\n", "w_query", "=", "tf", ".", "get_variable", "(", "\"w_Q\"", ",", "[", "1", ",", "params", ".", "num_units", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "if", "mode", "!=", "\"infer\"", ":", "\n", "        ", "decoder_output", "=", "transformer_decoder", "(", "decoder_input", ",", "encoder_output", ",", "\n", "dec_attn_bias", ",", "enc_attn_bias", ",", "\n", "params", ")", "\n", "\n", "post_encode", ",", "weight", "=", "w_encoder_attention", "(", "w_query", ",", "\n", "decoder_output", ",", "\n", "params", ".", "input_lens", ",", "\n", "num_units", "=", "params", ".", "num_units", ",", "\n", "num_heads", "=", "params", ".", "num_heads", ",", "\n", "dropout_rate", "=", "params", ".", "dropout_rate", ",", "\n", "is_training", "=", "True", ",", "\n", "using_mask", "=", "False", ",", "\n", "mymasks", "=", "None", ",", "\n", "scope", "=", "\"concentrate_attention\"", "\n", ")", "\n", "\n", "prior_encode", ",", "weight", "=", "w_encoder_attention", "(", "w_query", ",", "\n", "encoder_output", ",", "\n", "params", ".", "input_lens", ",", "\n", "num_units", "=", "params", ".", "num_units", ",", "\n", "num_heads", "=", "params", ".", "num_heads", ",", "\n", "dropout_rate", "=", "params", ".", "dropout_rate", ",", "\n", "is_training", "=", "True", ",", "\n", "using_mask", "=", "True", ",", "\n", "mymasks", "=", "big_window", ",", "\n", "scope", "=", "\"concentrate_attention\"", ",", "\n", "reuse", "=", "tf", ".", "AUTO_REUSE", "\n", ")", "\n", "\n", "post_mulogvar", "=", "tf", ".", "layers", ".", "dense", "(", "post_encode", ",", "params", ".", "latent_dim", "*", "2", ",", "use_bias", "=", "False", ",", "name", "=", "\"post_fc\"", ")", "\n", "post_mu", ",", "post_logvar", "=", "tf", ".", "split", "(", "post_mulogvar", ",", "2", ",", "axis", "=", "1", ")", "\n", "\n", "prior_mulogvar", "=", "tf", ".", "layers", ".", "dense", "(", "tf", ".", "layers", ".", "dense", "(", "prior_encode", ",", "256", ",", "activation", "=", "tf", ".", "nn", ".", "tanh", ")", ",", "params", ".", "latent_dim", "*", "2", ",", "use_bias", "=", "False", ",", "name", "=", "\"prior_fc\"", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "tf", ".", "split", "(", "prior_mulogvar", ",", "2", ",", "axis", "=", "1", ")", "\n", "\n", "latent_sample", "=", "sample_gaussian", "(", "post_mu", ",", "post_logvar", ")", "\n", "", "else", ":", "\n", "        ", "latent_sample", "=", "sample_gaussian", "(", "prior_mu", ",", "prior_logvar", ")", "\n", "decoder_input", "=", "decoder_input", "[", ":", ",", "-", "1", ":", ",", ":", "]", "\n", "dec_attn_bias", "=", "dec_attn_bias", "[", ":", ",", ":", ",", "-", "1", ":", ",", ":", "]", "\n", "decoder_outputs", "=", "transformer_decoder", "(", "decoder_input", ",", "encoder_output", ",", "\n", "dec_attn_bias", ",", "enc_attn_bias", ",", "\n", "params", ",", "state", "=", "state", "[", "\"decoder\"", "]", ")", "\n", "\n", "decoder_output", ",", "decoder_state", "=", "decoder_outputs", "\n", "decoder_output", "=", "decoder_output", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "logits", "=", "tf", ".", "matmul", "(", "decoder_output", ",", "weights", ",", "False", ",", "True", ")", "\n", "log_prob", "=", "tf", ".", "nn", ".", "log_softmax", "(", "logits", ")", "\n", "\n", "return", "log_prob", ",", "{", "\"encoder\"", ":", "encoder_output", ",", "\"decoder\"", ":", "decoder_state", ",", "\"context\"", ":", "context_output", "}", "\n", "\n", "", "latent_sample", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "latent_sample", ",", "1", ")", ",", "[", "1", ",", "50", ",", "1", "]", ")", "\n", "\n", "decoder_output", "=", "tf", ".", "reshape", "(", "decoder_output", ",", "[", "-", "1", ",", "hidden_size", "]", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "decoder_output", ",", "weights", ",", "False", ",", "True", ")", "\n", "labels", "=", "features", "[", "\"target\"", "]", "\n", "\n", "# label smoothing", "\n", "ce", "=", "losses", ".", "smoothed_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "\n", "labels", "=", "labels", ",", "\n", "smoothing", "=", "params", ".", "label_smoothing", ",", "\n", "normalize", "=", "True", "\n", ")", "\n", "tgt_mask", "=", "tf", ".", "cast", "(", "tgt_mask", ",", "ce", ".", "dtype", ")", "\n", "\n", "ce", "=", "tf", ".", "reshape", "(", "ce", ",", "tf", ".", "shape", "(", "tgt_seq", ")", ")", "\n", "\n", "if", "mode", "==", "\"eval\"", ":", "\n", "        ", "return", "-", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ",", "axis", "=", "1", ")", "\n", "\n", "", "loss", "=", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ")", "/", "tf", ".", "reduce_sum", "(", "tgt_mask", ")", "\n", "\n", "kl_weights", "=", "tf", ".", "minimum", "(", "tf", ".", "to_float", "(", "params", ".", "global_step", ")", "/", "20000", ",", "1.0", ")", "\n", "kld", "=", "gaussian_kld", "(", "post_mu", ",", "post_logvar", ",", "prior_mu", ",", "prior_logvar", ")", "\n", "kl_loss", "=", "tf", ".", "reduce_mean", "(", "kld", ")", "*", "kl_weights", "\n", "\n", "return", "loss", "+", "kl_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_ctx.model_graph": [[512, 521], ["transformer_ctx.encoding_graph", "transformer_ctx.decoding_graph"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.encoding_graph", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.decoding_graph"], ["", "def", "model_graph", "(", "features", ",", "mode", ",", "params", ")", ":", "\n", "    ", "encoder_output", ",", "context_output", "=", "encoding_graph", "(", "features", ",", "mode", ",", "params", ")", "\n", "state", "=", "{", "\n", "\"encoder\"", ":", "encoder_output", ",", "\n", "\"context\"", ":", "context_output", "\n", "}", "\n", "output", "=", "decoding_graph", "(", "features", ",", "state", ",", "mode", ",", "params", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.model.NMTModel.__init__": [[12, 15], ["None"], "methods", ["None"], ["        ", "self", ".", "_scope", "=", "scope", "\n", "self", ".", "_params", "=", "params", "\n", "\n", "", "def", "get_training_func", "(", "self", ",", "initializer", ")", ":", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.model.NMTModel.get_training_func": [[16, 25], ["NotImplementedError"], "methods", ["None"], ["        ", "raise", "NotImplementedError", "(", "\"Not implemented\"", ")", "\n", "\n", "", "def", "get_evaluation_func", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Not implemented\"", ")", "\n", "\n", "", "def", "get_inference_func", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Not implemented\"", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "get_name", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.model.NMTModel.get_evaluation_func": [[26, 32], ["NotImplementedError"], "methods", ["None"], ["        ", "raise", "NotImplementedError", "(", "\"Not implemented\"", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "get_parameters", "(", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Not implemented\"", ")", "\n", "\n", "", "@", "property", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.model.NMTModel.get_inference_func": [[33, 52], ["NotImplementedError"], "methods", ["None"], ["def", "parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.model.NMTModel.get_name": [[53, 56], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.model.NMTModel.get_parameters": [[57, 60], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.model.NMTModel.parameters": [[61, 64], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.__init__.get_model": [[15, 32], ["name.lower.lower", "LookupError"], "function", ["None"], []], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer.Transformer.__init__": [[324, 326], ["thumt.models.model.NMTModel.__init__"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.train_word2vec.MySentences.__init__"], ["\n", "#emotion = features[\"emotion\"]", "\n", "src_len", "=", "features", "[", "\"source_length\"", "]", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer.Transformer.get_training_func": [[327, 343], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "transformer.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["sample_len", "=", "features", "[", "\"sample_length\"", "]", "\n", "\n", "ctx_dia_src_len", "=", "features", "[", "\"context_dia_src_length\"", "]", "\n", "ctx_dia_tgt_len", "=", "features", "[", "\"context_dia_tgt_length\"", "]", "\n", "ctx_sty_src_len", "=", "features", "[", "\"context_sty_src_length\"", "]", "\n", "ctx_sty_tgt_len", "=", "features", "[", "\"context_sty_tgt_length\"", "]", "\n", "ctx_src_len", "=", "features", "[", "\"context_source_length\"", "]", "\n", "sample_len", "=", "features", "[", "\"sample_length\"", "]", "\n", "\n", "\n", "src_mask", "=", "tf", ".", "sequence_mask", "(", "src_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "dtype", "or", "tf", ".", "float32", ")", "\n", "\n", "ctx_dia_src_mask", "=", "tf", ".", "sequence_mask", "(", "ctx_dia_src_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"context_dia_src\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer.Transformer.get_evaluation_func": [[344, 357], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "transformer.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["ctx_dia_tgt_mask", "=", "tf", ".", "sequence_mask", "(", "ctx_dia_tgt_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"context_dia_tgt\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "ctx_sty_src_mask", "=", "tf", ".", "sequence_mask", "(", "ctx_sty_src_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"context_sty_src\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "ctx_sty_tgt_mask", "=", "tf", ".", "sequence_mask", "(", "ctx_sty_tgt_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"context_sty_tgt\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "ctx_src_mask", "=", "tf", ".", "sequence_mask", "(", "ctx_src_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"context_source\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "sample_mask", "=", "tf", ".", "sequence_mask", "(", "sample_len", ",", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer.Transformer.get_inference_func": [[358, 394], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "transformer.encoding_graph", "copy.copy", "copy.copy", "tensorflow.variable_scope", "transformer.decoding_graph", "tensorflow.shape", "tensorflow.zeros", "tensorflow.zeros", "range"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.encoding_graph", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.decoding_graph"], ["maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"sample\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "#    code.interact(local=locals())", "\n", "# dialogue mask", "\n", "ctx_mask", "=", "tf", ".", "sequence_mask", "(", "ctx_dia_src_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"context_source\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "top_mask", "=", "tf", ".", "equal", "(", "ctx_mask", ",", "ctx_src_mask", ")", "\n", "top_mask", "=", "tf", ".", "cast", "(", "top_mask", ",", "tf", ".", "float32", ")", "\n", "inf", "=", "-", "1e9", "\n", "if", "dtype", "is", "None", ":", "\n", "        ", "dtype", "=", "tf", ".", "float32", "\n", "", "if", "dtype", "!=", "tf", ".", "float32", ":", "\n", "        ", "inf", "=", "dtype", ".", "min", "\n", "#dia_mask = inf * top_mask", "\n", "\n", "#    dia_mask = features[\"mask\"]", "\n", "", "length", "=", "tf", ".", "shape", "(", "top_mask", ")", "[", "-", "1", "]", "\n", "k_mask", "=", "tf", ".", "tile", "(", "top_mask", ",", "[", "1", ",", "length", "]", ")", "\n", "ex_mask", "=", "tf", ".", "expand_dims", "(", "k_mask", ",", "1", ")", "\n", "ti_mask", "=", "tf", ".", "tile", "(", "ex_mask", ",", "[", "1", ",", "params", ".", "num_heads", ",", "1", "]", ")", "\n", "ori_mask", "=", "tf", ".", "reshape", "(", "ti_mask", ",", "[", "-", "1", ",", "params", ".", "num_heads", ",", "length", ",", "length", "]", ")", "\n", "trans_mask", "=", "tf", ".", "transpose", "(", "ori_mask", ",", "[", "0", ",", "1", ",", "3", ",", "2", "]", ")", "\n", "part_mask", "=", "ori_mask", "+", "trans_mask", "\n", "part_mask", "=", "tf", ".", "cast", "(", "part_mask", ",", "dtype", ")", "\n", "dia_mask", "=", "inf", "*", "part_mask", "\n", "\n", "svocab", "=", "params", ".", "vocabulary", "[", "\"source\"", "]", "\n", "src_vocab_size", "=", "len", "(", "svocab", ")", "\n", "tvocab", "=", "params", ".", "vocabulary", "[", "\"target\"", "]", "\n", "tgt_vocab_size", "=", "len", "(", "tvocab", ")", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.0", ",", "params", ".", "hidden_size", "**", "-", "0.5", ")", "\n", "\n", "if", "params", ".", "shared_source_target_embedding", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "src_embedding", "=", "tf", ".", "get_variable", "(", "\"weights\"", ",", "\n", "[", "src_vocab_size", ",", "hidden_size", "]", ",", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer.Transformer.get_name": [[395, 398], ["None"], "methods", ["None"], ["initializer", "=", "initializer", ",", "trainable", "=", "True", ")", "\n", "", "", "else", ":", "\n", "        ", "src_embedding", "=", "tf", ".", "get_variable", "(", "\"source_embedding\"", ",", "\n", "[", "src_vocab_size", ",", "hidden_size", "]", ",", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer.Transformer.get_parameters": [[399, 441], ["tensorflow.contrib.training.HParams"], "methods", ["None"], ["initializer", "=", "initializer", ",", "trainable", "=", "True", ")", "\n", "\n", "", "if", "params", ".", "shared_source_target_embedding", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "True", ")", ":", "\n", "            ", "tgt_embedding", "=", "tf", ".", "get_variable", "(", "\"weights\"", ",", "\n", "[", "src_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ",", "trainable", "=", "True", ")", "\n", "", "", "else", ":", "\n", "        ", "tgt_embedding", "=", "tf", ".", "get_variable", "(", "\"target_embedding\"", ",", "\n", "[", "tgt_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ",", "trainable", "=", "True", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "hidden_size", "]", ")", "\n", "\n", "", "inputs", "=", "tf", ".", "gather", "(", "src_embedding", ",", "src_seq", ")", "\n", "#emotion_inputs = tf.gather(src_embedding, emotion)", "\n", "\n", "if", "params", ".", "multiply_embedding_mode", "==", "\"sqrt_depth\"", ":", "\n", "        ", "inputs", "=", "inputs", "*", "(", "hidden_size", "**", "0.5", ")", "\n", "#    emotion_inputs = emotion_inputs * (hidden_size ** 0.5)", "\n", "", "'''\n    with tf.variable_scope(\"emotion_embedding\"):\n        if params.use_emovec:\n#            emo_emb = tf.Variable(_load_embedding(params.vocabulary[\"emotion\"], params), name=\"emo_embedding\", trainable=False)\n            emo_emb = tf.get_variable(\"emo_embedding\", initializer=_load_embedding(params.vocabulary[\"emotion\"], params), trainable=False)\n        else:\n            emo_emb = tf.get_variable(\"emo_embedding\",\n                                     [len(params.vocabulary[\"emotion\"]), 300], initializer=tf.contrib.layers.xavier_initializer())\n        emo_bias = tf.get_variable(\"emo_bias\", [300])\n        emo_inputs = tf.nn.embedding_lookup(emo_emb, features[\"emotion\"])\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "\"turn_position_embedding\"", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "pos_emb", "=", "tf", ".", "get_variable", "(", "\"turn_pos_embedding\"", ",", "[", "len", "(", "params", ".", "vocabulary", "[", "\"position\"", "]", ")", ",", "hidden_size", "]", ",", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", ")", "\n", "\n", "", "inputs", "=", "inputs", "*", "tf", ".", "expand_dims", "(", "src_mask", ",", "-", "1", ")", "#src_mask, -1)", "\n", "\n", "encoder_input", "=", "tf", ".", "nn", ".", "bias_add", "(", "inputs", ",", "bias", ")", "\n", "enc_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "src_mask", ",", "\"masking\"", ",", "\n", "dtype", "=", "dtype", ")", "\n", "if", "params", ".", "position_info_type", "==", "'absolute'", ":", "\n", "        ", "encoder_input", "=", "layers", ".", "attention", ".", "add_timing_signal", "(", "encoder_input", ")", "\n", "#segment embeddings", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer._layer_process": [[18, 25], ["thumt.nn.layer_norm", "ValueError"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.layer_norm"], ["def", "_layer_process", "(", "x", ",", "mode", ",", "trainable", "=", "True", ")", ":", "\n", "    ", "if", "not", "mode", "or", "mode", "==", "\"none\"", ":", "\n", "        ", "return", "x", "\n", "", "elif", "mode", "==", "\"layer_norm\"", ":", "\n", "        ", "return", "layers", ".", "nn", ".", "layer_norm", "(", "x", ",", "trainable", "=", "trainable", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown mode %s\"", "%", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer._residual_fn": [[27, 31], ["tensorflow.nn.dropout"], "function", ["None"], ["", "", "def", "_residual_fn", "(", "x", ",", "y", ",", "keep_prob", "=", "None", ")", ":", "\n", "    ", "if", "keep_prob", "and", "keep_prob", "<", "1.0", ":", "\n", "        ", "y", "=", "tf", ".", "nn", ".", "dropout", "(", "y", ",", "keep_prob", ")", "\n", "", "return", "x", "+", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer._ffn_layer": [[33, 48], ["tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.nn.linear", "tensorflow.nn.relu", "tensorflow.nn.dropout", "tensorflow.variable_scope", "thumt.nn.linear"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear"], ["", "def", "_ffn_layer", "(", "inputs", ",", "hidden_size", ",", "output_size", ",", "keep_prob", "=", "None", ",", "\n", "dtype", "=", "None", ",", "scope", "=", "None", ",", "trainable", "=", "True", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"ffn_layer\"", ",", "values", "=", "[", "inputs", "]", ",", "\n", "dtype", "=", "dtype", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"input_layer\"", ")", ":", "\n", "            ", "hidden", "=", "layers", ".", "nn", ".", "linear", "(", "inputs", ",", "hidden_size", ",", "True", ",", "True", ",", "trainable", "=", "trainable", ")", "\n", "hidden", "=", "tf", ".", "nn", ".", "relu", "(", "hidden", ")", "\n", "\n", "", "if", "keep_prob", "and", "keep_prob", "<", "1.0", ":", "\n", "            ", "hidden", "=", "tf", ".", "nn", ".", "dropout", "(", "hidden", ",", "keep_prob", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"output_layer\"", ")", ":", "\n", "            ", "output", "=", "layers", ".", "nn", ".", "linear", "(", "hidden", ",", "output_size", ",", "True", ",", "True", ",", "trainable", "=", "trainable", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer._load_embedding": [[49, 76], ["print", "print", "numpy.array", "open", "line.strip().split", "numpy.array", "word_vectors.append", "word_vectors.append", "len", "numpy.random.uniform", "line.strip"], "function", ["None"], ["", "", "def", "_load_embedding", "(", "word_list", ",", "params", ",", "uniform_scale", "=", "0.25", ",", "dimension_size", "=", "300", ",", "embed_file", "=", "'glove'", ")", ":", "\n", "\n", "    ", "word2embed", "=", "{", "}", "\n", "if", "embed_file", "==", "'w2v'", ":", "\n", "        ", "file_path", "=", "params", ".", "embedding_path", "\n", "", "else", ":", "\n", "        ", "file_path", "=", "params", ".", "embedding_path", "\n", "\n", "", "with", "open", "(", "file_path", ",", "'r'", ")", "as", "fopen", ":", "\n", "        ", "for", "line", "in", "fopen", ":", "\n", "            ", "w", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "word2embed", "[", "' '", ".", "join", "(", "w", "[", ":", "-", "dimension_size", "]", ")", "]", "=", "w", "[", "-", "dimension_size", ":", "]", "\n", "", "", "word_vectors", "=", "[", "]", "\n", "\n", "c", "=", "0", "\n", "for", "word", "in", "word_list", ":", "\n", "        ", "if", "word", "in", "word2embed", ":", "\n", "            ", "c", "+=", "1", "\n", "s", "=", "np", ".", "array", "(", "word2embed", "[", "word", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "word_vectors", ".", "append", "(", "s", ")", "\n", "", "else", ":", "\n", "            ", "word_vectors", ".", "append", "(", "np", ".", "random", ".", "uniform", "(", "-", "uniform_scale", ",", "uniform_scale", ",", "dimension_size", ")", ")", "\n", "\n", "", "", "print", "(", "'glove initializes {}'", ".", "format", "(", "c", ")", ")", "\n", "print", "(", "'all words initializes {}'", ".", "format", "(", "len", "(", "word_vectors", ")", ")", ")", "\n", "\n", "return", "np", ".", "array", "(", "word_vectors", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer.birnn": [[77, 84], ["rnn.BasicLSTMCell", "rnn.BasicLSTMCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.concat"], "function", ["None"], ["", "def", "birnn", "(", "inputs", ",", "sequence_length", ",", "params", ")", ":", "\n", "    ", "lstm_fw_cell", "=", "rnn", ".", "BasicLSTMCell", "(", "params", ".", "hidden_size", ")", "\n", "lstm_bw_cell", "=", "rnn", ".", "BasicLSTMCell", "(", "params", ".", "hidden_size", ")", "\n", "outputs", ",", "states", "=", "tf", ".", "nn", ".", "bidirectional_dynamic_rnn", "(", "lstm_fw_cell", ",", "lstm_bw_cell", ",", "inputs", ",", "\n", "sequence_length", "=", "sequence_length", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "states_fw", ",", "states_bw", "=", "outputs", "\n", "return", "tf", ".", "concat", "(", "[", "states_fw", ",", "states_bw", "]", ",", "axis", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer.sample_gaussian": [[85, 90], ["tensorflow.random_normal", "tensorflow.exp", "tensorflow.shape", "tensorflow.multiply"], "function", ["None"], ["", "def", "sample_gaussian", "(", "mu", ",", "logvar", ")", ":", "\n", "    ", "epsilon", "=", "tf", ".", "random_normal", "(", "tf", ".", "shape", "(", "logvar", ")", ",", "name", "=", "\"epsilon\"", ")", "\n", "std", "=", "tf", ".", "exp", "(", "0.5", "*", "logvar", ")", "\n", "z", "=", "mu", "+", "tf", ".", "multiply", "(", "std", ",", "epsilon", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer.gaussian_kld": [[91, 96], ["tensorflow.reduce_sum", "tensorflow.div", "tensorflow.div", "tensorflow.exp", "tensorflow.exp", "tensorflow.pow", "tensorflow.exp"], "function", ["None"], ["", "def", "gaussian_kld", "(", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ")", ":", "\n", "    ", "kld", "=", "-", "0.5", "*", "tf", ".", "reduce_sum", "(", "1", "+", "(", "recog_logvar", "-", "prior_logvar", ")", "\n", "-", "tf", ".", "div", "(", "tf", ".", "pow", "(", "prior_mu", "-", "recog_mu", ",", "2", ")", ",", "tf", ".", "exp", "(", "prior_logvar", ")", ")", "\n", "-", "tf", ".", "div", "(", "tf", ".", "exp", "(", "recog_logvar", ")", ",", "tf", ".", "exp", "(", "prior_logvar", ")", ")", ",", "reduction_indices", "=", "1", ")", "\n", "return", "kld", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer.gelu": [[97, 108], ["tensorflow.erf", "tensorflow.sqrt"], "function", ["None"], ["", "def", "gelu", "(", "input_tensor", ")", ":", "\n", "  ", "\"\"\"Gaussian Error Linear Unit.\n  This is a smoother version of the RELU.\n  Original paper: https://arxiv.org/abs/1606.08415\n  Args:\n    input_tensor: float Tensor to perform activation.\n  Returns:\n    `input_tensor` with the GELU activation applied.\n  \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "erf", "(", "input_tensor", "/", "tf", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "return", "input_tensor", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer.transformer_context": [[109, 145], ["tensorflow.variable_scope", "range", "transformer._layer_process", "tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.attention.multihead_attention", "transformer._residual_fn", "transformer._layer_process", "tensorflow.variable_scope", "transformer._ffn_layer", "transformer._residual_fn", "transformer._layer_process", "transformer._layer_process", "transformer._layer_process"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multihead_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._ffn_layer", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process"], ["", "def", "transformer_context", "(", "inputs", ",", "bias", ",", "params", ",", "dtype", "=", "None", ",", "scope", "=", "\"ctx_transformer\"", ",", "trainable", "=", "True", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"context\"", ",", "dtype", "=", "dtype", ",", "\n", "values", "=", "[", "inputs", ",", "bias", "]", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "for", "layer", "in", "range", "(", "params", ".", "num_context_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "layer", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"self_attention\"", ")", ":", "\n", "                    ", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "None", ",", "\n", "bias", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", "trainable", "=", "trainable", "\n", ")", "\n", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"feed_forward\"", ")", ":", "\n", "                    ", "y", "=", "_ffn_layer", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "params", ".", "filter_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "relu_dropout", ",", "\n", "trainable", "=", "trainable", "\n", ")", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "\n", "", "", "", "outputs", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer.transformer_encoder": [[50, 88], ["tensorflow.variable_scope", "range", "transformer._layer_process", "tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.attention.multihead_attention", "transformer._residual_fn", "transformer._layer_process", "tensorflow.variable_scope", "transformer._ffn_layer", "transformer._residual_fn", "transformer._layer_process", "transformer._layer_process", "transformer._layer_process"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multihead_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._ffn_layer", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process"], ["\n", "    ", "word2embed", "=", "{", "}", "\n", "if", "embed_file", "==", "'w2v'", ":", "\n", "        ", "file_path", "=", "params", ".", "embedding_path", "\n", "", "else", ":", "\n", "        ", "file_path", "=", "params", ".", "embedding_path", "\n", "\n", "", "with", "open", "(", "file_path", ",", "'r'", ")", "as", "fopen", ":", "\n", "        ", "for", "line", "in", "fopen", ":", "\n", "            ", "w", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "word2embed", "[", "' '", ".", "join", "(", "w", "[", ":", "-", "dimension_size", "]", ")", "]", "=", "w", "[", "-", "dimension_size", ":", "]", "\n", "", "", "word_vectors", "=", "[", "]", "\n", "\n", "c", "=", "0", "\n", "for", "word", "in", "word_list", ":", "\n", "        ", "if", "word", "in", "word2embed", ":", "\n", "            ", "c", "+=", "1", "\n", "s", "=", "np", ".", "array", "(", "word2embed", "[", "word", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "word_vectors", ".", "append", "(", "s", ")", "\n", "", "else", ":", "\n", "            ", "word_vectors", ".", "append", "(", "np", ".", "random", ".", "uniform", "(", "-", "uniform_scale", ",", "uniform_scale", ",", "dimension_size", ")", ")", "\n", "\n", "", "", "print", "(", "'glove initializes {}'", ".", "format", "(", "c", ")", ")", "\n", "print", "(", "'all words initializes {}'", ".", "format", "(", "len", "(", "word_vectors", ")", ")", ")", "\n", "\n", "return", "np", ".", "array", "(", "word_vectors", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "def", "birnn", "(", "inputs", ",", "sequence_length", ",", "params", ")", ":", "\n", "    ", "lstm_fw_cell", "=", "rnn", ".", "BasicLSTMCell", "(", "params", ".", "hidden_size", ")", "\n", "lstm_bw_cell", "=", "rnn", ".", "BasicLSTMCell", "(", "params", ".", "hidden_size", ")", "\n", "outputs", ",", "states", "=", "tf", ".", "nn", ".", "bidirectional_dynamic_rnn", "(", "lstm_fw_cell", ",", "lstm_bw_cell", ",", "inputs", ",", "\n", "sequence_length", "=", "sequence_length", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "states_fw", ",", "states_bw", "=", "outputs", "\n", "return", "tf", ".", "concat", "(", "[", "states_fw", ",", "states_bw", "]", ",", "axis", "=", "2", ")", "\n", "\n", "", "def", "sample_gaussian", "(", "mu", ",", "logvar", ")", ":", "\n", "    ", "epsilon", "=", "tf", ".", "random_normal", "(", "tf", ".", "shape", "(", "logvar", ")", ",", "name", "=", "\"epsilon\"", ")", "\n", "std", "=", "tf", ".", "exp", "(", "0.5", "*", "logvar", ")", "\n", "z", "=", "mu", "+", "tf", ".", "multiply", "(", "std", ",", "epsilon", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer.transformer_decoder": [[90, 156], ["tensorflow.variable_scope", "range", "transformer._layer_process", "tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.attention.multihead_attention", "transformer._residual_fn", "transformer._layer_process", "tensorflow.variable_scope", "thumt.attention.multihead_attention", "transformer._residual_fn", "transformer._layer_process", "tensorflow.variable_scope", "transformer._ffn_layer", "transformer._residual_fn", "transformer._layer_process", "transformer._layer_process", "transformer._layer_process", "transformer._layer_process"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multihead_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multihead_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._ffn_layer", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process"], ["\n", "", "def", "gaussian_kld", "(", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ")", ":", "\n", "    ", "kld", "=", "-", "0.5", "*", "tf", ".", "reduce_sum", "(", "1", "+", "(", "recog_logvar", "-", "prior_logvar", ")", "\n", "-", "tf", ".", "div", "(", "tf", ".", "pow", "(", "prior_mu", "-", "recog_mu", ",", "2", ")", ",", "tf", ".", "exp", "(", "prior_logvar", ")", ")", "\n", "-", "tf", ".", "div", "(", "tf", ".", "exp", "(", "recog_logvar", ")", ",", "tf", ".", "exp", "(", "prior_logvar", ")", ")", ",", "reduction_indices", "=", "1", ")", "\n", "return", "kld", "\n", "\n", "", "def", "gelu", "(", "input_tensor", ")", ":", "\n", "  ", "\"\"\"Gaussian Error Linear Unit.\n  This is a smoother version of the RELU.\n  Original paper: https://arxiv.org/abs/1606.08415\n  Args:\n    input_tensor: float Tensor to perform activation.\n  Returns:\n    `input_tensor` with the GELU activation applied.\n  \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "erf", "(", "input_tensor", "/", "tf", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "return", "input_tensor", "*", "cdf", "\n", "\n", "", "def", "transformer_context", "(", "inputs", ",", "bias", ",", "params", ",", "dtype", "=", "None", ",", "scope", "=", "\"ctx_transformer\"", ",", "trainable", "=", "True", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"context\"", ",", "dtype", "=", "dtype", ",", "\n", "values", "=", "[", "inputs", ",", "bias", "]", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "for", "layer", "in", "range", "(", "params", ".", "num_context_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "layer", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"self_attention\"", ")", ":", "\n", "                    ", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "None", ",", "\n", "bias", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", "trainable", "=", "trainable", "\n", ")", "\n", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"feed_forward\"", ")", ":", "\n", "                    ", "y", "=", "_ffn_layer", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "params", ".", "filter_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "relu_dropout", ",", "\n", "trainable", "=", "trainable", "\n", ")", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "\n", "", "", "", "outputs", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", "\n", "\n", "return", "outputs", "\n", "\n", "", "", "def", "transformer_encoder", "(", "inputs", ",", "bias", ",", "params", ",", "dia_mask", "=", "None", ",", "dtype", "=", "None", ",", "scope", "=", "None", ",", "trainable", "=", "True", ",", "get_first_layer", "=", "False", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"encoder\"", ",", "dtype", "=", "dtype", ",", "\n", "values", "=", "[", "inputs", ",", "bias", "]", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "for", "layer", "in", "range", "(", "params", ".", "num_encoder_layers", ")", ":", "\n", "            ", "if", "layer", "<", "params", ".", "bottom_block", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "layer", ")", ":", "\n", "                    ", "with", "tf", ".", "variable_scope", "(", "\"self_attention\"", ")", ":", "\n", "                        ", "max_relative_dis", "=", "params", ".", "max_relative_dis", "if", "params", ".", "position_info_type", "==", "'relative'", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer.encoding_graph": [[158, 208], ["tensorflow.sequence_mask", "len", "tensorflow.random_normal_initializer", "tensorflow.get_variable", "tensorflow.gather", "tensorflow.nn.bias_add", "thumt.attention.attention_bias", "transformer.transformer_encoder", "tensorflow.get_variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.expand_dims", "thumt.attention.add_timing_signal", "tensorflow.nn.dropout", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.transformer_encoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.add_timing_signal"], ["_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "None", ",", "\n", "bias", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", "max_relative_dis", "=", "max_relative_dis", ",", "\n", "trainable", "=", "trainable", "\n", ")", "\n", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "trainable", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"feed_forward\"", ")", ":", "\n", "                        ", "y", "=", "_ffn_layer", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "params", ".", "filter_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "relu_dropout", ",", "\n", "trainable", "=", "trainable", "\n", ")", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "trainable", ")", "\n", "", "", "first_layer_output", "=", "x", "\n", "#print(\"first_layer_output\", first_layer_output)", "\n", "if", "get_first_layer", "and", "layer", "==", "(", "params", ".", "bottom_block", "-", "1", ")", ":", "\n", "                    ", "return", "x", ",", "first_layer_output", "\n", "", "", "else", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "layer", ")", ":", "\n", "                    ", "with", "tf", ".", "variable_scope", "(", "\"self_attention\"", ")", ":", "\n", "                        ", "max_relative_dis", "=", "params", ".", "max_relative_dis", "if", "params", ".", "position_info_type", "==", "'relative'", "else", "None", "\n", "\n", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "None", ",", "\n", "bias", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", "max_relative_dis", "=", "max_relative_dis", ",", "\n", "trainable", "=", "trainable", ",", "\n", "dia_mask", "=", "dia_mask", "\n", ")", "\n", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "trainable", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer.decoding_graph": [[210, 310], ["tensorflow.sequence_mask", "tensorflow.sequence_mask", "len", "tensorflow.random_normal_initializer", "tensorflow.gather", "thumt.attention.attention_bias", "thumt.attention.attention_bias", "tensorflow.reshape", "tensorflow.matmul", "thumt.smoothed_softmax_cross_entropy_with_logits", "tensorflow.cast", "tensorflow.reshape", "tensorflow.get_variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.expand_dims", "tensorflow.pad", "thumt.attention.add_timing_signal", "tensorflow.nn.dropout", "transformer.transformer_decoder", "transformer.transformer_decoder", "tensorflow.matmul", "tensorflow.nn.log_softmax", "tensorflow.shape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.shape", "tensorflow.reduce_sum", "tensorflow.shape", "tensorflow.shape", "tensorflow.get_variable_scope"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.losses.losses.smoothed_softmax_cross_entropy_with_logits", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.add_timing_signal", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.transformer_decoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.transformer_decoder"], ["", "with", "tf", ".", "variable_scope", "(", "\"feed_forward\"", ")", ":", "\n", "                        ", "y", "=", "_ffn_layer", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "params", ".", "filter_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "relu_dropout", ",", "\n", "trainable", "=", "trainable", "\n", ")", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "trainable", ")", "\n", "\n", "#            if params.bottom_block and get_first_layer:", "\n", "#                return first_layer_output, first_layer_output", "\n", "\n", "", "", "", "", "outputs", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", "\n", "if", "params", ".", "bottom_block", "==", "0", ":", "\n", "            ", "first_layer_output", "=", "x", "\n", "\n", "", "return", "outputs", ",", "first_layer_output", "\n", "\n", "\n", "", "", "def", "transformer_decoder", "(", "inputs", ",", "memory", ",", "bias", ",", "mem_bias", ",", "params", ",", "state", "=", "None", ",", "dia_mask", "=", "None", ",", "\n", "dtype", "=", "None", ",", "scope", "=", "None", ",", "trainable", "=", "True", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"decoder\"", ",", "dtype", "=", "dtype", ",", "\n", "values", "=", "[", "inputs", ",", "memory", ",", "bias", ",", "mem_bias", "]", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "#    with tf.variable_scope(scope, default_name=\"decoder\", dtype=dtype,", "\n", "#                           values=[inputs, memory, bias, mem_bias]):", "\n", "        ", "x", "=", "inputs", "\n", "next_state", "=", "{", "}", "\n", "for", "layer", "in", "range", "(", "params", ".", "num_decoder_layers", ")", ":", "\n", "            ", "layer_name", "=", "\"layer_%d\"", "%", "layer", "\n", "with", "tf", ".", "variable_scope", "(", "layer_name", ")", ":", "\n", "                ", "layer_state", "=", "state", "[", "layer_name", "]", "if", "state", "is", "not", "None", "else", "None", "\n", "max_relative_dis", "=", "params", ".", "max_relative_dis", "if", "params", ".", "position_info_type", "==", "'relative'", "else", "None", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"self_attention\"", ")", ":", "\n", "                    ", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "None", ",", "\n", "bias", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", "state", "=", "layer_state", ",", "\n", "max_relative_dis", "=", "max_relative_dis", ",", "\n", "trainable", "=", "trainable", "\n", ")", "\n", "\n", "if", "layer_state", "is", "not", "None", ":", "\n", "                        ", "next_state", "[", "layer_name", "]", "=", "y", "[", "\"state\"", "]", "\n", "\n", "", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "trainable", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"encdec_attention\"", ")", ":", "\n", "                    ", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "memory", ",", "\n", "mem_bias", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", "max_relative_dis", "=", "max_relative_dis", ",", "\n", "trainable", "=", "trainable", ",", "\n", "dia_mask", "=", "dia_mask", "\n", ")", "\n", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "trainable", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"feed_forward\"", ")", ":", "\n", "                    ", "y", "=", "_ffn_layer", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "params", ".", "filter_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "relu_dropout", ",", "\n", "trainable", "=", "trainable", "\n", ")", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "trainable", ")", "\n", "\n", "", "", "", "outputs", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", "\n", "\n", "if", "state", "is", "not", "None", ":", "\n", "            ", "return", "outputs", ",", "next_state", "\n", "\n", "", "return", "outputs", "\n", "\n", "\n", "", "", "def", "encoding_graph", "(", "features", ",", "mode", ",", "params", ")", ":", "\n", "    ", "if", "mode", "!=", "\"train\"", ":", "\n", "        ", "params", ".", "residual_dropout", "=", "0.0", "\n", "params", ".", "attention_dropout", "=", "0.0", "\n", "params", ".", "relu_dropout", "=", "0.0", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer.model_graph": [[312, 320], ["transformer.encoding_graph", "transformer.decoding_graph"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.encoding_graph", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.decoding_graph"], ["", "dtype", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "dtype", "\n", "hidden_size", "=", "params", ".", "hidden_size", "\n", "src_seq", "=", "features", "[", "\"source\"", "]", "\n", "sample_seq", "=", "features", "[", "\"sample\"", "]", "\n", "print", "(", "features", ")", "\n", "ctx_dia_src_seq", "=", "features", "[", "\"context_dia_src\"", "]", "\n", "ctx_dia_tgt_seq", "=", "features", "[", "\"context_dia_tgt\"", "]", "\n", "ctx_sty_src_seq", "=", "features", "[", "\"context_sty_src\"", "]", "\n", "ctx_sty_tgt_seq", "=", "features", "[", "\"context_sty_tgt\"", "]", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.RNNsearchLRP.__init__": [[447, 449], ["thumt.models.model.NMTModel.__init__"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.train_word2vec.MySentences.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "scope", "=", "\"rnnsearch\"", ")", ":", "\n", "        ", "super", "(", "RNNsearchLRP", ",", "self", ")", ".", "__init__", "(", "params", "=", "params", ",", "scope", "=", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.RNNsearchLRP.get_training_func": [[450, 460], ["tensorflow.variable_scope", "rnnsearch_lrp.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_training_func", "(", "self", ",", "initializer", ")", ":", "\n", "        ", "def", "training_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "self", ".", "parameters", "\n", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ",", "initializer", "=", "initializer", ",", "\n", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "loss", "=", "model_graph", "(", "features", ",", "features", "[", "\"target\"", "]", ",", "params", ")", "[", "0", "]", "\n", "return", "loss", "\n", "\n", "", "", "return", "training_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.RNNsearchLRP.get_evaluation_func": [[461, 477], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "rnnsearch_lrp.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_evaluation_func", "(", "self", ")", ":", "\n", "        ", "def", "evaluation_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "", "params", ".", "dropout", "=", "0.0", "\n", "params", ".", "use_variational_dropout", "=", "False", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "logits", "=", "model_graph", "(", "features", ",", "None", ",", "params", ")", "\n", "\n", "", "return", "logits", "\n", "\n", "", "return", "evaluation_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.RNNsearchLRP.get_relevance_func": [[478, 494], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "rnnsearch_lrp.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_relevance_func", "(", "self", ")", ":", "\n", "        ", "def", "relevance_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "params", ".", "dropout", "=", "0.0", "\n", "params", ".", "use_variational_dropout", "=", "False", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "loss", ",", "rlv", "=", "model_graph", "(", "features", ",", "features", "[", "\"target\"", "]", ",", "\n", "params", ")", "\n", "return", "features", "[", "\"source\"", "]", ",", "features", "[", "\"target\"", "]", ",", "rlv", ",", "loss", "\n", "", "", "return", "relevance_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.RNNsearchLRP.get_inference_func": [[495, 511], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "rnnsearch_lrp.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_inference_func", "(", "self", ")", ":", "\n", "        ", "def", "inference_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "", "params", ".", "dropout", "=", "0.0", "\n", "params", ".", "use_variational_dropout", "=", "False", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "logits", "=", "model_graph", "(", "features", ",", "None", ",", "params", ")", "\n", "\n", "", "return", "logits", "\n", "\n", "", "return", "inference_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.RNNsearchLRP.get_name": [[512, 515], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_name", "(", ")", ":", "\n", "        ", "return", "\"rnnsearch\"", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.RNNsearchLRP.get_parameters": [[516, 543], ["tensorflow.contrib.training.HParams"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_parameters", "(", ")", ":", "\n", "        ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "# vocabulary", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "eos", "=", "\"<eos>\"", ",", "\n", "bos", "=", "\"<eos>\"", ",", "\n", "append_eos", "=", "False", ",", "\n", "# model", "\n", "rnn_cell", "=", "\"LegacyGRUCell\"", ",", "\n", "embedding_size", "=", "620", ",", "\n", "hidden_size", "=", "1000", ",", "\n", "maxnum", "=", "2", ",", "\n", "# regularization", "\n", "dropout", "=", "0.2", ",", "\n", "use_variational_dropout", "=", "False", ",", "\n", "label_smoothing", "=", "0.1", ",", "\n", "constant_batch_size", "=", "True", ",", "\n", "batch_size", "=", "128", ",", "\n", "max_length", "=", "60", ",", "\n", "clip_grad_norm", "=", "5.0", ",", "\n", "#lrp", "\n", "stab", "=", "0.05", "\n", ")", "\n", "\n", "return", "params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.normalize": [[18, 27], ["tensorflow.abs", "tensorflow.reduce_sum", "tensorflow.abs", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.expand_dims"], "function", ["None"], ["def", "normalize", "(", "matrix", ",", "negative", "=", "False", ")", ":", "\n", "    ", "if", "negative", ":", "\n", "        ", "matrix_abs", "=", "tf", ".", "abs", "(", "matrix", ")", "\n", "total", "=", "tf", ".", "reduce_sum", "(", "matrix_abs", ",", "-", "1", ")", "\n", "return", "matrix", "/", "tf", ".", "expand_dims", "(", "total", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "matrix", "=", "tf", ".", "abs", "(", "matrix", ")", "\n", "total", "=", "tf", ".", "reduce_sum", "(", "matrix", ",", "-", "1", ")", "\n", "return", "matrix", "/", "tf", ".", "expand_dims", "(", "total", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.stabilize": [[29, 36], ["tensorflow.sign", "tensorflow.equal", "tensorflow.cast", "tensorflow.zeros", "tensorflow.shape"], "function", ["None"], ["", "", "def", "stabilize", "(", "matrix", ",", "stab", ")", ":", "\n", "    ", "sign", "=", "tf", ".", "sign", "(", "matrix", ")", "\n", "zero_pos", "=", "tf", ".", "equal", "(", "sign", ",", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "sign", ")", ")", ")", "\n", "zero_pos", "=", "tf", ".", "cast", "(", "zero_pos", ",", "tf", ".", "float32", ")", "\n", "sign", "+=", "zero_pos", "\n", "result", "=", "matrix", "+", "stab", "*", "sign", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._copy_through": [[38, 41], ["tensorflow.where"], "function", ["None"], ["", "def", "_copy_through", "(", "time", ",", "length", ",", "output", ",", "new_output", ")", ":", "\n", "    ", "copy_cond", "=", "(", "time", ">=", "length", ")", "\n", "return", "tf", ".", "where", "(", "copy_cond", ",", "output", ",", "new_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._gru_encoder": [[43, 101], ["tensorflow.zeros", "tensorflow.TensorArray", "tensorflow.TensorArray", "tensorflow.TensorArray", "tensorflow.zeros", "input_ta.unstack.unstack", "tensorflow.constant", "tensorflow.while_loop", "output_final_ta.stack", "tf.transpose.set_shape", "tensorflow.transpose", "w_x_h_final_ta.stack", "tensorflow.shape", "tensorflow.shape", "cell.zero_state", "tensorflow.transpose", "input_ta.unstack.read", "cell", "tensorflow.pad", "rnnsearch_lrp._copy_through", "rnnsearch_lrp._copy_through", "rnnsearch_lrp._copy_through", "out_ta.write.write", "wxh_ta.write.write"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._copy_through", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._copy_through", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._copy_through"], ["", "def", "_gru_encoder", "(", "cell", ",", "inputs", ",", "sequence_length", ",", "initial_state", ",", "params", ",", "\n", "dtype", "=", "None", ")", ":", "\n", "# Assume that the underlying cell is GRUCell-like", "\n", "    ", "output_size", "=", "cell", ".", "output_size", "\n", "dtype", "=", "dtype", "or", "inputs", ".", "dtype", "\n", "\n", "batch", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "time_steps", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", "\n", "\n", "zero_output", "=", "tf", ".", "zeros", "(", "[", "batch", ",", "output_size", "]", ",", "dtype", ")", "\n", "\n", "if", "initial_state", "is", "None", ":", "\n", "        ", "initial_state", "=", "cell", ".", "zero_state", "(", "batch", ",", "dtype", ")", "\n", "\n", "", "input_ta", "=", "tf", ".", "TensorArray", "(", "dtype", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"input_array\"", ")", "\n", "output_ta", "=", "tf", ".", "TensorArray", "(", "dtype", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"output_array\"", ")", "\n", "\n", "w_x_h_ta", "=", "tf", ".", "TensorArray", "(", "dtype", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"w_x_h_array\"", ")", "\n", "w_x_h_init", "=", "tf", ".", "zeros", "(", "[", "batch", ",", "time_steps", ",", "output_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "input_ta", "=", "input_ta", ".", "unstack", "(", "tf", ".", "transpose", "(", "inputs", ",", "[", "1", ",", "0", ",", "2", "]", ")", ")", "\n", "\n", "def", "loop_func", "(", "t", ",", "out_ta", ",", "state", ",", "wxh_ta", ",", "w_x_h_last", ")", ":", "\n", "        ", "inp_t", "=", "input_ta", ".", "read", "(", "t", ")", "\n", "cell_output", ",", "new_state", ",", "w_xlast_newh", ",", "w_x_newh", "=", "cell", "(", "inp_t", ",", "state", ",", "\n", "w_x_h_last", ",", "\n", "params", ")", "\n", "w_x_newh", "=", "tf", ".", "pad", "(", "w_x_newh", ",", "[", "[", "0", ",", "0", "]", ",", "[", "t", ",", "time_steps", "-", "t", "-", "1", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "w_x_h_new", "=", "w_xlast_newh", "+", "w_x_newh", "\n", "cell_output", "=", "_copy_through", "(", "t", ",", "sequence_length", ",", "zero_output", ",", "\n", "cell_output", ")", "\n", "new_state", "=", "_copy_through", "(", "t", ",", "sequence_length", ",", "state", ",", "new_state", ")", "\n", "w_x_h_new", "=", "_copy_through", "(", "t", ",", "sequence_length", ",", "w_x_h_last", ",", "w_x_h_new", ")", "\n", "out_ta", "=", "out_ta", ".", "write", "(", "t", ",", "cell_output", ")", "\n", "wxh_ta", "=", "wxh_ta", ".", "write", "(", "t", ",", "w_x_h_new", ")", "\n", "return", "t", "+", "1", ",", "out_ta", ",", "new_state", ",", "wxh_ta", ",", "w_x_h_new", "\n", "\n", "", "time", "=", "tf", ".", "constant", "(", "0", ",", "dtype", "=", "tf", ".", "int32", ",", "name", "=", "\"time\"", ")", "\n", "loop_vars", "=", "(", "time", ",", "output_ta", ",", "initial_state", ",", "w_x_h_ta", ",", "w_x_h_init", ")", "\n", "\n", "outputs", "=", "tf", ".", "while_loop", "(", "lambda", "t", ",", "*", "_", ":", "t", "<", "time_steps", ",", "loop_func", ",", "\n", "loop_vars", ",", "parallel_iterations", "=", "32", ",", "\n", "swap_memory", "=", "True", ")", "\n", "\n", "output_final_ta", "=", "outputs", "[", "1", "]", "\n", "final_state", "=", "outputs", "[", "2", "]", "\n", "\n", "all_output", "=", "output_final_ta", ".", "stack", "(", ")", "\n", "all_output", ".", "set_shape", "(", "[", "None", ",", "None", ",", "output_size", "]", ")", "\n", "all_output", "=", "tf", ".", "transpose", "(", "all_output", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "w_x_h_final_ta", "=", "outputs", "[", "3", "]", "\n", "w_x_h_final", "=", "w_x_h_final_ta", ".", "stack", "(", ")", "\n", "\n", "return", "all_output", ",", "final_state", ",", "w_x_h_final", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._encoder": [[103, 137], ["tensorflow.variable_scope", "tensorflow.reverse_sequence", "tensorflow.variable_scope", "rnnsearch_lrp._gru_encoder", "tensorflow.variable_scope", "rnnsearch_lrp._gru_encoder", "tensorflow.reverse_sequence", "tensorflow.concat"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._gru_encoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._gru_encoder"], ["", "def", "_encoder", "(", "cell_fw", ",", "cell_bw", ",", "inputs", ",", "sequence_length", ",", "params", ",", "dtype", "=", "None", ",", "\n", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"encoder\"", ",", "\n", "values", "=", "[", "inputs", ",", "sequence_length", "]", ")", ":", "\n", "        ", "inputs_fw", "=", "inputs", "\n", "inputs_bw", "=", "tf", ".", "reverse_sequence", "(", "inputs", ",", "sequence_length", ",", "\n", "batch_axis", "=", "0", ",", "seq_axis", "=", "1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"forward\"", ")", ":", "\n", "            ", "output_fw", ",", "state_fw", ",", "w_x_h_fw", "=", "_gru_encoder", "(", "cell_fw", ",", "inputs_fw", ",", "\n", "sequence_length", ",", "None", ",", "params", ",", "\n", "dtype", "=", "dtype", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"backward\"", ")", ":", "\n", "            ", "output_bw", ",", "state_bw", ",", "w_x_h_bw", "=", "_gru_encoder", "(", "cell_bw", ",", "inputs_bw", ",", "\n", "sequence_length", ",", "None", ",", "params", ",", "\n", "dtype", "=", "dtype", ")", "\n", "output_bw", "=", "tf", ".", "reverse_sequence", "(", "output_bw", ",", "sequence_length", ",", "\n", "batch_axis", "=", "0", ",", "seq_axis", "=", "1", ")", "\n", "\n", "", "results", "=", "{", "\n", "\"annotation\"", ":", "tf", ".", "concat", "(", "[", "output_fw", ",", "output_bw", "]", ",", "axis", "=", "2", ")", ",", "\n", "\"outputs\"", ":", "{", "\n", "\"forward\"", ":", "output_fw", ",", "\n", "\"backward\"", ":", "output_bw", "\n", "}", ",", "\n", "\"final_states\"", ":", "{", "\n", "\"forward\"", ":", "state_fw", ",", "\n", "\"backward\"", ":", "state_bw", "\n", "}", ",", "\n", "\"weight_ratios\"", ":", "[", "w_x_h_fw", ",", "w_x_h_bw", "]", "\n", "}", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._decoder": [[139, 270], ["tensorflow.zeros", "tensorflow.zeros", "tensorflow.shape", "tensorflow.shape", "tensorflow.variable_scope", "tensorflow.transpose", "tensorflow.sequence_mask", "thumt.attention.attention_bias", "tensorflow.squeeze", "thumt.attention.attention", "tensorflow.TensorArray", "tensorflow.TensorArray", "tensorflow.TensorArray", "tensorflow.TensorArray", "input_ta.unstack.unstack", "tensorflow.TensorArray", "w_x_bw_ta.unstack.unstack", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.TensorArray", "tensorflow.TensorArray", "thumt.linear_v2n", "tensorflow.tanh", "tensorflow.constant", "tensorflow.while_loop", "output_final_ta.stack", "tf.transpose.set_shape", "tensorflow.transpose", "value_final_ta.stack", "tf.transpose.set_shape", "tensorflow.transpose", "w_x_h_final_ta.stack", "w_x_c_final_ta.stack", "tensorflow.shape", "tensorflow.shape", "tensorflow.concat", "wxh_ta.write.write", "input_ta.unstack.read", "thumt.attention.attention", "tensorflow.expand_dims", "tensorflow.squeeze", "rnnsearch_lrp.stabilize", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.reshape", "wxc_ta.write.write", "cell", "rnnsearch_lrp._copy_through", "rnnsearch_lrp._copy_through", "rnnsearch_lrp._copy_through", "rnnsearch_lrp._copy_through", "out_ta.write.write", "att_ta.write.write", "val_ta.write.write", "tensorflow.identity", "w_x_bw_ta.unstack.read", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.reshape", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.linear_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.stabilize", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._copy_through", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._copy_through", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._copy_through", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._copy_through"], ["", "", "def", "_decoder", "(", "cell", ",", "inputs", ",", "memory", ",", "sequence_length", ",", "initial_state", ",", "w_x_enc", ",", "\n", "w_x_bw", ",", "params", ",", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "# Assume that the underlying cell is GRUCell-like", "\n", "    ", "batch", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "time_steps", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", "\n", "dtype", "=", "dtype", "or", "inputs", ".", "dtype", "\n", "output_size", "=", "cell", ".", "output_size", "\n", "zero_output", "=", "tf", ".", "zeros", "(", "[", "batch", ",", "output_size", "]", ",", "dtype", ")", "\n", "zero_value", "=", "tf", ".", "zeros", "(", "[", "batch", ",", "memory", ".", "shape", "[", "-", "1", "]", ".", "value", "]", ",", "dtype", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"decoder\"", ",", "dtype", "=", "dtype", ")", ":", "\n", "        ", "inputs", "=", "tf", ".", "transpose", "(", "inputs", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "mem_mask", "=", "tf", ".", "sequence_mask", "(", "sequence_length", "[", "\"source\"", "]", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "memory", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "mem_mask", ",", "\"masking\"", ")", "\n", "bias", "=", "tf", ".", "squeeze", "(", "bias", ",", "axis", "=", "[", "1", ",", "2", "]", ")", "\n", "cache", "=", "layers", ".", "attention", ".", "attention", "(", "None", ",", "memory", ",", "None", ",", "output_size", ")", "\n", "\n", "input_ta", "=", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"input_array\"", ")", "\n", "output_ta", "=", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"output_array\"", ")", "\n", "value_ta", "=", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"value_array\"", ")", "\n", "alpha_ta", "=", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"alpha_array\"", ")", "\n", "input_ta", "=", "input_ta", ".", "unstack", "(", "inputs", ")", "\n", "\n", "len_src", "=", "tf", ".", "shape", "(", "w_x_bw", ")", "[", "0", "]", "\n", "w_x_bw_ta", "=", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "len_src", ",", "\n", "tensor_array_name", "=", "\"w_x_bw_array\"", ")", "\n", "\n", "w_x_bw_ta", "=", "w_x_bw_ta", ".", "unstack", "(", "w_x_bw", ")", "\n", "w_x_c_shape", "=", "tf", ".", "shape", "(", "w_x_enc", ")", "[", "1", ":", "]", "\n", "w_x_enc", "=", "tf", ".", "transpose", "(", "w_x_enc", ",", "[", "1", ",", "0", ",", "2", ",", "3", "]", ")", "\n", "w_x_enc", "=", "tf", ".", "reshape", "(", "w_x_enc", ",", "\n", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "w_x_enc", ")", "[", ":", "2", "]", ",", "[", "-", "1", "]", "]", ",", "-", "1", ")", ")", "\n", "\n", "w_x_h_ta", "=", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"w_x_h_array\"", ")", "\n", "w_x_ctx_ta", "=", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"w_x_ctx_array\"", ")", "\n", "\n", "initial_state_linear", "=", "lrp", ".", "linear_v2n", "(", "initial_state", ",", "output_size", ",", "True", ",", "\n", "[", "w_x_bw_ta", ".", "read", "(", "0", ")", "]", ",", "params", ",", "\n", "False", ",", "scope", "=", "\"s_transform\"", ",", "\n", "d2", "=", "True", ")", "\n", "initial_state", "=", "initial_state_linear", "[", "\"output\"", "]", "\n", "w_initial", "=", "initial_state_linear", "[", "\"weight_ratios\"", "]", "[", "0", "]", "\n", "initial_state", "=", "tf", ".", "tanh", "(", "initial_state", ")", "\n", "\n", "def", "loop_func", "(", "t", ",", "out_ta", ",", "att_ta", ",", "val_ta", ",", "state", ",", "cache_key", ",", "wxh_ta", ",", "\n", "wxc_ta", ",", "w_x_h_last", ")", ":", "\n", "# now state", "\n", "            ", "wxh_ta", "=", "wxh_ta", ".", "write", "(", "t", ",", "w_x_h_last", ")", "\n", "inp_t", "=", "input_ta", ".", "read", "(", "t", ")", "\n", "results", "=", "layers", ".", "attention", ".", "attention", "(", "state", ",", "memory", ",", "bias", ",", "\n", "output_size", ",", "\n", "cache", "=", "{", "\"key\"", ":", "cache_key", "}", ")", "\n", "alpha", "=", "results", "[", "\"weight\"", "]", "\n", "context", "=", "results", "[", "\"value\"", "]", "\n", "\n", "att", "=", "tf", ".", "expand_dims", "(", "alpha", ",", "1", ")", "\n", "\n", "wr_att", "=", "tf", ".", "expand_dims", "(", "att", ",", "-", "1", ")", "*", "tf", ".", "expand_dims", "(", "memory", ",", "1", ")", "\n", "wr_att", "=", "tf", ".", "squeeze", "(", "wr_att", ",", "1", ")", "\n", "result_stab", "=", "stabilize", "(", "context", ",", "params", ".", "stab", ")", "\n", "wr_att", "/=", "tf", ".", "expand_dims", "(", "result_stab", ",", "1", ")", "\n", "len_src", "=", "tf", ".", "shape", "(", "wr_att", ")", "[", "1", "]", "\n", "w_x_c", "=", "tf", ".", "reshape", "(", "w_x_enc", ",", "[", "1", ",", "len_src", ",", "len_src", ",", "-", "1", "]", ")", "*", "wr_att", "\n", "w_x_c", "=", "tf", ".", "reduce_sum", "(", "w_x_c", ",", "2", ")", "\n", "\n", "#w_x_c = tf.matmul(att, w_x_enc)", "\n", "w_x_c", "=", "tf", ".", "reshape", "(", "w_x_c", ",", "w_x_c_shape", ")", "\n", "wxc_ta", "=", "wxc_ta", ".", "write", "(", "t", ",", "w_x_c", ")", "\n", "\n", "# next state", "\n", "cell_input", "=", "[", "inp_t", ",", "context", "]", "\n", "cell_output", ",", "new_state", ",", "w_x_h_new", "=", "cell", "(", "cell_input", ",", "state", ",", "\n", "w_x_h_last", ",", "w_x_c", ",", "params", ")", "\n", "cell_output", "=", "_copy_through", "(", "t", ",", "sequence_length", "[", "\"target\"", "]", ",", "\n", "zero_output", ",", "cell_output", ")", "\n", "new_state", "=", "_copy_through", "(", "t", ",", "sequence_length", "[", "\"target\"", "]", ",", "state", ",", "\n", "new_state", ")", "\n", "new_value", "=", "_copy_through", "(", "t", ",", "sequence_length", "[", "\"target\"", "]", ",", "zero_value", ",", "\n", "context", ")", "\n", "w_x_h_new", "=", "_copy_through", "(", "t", ",", "sequence_length", "[", "\"target\"", "]", ",", "w_x_h_last", ",", "\n", "w_x_h_new", ")", "\n", "\n", "out_ta", "=", "out_ta", ".", "write", "(", "t", ",", "cell_output", ")", "\n", "att_ta", "=", "att_ta", ".", "write", "(", "t", ",", "alpha", ")", "\n", "val_ta", "=", "val_ta", ".", "write", "(", "t", ",", "new_value", ")", "\n", "cache_key", "=", "tf", ".", "identity", "(", "cache_key", ")", "\n", "\n", "return", "t", "+", "1", ",", "out_ta", ",", "att_ta", ",", "val_ta", ",", "new_state", ",", "cache_key", ",", "wxh_ta", ",", "wxc_ta", ",", "w_x_h_new", "\n", "\n", "", "time", "=", "tf", ".", "constant", "(", "0", ",", "dtype", "=", "tf", ".", "int32", ",", "name", "=", "\"time\"", ")", "\n", "loop_vars", "=", "(", "time", ",", "output_ta", ",", "alpha_ta", ",", "value_ta", ",", "initial_state", ",", "\n", "cache", "[", "\"key\"", "]", ",", "w_x_h_ta", ",", "w_x_ctx_ta", ",", "w_initial", ")", "\n", "\n", "outputs", "=", "tf", ".", "while_loop", "(", "lambda", "t", ",", "*", "_", ":", "t", "<", "time_steps", ",", "\n", "loop_func", ",", "loop_vars", ",", "\n", "parallel_iterations", "=", "32", ",", "\n", "swap_memory", "=", "True", ")", "\n", "\n", "output_final_ta", "=", "outputs", "[", "1", "]", "\n", "value_final_ta", "=", "outputs", "[", "3", "]", "\n", "\n", "final_output", "=", "output_final_ta", ".", "stack", "(", ")", "\n", "final_output", ".", "set_shape", "(", "[", "None", ",", "None", ",", "output_size", "]", ")", "\n", "final_output", "=", "tf", ".", "transpose", "(", "final_output", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "final_value", "=", "value_final_ta", ".", "stack", "(", ")", "\n", "final_value", ".", "set_shape", "(", "[", "None", ",", "None", ",", "memory", ".", "shape", "[", "-", "1", "]", ".", "value", "]", ")", "\n", "final_value", "=", "tf", ".", "transpose", "(", "final_value", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "w_x_h_final_ta", "=", "outputs", "[", "6", "]", "\n", "w_x_h_final", "=", "w_x_h_final_ta", ".", "stack", "(", ")", "\n", "w_x_c_final_ta", "=", "outputs", "[", "7", "]", "\n", "w_x_c_final", "=", "w_x_c_final_ta", ".", "stack", "(", ")", "\n", "\n", "result", "=", "{", "\n", "\"outputs\"", ":", "final_output", ",", "\n", "\"values\"", ":", "final_value", ",", "\n", "\"initial_state\"", ":", "initial_state", ",", "\n", "\"weight_ratios\"", ":", "[", "w_x_h_final", ",", "w_x_c_final", ",", "w_initial", "]", "\n", "}", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.model_graph": [[272, 444], ["len", "len", "tensorflow.nn.bias_add", "tensorflow.nn.bias_add", "thumt.LegacyGRUCell_encoder_v2n", "thumt.LegacyGRUCell_encoder_v2n", "rnnsearch_lrp._encoder", "tensorflow.concat", "thumt.LegacyGRUCell_decoder_v2n", "rnnsearch_lrp._decoder", "tensorflow.pad", "tensorflow.concat", "thumt.maxout_v2n", "tensorflow.transpose", "thumt.linear_v2n", "thumt.linear_v2n", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.range", "tensorflow.cast", "tensorflow.reshape", "tensorflow.concat", "tensorflow.transpose", "tensorflow.gather_nd", "tensorflow.reshape", "thumt.smoothed_softmax_cross_entropy_with_logits", "tensorflow.reshape", "tensorflow.to_float", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.rnn_cell.DropoutWrapper", "tensorflow.nn.rnn_cell.DropoutWrapper", "tensorflow.nn.rnn_cell.DropoutWrapper", "thumt.nn.maxout", "thumt.nn.linear", "thumt.nn.linear", "tensorflow.nn.dropout", "tensorflow.shape", "tensorflow.shape", "tensorflow.sequence_mask", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._encoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp._decoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.maxout_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.linear_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.linear_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.losses.losses.smoothed_softmax_cross_entropy_with_logits", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.maxout", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear"], ["", "def", "model_graph", "(", "features", ",", "labels", ",", "params", ")", ":", "\n", "    ", "src_vocab_size", "=", "len", "(", "params", ".", "vocabulary", "[", "\"source\"", "]", ")", "\n", "tgt_vocab_size", "=", "len", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"source_embedding\"", ")", ":", "\n", "        ", "src_emb", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ",", "\n", "[", "src_vocab_size", ",", "params", ".", "embedding_size", "]", ")", "\n", "src_bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "params", ".", "embedding_size", "]", ")", "\n", "src_inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "src_emb", ",", "features", "[", "\"source\"", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"target_embedding\"", ")", ":", "\n", "        ", "tgt_emb", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ",", "\n", "[", "tgt_vocab_size", ",", "params", ".", "embedding_size", "]", ")", "\n", "tgt_bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "params", ".", "embedding_size", "]", ")", "\n", "tgt_inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "tgt_emb", ",", "features", "[", "\"target\"", "]", ")", "\n", "\n", "", "src_inputs", "=", "tf", ".", "nn", ".", "bias_add", "(", "src_inputs", ",", "src_bias", ")", "\n", "tgt_inputs", "=", "tf", ".", "nn", ".", "bias_add", "(", "tgt_inputs", ",", "tgt_bias", ")", "\n", "\n", "if", "params", ".", "dropout", "and", "not", "params", ".", "use_variational_dropout", ":", "\n", "        ", "src_inputs", "=", "tf", ".", "nn", ".", "dropout", "(", "src_inputs", ",", "1.0", "-", "params", ".", "dropout", ")", "\n", "tgt_inputs", "=", "tf", ".", "nn", ".", "dropout", "(", "tgt_inputs", ",", "1.0", "-", "params", ".", "dropout", ")", "\n", "\n", "# encoder", "\n", "", "cell_fw", "=", "lrp", ".", "LegacyGRUCell_encoder_v2n", "(", "params", ".", "hidden_size", ")", "\n", "cell_bw", "=", "lrp", ".", "LegacyGRUCell_encoder_v2n", "(", "params", ".", "hidden_size", ")", "\n", "\n", "if", "params", ".", "use_variational_dropout", ":", "\n", "        ", "cell_fw", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell_fw", ",", "\n", "input_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "output_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "state_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "variational_recurrent", "=", "True", ",", "\n", "input_size", "=", "params", ".", "embedding_size", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "cell_bw", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell_bw", ",", "\n", "input_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "output_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "state_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "variational_recurrent", "=", "True", ",", "\n", "input_size", "=", "params", ".", "embedding_size", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "\n", "", "encoder_output", "=", "_encoder", "(", "cell_fw", ",", "cell_bw", ",", "src_inputs", ",", "\n", "features", "[", "\"source_length\"", "]", ",", "params", ")", "\n", "\n", "w_x_h_fw", ",", "w_x_h_bw", "=", "encoder_output", "[", "\"weight_ratios\"", "]", "\n", "w_x_h_bw", "=", "w_x_h_bw", "[", ":", ":", "-", "1", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "w_x_enc", "=", "tf", ".", "concat", "(", "[", "w_x_h_fw", ",", "w_x_h_bw", "]", ",", "-", "1", ")", "\n", "\n", "# decoder", "\n", "cell", "=", "lrp", ".", "LegacyGRUCell_decoder_v2n", "(", "params", ".", "hidden_size", ")", "\n", "\n", "if", "params", ".", "use_variational_dropout", ":", "\n", "        ", "cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell", ",", "\n", "input_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "output_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "state_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "variational_recurrent", "=", "True", ",", "\n", "# input + context", "\n", "input_size", "=", "params", ".", "embedding_size", "+", "2", "*", "params", ".", "hidden_size", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "\n", "", "length", "=", "{", "\n", "\"source\"", ":", "features", "[", "\"source_length\"", "]", ",", "\n", "\"target\"", ":", "features", "[", "\"target_length\"", "]", "\n", "}", "\n", "initial_state", "=", "encoder_output", "[", "\"final_states\"", "]", "[", "\"backward\"", "]", "\n", "decoder_output", "=", "_decoder", "(", "cell", ",", "tgt_inputs", ",", "encoder_output", "[", "\"annotation\"", "]", ",", "\n", "length", ",", "initial_state", ",", "w_x_enc", ",", "w_x_h_bw", ",", "params", ")", "\n", "\n", "w_x_dec", ",", "w_x_ctx", ",", "w_x_init", "=", "decoder_output", "[", "\"weight_ratios\"", "]", "\n", "\n", "# Shift left", "\n", "shifted_tgt_inputs", "=", "tf", ".", "pad", "(", "tgt_inputs", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "shifted_tgt_inputs", "=", "shifted_tgt_inputs", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "\n", "all_outputs", "=", "tf", ".", "concat", "(", "\n", "[", "\n", "tf", ".", "expand_dims", "(", "decoder_output", "[", "\"initial_state\"", "]", ",", "axis", "=", "1", ")", ",", "\n", "decoder_output", "[", "\"outputs\"", "]", ",", "\n", "]", ",", "\n", "axis", "=", "1", "\n", ")", "\n", "shifted_outputs", "=", "all_outputs", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "\n", "maxout_features", "=", "[", "\n", "shifted_tgt_inputs", ",", "\n", "shifted_outputs", ",", "\n", "decoder_output", "[", "\"values\"", "]", "\n", "]", "\n", "maxout_size", "=", "params", ".", "hidden_size", "//", "params", ".", "maxnum", "\n", "\n", "if", "labels", "is", "None", ":", "\n", "# Special case for non-incremental decoding", "\n", "        ", "maxout_features", "=", "[", "\n", "shifted_tgt_inputs", "[", ":", ",", "-", "1", ",", ":", "]", ",", "\n", "shifted_outputs", "[", ":", ",", "-", "1", ",", ":", "]", ",", "\n", "decoder_output", "[", "\"values\"", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "]", "\n", "maxhid", "=", "layers", ".", "nn", ".", "maxout", "(", "maxout_features", ",", "maxout_size", ",", "params", ".", "maxnum", ",", "\n", "params", ",", "concat", "=", "False", ")", "\n", "\n", "readout", "=", "layers", ".", "nn", ".", "linear", "(", "maxhid", ",", "params", ".", "embedding_size", ",", "False", ",", "\n", "False", ",", "scope", "=", "\"deepout\"", ")", "\n", "\n", "# Prediction", "\n", "logits", "=", "layers", ".", "nn", ".", "linear", "(", "readout", ",", "tgt_vocab_size", ",", "True", ",", "False", ",", "\n", "scope", "=", "\"softmax\"", ")", "\n", "\n", "return", "logits", "\n", "\n", "", "maxhid_maxout", "=", "lrp", ".", "maxout_v2n", "(", "maxout_features", ",", "maxout_size", ",", "params", ".", "maxnum", ",", "\n", "[", "w_x_dec", ",", "w_x_ctx", "]", ",", "params", ",", "concat", "=", "False", ")", "\n", "maxhid", "=", "maxhid_maxout", "[", "\"output\"", "]", "\n", "w_x_maxout", "=", "maxhid_maxout", "[", "\"weight_ratios\"", "]", "[", "0", "]", "\n", "w_x_maxout", "=", "tf", ".", "transpose", "(", "w_x_maxout", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "readout", "=", "lrp", ".", "linear_v2n", "(", "maxhid", ",", "params", ".", "embedding_size", ",", "False", ",", "\n", "[", "w_x_maxout", "]", ",", "params", ",", "False", ",", "scope", "=", "\"deepout\"", ")", "\n", "w_x_readout", "=", "readout", "[", "\"weight_ratios\"", "]", "[", "0", "]", "\n", "readout", "=", "readout", "[", "\"output\"", "]", "\n", "\n", "if", "params", ".", "dropout", "and", "not", "params", ".", "use_variational_dropout", ":", "\n", "        ", "readout", "=", "tf", ".", "nn", ".", "dropout", "(", "readout", ",", "1.0", "-", "params", ".", "dropout", ")", "\n", "\n", "# Prediction and final relevance", "\n", "", "logits", "=", "lrp", ".", "linear_v2n", "(", "readout", ",", "tgt_vocab_size", ",", "True", ",", "[", "w_x_readout", "]", ",", "\n", "params", ",", "False", ",", "scope", "=", "\"softmax\"", ")", "\n", "w_x_true", "=", "logits", "[", "\"weight_ratios\"", "]", "[", "0", "]", "\n", "logits", "=", "logits", "[", "\"output\"", "]", "\n", "logits", "=", "tf", ".", "reshape", "(", "logits", ",", "[", "-", "1", ",", "tgt_vocab_size", "]", ")", "\n", "w_x_true", "=", "tf", ".", "transpose", "(", "w_x_true", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "w_x_true", "=", "tf", ".", "reshape", "(", "w_x_true", ",", "[", "-", "1", ",", "tf", ".", "shape", "(", "w_x_true", ")", "[", "-", "2", "]", ",", "\n", "tf", ".", "shape", "(", "w_x_true", ")", "[", "-", "1", "]", "]", ")", "\n", "w_x_true", "=", "tf", ".", "transpose", "(", "w_x_true", ",", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "labels_lrp", "=", "labels", "\n", "bs", "=", "tf", ".", "shape", "(", "labels_lrp", ")", "[", "0", "]", "\n", "idx", "=", "tf", ".", "range", "(", "tf", ".", "shape", "(", "labels_lrp", ")", "[", "-", "1", "]", ")", "\n", "idx", "=", "tf", ".", "cast", "(", "idx", ",", "tf", ".", "int64", ")", "\n", "idx", "=", "tf", ".", "reshape", "(", "idx", ",", "[", "1", ",", "-", "1", "]", ")", "\n", "labels_lrp", "=", "tf", ".", "concat", "(", "[", "idx", ",", "labels_lrp", "]", ",", "axis", "=", "0", ")", "\n", "labels_lrp", "=", "tf", ".", "transpose", "(", "labels_lrp", ",", "[", "1", ",", "0", "]", ")", "\n", "w_x_true", "=", "tf", ".", "gather_nd", "(", "w_x_true", ",", "labels_lrp", ")", "\n", "w_x_true", "=", "tf", ".", "reshape", "(", "w_x_true", ",", "[", "bs", ",", "-", "1", ",", "tf", ".", "shape", "(", "w_x_true", ")", "[", "-", "1", "]", "]", ")", "\n", "\n", "ce", "=", "losses", ".", "smoothed_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "\n", "labels", "=", "labels", ",", "\n", "smoothing", "=", "params", ".", "label_smoothing", ",", "\n", "normalize", "=", "True", "\n", ")", "\n", "\n", "ce", "=", "tf", ".", "reshape", "(", "ce", ",", "tf", ".", "shape", "(", "labels", ")", ")", "\n", "tgt_mask", "=", "tf", ".", "to_float", "(", "\n", "tf", ".", "sequence_mask", "(", "\n", "features", "[", "\"target_length\"", "]", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", "\n", ")", "\n", ")", "\n", "\n", "rlv_info", "=", "{", "}", "\n", "rlv_info", "[", "\"result\"", "]", "=", "w_x_true", "\n", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ")", "/", "tf", ".", "reduce_sum", "(", "tgt_mask", ")", "\n", "\n", "return", "loss", ",", "rlv_info", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.Contextual_Transformer.__init__": [[625, 627], ["thumt.NMTModel.__init__"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.train_word2vec.MySentences.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "scope", "=", "\"transformer\"", ")", ":", "\n", "        ", "super", "(", "Contextual_Transformer", ",", "self", ")", ".", "__init__", "(", "params", "=", "params", ",", "scope", "=", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.Contextual_Transformer.get_training_func": [[628, 641], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "contextual_transformer.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_training_func", "(", "self", ",", "initializer", ")", ":", "\n", "        ", "def", "training_fn", "(", "features", ",", "params", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ",", "initializer", "=", "initializer", ",", "\n", "reuse", "=", "reuse", ")", ":", "\n", "                ", "loss", "=", "model_graph", "(", "features", ",", "\"train\"", ",", "params", ")", "\n", "return", "loss", "\n", "\n", "", "", "return", "training_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.Contextual_Transformer.get_evaluation_func": [[642, 655], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "contextual_transformer.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_evaluation_func", "(", "self", ")", ":", "\n", "        ", "def", "evaluation_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "score", "=", "model_graph", "(", "features", ",", "\"eval\"", ",", "params", ")", "\n", "\n", "", "return", "score", "\n", "\n", "", "return", "evaluation_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.Contextual_Transformer.get_inference_func": [[656, 693], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "contextual_transformer.encoding_graph", "copy.copy", "copy.copy", "tensorflow.variable_scope", "contextual_transformer.decoding_graph", "tensorflow.shape", "tensorflow.zeros", "tensorflow.zeros", "range"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.encoding_graph", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.decoding_graph"], ["", "def", "get_inference_func", "(", "self", ")", ":", "\n", "        ", "def", "encoding_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "context_output", ",", "encoder_output", "=", "encoding_graph", "(", "features", ",", "\"infer\"", ",", "params", ")", "\n", "batch", "=", "tf", ".", "shape", "(", "encoder_output", ")", "[", "0", "]", "\n", "\n", "state", "=", "{", "\n", "\"encoder\"", ":", "encoder_output", ",", "\n", "\"context\"", ":", "context_output", ",", "\n", "\"decoder\"", ":", "{", "\n", "\"layer_%d\"", "%", "i", ":", "{", "\n", "\"key\"", ":", "tf", ".", "zeros", "(", "[", "batch", ",", "0", ",", "params", ".", "hidden_size", "]", ")", ",", "\n", "\"value\"", ":", "tf", ".", "zeros", "(", "[", "batch", ",", "0", ",", "params", ".", "hidden_size", "]", ")", "\n", "}", "\n", "for", "i", "in", "range", "(", "params", ".", "num_decoder_layers", ")", "\n", "}", "\n", "}", "\n", "", "return", "state", "\n", "\n", "", "def", "decoding_fn", "(", "features", ",", "state", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "log_prob", ",", "new_state", "=", "decoding_graph", "(", "features", ",", "state", ",", "\"infer\"", ",", "\n", "params", ")", "\n", "\n", "", "return", "log_prob", ",", "new_state", "\n", "\n", "", "return", "encoding_fn", ",", "decoding_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.Contextual_Transformer.get_name": [[694, 697], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_name", "(", ")", ":", "\n", "        ", "return", "\"transformer\"", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.Contextual_Transformer.get_parameters": [[698, 746], ["tensorflow.contrib.training.HParams"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_parameters", "(", ")", ":", "\n", "        ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "bos", "=", "\"<eos>\"", ",", "\n", "eos", "=", "\"<eos>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "is_training", "=", "False", ",", "\n", "append_eos", "=", "False", ",", "\n", "decode_length", "=", "50", ",", "\n", "latent_dim", "=", "16", ",", "\n", "num_units", "=", "512", ",", "\n", "hidden_size", "=", "512", ",", "\n", "filter_size", "=", "2048", ",", "\n", "num_heads", "=", "8", ",", "\n", "num_encoder_layers", "=", "6", ",", "\n", "num_decoder_layers", "=", "6", ",", "\n", "attention_dropout", "=", "0.0", ",", "\n", "residual_dropout", "=", "0.1", ",", "\n", "relu_dropout", "=", "0.0", ",", "\n", "label_smoothing", "=", "0.1", ",", "\n", "attention_key_channels", "=", "0", ",", "\n", "attention_value_channels", "=", "0", ",", "\n", "multiply_embedding_mode", "=", "\"sqrt_depth\"", ",", "\n", "shared_embedding_and_softmax_weights", "=", "False", ",", "\n", "shared_source_target_embedding", "=", "False", ",", "\n", "# contextual ", "\n", "context_encoder_attention", "=", "False", ",", "\n", "context_decoder_attention", "=", "False", ",", "\n", "context_gating", "=", "False", ",", "\n", "context_representation", "=", "\"self_attention\"", ",", "\n", "num_context_layers", "=", "6", ",", "\n", "# Override default parameters", "\n", "learning_rate_decay", "=", "\"linear_warmup_rsqrt_decay\"", ",", "\n", "initializer", "=", "\"uniform_unit_scaling\"", ",", "\n", "initializer_gain", "=", "1.0", ",", "\n", "learning_rate", "=", "0.1", ",", "\n", "layer_preprocess", "=", "\"none\"", ",", "\n", "layer_postprocess", "=", "\"layer_norm\"", ",", "\n", "batch_size", "=", "4096", ",", "\n", "constant_batch_size", "=", "False", ",", "\n", "adam_beta1", "=", "0.9", ",", "\n", "adam_beta2", "=", "0.98", ",", "\n", "adam_epsilon", "=", "1e-9", ",", "\n", "clip_grad_norm", "=", "0.0", "\n", ")", "\n", "\n", "return", "params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process": [[16, 23], ["thumt.nn.layer_norm", "ValueError"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.layer_norm"], ["def", "_layer_process", "(", "x", ",", "mode", ",", "trainable", "=", "True", ")", ":", "\n", "    ", "if", "not", "mode", "or", "mode", "==", "\"none\"", ":", "\n", "        ", "return", "x", "\n", "", "elif", "mode", "==", "\"layer_norm\"", ":", "\n", "        ", "return", "layers", ".", "nn", ".", "layer_norm", "(", "x", ",", "trainable", "=", "trainable", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown mode %s\"", "%", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn": [[25, 29], ["tensorflow.nn.dropout"], "function", ["None"], ["", "", "def", "_residual_fn", "(", "x", ",", "y", ",", "keep_prob", "=", "None", ")", ":", "\n", "    ", "if", "keep_prob", "and", "keep_prob", "<", "1.0", ":", "\n", "        ", "y", "=", "tf", ".", "nn", ".", "dropout", "(", "y", ",", "keep_prob", ")", "\n", "", "return", "x", "+", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_gating_fn": [[30, 39], ["tensorflow.sigmoid", "tensorflow.variable_scope", "thumt.nn.linear", "tensorflow.variable_scope", "thumt.nn.linear"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear"], ["", "def", "_residual_gating_fn", "(", "x", ",", "y", ",", "hidden_size", ",", "keep_prob", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"gating_x\"", ")", ":", "\n", "        ", "gating_x", "=", "layers", ".", "nn", ".", "linear", "(", "x", ",", "hidden_size", ",", "False", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"gating_y\"", ")", ":", "\n", "        ", "gating_y", "=", "layers", ".", "nn", ".", "linear", "(", "y", ",", "hidden_size", ",", "False", ")", "\n", "", "gate", "=", "tf", ".", "sigmoid", "(", "gating_x", "+", "gating_y", ")", "\n", "#if keep_prob and keep_prob < 1.0:", "\n", "#    y = tf.nn.dropout(y, keep_prob)", "\n", "return", "gate", "*", "x", "+", "(", "1", "-", "gate", ")", "*", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._ffn_layer": [[40, 55], ["tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.nn.linear", "tensorflow.nn.relu", "tensorflow.nn.dropout", "tensorflow.variable_scope", "thumt.nn.linear"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.linear"], ["", "def", "_ffn_layer", "(", "inputs", ",", "hidden_size", ",", "output_size", ",", "keep_prob", "=", "None", ",", "\n", "dtype", "=", "None", ",", "scope", "=", "None", ",", "trainable", "=", "True", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"ffn_layer\"", ",", "values", "=", "[", "inputs", "]", ",", "\n", "dtype", "=", "dtype", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"input_layer\"", ")", ":", "\n", "            ", "hidden", "=", "layers", ".", "nn", ".", "linear", "(", "inputs", ",", "hidden_size", ",", "True", ",", "True", ",", "trainable", "=", "trainable", ")", "\n", "hidden", "=", "tf", ".", "nn", ".", "relu", "(", "hidden", ")", "\n", "\n", "", "if", "keep_prob", "and", "keep_prob", "<", "1.0", ":", "\n", "            ", "hidden", "=", "tf", ".", "nn", ".", "dropout", "(", "hidden", ",", "keep_prob", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"output_layer\"", ")", ":", "\n", "            ", "output", "=", "layers", ".", "nn", ".", "linear", "(", "hidden", ",", "output_size", ",", "True", ",", "True", ",", "trainable", "=", "trainable", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.birnn": [[56, 63], ["tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.concat"], "function", ["None"], ["", "", "def", "birnn", "(", "inputs", ",", "sequence_length", ",", "params", ")", ":", "\n", "    ", "lstm_fw_cell", "=", "rnn", ".", "BasicLSTMCell", "(", "params", ".", "hidden_size", ")", "\n", "lstm_bw_cell", "=", "rnn", ".", "BasicLSTMCell", "(", "params", ".", "hidden_size", ")", "\n", "outputs", ",", "states", "=", "tf", ".", "nn", ".", "bidirectional_dynamic_rnn", "(", "lstm_fw_cell", ",", "lstm_bw_cell", ",", "inputs", ",", "\n", "sequence_length", "=", "sequence_length", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "states_fw", ",", "states_bw", "=", "outputs", "\n", "return", "tf", ".", "concat", "(", "[", "states_fw", ",", "states_bw", "]", ",", "axis", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.sample_gaussian": [[64, 69], ["tensorflow.random_normal", "tensorflow.exp", "tensorflow.shape", "tensorflow.multiply"], "function", ["None"], ["", "def", "sample_gaussian", "(", "mu", ",", "logvar", ")", ":", "\n", "    ", "epsilon", "=", "tf", ".", "random_normal", "(", "tf", ".", "shape", "(", "logvar", ")", ",", "name", "=", "\"epsilon\"", ")", "\n", "std", "=", "tf", ".", "exp", "(", "0.5", "*", "logvar", ")", "\n", "z", "=", "mu", "+", "tf", ".", "multiply", "(", "std", ",", "epsilon", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.gaussian_kld": [[70, 75], ["tensorflow.reduce_sum", "tensorflow.div", "tensorflow.div", "tensorflow.exp", "tensorflow.exp", "tensorflow.pow", "tensorflow.exp"], "function", ["None"], ["", "def", "gaussian_kld", "(", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ")", ":", "\n", "    ", "kld", "=", "-", "0.5", "*", "tf", ".", "reduce_sum", "(", "1", "+", "(", "recog_logvar", "-", "prior_logvar", ")", "\n", "-", "tf", ".", "div", "(", "tf", ".", "pow", "(", "prior_mu", "-", "recog_mu", ",", "2", ")", ",", "tf", ".", "exp", "(", "prior_logvar", ")", ")", "\n", "-", "tf", ".", "div", "(", "tf", ".", "exp", "(", "recog_logvar", ")", ",", "tf", ".", "exp", "(", "prior_logvar", ")", ")", ",", "reduction_indices", "=", "1", ")", "\n", "return", "kld", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.gelu": [[76, 87], ["tensorflow.erf", "tensorflow.sqrt"], "function", ["None"], ["", "def", "gelu", "(", "input_tensor", ")", ":", "\n", "  ", "\"\"\"Gaussian Error Linear Unit.\n  This is a smoother version of the RELU.\n  Original paper: https://arxiv.org/abs/1606.08415\n  Args:\n    input_tensor: float Tensor to perform activation.\n  Returns:\n    `input_tensor` with the GELU activation applied.\n  \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "erf", "(", "input_tensor", "/", "tf", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "return", "input_tensor", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.w_encoder_attention": [[88, 151], ["tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.where", "tensorflow.nn.softmax", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.layers.dense", "tensorflow.layers.dropout", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.sequence_mask", "tensorflow.reshape", "tensorflow.ones_like", "tensorflow.equal", "tensorflow.reshape", "int", "tensorflow.tile", "tensorflow.tile", "int", "tensorflow.reduce_sum", "tensorflow.convert_to_tensor", "queries.get_shape", "tensorflow.shape", "tensorflow.shape", "tf.layers.dense.get_shape().as_list", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.expand_dims", "tf.layers.dense.get_shape"], "function", ["None"], ["", "def", "w_encoder_attention", "(", "queries", ",", "\n", "keys", ",", "\n", "sequence_length", ",", "\n", "num_units", "=", "None", ",", "\n", "num_heads", "=", "8", ",", "\n", "dropout_rate", "=", "0", ",", "\n", "is_training", "=", "True", ",", "\n", "using_mask", "=", "False", ",", "\n", "mymasks", "=", "None", ",", "\n", "scope", "=", "\"w_encoder_attention\"", ",", "\n", "reuse", "=", "None", ")", ":", "\n", "    ", "'''Applies multihead attention.\n\n    Args:\n      queries: A 3d tensor with shape of [N, T_q, C_q].\n      keys: A 3d tensor with shape of [N, T_k, C_k].\n      num_units: A scalar. Attention size.\n      dropout_rate: A floating point number.\n      is_training: Boolean. Controller of mechanism for dropout.\n      causality: Boolean. If true, units that reference the future are masked.\n      num_heads: An int. Number of heads.\n      scope: Optional scope for `variable_scope`.\n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n\n    Returns\n      A 3d tensor with shape of (N, T_q, C)\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "# Set the fall back option for num_units", "\n", "# print(queries)", "\n", "# print(queries.get_shape().as_list)", "\n", "        ", "if", "num_units", "is", "None", ":", "\n", "            ", "num_units", "=", "queries", ".", "get_shape", "(", ")", ".", "as_list", "[", "-", "1", "]", "\n", "# Linear projections", "\n", "\n", "", "Q", "=", "tf", ".", "layers", ".", "dense", "(", "queries", ",", "num_units", ",", "activation", "=", "None", ",", "use_bias", "=", "False", ")", "# (N, T_q, C)", "\n", "K", "=", "tf", ".", "layers", ".", "dense", "(", "keys", ",", "num_units", ",", "activation", "=", "None", ",", "use_bias", "=", "False", ")", "# (N, T_k, C)", "\n", "V", "=", "tf", ".", "layers", ".", "dense", "(", "keys", ",", "num_units", ",", "activation", "=", "None", ",", "use_bias", "=", "False", ")", "# (N, T_k, C)", "\n", "\n", "x", "=", "K", "*", "Q", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "x", ")", "[", "1", "]", ",", "num_heads", ",", "int", "(", "num_units", "/", "num_heads", ")", "]", ")", "\n", "outputs", "=", "tf", ".", "transpose", "(", "tf", ".", "reduce_sum", "(", "x", ",", "3", ")", ",", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "outputs", "=", "outputs", "/", "(", "K", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "**", "0.5", ")", "\n", "\n", "if", "using_mask", ":", "\n", "            ", "key_masks", "=", "mymasks", "\n", "key_masks", "=", "tf", ".", "reshape", "(", "tf", ".", "tile", "(", "key_masks", ",", "[", "1", ",", "num_heads", "]", ")", ",", "\n", "[", "tf", ".", "shape", "(", "key_masks", ")", "[", "0", "]", ",", "num_heads", ",", "tf", ".", "shape", "(", "key_masks", ")", "[", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "key_masks", "=", "tf", ".", "sequence_mask", "(", "sequence_length", ",", "tf", ".", "shape", "(", "keys", ")", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "key_masks", "=", "tf", ".", "reshape", "(", "tf", ".", "tile", "(", "key_masks", ",", "[", "1", ",", "num_heads", "]", ")", ",", "[", "tf", ".", "shape", "(", "key_masks", ")", "[", "0", "]", ",", "num_heads", ",", "tf", ".", "shape", "(", "key_masks", ")", "[", "1", "]", "]", ")", "\n", "\n", "", "paddings", "=", "tf", ".", "ones_like", "(", "outputs", ")", "*", "(", "-", "2", "**", "32", "+", "1", ")", "\n", "outputs", "=", "tf", ".", "where", "(", "tf", ".", "equal", "(", "key_masks", ",", "0", ")", ",", "paddings", ",", "outputs", ")", "\n", "outputs", "=", "tf", ".", "nn", ".", "softmax", "(", "outputs", ",", "2", ")", "\n", "V_", "=", "tf", ".", "reshape", "(", "V", ",", "[", "tf", ".", "shape", "(", "V", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "V", ")", "[", "1", "]", ",", "num_heads", ",", "int", "(", "num_units", "/", "num_heads", ")", "]", ")", "\n", "V_", "=", "tf", ".", "transpose", "(", "V_", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "outputs", "=", "tf", ".", "layers", ".", "dense", "(", "tf", ".", "reshape", "(", "tf", ".", "reduce_sum", "(", "V_", "*", "tf", ".", "expand_dims", "(", "outputs", ",", "-", "1", ")", ",", "2", ")", ",", "[", "-", "1", ",", "num_units", "]", ")", ",", "\n", "num_units", ",", "activation", "=", "None", ",", "use_bias", "=", "False", ")", "\n", "weight", "=", "outputs", "\n", "outputs", "=", "tf", ".", "layers", ".", "dropout", "(", "outputs", ",", "rate", "=", "dropout_rate", ",", "training", "=", "tf", ".", "convert_to_tensor", "(", "is_training", ")", ")", "\n", "", "return", "outputs", ",", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.transformer_context": [[152, 188], ["tensorflow.variable_scope", "range", "contextual_transformer._layer_process", "tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.attention.multihead_attention", "contextual_transformer._residual_fn", "contextual_transformer._layer_process", "tensorflow.variable_scope", "contextual_transformer._ffn_layer", "contextual_transformer._residual_fn", "contextual_transformer._layer_process", "contextual_transformer._layer_process", "contextual_transformer._layer_process"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multihead_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._ffn_layer", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process"], ["", "def", "transformer_context", "(", "inputs", ",", "bias", ",", "params", ",", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"context_transformer\"", ",", "dtype", "=", "dtype", ",", "\n", "values", "=", "[", "inputs", ",", "bias", "]", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "for", "layer", "in", "range", "(", "params", ".", "num_context_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "layer", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"ctx_self_attention\"", ")", ":", "\n", "                    ", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "None", ",", "\n", "bias", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", "trainable", "=", "True", "\n", ")", "\n", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"feed_forward\"", ")", ":", "\n", "                    ", "y", "=", "_ffn_layer", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "params", ".", "filter_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "relu_dropout", ",", "\n", "trainable", "=", "True", "\n", ")", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "\n", "", "", "", "outputs", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.transformer_encoder": [[189, 249], ["tensorflow.variable_scope", "range", "contextual_transformer._layer_process", "tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.attention.multihead_attention", "contextual_transformer._residual_fn", "contextual_transformer._layer_process", "tensorflow.variable_scope", "contextual_transformer._ffn_layer", "contextual_transformer._residual_fn", "contextual_transformer._layer_process", "contextual_transformer._layer_process", "tensorflow.variable_scope", "thumt.attention.multihead_attention", "contextual_transformer._layer_process", "contextual_transformer._layer_process", "contextual_transformer._residual_gating_fn", "contextual_transformer._layer_process", "contextual_transformer._residual_fn", "contextual_transformer._layer_process"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multihead_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._ffn_layer", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multihead_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_gating_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process"], ["", "", "def", "transformer_encoder", "(", "inputs", ",", "memory_ctx", ",", "bias", ",", "bias_ctx", ",", "params", ",", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"encoder\"", ",", "dtype", "=", "dtype", ",", "\n", "values", "=", "[", "inputs", ",", "bias", "]", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "for", "layer", "in", "range", "(", "params", ".", "num_encoder_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "layer", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"self_attention\"", ")", ":", "\n", "                    ", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "None", ",", "\n", "bias", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", "trainable", "=", "params", ".", "is_training", "\n", ")", "\n", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "params", ".", "is_training", ")", "\n", "\n", "", "if", "params", ".", "context_encoder_attention", ":", "\n", "                    ", "with", "tf", ".", "variable_scope", "(", "\"ctxenc_attention\"", ")", ":", "\n", "                        ", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "memory_ctx", ",", "\n", "bias_ctx", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", "trainable", "=", "True", "\n", ")", "\n", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "\n", "if", "params", ".", "context_gating", ":", "\n", "                            ", "x", "=", "_residual_gating_fn", "(", "x", ",", "y", ",", "params", ".", "hidden_size", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "", "else", ":", "\n", "                            ", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "\n", "\n", "\n", "", "", "", "with", "tf", ".", "variable_scope", "(", "\"feed_forward\"", ")", ":", "\n", "                    ", "y", "=", "_ffn_layer", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "params", ".", "filter_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "relu_dropout", ",", "\n", "trainable", "=", "params", ".", "is_training", "\n", ")", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "params", ".", "is_training", ")", "\n", "\n", "", "", "", "outputs", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.transformer_decoder": [[251, 337], ["tensorflow.variable_scope", "range", "contextual_transformer._layer_process", "tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.attention.multihead_attention", "contextual_transformer._residual_fn", "contextual_transformer._layer_process", "tensorflow.variable_scope", "thumt.attention.multihead_attention", "contextual_transformer._residual_fn", "contextual_transformer._layer_process", "tensorflow.variable_scope", "contextual_transformer._ffn_layer", "contextual_transformer._residual_fn", "contextual_transformer._layer_process", "contextual_transformer._layer_process", "tensorflow.variable_scope", "thumt.attention.multihead_attention", "contextual_transformer._layer_process", "contextual_transformer._layer_process", "contextual_transformer._layer_process", "contextual_transformer._residual_gating_fn", "contextual_transformer._layer_process", "contextual_transformer._residual_fn", "contextual_transformer._layer_process"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multihead_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multihead_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._ffn_layer", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.multihead_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_gating_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer._layer_process"], ["", "", "def", "transformer_decoder", "(", "inputs", ",", "memory", ",", "memory_ctx", ",", "bias", ",", "mem_bias", ",", "bias_ctx", ",", "\n", "params", ",", "state", "=", "None", ",", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"decoder\"", ",", "dtype", "=", "dtype", ",", "\n", "values", "=", "[", "inputs", ",", "memory", ",", "bias", ",", "mem_bias", "]", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "next_state", "=", "{", "}", "\n", "for", "layer", "in", "range", "(", "params", ".", "num_decoder_layers", ")", ":", "\n", "            ", "layer_name", "=", "\"layer_%d\"", "%", "layer", "\n", "with", "tf", ".", "variable_scope", "(", "layer_name", ")", ":", "\n", "                ", "layer_state", "=", "state", "[", "layer_name", "]", "if", "state", "is", "not", "None", "else", "None", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"self_attention\"", ")", ":", "\n", "                    ", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "None", ",", "\n", "bias", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", "state", "=", "layer_state", ",", "\n", "trainable", "=", "params", ".", "is_training", "\n", ")", "\n", "\n", "if", "layer_state", "is", "not", "None", ":", "\n", "                        ", "next_state", "[", "layer_name", "]", "=", "y", "[", "\"state\"", "]", "\n", "\n", "", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "params", ".", "is_training", ")", "\n", "\n", "", "if", "params", ".", "context_decoder_attention", ":", "\n", "                    ", "with", "tf", ".", "variable_scope", "(", "\"ctxdec_attention\"", ")", ":", "\n", "                        ", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "memory_ctx", ",", "\n", "bias_ctx", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", "trainable", "=", "True", "\n", ")", "\n", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "if", "params", ".", "context_gating", ":", "\n", "                            ", "x", "=", "_residual_gating_fn", "(", "x", ",", "y", ",", "params", ".", "hidden_size", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "", "else", ":", "\n", "                            ", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "\n", "", "", "", "with", "tf", ".", "variable_scope", "(", "\"encdec_attention\"", ")", ":", "\n", "                    ", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "memory", ",", "\n", "mem_bias", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", "trainable", "=", "params", ".", "is_training", "\n", ")", "\n", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "params", ".", "is_training", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"feed_forward\"", ")", ":", "\n", "                    ", "y", "=", "_ffn_layer", "(", "\n", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "params", ".", "filter_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "relu_dropout", ",", "\n", "trainable", "=", "params", ".", "is_training", "\n", ")", "\n", "x", "=", "_residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "trainable", "=", "params", ".", "is_training", ")", "\n", "\n", "", "", "", "outputs", "=", "_layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", "\n", "\n", "if", "state", "is", "not", "None", ":", "\n", "            ", "return", "outputs", ",", "next_state", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.encoding_graph": [[339, 425], ["tensorflow.sequence_mask", "tensorflow.sequence_mask", "len", "tensorflow.random_normal_initializer", "tensorflow.get_variable", "print", "print", "tensorflow.nn.bias_add", "thumt.attention.add_timing_signal", "thumt.attention.attention_bias", "tensorflow.get_variable", "tensorflow.get_variable", "print", "tensorflow.nn.bias_add", "thumt.attention.add_timing_signal", "thumt.attention.attention_bias", "contextual_transformer.transformer_context", "tensorflow.gather", "tensorflow.expand_dims", "tensorflow.nn.dropout", "contextual_transformer.transformer_encoder", "contextual_transformer.transformer_encoder", "tensorflow.gather", "tensorflow.expand_dims", "print", "tensorflow.nn.bias_add", "thumt.attention.attention_bias", "tensorflow.shape", "tensorflow.shape", "tensorflow.gather", "tensorflow.expand_dims", "print", "tensorflow.nn.bias_add", "thumt.attention.attention_bias", "contextual_transformer.birnn", "tensorflow.gather", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.add_timing_signal", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.add_timing_signal", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.transformer_context", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.transformer_encoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.transformer_encoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.birnn"], ["", "", "def", "encoding_graph", "(", "features", ",", "mode", ",", "params", ")", ":", "\n", "    ", "if", "mode", "!=", "\"train\"", ":", "\n", "        ", "params", ".", "residual_dropout", "=", "0.0", "\n", "params", ".", "attention_dropout", "=", "0.0", "\n", "params", ".", "relu_dropout", "=", "0.0", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "", "hidden_size", "=", "params", ".", "hidden_size", "\n", "src_seq", "=", "features", "[", "\"source\"", "]", "\n", "ctx_seq", "=", "features", "[", "\"context\"", "]", "\n", "src_len", "=", "features", "[", "\"source_length\"", "]", "\n", "ctx_len", "=", "features", "[", "\"context_length\"", "]", "\n", "src_mask", "=", "tf", ".", "sequence_mask", "(", "src_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "ctx_mask", "=", "tf", ".", "sequence_mask", "(", "ctx_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"context\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "svocab", "=", "params", ".", "vocabulary", "[", "\"source\"", "]", "\n", "src_vocab_size", "=", "len", "(", "svocab", ")", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.0", ",", "params", ".", "hidden_size", "**", "-", "0.5", ")", "\n", "\n", "if", "params", ".", "shared_source_target_embedding", ":", "\n", "        ", "src_embedding", "=", "tf", ".", "get_variable", "(", "\"weights\"", ",", "\n", "[", "src_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ",", "trainable", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "src_embedding", "=", "tf", ".", "get_variable", "(", "\"source_embedding\"", ",", "\n", "[", "src_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ",", "trainable", "=", "False", ")", "\n", "\n", "", "bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "hidden_size", "]", ",", "trainable", "=", "False", ")", "\n", "\n", "## context", "\n", "# ctx_seq: [batch, max_ctx_length]", "\n", "print", "(", "\"building context graph\"", ")", "\n", "if", "params", ".", "context_representation", "==", "\"self_attention\"", ":", "\n", "        ", "print", "(", "'use self attention'", ")", "\n", "ctx_inputs", "=", "tf", ".", "gather", "(", "src_embedding", ",", "ctx_seq", ")", "*", "(", "hidden_size", "**", "0.5", ")", "\n", "ctx_inputs", "=", "ctx_inputs", "*", "tf", ".", "expand_dims", "(", "ctx_mask", ",", "-", "1", ")", "\n", "\n", "context_input", "=", "tf", ".", "nn", ".", "bias_add", "(", "ctx_inputs", ",", "bias", ")", "\n", "context_input", "=", "layers", ".", "attention", ".", "add_timing_signal", "(", "context_input", ")", "\n", "ctx_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "ctx_mask", ",", "\"masking\"", ")", "\n", "\n", "context_output", "=", "transformer_context", "(", "context_input", ",", "ctx_attn_bias", ",", "params", ")", "\n", "", "elif", "params", ".", "context_representation", "==", "\"embedding\"", ":", "\n", "        ", "print", "(", "'use embedding'", ")", "\n", "ctx_inputs", "=", "tf", ".", "gather", "(", "src_embedding", ",", "ctx_seq", ")", "*", "(", "hidden_size", "**", "0.5", ")", "\n", "ctx_inputs", "=", "ctx_inputs", "*", "tf", ".", "expand_dims", "(", "ctx_mask", ",", "-", "1", ")", "\n", "context_input", "=", "tf", ".", "nn", ".", "bias_add", "(", "ctx_inputs", ",", "bias", ")", "\n", "ctx_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "ctx_mask", ",", "\"masking\"", ")", "\n", "context_output", "=", "context_input", "\n", "", "elif", "params", ".", "context_representation", "==", "\"bilstm\"", ":", "\n", "        ", "print", "(", "'use bilstm'", ")", "\n", "ctx_inputs", "=", "tf", ".", "gather", "(", "src_embedding", ",", "ctx_seq", ")", "*", "(", "hidden_size", "**", "0.5", ")", "\n", "ctx_inputs", "=", "ctx_inputs", "*", "tf", ".", "expand_dims", "(", "ctx_mask", ",", "-", "1", ")", "\n", "context_input", "=", "tf", ".", "nn", ".", "bias_add", "(", "ctx_inputs", ",", "bias", ")", "\n", "ctx_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "ctx_mask", ",", "\"masking\"", ")", "\n", "context_output", "=", "birnn", "(", "context_input", ",", "ctx_len", ",", "params", ")", "\n", "\n", "\n", "## encoder", "\n", "\n", "# id => embedding", "\n", "# src_seq: [batch, max_src_length]", "\n", "", "print", "(", "\"building encoder graph\"", ")", "\n", "inputs", "=", "tf", ".", "gather", "(", "src_embedding", ",", "src_seq", ")", "*", "(", "hidden_size", "**", "0.5", ")", "\n", "inputs", "=", "inputs", "*", "tf", ".", "expand_dims", "(", "src_mask", ",", "-", "1", ")", "\n", "\n", "# Preparing encoder", "\n", "encoder_input", "=", "tf", ".", "nn", ".", "bias_add", "(", "inputs", ",", "bias", ")", "\n", "encoder_input", "=", "layers", ".", "attention", ".", "add_timing_signal", "(", "encoder_input", ")", "\n", "enc_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "src_mask", ",", "\"masking\"", ")", "\n", "\n", "if", "params", ".", "residual_dropout", ":", "\n", "        ", "keep_prob", "=", "1.0", "-", "params", ".", "residual_dropout", "\n", "encoder_input", "=", "tf", ".", "nn", ".", "dropout", "(", "encoder_input", ",", "keep_prob", ")", "\n", "\n", "", "if", "params", ".", "context_encoder_attention", ":", "\n", "        ", "encoder_output", "=", "transformer_encoder", "(", "encoder_input", ",", "context_output", ",", "enc_attn_bias", ",", "ctx_attn_bias", ",", "params", ")", "\n", "", "else", ":", "\n", "        ", "encoder_output", "=", "transformer_encoder", "(", "encoder_input", ",", "None", ",", "enc_attn_bias", ",", "None", ",", "params", ")", "\n", "\n", "", "return", "context_output", ",", "encoder_output", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.decoding_graph": [[427, 610], ["tensorflow.sequence_mask", "tensorflow.sequence_mask", "tensorflow.sequence_mask", "len", "tensorflow.random_normal_initializer", "thumt.attention.attention_bias", "thumt.attention.attention_bias", "thumt.attention.attention_bias", "thumt.attention.add_timing_signal", "tensorflow.get_variable", "tensorflow.reduce_mean", "tensorflow.tile", "tensorflow.concat", "contextual_transformer.w_encoder_attention", "tensorflow.layers.dense", "tensorflow.split", "tensorflow.tile", "tensorflow.concat", "tensorflow.layers.dense", "tensorflow.reshape", "tensorflow.matmul", "thumt.nn.smoothed_softmax_cross_entropy_with_logits", "tensorflow.reshape", "tensorflow.minimum", "contextual_transformer.gaussian_kld", "print", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.gather", "tensorflow.expand_dims", "tensorflow.pad", "tensorflow.nn.dropout", "tensorflow.expand_dims", "tensorflow.layers.dense", "tensorflow.layers.dense", "contextual_transformer.w_encoder_attention", "tensorflow.layers.dense", "tensorflow.split", "contextual_transformer.sample_gaussian", "contextual_transformer.sample_gaussian", "contextual_transformer.transformer_decoder", "tensorflow.concat", "tensorflow.layers.dense", "tensorflow.matmul", "tensorflow.nn.log_softmax", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.shape", "contextual_transformer.transformer_decoder", "contextual_transformer.transformer_decoder", "tensorflow.reduce_sum", "tensorflow.to_float", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.get_variable_scope", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.add_timing_signal", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.w_encoder_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.losses.losses.smoothed_softmax_cross_entropy_with_logits", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.gaussian_kld", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.w_encoder_attention", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.sample_gaussian", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.sample_gaussian", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.transformer_decoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.transformer_decoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.transformer_decoder"], ["", "def", "decoding_graph", "(", "features", ",", "state", ",", "mode", ",", "params", ")", ":", "\n", "    ", "if", "mode", "!=", "\"train\"", ":", "\n", "        ", "params", ".", "residual_dropout", "=", "0.0", "\n", "params", ".", "attention_dropout", "=", "0.0", "\n", "params", ".", "relu_dropout", "=", "0.0", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "is_training", "=", "False", "\n", "", "else", ":", "\n", "        ", "is_training", "=", "True", "\n", "\n", "", "tgt_seq", "=", "features", "[", "\"target\"", "]", "\n", "src_len", "=", "features", "[", "\"source_length\"", "]", "\n", "tgt_len", "=", "features", "[", "\"target_length\"", "]", "\n", "ctx_len", "=", "features", "[", "\"context_length\"", "]", "\n", "src_mask", "=", "tf", ".", "sequence_mask", "(", "src_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "tgt_mask", "=", "tf", ".", "sequence_mask", "(", "tgt_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "ctx_mask", "=", "tf", ".", "sequence_mask", "(", "ctx_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"context\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "hidden_size", "=", "params", ".", "hidden_size", "\n", "tvocab", "=", "params", ".", "vocabulary", "[", "\"target\"", "]", "\n", "tgt_vocab_size", "=", "len", "(", "tvocab", ")", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.0", ",", "params", ".", "hidden_size", "**", "-", "0.5", ")", "\n", "\n", "if", "params", ".", "shared_source_target_embedding", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "True", ")", ":", "\n", "            ", "tgt_embedding", "=", "tf", ".", "get_variable", "(", "\"weights\"", ",", "\n", "[", "tgt_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ",", "trainable", "=", "False", ")", "\n", "", "", "else", ":", "\n", "        ", "tgt_embedding", "=", "tf", ".", "get_variable", "(", "\"target_embedding\"", ",", "\n", "[", "tgt_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ",", "trainable", "=", "False", ")", "\n", "\n", "", "if", "params", ".", "shared_embedding_and_softmax_weights", ":", "\n", "        ", "weights", "=", "tgt_embedding", "\n", "", "else", ":", "\n", "        ", "weights", "=", "tf", ".", "get_variable", "(", "\"softmax\"", ",", "[", "tgt_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ",", "trainable", "=", "False", ")", "\n", "\n", "# id => embedding", "\n", "# tgt_seq: [batch, max_tgt_length]", "\n", "", "targets", "=", "tf", ".", "gather", "(", "tgt_embedding", ",", "tgt_seq", ")", "*", "(", "hidden_size", "**", "0.5", ")", "\n", "targets", "=", "targets", "*", "tf", ".", "expand_dims", "(", "tgt_mask", ",", "-", "1", ")", "\n", "\n", "# Preparing encoder and decoder input", "\n", "enc_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "src_mask", ",", "\"masking\"", ")", "\n", "ctx_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "ctx_mask", ",", "\"masking\"", ")", "\n", "dec_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "tf", ".", "shape", "(", "targets", ")", "[", "1", "]", ",", "\n", "\"causal\"", ")", "\n", "# Shift left", "\n", "decoder_input", "=", "tf", ".", "pad", "(", "targets", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "decoder_input", "=", "layers", ".", "attention", ".", "add_timing_signal", "(", "decoder_input", ")", "\n", "\n", "if", "params", ".", "residual_dropout", ":", "\n", "        ", "keep_prob", "=", "1.0", "-", "params", ".", "residual_dropout", "\n", "decoder_input", "=", "tf", ".", "nn", ".", "dropout", "(", "decoder_input", ",", "keep_prob", ")", "\n", "\n", "", "encoder_output", "=", "state", "[", "\"encoder\"", "]", "\n", "context_output", "=", "state", "[", "\"context\"", "]", "\n", "latent_sample", "=", "[", "]", "\n", "w_query", "=", "tf", ".", "get_variable", "(", "\"w_Q\"", ",", "[", "1", ",", "params", ".", "num_units", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# cvae", "\n", "#    '''", "\n", "context_rep", "=", "tf", ".", "reduce_mean", "(", "context_output", ",", "-", "2", ")", "\n", "context_rep", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "context_rep", ",", "1", ")", ",", "[", "1", ",", "tf", ".", "shape", "(", "encoder_output", ")", "[", "-", "2", "]", ",", "1", "]", ")", "\n", "encoder_output1", "=", "tf", ".", "concat", "(", "[", "encoder_output", ",", "context_rep", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "prior_encode", ",", "w_", "=", "w_encoder_attention", "(", "w_query", ",", "\n", "tf", ".", "layers", ".", "dense", "(", "encoder_output1", ",", "512", ",", "activation", "=", "tf", ".", "nn", ".", "tanh", ")", ",", "\n", "src_len", ",", "\n", "num_units", "=", "params", ".", "num_units", ",", "\n", "num_heads", "=", "params", ".", "num_heads", ",", "\n", "dropout_rate", "=", "params", ".", "residual_dropout", ",", "\n", "is_training", "=", "is_training", ",", "\n", "mymasks", "=", "src_mask", ",", "\n", "scope", "=", "\"concentrate_attention\"", ",", "\n", "reuse", "=", "tf", ".", "AUTO_REUSE", "\n", ")", "\n", "'''\n    #post_encode = tf.reduce_mean(decoder_output, -2)\n\n    encoder_rep = tf.reduce_mean(encoder_output, -2)\n    context_rep = tf.reduce_mean(context_output, -2)\n    prior_encode = tf.concat([encoder_rep, context_rep], axis=-1)\n    '''", "\n", "prior_mulogvar", "=", "tf", ".", "layers", ".", "dense", "(", "tf", ".", "layers", ".", "dense", "(", "prior_encode", ",", "256", ",", "activation", "=", "tf", ".", "nn", ".", "tanh", ")", ",", "params", ".", "latent_dim", "*", "2", ",", "use_bias", "=", "False", ",", "name", "=", "\"prior_fc\"", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "tf", ".", "split", "(", "prior_mulogvar", ",", "2", ",", "axis", "=", "1", ")", "\n", "\n", "if", "mode", "!=", "\"infer\"", ":", "\n", "        ", "if", "params", ".", "context_decoder_attention", ":", "\n", "            ", "decoder_output", "=", "transformer_decoder", "(", "decoder_input", ",", "encoder_output", ",", "context_output", ",", "\n", "dec_attn_bias", ",", "enc_attn_bias", ",", "ctx_attn_bias", ",", "\n", "params", ")", "\n", "", "else", ":", "\n", "            ", "decoder_output", "=", "transformer_decoder", "(", "decoder_input", ",", "encoder_output", ",", "None", ",", "\n", "dec_attn_bias", ",", "enc_attn_bias", ",", "None", ",", "\n", "params", ")", "\n", "#        '''", "\n", "", "post_encode", ",", "w_", "=", "w_encoder_attention", "(", "w_query", ",", "\n", "decoder_output", ",", "\n", "tgt_len", ",", "\n", "num_units", "=", "params", ".", "num_units", ",", "\n", "num_heads", "=", "params", ".", "num_heads", ",", "\n", "dropout_rate", "=", "params", ".", "residual_dropout", ",", "\n", "is_training", "=", "is_training", ",", "\n", "using_mask", "=", "False", ",", "\n", "mymasks", "=", "None", ",", "\n", "scope", "=", "\"concentrate_attention\"", "\n", ")", "\n", "#        '''", "\n", "#        post_encode = tf.reduce_mean(decoder_output, -2)", "\n", "post_mulogvar", "=", "tf", ".", "layers", ".", "dense", "(", "post_encode", ",", "params", ".", "latent_dim", "*", "2", ",", "use_bias", "=", "False", ",", "name", "=", "\"post_fc\"", ")", "\n", "post_mu", ",", "post_logvar", "=", "tf", ".", "split", "(", "post_mulogvar", ",", "2", ",", "axis", "=", "1", ")", "\n", "\n", "latent_sample", "=", "sample_gaussian", "(", "post_mu", ",", "post_logvar", ")", "\n", "#code.interact(local=locals())", "\n", "\n", "", "else", ":", "\n", "        ", "latent_sample", "=", "sample_gaussian", "(", "prior_mu", ",", "prior_logvar", ")", "\n", "#latent_sample = tf.tile(tf.expand_dims(latent_sample, 1), [1, params.decode_length, 1])", "\n", "#        inputs = tf.concat([inputs, latent_sample], axis=2)", "\n", "#        inputs = tf.layers.dense(inputs, params.num_units, activation=tf.tanh, use_bias=False, name=\"last\")", "\n", "\n", "decoder_input", "=", "decoder_input", "[", ":", ",", "-", "1", ":", ",", ":", "]", "\n", "dec_attn_bias", "=", "dec_attn_bias", "[", ":", ",", ":", ",", "-", "1", ":", ",", ":", "]", "\n", "decoder_outputs", "=", "transformer_decoder", "(", "decoder_input", ",", "encoder_output", ",", "context_output", ",", "\n", "dec_attn_bias", ",", "enc_attn_bias", ",", "ctx_attn_bias", ",", "\n", "params", ",", "state", "=", "state", "[", "\"decoder\"", "]", ")", "\n", "\n", "decoder_output", ",", "decoder_state", "=", "decoder_outputs", "\n", "decoder_output", "=", "decoder_output", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "#        code.interact(local=locals())", "\n", "out_lat", "=", "tf", ".", "concat", "(", "[", "decoder_output", ",", "latent_sample", "]", ",", "axis", "=", "-", "1", ")", "\n", "out_lat1", "=", "tf", ".", "layers", ".", "dense", "(", "out_lat", ",", "params", ".", "num_units", ",", "activation", "=", "tf", ".", "tanh", ",", "use_bias", "=", "False", ",", "name", "=", "\"last\"", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "out_lat1", ",", "weights", ",", "False", ",", "True", ")", "\n", "log_prob", "=", "tf", ".", "nn", ".", "log_softmax", "(", "logits", ")", "\n", "\n", "return", "log_prob", ",", "{", "\"encoder\"", ":", "encoder_output", ",", "\"decoder\"", ":", "decoder_state", ",", "\"context\"", ":", "context_output", "}", "\n", "\n", "# [batch, length, channel] => [batch * length, vocab_size]", "\n", "#    decoder_output1 = tf.reshape(decoder_output, [-1, hidden_size])", "\n", "# cvae", "\n", "#    length = decoder_output.get_shape().as_list()[-2]", "\n", "#    code.interact(local=locals())", "\n", "#    latent_sample = tf.tile(tf.expand_dims(latent_sample, 1), [1, length, 1])", "\n", "", "latent_sample", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "latent_sample", ",", "1", ")", ",", "[", "1", ",", "tf", ".", "shape", "(", "decoder_output", ")", "[", "-", "2", "]", ",", "1", "]", ")", "\n", "#code.interact(local=locals())", "\n", "out_lat", "=", "tf", ".", "concat", "(", "[", "decoder_output", ",", "latent_sample", "]", ",", "axis", "=", "-", "1", ")", "\n", "out_lat1", "=", "tf", ".", "layers", ".", "dense", "(", "out_lat", ",", "hidden_size", ",", "activation", "=", "tf", ".", "tanh", ",", "use_bias", "=", "False", ",", "name", "=", "\"last\"", ")", "\n", "decoder_output1", "=", "tf", ".", "reshape", "(", "out_lat1", ",", "[", "-", "1", ",", "hidden_size", "]", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "decoder_output1", ",", "weights", ",", "False", ",", "True", ")", "\n", "#logits = tf.matmul(out_lat, weights, False, True)", "\n", "labels", "=", "features", "[", "\"target\"", "]", "\n", "\n", "# label smoothing", "\n", "ce", "=", "layers", ".", "nn", ".", "smoothed_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "\n", "labels", "=", "labels", ",", "\n", "smoothing", "=", "params", ".", "label_smoothing", ",", "\n", "normalize", "=", "True", "\n", ")", "\n", "\n", "ce", "=", "tf", ".", "reshape", "(", "ce", ",", "tf", ".", "shape", "(", "tgt_seq", ")", ")", "\n", "\n", "if", "mode", "==", "\"eval\"", ":", "\n", "        ", "return", "-", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ",", "axis", "=", "1", ")", "\n", "\n", "", "loss", "=", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ")", "/", "tf", ".", "reduce_sum", "(", "tgt_mask", ")", "\n", "#    code.interact(local=locals())", "\n", "#kl loss", "\n", "kl_weights", "=", "tf", ".", "minimum", "(", "tf", ".", "to_float", "(", "params", ".", "global_step", ")", "/", "10000", ",", "1.0", ")", "\n", "kld", "=", "gaussian_kld", "(", "post_mu", ",", "post_logvar", ",", "prior_mu", ",", "prior_logvar", ")", "\n", "kl_loss", "=", "tf", ".", "reduce_mean", "(", "kld", ")", "*", "kl_weights", "\n", "print", "(", "'global, kl_loss'", ",", "params", ".", "global_step", ",", "kl_loss", ")", "\n", "\n", "return", "1.0", "*", "loss", "+", "1.0", "*", "kl_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.model_graph": [[612, 621], ["contextual_transformer.encoding_graph", "contextual_transformer.decoding_graph"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.encoding_graph", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.contextual_transformer.decoding_graph"], ["", "def", "model_graph", "(", "features", ",", "mode", ",", "params", ")", ":", "\n", "    ", "context_output", ",", "encoder_output", "=", "encoding_graph", "(", "features", ",", "mode", ",", "params", ")", "\n", "state", "=", "{", "\n", "\"encoder\"", ":", "encoder_output", ",", "\n", "\"context\"", ":", "context_output", "\n", "}", "\n", "output", "=", "decoding_graph", "(", "features", ",", "state", ",", "mode", ",", "params", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.__init__": [[367, 369], ["thumt.models.model.NMTModel.__init__"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.train_word2vec.MySentences.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "scope", "=", "\"transformer\"", ")", ":", "\n", "        ", "super", "(", "TransformerLRP", ",", "self", ")", ".", "__init__", "(", "params", "=", "params", ",", "scope", "=", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_training_func": [[370, 381], ["tensorflow.variable_scope", "transformer_lrp.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_training_func", "(", "self", ",", "initializer", ")", ":", "\n", "        ", "def", "training_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "self", ".", "parameters", "\n", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ",", "initializer", "=", "initializer", ",", "\n", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "loss", "=", "model_graph", "(", "features", ",", "features", "[", "\"target\"", "]", ",", "\n", "\"train\"", ",", "params", ")", "[", "0", "]", "\n", "return", "loss", "\n", "\n", "", "", "return", "training_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_relevance_func": [[382, 399], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "transformer_lrp.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_relevance_func", "(", "self", ")", ":", "\n", "        ", "def", "relevance_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "params", ".", "residual_dropout", "=", "0.0", "\n", "params", ".", "attention_dropout", "=", "0.0", "\n", "params", ".", "relu_dropout", "=", "0.0", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "loss", ",", "rlv", "=", "model_graph", "(", "features", ",", "features", "[", "\"target\"", "]", ",", "\n", "\"train\"", ",", "params", ")", "\n", "return", "features", "[", "\"source\"", "]", ",", "features", "[", "\"target\"", "]", ",", "rlv", ",", "loss", "\n", "", "", "return", "relevance_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_evaluation_func": [[400, 418], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "transformer_lrp.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_evaluation_func", "(", "self", ")", ":", "\n", "        ", "def", "evaluation_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "params", ".", "residual_dropout", "=", "0.0", "\n", "params", ".", "attention_dropout", "=", "0.0", "\n", "params", ".", "relu_dropout", "=", "0.0", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "logits", "=", "model_graph", "(", "features", ",", "None", ",", "\"infer\"", ",", "params", ")", "\n", "\n", "", "return", "logits", "\n", "\n", "", "return", "evaluation_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_inference_func": [[419, 437], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "transformer_lrp.model_graph"], "methods", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph"], ["", "def", "get_inference_func", "(", "self", ")", ":", "\n", "        ", "def", "inference_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "params", ".", "residual_dropout", "=", "0.0", "\n", "params", ".", "attention_dropout", "=", "0.0", "\n", "params", ".", "relu_dropout", "=", "0.0", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "logits", "=", "model_graph", "(", "features", ",", "None", ",", "\"infer\"", ",", "params", ")", "\n", "\n", "", "return", "logits", "\n", "\n", "", "return", "inference_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_name": [[438, 441], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_name", "(", ")", ":", "\n", "        ", "return", "\"transformer\"", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.TransformerLRP.get_parameters": [[442, 482], ["tensorflow.contrib.training.HParams"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_parameters", "(", ")", ":", "\n", "        ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "bos", "=", "\"<eos>\"", ",", "\n", "eos", "=", "\"<eos>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "append_eos", "=", "False", ",", "\n", "hidden_size", "=", "512", ",", "\n", "filter_size", "=", "2048", ",", "\n", "num_heads", "=", "8", ",", "\n", "num_encoder_layers", "=", "6", ",", "\n", "num_decoder_layers", "=", "6", ",", "\n", "attention_dropout", "=", "0.0", ",", "\n", "residual_dropout", "=", "0.1", ",", "\n", "relu_dropout", "=", "0.0", ",", "\n", "label_smoothing", "=", "0.1", ",", "\n", "attention_key_channels", "=", "0", ",", "\n", "attention_value_channels", "=", "0", ",", "\n", "multiply_embedding_mode", "=", "\"sqrt_depth\"", ",", "\n", "shared_embedding_and_softmax_weights", "=", "False", ",", "\n", "shared_source_target_embedding", "=", "False", ",", "\n", "# Override default parameters", "\n", "learning_rate_decay", "=", "\"noam\"", ",", "\n", "initializer", "=", "\"uniform_unit_scaling\"", ",", "\n", "initializer_gain", "=", "1.0", ",", "\n", "learning_rate", "=", "1.0", ",", "\n", "layer_preprocess", "=", "\"none\"", ",", "\n", "layer_postprocess", "=", "\"layer_norm\"", ",", "\n", "batch_size", "=", "4096", ",", "\n", "constant_batch_size", "=", "False", ",", "\n", "adam_beta1", "=", "0.9", ",", "\n", "adam_beta2", "=", "0.98", ",", "\n", "adam_epsilon", "=", "1e-9", ",", "\n", "clip_grad_norm", "=", "0.0", ",", "\n", "# lrp", "\n", "stab", "=", "0.05", ",", "\n", ")", "\n", "\n", "return", "params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.normalize": [[19, 28], ["tensorflow.abs", "tensorflow.reduce_sum", "tensorflow.abs", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.expand_dims"], "function", ["None"], ["def", "normalize", "(", "matrix", ",", "negative", "=", "False", ")", ":", "\n", "    ", "if", "negative", ":", "\n", "        ", "matrix_abs", "=", "tf", ".", "abs", "(", "matrix", ")", "\n", "total", "=", "tf", ".", "reduce_sum", "(", "matrix_abs", ",", "-", "1", ")", "\n", "return", "matrix", "/", "tf", ".", "expand_dims", "(", "total", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "matrix", "=", "tf", ".", "abs", "(", "matrix", ")", "\n", "total", "=", "tf", ".", "reduce_sum", "(", "matrix", ",", "-", "1", ")", "\n", "return", "matrix", "/", "tf", ".", "expand_dims", "(", "total", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.get_weights": [[30, 62], ["len", "len", "tensorflow.random_normal_initializer", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "cmp", "ValueError"], "function", ["None"], ["", "", "def", "get_weights", "(", "params", ")", ":", "\n", "    ", "svocab", "=", "params", ".", "vocabulary", "[", "\"source\"", "]", "\n", "tvocab", "=", "params", ".", "vocabulary", "[", "\"target\"", "]", "\n", "src_vocab_size", "=", "len", "(", "svocab", ")", "\n", "tgt_vocab_size", "=", "len", "(", "tvocab", ")", "\n", "vocab_size", "=", "tgt_vocab_size", "\n", "\n", "hidden_size", "=", "params", ".", "hidden_size", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.0", ",", "params", ".", "hidden_size", "**", "-", "0.5", ")", "\n", "\n", "if", "params", ".", "shared_source_target_embedding", ":", "\n", "        ", "if", "cmp", "(", "svocab", ",", "tvocab", ")", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Source and target vocabularies are not the same\"", ")", "\n", "\n", "", "weights", "=", "tf", ".", "get_variable", "(", "\"weights\"", ",", "[", "src_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ")", "\n", "semb", ",", "temb", "=", "weights", ",", "weights", "\n", "", "else", ":", "\n", "        ", "semb", "=", "tf", ".", "get_variable", "(", "\"source_embedding\"", ",", "\n", "[", "src_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ")", "\n", "temb", "=", "tf", ".", "get_variable", "(", "\"target_embedding\"", ",", "\n", "[", "tgt_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ")", "\n", "\n", "", "if", "params", ".", "shared_embedding_and_softmax_weights", ":", "\n", "        ", "softmax_weights", "=", "temb", "\n", "", "else", ":", "\n", "        ", "softmax_weights", "=", "tf", ".", "get_variable", "(", "\"softmax\"", ",", "[", "vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ")", "\n", "\n", "", "return", "semb", ",", "temb", ",", "softmax_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.layer_process": [[64, 71], ["thumt.nn.layer_norm", "ValueError"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.layers.nn.layer_norm"], ["", "def", "layer_process", "(", "x", ",", "mode", ")", ":", "\n", "    ", "if", "not", "mode", "or", "mode", "==", "\"none\"", ":", "\n", "        ", "return", "x", "\n", "", "elif", "mode", "==", "\"layer_norm\"", ":", "\n", "        ", "return", "layers", ".", "nn", ".", "layer_norm", "(", "x", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown mode %s\"", "%", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.residual_fn": [[73, 97], ["tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "thumt.weight_ratio_weighted_sum", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.dropout", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.weight_ratio.weight_ratio_weighted_sum"], ["", "", "def", "residual_fn", "(", "x", ",", "y", ",", "w_x_last", ",", "w_x_inp", ",", "params", ",", "keep_prob", "=", "None", ")", ":", "\n", "    ", "if", "keep_prob", "and", "keep_prob", "<", "1.0", ":", "\n", "        ", "y", "=", "tf", ".", "nn", ".", "dropout", "(", "y", ",", "keep_prob", ")", "\n", "", "batchsize", "=", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", "\n", "len_inp", "=", "tf", ".", "shape", "(", "x", ")", "[", "1", "]", "\n", "len_src", "=", "tf", ".", "shape", "(", "w_x_last", ")", "[", "1", "]", "\n", "dim", "=", "tf", ".", "shape", "(", "x", ")", "[", "2", "]", "\n", "result", "=", "{", "}", "\n", "result", "[", "\"output\"", "]", "=", "x", "+", "y", "\n", "x_down", "=", "tf", ".", "reshape", "(", "x", ",", "[", "batchsize", ",", "-", "1", "]", ")", "\n", "y_down", "=", "tf", ".", "reshape", "(", "y", ",", "[", "batchsize", ",", "-", "1", "]", ")", "\n", "z_down", "=", "tf", ".", "reshape", "(", "result", "[", "\"output\"", "]", ",", "[", "batchsize", ",", "-", "1", "]", ")", "\n", "\n", "w_last_out", ",", "w_inp_out", "=", "wr", ".", "weight_ratio_weighted_sum", "(", "[", "x_down", ",", "y_down", "]", ",", "\n", "[", "1.", ",", "1.", "]", ",", "\n", "z_down", ",", "\n", "stab", "=", "params", ".", "stab", ",", "\n", "flatten", "=", "True", ")", "\n", "# bs, len*d", "\n", "w_last_out", "=", "tf", ".", "reshape", "(", "w_last_out", ",", "[", "batchsize", ",", "1", ",", "len_inp", ",", "dim", "]", ")", "\n", "w_inp_out", "=", "tf", ".", "reshape", "(", "w_inp_out", ",", "[", "batchsize", ",", "1", ",", "len_inp", ",", "dim", "]", ")", "\n", "w_x_out", "=", "w_x_last", "*", "w_last_out", "+", "w_x_inp", "*", "w_inp_out", "\n", "result", "[", "\"weight_ratio\"", "]", "=", "w_x_out", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.ffn_layer": [[99, 120], ["tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.linear_v2n", "tensorflow.nn.relu", "tensorflow.nn.dropout", "tensorflow.variable_scope", "thumt.linear_v2n"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.linear_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.linear_v2n"], ["", "def", "ffn_layer", "(", "inputs", ",", "w_x_inp", ",", "hidden_size", ",", "output_size", ",", "params", ",", "\n", "keep_prob", "=", "None", ",", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"ffn_layer\"", ",", "values", "=", "[", "inputs", "]", ",", "\n", "dtype", "=", "dtype", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"input_layer\"", ")", ":", "\n", "            ", "hidden_linear", "=", "lrp", ".", "linear_v2n", "(", "inputs", ",", "hidden_size", ",", "True", ",", "\n", "[", "w_x_inp", "]", ",", "params", ",", "True", ")", "\n", "hidden", "=", "hidden_linear", "[", "\"output\"", "]", "\n", "w_x_hid", "=", "hidden_linear", "[", "\"weight_ratios\"", "]", "[", "0", "]", "\n", "hidden", "=", "tf", ".", "nn", ".", "relu", "(", "hidden", ")", "\n", "\n", "", "if", "keep_prob", "and", "keep_prob", "<", "1.0", ":", "\n", "            ", "hidden", "=", "tf", ".", "nn", ".", "dropout", "(", "hidden", ",", "keep_prob", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"output_layer\"", ")", ":", "\n", "            ", "output_linear", "=", "lrp", ".", "linear_v2n", "(", "hidden", ",", "output_size", ",", "True", ",", "\n", "[", "w_x_hid", "]", ",", "params", ",", "True", ")", "\n", "output", "=", "output_linear", "[", "\"output\"", "]", "\n", "w_x_outp", "=", "output_linear", "[", "\"weight_ratios\"", "]", "[", "0", "]", "\n", "\n", "", "return", "{", "\"output\"", ":", "output", ",", "\"weight_ratios\"", ":", "w_x_outp", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.transformer_encoder": [[122, 184], ["tensorflow.variable_scope", "thumt.create_diagonal_v2n", "range", "transformer_lrp.layer_process", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.multihead_attention_v2n", "transformer_lrp.residual_fn", "thumt.layer_process", "tensorflow.variable_scope", "transformer_lrp.ffn_layer", "transformer_lrp.residual_fn", "thumt.layer_process", "transformer_lrp.layer_process", "transformer_lrp.layer_process"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.create_diagonal_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.multihead_attention_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.ffn_layer", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.layer_process"], ["", "", "def", "transformer_encoder", "(", "inputs", ",", "bias", ",", "params", ",", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"encoder\"", ",", "dtype", "=", "dtype", ",", "\n", "values", "=", "[", "inputs", ",", "bias", "]", ")", ":", "\n", "        ", "len_src", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", "\n", "batchsize", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "dim", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "2", "]", "\n", "x", "=", "inputs", "\n", "w_x_last", "=", "lrp", ".", "create_diagonal_v2n", "(", "batchsize", ",", "len_src", ",", "dim", ")", "\n", "for", "layer", "in", "range", "(", "params", ".", "num_encoder_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "layer", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"self_attention\"", ")", ":", "\n", "                    ", "y_self", "=", "lrp", ".", "multihead_attention_v2n", "(", "\n", "layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "None", ",", "\n", "bias", ",", "\n", "w_x_last", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "params", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", "\n", ")", "\n", "y", "=", "y_self", "[", "\"outputs\"", "]", "\n", "w_x_self", "=", "y_self", "[", "\"weight_ratio\"", "]", "\n", "\n", "x_res", "=", "residual_fn", "(", "x", ",", "y", ",", "w_x_last", ",", "w_x_self", ",", "params", ",", "\n", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "x_res", "[", "\"output\"", "]", "\n", "w_x_selfres", "=", "x_res", "[", "\"weight_ratio\"", "]", "\n", "\n", "x_norm", "=", "lrp", ".", "layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "\n", "w_x_selfres", ",", "params", ")", "\n", "x", "=", "x_norm", "[", "\"outputs\"", "]", "\n", "w_x_selfres", "=", "x_norm", "[", "\"weight_ratios\"", "]", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"feed_forward\"", ")", ":", "\n", "                    ", "y_ffn", "=", "ffn_layer", "(", "\n", "layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "w_x_selfres", ",", "\n", "params", ".", "filter_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "params", ",", "\n", "1.0", "-", "params", ".", "relu_dropout", ",", "\n", ")", "\n", "y", "=", "y_ffn", "[", "\"output\"", "]", "\n", "w_x_ffn", "=", "y_ffn", "[", "\"weight_ratios\"", "]", "\n", "\n", "x_res", "=", "residual_fn", "(", "x", ",", "y", ",", "w_x_selfres", ",", "w_x_ffn", ",", "params", ",", "\n", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "x_res", "[", "\"output\"", "]", "\n", "w_x_ffnres", "=", "x_res", "[", "\"weight_ratio\"", "]", "\n", "\n", "x_norm", "=", "lrp", ".", "layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "\n", "w_x_ffnres", ",", "params", ")", "\n", "x", "=", "x_norm", "[", "\"outputs\"", "]", "\n", "w_x_ffnres", "=", "x_norm", "[", "\"weight_ratios\"", "]", "\n", "\n", "w_x_last", "=", "w_x_ffnres", "\n", "\n", "", "", "", "outputs", "=", "layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", "\n", "return", "{", "\"outputs\"", ":", "outputs", ",", "\"weight_ratios\"", ":", "w_x_last", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.transformer_decoder": [[186, 278], ["tensorflow.variable_scope", "tensorflow.zeros", "range", "transformer_lrp.layer_process", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.multihead_attention_v2n", "transformer_lrp.residual_fn", "thumt.layer_process", "tensorflow.variable_scope", "thumt.multihead_attention_v2n", "transformer_lrp.residual_fn", "thumt.layer_process", "tensorflow.variable_scope", "transformer_lrp.ffn_layer", "transformer_lrp.residual_fn", "thumt.layer_process", "transformer_lrp.layer_process", "transformer_lrp.layer_process", "transformer_lrp.layer_process"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.multihead_attention_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.lrp.multihead_attention_v2n", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.ffn_layer", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.residual_fn", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.layer_process", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.layer_process"], ["", "", "def", "transformer_decoder", "(", "inputs", ",", "memory", ",", "bias", ",", "mem_bias", ",", "w_x_enc", ",", "params", ",", "\n", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"decoder\"", ",", "dtype", "=", "dtype", ",", "\n", "values", "=", "[", "inputs", ",", "memory", ",", "bias", ",", "mem_bias", "]", ")", ":", "\n", "        ", "len_src", "=", "tf", ".", "shape", "(", "memory", ")", "[", "1", "]", "\n", "len_trg", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", "\n", "batchsize", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "dim", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "2", "]", "\n", "x", "=", "inputs", "\n", "w_x_last", "=", "tf", ".", "zeros", "(", "[", "batchsize", ",", "len_src", ",", "len_trg", ",", "dim", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "for", "layer", "in", "range", "(", "params", ".", "num_decoder_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "layer", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"self_attention\"", ")", ":", "\n", "                    ", "y_self", "=", "lrp", ".", "multihead_attention_v2n", "(", "\n", "layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "None", ",", "\n", "bias", ",", "\n", "w_x_last", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "params", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", "\n", ")", "\n", "y", "=", "y_self", "[", "\"outputs\"", "]", "\n", "w_x_self", "=", "y_self", "[", "\"weight_ratio\"", "]", "\n", "\n", "x_res", "=", "residual_fn", "(", "x", ",", "y", ",", "w_x_last", ",", "w_x_self", ",", "params", ",", "\n", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "x_res", "[", "\"output\"", "]", "\n", "w_x_selfres", "=", "x_res", "[", "\"weight_ratio\"", "]", "\n", "\n", "x_norm", "=", "lrp", ".", "layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "\n", "w_x_selfres", ",", "params", ")", "\n", "x", "=", "x_norm", "[", "\"outputs\"", "]", "\n", "w_x_selfres", "=", "x_norm", "[", "\"weight_ratios\"", "]", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"encdec_attention\"", ")", ":", "\n", "                    ", "y_encdec", "=", "lrp", ".", "multihead_attention_v2n", "(", "\n", "layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "memory", ",", "\n", "mem_bias", ",", "\n", "w_x_enc", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "params", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", "\n", ")", "\n", "y", "=", "y_encdec", "[", "\"outputs\"", "]", "\n", "w_x_encdec", "=", "y_encdec", "[", "\"weight_ratio\"", "]", "\n", "\n", "x_res", "=", "residual_fn", "(", "x", ",", "y", ",", "w_x_selfres", ",", "w_x_encdec", ",", "params", ",", "\n", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "x_res", "[", "\"output\"", "]", "\n", "w_x_encdecres", "=", "x_res", "[", "\"weight_ratio\"", "]", "\n", "\n", "x_norm", "=", "lrp", ".", "layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "\n", "w_x_encdecres", ",", "params", ")", "\n", "x", "=", "x_norm", "[", "\"outputs\"", "]", "\n", "w_x_encdecres", "=", "x_norm", "[", "\"weight_ratios\"", "]", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"feed_forward\"", ")", ":", "\n", "                    ", "y_ffn", "=", "ffn_layer", "(", "\n", "layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "w_x_encdecres", ",", "\n", "params", ".", "filter_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "params", ",", "\n", "1.0", "-", "params", ".", "relu_dropout", ",", "\n", ")", "\n", "y", "=", "y_ffn", "[", "\"output\"", "]", "\n", "w_x_ffn", "=", "y_ffn", "[", "\"weight_ratios\"", "]", "\n", "\n", "x_res", "=", "residual_fn", "(", "x", ",", "y", ",", "w_x_encdecres", ",", "w_x_ffn", ",", "params", ",", "\n", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "x_res", "[", "\"output\"", "]", "\n", "w_x_ffnres", "=", "x_res", "[", "\"weight_ratio\"", "]", "\n", "\n", "x_norm", "=", "lrp", ".", "layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ",", "\n", "w_x_ffnres", ",", "params", ")", "\n", "x", "=", "x_norm", "[", "\"outputs\"", "]", "\n", "w_x_ffnres", "=", "x_norm", "[", "\"weight_ratios\"", "]", "\n", "\n", "w_x_last", "=", "w_x_ffnres", "\n", "\n", "", "", "", "outputs", "=", "layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", "\n", "\n", "return", "{", "\"outputs\"", ":", "outputs", ",", "\"weight_ratios\"", ":", "w_x_last", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.model_graph": [[280, 364], ["tensorflow.sequence_mask", "tensorflow.sequence_mask", "transformer_lrp.get_weights", "tensorflow.get_variable", "tensorflow.nn.bias_add", "thumt.attention.add_timing_signal", "thumt.attention.attention_bias", "thumt.attention.attention_bias", "thumt.attention.add_timing_signal", "transformer_lrp.transformer_encoder", "transformer_lrp.transformer_decoder", "tensorflow.gather", "tensorflow.reduce_sum", "thumt.stabilize", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.matmul", "thumt.smoothed_softmax_cross_entropy_with_logits", "tensorflow.reshape", "tensorflow.transpose", "transformer_lrp.normalize", "tensorflow.gather", "tensorflow.gather", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.pad", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.matmul", "tensorflow.shape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.get_weights", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.add_timing_signal", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.attention_bias", "home.repos.pwc.inspect_result.xl2248_csa-nct.layers.attention.add_timing_signal", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.transformer_encoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.transformer_decoder", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.rnnsearch_lrp.stabilize", "home.repos.pwc.inspect_result.xl2248_csa-nct.losses.losses.smoothed_softmax_cross_entropy_with_logits", "home.repos.pwc.inspect_result.xl2248_csa-nct.models.transformer_lrp.normalize"], ["", "", "def", "model_graph", "(", "features", ",", "labels", ",", "mode", ",", "params", ")", ":", "\n", "    ", "hidden_size", "=", "params", ".", "hidden_size", "\n", "\n", "src_seq", "=", "features", "[", "\"source\"", "]", "\n", "tgt_seq", "=", "features", "[", "\"target\"", "]", "\n", "src_len", "=", "features", "[", "\"source_length\"", "]", "\n", "tgt_len", "=", "features", "[", "\"target_length\"", "]", "\n", "src_mask", "=", "tf", ".", "sequence_mask", "(", "src_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "tgt_mask", "=", "tf", ".", "sequence_mask", "(", "tgt_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "src_embedding", ",", "tgt_embedding", ",", "weights", "=", "get_weights", "(", "params", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "hidden_size", "]", ")", "\n", "\n", "# id => embedding", "\n", "# src_seq: [batch, max_src_length]", "\n", "# tgt_seq: [batch, max_tgt_length]", "\n", "inputs", "=", "tf", ".", "gather", "(", "src_embedding", ",", "src_seq", ")", "*", "(", "hidden_size", "**", "0.5", ")", "\n", "targets", "=", "tf", ".", "gather", "(", "tgt_embedding", ",", "tgt_seq", ")", "*", "(", "hidden_size", "**", "0.5", ")", "\n", "inputs", "=", "inputs", "*", "tf", ".", "expand_dims", "(", "src_mask", ",", "-", "1", ")", "\n", "targets", "=", "targets", "*", "tf", ".", "expand_dims", "(", "tgt_mask", ",", "-", "1", ")", "\n", "\n", "# Preparing encoder & decoder input", "\n", "encoder_input", "=", "tf", ".", "nn", ".", "bias_add", "(", "inputs", ",", "bias", ")", "\n", "encoder_input", "=", "layers", ".", "attention", ".", "add_timing_signal", "(", "encoder_input", ")", "\n", "enc_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "src_mask", ",", "\"masking\"", ")", "\n", "dec_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "tf", ".", "shape", "(", "targets", ")", "[", "1", "]", ",", "\n", "\"causal\"", ")", "\n", "\n", "# Shift left", "\n", "decoder_input", "=", "tf", ".", "pad", "(", "targets", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "decoder_input", "=", "layers", ".", "attention", ".", "add_timing_signal", "(", "decoder_input", ")", "\n", "\n", "if", "params", ".", "residual_dropout", ":", "\n", "        ", "keep_prob", "=", "1.0", "-", "params", ".", "residual_dropout", "\n", "encoder_input", "=", "tf", ".", "nn", ".", "dropout", "(", "encoder_input", ",", "keep_prob", ")", "\n", "decoder_input", "=", "tf", ".", "nn", ".", "dropout", "(", "decoder_input", ",", "keep_prob", ")", "\n", "\n", "", "encoder_out", "=", "transformer_encoder", "(", "encoder_input", ",", "enc_attn_bias", ",", "params", ")", "\n", "encoder_output", "=", "encoder_out", "[", "\"outputs\"", "]", "\n", "w_x_enc", "=", "encoder_out", "[", "\"weight_ratios\"", "]", "\n", "decoder_out", "=", "transformer_decoder", "(", "decoder_input", ",", "encoder_output", ",", "\n", "dec_attn_bias", ",", "enc_attn_bias", ",", "\n", "w_x_enc", ",", "params", ")", "\n", "decoder_output", "=", "decoder_out", "[", "\"outputs\"", "]", "\n", "w_x_dec", "=", "decoder_out", "[", "\"weight_ratios\"", "]", "\n", "\n", "weights_true", "=", "tf", ".", "gather", "(", "weights", ",", "labels", ")", "\n", "logits_elewise_true", "=", "decoder_output", "*", "weights_true", "\n", "logits_true", "=", "tf", ".", "reduce_sum", "(", "logits_elewise_true", ",", "-", "1", ")", "\n", "logits_stab", "=", "lrp", ".", "stabilize", "(", "tf", ".", "expand_dims", "(", "logits_true", ",", "-", "1", ")", ",", "params", ".", "stab", ")", "\n", "wr_logit_decoder", "=", "logits_elewise_true", "/", "logits_stab", "\n", "w_x_true", "=", "w_x_dec", "*", "tf", ".", "expand_dims", "(", "wr_logit_decoder", ",", "1", ")", "\n", "w_x_true", "=", "tf", ".", "reduce_sum", "(", "w_x_true", ",", "-", "1", ")", "\n", "# inference mode, take the last position", "\n", "if", "mode", "==", "\"infer\"", ":", "\n", "        ", "decoder_output", "=", "decoder_output", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "logits", "=", "tf", ".", "matmul", "(", "decoder_output", ",", "weights", ",", "False", ",", "True", ")", "\n", "\n", "return", "logits", "\n", "\n", "# [batch, length, channel] => [batch * length, vocab_size]", "\n", "", "decoder_output", "=", "tf", ".", "reshape", "(", "decoder_output", ",", "[", "-", "1", ",", "hidden_size", "]", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "decoder_output", ",", "weights", ",", "False", ",", "True", ")", "\n", "\n", "# label smoothing", "\n", "ce", "=", "losses", ".", "smoothed_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "\n", "labels", "=", "labels", ",", "\n", "smoothing", "=", "params", ".", "label_smoothing", ",", "\n", "normalize", "=", "True", "\n", ")", "\n", "\n", "ce", "=", "tf", ".", "reshape", "(", "ce", ",", "tf", ".", "shape", "(", "tgt_seq", ")", ")", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ")", "/", "tf", ".", "reduce_sum", "(", "tgt_mask", ")", "\n", "\n", "rlv_info", "=", "{", "}", "\n", "R_x_true", "=", "tf", ".", "transpose", "(", "w_x_true", ",", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "rlv_info", "[", "\"result\"", "]", "=", "normalize", "(", "R_x_true", ",", "True", ")", "\n", "\n", "return", "loss", ",", "rlv_info", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.cache.cache_features": [[11, 29], ["list", "tensorflow.FIFOQueue", "list", "tf.FIFOQueue.dequeue", "zip", "features.itervalues", "tensorflow.split", "zip", "tf.FIFOQueue.enqueue", "features.iterkeys", "v.set_shape", "tensorflow.group", "tensorflow.no_op", "enumerate"], "function", ["None"], ["def", "cache_features", "(", "features", ",", "num_shards", ")", ":", "\n", "    ", "if", "num_shards", "==", "1", ":", "\n", "        ", "return", "features", ",", "tf", ".", "no_op", "(", "name", "=", "\"init_queue\"", ")", "\n", "\n", "", "flat_features", "=", "list", "(", "features", ".", "itervalues", "(", ")", ")", "\n", "queue", "=", "tf", ".", "FIFOQueue", "(", "num_shards", ",", "dtypes", "=", "[", "v", ".", "dtype", "for", "v", "in", "flat_features", "]", ")", "\n", "flat_features", "=", "[", "tf", ".", "split", "(", "v", ",", "num_shards", ",", "axis", "=", "0", ")", "for", "v", "in", "flat_features", "]", "\n", "flat_features", "=", "list", "(", "zip", "(", "*", "flat_features", ")", ")", "\n", "init_ops", "=", "[", "queue", ".", "enqueue", "(", "v", ",", "name", "=", "\"enqueue_%d\"", "%", "i", ")", "\n", "for", "i", ",", "v", "in", "enumerate", "(", "flat_features", ")", "]", "\n", "flat_feature", "=", "queue", ".", "dequeue", "(", ")", "\n", "new_features", "=", "{", "}", "\n", "\n", "for", "k", ",", "v", "in", "zip", "(", "features", ".", "iterkeys", "(", ")", ",", "flat_feature", ")", ":", "\n", "        ", "v", ".", "set_shape", "(", "features", "[", "k", "]", ".", "shape", ")", "\n", "new_features", "[", "k", "]", "=", "v", "\n", "\n", "", "return", "new_features", ",", "tf", ".", "group", "(", "*", "init_ops", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.batch_examples": [[15, 82], ["tensorflow.name_scope", "example.values", "tensorflow.contrib.training.bucket_by_sequence_length", "boundaries.append", "max", "max", "tensorflow.maximum", "tensorflow.shape", "int", "math.log"], "function", ["None"], ["\n", "def", "batch_examples", "(", "example", ",", "batch_size", ",", "max_length", ",", "mantissa_bits", ",", "\n", "shard_multiplier", "=", "1", ",", "length_multiplier", "=", "1", ",", "constant", "=", "False", ",", "\n", "num_threads", "=", "4", ",", "drop_long_sequences", "=", "True", ")", ":", "\n", "    ", "\"\"\" Batch examples\n\n    :param example: A dictionary of <feature name, Tensor>.\n    :param batch_size: The number of tokens or sentences in a batch\n    :param max_length: The maximum length of a example to keep\n    :param mantissa_bits: An integer\n    :param shard_multiplier: an integer increasing the batch_size to suit\n        splitting across data shards.\n    :param length_multiplier: an integer multiplier that is used to\n        increase the batch sizes and sequence length tolerance.\n    :param constant: Whether to use constant batch size\n    :param num_threads: Number of threads\n    :param drop_long_sequences: Whether to drop long sequences\n\n    :returns: A dictionary of batched examples\n    \"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"batch_examples\"", ")", ":", "\n", "        ", "max_length", "=", "max_length", "or", "batch_size", "\n", "min_length", "=", "8", "\n", "mantissa_bits", "=", "mantissa_bits", "\n", "\n", "# Compute boundaries", "\n", "x", "=", "min_length", "\n", "boundaries", "=", "[", "]", "\n", "\n", "while", "x", "<", "max_length", ":", "\n", "            ", "boundaries", ".", "append", "(", "x", ")", "\n", "x", "+=", "2", "**", "max", "(", "0", ",", "int", "(", "math", ".", "log", "(", "x", ",", "2", ")", ")", "-", "mantissa_bits", ")", "\n", "\n", "# Whether the batch size is constant", "\n", "", "if", "not", "constant", ":", "\n", "            ", "batch_sizes", "=", "[", "max", "(", "1", ",", "batch_size", "//", "length", ")", "\n", "for", "length", "in", "boundaries", "+", "[", "max_length", "]", "]", "\n", "batch_sizes", "=", "[", "b", "*", "shard_multiplier", "for", "b", "in", "batch_sizes", "]", "\n", "bucket_capacities", "=", "[", "2", "*", "b", "for", "b", "in", "batch_sizes", "]", "\n", "", "else", ":", "\n", "            ", "batch_sizes", "=", "batch_size", "*", "shard_multiplier", "\n", "bucket_capacities", "=", "[", "2", "*", "n", "for", "n", "in", "boundaries", "+", "[", "max_length", "]", "]", "\n", "\n", "", "max_length", "*=", "length_multiplier", "\n", "boundaries", "=", "[", "boundary", "*", "length_multiplier", "for", "boundary", "in", "boundaries", "]", "\n", "max_length", "=", "max_length", "if", "drop_long_sequences", "else", "10", "**", "9", "\n", "\n", "# The queue to bucket on will be chosen based on maximum length", "\n", "max_example_length", "=", "0", "\n", "for", "v", "in", "example", ".", "values", "(", ")", ":", "\n", "            ", "if", "v", ".", "shape", ".", "ndims", ">", "0", ":", "\n", "                ", "seq_length", "=", "tf", ".", "shape", "(", "v", ")", "[", "0", "]", "\n", "max_example_length", "=", "tf", ".", "maximum", "(", "max_example_length", ",", "seq_length", ")", "\n", "\n", "", "", "(", "_", ",", "outputs", ")", "=", "tf", ".", "contrib", ".", "training", ".", "bucket_by_sequence_length", "(", "\n", "max_example_length", ",", "\n", "example", ",", "\n", "batch_sizes", ",", "\n", "[", "b", "+", "1", "for", "b", "in", "boundaries", "]", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "capacity", "=", "2", ",", "# Number of full batches to store, we don't need many.", "\n", "bucket_capacities", "=", "bucket_capacities", ",", "\n", "dynamic_pad", "=", "True", ",", "\n", "keep_input", "=", "(", "max_example_length", "<=", "max_length", ")", "\n", ")", "\n", "\n", "", "return", "outputs", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position_eos": [[84, 128], ["open", "fr.readlines", "turn_position.append", "mask.append", "file1.split", "os.path.exists", "os.path.exists", "open", "open", "line.strip", "lines.strip().split", "tmp.append", "mask_tmp.append", "len", "len", "print", "file1.split", "os.path.getsize", "os.path.getsize", "sorted", "fw.write", "sorted", "fw.write", "str", "str", "lines.strip().split", "lines.strip", "lines.strip"], "function", ["None"], ["", "def", "get_turn_position_eos", "(", "file1", ")", ":", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "content", "=", "fr", ".", "readlines", "(", ")", "\n", "", "turn_position", "=", "[", "]", "\n", "mask", "=", "[", "]", "\n", "for", "line", "in", "content", ":", "\n", "        ", "tmp", "=", "[", "]", "\n", "mask_tmp", "=", "[", "]", "\n", "index", "=", "0", "\n", "flag", "=", "0", "\n", "lines", "=", "line", ".", "strip", "(", ")", "+", "\" <eos>\"", "\n", "for", "i", "in", "lines", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "#tmp.append(str(index))", "\n", "#            flag = 0", "\n", "            ", "if", "i", "==", "'[SEP]'", ":", "\n", "                ", "index", "+=", "1", "\n", "flag", "=", "1", "\n", "", "tmp", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "mask_tmp", ".", "append", "(", "str", "(", "flag", ")", ")", "\n", "", "if", "len", "(", "lines", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", ")", "!=", "len", "(", "tmp", ")", ":", "\n", "            ", "print", "(", "line", ")", "\n", "", "turn_position", ".", "append", "(", "tmp", ")", "\n", "mask", ".", "append", "(", "mask_tmp", ")", "\n", "\n", "", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.turn_position'", "\n", "mask_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.mask'", "\n", "\n", "#    if os.path.exists(position_file) and os.path.exists(mask_file):", "\n", "if", "os", ".", "path", ".", "exists", "(", "position_file", ")", "and", "os", ".", "path", ".", "exists", "(", "mask_file", ")", "and", "not", "os", ".", "path", ".", "getsize", "(", "position_file", ")", "and", "not", "os", ".", "path", ".", "getsize", "(", "mask_file", ")", ":", "\n", "        ", "return", "position_file", ",", "mask_file", "\n", "\n", "", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "with", "open", "(", "mask_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_mask", "in", "mask", ":", "\n", "            ", "line_mask", "=", "sorted", "(", "line_mask", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_mask", ")", "+", "'\\n'", ")", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", ",", "mask_file", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position": [[129, 156], ["os.path.exists", "open", "fr.readlines", "turn_position.append", "file1.split", "open", "line.strip().split", "tmp.append", "len", "len", "print", "file1.split", "sorted", "fw.write", "str", "line.strip().split", "line.strip", "line.strip"], "function", ["None"], ["", "def", "get_turn_position", "(", "file1", ")", ":", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "content", "=", "fr", ".", "readlines", "(", ")", "\n", "", "turn_position", "=", "[", "]", "\n", "for", "line", "in", "content", ":", "\n", "        ", "tmp", "=", "[", "]", "\n", "index", "=", "0", "\n", "for", "i", "in", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "#tmp.append(str(index))", "\n", "            ", "if", "i", "==", "'[SEP]'", ":", "\n", "                ", "index", "+=", "1", "\n", "", "tmp", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "#        if len(line.strip().split()) != len(tmp):", "\n", "", "if", "len", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", ")", "!=", "len", "(", "tmp", ")", ":", "\n", "            ", "print", "(", "line", ")", "\n", "", "turn_position", ".", "append", "(", "tmp", ")", "\n", "", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.turn_position'", "\n", "if", "os", ".", "path", ".", "exists", "(", "position_file", ")", ":", "\n", "        ", "return", "position_file", "\n", "", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_training_input_contextual": [[157, 355], ["tensorflow.device", "tensorflow.data.TextLineDataset", "tensorflow.data.TextLineDataset", "tensorflow.data.TextLineDataset", "tensorflow.data.TextLineDataset", "tensorflow.data.TextLineDataset", "tensorflow.data.TextLineDataset", "tensorflow.data.TextLineDataset", "tensorflow.data.TextLineDataset", "dataset.get_turn_position", "dataset.get_turn_position", "dataset.get_turn_position", "dataset.get_turn_position", "dataset.get_turn_position", "tensorflow.data.TextLineDataset", "tensorflow.data.TextLineDataset", "tensorflow.data.TextLineDataset", "tensorflow.data.TextLineDataset", "tensorflow.data.TextLineDataset", "tensorflow.data.Dataset.zip", "thumt.is_distributed_training_mode", "dataset.shard.shuffle", "dataset.shard.repeat", "dataset.shard.map", "dataset.shard.map", "dataset.shard.map", "dataset.shard.make_one_shot_iterator", "dataset.make_one_shot_iterator.get_next", "tensorflow.contrib.lookup.index_table_from_tensor", "tensorflow.contrib.lookup.index_table_from_tensor", "tensorflow.contrib.lookup.index_table_from_tensor", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "dataset.batch_examples", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.squeeze", "tensorflow.squeeze", "tensorflow.squeeze", "tensorflow.squeeze", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.squeeze", "tensorflow.to_int32", "tensorflow.squeeze", "tensorflow.to_int32", "tensorflow.squeeze", "tensorflow.to_int32", "tensorflow.squeeze", "dataset.shard.shard", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "thumt.size", "thumt.rank", "len", "tensorflow.concat", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.string_split", "tensorflow.string_split", "tensorflow.string_split", "tensorflow.string_split", "tensorflow.string_split", "tensorflow.string_split", "tensorflow.string_split", "tensorflow.string_split", "tensorflow.string_split", "tensorflow.string_split", "tensorflow.string_split", "tensorflow.string_split", "tensorflow.string_split", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_turn_position", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.is_distributed_training_mode", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.record.batch_examples", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.size", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.rank"], ["", "def", "get_training_input_contextual", "(", "filenames", ",", "params", ")", ":", "\n", "    ", "\"\"\" Get input for training stage\n\n    :param filenames: A list contains [source_filenames, target_filenames]\n    :param params: Hyper-parameters\n\n    :returns: A dictionary of pair <Key, Tensor>\n    \"\"\"", "\n", "\n", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "        ", "src_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "filenames", "[", "0", "]", ")", "\n", "tgt_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "filenames", "[", "1", "]", ")", "\n", "sample_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "params", ".", "sample", ")", "\n", "\n", "context_source_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "params", ".", "context_source", ")", "\n", "ctx_dia_src_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "params", ".", "dialog_src_context", ")", "\n", "ctx_dia_tgt_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "params", ".", "dialog_tgt_context", ")", "\n", "ctx_sty_src_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "params", ".", "style_src_context", ")", "\n", "ctx_sty_tgt_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "params", ".", "style_tgt_context", ")", "\n", "#        ctx_lan_src_dataset = tf.data.TextLineDataset(params.language_src_context)", "\n", "#        ctx_lan_tgt_dataset = tf.data.TextLineDataset(params.language_tgt_context)", "\n", "\n", "position_file_ctx_src", "=", "get_turn_position", "(", "params", ".", "context_source", ")", "\n", "\n", "position_file_src_dia", "=", "get_turn_position", "(", "params", ".", "dialog_src_context", ")", "\n", "position_file_tgt_dia", "=", "get_turn_position", "(", "params", ".", "dialog_tgt_context", ")", "\n", "position_file_src_sty", "=", "get_turn_position", "(", "params", ".", "style_src_context", ")", "\n", "position_file_tgt_sty", "=", "get_turn_position", "(", "params", ".", "style_tgt_context", ")", "\n", "#        position_file_src_lan = get_turn_position(params.language_src_context)", "\n", "#        position_file_tgt_lan = get_turn_position(params.language_tgt_context)", "\n", "\n", "position_ctx_src_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "position_file_ctx_src", ")", "\n", "#        mask_dataset = tf.data.TextLineDataset(mask_file)", "\n", "\n", "position_src_dia_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "position_file_src_dia", ")", "\n", "position_tgt_dia_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "position_file_tgt_dia", ")", "\n", "position_src_sty_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "position_file_src_sty", ")", "\n", "position_tgt_sty_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "position_file_tgt_sty", ")", "\n", "#        position_src_lan_dataset = tf.data.TextLineDataset(position_file_src_lan)", "\n", "#        position_tgt_lan_dataset = tf.data.TextLineDataset(position_file_tgt_lan)", "\n", "#        code.interact(local=locals())", "\n", "#        dataset = tf.data.Dataset.zip((src_dataset, tgt_dataset, emo_dataset, ctx_dia_src_dataset, ctx_dia_tgt_dataset, ctx_sty_src_dataset, ctx_sty_tgt_dataset, ctx_lan_src_dataset, ctx_lan_tgt_dataset, position_src_dia_dataset, position_tgt_dia_dataset, position_src_sty_dataset, position_tgt_sty_dataset, position_src_lan_dataset, position_tgt_lan_dataset, sample_dataset))", "\n", "#        dataset = tf.data.Dataset.zip((src_dataset, tgt_dataset, context_source_dataset, position_ctx_src_dataset, ctx_dia_src_dataset, ctx_dia_tgt_dataset, position_src_dia_dataset, position_tgt_dia_dataset, sample_dataset))", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "zip", "(", "(", "src_dataset", ",", "tgt_dataset", ",", "context_source_dataset", ",", "position_ctx_src_dataset", ",", "ctx_dia_src_dataset", ",", "ctx_dia_tgt_dataset", ",", "ctx_sty_src_dataset", ",", "ctx_sty_tgt_dataset", ",", "position_src_dia_dataset", ",", "position_tgt_dia_dataset", ",", "position_src_sty_dataset", ",", "position_tgt_sty_dataset", ",", "sample_dataset", ")", ")", "\n", "if", "distribute", ".", "is_distributed_training_mode", "(", ")", ":", "\n", "            ", "dataset", "=", "dataset", ".", "shard", "(", "distribute", ".", "size", "(", ")", ",", "distribute", ".", "rank", "(", ")", ")", "\n", "\n", "", "dataset", "=", "dataset", ".", "shuffle", "(", "params", ".", "buffer_size", ")", "\n", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "\n", "# Split string", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "src", ",", "tgt", ",", "ctx_src", ",", "pos_ctx_src", ",", "ctx_dia_src", ",", "ctx_dia_tgt", ",", "ctx_sty_src", ",", "ctx_sty_tgt", ",", "pos_dia_src", ",", "pos_dia_tgt", ",", "pos_sty_src", ",", "pos_sty_tgt", ",", "sample", ":", "(", "\n", "tf", ".", "string_split", "(", "[", "src", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "tgt", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "ctx_src", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "pos_ctx_src", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "ctx_dia_src", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "ctx_dia_tgt", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "ctx_sty_src", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "ctx_sty_tgt", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "pos_dia_src", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "pos_dia_tgt", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "pos_sty_src", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "pos_sty_tgt", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "sample", "]", ")", ".", "values", ",", "\n", ")", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "# Append <eos> symbol", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "src", ",", "tgt", ",", "ctx_src", ",", "pos_ctx_src", ",", "ctx_dia_src", ",", "ctx_dia_tgt", ",", "ctx_sty_src", ",", "ctx_sty_tgt", ",", "pos_dia_src", ",", "pos_dia_tgt", ",", "pos_sty_src", ",", "pos_sty_tgt", ",", "sample", ":", "(", "\n", "src", ",", "\n", "tf", ".", "concat", "(", "[", "tgt", ",", "[", "tf", ".", "constant", "(", "params", ".", "eos", ")", "]", "]", ",", "axis", "=", "0", ")", ",", "\n", "ctx_src", ",", "#tf.concat([ctx_src, [tf.constant(params.eos)]], axis=0),", "\n", "pos_ctx_src", ",", "\n", "ctx_dia_src", ",", "#tf.concat([src, [tf.constant(params.eos)], ctx_dia_src], axis=0),", "\n", "ctx_dia_tgt", ",", "\n", "ctx_sty_src", ",", "\n", "ctx_sty_tgt", ",", "\n", "pos_dia_src", ",", "\n", "pos_dia_tgt", ",", "\n", "pos_sty_src", ",", "\n", "pos_sty_tgt", ",", "\n", "sample", "\n", ")", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "\n", "# Convert to dictionary", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "src", ",", "tgt", ",", "ctx_src", ",", "pos_ctx_src", ",", "ctx_dia_src", ",", "ctx_dia_tgt", ",", "ctx_sty_src", ",", "ctx_sty_tgt", ",", "pos_dia_src", ",", "pos_dia_tgt", ",", "pos_sty_src", ",", "pos_sty_tgt", ",", "sample", ":", "{", "\n", "\"source\"", ":", "src", ",", "\n", "\"target\"", ":", "tgt", ",", "\n", "\"context_source\"", ":", "ctx_src", ",", "\n", "\"position_ctx_src\"", ":", "pos_ctx_src", ",", "\n", "\"context_dia_src\"", ":", "ctx_dia_src", ",", "\n", "\"context_dia_tgt\"", ":", "ctx_dia_tgt", ",", "\n", "\"context_sty_src\"", ":", "ctx_sty_src", ",", "\n", "\"context_sty_tgt\"", ":", "ctx_sty_tgt", ",", "\n", "\"position_dia_src\"", ":", "pos_dia_src", ",", "\n", "\"position_dia_tgt\"", ":", "pos_dia_tgt", ",", "\n", "\"position_sty_src\"", ":", "pos_sty_src", ",", "\n", "\"position_sty_tgt\"", ":", "pos_sty_tgt", ",", "\n", "\"sample\"", ":", "sample", ",", "\n", "\"source_length\"", ":", "tf", ".", "shape", "(", "src", ")", ",", "\n", "\"target_length\"", ":", "tf", ".", "shape", "(", "tgt", ")", ",", "\n", "\"context_source_length\"", ":", "tf", ".", "shape", "(", "ctx_src", ")", ",", "\n", "\"context_dia_src_length\"", ":", "tf", ".", "shape", "(", "ctx_dia_src", ")", ",", "\n", "\"context_dia_tgt_length\"", ":", "tf", ".", "shape", "(", "ctx_dia_tgt", ")", ",", "\n", "\"context_sty_src_length\"", ":", "tf", ".", "shape", "(", "ctx_sty_src", ")", ",", "\n", "\"context_sty_tgt_length\"", ":", "tf", ".", "shape", "(", "ctx_sty_tgt", ")", ",", "\n", "\"sample_length\"", ":", "tf", ".", "shape", "(", "sample", ")", "\n", "}", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "\n", "# Create iterator", "\n", "iterator", "=", "dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "features", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "# Create lookup table", "\n", "src_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"source\"", "]", ")", ",", "\n", "default_value", "=", "params", ".", "mapping", "[", "\"source\"", "]", "[", "params", ".", "unk", "]", "\n", ")", "\n", "tgt_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", ",", "\n", "default_value", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "unk", "]", "\n", ")", "\n", "pos_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"position\"", "]", ")", ",", "\n", "default_value", "=", "1", "\n", ")", "\n", "\n", "# String to index lookup", "\n", "features", "[", "\"source\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"source\"", "]", ")", "\n", "features", "[", "\"target\"", "]", "=", "tgt_table", ".", "lookup", "(", "features", "[", "\"target\"", "]", ")", "\n", "features", "[", "\"context_source\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"context_source\"", "]", ")", "\n", "\n", "features", "[", "\"sample\"", "]", "=", "tgt_table", ".", "lookup", "(", "features", "[", "\"sample\"", "]", ")", "\n", "features", "[", "\"context_dia_src\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"context_dia_src\"", "]", ")", "\n", "features", "[", "\"context_dia_tgt\"", "]", "=", "tgt_table", ".", "lookup", "(", "features", "[", "\"context_dia_tgt\"", "]", ")", "\n", "features", "[", "\"context_sty_src\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"context_sty_src\"", "]", ")", "\n", "features", "[", "\"context_sty_tgt\"", "]", "=", "tgt_table", ".", "lookup", "(", "features", "[", "\"context_sty_tgt\"", "]", ")", "\n", "\n", "#        features[\"emotion\"] = emo_table.lookup(features[\"emotion\"])", "\n", "features", "[", "\"position_ctx_src\"", "]", "=", "pos_table", ".", "lookup", "(", "features", "[", "\"position_ctx_src\"", "]", ")", "\n", "features", "[", "\"position_dia_src\"", "]", "=", "pos_table", ".", "lookup", "(", "features", "[", "\"position_dia_src\"", "]", ")", "\n", "features", "[", "\"position_dia_tgt\"", "]", "=", "pos_table", ".", "lookup", "(", "features", "[", "\"position_dia_tgt\"", "]", ")", "\n", "features", "[", "\"position_sty_src\"", "]", "=", "pos_table", ".", "lookup", "(", "features", "[", "\"position_sty_src\"", "]", ")", "\n", "features", "[", "\"position_sty_tgt\"", "]", "=", "pos_table", ".", "lookup", "(", "features", "[", "\"position_sty_tgt\"", "]", ")", "\n", "\n", "# Batching", "\n", "features", "=", "batch_examples", "(", "features", ",", "params", ".", "batch_size", ",", "\n", "params", ".", "max_length", ",", "params", ".", "mantissa_bits", ",", "\n", "shard_multiplier", "=", "len", "(", "params", ".", "device_list", ")", ",", "\n", "length_multiplier", "=", "params", ".", "length_multiplier", ",", "\n", "constant", "=", "params", ".", "constant_batch_size", ",", "\n", "num_threads", "=", "params", ".", "num_threads", ")", "\n", "\n", "# Convert to int32", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"source\"", "]", ")", "\n", "features", "[", "\"context_source\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context_source\"", "]", ")", "\n", "features", "[", "\"target\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"target\"", "]", ")", "\n", "features", "[", "\"sample\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"sample\"", "]", ")", "\n", "\n", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"source_length\"", "]", ")", "\n", "features", "[", "\"target_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"target_length\"", "]", ")", "\n", "features", "[", "\"sample_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"sample_length\"", "]", ")", "\n", "features", "[", "\"context_source_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context_source_length\"", "]", ")", "\n", "\n", "features", "[", "\"context_source_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"context_source_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"source_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"target_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"target_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"sample_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"sample_length\"", "]", ",", "1", ")", "\n", "\n", "features", "[", "\"context_dia_src\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context_dia_src\"", "]", ")", "\n", "features", "[", "\"context_dia_tgt\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context_dia_tgt\"", "]", ")", "\n", "features", "[", "\"position_sty_src\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"position_sty_src\"", "]", ")", "\n", "features", "[", "\"position_sty_tgt\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"position_sty_tgt\"", "]", ")", "\n", "\n", "features", "[", "\"position_ctx_src\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"position_ctx_src\"", "]", ")", "\n", "features", "[", "\"position_dia_src\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"position_dia_src\"", "]", ")", "\n", "features", "[", "\"position_dia_tgt\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"position_dia_tgt\"", "]", ")", "\n", "\n", "features", "[", "\"context_dia_src_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context_dia_src_length\"", "]", ")", "\n", "features", "[", "\"context_dia_src_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"context_dia_src_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_dia_tgt_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context_dia_tgt_length\"", "]", ")", "\n", "features", "[", "\"context_dia_tgt_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"context_dia_tgt_length\"", "]", ",", "1", ")", "\n", "\n", "features", "[", "\"context_sty_src_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context_sty_src_length\"", "]", ")", "\n", "features", "[", "\"context_sty_src_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"context_sty_src_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_sty_tgt_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context_sty_tgt_length\"", "]", ")", "\n", "features", "[", "\"context_sty_tgt_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"context_sty_tgt_length\"", "]", ",", "1", ")", "\n", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_training_input_contextual_emo": [[356, 443], ["tensorflow.device", "tensorflow.data.Dataset.zip", "dataset.map.shuffle", "dataset.map.repeat", "dataset.map.map", "dataset.map.make_one_shot_iterator", "dataset.make_one_shot_iterator.get_next", "tensorflow.contrib.lookup.index_table_from_tensor", "tensorflow.contrib.lookup.index_table_from_tensor", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "dataset.batch_examples", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.squeeze", "tensorflow.squeeze", "tensorflow.squeeze", "tensorflow.data.Dataset.from_tensor_slices", "dataset.map.map", "dataset.map.map", "datasets.append", "tuple", "tensorflow.constant", "tensorflow.constant", "len", "tensorflow.concat", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.string_split", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.data.record.batch_examples"], ["", "", "def", "get_training_input_contextual_emo", "(", "filenames", ",", "params", ")", ":", "\n", "\n", "    ", "\"\"\" Get input for training stage\n\n    :param filenames: A list contains [source_filenames, target_filenames]\n    :param params: Hyper-parameters\n\n    :returns: A dictionary of pair <Key, Tensor>\n    \"\"\"", "\n", "#print(\"filenames:\", filenames)", "\n", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "\n", "        ", "datasets", "=", "[", "]", "\n", "#code.interact(local=locals())", "\n", "for", "data", "in", "filenames", ":", "# bianli 4 ge file", "\n", "            ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "data", ")", "\n", "# Split string", "\n", "dataset", "=", "dataset", ".", "map", "(", "lambda", "x", ":", "tf", ".", "string_split", "(", "[", "x", "]", ")", ".", "values", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", ")", "\n", "# Append <eos>", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "x", ":", "tf", ".", "concat", "(", "[", "x", ",", "[", "tf", ".", "constant", "(", "params", ".", "eos", ")", "]", "]", ",", "axis", "=", "0", ")", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "datasets", ".", "append", "(", "dataset", ")", "\n", "#code.interact(local=locals())", "\n", "", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "zip", "(", "tuple", "(", "datasets", ")", ")", "\n", "dataset", "=", "dataset", ".", "shuffle", "(", "params", ".", "buffer_size", ")", "\n", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "#for one_element in tfe.Iterator(dataset):", "\n", "#    print(one_element)", "\n", "# Convert to dictionary", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "*", "x", ":", "{", "\n", "\"source\"", ":", "x", "[", "0", "]", ",", "\n", "\"target\"", ":", "x", "[", "1", "]", ",", "\n", "\"context\"", ":", "x", "[", "2", "]", ",", "\n", "\"emotion\"", ":", "x", "[", "3", "]", ",", "\n", "\"source_length\"", ":", "tf", ".", "shape", "(", "x", "[", "0", "]", ")", ",", "\n", "\"target_length\"", ":", "tf", ".", "shape", "(", "x", "[", "1", "]", ")", ",", "\n", "\"context_length\"", ":", "tf", ".", "shape", "(", "x", "[", "2", "]", ")", "\n", "}", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "\n", "# Create iterator", "\n", "iterator", "=", "dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "features", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "# Create lookup table", "\n", "src_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"source\"", "]", ")", ",", "\n", "default_value", "=", "params", ".", "mapping", "[", "\"source\"", "]", "[", "params", ".", "unk", "]", "\n", ")", "\n", "tgt_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", ",", "\n", "default_value", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "unk", "]", "\n", ")", "\n", "\n", "# String to index lookup", "\n", "features", "[", "\"source\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"source\"", "]", ")", "\n", "features", "[", "\"target\"", "]", "=", "tgt_table", ".", "lookup", "(", "features", "[", "\"target\"", "]", ")", "\n", "features", "[", "\"context\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"context\"", "]", ")", "\n", "features", "[", "\"emotion\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"emotion\"", "]", ")", "\n", "\n", "# Batching", "\n", "features", "=", "batch_examples", "(", "features", ",", "params", ".", "batch_size", ",", "\n", "params", ".", "max_length", ",", "params", ".", "mantissa_bits", ",", "\n", "shard_multiplier", "=", "len", "(", "params", ".", "device_list", ")", ",", "\n", "length_multiplier", "=", "params", ".", "length_multiplier", ",", "\n", "constant", "=", "params", ".", "constant_batch_size", ",", "\n", "num_threads", "=", "params", ".", "num_threads", ")", "\n", "\n", "# Convert to int32", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"source\"", "]", ")", "\n", "features", "[", "\"target\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"target\"", "]", ")", "\n", "features", "[", "\"context\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context\"", "]", ")", "\n", "features", "[", "\"emotion\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"emotion\"", "]", ")", "\n", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"source_length\"", "]", ")", "\n", "features", "[", "\"target_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"target_length\"", "]", ")", "\n", "features", "[", "\"context_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context_length\"", "]", ")", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"source_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"target_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"target_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"context_length\"", "]", ",", "1", ")", "\n", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_training_input": [[84, 169], ["tensorflow.device", "tensorflow.data.TextLineDataset", "tensorflow.data.TextLineDataset", "tensorflow.data.Dataset.zip", "thumt.is_distributed_training_mode", "dataset.shard.shuffle", "dataset.shard.repeat", "dataset.shard.map", "dataset.shard.map", "dataset.shard.map", "dataset.shard.make_one_shot_iterator", "dataset.make_one_shot_iterator.get_next", "tensorflow.contrib.lookup.index_table_from_tensor", "tensorflow.contrib.lookup.index_table_from_tensor", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "dataset.batch_examples", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.squeeze", "tensorflow.squeeze", "dataset.shard.shard", "tensorflow.constant", "tensorflow.constant", "thumt.size", "thumt.rank", "len", "tensorflow.concat", "tensorflow.concat", "tensorflow.shape", "tensorflow.shape", "tensorflow.string_split", "tensorflow.string_split", "tensorflow.constant", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.is_distributed_training_mode", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.record.batch_examples", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.size", "home.repos.pwc.inspect_result.xl2248_csa-nct.utils.distribute.rank"], ["", "def", "get_turn_position_eos", "(", "file1", ")", ":", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "content", "=", "fr", ".", "readlines", "(", ")", "\n", "", "turn_position", "=", "[", "]", "\n", "mask", "=", "[", "]", "\n", "for", "line", "in", "content", ":", "\n", "        ", "tmp", "=", "[", "]", "\n", "mask_tmp", "=", "[", "]", "\n", "index", "=", "0", "\n", "flag", "=", "0", "\n", "lines", "=", "line", ".", "strip", "(", ")", "+", "\" <eos>\"", "\n", "for", "i", "in", "lines", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "#tmp.append(str(index))", "\n", "#            flag = 0", "\n", "            ", "if", "i", "==", "'[SEP]'", ":", "\n", "                ", "index", "+=", "1", "\n", "flag", "=", "1", "\n", "", "tmp", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "mask_tmp", ".", "append", "(", "str", "(", "flag", ")", ")", "\n", "", "if", "len", "(", "lines", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", ")", "!=", "len", "(", "tmp", ")", ":", "\n", "            ", "print", "(", "line", ")", "\n", "", "turn_position", ".", "append", "(", "tmp", ")", "\n", "mask", ".", "append", "(", "mask_tmp", ")", "\n", "\n", "", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.turn_position'", "\n", "mask_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.mask'", "\n", "\n", "#    if os.path.exists(position_file) and os.path.exists(mask_file):", "\n", "if", "os", ".", "path", ".", "exists", "(", "position_file", ")", "and", "os", ".", "path", ".", "exists", "(", "mask_file", ")", "and", "not", "os", ".", "path", ".", "getsize", "(", "position_file", ")", "and", "not", "os", ".", "path", ".", "getsize", "(", "mask_file", ")", ":", "\n", "        ", "return", "position_file", ",", "mask_file", "\n", "\n", "", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "with", "open", "(", "mask_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_mask", "in", "mask", ":", "\n", "            ", "line_mask", "=", "sorted", "(", "line_mask", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_mask", ")", "+", "'\\n'", ")", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", ",", "mask_file", "\n", "\n", "", "def", "get_turn_position", "(", "file1", ")", ":", "\n", "    ", "with", "open", "(", "file1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "content", "=", "fr", ".", "readlines", "(", ")", "\n", "", "turn_position", "=", "[", "]", "\n", "for", "line", "in", "content", ":", "\n", "        ", "tmp", "=", "[", "]", "\n", "index", "=", "0", "\n", "for", "i", "in", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "#tmp.append(str(index))", "\n", "            ", "if", "i", "==", "'[SEP]'", ":", "\n", "                ", "index", "+=", "1", "\n", "", "tmp", ".", "append", "(", "str", "(", "index", ")", ")", "\n", "#        if len(line.strip().split()) != len(tmp):", "\n", "", "if", "len", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", ")", "!=", "len", "(", "tmp", ")", ":", "\n", "            ", "print", "(", "line", ")", "\n", "", "turn_position", ".", "append", "(", "tmp", ")", "\n", "", "base_path", "=", "'/'", ".", "join", "(", "file1", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "signal", "=", "file1", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "#.split('.')[0]", "\n", "position_file", "=", "base_path", "+", "'/'", "+", "signal", "+", "'.turn_position'", "\n", "if", "os", ".", "path", ".", "exists", "(", "position_file", ")", ":", "\n", "        ", "return", "position_file", "\n", "", "with", "open", "(", "position_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "for", "line_position", "in", "turn_position", ":", "\n", "            ", "line_position", "=", "sorted", "(", "line_position", ",", "reverse", "=", "True", ")", "\n", "fw", ".", "write", "(", "' '", ".", "join", "(", "line_position", ")", "+", "'\\n'", ")", "\n", "#code.interact(local=locals())", "\n", "", "", "return", "position_file", "\n", "\n", "", "def", "get_training_input_contextual", "(", "filenames", ",", "params", ")", ":", "\n", "    ", "\"\"\" Get input for training stage\n\n    :param filenames: A list contains [source_filenames, target_filenames]\n    :param params: Hyper-parameters\n\n    :returns: A dictionary of pair <Key, Tensor>\n    \"\"\"", "\n", "\n", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "        ", "src_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "filenames", "[", "0", "]", ")", "\n", "tgt_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "filenames", "[", "1", "]", ")", "\n", "sample_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "params", ".", "sample", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.sort_input_file": [[171, 190], ["sorted", "enumerate", "tensorflow.gfile.Open", "sorted_inputs.append", "line.strip", "len", "enumerate", "operator.itemgetter", "line.strip().split", "line.strip"], "function", ["None"], ["context_source_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "params", ".", "context_source", ")", "\n", "ctx_dia_src_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "params", ".", "dialog_src_context", ")", "\n", "ctx_dia_tgt_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "params", ".", "dialog_tgt_context", ")", "\n", "ctx_sty_src_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "params", ".", "style_src_context", ")", "\n", "ctx_sty_tgt_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "params", ".", "style_tgt_context", ")", "\n", "#        ctx_lan_src_dataset = tf.data.TextLineDataset(params.language_src_context)", "\n", "#        ctx_lan_tgt_dataset = tf.data.TextLineDataset(params.language_tgt_context)", "\n", "\n", "position_file_ctx_src", "=", "get_turn_position", "(", "params", ".", "context_source", ")", "\n", "\n", "position_file_src_dia", "=", "get_turn_position", "(", "params", ".", "dialog_src_context", ")", "\n", "position_file_tgt_dia", "=", "get_turn_position", "(", "params", ".", "dialog_tgt_context", ")", "\n", "position_file_src_sty", "=", "get_turn_position", "(", "params", ".", "style_src_context", ")", "\n", "position_file_tgt_sty", "=", "get_turn_position", "(", "params", ".", "style_tgt_context", ")", "\n", "#        position_file_src_lan = get_turn_position(params.language_src_context)", "\n", "#        position_file_tgt_lan = get_turn_position(params.language_tgt_context)", "\n", "\n", "position_ctx_src_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "position_file_ctx_src", ")", "\n", "#        mask_dataset = tf.data.TextLineDataset(mask_file)", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.sort_input_file_ctx": [[551, 613], ["sorted", "enumerate", "tensorflow.gfile.Open", "tensorflow.gfile.Open", "tensorflow.gfile.Open", "tensorflow.gfile.Open", "tensorflow.gfile.Open", "tensorflow.gfile.Open", "tensorflow.gfile.Open", "tensorflow.gfile.Open", "tensorflow.gfile.Open", "tensorflow.gfile.Open", "tensorflow.gfile.Open", "sorted_inputs.append", "dialog_src_context.append", "pos_src_dia.append", "dialog_tgt_context.append", "pos_tgt_dia.append", "ctx_src.append", "pos_ctx_src.append", "style_src_context.append", "pos_src_sty.append", "style_tgt_context.append", "pos_tgt_sty.append", "line.strip", "line.strip", "line.strip", "line.strip", "line.strip", "line.strip", "line.strip", "line.strip", "line.strip", "line.strip", "line.strip", "len", "enumerate", "operator.itemgetter", "line.strip().split", "line.strip"], "function", ["None"], ["", "def", "sort_input_file_ctx", "(", "filename", ",", "f1", ",", "f2", ",", "f3", ",", "f4", ",", "f5", ",", "f6", ",", "f7", ",", "f8", ",", "f9", ",", "f10", ",", "reverse", "=", "True", ")", ":", "\n", "# Read file", "\n", "    ", "with", "tf", ".", "gfile", ".", "Open", "(", "filename", ")", "as", "fd", ":", "\n", "        ", "inputs", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fd", "]", "\n", "\n", "#   with tf.gfile.Open(filename_ctx) as fd:", "\n", "#       ctxs = [line.strip() for line in fd]", "\n", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "f1", ")", "as", "fd", ":", "\n", "        ", "ctx1", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fd", "]", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "f2", ")", "as", "fd", ":", "\n", "        ", "ctx2", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fd", "]", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "f3", ")", "as", "fd", ":", "\n", "        ", "ctx3", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fd", "]", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "f4", ")", "as", "fd", ":", "\n", "        ", "ctx4", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fd", "]", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "f5", ")", "as", "fd", ":", "\n", "        ", "ctx5", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fd", "]", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "f6", ")", "as", "fd", ":", "\n", "        ", "ctx6", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fd", "]", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "f7", ")", "as", "fd", ":", "\n", "        ", "ctx7", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fd", "]", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "f8", ")", "as", "fd", ":", "\n", "        ", "ctx8", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fd", "]", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "f9", ")", "as", "fd", ":", "\n", "        ", "ctx9", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fd", "]", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "f10", ")", "as", "fd", ":", "\n", "        ", "ctx10", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fd", "]", "\n", "\n", "#    return inputs,ctx1,ctx2,ctx3,ctx4,ctx5,ctx6,ctx7,ctx8,ctx9,ctx10,ctx11,ctx12,ctx13", "\n", "", "input_lens", "=", "[", "\n", "(", "i", ",", "len", "(", "line", ".", "strip", "(", ")", ".", "split", "(", ")", ")", ")", "for", "i", ",", "line", "in", "enumerate", "(", "inputs", ")", "\n", "]", "\n", "\n", "sorted_input_lens", "=", "sorted", "(", "input_lens", ",", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ",", "\n", "reverse", "=", "reverse", ")", "\n", "sorted_keys", "=", "{", "}", "\n", "sorted_inputs", "=", "[", "]", "\n", "sorted_ctxs", "=", "[", "]", "\n", "dialog_src_context", ",", "pos_src_dia", ",", "dialog_tgt_context", ",", "pos_tgt_dia", ",", "style_src_context", ",", "pos_src_sty", ",", "style_tgt_context", ",", "pos_tgt_sty", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "ctx_src", ",", "pos_ctx_src", "=", "[", "]", ",", "[", "]", "\n", "\n", "for", "i", ",", "(", "index", ",", "_", ")", "in", "enumerate", "(", "sorted_input_lens", ")", ":", "\n", "        ", "sorted_inputs", ".", "append", "(", "inputs", "[", "index", "]", ")", "\n", "#        sorted_ctxs.append(ctxs[index])", "\n", "\n", "dialog_src_context", ".", "append", "(", "ctx1", "[", "index", "]", ")", "\n", "pos_src_dia", ".", "append", "(", "ctx2", "[", "index", "]", ")", "\n", "dialog_tgt_context", ".", "append", "(", "ctx3", "[", "index", "]", ")", "\n", "pos_tgt_dia", ".", "append", "(", "ctx4", "[", "index", "]", ")", "\n", "\n", "ctx_src", ".", "append", "(", "ctx5", "[", "index", "]", ")", "\n", "pos_ctx_src", ".", "append", "(", "ctx6", "[", "index", "]", ")", "\n", "\n", "style_src_context", ".", "append", "(", "ctx7", "[", "index", "]", ")", "\n", "pos_src_sty", ".", "append", "(", "ctx8", "[", "index", "]", ")", "\n", "style_tgt_context", ".", "append", "(", "ctx9", "[", "index", "]", ")", "\n", "pos_tgt_sty", ".", "append", "(", "ctx10", "[", "index", "]", ")", "\n", "\n", "sorted_keys", "[", "index", "]", "=", "i", "\n", "\n", "", "return", "sorted_keys", ",", "sorted_inputs", ",", "dialog_src_context", ",", "pos_src_dia", ",", "dialog_tgt_context", ",", "pos_tgt_dia", ",", "ctx_src", ",", "pos_ctx_src", ",", "style_src_context", ",", "pos_src_sty", ",", "style_tgt_context", ",", "pos_tgt_sty", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.sort_and_zip_files": [[192, 217], ["zip", "sorted", "enumerate", "tensorflow.gfile.GFile", "input_lens.append", "inputs.append", "fd.close", "sorted_inputs.append", "list", "line.strip", "operator.itemgetter", "zip", "len", "lines[].split"], "function", ["None"], ["position_tgt_dia_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "position_file_tgt_dia", ")", "\n", "position_src_sty_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "position_file_src_sty", ")", "\n", "position_tgt_sty_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "position_file_tgt_sty", ")", "\n", "#        position_src_lan_dataset = tf.data.TextLineDataset(position_file_src_lan)", "\n", "#        position_tgt_lan_dataset = tf.data.TextLineDataset(position_file_tgt_lan)", "\n", "#        code.interact(local=locals())", "\n", "#        dataset = tf.data.Dataset.zip((src_dataset, tgt_dataset, emo_dataset, ctx_dia_src_dataset, ctx_dia_tgt_dataset, ctx_sty_src_dataset, ctx_sty_tgt_dataset, ctx_lan_src_dataset, ctx_lan_tgt_dataset, position_src_dia_dataset, position_tgt_dia_dataset, position_src_sty_dataset, position_tgt_sty_dataset, position_src_lan_dataset, position_tgt_lan_dataset, sample_dataset))", "\n", "#        dataset = tf.data.Dataset.zip((src_dataset, tgt_dataset, context_source_dataset, position_ctx_src_dataset, ctx_dia_src_dataset, ctx_dia_tgt_dataset, position_src_dia_dataset, position_tgt_dia_dataset, sample_dataset))", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "zip", "(", "(", "src_dataset", ",", "tgt_dataset", ",", "context_source_dataset", ",", "position_ctx_src_dataset", ",", "ctx_dia_src_dataset", ",", "ctx_dia_tgt_dataset", ",", "ctx_sty_src_dataset", ",", "ctx_sty_tgt_dataset", ",", "position_src_dia_dataset", ",", "position_tgt_dia_dataset", ",", "position_src_sty_dataset", ",", "position_tgt_sty_dataset", ",", "sample_dataset", ")", ")", "\n", "if", "distribute", ".", "is_distributed_training_mode", "(", ")", ":", "\n", "            ", "dataset", "=", "dataset", ".", "shard", "(", "distribute", ".", "size", "(", ")", ",", "distribute", ".", "rank", "(", ")", ")", "\n", "\n", "", "dataset", "=", "dataset", ".", "shuffle", "(", "params", ".", "buffer_size", ")", "\n", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "\n", "# Split string", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "src", ",", "tgt", ",", "ctx_src", ",", "pos_ctx_src", ",", "ctx_dia_src", ",", "ctx_dia_tgt", ",", "ctx_sty_src", ",", "ctx_sty_tgt", ",", "pos_dia_src", ",", "pos_dia_tgt", ",", "pos_sty_src", ",", "pos_sty_tgt", ",", "sample", ":", "(", "\n", "tf", ".", "string_split", "(", "[", "src", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "tgt", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "ctx_src", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "pos_ctx_src", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "ctx_dia_src", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "ctx_dia_tgt", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "ctx_sty_src", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "ctx_sty_tgt", "]", ")", ".", "values", ",", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_evaluation_input_ctx": [[643, 778], ["tensorflow.device", "print", "enumerate", "tensorflow.data.Dataset.zip", "dataset.map.map", "dataset.map.padded_batch", "dataset.map.make_one_shot_iterator", "dataset.make_one_shot_iterator.get_next", "tensorflow.contrib.lookup.index_table_from_tensor", "tensorflow.contrib.lookup.index_table_from_tensor", "tensorflow.contrib.lookup.index_table_from_tensor", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "len", "tensorflow.data.Dataset.from_tensor_slices", "dataset.map.map", "datasets.append", "tuple", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "dataset.map.map", "dataset.map.map", "tensorflow.Dimension", "tensorflow.Dimension", "tensorflow.Dimension", "tensorflow.Dimension", "tensorflow.Dimension", "tensorflow.Dimension", "tensorflow.Dimension", "tensorflow.Dimension", "tensorflow.Dimension", "tensorflow.Dimension", "tensorflow.Dimension", "tensorflow.Dimension", "tensorflow.string_split", "tensorflow.concat", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.Dimension", "len", "len", "tensorflow.constant"], "function", ["None"], ["", "def", "get_evaluation_input_ctx", "(", "inputs", ",", "params", ")", ":", "\n", "    ", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "# Create datasets", "\n", "        ", "datasets", "=", "[", "]", "\n", "print", "(", "len", "(", "inputs", ")", ")", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "inputs", ")", ":", "\n", "            ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "data", ")", "\n", "# Split string", "\n", "dataset", "=", "dataset", ".", "map", "(", "lambda", "x", ":", "tf", ".", "string_split", "(", "[", "x", "]", ")", ".", "values", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", ")", "\n", "# Append <eos>", "\n", "if", "i", ">", "11", ":", "\n", "                ", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "x", ":", "tf", ".", "concat", "(", "[", "x", ",", "[", "tf", ".", "constant", "(", "params", ".", "eos", ")", "]", "]", ",", "axis", "=", "0", ")", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "", "else", ":", "\n", "                ", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "x", ":", "x", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "\n", "", "datasets", ".", "append", "(", "dataset", ")", "\n", "\n", "", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "zip", "(", "tuple", "(", "datasets", ")", ")", "\n", "\n", "# Convert tuple to dictionary", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "*", "x", ":", "{", "\n", "\"source\"", ":", "x", "[", "0", "]", ",", "\n", "\"source_length\"", ":", "tf", ".", "shape", "(", "x", "[", "0", "]", ")", "[", "0", "]", ",", "\n", "\"context_dia_src\"", ":", "x", "[", "1", "]", ",", "\n", "\"position_dia_src\"", ":", "x", "[", "2", "]", ",", "\n", "\"context_dia_src_length\"", ":", "tf", ".", "shape", "(", "x", "[", "1", "]", ")", "[", "0", "]", ",", "\n", "\"context_dia_tgt\"", ":", "x", "[", "3", "]", ",", "\n", "\"position_dia_tgt\"", ":", "x", "[", "4", "]", ",", "\n", "\"context_dia_tgt_length\"", ":", "tf", ".", "shape", "(", "x", "[", "3", "]", ")", "[", "0", "]", ",", "\n", "\"position_ctx_src\"", ":", "x", "[", "5", "]", ",", "\n", "\"sample\"", ":", "x", "[", "6", "]", ",", "\n", "\"sample_length\"", ":", "tf", ".", "shape", "(", "x", "[", "6", "]", ")", "[", "0", "]", ",", "\n", "\"context_source\"", ":", "x", "[", "7", "]", ",", "\n", "\"context_source_length\"", ":", "tf", ".", "shape", "(", "x", "[", "7", "]", ")", "[", "0", "]", ",", "\n", "\"context_sty_src\"", ":", "x", "[", "8", "]", ",", "\n", "\"position_sty_src\"", ":", "x", "[", "9", "]", ",", "\n", "\"context_sty_src_length\"", ":", "tf", ".", "shape", "(", "x", "[", "8", "]", ")", "[", "0", "]", ",", "\n", "\"context_sty_tgt\"", ":", "x", "[", "10", "]", ",", "\n", "\"position_sty_tgt\"", ":", "x", "[", "11", "]", ",", "\n", "\"context_sty_tgt_length\"", ":", "tf", ".", "shape", "(", "x", "[", "10", "]", ")", "[", "0", "]", ",", "\n", "\"references\"", ":", "x", "[", "12", ":", "]", "\n", "}", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "#        code.interact(local=locals())", "\n", "dataset", "=", "dataset", ".", "padded_batch", "(", "\n", "params", ".", "eval_batch_size", ",", "\n", "{", "\n", "\"source\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\n", "\"source_length\"", ":", "[", "]", ",", "\n", "\"context_dia_src\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\n", "\"context_dia_tgt\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\n", "\"context_source\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\n", "\"context_dia_src_length\"", ":", "[", "]", ",", "\n", "\"context_dia_tgt_length\"", ":", "[", "]", ",", "\n", "\"context_sty_src_length\"", ":", "[", "]", ",", "\n", "\"context_sty_tgt_length\"", ":", "[", "]", ",", "\n", "\"context_source_length\"", ":", "[", "]", ",", "\n", "\"position_dia_src\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\n", "\"position_dia_tgt\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\n", "\"position_ctx_src\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\n", "\"sample\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\n", "\"sample_length\"", ":", "[", "]", ",", "\n", "\"context_sty_src\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\n", "\"context_sty_tgt\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\n", "\"position_sty_src\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\n", "\"position_sty_tgt\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\n", "\"references\"", ":", "(", "tf", ".", "Dimension", "(", "None", ")", ",", ")", "*", "(", "len", "(", "inputs", ")", "-", "12", ")", "\n", "}", ",", "\n", "{", "\n", "\"source\"", ":", "params", ".", "pad", ",", "\n", "\"source_length\"", ":", "0", ",", "\n", "\"context_dia_src\"", ":", "params", ".", "pad", ",", "\n", "\"context_dia_tgt\"", ":", "params", ".", "pad", ",", "\n", "\"context_source\"", ":", "params", ".", "pad", ",", "\n", "\"context_dia_src_length\"", ":", "0", ",", "\n", "\"context_dia_tgt_length\"", ":", "0", ",", "\n", "\"context_sty_src_length\"", ":", "0", ",", "\n", "\"context_sty_tgt_length\"", ":", "0", ",", "\n", "\"context_source_length\"", ":", "0", ",", "\n", "\"position_dia_src\"", ":", "params", ".", "pad", ",", "\n", "\"position_dia_tgt\"", ":", "params", ".", "pad", ",", "\n", "\"position_ctx_src\"", ":", "params", ".", "pad", ",", "\n", "\"sample\"", ":", "params", ".", "pad", ",", "\n", "\"sample_length\"", ":", "0", ",", "\n", "\"context_sty_src\"", ":", "params", ".", "pad", ",", "\n", "\"context_sty_tgt\"", ":", "params", ".", "pad", ",", "\n", "\"position_sty_src\"", ":", "params", ".", "pad", ",", "\n", "\"position_sty_tgt\"", ":", "params", ".", "pad", ",", "\n", "\"references\"", ":", "(", "params", ".", "pad", ",", ")", "*", "(", "len", "(", "inputs", ")", "-", "12", ")", "\n", "}", "\n", ")", "\n", "\n", "iterator", "=", "dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "features", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "# Covert source symbols to ids", "\n", "src_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"source\"", "]", ")", ",", "\n", "default_value", "=", "params", ".", "mapping", "[", "\"source\"", "]", "[", "params", ".", "unk", "]", "\n", ")", "\n", "tgt_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", ",", "\n", "default_value", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "unk", "]", "\n", ")", "\n", "pos_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"position\"", "]", ")", ",", "\n", "default_value", "=", "1", "\n", ")", "\n", "features", "[", "\"source\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"source\"", "]", ")", "\n", "features", "[", "\"sample\"", "]", "=", "tgt_table", ".", "lookup", "(", "features", "[", "\"sample\"", "]", ")", "\n", "\n", "features", "[", "\"context_source\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"context_source\"", "]", ")", "\n", "\n", "features", "[", "\"context_dia_src\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"context_dia_src\"", "]", ")", "\n", "features", "[", "\"context_dia_tgt\"", "]", "=", "tgt_table", ".", "lookup", "(", "features", "[", "\"context_dia_tgt\"", "]", ")", "\n", "features", "[", "\"context_sty_src\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"context_sty_src\"", "]", ")", "\n", "features", "[", "\"context_sty_tgt\"", "]", "=", "tgt_table", ".", "lookup", "(", "features", "[", "\"context_sty_tgt\"", "]", ")", "\n", "\n", "features", "[", "\"position_dia_src\"", "]", "=", "pos_table", ".", "lookup", "(", "features", "[", "\"position_dia_src\"", "]", ")", "\n", "features", "[", "\"position_dia_tgt\"", "]", "=", "pos_table", ".", "lookup", "(", "features", "[", "\"position_dia_tgt\"", "]", ")", "\n", "features", "[", "\"position_sty_src\"", "]", "=", "pos_table", ".", "lookup", "(", "features", "[", "\"position_sty_src\"", "]", ")", "\n", "features", "[", "\"position_sty_tgt\"", "]", "=", "pos_table", ".", "lookup", "(", "features", "[", "\"position_sty_tgt\"", "]", ")", "\n", "\n", "features", "[", "\"position_ctx_src\"", "]", "=", "pos_table", ".", "lookup", "(", "features", "[", "\"position_ctx_src\"", "]", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_evaluation_input": [[219, 274], ["tensorflow.device", "tensorflow.data.Dataset.zip", "dataset.map.map", "dataset.map.padded_batch", "dataset.map.make_one_shot_iterator", "dataset.make_one_shot_iterator.get_next", "tensorflow.contrib.lookup.index_table_from_tensor", "tf.contrib.lookup.index_table_from_tensor.lookup", "tensorflow.data.Dataset.from_tensor_slices", "dataset.map.map", "dataset.map.map", "datasets.append", "tuple", "tensorflow.constant", "len", "tensorflow.concat", "tensorflow.Dimension", "tensorflow.string_split", "tensorflow.shape", "tensorflow.Dimension", "len", "len", "tensorflow.constant"], "function", ["None"], ["tf", ".", "string_split", "(", "[", "pos_dia_tgt", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "pos_sty_src", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "pos_sty_tgt", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "sample", "]", ")", ".", "values", ",", "\n", ")", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "# Append <eos> symbol", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "src", ",", "tgt", ",", "ctx_src", ",", "pos_ctx_src", ",", "ctx_dia_src", ",", "ctx_dia_tgt", ",", "ctx_sty_src", ",", "ctx_sty_tgt", ",", "pos_dia_src", ",", "pos_dia_tgt", ",", "pos_sty_src", ",", "pos_sty_tgt", ",", "sample", ":", "(", "\n", "src", ",", "\n", "tf", ".", "concat", "(", "[", "tgt", ",", "[", "tf", ".", "constant", "(", "params", ".", "eos", ")", "]", "]", ",", "axis", "=", "0", ")", ",", "\n", "ctx_src", ",", "#tf.concat([ctx_src, [tf.constant(params.eos)]], axis=0),", "\n", "pos_ctx_src", ",", "\n", "ctx_dia_src", ",", "#tf.concat([src, [tf.constant(params.eos)], ctx_dia_src], axis=0),", "\n", "ctx_dia_tgt", ",", "\n", "ctx_sty_src", ",", "\n", "ctx_sty_tgt", ",", "\n", "pos_dia_src", ",", "\n", "pos_dia_tgt", ",", "\n", "pos_sty_src", ",", "\n", "pos_sty_tgt", ",", "\n", "sample", "\n", ")", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "\n", "# Convert to dictionary", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "src", ",", "tgt", ",", "ctx_src", ",", "pos_ctx_src", ",", "ctx_dia_src", ",", "ctx_dia_tgt", ",", "ctx_sty_src", ",", "ctx_sty_tgt", ",", "pos_dia_src", ",", "pos_dia_tgt", ",", "pos_sty_src", ",", "pos_sty_tgt", ",", "sample", ":", "{", "\n", "\"source\"", ":", "src", ",", "\n", "\"target\"", ":", "tgt", ",", "\n", "\"context_source\"", ":", "ctx_src", ",", "\n", "\"position_ctx_src\"", ":", "pos_ctx_src", ",", "\n", "\"context_dia_src\"", ":", "ctx_dia_src", ",", "\n", "\"context_dia_tgt\"", ":", "ctx_dia_tgt", ",", "\n", "\"context_sty_src\"", ":", "ctx_sty_src", ",", "\n", "\"context_sty_tgt\"", ":", "ctx_sty_tgt", ",", "\n", "\"position_dia_src\"", ":", "pos_dia_src", ",", "\n", "\"position_dia_tgt\"", ":", "pos_dia_tgt", ",", "\n", "\"position_sty_src\"", ":", "pos_sty_src", ",", "\n", "\"position_sty_tgt\"", ":", "pos_sty_tgt", ",", "\n", "\"sample\"", ":", "sample", ",", "\n", "\"source_length\"", ":", "tf", ".", "shape", "(", "src", ")", ",", "\n", "\"target_length\"", ":", "tf", ".", "shape", "(", "tgt", ")", ",", "\n", "\"context_source_length\"", ":", "tf", ".", "shape", "(", "ctx_src", ")", ",", "\n", "\"context_dia_src_length\"", ":", "tf", ".", "shape", "(", "ctx_dia_src", ")", ",", "\n", "\"context_dia_tgt_length\"", ":", "tf", ".", "shape", "(", "ctx_dia_tgt", ")", ",", "\n", "\"context_sty_src_length\"", ":", "tf", ".", "shape", "(", "ctx_sty_src", ")", ",", "\n", "\"context_sty_tgt_length\"", ":", "tf", ".", "shape", "(", "ctx_sty_tgt", ")", ",", "\n", "\"sample_length\"", ":", "tf", ".", "shape", "(", "sample", ")", "\n", "}", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "\n", "# Create iterator", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input_bak": [[835, 878], ["tensorflow.device", "tensorflow.data.Dataset.from_tensor_slices", "dataset.padded_batch.map", "dataset.padded_batch.map", "dataset.padded_batch.map", "dataset.padded_batch.padded_batch", "dataset.padded_batch.make_one_shot_iterator", "dataset.make_one_shot_iterator.get_next", "tensorflow.contrib.lookup.index_table_from_tensor", "tf.contrib.lookup.index_table_from_tensor.lookup", "tensorflow.constant", "tensorflow.constant", "tensorflow.concat", "len", "tensorflow.string_split", "tensorflow.Dimension", "tensorflow.shape", "tensorflow.constant"], "function", ["None"], ["", "def", "get_inference_input_bak", "(", "inputs", ",", "params", ")", ":", "\n", "    ", "if", "params", ".", "generate_samples", ":", "\n", "        ", "batch_size", "=", "params", ".", "sample_batch_size", "\n", "", "else", ":", "\n", "        ", "batch_size", "=", "params", ".", "decode_batch_size", "\n", "\n", "", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "        ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "\n", "tf", ".", "constant", "(", "inputs", ")", "\n", ")", "\n", "\n", "# Split string", "\n", "dataset", "=", "dataset", ".", "map", "(", "lambda", "x", ":", "tf", ".", "string_split", "(", "[", "x", "]", ")", ".", "values", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", ")", "\n", "\n", "# Append <eos>", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "x", ":", "tf", ".", "concat", "(", "[", "x", ",", "[", "tf", ".", "constant", "(", "params", ".", "eos", ")", "]", "]", ",", "axis", "=", "0", ")", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "\n", "# Convert tuple to dictionary", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "x", ":", "{", "\"source\"", ":", "x", ",", "\"source_length\"", ":", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", "}", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "\n", "dataset", "=", "dataset", ".", "padded_batch", "(", "\n", "batch_size", "*", "len", "(", "params", ".", "device_list", ")", ",", "\n", "{", "\"source\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\"source_length\"", ":", "[", "]", "}", ",", "\n", "{", "\"source\"", ":", "params", ".", "pad", ",", "\"source_length\"", ":", "0", "}", "\n", ")", "\n", "\n", "iterator", "=", "dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "features", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "src_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"source\"", "]", ")", ",", "\n", "default_value", "=", "params", ".", "mapping", "[", "\"source\"", "]", "[", "params", ".", "unk", "]", "\n", ")", "\n", "features", "[", "\"source\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"source\"", "]", ")", "\n", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_inference_input": [[276, 319], ["tensorflow.device", "tensorflow.data.Dataset.from_tensor_slices", "dataset.padded_batch.map", "dataset.padded_batch.map", "dataset.padded_batch.map", "dataset.padded_batch.padded_batch", "dataset.padded_batch.make_one_shot_iterator", "dataset.make_one_shot_iterator.get_next", "tensorflow.contrib.lookup.index_table_from_tensor", "tf.contrib.lookup.index_table_from_tensor.lookup", "tensorflow.constant", "tensorflow.constant", "tensorflow.concat", "len", "tensorflow.string_split", "tensorflow.Dimension", "tensorflow.shape", "tensorflow.constant"], "function", ["None"], ["features", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "# Create lookup table", "\n", "src_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"source\"", "]", ")", ",", "\n", "default_value", "=", "params", ".", "mapping", "[", "\"source\"", "]", "[", "params", ".", "unk", "]", "\n", ")", "\n", "tgt_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", ",", "\n", "default_value", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "unk", "]", "\n", ")", "\n", "pos_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"position\"", "]", ")", ",", "\n", "default_value", "=", "1", "\n", ")", "\n", "\n", "# String to index lookup", "\n", "features", "[", "\"source\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"source\"", "]", ")", "\n", "features", "[", "\"target\"", "]", "=", "tgt_table", ".", "lookup", "(", "features", "[", "\"target\"", "]", ")", "\n", "features", "[", "\"context_source\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"context_source\"", "]", ")", "\n", "\n", "features", "[", "\"sample\"", "]", "=", "tgt_table", ".", "lookup", "(", "features", "[", "\"sample\"", "]", ")", "\n", "features", "[", "\"context_dia_src\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"context_dia_src\"", "]", ")", "\n", "features", "[", "\"context_dia_tgt\"", "]", "=", "tgt_table", ".", "lookup", "(", "features", "[", "\"context_dia_tgt\"", "]", ")", "\n", "features", "[", "\"context_sty_src\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"context_sty_src\"", "]", ")", "\n", "features", "[", "\"context_sty_tgt\"", "]", "=", "tgt_table", ".", "lookup", "(", "features", "[", "\"context_sty_tgt\"", "]", ")", "\n", "\n", "#        features[\"emotion\"] = emo_table.lookup(features[\"emotion\"])", "\n", "features", "[", "\"position_ctx_src\"", "]", "=", "pos_table", ".", "lookup", "(", "features", "[", "\"position_ctx_src\"", "]", ")", "\n", "features", "[", "\"position_dia_src\"", "]", "=", "pos_table", ".", "lookup", "(", "features", "[", "\"position_dia_src\"", "]", ")", "\n", "features", "[", "\"position_dia_tgt\"", "]", "=", "pos_table", ".", "lookup", "(", "features", "[", "\"position_dia_tgt\"", "]", ")", "\n", "features", "[", "\"position_sty_src\"", "]", "=", "pos_table", ".", "lookup", "(", "features", "[", "\"position_sty_src\"", "]", ")", "\n", "features", "[", "\"position_sty_tgt\"", "]", "=", "pos_table", ".", "lookup", "(", "features", "[", "\"position_sty_tgt\"", "]", ")", "\n", "\n", "# Batching", "\n", "features", "=", "batch_examples", "(", "features", ",", "params", ".", "batch_size", ",", "\n", "params", ".", "max_length", ",", "params", ".", "mantissa_bits", ",", "\n", "shard_multiplier", "=", "len", "(", "params", ".", "device_list", ")", ",", "\n", "length_multiplier", "=", "params", ".", "length_multiplier", ",", "\n", "constant", "=", "params", ".", "constant_batch_size", ",", "\n", "num_threads", "=", "params", ".", "num_threads", ")", "\n", "\n", "# Convert to int32", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"source\"", "]", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.dataset.get_relevance_input": [[321, 396], ["tensorflow.data.Dataset.from_tensor_slices", "dataset.padded_batch.map", "dataset.padded_batch.map", "dataset.padded_batch.map", "dataset.padded_batch.padded_batch", "dataset.padded_batch.make_one_shot_iterator", "dataset_o.make_one_shot_iterator.get_next", "tensorflow.contrib.lookup.index_table_from_tensor", "tf.contrib.lookup.index_table_from_tensor.lookup", "tensorflow.data.Dataset.from_tensor_slices", "dataset_o.padded_batch.map", "dataset_o.padded_batch.map", "dataset_o.padded_batch.map", "dataset_o.padded_batch.padded_batch", "dataset_o.padded_batch.make_one_shot_iterator", "dataset_o.make_one_shot_iterator.get_next", "tensorflow.contrib.lookup.index_table_from_tensor", "tf.contrib.lookup.index_table_from_tensor.lookup", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.concat", "tensorflow.concat", "tensorflow.string_split", "tensorflow.Dimension", "tensorflow.string_split", "tensorflow.Dimension", "tensorflow.shape", "tensorflow.shape", "tensorflow.constant", "tensorflow.constant"], "function", ["None"], ["features", "[", "\"target\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"target\"", "]", ")", "\n", "features", "[", "\"sample\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"sample\"", "]", ")", "\n", "\n", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"source_length\"", "]", ")", "\n", "features", "[", "\"target_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"target_length\"", "]", ")", "\n", "features", "[", "\"sample_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"sample_length\"", "]", ")", "\n", "features", "[", "\"context_source_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context_source_length\"", "]", ")", "\n", "\n", "features", "[", "\"context_source_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"context_source_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"source_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"target_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"target_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"sample_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"sample_length\"", "]", ",", "1", ")", "\n", "\n", "features", "[", "\"context_dia_src\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context_dia_src\"", "]", ")", "\n", "features", "[", "\"context_dia_tgt\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context_dia_tgt\"", "]", ")", "\n", "features", "[", "\"position_sty_src\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"position_sty_src\"", "]", ")", "\n", "features", "[", "\"position_sty_tgt\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"position_sty_tgt\"", "]", ")", "\n", "\n", "features", "[", "\"position_ctx_src\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"position_ctx_src\"", "]", ")", "\n", "features", "[", "\"position_dia_src\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"position_dia_src\"", "]", ")", "\n", "features", "[", "\"position_dia_tgt\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"position_dia_tgt\"", "]", ")", "\n", "\n", "features", "[", "\"context_dia_src_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context_dia_src_length\"", "]", ")", "\n", "features", "[", "\"context_dia_src_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"context_dia_src_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_dia_tgt_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context_dia_tgt_length\"", "]", ")", "\n", "features", "[", "\"context_dia_tgt_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"context_dia_tgt_length\"", "]", ",", "1", ")", "\n", "\n", "features", "[", "\"context_sty_src_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context_sty_src_length\"", "]", ")", "\n", "features", "[", "\"context_sty_src_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"context_sty_src_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"context_sty_tgt_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"context_sty_tgt_length\"", "]", ")", "\n", "features", "[", "\"context_sty_tgt_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"context_sty_tgt_length\"", "]", ",", "1", ")", "\n", "\n", "return", "features", "\n", "\n", "", "", "def", "get_training_input_contextual_emo", "(", "filenames", ",", "params", ")", ":", "\n", "\n", "    ", "\"\"\" Get input for training stage\n\n    :param filenames: A list contains [source_filenames, target_filenames]\n    :param params: Hyper-parameters\n\n    :returns: A dictionary of pair <Key, Tensor>\n    \"\"\"", "\n", "#print(\"filenames:\", filenames)", "\n", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "\n", "        ", "datasets", "=", "[", "]", "\n", "#code.interact(local=locals())", "\n", "for", "data", "in", "filenames", ":", "# bianli 4 ge file", "\n", "            ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "data", ")", "\n", "# Split string", "\n", "dataset", "=", "dataset", ".", "map", "(", "lambda", "x", ":", "tf", ".", "string_split", "(", "[", "x", "]", ")", ".", "values", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", ")", "\n", "# Append <eos>", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "x", ":", "tf", ".", "concat", "(", "[", "x", ",", "[", "tf", ".", "constant", "(", "params", ".", "eos", ")", "]", "]", ",", "axis", "=", "0", ")", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "datasets", ".", "append", "(", "dataset", ")", "\n", "#code.interact(local=locals())", "\n", "", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "zip", "(", "tuple", "(", "datasets", ")", ")", "\n", "dataset", "=", "dataset", ".", "shuffle", "(", "params", ".", "buffer_size", ")", "\n", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "#for one_element in tfe.Iterator(dataset):", "\n", "#    print(one_element)", "\n", "# Convert to dictionary", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "*", "x", ":", "{", "\n", "\"source\"", ":", "x", "[", "0", "]", ",", "\n", "\"target\"", ":", "x", "[", "1", "]", ",", "\n", "\"context\"", ":", "x", "[", "2", "]", ",", "\n", "\"emotion\"", ":", "x", "[", "3", "]", ",", "\n", "\"source_length\"", ":", "tf", ".", "shape", "(", "x", "[", "0", "]", ")", ",", "\n", "\"target_length\"", ":", "tf", ".", "shape", "(", "x", "[", "1", "]", ")", ",", "\n", "\"context_length\"", ":", "tf", ".", "shape", "(", "x", "[", "2", "]", ")", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.record.input_pipeline": [[17, 58], ["tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.contrib.slim.tfexample_decoder.Tensor", "tensorflow.contrib.slim.tfexample_decoder.Tensor", "tensorflow.contrib.slim.tfexample_decoder.Tensor", "tensorflow.contrib.slim.tfexample_decoder.Tensor", "tensorflow.name_scope", "tensorflow.contrib.slim.parallel_reader.get_data_files", "min", "tensorflow.contrib.slim.parallel_reader.parallel_read", "tensorflow.contrib.slim.tfexample_decoder.TFExampleDecoder", "tfexample_decoder.TFExampleDecoder.decode", "zip", "len", "tensorflow.to_int32", "list", "six.iteritems"], "function", ["None"], ["def", "input_pipeline", "(", "file_pattern", ",", "mode", ",", "capacity", "=", "64", ")", ":", "\n", "    ", "keys_to_features", "=", "{", "\n", "\"source\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", ",", "\n", "\"target\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", ",", "\n", "\"source_length\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "1", "]", ",", "tf", ".", "int64", ")", ",", "\n", "\"target_length\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "1", "]", ",", "tf", ".", "int64", ")", "\n", "}", "\n", "\n", "items_to_handlers", "=", "{", "\n", "\"source\"", ":", "tfexample_decoder", ".", "Tensor", "(", "\"source\"", ")", ",", "\n", "\"target\"", ":", "tfexample_decoder", ".", "Tensor", "(", "\"target\"", ")", ",", "\n", "\"source_length\"", ":", "tfexample_decoder", ".", "Tensor", "(", "\"source_length\"", ")", ",", "\n", "\"target_length\"", ":", "tfexample_decoder", ".", "Tensor", "(", "\"target_length\"", ")", "\n", "}", "\n", "\n", "# Now the non-trivial case construction.", "\n", "with", "tf", ".", "name_scope", "(", "\"examples_queue\"", ")", ":", "\n", "        ", "training", "=", "(", "mode", "==", "\"train\"", ")", "\n", "# Read serialized examples using slim parallel_reader.", "\n", "num_epochs", "=", "None", "if", "training", "else", "1", "\n", "data_files", "=", "parallel_reader", ".", "get_data_files", "(", "file_pattern", ")", "\n", "num_readers", "=", "min", "(", "4", "if", "training", "else", "1", ",", "len", "(", "data_files", ")", ")", "\n", "_", ",", "examples", "=", "parallel_reader", ".", "parallel_read", "(", "[", "file_pattern", "]", ",", "\n", "tf", ".", "TFRecordReader", ",", "\n", "num_epochs", "=", "num_epochs", ",", "\n", "shuffle", "=", "training", ",", "\n", "capacity", "=", "2", "*", "capacity", ",", "\n", "min_after_dequeue", "=", "capacity", ",", "\n", "num_readers", "=", "num_readers", ")", "\n", "\n", "decoder", "=", "tfexample_decoder", ".", "TFExampleDecoder", "(", "keys_to_features", ",", "\n", "items_to_handlers", ")", "\n", "\n", "decoded", "=", "decoder", ".", "decode", "(", "examples", ",", "items", "=", "list", "(", "items_to_handlers", ")", ")", "\n", "examples", "=", "{", "}", "\n", "\n", "for", "(", "field", ",", "tensor", ")", "in", "zip", "(", "keys_to_features", ",", "decoded", ")", ":", "\n", "            ", "examples", "[", "field", "]", "=", "tensor", "\n", "\n", "# We do not want int64s as they do are not supported on GPUs.", "\n", "", "return", "{", "k", ":", "tf", ".", "to_int32", "(", "v", ")", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "examples", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.record.batch_examples": [[60, 107], ["tensorflow.name_scope", "examples.values", "tensorflow.contrib.training.bucket_by_sequence_length", "boundaries.append", "tensorflow.maximum", "max", "max", "tensorflow.shape", "int", "math.log"], "function", ["None"], ["", "", "def", "batch_examples", "(", "examples", ",", "batch_size", ",", "max_length", ",", "mantissa_bits", ",", "\n", "shard_multiplier", "=", "1", ",", "length_multiplier", "=", "1", ",", "scheme", "=", "\"token\"", ",", "\n", "drop_long_sequences", "=", "True", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"batch_examples\"", ")", ":", "\n", "        ", "max_length", "=", "max_length", "or", "batch_size", "\n", "min_length", "=", "8", "\n", "mantissa_bits", "=", "mantissa_bits", "\n", "\n", "# compute boundaries", "\n", "x", "=", "min_length", "\n", "boundaries", "=", "[", "]", "\n", "\n", "while", "x", "<", "max_length", ":", "\n", "            ", "boundaries", ".", "append", "(", "x", ")", "\n", "x", "+=", "2", "**", "max", "(", "0", ",", "int", "(", "math", ".", "log", "(", "x", ",", "2", ")", ")", "-", "mantissa_bits", ")", "\n", "\n", "", "if", "scheme", "is", "\"token\"", ":", "\n", "            ", "batch_sizes", "=", "[", "max", "(", "1", ",", "batch_size", "//", "length", ")", "\n", "for", "length", "in", "boundaries", "+", "[", "max_length", "]", "]", "\n", "batch_sizes", "=", "[", "b", "*", "shard_multiplier", "for", "b", "in", "batch_sizes", "]", "\n", "bucket_capacities", "=", "[", "2", "*", "b", "for", "b", "in", "batch_sizes", "]", "\n", "", "else", ":", "\n", "            ", "batch_sizes", "=", "batch_size", "*", "shard_multiplier", "\n", "bucket_capacities", "=", "[", "2", "*", "n", "for", "n", "in", "boundaries", "+", "[", "max_length", "]", "]", "\n", "\n", "", "max_length", "*=", "length_multiplier", "\n", "boundaries", "=", "[", "boundary", "*", "length_multiplier", "for", "boundary", "in", "boundaries", "]", "\n", "max_length", "=", "max_length", "if", "drop_long_sequences", "else", "10", "**", "9", "\n", "\n", "# The queue to bucket on will be chosen based on maximum length.", "\n", "max_example_length", "=", "0", "\n", "for", "v", "in", "examples", ".", "values", "(", ")", ":", "\n", "            ", "seq_length", "=", "tf", ".", "shape", "(", "v", ")", "[", "0", "]", "\n", "max_example_length", "=", "tf", ".", "maximum", "(", "max_example_length", ",", "seq_length", ")", "\n", "\n", "", "(", "_", ",", "outputs", ")", "=", "tf", ".", "contrib", ".", "training", ".", "bucket_by_sequence_length", "(", "\n", "max_example_length", ",", "\n", "examples", ",", "\n", "batch_sizes", ",", "\n", "[", "b", "+", "1", "for", "b", "in", "boundaries", "]", ",", "\n", "capacity", "=", "2", ",", "\n", "bucket_capacities", "=", "bucket_capacities", ",", "\n", "dynamic_pad", "=", "True", ",", "\n", "keep_input", "=", "(", "max_example_length", "<=", "max_length", ")", "\n", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.record.get_input_features": [[109, 143], ["tensorflow.name_scope", "tensorflow.device", "record.input_pipeline", "record.batch_examples", "tensorflow.squeeze", "tensorflow.squeeze", "len"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.data.record.input_pipeline", "home.repos.pwc.inspect_result.xl2248_csa-nct.data.record.batch_examples"], ["", "def", "get_input_features", "(", "file_patterns", ",", "mode", ",", "params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"input_queues\"", ")", ":", "\n", "        ", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "            ", "if", "mode", "!=", "\"train\"", ":", "\n", "                ", "num_datashards", "=", "1", "\n", "batch_size", "=", "params", ".", "eval_batch_size", "\n", "", "else", ":", "\n", "                ", "num_datashards", "=", "len", "(", "params", ".", "device_list", ")", "\n", "batch_size", "=", "params", ".", "batch_size", "\n", "\n", "", "batch_size_multiplier", "=", "1", "\n", "capacity", "=", "64", "*", "num_datashards", "\n", "examples", "=", "input_pipeline", "(", "file_patterns", ",", "mode", ",", "capacity", ")", "\n", "drop_long_sequences", "=", "(", "mode", "==", "\"train\"", ")", "\n", "\n", "feature_map", "=", "batch_examples", "(", "\n", "examples", ",", "\n", "batch_size", ",", "\n", "params", ".", "max_length", ",", "\n", "params", ".", "mantissa_bits", ",", "\n", "num_datashards", ",", "\n", "batch_size_multiplier", ",", "\n", "\"token\"", "if", "not", "params", ".", "constant_batch_size", "else", "\"constant\"", ",", "\n", "drop_long_sequences", "\n", ")", "\n", "\n", "", "features", "=", "{", "\n", "\"source\"", ":", "feature_map", "[", "\"source\"", "]", ",", "\n", "\"target\"", ":", "feature_map", "[", "\"target\"", "]", ",", "\n", "\"source_length\"", ":", "tf", ".", "squeeze", "(", "feature_map", "[", "\"source_length\"", "]", ",", "axis", "=", "1", ")", ",", "\n", "\"target_length\"", ":", "tf", ".", "squeeze", "(", "feature_map", "[", "\"target_length\"", "]", ",", "axis", "=", "1", ")", "\n", "}", "\n", "\n", "", "return", "features", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.load_vocabulary": [[11, 19], ["tensorflow.gfile.GFile", "line.strip", "vocab.append"], "function", ["None"], ["def", "load_vocabulary", "(", "filename", ")", ":", "\n", "    ", "vocab", "=", "[", "]", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "filename", ")", "as", "fd", ":", "\n", "        ", "for", "line", "in", "fd", ":", "\n", "            ", "word", "=", "line", ".", "strip", "(", ")", "\n", "vocab", ".", "append", "(", "word", ")", "\n", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.process_vocabulary": [[21, 26], ["vocab.append"], "function", ["None"], ["", "def", "process_vocabulary", "(", "vocab", ",", "params", ")", ":", "\n", "    ", "if", "params", ".", "append_eos", ":", "\n", "        ", "vocab", ".", "append", "(", "params", ".", "eos", ")", "\n", "\n", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.data.vocab.get_control_mapping": [[28, 37], ["enumerate"], "function", ["None"], ["", "def", "get_control_mapping", "(", "vocab", ",", "symbols", ")", ":", "\n", "    ", "mapping", "=", "{", "}", "\n", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "vocab", ")", ":", "\n", "        ", "for", "symbol", "in", "symbols", ":", "\n", "            ", "if", "symbol", "==", "token", ":", "\n", "                ", "mapping", "[", "symbol", "]", "=", "i", "\n", "\n", "", "", "", "return", "mapping", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.losses.losses.smoothed_softmax_cross_entropy_with_logits": [[11, 56], ["kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "ValueError", "tensorflow.name_scope", "tensorflow.reshape", "tensorflow.to_float", "tensorflow.one_hot", "tensorflow.stop_gradient", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.shape", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.log", "tensorflow.log"], "function", ["None"], ["def", "smoothed_softmax_cross_entropy_with_logits", "(", "**", "kwargs", ")", ":", "\n", "    ", "logits", "=", "kwargs", ".", "get", "(", "\"logits\"", ")", "\n", "labels", "=", "kwargs", ".", "get", "(", "\"labels\"", ")", "\n", "smoothing", "=", "kwargs", ".", "get", "(", "\"smoothing\"", ")", "or", "0.0", "\n", "normalize", "=", "kwargs", ".", "get", "(", "\"normalize\"", ")", "\n", "scope", "=", "kwargs", ".", "get", "(", "\"scope\"", ")", "\n", "\n", "if", "logits", "is", "None", "or", "labels", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Both logits and labels must be provided\"", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "scope", "or", "\"smoothed_softmax_cross_entropy_with_logits\"", ",", "\n", "values", "=", "[", "logits", ",", "labels", "]", ")", ":", "\n", "\n", "        ", "labels", "=", "tf", ".", "reshape", "(", "labels", ",", "[", "-", "1", "]", ")", "\n", "\n", "if", "not", "smoothing", ":", "\n", "            ", "ce", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "tf", ".", "cast", "(", "logits", ",", "tf", ".", "float32", ")", ",", "\n", "labels", "=", "labels", "\n", ")", "\n", "return", "ce", "\n", "\n", "# label smoothing", "\n", "", "vocab_size", "=", "tf", ".", "shape", "(", "logits", ")", "[", "1", "]", "\n", "\n", "n", "=", "tf", ".", "to_float", "(", "vocab_size", "-", "1", ")", "\n", "p", "=", "1.0", "-", "smoothing", "\n", "q", "=", "smoothing", "/", "n", "\n", "\n", "soft_targets", "=", "tf", ".", "one_hot", "(", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "int32", ")", ",", "depth", "=", "vocab_size", ",", "\n", "on_value", "=", "p", ",", "off_value", "=", "q", ")", "\n", "soft_targets", "=", "tf", ".", "stop_gradient", "(", "soft_targets", ")", "\n", "xentropy", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "logits", "=", "tf", ".", "cast", "(", "logits", ",", "tf", ".", "float32", ")", ",", "\n", "labels", "=", "soft_targets", ")", "\n", "\n", "if", "normalize", "is", "False", ":", "\n", "            ", "return", "xentropy", "\n", "\n", "# Normalizing constant is the best cross-entropy value with soft", "\n", "# targets. We subtract it just for readability, makes no difference on", "\n", "# learning", "\n", "", "normalizing", "=", "-", "(", "p", "*", "tf", ".", "log", "(", "p", ")", "+", "n", "*", "q", "*", "tf", ".", "log", "(", "q", "+", "1e-20", ")", ")", "\n", "\n", "return", "xentropy", "-", "normalizing", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.losses.losses.smoothed_sigmoid_cross_entropy_with_logits": [[58, 91], ["kwargs.get", "kwargs.get", "kwargs.get", "ValueError", "tensorflow.name_scope", "tensorflow.map_fn", "tensorflow.reduce_max", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.shape", "tensorflow.one_hot", "tensorflow.cast"], "function", ["None"], ["", "", "def", "smoothed_sigmoid_cross_entropy_with_logits", "(", "**", "kwargs", ")", ":", "\n", "    ", "logits", "=", "kwargs", ".", "get", "(", "\"logits\"", ")", "\n", "labels", "=", "kwargs", ".", "get", "(", "\"labels\"", ")", "\n", "#tes = kwargs.get(\"tes\")", "\n", "scope", "=", "kwargs", ".", "get", "(", "\"scope\"", ")", "\n", "\n", "if", "logits", "is", "None", "or", "labels", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Both logits and labels must be provided\"", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "scope", "or", "\"smoothed_sigmoid_cross_entropy_with_logits\"", ",", "\n", "values", "=", "[", "logits", ",", "labels", "]", ")", ":", "\n", "\n", "#labels = tf.reshape(labels, [-1])", "\n", "\n", "# label smoothing", "\n", "        ", "vocab_size", "=", "tf", ".", "shape", "(", "logits", ")", "[", "1", "]", "\n", "#print(\"vocab_size\", tf.shape(vocab_size))", "\n", "#print(\"logits\", tf.shape(logits))", "\n", "#print(\"labels\", tf.shape(labels))", "\n", "#print(\"tes\", tf.shape(tes))", "\n", "\n", "multi_one_hot", "=", "tf", ".", "map_fn", "(", "lambda", "x", ":", "tf", ".", "one_hot", "(", "tf", ".", "cast", "(", "x", ",", "tf", ".", "int32", ")", ",", "depth", "=", "vocab_size", ")", ",", "labels", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "soft_targets", "=", "tf", ".", "reduce_max", "(", "multi_one_hot", ",", "axis", "=", "1", ")", "\n", "\n", "#print(\"multi_one_hot:\", tf.shape(multi_one_hot))", "\n", "#print(\"soft_targets\", tf.shape(soft_targets))", "\n", "#code.interact(local=locals())", "\n", "\n", "\n", "\n", "xentropy", "=", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "logits", ",", "\n", "labels", "=", "soft_targets", ")", "\n", "return", "xentropy", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.losses.losses.bag_of_words_loss": [[92, 104], ["F.log_softmax", "target_bow.sum().view", "torch.log", "target_bow.sum"], "function", ["None"], ["", "", "def", "bag_of_words_loss", "(", "bow_logits", ",", "target_bow", ",", "weight", "=", "None", ")", ":", "\n", "    ", "''' Calculate bag of words representation loss\n    Args\n        - bow_logits: [num_sentences, vocab_size]\n        - target_bow: [num_sentences]\n    '''", "\n", "log_probs", "=", "F", ".", "log_softmax", "(", "bow_logits", ",", "dim", "=", "1", ")", "\n", "target_distribution", "=", "target_bow", "/", "(", "target_bow", ".", "sum", "(", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", "+", "1e-23", ")", "+", "1e-23", "\n", "entropy", "=", "-", "(", "torch", ".", "log", "(", "target_distribution", ")", "*", "target_bow", ")", ".", "sum", "(", ")", "\n", "loss", "=", "-", "(", "log_probs", "*", "target_bow", ")", ".", "sum", "(", ")", "-", "entropy", "\n", "\n", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.transform_xml.genrefxml": [[12, 31], ["xml.etree.ElementTree.Element", "xml.etree.ElementTree.ElementTree", "xml.etree.ElementTree.ElementTree.write", "xml.etree.ElementTree.SubElement", "xml.etree.ElementTree.SubElement", "xml.etree.ElementTree.SubElement", "xml.etree.ElementTree.SubElement", "str"], "function", ["None"], ["def", "genrefxml", "(", "reflists", ",", "setid", ",", "srclang", ",", "trglang", ")", ":", "\n", "    ", "mteval", "=", "Element", "(", "'mteval'", ")", "\n", "for", "reflist", "in", "reflists", ":", "\n", "        ", "sysid", "=", "reflist", "[", "0", "]", "\n", "set", "=", "SubElement", "(", "mteval", ",", "\"refset\"", ")", "\n", "set", ".", "attrib", "=", "{", "\"setid\"", ":", "setid", ",", "\"srclang\"", ":", "srclang", ",", "\"trglang\"", ":", "trglang", ",", "\"refid\"", ":", "sysid", "}", "\n", "doc", "=", "SubElement", "(", "set", ",", "\"doc\"", ")", "\n", "doc", ".", "attrib", "=", "{", "\"docid\"", ":", "\"doc1\"", "}", "\n", "\n", "i", "=", "0", "\n", "for", "sentence", "in", "reflist", ":", "\n", "            ", "if", "i", "!=", "0", ":", "\n", "                ", "p", "=", "SubElement", "(", "doc", ",", "\"p\"", ")", "\n", "seg", "=", "SubElement", "(", "p", ",", "\"seg\"", ")", "\n", "seg", ".", "attrib", "=", "{", "\"id\"", ":", "str", "(", "i", ")", "}", "\n", "seg", ".", "text", "=", "sentence", "\n", "", "i", "=", "i", "+", "1", "\n", "", "", "tree", "=", "ElementTree", "(", "mteval", ")", "\n", "tree", ".", "write", "(", "setid", "+", "'_ref.xml'", ",", "encoding", "=", "'utf-8'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.transform_xml.gentstxml": [[33, 52], ["xml.etree.ElementTree.Element", "xml.etree.ElementTree.ElementTree", "xml.etree.ElementTree.ElementTree.write", "xml.etree.ElementTree.SubElement", "xml.etree.ElementTree.SubElement", "xml.etree.ElementTree.SubElement", "xml.etree.ElementTree.SubElement", "str"], "function", ["None"], ["", "def", "gentstxml", "(", "tstlists", ",", "setid", ",", "srclang", ",", "trglang", ")", ":", "\n", "    ", "mteval", "=", "Element", "(", "'mteval'", ")", "\n", "for", "tstlist", "in", "tstlists", ":", "\n", "        ", "sysid", "=", "tstlist", "[", "0", "]", "\n", "set", "=", "SubElement", "(", "mteval", ",", "\"tstset\"", ")", "\n", "set", ".", "attrib", "=", "{", "\"setid\"", ":", "setid", ",", "\"srclang\"", ":", "srclang", ",", "\"trglang\"", ":", "trglang", ",", "\"sysid\"", ":", "sysid", "}", "\n", "doc", "=", "SubElement", "(", "set", ",", "\"doc\"", ")", "\n", "doc", ".", "attrib", "=", "{", "\"docid\"", ":", "\"doc1\"", "}", "\n", "\n", "i", "=", "0", "\n", "for", "sentence", "in", "tstlist", ":", "\n", "            ", "if", "i", "!=", "0", ":", "\n", "                ", "p", "=", "SubElement", "(", "doc", ",", "\"p\"", ")", "\n", "seg", "=", "SubElement", "(", "p", ",", "\"seg\"", ")", "\n", "seg", ".", "attrib", "=", "{", "\"id\"", ":", "str", "(", "i", ")", "}", "\n", "seg", ".", "text", "=", "sentence", "\n", "", "i", "=", "i", "+", "1", "\n", "", "", "tree", "=", "ElementTree", "(", "mteval", ")", "\n", "tree", ".", "write", "(", "setid", "+", "'_tst.xml'", ",", "encoding", "=", "'utf-8'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.transform_xml.gensrcxml": [[54, 70], ["xml.etree.ElementTree.Element", "xml.etree.ElementTree.SubElement", "xml.etree.ElementTree.SubElement", "xml.etree.ElementTree.ElementTree", "xml.etree.ElementTree.ElementTree.write", "xml.etree.ElementTree.SubElement", "xml.etree.ElementTree.SubElement", "str"], "function", ["None"], ["", "def", "gensrcxml", "(", "senlist", ",", "setid", ",", "srclang", ")", ":", "\n", "    ", "mteval", "=", "Element", "(", "'mteval'", ")", "\n", "set", "=", "SubElement", "(", "mteval", ",", "\"srcset\"", ")", "\n", "set", ".", "attrib", "=", "{", "\"setid\"", ":", "setid", ",", "\"srclang\"", ":", "srclang", "}", "\n", "doc", "=", "SubElement", "(", "set", ",", "\"doc\"", ")", "\n", "doc", ".", "attrib", "=", "{", "\"docid\"", ":", "\"doc1\"", "}", "\n", "\n", "i", "=", "1", "\n", "for", "sentence", "in", "senlist", ":", "\n", "        ", "p", "=", "SubElement", "(", "doc", ",", "\"p\"", ")", "\n", "seg", "=", "SubElement", "(", "p", ",", "\"seg\"", ")", "\n", "seg", ".", "attrib", "=", "{", "\"id\"", ":", "str", "(", "i", ")", "}", "\n", "seg", ".", "text", "=", "sentence", "\n", "i", "+=", "1", "\n", "", "tree", "=", "ElementTree", "(", "mteval", ")", "\n", "tree", ".", "write", "(", "setid", "+", "'_src.xml'", ",", "encoding", "=", "'utf-8'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.transform_xml.genxmltree": [[72, 108], ["print", "open", "transform_xml.gensrcxml", "transform_xml.gentstxml", "transform_xml.genrefxml", "line.strip.strip", "tstlist.append", "open", "tstslist.append", "reflist.append", "open", "reflists.append", "srclist.append", "str().strip", "line.strip.strip", "str().strip", "line.strip.strip", "tstlist.append", "reflist.append", "str", "str"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.transform_xml.gensrcxml", "home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.transform_xml.gentstxml", "home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.transform_xml.genrefxml"], ["", "def", "genxmltree", "(", "filetype", ",", "setid", ",", "srclang", ",", "trglang", ",", "files", ")", ":", "\n", "    ", "if", "filetype", "not", "in", "[", "\"src\"", ",", "\"tst\"", ",", "\"ref\"", "]", ":", "\n", "        ", "print", "(", "\"filetype is error\"", ")", "\n", "return", "\n", "\n", "", "if", "filetype", "==", "\"src\"", ":", "\n", "        ", "srclist", "=", "[", "]", "\n", "for", "line", "in", "open", "(", "files", "[", "0", "]", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ":", "\n", "                ", "srclist", ".", "append", "(", "line", ")", "\n", "", "", "gensrcxml", "(", "srclist", ",", "setid", ",", "srclang", ")", "\n", "\n", "", "if", "filetype", "==", "\"tst\"", ":", "\n", "        ", "tstslist", "=", "[", "]", "\n", "for", "tstfile", "in", "files", ":", "\n", "            ", "tstlist", "=", "[", "]", "\n", "tstlist", ".", "append", "(", "str", "(", "tstfile", ")", ".", "strip", "(", "'.txt'", ")", ")", "\n", "for", "line", "in", "open", "(", "tstfile", ")", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ":", "\n", "                    ", "tstlist", ".", "append", "(", "line", ")", "\n", "", "", "tstslist", ".", "append", "(", "tstlist", ")", "\n", "", "gentstxml", "(", "tstslist", ",", "setid", ",", "srclang", ",", "trglang", ")", "\n", "\n", "", "if", "filetype", "==", "\"ref\"", ":", "\n", "        ", "reflists", "=", "[", "]", "\n", "for", "reffile", "in", "files", ":", "\n", "            ", "reflist", "=", "[", "]", "\n", "reflist", ".", "append", "(", "str", "(", "reffile", ")", ".", "strip", "(", "'.txt'", ")", ")", "\n", "for", "line", "in", "open", "(", "reffile", ")", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ":", "\n", "                    ", "reflist", ".", "append", "(", "line", ")", "\n", "", "", "reflists", ".", "append", "(", "reflist", ")", "\n", "", "genrefxml", "(", "reflists", ",", "setid", ",", "srclang", ",", "trglang", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.train_word2vec.MySentences.__init__": [[9, 11], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dirname_list", ")", ":", "\n", "        ", "self", ".", "dirname_list", "=", "dirname_list", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.train_word2vec.MySentences.__iter__": [[12, 17], ["tk.tokenize"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "line", "in", "self", ".", "dirname_list", ":", "\n", "            ", "pieces", "=", "tk", ".", "tokenize", "(", "line", ")", "\n", "words", "=", "[", "w", "for", "w", "in", "pieces", "]", "\n", "yield", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.eval_coherence.bit_product_sum": [[7, 9], ["sum", "zip"], "function", ["None"], ["def", "bit_product_sum", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "sum", "(", "[", "item", "[", "0", "]", "*", "item", "[", "1", "]", "for", "item", "in", "zip", "(", "x", ",", "y", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.eval_coherence.cosine_similarity": [[11, 23], ["numpy.array", "len", "len", "float", "len", "sum", "float", "float", "numpy.sqrt", "numpy.sqrt", "range", "sum", "sum", "len"], "function", ["None"], ["", "def", "cosine_similarity", "(", "x", ",", "y", ",", "norm", "=", "True", ")", ":", "\n", "\n", "    ", "if", "len", "(", "x", ")", "!=", "len", "(", "y", ")", ":", "\n", "        ", "return", "float", "(", "0", ")", "\n", "", "zero_list", "=", "[", "0", "]", "*", "len", "(", "x", ")", "\n", "if", "x", "==", "zero_list", "or", "y", "==", "zero_list", ":", "\n", "        ", "return", "float", "(", "1", ")", "if", "x", "==", "y", "else", "float", "(", "0", ")", "\n", "\n", "", "res", "=", "np", ".", "array", "(", "[", "[", "x", "[", "i", "]", "*", "y", "[", "i", "]", ",", "x", "[", "i", "]", "*", "x", "[", "i", "]", ",", "y", "[", "i", "]", "*", "y", "[", "i", "]", "]", "for", "i", "in", "range", "(", "len", "(", "x", ")", ")", "]", ")", "\n", "cos", "=", "sum", "(", "res", "[", ":", ",", "0", "]", ")", "/", "(", "np", ".", "sqrt", "(", "sum", "(", "res", "[", ":", ",", "1", "]", ")", ")", "*", "np", ".", "sqrt", "(", "sum", "(", "res", "[", ":", ",", "2", "]", ")", ")", ")", "\n", "\n", "return", "0.5", "*", "cos", "+", "0.5", "if", "norm", "else", "cos", "\n", "\n"]], "home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.eval_coherence.read_embedding": [[24, 62], ["set", "set", "zip", "open", "ground_truth.append", "predict.append", "eval_coherence.cosine_similarity", "len", "line.strip().split", "set.add", "g.tolist", "p.tolist", "set.add", "numpy.array", "numpy.random.uniform", "len", "numpy.array", "numpy.random.uniform", "len", "line.strip"], "function", ["home.repos.pwc.inspect_result.xl2248_csa-nct.SacreBLEU_TER_Coherence_Evaluation_code.eval_coherence.cosine_similarity"], ["", "def", "read_embedding", "(", "word_list", ",", "golden_list", ",", "file_path", "=", "\"default_embedding_path\"", ",", "dimension_size", "=", "100", ",", "uniform_scale", "=", "0.25", ")", ":", "\n", "    ", "word2embed", "=", "{", "}", "\n", "with", "open", "(", "file_path", ",", "'r'", ")", "as", "fopen", ":", "\n", "        ", "for", "line", "in", "fopen", ":", "\n", "            ", "w", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "word2embed", "[", "' '", ".", "join", "(", "w", "[", ":", "-", "dimension_size", "]", ")", "]", "=", "w", "[", "-", "dimension_size", ":", "]", "\n", "", "", "word_vectors", "=", "[", "]", "\n", "\n", "ground_truth", "=", "[", "]", "\n", "cw", "=", "set", "(", ")", "\n", "g_set", "=", "set", "(", ")", "\n", "for", "line", "in", "golden_list", ":", "\n", "        ", "sentence_emb", "=", "0", "\n", "for", "word", "in", "line", ":", "\n", "            ", "g_set", ".", "add", "(", "word", ")", "\n", "if", "word", "in", "word2embed", ":", "\n", "                ", "cw", ".", "add", "(", "word", ")", "\n", "sentence_emb", "+=", "np", ".", "array", "(", "word2embed", "[", "word", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "                ", "sentence_emb", "+=", "np", ".", "random", ".", "uniform", "(", "-", "uniform_scale", ",", "uniform_scale", ",", "dimension_size", ")", "\n", "", "", "ground_truth", ".", "append", "(", "sentence_emb", "/", "len", "(", "line", ")", ")", "# sum sentence embedding", "\n", "\n", "", "c", "=", "0", "\n", "predict", "=", "[", "]", "\n", "for", "line", "in", "word_list", ":", "\n", "        ", "sentence_emb", "=", "0", "\n", "for", "word", "in", "line", ":", "\n", "            ", "if", "word", "in", "word2embed", ":", "\n", "                ", "c", "+=", "1", "\n", "sentence_emb", "+=", "np", ".", "array", "(", "word2embed", "[", "word", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "                ", "sentence_emb", "+=", "np", ".", "random", ".", "uniform", "(", "-", "uniform_scale", ",", "uniform_scale", ",", "dimension_size", ")", "\n", "", "", "predict", ".", "append", "(", "sentence_emb", "/", "len", "(", "line", ")", ")", "\n", "\n", "", "sim", "=", "0", "\n", "for", "g", ",", "p", "in", "zip", "(", "ground_truth", ",", "predict", ")", ":", "\n", "        ", "sim", "+=", "cosine_similarity", "(", "g", ".", "tolist", "(", ")", ",", "p", ".", "tolist", "(", ")", ")", "\n", "", "return", "sim", "/", "len", "(", "ground_truth", ")", "\n", "\n"]]}