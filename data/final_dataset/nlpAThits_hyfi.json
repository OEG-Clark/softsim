{"home.repos.pwc.inspect_result.nlpAThits_hyfi.None.export_embeds.main": [[25, 49], ["log.debug", "torch.load", "torch.load", "export_embeds.export_types", "export_embeds.export_position_embeddings", "log.info"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.None.export_embeds.export_types", "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.export_embeds.export_position_embeddings"], ["def", "main", "(", ")", ":", "\n", "    ", "log", ".", "debug", "(", "\"Loading data from '%s'.\"", "%", "args", ".", "data", ")", "\n", "data", "=", "torch", ".", "load", "(", "args", ".", "data", "+", "\"/data.pt\"", ")", "\n", "vocabs", "=", "data", "[", "\"vocabs\"", "]", "\n", "type_vocab", "=", "vocabs", "[", "cs", ".", "TYPE_VOCAB", "]", "\n", "token_vocab", "=", "vocabs", "[", "cs", ".", "TOKEN_VOCAB", "]", "\n", "\n", "state_dict", "=", "torch", ".", "load", "(", "args", ".", "export_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "\n", "# log.debug(\"Building model...\")", "\n", "# model = Model(args, vocabs)", "\n", "# model = DataParallel(model)", "\n", "# model.load_state_dict(state_dict)", "\n", "# model.to(cs.DEVICE)", "\n", "\n", "types", "=", "state_dict", "[", "\"module.classifier.p_k\"", "]", "\n", "export_types", "(", "types", ",", "type_vocab", ")", "\n", "\n", "pos_embeds", "=", "state_dict", "[", "\"module.hyper_attn.position_embeds\"", "]", "\n", "export_position_embeddings", "(", "pos_embeds", ")", "\n", "\n", "# word_lut = state_dict[\"module.word_lut\"]", "\n", "# export_words(word_lut, token_vocab)", "\n", "log", ".", "info", "(", "\"Done!!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.export_embeds.export_types": [[51, 68], ["range", "export_embeds.export", "export_embeds.export", "len", "type_vocab.get_label", "vecs.append", "meta.append", "args.export_path.split", "map", "types[].tolist"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.None.export_embeds.export", "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.export_embeds.export", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.get_label"], ["", "def", "export_types", "(", "types", ",", "type_vocab", ")", ":", "\n", "    ", "vecs", ",", "meta", "=", "[", "]", ",", "[", "\"label\\tgran\"", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "types", ")", ")", ":", "\n", "        ", "type_vec", "=", "\"\\t\"", ".", "join", "(", "map", "(", "str", ",", "types", "[", "i", "]", ".", "tolist", "(", ")", ")", ")", "\n", "type_label", "=", "type_vocab", ".", "get_label", "(", "i", ")", "\n", "if", "type_label", "in", "cs", ".", "COARSE", ":", "\n", "            ", "gran", "=", "\"coarse\"", "\n", "", "elif", "type_label", "in", "cs", ".", "FINE", ":", "\n", "            ", "gran", "=", "\"fine\"", "\n", "", "else", ":", "\n", "            ", "gran", "=", "\"ultra\"", "\n", "\n", "", "vecs", ".", "append", "(", "type_vec", ")", "\n", "meta", ".", "append", "(", "f\"{type_label}\\t{gran}\"", ")", "\n", "", "export_name", "=", "args", ".", "export_path", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "export", "(", "f\"export/{export_name}-pk-vecs.tsv\"", ",", "vecs", ")", "\n", "export", "(", "f\"export/{export_name}-pk-meta.tsv\"", ",", "meta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.export_embeds.export_position_embeddings": [[70, 81], ["range", "export_embeds.export", "export_embeds.export", "len", "vecs.append", "meta.append", "args.export_path.split", "map", "str", "pos_embeds[].tolist"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.None.export_embeds.export", "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.export_embeds.export"], ["", "def", "export_position_embeddings", "(", "pos_embeds", ")", ":", "\n", "    ", "vecs", ",", "meta", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "pos_embeds", ")", ")", ":", "\n", "        ", "embed", "=", "\"\\t\"", ".", "join", "(", "map", "(", "str", ",", "pos_embeds", "[", "i", "]", ".", "tolist", "(", ")", ")", ")", "\n", "\n", "vecs", ".", "append", "(", "embed", ")", "\n", "meta", ".", "append", "(", "str", "(", "i", ")", ")", "\n", "\n", "", "export_name", "=", "args", ".", "export_path", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "export", "(", "f\"export/{export_name}-pos_embeds.tsv\"", ",", "vecs", ")", "\n", "export", "(", "f\"export/{export_name}-pos_embeds-meta.tsv\"", ",", "meta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.export_embeds.export_words": [[83, 99], ["min", "range", "export_embeds.export", "export_embeds.export", "token_vocab.size_of_word2vecs", "token_vocab.get_label", "vecs.append", "meta.append", "args.export_path.split", "map", "word_lut[].tolist"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.None.export_embeds.export", "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.export_embeds.export", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TokenDict.size_of_word2vecs", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.get_label"], ["", "def", "export_words", "(", "word_lut", ",", "token_vocab", ")", ":", "\n", "    ", "if", "args", ".", "words", "<=", "0", ":", "\n", "        ", "return", "\n", "\n", "", "word_limit", "=", "min", "(", "args", ".", "words", ",", "token_vocab", ".", "size_of_word2vecs", "(", ")", ")", "\n", "\n", "vecs", ",", "meta", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "word_limit", ")", ":", "\n", "        ", "word_vec", "=", "\"\\t\"", ".", "join", "(", "map", "(", "str", ",", "word_lut", "[", "i", "]", ".", "tolist", "(", ")", ")", ")", "\n", "word_label", "=", "token_vocab", ".", "get_label", "(", "i", ")", "\n", "\n", "vecs", ".", "append", "(", "word_vec", ")", "\n", "meta", ".", "append", "(", "word_label", ")", "\n", "", "export_name", "=", "args", ".", "export_path", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "export", "(", "f\"export/{export_name}-wordsvecs.tsv\"", ",", "vecs", ")", "\n", "export", "(", "f\"export/{export_name}-wordsmeta.tsv\"", ",", "meta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.export_embeds.export": [[101, 105], ["open", "fp.write"], "function", ["None"], ["", "def", "export", "(", "path", ",", "data", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"w\"", ")", "as", "fp", ":", "\n", "        ", "for", "res", "in", "data", ":", "\n", "            ", "fp", ".", "write", "(", "res", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.train.config_parser": [[16, 53], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["def", "config_parser", "(", "parser", ")", ":", "\n", "# Data options", "\n", "    ", "parser", ".", "add_argument", "(", "\"--data\"", ",", "required", "=", "True", ",", "type", "=", "str", ",", "help", "=", "\"Data path.\"", ")", "\n", "\n", "# Sentence-level context parameters", "\n", "parser", ".", "add_argument", "(", "\"--men_nonlin\"", ",", "default", "=", "\"tanh\"", ",", "type", "=", "str", ",", "help", "=", "\"Non-linearity in mention encoder\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--ctx_nonlin\"", ",", "default", "=", "\"tanh\"", ",", "type", "=", "str", ",", "help", "=", "\"Non-linearity in context encoder\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_layers\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "\"Number of layers in MobiusGRU\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--space_dims\"", ",", "default", "=", "20", ",", "type", "=", "int", ",", "help", "=", "\"Space dims.\"", ")", "\n", "\n", "# Component metrics", "\n", "parser", ".", "add_argument", "(", "\"--embedding_metric\"", ",", "default", "=", "cs", ".", "HY", ",", "type", "=", "str", ",", "help", "=", "\"hyperbolic | euclidean\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--encoder_metric\"", ",", "default", "=", "cs", ".", "HY", ",", "type", "=", "str", ",", "help", "=", "\"hyperbolic | euclidean\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--attn_metric\"", ",", "default", "=", "cs", ".", "HY", ",", "type", "=", "str", ",", "help", "=", "\"hyperbolic | euclidean\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--concat_metric\"", ",", "default", "=", "cs", ".", "HY", ",", "type", "=", "str", ",", "help", "=", "\"hyperbolic | euclidean\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mlr_metric\"", ",", "default", "=", "cs", ".", "HY", ",", "type", "=", "str", ",", "help", "=", "\"hyperbolic | euclidean\"", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--input_dropout\"", ",", "default", "=", "0.3", ",", "type", "=", "float", ",", "help", "=", "\"Dropout over input.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--concat_dropout\"", ",", "default", "=", "0.2", ",", "type", "=", "float", ",", "help", "=", "\"Dropout in concat.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--classif_dropout\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Dropout in classifier.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--crowd_cycles\"", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "\"Number of crowd re-train.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "0.0005", ",", "type", "=", "float", ",", "help", "=", "\"Starting learning rate.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.00", ",", "type", "=", "float", ",", "help", "=", "\"L2 Regularization.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "default", "=", "900", ",", "type", "=", "int", ",", "help", "=", "\"Batch size.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "default", "=", "30", ",", "type", "=", "int", ",", "help", "=", "\"Number of training epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"If the norm of the gradient vector exceeds this, renormalize it to max_grad_norm\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--patience\"", ",", "default", "=", "50", ",", "type", "=", "int", ",", "help", "=", "\"Patience for lr scheduler\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--export_path\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Name of model to export\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--export_epochs\"", ",", "default", "=", "20", ",", "type", "=", "int", ",", "help", "=", "\"Export every n epochs\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_epochs\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Log examples every n epochs\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--load_model\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Path of model to load\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_word_embeds\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Wether to train word embeds or not\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"Seed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--c\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"c param to project embeddings\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--attn\"", ",", "default", "=", "\"softmax\"", ",", "type", "=", "str", ",", "help", "=", "\"Options: sigmoid | softmax\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.train.get_dataset": [[66, 72], ["dataset.set_batch_size", "dataset.shuffle"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.set_batch_size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.shuffle"], ["def", "get_dataset", "(", "data", ",", "args", ",", "key", ")", ":", "\n", "    ", "dataset", "=", "data", "[", "key", "]", "\n", "dataset", ".", "set_batch_size", "(", "args", ".", "batch_size", ")", "\n", "dataset", ".", "shuffle", "(", ")", "\n", "dataset", ".", "device", "=", "cs", ".", "DEVICE", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.train.main": [[74, 127], ["log.debug", "torch.load", "train.get_dataset", "train.get_dataset", "train.get_dataset", "train.get_dataset", "get_dataset.get_mention_len", "get_dataset.get_context_len", "log.info", "torch.nn.DataParallel.to", "geoopt.optim.RiemannianAdam", "torch.optim.lr_scheduler.ReduceLROnPlateau", "sum", "log.debug", "hyfi.runner.Runner", "log.info", "hyfi.runner.Runner.train", "log.info", "log.debug", "torch.load", "torch.load.size", "hyfi.models.define_mapping", "log.debug", "log.debug", "hyfi.models.Model", "torch.nn.DataParallel", "log.debug", "torch.load", "state_dict[].size", "hyfi.models.Model", "torch.nn.DataParallel", "torch.nn.DataParallel.load_state_dict", "torch.nn.DataParallel.parameters", "hyfi.models.define_mapping.", "p.nelement", "torch.cuda.device_count", "torch.nn.DataParallel.parameters"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.None.train.get_dataset", "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.train.get_dataset", "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.train.get_dataset", "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.train.get_dataset", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.get_mention_len", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.get_context_len", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.train", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.define_mapping", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "def", "main", "(", ")", ":", "\n", "# Load data.", "\n", "    ", "log", ".", "debug", "(", "f\"Loading data from {args.data }/data.pt\"", ")", "\n", "data", "=", "torch", ".", "load", "(", "args", ".", "data", "+", "\"/data.pt\"", ")", "\n", "vocabs", "=", "data", "[", "\"vocabs\"", "]", "\n", "\n", "# dataset splits", "\n", "train_data", "=", "get_dataset", "(", "data", ",", "args", ",", "\"train\"", ")", "\n", "crowd_train_data", "=", "get_dataset", "(", "data", ",", "args", ",", "\"crowd_train\"", ")", "\n", "dev_data", "=", "get_dataset", "(", "data", ",", "args", ",", "\"dev\"", ")", "\n", "test_data", "=", "get_dataset", "(", "data", ",", "args", ",", "\"test\"", ")", "\n", "\n", "args", ".", "mention_len", "=", "train_data", ".", "get_mention_len", "(", ")", "\n", "args", ".", "context_len", "=", "train_data", ".", "get_context_len", "(", ")", "\n", "\n", "if", "not", "args", ".", "load_model", ":", "\n", "        ", "log", ".", "debug", "(", "f\"Loading word2vec from {args.data}/word2vec.pt\"", ")", "\n", "word2vec", "=", "torch", ".", "load", "(", "args", ".", "data", "+", "\"/word2vec.pt\"", ")", "\n", "args", ".", "word_emb_size", "=", "word2vec", ".", "size", "(", "1", ")", "\n", "\n", "embed_mapping", "=", "define_mapping", "(", "args", ".", "embedding_metric", ",", "args", ".", "encoder_metric", ",", "args", ".", "c", ")", "\n", "log", ".", "debug", "(", "f\"Embed mapping: Applying {embed_mapping} with c={args.c}\"", ")", "\n", "\n", "log", ".", "debug", "(", "\"Building model...\"", ")", "\n", "model", "=", "Model", "(", "args", ",", "vocabs", ",", "embed_mapping", "(", "word2vec", ")", ")", "\n", "model", "=", "DataParallel", "(", "model", ")", "\n", "\n", "", "else", ":", "\n", "        ", "log", ".", "debug", "(", "f\"Loading model from {args.load_model}\"", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "args", ".", "load_model", ")", "\n", "args", ".", "word_emb_size", "=", "state_dict", "[", "\"module.word_lut\"", "]", ".", "size", "(", "1", ")", "\n", "\n", "model", "=", "Model", "(", "args", ",", "vocabs", ")", "\n", "model", "=", "DataParallel", "(", "model", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "", "log", ".", "info", "(", "f\"GPU's available: {torch.cuda.device_count()}\"", ")", "\n", "model", ".", "to", "(", "cs", ".", "DEVICE", ")", "\n", "\n", "optim", "=", "gt", ".", "optim", ".", "RiemannianAdam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "learning_rate", ",", "weight_decay", "=", "args", ".", "weight_decay", ",", "\n", "stabilize", "=", "5", ")", "\n", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optim", ",", "mode", "=", "'max'", ",", "factor", "=", "0.5", ",", "patience", "=", "args", ".", "patience", ",", "\n", "verbose", "=", "True", ")", "\n", "\n", "n_params", "=", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", ")", "\n", "log", ".", "debug", "(", "f\"Number of parameters: {n_params}\"", ")", "\n", "\n", "runner", "=", "Runner", "(", "model", ",", "optim", ",", "scheduler", ",", "vocabs", ",", "train_data", ",", "crowd_train_data", ",", "dev_data", ",", "test_data", ",", "args", ")", "\n", "\n", "# Train.", "\n", "log", ".", "info", "(", "\"Start training...\"", ")", "\n", "runner", ".", "train", "(", ")", "\n", "log", ".", "info", "(", "\"Done!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.infer.main": [[21, 49], ["log.debug", "torch.load", "train.get_dataset", "train.get_dataset", "torch.load", "state_dict[].size", "train.get_dataset.get_mention_len", "train.get_dataset.get_context_len", "log.debug", "hyfi.models.Model", "torch.nn.DataParallel", "torch.nn.DataParallel.load_state_dict", "torch.nn.DataParallel.to", "hyfi.runner.Runner", "log.info", "hyfi.runner.Runner.instance_printer.show", "hyfi.runner.Runner.print_full_validation", "log.info", "hyfi.runner.Runner.instance_printer.show", "hyfi.runner.Runner.print_full_validation"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.None.train.get_dataset", "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.train.get_dataset", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.get_mention_len", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.get_context_len", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.instance_printer.InstancePrinter.show", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.print_full_validation", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.instance_printer.InstancePrinter.show", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.print_full_validation"], ["def", "main", "(", ")", ":", "\n", "    ", "log", ".", "debug", "(", "\"Loading data from '%s'.\"", "%", "args", ".", "data", ")", "\n", "data", "=", "torch", ".", "load", "(", "args", ".", "data", "+", "\"/data.pt\"", ")", "\n", "vocabs", "=", "data", "[", "\"vocabs\"", "]", "\n", "\n", "dev_data", "=", "get_dataset", "(", "data", ",", "args", ",", "\"dev\"", ")", "\n", "test_data", "=", "get_dataset", "(", "data", ",", "args", ",", "\"test\"", ")", "\n", "\n", "state_dict", "=", "torch", ".", "load", "(", "args", ".", "export_path", ")", "\n", "args", ".", "word_emb_size", "=", "state_dict", "[", "\"module.word_lut\"", "]", ".", "size", "(", "1", ")", "\n", "args", ".", "mention_len", "=", "dev_data", ".", "get_mention_len", "(", ")", "\n", "args", ".", "context_len", "=", "dev_data", ".", "get_context_len", "(", ")", "\n", "\n", "log", ".", "debug", "(", "\"Building model...\"", ")", "\n", "model", "=", "Model", "(", "args", ",", "vocabs", ")", "\n", "model", "=", "DataParallel", "(", "model", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "model", ".", "to", "(", "DEVICE", ")", "\n", "\n", "runner", "=", "Runner", "(", "model", ",", "None", ",", "None", ",", "vocabs", ",", "None", ",", "None", ",", "dev_data", ",", "test_data", ",", "args", ")", "\n", "\n", "log", ".", "info", "(", "\"INFERENCE ON DEV DATA:\"", ")", "\n", "runner", ".", "instance_printer", ".", "show", "(", "dev_data", ")", "\n", "runner", ".", "print_full_validation", "(", "dev_data", ",", "\"DEV\"", ")", "\n", "\n", "log", ".", "info", "(", "\"\\n\\nINFERENCE ON TEST DATA:\"", ")", "\n", "runner", ".", "instance_printer", ".", "show", "(", "test_data", ")", "\n", "runner", ".", "print_full_validation", "(", "test_data", ",", "\"TEST\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.Word2Vec.__init__": [[29, 31], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "token2vec", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.Word2Vec.add": [[32, 34], ["None"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "token", ",", "vector", ")", ":", "\n", "        ", "self", ".", "token2vec", "[", "token", "]", "=", "vector", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.Word2Vec.get_vec": [[35, 42], ["preprocess.Word2Vec.get_unk_vector", "word.lower", "word.lower"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.Word2Vec.get_unk_vector"], ["", "def", "get_vec", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "word", "in", "self", ".", "token2vec", ":", "\n", "            ", "return", "self", ".", "token2vec", "[", "word", "]", "\n", "", "if", "word", ".", "lower", "(", ")", "in", "self", ".", "token2vec", ":", "\n", "            ", "return", "self", ".", "token2vec", "[", "word", ".", "lower", "(", ")", "]", "\n", "\n", "", "return", "self", ".", "get_unk_vector", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.Word2Vec.__contains__": [[43, 45], ["word.lower"], "methods", ["None"], ["", "def", "__contains__", "(", "self", ",", "word", ")", ":", "\n", "        ", "return", "word", "in", "self", ".", "token2vec", "or", "word", ".", "lower", "(", ")", "in", "self", ".", "token2vec", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.Word2Vec.get_unk_vector": [[46, 48], ["None"], "methods", ["None"], ["", "def", "get_unk_vector", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "token2vec", "[", "UNK_WORD", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.make_vocabs": [[50, 80], ["hyfi.TokenDict", "hyfi.TypeDict", "tqdm.tqdm", "tqdm.tqdm.close", "hyfi.Dict", "hyfi.Dict.add", "log.info", "os.path.join", "open", "hyfi.Dict.add", "hyfi.utils.wc", "tqdm.tqdm.update", "hyfi.utils.process_line", "hyfi.TokenDict.size", "hyfi.TypeDict.size", "hyfi.Dict.size", "hyfi.TokenDict.add", "hyfi.TypeDict.add"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.add", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.add", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.utils.wc", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.utils.process_line", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.add", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.add"], ["", "", "def", "make_vocabs", "(", "args", ")", ":", "\n", "    ", "\"\"\"It creates a Dict for the words on the whole dataset, and the types\"\"\"", "\n", "token_vocab", "=", "hyfi", ".", "TokenDict", "(", "lower", "=", "True", ")", "\n", "type_vocab", "=", "hyfi", ".", "TypeDict", "(", ")", "\n", "\n", "all_files", "=", "[", "path", ".", "join", "(", "args", ".", "dataset", ",", "fpath", ")", "for", "fpath", "in", "[", "EL_TRAIN", ",", "HW_TRAIN", ",", "CR_TRAIN", ",", "CR_DEV", ",", "CR_TEST", "]", "]", "\n", "bar", "=", "tqdm", "(", "desc", "=", "\"make_vocabs\"", ",", "total", "=", "hyfi", ".", "utils", ".", "wc", "(", "all_files", ")", ")", "\n", "for", "data_file", "in", "all_files", ":", "\n", "        ", "for", "line", "in", "open", "(", "data_file", ",", "buffering", "=", "BUFFER_SIZE", ")", ":", "\n", "            ", "bar", ".", "update", "(", ")", "\n", "\n", "fields", ",", "tokens", "=", "process_line", "(", "line", ")", "\n", "\n", "for", "token", "in", "tokens", ":", "\n", "                ", "token_vocab", ".", "add", "(", "token", ")", "\n", "\n", "", "for", "mention_type", "in", "fields", "[", "TYPE", "]", ":", "\n", "                ", "type_vocab", ".", "add", "(", "mention_type", ")", "\n", "\n", "", "", "", "bar", ".", "close", "(", ")", "\n", "\n", "char_vocab", "=", "hyfi", ".", "Dict", "(", ")", "\n", "char_vocab", ".", "add", "(", "UNK_WORD", ")", "\n", "for", "char", "in", "CHARS", ":", "\n", "        ", "char_vocab", ".", "add", "(", "char", ")", "\n", "\n", "", "log", ".", "info", "(", "\"Created vocabs:\\n\\t#token: {}\\n\\t#type: {}\\n\\t#chars: {}\"", ".", "format", "(", "token_vocab", ".", "size", "(", ")", ",", "type_vocab", ".", "size", "(", ")", ",", "\n", "char_vocab", ".", "size", "(", ")", ")", ")", "\n", "\n", "return", "{", "TOKEN_VOCAB", ":", "token_vocab", ",", "TYPE_VOCAB", ":", "type_vocab", ",", "CHAR_VOCAB", ":", "char_vocab", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.make_word2vec": [[82, 128], ["preprocess.Word2Vec", "log.info", "tqdm.tqdm", "torch.stack.append", "range", "torch.stack", "log.info", "log.info", "log.info", "open", "line.strip().split", "torch.Tensor", "preprocess.Word2Vec.add", "torch.zeros", "token_vocab.size", "hyfi.utils.wc", "list", "Word2Vec.get_unk_vector().size", "preprocess.Word2Vec.get_vec", "len", "torch.stack.append", "line.strip", "len", "map", "len", "log.info", "torch.stack.norm", "map", "preprocess.Word2Vec.get_unk_vector", "list", "torch.stack.size"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.add", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.utils.wc", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.Word2Vec.get_vec", "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.Word2Vec.get_unk_vector", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "def", "make_word2vec", "(", "filepath", ",", "token_vocab", ")", ":", "\n", "    ", "word2vec", "=", "Word2Vec", "(", ")", "\n", "log", ".", "info", "(", "f\"Start loading pretrained word vecs from {filepath}\"", ")", "\n", "for", "line", "in", "tqdm", "(", "open", "(", "filepath", ")", ",", "total", "=", "hyfi", ".", "utils", ".", "wc", "(", "filepath", ")", ")", ":", "\n", "        ", "fields", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "embed_dim", "=", "100", "if", "len", "(", "fields", ")", "<", "200", "else", "300", "\n", "token", "=", "fields", "[", "0", "]", "\n", "try", ":", "\n", "            ", "vec", "=", "list", "(", "map", "(", "float", ",", "fields", "[", "1", ":", "]", ")", ")", "\n", "if", "len", "(", "vec", ")", "!=", "embed_dim", ":", "\n", "                ", "raise", "ValueError", "\n", "", "", "except", "ValueError", ":", "\n", "            ", "log", ".", "info", "(", "f\"Wrong parse: {token}\"", ")", "\n", "continue", "\n", "\n", "", "embedding", "=", "torch", ".", "Tensor", "(", "vec", ")", "\n", "\n", "if", "token", "==", "UNK_WORD", ":", "\n", "            ", "embedding", "/=", "10", "\n", "\n", "", "word2vec", ".", "add", "(", "token", ",", "embedding", ")", "\n", "\n", "", "ret", "=", "[", "]", "\n", "oov", "=", "0", "\n", "\n", "# PAD word (index 0) is a vector full of zeros", "\n", "ret", ".", "append", "(", "torch", ".", "zeros", "(", "word2vec", ".", "get_unk_vector", "(", ")", ".", "size", "(", ")", ")", ")", "\n", "token_vocab", ".", "label2wordvec_idx", "[", "hyfi", ".", "constants", ".", "PAD_WORD", "]", "=", "0", "\n", "\n", "for", "idx", "in", "range", "(", "1", ",", "token_vocab", ".", "size", "(", ")", ")", ":", "\n", "        ", "token", "=", "token_vocab", ".", "idx2label", "[", "idx", "]", "\n", "\n", "if", "token", "in", "word2vec", ":", "\n", "            ", "vec", "=", "word2vec", ".", "get_vec", "(", "token", ")", "\n", "token_vocab", ".", "label2wordvec_idx", "[", "token", "]", "=", "len", "(", "ret", ")", "\n", "ret", ".", "append", "(", "vec", ")", "\n", "", "else", ":", "\n", "            ", "oov", "+=", "1", "\n", "\n", "", "", "ret", "=", "torch", ".", "stack", "(", "ret", ")", "# creates a \"matrix\" of token.size() x embed_dim", "\n", "\n", "norm_bigger_than_one", "=", "(", "ret", ".", "norm", "(", "dim", "=", "1", ")", ">", "1", ")", ".", "sum", "(", ")", "\n", "log", ".", "info", "(", "f\"Amount of word embeddings with norm > 1: {norm_bigger_than_one}\"", ")", "\n", "log", ".", "info", "(", "\"* OOV count: %d\"", "%", "oov", ")", "\n", "log", ".", "info", "(", "\"* Embedding size (%s)\"", "%", "(", "\", \"", ".", "join", "(", "map", "(", "str", ",", "list", "(", "ret", ".", "size", "(", ")", ")", ")", ")", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.make_data": [[130, 147], ["log.info", "hyfi.Dataset", "log.info", "hyfi.Dataset.to_matrix", "os.path.join", "tqdm.tqdm", "open", "hyfi.utils.process_line", "hyfi.Mention", "data.append", "hyfi.utils.wc", "len", "len"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.to_matrix", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.utils.process_line", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.utils.wc"], ["", "def", "make_data", "(", "data_files", ",", "vocabs", ",", "type_quantity", ",", "args", ")", ":", "\n", "    ", "data", "=", "[", "]", "\n", "for", "fname", "in", "data_files", ":", "\n", "        ", "file_path", "=", "path", ".", "join", "(", "args", ".", "dataset", ",", "fname", ")", "\n", "for", "line", "in", "tqdm", "(", "open", "(", "file_path", ",", "buffering", "=", "BUFFER_SIZE", ")", ",", "total", "=", "hyfi", ".", "utils", ".", "wc", "(", "file_path", ")", ")", ":", "\n", "            ", "fields", ",", "_", "=", "process_line", "(", "line", ")", "\n", "\n", "mention", "=", "hyfi", ".", "Mention", "(", "fields", ")", "\n", "data", ".", "append", "(", "mention", ")", "\n", "\n", "", "", "log", ".", "info", "(", "f\"Prepared {len(data)} mentions.\"", ")", "\n", "dataset", "=", "hyfi", ".", "Dataset", "(", "data", ",", "args", ",", "type_quantity", ")", "\n", "\n", "log", ".", "info", "(", "f\"Transforming to matrix {len(data)} mentions from {data_files}\"", ")", "\n", "dataset", ".", "to_matrix", "(", "vocabs", ",", "args", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.main": [[149, 172], ["log.info", "preprocess.make_vocabs", "len", "log.info", "preprocess.make_word2vec", "log.info", "preprocess.make_data", "log.info", "preprocess.make_data", "log.info", "preprocess.make_data", "log.info", "preprocess.make_data", "log.info", "torch.save", "log.info", "torch.save"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.make_vocabs", "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.make_word2vec", "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.make_data", "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.make_data", "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.make_data", "home.repos.pwc.inspect_result.nlpAThits_hyfi.None.preprocess.make_data"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "log", ".", "info", "(", "\"Preparing vocabulary...\"", ")", "\n", "vocabs", "=", "make_vocabs", "(", "args", ")", "\n", "type_quantity", "=", "len", "(", "vocabs", "[", "TYPE_VOCAB", "]", ".", "label2idx", ")", "\n", "\n", "log", ".", "info", "(", "\"Preparing word vectors...\"", ")", "\n", "word2vec", "=", "make_word2vec", "(", "args", ".", "word2vec", ",", "vocabs", "[", "TOKEN_VOCAB", "]", ")", "\n", "\n", "log", ".", "info", "(", "\"Preparing training...\"", ")", "\n", "train", "=", "make_data", "(", "[", "CR_TRAIN", ",", "EL_TRAIN", ",", "HW_TRAIN", "]", ",", "vocabs", ",", "type_quantity", ",", "args", ")", "\n", "log", ".", "info", "(", "\"Preparing crowd training...\"", ")", "\n", "crowd_train", "=", "make_data", "(", "[", "CR_TRAIN", "]", ",", "vocabs", ",", "type_quantity", ",", "args", ")", "\n", "log", ".", "info", "(", "\"Preparing dev...\"", ")", "\n", "dev", "=", "make_data", "(", "[", "CR_DEV", "]", ",", "vocabs", ",", "type_quantity", ",", "args", ")", "\n", "log", ".", "info", "(", "\"Preparing test...\"", ")", "\n", "test", "=", "make_data", "(", "[", "CR_TEST", "]", ",", "vocabs", ",", "type_quantity", ",", "args", ")", "\n", "\n", "log", ".", "info", "(", "\"Saving pretrained word vectors to '%s'...\"", "%", "(", "args", ".", "save_data", "+", "\"/word2vec.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "word2vec", ",", "args", ".", "save_data", "+", "\"/word2vec.pt\"", ")", "\n", "\n", "log", ".", "info", "(", "\"Saving data to '%s'...\"", "%", "(", "args", ".", "save_data", "+", "\"/data.pt\"", ")", ")", "\n", "save_data", "=", "{", "\"vocabs\"", ":", "vocabs", ",", "\"train\"", ":", "train", ",", "\"crowd_train\"", ":", "crowd_train", ",", "\"dev\"", ":", "dev", ",", "\"test\"", ":", "test", "}", "\n", "torch", ".", "save", "(", "save_data", ",", "args", ".", "save_data", "+", "\"/data.pt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.instance_printer.InstancePrinter.__init__": [[37, 45], ["instance_printer.InstancePrinter.type_vocab.get_coarse_ids().union", "torch.nn.Sigmoid", "instance_printer.InstancePrinter.type_vocab.get_fine_ids", "instance_printer.InstancePrinter.type_vocab.get_coarse_ids"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TypeDict.get_fine_ids", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TypeDict.get_coarse_ids"], ["    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "model", ")", ":", "\n", "        ", "self", ".", "token_vocab", "=", "vocabs", "[", "TOKEN_VOCAB", "]", "\n", "self", ".", "type_vocab", "=", "vocabs", "[", "TYPE_VOCAB", "]", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "coarse_matrixes", "=", "[", "{", "self", ".", "type_vocab", ".", "label2idx", "[", "label", "]", ":", "[", "0", ",", "0", ",", "0", "]", "for", "label", "in", "COARSE", "\n", "if", "label", "in", "self", ".", "type_vocab", ".", "label2idx", "}", "for", "_", "in", "[", "COARSE_FLAG", ",", "FINE_FLAG", ",", "UF_FLAG", "]", "]", "\n", "self", ".", "co_fi_ids", "=", "self", ".", "type_vocab", ".", "get_coarse_ids", "(", ")", ".", "union", "(", "self", ".", "type_vocab", ".", "get_fine_ids", "(", ")", ")", "\n", "self", ".", "sigmoid", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.instance_printer.InstancePrinter.show": [[46, 70], ["instance_printer.InstancePrinter.print_results", "len", "torch.no_grad", "range", "len", "instance_printer.InstancePrinter.model", "instance_printer.InstancePrinter.sigmoid", "hyfi.predictor.assign_types", "instance_printer.get_score", "to_show.append", "len"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.instance_printer.InstancePrinter.print_results", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.predictor.assign_types", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.instance_printer.get_score"], ["", "def", "show", "(", "self", ",", "data", ",", "n", "=", "99999999", ")", ":", "\n", "        ", "to_show", "=", "[", "]", "\n", "show_per_batch", "=", "n", "/", "len", "(", "data", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch_index", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "                ", "batch", "=", "data", "[", "batch_index", "]", "\n", "type_indexes", ",", "one_hot_true_types", "=", "batch", "[", "-", "2", "]", ",", "batch", "[", "6", "]", "\n", "\n", "logits", ",", "attn_weights", ",", "_", "=", "self", ".", "model", "(", "batch", ")", "\n", "probability_predictions", "=", "self", ".", "sigmoid", "(", "logits", ")", "\n", "partial_result", "=", "assign_types", "(", "probability_predictions", ",", "type_indexes", ")", "\n", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "partial_result", ")", "and", "i", "<", "show_per_batch", ":", "\n", "                    ", "truth", ",", "predicted", "=", "partial_result", "[", "i", "]", "\n", "score", "=", "get_score", "(", "truth", ",", "predicted", ")", "\n", "attn", "=", "attn_weights", "[", "i", "]", "if", "attn_weights", "is", "not", "None", "else", "None", "\n", "# score, mention_idx, ctx, attn, true, predicted", "\n", "to_show", ".", "append", "(", "[", "score", ",", "batch", "[", "3", "]", "[", "i", "]", ",", "batch", "[", "0", "]", "[", "i", "]", ",", "attn", ",", "truth", ",", "predicted", "]", ")", "\n", "i", "+=", "1", "\n", "\n", "# self.update_coarse_matrixes(partial_result)", "\n", "\n", "", "", "", "self", ".", "print_results", "(", "to_show", ")", "\n", "# self.print_coarse_matrix()", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.instance_printer.InstancePrinter.print_results": [[72, 94], ["sorted", "instance_printer.stratify", "instance_printer.stratify", "log.debug", "operator.itemgetter", "zip", "ctx_ids.tolist", "instance_printer.InstancePrinter.token_vocab.get_label_from_word2vec_id", "ctx_ids.tolist", "attn_weights.tolist", "instance_printer.InstancePrinter.type_vocab.get_label", "instance_printer.InstancePrinter.type_vocab.get_label", "instance_printer.InstancePrinter.type_vocab.get_label", "instance_printer.InstancePrinter.type_vocab.get_label", "i.item", "instance_printer.InstancePrinter.token_vocab.get_label_from_word2vec_id", "instance_printer.InstancePrinter.token_vocab.get_label_from_word2vec_id"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.stratify", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.stratify", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TokenDict.get_label_from_word2vec_id", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.get_label", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.get_label", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.get_label", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.get_label", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TokenDict.get_label_from_word2vec_id", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TokenDict.get_label_from_word2vec_id"], ["", "def", "print_results", "(", "self", ",", "to_show", ")", ":", "\n", "        ", "unk", "=", "\"@\"", "\n", "to_show", "=", "sorted", "(", "to_show", ",", "key", "=", "itemgetter", "(", "0", ")", ",", "reverse", "=", "True", ")", "\n", "for", "score", ",", "mention", ",", "ctx_ids", ",", "attn_weights", ",", "true", ",", "predicted", "in", "to_show", ":", "\n", "            ", "mention_words", "=", "\" \"", ".", "join", "(", "[", "self", ".", "token_vocab", ".", "get_label_from_word2vec_id", "(", "i", ".", "item", "(", ")", ",", "unk", ")", "for", "i", "in", "mention", "if", "i", "!=", "0", "]", ")", "\n", "\n", "if", "attn_weights", "is", "not", "None", ":", "\n", "                ", "ctx", "=", "zip", "(", "ctx_ids", ".", "tolist", "(", ")", ",", "attn_weights", ".", "tolist", "(", ")", ")", "\n", "ctx_words", "=", "\" \"", ".", "join", "(", "[", "f\"{self.token_vocab.get_label_from_word2vec_id(idx, unk)}({weight * 100:0.2f})\"", "for", "idx", ",", "weight", "in", "ctx", "]", ")", "\n", "", "else", ":", "\n", "                ", "ctx", "=", "ctx_ids", ".", "tolist", "(", ")", "\n", "ctx_words", "=", "\" \"", ".", "join", "(", "[", "f\"{self.token_vocab.get_label_from_word2vec_id(idx, unk)}\"", "for", "idx", "in", "ctx", "]", ")", "\n", "\n", "", "true_co_fi", ",", "true_uf", "=", "stratify", "(", "true", ",", "self", ".", "co_fi_ids", ")", "\n", "pred_co_fi", ",", "pred_uf", "=", "stratify", "(", "predicted", ",", "self", ".", "co_fi_ids", ")", "\n", "\n", "true_co_fi_types", "=", "\" \"", ".", "join", "(", "[", "self", ".", "type_vocab", ".", "get_label", "(", "i", ")", "for", "i", "in", "true_co_fi", "]", ")", "\n", "true_uf_types", "=", "\" \"", ".", "join", "(", "[", "self", ".", "type_vocab", ".", "get_label", "(", "i", ")", "for", "i", "in", "true_uf", "]", ")", "\n", "pred_co_fi_types", "=", "\" \"", ".", "join", "(", "[", "self", ".", "type_vocab", ".", "get_label", "(", "i", ")", "for", "i", "in", "pred_co_fi", "]", ")", "\n", "pred_uf_types", "=", "\" \"", ".", "join", "(", "[", "self", ".", "type_vocab", ".", "get_label", "(", "i", ")", "for", "i", "in", "pred_uf", "]", ")", "\n", "\n", "log", ".", "debug", "(", "f\"Mention: '{mention_words}'\\nCtx:'{ctx_words}'\\n\"", "\n", "f\"Score: {score * 100:0.2f}: True: co: '{true_co_fi_types}', uf: '{true_uf_types}' - \"", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.instance_printer.InstancePrinter.update_coarse_matrixes": [[97, 114], ["range", "len", "set", "y.item", "x.item"], "methods", ["None"], ["", "", "def", "update_coarse_matrixes", "(", "self", ",", "results", ")", ":", "\n", "        ", "for", "idx", "in", "range", "(", "len", "(", "results", ")", ")", ":", "\n", "            ", "result", "=", "results", "[", "idx", "]", "\n", "matrix", "=", "self", ".", "coarse_matrixes", "[", "idx", "]", "\n", "\n", "for", "true_types", ",", "predictions", "in", "result", ":", "\n", "                ", "true_set", "=", "set", "(", "[", "x", ".", "item", "(", ")", "for", "x", "in", "true_types", "]", ")", "\n", "for", "true_type", "in", "true_set", ":", "\n", "                    ", "if", "true_type", "in", "matrix", ":", "\n", "                        ", "matrix", "[", "true_type", "]", "[", "TRUE", "]", "+=", "1", "\n", "\n", "", "", "for", "predicted", "in", "[", "y", ".", "item", "(", ")", "for", "y", "in", "predictions", "]", ":", "\n", "                    ", "if", "predicted", "in", "matrix", ":", "\n", "                        ", "matrix", "[", "predicted", "]", "[", "ASSIGN", "]", "+=", "1", "\n", "\n", "if", "predicted", "in", "true_set", ":", "\n", "                            ", "matrix", "[", "predicted", "]", "[", "CORRECT", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.instance_printer.InstancePrinter.print_coarse_matrix": [[115, 131], ["range", "len", "matrix.items", "log.info", "instance_printer.InstancePrinter.type_vocab.get_label", "results.append"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.get_label"], ["", "", "", "", "", "", "def", "print_coarse_matrix", "(", "self", ")", ":", "\n", "        ", "grans", "=", "[", "\"COARSE\"", ",", "\"FINE\"", ",", "\"ULTRAFINE\"", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "coarse_matrixes", ")", ")", ":", "\n", "            ", "matrix", "=", "self", ".", "coarse_matrixes", "[", "i", "]", "\n", "results", "=", "[", "]", "\n", "for", "coarse", ",", "values", "in", "matrix", ".", "items", "(", ")", ":", "\n", "                ", "label", "=", "self", ".", "type_vocab", ".", "get_label", "(", "coarse", ")", "\n", "assign", ",", "true", ",", "correct", "=", "values", "[", "ASSIGN", "]", ",", "values", "[", "TRUE", "]", ",", "values", "[", "CORRECT", "]", "\n", "p", "=", "correct", "/", "assign", "*", "100", "if", "assign", "!=", "0", "else", "0", "\n", "r", "=", "correct", "/", "true", "*", "100", "if", "true", "!=", "0", "else", "0", "\n", "f1", "=", "2", "*", "p", "*", "r", "/", "(", "p", "+", "r", ")", "if", "p", "+", "r", "!=", "0", "else", "0", "\n", "extra_tab", "=", "'    '", "if", "label", "!=", "'organization'", "and", "label", "!=", "'location'", "else", "''", "\n", "results", ".", "append", "(", "f\"{label}\\t{extra_tab}{assign}/{correct}/{true}\\t\"", "\n", "f\"{p:0.2f}\\t{r:0.2f}\\t{f1:0.2f}\"", ")", "\n", "\n", "", "log", ".", "info", "(", "f\"{grans[i]} labels matrix results (assign/correct/true) (P,R,F1):\\n\"", "+", "\"\\n\"", ".", "join", "(", "results", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.instance_printer.stratify": [[15, 23], ["types.tolist", "set", "set", "co_fi.add", "uf.add"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.add", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.add"], ["def", "stratify", "(", "types", ",", "co_fi_ids", ")", ":", "\n", "    ", "co_fi", ",", "uf", "=", "set", "(", ")", ",", "set", "(", ")", "\n", "for", "t", "in", "types", ".", "tolist", "(", ")", ":", "\n", "        ", "if", "t", "in", "co_fi_ids", ":", "\n", "            ", "co_fi", ".", "add", "(", "t", ")", "\n", "", "else", ":", "\n", "            ", "uf", ".", "add", "(", "t", ")", "\n", "", "", "return", "co_fi", ",", "uf", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.instance_printer.get_score": [[25, 33], ["len", "set().intersection", "float", "float", "float", "set", "len", "len", "set", "true.tolist", "predicted.tolist"], "function", ["None"], ["", "def", "get_score", "(", "true", ",", "predicted", ")", ":", "\n", "    ", "\"\"\"Returns F1 per instance\"\"\"", "\n", "numerator", "=", "len", "(", "set", "(", "predicted", ".", "tolist", "(", ")", ")", ".", "intersection", "(", "set", "(", "true", ".", "tolist", "(", ")", ")", ")", ")", "\n", "p", "=", "numerator", "/", "float", "(", "len", "(", "predicted", ")", ")", "\n", "r", "=", "numerator", "/", "float", "(", "len", "(", "true", ")", ")", "\n", "if", "r", "==", "0.", ":", "\n", "        ", "return", "0.", "\n", "", "return", "2", "*", "p", "*", "r", "/", "float", "(", "p", "+", "r", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.instance_printer.is_strictly_right": [[133, 137], ["true.size", "predicted.size", "torch.all().item", "torch.all"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "", "", "def", "is_strictly_right", "(", "true", ",", "predicted", ")", ":", "\n", "    ", "if", "true", ".", "size", "(", ")", "!=", "predicted", ".", "size", "(", ")", ":", "\n", "        ", "return", "False", "\n", "", "return", "torch", ".", "all", "(", "true", "==", "predicted", ")", ".", "item", "(", ")", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.instance_printer.is_partially_right": [[139, 142], ["len", "set().intersection", "len", "set", "set", "j.item", "i.item"], "function", ["None"], ["", "def", "is_partially_right", "(", "true", ",", "predicted", ")", ":", "\n", "    ", "rights", "=", "len", "(", "set", "(", "[", "i", ".", "item", "(", ")", "for", "i", "in", "predicted", "]", ")", ".", "intersection", "(", "set", "(", "[", "j", ".", "item", "(", ")", "for", "j", "in", "true", "]", ")", ")", ")", "\n", "return", "0", "<", "rights", "<", "len", "(", "true", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.instance_printer.is_totally_wrong": [[144, 147], ["len", "set().intersection", "set", "set", "j.item", "i.item"], "function", ["None"], ["", "def", "is_totally_wrong", "(", "true", ",", "predicted", ")", ":", "\n", "    ", "rights", "=", "len", "(", "set", "(", "[", "i", ".", "item", "(", ")", "for", "i", "in", "predicted", "]", ")", ".", "intersection", "(", "set", "(", "[", "j", ".", "item", "(", ")", "for", "j", "in", "true", "]", ")", ")", ")", "\n", "return", "rights", "==", "0", "\n", "", ""]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.__init__": [[14, 27], ["isinstance", "dicts.Dict.load_file", "dicts.Dict.add_specials"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.load_file", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.add_specials"], ["def", "__init__", "(", "self", ",", "data", "=", "None", ",", "lower", "=", "False", ")", ":", "\n", "        ", "self", ".", "idx2label", "=", "{", "}", "\n", "self", ".", "label2idx", "=", "{", "}", "\n", "self", ".", "frequencies", "=", "{", "}", "\n", "self", ".", "lower", "=", "lower", "\n", "\n", "self", ".", "special", "=", "[", "]", "\n", "\n", "if", "data", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "data", ",", "str", ")", ":", "\n", "                ", "self", ".", "load_file", "(", "data", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "add_specials", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size": [[28, 30], ["len"], "methods", ["None"], ["", "", "", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idx2label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.load_file": [[31, 37], ["open", "line.strip().split", "int", "dicts.Dict.add", "line.strip"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.add"], ["", "def", "load_file", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "for", "line", "in", "open", "(", "filepath", ")", ":", "\n", "            ", "fields", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "label", "=", "fields", "[", "0", "]", "\n", "idx", "=", "int", "(", "fields", "[", "1", "]", ")", "\n", "self", ".", "add", "(", "label", ",", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.write_file": [[38, 43], ["open", "range", "dicts.Dict.size", "f.write"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "", "def", "write_file", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "with", "open", "(", "filepath", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "size", "(", ")", ")", ":", "\n", "                ", "label", "=", "self", ".", "idx2label", "[", "i", "]", "\n", "f", ".", "write", "(", "\"%s %d\\n\"", "%", "(", "label", ",", "i", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.lookup": [[44, 50], ["key.lower"], "methods", ["None"], ["", "", "", "def", "lookup", "(", "self", ",", "key", ",", "default", "=", "None", ")", ":", "\n", "        ", "key", "=", "key", ".", "lower", "(", ")", "if", "self", ".", "lower", "else", "key", "\n", "try", ":", "\n", "            ", "return", "self", ".", "label2idx", "[", "key", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.get_label": [[51, 56], ["None"], "methods", ["None"], ["", "", "def", "get_label", "(", "self", ",", "idx", ",", "default", "=", "None", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "self", ".", "idx2label", "[", "idx", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.add_special": [[57, 60], ["dicts.Dict.add", "dicts.Dict.special.append"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.add"], ["", "", "def", "add_special", "(", "self", ",", "label", ",", "idx", "=", "None", ")", ":", "\n", "        ", "idx", "=", "self", ".", "add", "(", "label", ",", "idx", ")", "\n", "self", ".", "special", ".", "append", "(", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.add_specials": [[61, 64], ["dicts.Dict.add_special"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.add_special"], ["", "def", "add_specials", "(", "self", ",", "labels", ")", ":", "\n", "        ", "for", "label", "in", "labels", ":", "\n", "            ", "self", ".", "add_special", "(", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.add": [[65, 84], ["label.lower", "len"], "methods", ["None"], ["", "", "def", "add", "(", "self", ",", "label", ",", "idx", "=", "None", ")", ":", "\n", "        ", "label", "=", "label", ".", "lower", "(", ")", "if", "self", ".", "lower", "else", "label", "\n", "if", "idx", "is", "not", "None", ":", "\n", "            ", "self", ".", "idx2label", "[", "idx", "]", "=", "label", "\n", "self", ".", "label2idx", "[", "label", "]", "=", "idx", "\n", "", "else", ":", "\n", "            ", "if", "label", "in", "self", ".", "label2idx", ":", "\n", "                ", "idx", "=", "self", ".", "label2idx", "[", "label", "]", "\n", "", "else", ":", "\n", "                ", "idx", "=", "len", "(", "self", ".", "idx2label", ")", "\n", "self", ".", "idx2label", "[", "idx", "]", "=", "label", "\n", "self", ".", "label2idx", "[", "label", "]", "=", "idx", "\n", "\n", "", "", "if", "idx", "not", "in", "self", ".", "frequencies", ":", "\n", "            ", "self", ".", "frequencies", "[", "idx", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "frequencies", "[", "idx", "]", "+=", "1", "\n", "\n", "", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.prune": [[85, 108], ["torch.Tensor", "torch.sort", "dicts.Dict.__class__", "dicts.Dict.size", "dicts.Dict.add_special", "dicts.Dict.add", "dicts.Dict.size", "range", "len", "i.item"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.add_special", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.add", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "def", "prune", "(", "self", ",", "size", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Returns a new Dict with only the most :size frequent words\n        \"\"\"", "\n", "if", "size", "and", "size", ">=", "self", ".", "size", "(", ")", ":", "\n", "            ", "return", "self", "\n", "\n", "", "if", "size", "is", "None", ":", "\n", "            ", "size", "=", "self", ".", "size", "(", ")", "\n", "\n", "", "freq", "=", "torch", ".", "Tensor", "(", "[", "self", ".", "frequencies", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "self", ".", "frequencies", ")", ")", "]", ")", "\n", "_", ",", "idx", "=", "torch", ".", "sort", "(", "freq", ",", "0", ",", "True", ")", "\n", "\n", "ret", "=", "self", ".", "__class__", "(", ")", "\n", "ret", ".", "lower", "=", "self", ".", "lower", "\n", "\n", "for", "i", "in", "self", ".", "special", ":", "\n", "            ", "ret", ".", "add_special", "(", "self", ".", "idx2label", "[", "i", "]", ")", "\n", "\n", "", "for", "i", "in", "idx", "[", ":", "size", "]", ":", "\n", "            ", "ret", ".", "add", "(", "self", ".", "idx2label", "[", "i", ".", "item", "(", ")", "]", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.convert_to_idx": [[109, 122], ["dicts.Dict.lookup", "_type", "vec.append", "dicts.Dict.lookup", "vec.append", "dicts.Dict.lookup", "dicts.Dict.lookup"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TokenDict.lookup", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TokenDict.lookup", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TokenDict.lookup", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TokenDict.lookup"], ["", "def", "convert_to_idx", "(", "self", ",", "labels", ",", "unk", "=", "None", ",", "bos", "=", "None", ",", "eos", "=", "None", ",", "_type", "=", "torch", ".", "LongTensor", ")", ":", "\n", "        ", "vec", "=", "[", "]", "\n", "\n", "if", "bos", "is", "not", "None", ":", "\n", "            ", "vec", ".", "append", "(", "self", ".", "lookup", "(", "bos", ")", ")", "\n", "\n", "", "unk_idx", "=", "self", ".", "lookup", "(", "unk", ")", "\n", "vec", "+=", "[", "self", ".", "lookup", "(", "label", ",", "default", "=", "unk_idx", ")", "for", "label", "in", "labels", "]", "\n", "\n", "if", "eos", "is", "not", "None", ":", "\n", "            ", "vec", ".", "append", "(", "self", ".", "lookup", "(", "eos", ")", ")", "\n", "\n", "", "return", "_type", "(", "vec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.convert_to_labels": [[123, 132], ["len", "idx.size", "dicts.Dict.get_label"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.get_label"], ["", "def", "convert_to_labels", "(", "self", ",", "idx", ",", "eos", "=", "None", ")", ":", "\n", "        ", "labels", "=", "[", "]", "\n", "if", "len", "(", "idx", ".", "size", "(", ")", ")", "==", "0", ":", "\n", "            ", "return", "labels", "\n", "", "for", "i", "in", "idx", ":", "\n", "            ", "labels", "+=", "[", "self", ".", "get_label", "(", "i", ")", "]", "\n", "if", "i", "==", "eos", ":", "\n", "                ", "break", "\n", "", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TokenDict.__init__": [[136, 143], ["dicts.Dict.__init__"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "lower", "=", "False", ")", ":", "\n", "        ", "Dict", ".", "__init__", "(", "self", ",", "[", "constants", ".", "PAD_WORD", ",", "constants", ".", "UNK_WORD", "]", ",", "lower", ")", "\n", "self", ".", "label2wordvec_idx", "=", "{", "\n", "constants", ".", "PAD_WORD", ":", "constants", ".", "PAD", ",", "\n", "constants", ".", "UNK_WORD", ":", "constants", ".", "UNK", "\n", "}", "\n", "self", ".", "word2vecIdx2label", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TokenDict.lookup": [[144, 154], ["key.lower"], "methods", ["None"], ["", "def", "lookup", "(", "self", ",", "key", ",", "default", "=", "constants", ".", "PAD", ")", ":", "\n", "        ", "\"\"\"\n        If key has a word2vec vector, should return the idx\n        If key doesn't have a word2vec vector, should return the idx of the unk vector\n        \"\"\"", "\n", "key", "=", "key", ".", "lower", "(", ")", "if", "self", ".", "lower", "else", "key", "\n", "\n", "if", "key", "in", "self", ".", "label2wordvec_idx", ":", "\n", "            ", "return", "self", ".", "label2wordvec_idx", "[", "key", "]", "\n", "", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TokenDict.size_of_word2vecs": [[155, 157], ["len"], "methods", ["None"], ["", "def", "size_of_word2vecs", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "label2wordvec_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TokenDict.get_label_from_word2vec_id": [[158, 165], ["dicts.TokenDict.label2wordvec_idx.items"], "methods", ["None"], ["", "def", "get_label_from_word2vec_id", "(", "self", ",", "idx", ",", "default", "=", "None", ")", ":", "\n", "        ", "if", "not", "self", ".", "word2vecIdx2label", ":", "\n", "            ", "self", ".", "word2vecIdx2label", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "label2wordvec_idx", ".", "items", "(", ")", "}", "\n", "", "try", ":", "\n", "            ", "return", "self", ".", "word2vecIdx2label", "[", "idx", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TypeDict.__init__": [[169, 178], ["dicts.Dict.__init__", "dicts.TypeDict.add", "dicts.TypeDict.add"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.add", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.add"], ["    ", "def", "__init__", "(", "self", ",", "data", "=", "None", ",", "lower", "=", "False", ")", ":", "\n", "        ", "Dict", ".", "__init__", "(", "self", ",", "data", ",", "lower", ")", "\n", "self", ".", "coarse_ids", "=", "None", "\n", "self", ".", "fine_ids", "=", "None", "\n", "self", ".", "ultrafine_ids", "=", "None", "\n", "for", "coarse_type", "in", "COARSE", ":", "\n", "            ", "self", ".", "add", "(", "coarse_type", ")", "\n", "", "for", "fine_type", "in", "FINE", ":", "\n", "            ", "self", ".", "add", "(", "fine_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TypeDict.get_coarse_ids": [[179, 183], ["None"], "methods", ["None"], ["", "", "def", "get_coarse_ids", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "coarse_ids", ":", "\n", "            ", "self", ".", "coarse_ids", "=", "{", "self", ".", "label2idx", "[", "label", "]", "for", "label", "in", "COARSE", "if", "label", "in", "self", ".", "label2idx", "}", "\n", "", "return", "self", ".", "coarse_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TypeDict.get_fine_ids": [[184, 188], ["None"], "methods", ["None"], ["", "def", "get_fine_ids", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "fine_ids", ":", "\n", "            ", "self", ".", "fine_ids", "=", "{", "self", ".", "label2idx", "[", "label", "]", "for", "label", "in", "FINE", "if", "label", "in", "self", ".", "label2idx", "}", "\n", "", "return", "self", ".", "fine_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TypeDict.get_ultrafine_ids": [[189, 194], ["None"], "methods", ["None"], ["", "def", "get_ultrafine_ids", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "ultrafine_ids", ":", "\n", "            ", "self", ".", "ultrafine_ids", "=", "{", "self", ".", "label2idx", "[", "label", "]", "for", "label", "in", "self", ".", "label2idx", "\n", "if", "label", "not", "in", "COARSE", "and", "label", "not", "in", "FINE", "}", "\n", "", "return", "self", ".", "ultrafine_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.MentionEncoder.__init__": [[40, 69], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "models.DistanceAttention", "models.define_mapping", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "geoopt.PoincareBall", "geoopt.PoincareBall", "hyfi.MobiusLinear", "hyfi.MobiusRNN", "geoopt.Euclidean", "geoopt.Euclidean", "torch.Linear", "torch.Linear", "models.get_nonlin", "hyfi.EuclRNN", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "models.init_embeddings", "char_vocab.size", "geoopt.expmap0", "geoopt.expmap0", "models.get_nonlin"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.define_mapping", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.get_nonlin", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.init_embeddings", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.get_nonlin"], ["def", "__init__", "(", "self", ",", "char_vocab", ",", "args", ")", ":", "\n", "        ", "super", "(", "MentionEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "mention_output_dim", "=", "args", ".", "space_dims", "*", "2", "\n", "self", ".", "char_output_dim", "=", "args", ".", "space_dims", "\n", "if", "args", ".", "encoder_metric", "==", "cs", ".", "HY", ":", "\n", "            ", "self", ".", "manifold", "=", "gt", ".", "PoincareBall", "(", ")", "\n", "self", ".", "word2space", "=", "hnn", ".", "MobiusLinear", "(", "args", ".", "word_emb_size", ",", "self", ".", "mention_output_dim", ",", "\n", "hyperbolic_input", "=", "True", ",", "hyperbolic_bias", "=", "True", ",", "\n", "nonlin", "=", "get_nonlin", "(", "args", ".", "men_nonlin", ")", ")", "\n", "self", ".", "non_lin", "=", "lambda", "x", ":", "x", "\n", "self", ".", "char_rnn", "=", "hnn", ".", "MobiusRNN", "(", "args", ".", "space_dims", ",", "args", ".", "space_dims", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "manifold", "=", "gt", ".", "Euclidean", "(", ")", "\n", "self", ".", "word2space", "=", "nn", ".", "Linear", "(", "args", ".", "word_emb_size", ",", "self", ".", "mention_output_dim", ")", "\n", "self", ".", "non_lin", "=", "get_nonlin", "(", "args", ".", "men_nonlin", ")", "\n", "self", ".", "char_rnn", "=", "hnn", ".", "EuclRNN", "(", "args", ".", "space_dims", ",", "args", ".", "space_dims", ")", "\n", "\n", "", "self", ".", "input_dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "args", ".", "input_dropout", ")", "\n", "self", ".", "mention_attn", "=", "DistanceAttention", "(", "args", ",", "args", ".", "mention_len", "+", "1", ",", "self", ".", "mention_output_dim", ")", "\n", "self", ".", "char_mapping", "=", "define_mapping", "(", "args", ".", "encoder_metric", ",", "args", ".", "attn_metric", ",", "args", ".", "c", ")", "\n", "self", ".", "char_midpoint", "=", "hnn", ".", "mobius_midpoint", "if", "args", ".", "attn_metric", "==", "cs", ".", "HY", "else", "hnn", ".", "euclidean_midpoint", "\n", "\n", "# char embeds", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "char_embeds", "=", "init_embeddings", "(", "char_vocab", ".", "size", "(", ")", ",", "self", ".", "char_output_dim", ")", "\n", "if", "args", ".", "encoder_metric", "==", "cs", ".", "HY", ":", "\n", "                ", "char_embeds", "=", "pmath", ".", "expmap0", "(", "char_embeds", ",", "k", "=", "self", ".", "manifold", ".", "k", ")", "\n", "", "", "self", ".", "char_lut", "=", "gt", ".", "ManifoldParameter", "(", "char_embeds", ",", "manifold", "=", "self", ".", "manifold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.MentionEncoder.forward": [[70, 93], ["models.MentionEncoder.input_dropout", "models.MentionEncoder.word2space", "models.MentionEncoder.non_lin", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.where", "torch.where", "torch.where", "torch.where", "models.MentionEncoder.mention_attn", "models.MentionEncoder.char_rnn", "models.MentionEncoder.char_mapping", "mentions.size", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "models.MentionEncoder.char_midpoint", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mentions.size"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "def", "forward", "(", "self", ",", "mentions", ",", "mention_chars", ",", "word_lut", ")", ":", "\n", "        ", "\"\"\"\n        :param mentions:\n        :param mention_chars:\n        :param word_lut:\n        :return: mention_vectors: b x space_dims, chars: b x space_dims\n        \"\"\"", "\n", "mention_embeds", "=", "self", ".", "input_dropout", "(", "word_lut", "[", "mentions", "]", ")", "# batch x men_len x word_emb_size", "\n", "mention_vectors", "=", "self", ".", "word2space", "(", "mention_embeds", ")", "# batch * men_len x space_dim", "\n", "mention_vectors", "=", "self", ".", "non_lin", "(", "mention_vectors", ")", "\n", "\n", "pos_index", "=", "torch", ".", "arange", "(", "start", "=", "1", ",", "end", "=", "mentions", ".", "size", "(", "1", ")", "+", "1", ",", "\n", "device", "=", "cs", ".", "DEVICE", ")", ".", "unsqueeze", "(", "dim", "=", "0", ")", ".", "expand", "(", "mentions", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "mask", "=", "mentions", ">", "0", "\n", "pos_index", "=", "torch", ".", "where", "(", "mask", ",", "pos_index", ",", "torch", ".", "LongTensor", "(", "[", "0", "]", ")", ".", "to", "(", "cs", ".", "DEVICE", ")", ")", "\n", "\n", "mention_vectors", ",", "_", "=", "self", ".", "mention_attn", "(", "mention_vectors", ",", "pos_index", ")", "\n", "\n", "char_embeds", "=", "self", ".", "char_lut", "[", "mention_chars", "]", "# batch x char_len x char_emb_size", "\n", "char_states", "=", "self", ".", "char_rnn", "(", "char_embeds", ")", "# batch x char_len x space_dims", "\n", "char_states", "=", "self", ".", "char_mapping", "(", "char_states", ")", "\n", "\n", "return", "mention_vectors", ",", "self", ".", "char_midpoint", "(", "char_states", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.ContextEncoder.__init__": [[97, 118], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "hyfi.MobiusGRU", "hyfi.MobiusGRU", "hyfi.EuclGRU", "hyfi.EuclGRU", "models.get_nonlin", "models.get_nonlin", "models.get_nonlin", "models.get_nonlin"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.get_nonlin", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.get_nonlin", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.get_nonlin", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.get_nonlin"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "ContextEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_len", "=", "args", ".", "context_len", "\n", "self", ".", "input_dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "args", ".", "input_dropout", ")", "\n", "self", ".", "ctx_output_dim", "=", "args", ".", "space_dims", "\n", "if", "args", ".", "encoder_metric", "==", "cs", ".", "HY", ":", "\n", "            ", "self", ".", "fwd", "=", "hnn", ".", "MobiusGRU", "(", "input_size", "=", "args", ".", "word_emb_size", ",", "hidden_size", "=", "self", ".", "ctx_output_dim", ",", "\n", "num_layers", "=", "args", ".", "num_layers", ",", "\n", "nonlin", "=", "get_nonlin", "(", "args", ".", "ctx_nonlin", ")", ",", "\n", "hyperbolic_input", "=", "True", ",", "hyperbolic_hidden_state0", "=", "True", ")", "\n", "self", ".", "bkwd", "=", "hnn", ".", "MobiusGRU", "(", "input_size", "=", "args", ".", "word_emb_size", ",", "hidden_size", "=", "self", ".", "ctx_output_dim", ",", "\n", "num_layers", "=", "args", ".", "num_layers", ",", "\n", "nonlin", "=", "get_nonlin", "(", "args", ".", "ctx_nonlin", ")", ",", "\n", "hyperbolic_input", "=", "True", ",", "hyperbolic_hidden_state0", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "fwd", "=", "hnn", ".", "EuclGRU", "(", "input_size", "=", "args", ".", "word_emb_size", ",", "hidden_size", "=", "self", ".", "ctx_output_dim", ",", "\n", "num_layers", "=", "args", ".", "num_layers", ",", "\n", "nonlin", "=", "get_nonlin", "(", "args", ".", "ctx_nonlin", ")", ")", "\n", "self", ".", "bkwd", "=", "hnn", ".", "EuclGRU", "(", "input_size", "=", "args", ".", "word_emb_size", ",", "hidden_size", "=", "self", ".", "ctx_output_dim", ",", "\n", "num_layers", "=", "args", ".", "num_layers", ",", "\n", "nonlin", "=", "get_nonlin", "(", "args", ".", "ctx_nonlin", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.ContextEncoder.forward": [[119, 137], ["fwd_ctx.flip", "models.ContextEncoder.input_dropout", "models.ContextEncoder.input_dropout", "models.ContextEncoder.apply_rnn", "models.ContextEncoder.apply_rnn", "models.ContextEncoder.flip"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.ContextEncoder.apply_rnn", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.ContextEncoder.apply_rnn"], ["", "", "def", "forward", "(", "self", ",", "fwd_ctx", ",", "word_lut", ")", ":", "\n", "        ", "\"\"\"\n        :param contexts: batch x seq_len\n        :param lengths: batch x 1\n        :returns batch x seq_len x space_dim\n        \"\"\"", "\n", "bkwd_ctx", "=", "fwd_ctx", ".", "flip", "(", "1", ")", "\n", "\n", "fwd_word_embeds", "=", "self", ".", "input_dropout", "(", "word_lut", "[", "fwd_ctx", "]", ")", "# batch x seq_len x embed_dim", "\n", "bkwd_word_embeds", "=", "self", ".", "input_dropout", "(", "word_lut", "[", "bkwd_ctx", "]", ")", "# batch x seq_len x embed_dim", "\n", "\n", "fwd_states", "=", "self", ".", "apply_rnn", "(", "self", ".", "fwd", ",", "fwd_word_embeds", ")", "# b x seq_len x space_dim", "\n", "bkwd_states", "=", "self", ".", "apply_rnn", "(", "self", ".", "bkwd", ",", "bkwd_word_embeds", ")", "# b x seq_len x space_dim", "\n", "\n", "# flip backward pass to align the states to the fwd pass", "\n", "bkwd_states_flipped", "=", "bkwd_states", ".", "flip", "(", "1", ")", "\n", "\n", "return", "fwd_states", ",", "bkwd_states_flipped", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.ContextEncoder.apply_rnn": [[138, 143], ["ctx_word_embeds.transpose", "rnn", "sequence_output.transpose"], "methods", ["None"], ["", "def", "apply_rnn", "(", "self", ",", "rnn", ",", "ctx_word_embeds", ")", ":", "\n", "        ", "seq_first_ctx_word_embeds", "=", "ctx_word_embeds", ".", "transpose", "(", "0", ",", "1", ")", "# seq_len x batch x embed_dim", "\n", "sequence_output", ",", "_", "=", "rnn", "(", "seq_first_ctx_word_embeds", ")", "\n", "batch_first_output", "=", "sequence_output", ".", "transpose", "(", "0", ",", "1", ")", "# batch x seq_len x space_dim", "\n", "return", "batch_first_output", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.DistanceAttention.__init__": [[146, 174], ["torch.Module.__init__", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "models.define_mapping", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "geoopt.PoincareBall", "geoopt.PoincareBall", "geoopt.Euclidean", "geoopt.Euclidean", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "models.init_embeddings", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "hyfi.MobiusLinear", "hyfi.MobiusLinear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Sigmoid", "torch.Sigmoid", "geoopt.expmap0", "geoopt.expmap0", "geoopt.mobius_add", "geoopt.mobius_add", "geoopt.dist", "geoopt.dist", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.define_mapping", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.init_embeddings"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "pos_embeds_rows", ",", "input_dims", ")", ":", "\n", "        ", "super", "(", "DistanceAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# pos embeds", "\n", "self", ".", "manifold", "=", "gt", ".", "PoincareBall", "(", ")", "if", "args", ".", "attn_metric", "==", "cs", ".", "HY", "else", "gt", ".", "Euclidean", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pos_embeds", "=", "init_embeddings", "(", "pos_embeds_rows", ",", "input_dims", ")", "\n", "if", "args", ".", "attn_metric", "==", "cs", ".", "HY", ":", "\n", "                ", "pos_embeds", "=", "pmath", ".", "expmap0", "(", "pos_embeds", ",", "k", "=", "self", ".", "manifold", ".", "k", ")", "\n", "", "beta", "=", "torch", ".", "Tensor", "(", "1", ")", ".", "uniform_", "(", "-", "0.01", ",", "0.01", ")", "\n", "", "self", ".", "position_embeds", "=", "gt", ".", "ManifoldParameter", "(", "pos_embeds", ",", "manifold", "=", "self", ".", "manifold", ")", "\n", "\n", "if", "args", ".", "attn_metric", "==", "cs", ".", "HY", ":", "\n", "            ", "self", ".", "key_dense", "=", "hnn", ".", "MobiusLinear", "(", "input_dims", ",", "input_dims", ",", "hyperbolic_input", "=", "True", ",", "hyperbolic_bias", "=", "True", ")", "\n", "self", ".", "query_dense", "=", "hnn", ".", "MobiusLinear", "(", "input_dims", ",", "input_dims", ",", "hyperbolic_input", "=", "True", ",", "hyperbolic_bias", "=", "True", ")", "\n", "self", ".", "addition", "=", "lambda", "x", ",", "y", ":", "pmath", ".", "mobius_add", "(", "x", ",", "y", ",", "k", "=", "self", ".", "manifold", ".", "k", ")", "\n", "self", ".", "distance_function", "=", "lambda", "x", ",", "y", ":", "pmath", ".", "dist", "(", "x", ",", "y", ",", "k", "=", "self", ".", "manifold", ".", "k", ")", "\n", "self", ".", "midpoint", "=", "hnn", ".", "weighted_mobius_midpoint", "\n", "", "else", ":", "\n", "            ", "self", ".", "key_dense", "=", "nn", ".", "Linear", "(", "input_dims", ",", "input_dims", ")", "\n", "self", ".", "query_dense", "=", "nn", ".", "Linear", "(", "input_dims", ",", "input_dims", ")", "\n", "self", ".", "addition", "=", "torch", ".", "add", "\n", "self", ".", "distance_function", "=", "utils", ".", "euclidean_distance", "\n", "self", ".", "midpoint", "=", "hnn", ".", "weighted_euclidean_midpoint", "\n", "\n", "", "self", ".", "encoder_to_attn_map", "=", "define_mapping", "(", "args", ".", "encoder_metric", ",", "args", ".", "attn_metric", ",", "args", ".", "c", ")", "\n", "self", ".", "attention_function", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "if", "args", ".", "attn", "==", "\"softmax\"", "else", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "beta", "=", "torch", ".", "nn", ".", "Parameter", "(", "beta", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.DistanceAttention.forward": [[175, 190], ["models.DistanceAttention.encoder_to_attn_map", "models.DistanceAttention.addition", "models.DistanceAttention.query_dense", "models.DistanceAttention.key_dense", "models.DistanceAttention.get_attention_weights", "models.DistanceAttention.midpoint", "models.DistanceAttention.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.DistanceAttention.get_attention_weights"], ["", "def", "forward", "(", "self", ",", "values", ",", "position_indexes", ")", ":", "\n", "        ", "\"\"\"\n        :param values: batch x seq_len x input_dim\n        :param position_indexes: batch x seq_len\n        :return: batch x input_dim\n        \"\"\"", "\n", "values", "=", "self", ".", "encoder_to_attn_map", "(", "values", ")", "\n", "pos_embeds", "=", "self", ".", "position_embeds", "[", "position_indexes", "]", "# b x seq_len x input_dim", "\n", "attn_embeds", "=", "self", ".", "addition", "(", "values", ",", "pos_embeds", ")", "# b x seq_len x input_dim", "\n", "\n", "queries", "=", "self", ".", "query_dense", "(", "attn_embeds", ")", "# b x seq_len x input_dim", "\n", "keys", "=", "self", ".", "key_dense", "(", "attn_embeds", ")", "# b x seq_len x input_dim", "\n", "\n", "attn_weights", "=", "self", ".", "get_attention_weights", "(", "queries", ",", "keys", ")", "# b x seq_len", "\n", "return", "self", ".", "midpoint", "(", "values", ",", "attn_weights", ".", "unsqueeze", "(", "dim", "=", "2", ")", ")", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.DistanceAttention.get_attention_weights": [[191, 199], ["models.DistanceAttention.distance_function", "models.DistanceAttention.attention_function"], "methods", ["None"], ["", "def", "get_attention_weights", "(", "self", ",", "queries", ",", "keys", ")", ":", "\n", "        ", "\"\"\"\n        :param queries: batch x seq_len x space_dim\n        :param keys: batch x seq_len x space_dim\n        \"\"\"", "\n", "distances", "=", "self", ".", "distance_function", "(", "queries", ",", "keys", ")", "# b x seq_len", "\n", "argument", "=", "-", "self", ".", "beta", "*", "distances", "\n", "return", "self", ".", "attention_function", "(", "argument", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.Model.__init__": [[203, 238], ["torch.Module.__init__", "models.Model.init_lut", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "models.MentionEncoder", "models.ContextEncoder", "ctx_concat_layer", "models.DistanceAttention", "full_concat_layer", "classifier_layer", "models.define_mapping", "models.define_mapping", "geoopt.PoincareBall", "geoopt.PoincareBall", "geoopt.Euclidean", "geoopt.Euclidean", "len", "vocabs[].size"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.Model.init_lut", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.define_mapping", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.define_mapping", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "vocabs", ",", "word2vec", "=", "None", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "\n", "super", "(", "Model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embed_manifold", "=", "gt", ".", "PoincareBall", "(", ")", "if", "args", ".", "embedding_metric", "==", "cs", ".", "HY", "else", "gt", ".", "Euclidean", "(", ")", "\n", "self", ".", "train_word_embeds", "=", "args", ".", "train_word_embeds", "==", "1", "\n", "self", ".", "word_lut", "=", "self", ".", "init_lut", "(", "word2vec", ",", "len", "(", "vocabs", "[", "cs", ".", "TOKEN_VOCAB", "]", ".", "label2wordvec_idx", ")", ",", "args", ".", "word_emb_size", ")", "\n", "self", ".", "word_lut", ".", "requires_grad", "=", "self", ".", "train_word_embeds", "\n", "\n", "self", ".", "concat_dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "args", ".", "concat_dropout", ")", "\n", "self", ".", "classif_dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "args", ".", "classif_dropout", ")", "\n", "\n", "# encoders", "\n", "self", ".", "mention_encoder", "=", "MentionEncoder", "(", "vocabs", "[", "cs", ".", "CHAR_VOCAB", "]", ",", "args", ")", "\n", "self", ".", "context_encoder", "=", "ContextEncoder", "(", "args", ")", "\n", "men_dim", "=", "self", ".", "mention_encoder", ".", "mention_output_dim", "\n", "char_dim", "=", "self", ".", "mention_encoder", ".", "char_output_dim", "\n", "ctx_dim", "=", "self", ".", "context_encoder", ".", "ctx_output_dim", "\n", "\n", "# ctx concat and attn", "\n", "ctx_concat_layer", "=", "hnn", ".", "MobiusConcat", "if", "args", ".", "encoder_metric", "==", "cs", ".", "HY", "else", "hnn", ".", "EuclConcat", "\n", "self", ".", "ctx_concat", "=", "ctx_concat_layer", "(", "ctx_dim", "*", "2", ",", "ctx_dim", ")", "\n", "self", ".", "ctx_attn", "=", "DistanceAttention", "(", "args", ",", "args", ".", "context_len", "*", "2", "+", "2", ",", "ctx_dim", "*", "2", ")", "\n", "\n", "# full concat of mention and context", "\n", "input_classif_dim", "=", "men_dim", "+", "char_dim", "+", "ctx_dim", "*", "2", "\n", "full_concat_layer", "=", "hnn", ".", "MobiusConcat", "if", "args", ".", "concat_metric", "==", "cs", ".", "HY", "else", "hnn", ".", "EuclConcat", "\n", "self", ".", "full_concat", "=", "full_concat_layer", "(", "input_classif_dim", ",", "men_dim", ",", "second_input_dim", "=", "ctx_dim", "*", "2", ",", "third_input_dim", "=", "char_dim", ")", "\n", "\n", "# classifier", "\n", "classifier_layer", "=", "hnn", ".", "MobiusMLR", "if", "args", ".", "mlr_metric", "==", "cs", ".", "HY", "else", "hnn", ".", "EuclMLR", "\n", "self", ".", "classifier", "=", "classifier_layer", "(", "input_classif_dim", ",", "vocabs", "[", "cs", ".", "TYPE_VOCAB", "]", ".", "size", "(", ")", ")", "\n", "\n", "self", ".", "attn_to_concat_map", "=", "define_mapping", "(", "args", ".", "attn_metric", ",", "args", ".", "concat_metric", ",", "args", ".", "c", ")", "\n", "self", ".", "concat_to_mlr_map", "=", "define_mapping", "(", "args", ".", "concat_metric", ",", "args", ".", "mlr_metric", ",", "args", ".", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.Model.forward": [[239, 264], ["models.Model.mention_encoder", "models.Model.context_encoder", "models.Model.ctx_concat", "models.Model.ctx_attn", "models.Model.concat_dropout", "models.Model.concat_dropout", "models.Model.concat_dropout", "models.Model.full_concat", "models.Model.classif_dropout", "models.Model.classifier", "models.Model.attn_to_concat_map", "models.Model.attn_to_concat_map", "models.Model.attn_to_concat_map", "models.Model.concat_to_mlr_map", "models.Model.detach"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "context", ",", "ctx_position", ",", "ctx_len_tensor", "=", "input", "[", "0", "]", ",", "input", "[", "1", "]", ",", "input", "[", "2", "]", "\n", "mentions", ",", "mention_chars", "=", "input", "[", "3", "]", ",", "input", "[", "4", "]", "\n", "\n", "# mention encoder", "\n", "mention_vectors", ",", "char_vectors", "=", "self", ".", "mention_encoder", "(", "mentions", ",", "mention_chars", ",", "self", ".", "word_lut", ")", "# men: b x 2*space_dim", "\n", "\n", "# context encoder", "\n", "fwd_pass", ",", "bkwd_pass", "=", "self", ".", "context_encoder", "(", "context", ",", "self", ".", "word_lut", ")", "# batch x ctx_len x space_dim", "\n", "ctx_concatenated", "=", "self", ".", "ctx_concat", "(", "fwd_pass", ",", "bkwd_pass", ")", "# b x ctx_len x 2*space_dim", "\n", "\n", "# context attention", "\n", "ctx_attn", ",", "attn_weights", "=", "self", ".", "ctx_attn", "(", "ctx_concatenated", ",", "ctx_position", ")", "# b x 2*space_dim", "\n", "\n", "# concat all", "\n", "mention_vectors", "=", "self", ".", "concat_dropout", "(", "self", ".", "attn_to_concat_map", "(", "mention_vectors", ")", ")", "\n", "char_vectors", "=", "self", ".", "concat_dropout", "(", "self", ".", "attn_to_concat_map", "(", "char_vectors", ")", ")", "\n", "ctx_attn", "=", "self", ".", "concat_dropout", "(", "self", ".", "attn_to_concat_map", "(", "ctx_attn", ")", ")", "\n", "text_vector", "=", "self", ".", "full_concat", "(", "mention_vectors", ",", "ctx_attn", ",", "third_input", "=", "char_vectors", ")", "# b x output_dim", "\n", "\n", "# classifier", "\n", "text_vector", "=", "self", ".", "classif_dropout", "(", "self", ".", "concat_to_mlr_map", "(", "text_vector", ")", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "text_vector", ")", "# batch x type_quantity", "\n", "\n", "return", "logits", ",", "attn_weights", ",", "text_vector", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.Model.init_lut": [[265, 272], ["geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "models.init_embeddings", "geoopt.expmap0", "geoopt.expmap0"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.init_embeddings"], ["", "def", "init_lut", "(", "self", ",", "weights", ",", "dim_0", ",", "dim_1", ")", ":", "\n", "        ", "if", "weights", "is", "None", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "weights", "=", "init_embeddings", "(", "dim_0", ",", "dim_1", ")", "\n", "if", "self", ".", "args", ".", "embedding_metric", "==", "cs", ".", "HY", ":", "\n", "                    ", "weights", "=", "pmath", ".", "expmap0", "(", "weights", ",", "k", "=", "self", ".", "word_embed_manifold", ".", "k", ")", "\n", "", "", "", "return", "gt", ".", "ManifoldParameter", "(", "weights", ",", "manifold", "=", "self", ".", "word_embed_manifold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.Model.project_embeds": [[273, 284], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "geoopt.project", "geoopt.project", "geoopt.project", "geoopt.project", "geoopt.project", "geoopt.project", "geoopt.project", "geoopt.project"], "methods", ["None"], ["", "def", "project_embeds", "(", "self", ")", ":", "\n", "        ", "\"\"\"Projects embeddings back into the hyperbolic ball, for numerical stability\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "self", ".", "train_word_embeds", "and", "self", ".", "args", ".", "embedding_metric", "==", "cs", ".", "HY", ":", "\n", "                ", "self", ".", "word_lut", ".", "data", "=", "pmath", ".", "project", "(", "self", ".", "word_lut", ",", "k", "=", "self", ".", "word_embed_manifold", ".", "k", ")", "\n", "", "if", "self", ".", "args", ".", "attn_metric", "==", "cs", ".", "HY", ":", "\n", "                ", "k", "=", "self", ".", "ctx_attn", ".", "manifold", ".", "k", "\n", "self", ".", "ctx_attn", ".", "position_embeds", ".", "data", "=", "pmath", ".", "project", "(", "self", ".", "ctx_attn", ".", "position_embeds", ",", "k", "=", "k", ")", "\n", "self", ".", "mention_encoder", ".", "mention_attn", ".", "position_embeds", ".", "data", "=", "pmath", ".", "project", "(", "self", ".", "mention_encoder", ".", "mention_attn", ".", "position_embeds", ",", "k", "=", "k", ")", "\n", "\n", "", "self", ".", "mention_encoder", ".", "char_lut", ".", "data", "=", "pmath", ".", "project", "(", "self", ".", "mention_encoder", ".", "char_lut", ",", "k", "=", "self", ".", "mention_encoder", ".", "manifold", ".", "k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.get_nonlin": [[16, 24], ["torch.Tanh", "torch.ReLU", "torch.Sigmoid"], "function", ["None"], ["def", "get_nonlin", "(", "nonlin", ")", ":", "\n", "    ", "if", "nonlin", "==", "\"tanh\"", ":", "\n", "        ", "return", "nn", ".", "Tanh", "(", ")", "\n", "", "if", "nonlin", "==", "\"relu\"", ":", "\n", "        ", "return", "nn", ".", "ReLU", "(", ")", "\n", "", "if", "nonlin", "==", "\"sigmoid\"", ":", "\n", "        ", "return", "nn", ".", "Sigmoid", "(", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.define_mapping": [[26, 35], ["geoopt.logmap0", "ValueError", "geoopt.expmap0"], "function", ["None"], ["", "def", "define_mapping", "(", "in_metric", ",", "out_metric", ",", "c_value", ")", ":", "\n", "    ", "if", "in_metric", "==", "out_metric", ":", "\n", "        ", "return", "lambda", "x", ":", "x", "\n", "", "elif", "in_metric", "==", "cs", ".", "HY", "and", "out_metric", "==", "cs", ".", "EU", ":", "\n", "        ", "return", "lambda", "x", ":", "pmath", ".", "logmap0", "(", "x", ",", "k", "=", "POINCARE_K", ")", "\n", "", "elif", "in_metric", "==", "cs", ".", "EU", "and", "out_metric", "==", "cs", ".", "HY", ":", "\n", "        ", "return", "lambda", "x", ":", "pmath", ".", "expmap0", "(", "x", ",", "k", "=", "POINCARE_K", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Wrong metrics: in_metric:'{in_metric}', out_metric:'{out_metric}'\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.init_embeddings": [[286, 288], ["torch.zeros().uniform_", "torch.zeros().uniform_", "torch.zeros", "torch.zeros"], "function", ["None"], ["", "", "", "def", "init_embeddings", "(", "dim_0", ",", "dim_1", ",", "k", "=", "0.0001", ")", ":", "\n", "    ", "return", "torch", ".", "zeros", "(", "(", "dim_0", ",", "dim_1", ")", ",", "dtype", "=", "cs", ".", "DEFAULT_DTYPE", ",", "device", "=", "cs", ".", "DEVICE", ")", ".", "uniform_", "(", "-", "k", ",", "k", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.__init__": [[24, 37], ["hyfi.loss.MultiTaskBCELoss", "hyfi.instance_printer.InstancePrinter", "tensorboardX.SummaryWriter"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "optim", ",", "scheduler", ",", "vocabs", ",", "train_data", ",", "crowd_train_data", ",", "dev_data", ",", "test_data", ",", "args", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "optim", "=", "optim", "\n", "self", ".", "scheduler", "=", "scheduler", "\n", "self", ".", "vocabs", "=", "vocabs", "\n", "self", ".", "train_data", "=", "train_data", "\n", "self", ".", "crowd_train_data", "=", "crowd_train_data", "\n", "self", ".", "dev_data", "=", "dev_data", "\n", "self", ".", "test_data", "=", "test_data", "\n", "self", ".", "loss", "=", "MultiTaskBCELoss", "(", "vocabs", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "instance_printer", "=", "InstancePrinter", "(", "vocabs", ",", "self", ".", "model", ")", "\n", "self", ".", "writer", "=", "SummaryWriter", "(", "f\"tensorboard/{args.export_path}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.train": [[38, 94], ["log.debug", "range", "log.info", "runner.Runner.model.load_state_dict", "torch.save", "log.info", "runner.Runner.instance_printer.show", "runner.Runner.print_full_validation", "runner.Runner.print_full_validation", "runner.Runner.writer.close", "runner.Runner.train_epoch", "range", "runner.Runner.validate_typing", "log.info", "runner.Runner.scheduler.step", "runner.Runner.writer.add_scalar", "runner.Runner.writer.add_scalar", "runner.Runner.writer.add_scalar", "runner.Runner.writer.add_scalar", "runner.Runner.print_full_validation", "runner.Runner.model.named_parameters", "runner.Runner.model.state_dict", "runner.Runner.train_crowd_data", "float", "copy.deepcopy", "log.info", "log.info", "torch.save", "runner.Runner.instance_printer.show", "runner.Runner.writer.add_histogram", "runner.Runner.model.state_dict", "runner.Runner.model.state_dict", "param.clone().cpu().data.numpy", "param.clone().cpu", "param.clone"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.instance_printer.InstancePrinter.show", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.print_full_validation", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.print_full_validation", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.train_epoch", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.validate_typing", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.print_full_validation", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.train_crowd_data", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.instance_printer.InstancePrinter.show"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "log", ".", "debug", "(", "self", ".", "model", ")", "\n", "\n", "max_macro_f1", ",", "best_model_state", ",", "best_epoch", "=", "-", "1", ",", "None", ",", "0", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "self", ".", "args", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "train_loss", "=", "self", ".", "train_epoch", "(", "epoch", ")", "\n", "\n", "# extra iterations to fine-tune on crowdsourced data", "\n", "for", "i", "in", "range", "(", "self", ".", "args", ".", "crowd_cycles", ")", ":", "\n", "                ", "self", ".", "train_crowd_data", "(", ")", "\n", "\n", "", "dev_results", ",", "dev_loss", "=", "self", ".", "validate_typing", "(", "self", ".", "dev_data", ",", "\"dev\"", ",", "epoch", ")", "\n", "dev_macro_f1", "=", "dev_results", "[", "1", "]", "[", "2", "]", "\n", "lr", "=", "self", ".", "optim", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", "\n", "\n", "log", ".", "info", "(", "f\"\\n\\nResults ep {epoch}: tr loss: {train_loss * 100:.2f}; \"", "\n", "f\"Dev loss: {dev_loss * 100:.2f}, MaF1 {dev_macro_f1:.2f}, lr: {lr}\"", ")", "\n", "\n", "self", ".", "scheduler", ".", "step", "(", "dev_macro_f1", ")", "\n", "\n", "self", ".", "writer", ".", "add_scalar", "(", "\"lr\"", ",", "float", "(", "lr", ")", ",", "epoch", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "\"train/loss\"", ",", "train_loss", ",", "epoch", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "\"dev/loss\"", ",", "dev_loss", ",", "epoch", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "\"dev/macro_f1\"", ",", "dev_macro_f1", ",", "epoch", ")", "\n", "\n", "if", "dev_macro_f1", ">", "max_macro_f1", ":", "\n", "                ", "max_macro_f1", "=", "dev_macro_f1", "\n", "best_model_state", "=", "copy", ".", "deepcopy", "(", "self", ".", "model", ".", "state_dict", "(", ")", ")", "\n", "best_epoch", "=", "epoch", "\n", "log", ".", "info", "(", "f\"* Best coarse macro F1 {dev_macro_f1:0.2f} at epoch {epoch} *\"", ")", "\n", "\n", "", "self", ".", "print_full_validation", "(", "self", ".", "dev_data", ",", "\"dev\"", ")", "\n", "\n", "if", "self", ".", "args", ".", "export_path", "and", "epoch", "%", "self", ".", "args", ".", "export_epochs", "==", "0", ":", "\n", "                ", "model_path", "=", "f\"models/{self.args.export_path}-{epoch}ep.pt\"", "\n", "log", ".", "info", "(", "f\"-- Exporting model to {model_path}\"", ")", "\n", "torch", ".", "save", "(", "self", ".", "model", ".", "state_dict", "(", ")", ",", "model_path", ")", "\n", "\n", "", "if", "epoch", "%", "self", ".", "args", ".", "log_epochs", "==", "0", ":", "\n", "                ", "self", ".", "instance_printer", ".", "show", "(", "self", ".", "dev_data", ",", "n", "=", "1", ")", "\n", "\n", "", "for", "name", ",", "param", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "self", ".", "writer", ".", "add_histogram", "(", "name", ",", "param", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "epoch", ")", "\n", "\n", "", "", "best_model_path", "=", "f\"models/{self.args.export_path}-{best_epoch}bstep.pt\"", "\n", "log", ".", "info", "(", "f\"-- Exporting b3st model to {best_model_path}\"", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "best_model_state", ")", "\n", "torch", ".", "save", "(", "self", ".", "model", ".", "state_dict", "(", ")", ",", "best_model_path", ")", "\n", "\n", "log", ".", "info", "(", "f\"Final evaluation on best Macro F1 ({max_macro_f1:0.3f}) from epoch {best_epoch}\"", ")", "\n", "self", ".", "instance_printer", ".", "show", "(", "self", ".", "dev_data", ",", "n", "=", "10", ")", "\n", "self", ".", "print_full_validation", "(", "self", ".", "dev_data", ",", "\"dev\"", ")", "\n", "self", ".", "print_full_validation", "(", "self", ".", "test_data", ",", "\"test\"", ")", "\n", "\n", "self", ".", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.train_epoch": [[95, 136], ["runner.Runner.train_data.shuffle", "runner.Runner.model.train", "tqdm.tqdm.tqdm", "runner.Runner.writer.add_scalar", "runner.Runner.writer.add_scalar", "runner.Runner.writer.add_scalar", "numpy.mean", "range", "runner.Runner.model.module.project_embeds", "runner.Runner.optim.zero_grad", "runner.Runner.model", "runner.Runner.loss.calculate_loss", "loss.mean.mean.mean", "loss.mean.mean.backward", "runner.Runner.write_total_grad_norm", "runner.Runner.optim.step", "total_loss.append", "text_vectors.norm().tolist", "geoopt.manifolds.stereographic.math.dist0.tolist", "numpy.mean", "numpy.mean", "numpy.mean", "len", "torch.nn.utils.clip_grad_norm_", "loss.mean.mean.item", "gradient.data.norm().item", "avg_grad_norm.append", "runner.Runner.writer.add_scalar", "runner.Runner.model.parameters", "text_vectors.norm", "geoopt.manifolds.stereographic.math.dist0", "gradient.data.norm", "torch.Tensor().to", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.shuffle", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.train", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.Model.project_embeds", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.loss.MultiTaskBCELoss.calculate_loss", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.write_total_grad_norm"], ["", "def", "train_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\":param epoch: int >= 1\"\"\"", "\n", "self", ".", "train_data", ".", "shuffle", "(", ")", "\n", "total_loss", ",", "avg_grad_norm", ",", "avg_text_euclid_norm", ",", "avg_text_hyperbolic_norm", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "self", ".", "train_data", ")", ")", ",", "desc", "=", "\"train_epoch_{}\"", ".", "format", "(", "epoch", ")", ")", ":", "\n", "            ", "batch", "=", "self", ".", "train_data", "[", "i", "]", "\n", "one_hot_true_types", "=", "batch", "[", "6", "]", "\n", "\n", "self", ".", "model", ".", "module", ".", "project_embeds", "(", ")", "\n", "\n", "self", ".", "optim", ".", "zero_grad", "(", ")", "\n", "logits", ",", "_", ",", "text_vectors", "=", "self", ".", "model", "(", "batch", ")", "\n", "loss", "=", "self", ".", "loss", ".", "calculate_loss", "(", "logits", ",", "one_hot_true_types", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "# because of DataParallel", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "self", ".", "write_total_grad_norm", "(", "i", ",", "epoch", ")", "\n", "\n", "if", "self", ".", "args", ".", "max_grad_norm", ">=", "0", ":", "\n", "                ", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "max_grad_norm", ")", "\n", "", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n", "total_loss", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# write norm of last layer", "\n", "gradient", "=", "self", ".", "model", ".", "module", ".", "classifier", ".", "a_k", ".", "grad", "\n", "if", "gradient", "is", "not", "None", ":", "\n", "                ", "grad_norm", "=", "gradient", ".", "data", ".", "norm", "(", "2", ")", ".", "item", "(", ")", "\n", "avg_grad_norm", ".", "append", "(", "grad_norm", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "f\"classif_grad_norm/epoch_{epoch}\"", ",", "grad_norm", ",", "i", ")", "\n", "\n", "# write text vector norms", "\n", "", "avg_text_euclid_norm", "+=", "text_vectors", ".", "norm", "(", "2", ",", "dim", "=", "1", ")", ".", "tolist", "(", ")", "\n", "avg_text_hyperbolic_norm", "+=", "hyperbolic_norm", "(", "text_vectors", ",", "k", "=", "torch", ".", "Tensor", "(", "[", "-", "1.0", "]", ")", ".", "to", "(", "DEVICE", ")", ")", ".", "tolist", "(", ")", "\n", "\n", "", "self", ".", "writer", ".", "add_scalar", "(", "\"classif_grad_norm/avg_norm\"", ",", "np", ".", "mean", "(", "avg_grad_norm", ")", ",", "epoch", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "\"text_vector/euclid_norm\"", ",", "np", ".", "mean", "(", "avg_text_euclid_norm", ")", ",", "epoch", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "\"text_vector/hyperb_norm\"", ",", "np", ".", "mean", "(", "avg_text_hyperbolic_norm", ")", ",", "epoch", ")", "\n", "\n", "return", "np", ".", "mean", "(", "total_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.train_crowd_data": [[137, 156], ["data.shuffle", "runner.Runner.model.train", "tqdm.tqdm.tqdm", "range", "runner.Runner.model.module.project_embeds", "runner.Runner.optim.zero_grad", "runner.Runner.model", "runner.Runner.loss.calculate_loss", "loss.mean.mean.mean", "loss.mean.mean.backward", "runner.Runner.optim.step", "len", "torch.nn.utils.clip_grad_norm_", "runner.Runner.model.parameters"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.shuffle", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.train", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.models.Model.project_embeds", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.loss.MultiTaskBCELoss.calculate_loss"], ["", "def", "train_crowd_data", "(", "self", ")", ":", "\n", "        ", "data", "=", "self", ".", "crowd_train_data", "\n", "data", ".", "shuffle", "(", ")", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "data", ")", ")", ",", "desc", "=", "\"train_crowd_data\"", ")", ":", "\n", "            ", "batch", "=", "data", "[", "i", "]", "\n", "one_hot_true_types", "=", "batch", "[", "6", "]", "\n", "\n", "self", ".", "model", ".", "module", ".", "project_embeds", "(", ")", "\n", "\n", "self", ".", "optim", ".", "zero_grad", "(", ")", "\n", "logits", ",", "_", ",", "_", "=", "self", ".", "model", "(", "batch", ")", "\n", "loss", "=", "self", ".", "loss", ".", "calculate_loss", "(", "logits", ",", "one_hot_true_types", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "# because of DataParallel", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "self", ".", "args", ".", "max_grad_norm", ">=", "0", ":", "\n", "                ", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "max_grad_norm", ")", "\n", "", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.write_total_grad_norm": [[157, 165], ["runner.Runner.model.parameters", "runner.Runner.writer.add_scalar", "p.grad.data.norm", "p.grad.data.norm.item"], "methods", ["None"], ["", "", "def", "write_total_grad_norm", "(", "self", ",", "batch_number", ",", "epoch", ")", ":", "\n", "        ", "total_norm", "=", "0", "\n", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "grad", "is", "None", "or", "p", ".", "grad", ".", "data", "is", "None", ":", "continue", "\n", "param_norm", "=", "p", ".", "grad", ".", "data", ".", "norm", "(", "2", ")", "\n", "total_norm", "+=", "param_norm", ".", "item", "(", ")", "**", "2", "\n", "", "total_norm", "=", "total_norm", "**", "(", "1.", "/", "2", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "f\"grad_total_norm/epoch_{epoch}\"", ",", "total_norm", ",", "batch_number", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.validate_typing": [[166, 170], ["runner.Runner.infer_results", "hyfi.evaluate.raw_evaluate"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.infer_results", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.raw_evaluate"], ["", "def", "validate_typing", "(", "self", ",", "data", ",", "name", ",", "epoch", ")", ":", "\n", "        ", "true_and_preds", ",", "loss", "=", "self", ".", "infer_results", "(", "data", ",", "name", ",", "epoch", ")", "\n", "result", "=", "raw_evaluate", "(", "true_and_preds", ")", "\n", "return", "result", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.infer_results": [[171, 193], ["runner.Runner.model.eval", "torch.nn.Sigmoid", "torch.no_grad", "tqdm.tqdm.tqdm", "range", "runner.Runner.model", "torch.nn.Sigmoid.", "runner.Runner.loss.calculate_loss", "loss.mean.mean.mean", "total_loss.append", "numpy.mean", "len", "loss.mean.mean.item", "hyfi.predictor.assign_exactly_k_types", "hyfi.predictor.assign_types"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.loss.MultiTaskBCELoss.calculate_loss", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.predictor.assign_exactly_k_types", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.predictor.assign_types"], ["", "def", "infer_results", "(", "self", ",", "data", ",", "name", ",", "epoch", ",", "precision_at", "=", "0", ")", ":", "\n", "        ", "total_loss", ",", "results", "=", "[", "]", ",", "[", "]", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "sigmoid", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "data", ")", ")", ",", "desc", "=", "f\"infer_{name}_ep{epoch}_P@{precision_at}\"", ")", ":", "\n", "                ", "batch", "=", "data", "[", "i", "]", "\n", "type_indexes", ",", "one_hot_true_types", "=", "batch", "[", "-", "2", "]", ",", "batch", "[", "6", "]", "\n", "\n", "logits", ",", "_", ",", "_", "=", "self", ".", "model", "(", "batch", ")", "\n", "probability_predictions", "=", "sigmoid", "(", "logits", ")", "\n", "loss", "=", "self", ".", "loss", ".", "calculate_loss", "(", "logits", ",", "one_hot_true_types", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "\n", "total_loss", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "if", "precision_at", ">", "0", ":", "\n", "                    ", "results", "+=", "assign_exactly_k_types", "(", "probability_predictions", ",", "type_indexes", ",", "\n", "self", ".", "vocabs", "[", "TYPE_VOCAB", "]", ",", "precision_at", "=", "precision_at", ")", "\n", "", "else", ":", "\n", "                    ", "results", "+=", "assign_types", "(", "probability_predictions", ",", "type_indexes", ")", "\n", "\n", "", "", "return", "results", ",", "np", ".", "mean", "(", "total_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.print_full_validation": [[194, 208], ["log.info", "runner.Runner.infer_results", "hyfi.evaluate.evaluate", "hyfi.evaluate.stratified_evaluate", "log.info", "log.info", "log.info", "log.info", "name.upper", "zip"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.infer_results", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.evaluate", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.stratified_evaluate"], ["", "", "def", "print_full_validation", "(", "self", ",", "dataset", ",", "name", ")", ":", "\n", "        ", "log", ".", "info", "(", "f\"FULL VALIDATION ON {name.upper()}\"", ")", "\n", "true_and_preds", ",", "_", "=", "self", ".", "infer_results", "(", "dataset", ",", "name", ",", "-", "1", ")", "\n", "\n", "full_eval", "=", "evaluate", "(", "true_and_preds", ")", "\n", "stratified_eval", "=", "stratified_evaluate", "(", "true_and_preds", ",", "self", ".", "vocabs", "[", "TYPE_VOCAB", "]", ")", "\n", "\n", "log", ".", "info", "(", "\"Strict (p,r,f1), Macro (p,r,f1), Micro (p,r,f1)\"", ")", "\n", "strat_string", "=", "\"\\n\"", ".", "join", "(", "[", "item", "for", "pair", "in", "zip", "(", "[", "\"COARSE\"", ",", "\"FINE\"", ",", "\"ULTRAFINE\"", "]", ",", "stratified_eval", ")", "for", "item", "in", "pair", "]", ")", "\n", "log", ".", "info", "(", "f\"Total:\\n{full_eval}\"", ")", "\n", "log", ".", "info", "(", "strat_string", ")", "\n", "# self.print_precision_at(dataset, name)", "\n", "for_export", "=", "\"\"", ".", "join", "(", "stratified_eval", ")", "\n", "log", ".", "info", "(", "f\"\\n{for_export}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.print_precision_at": [[209, 222], ["runner.Runner.infer_results", "hyfi.evaluate.stratified_evaluate", "runner.Runner.infer_results", "hyfi.evaluate.stratified_evaluate", "runner.Runner.infer_results", "hyfi.evaluate.stratified_evaluate", "log.info"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.infer_results", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.stratified_evaluate", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.infer_results", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.stratified_evaluate", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.runner.Runner.infer_results", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.stratified_evaluate"], ["", "def", "print_precision_at", "(", "self", ",", "dataset", ",", "name", ")", ":", "\n", "        ", "true_and_pred_at_1", ",", "_", "=", "self", ".", "infer_results", "(", "dataset", ",", "name", ",", "-", "1", ",", "precision_at", "=", "1", ")", "\n", "res_co_at_1", ",", "res_fi_at_1", ",", "res_uf_at_1", "=", "stratified_evaluate", "(", "true_and_pred_at_1", ",", "self", ".", "vocabs", "[", "TYPE_VOCAB", "]", ")", "\n", "\n", "true_and_pred_at_3", ",", "_", "=", "self", ".", "infer_results", "(", "dataset", ",", "name", ",", "-", "1", ",", "precision_at", "=", "3", ")", "\n", "_", ",", "_", ",", "res_uf_at_3", "=", "stratified_evaluate", "(", "true_and_pred_at_3", ",", "self", ".", "vocabs", "[", "TYPE_VOCAB", "]", ")", "\n", "\n", "true_and_pred_at_5", ",", "_", "=", "self", ".", "infer_results", "(", "dataset", ",", "name", ",", "-", "1", ",", "precision_at", "=", "5", ")", "\n", "_", ",", "_", ",", "res_uf_at_5", "=", "stratified_evaluate", "(", "true_and_pred_at_5", ",", "self", ".", "vocabs", "[", "TYPE_VOCAB", "]", ")", "\n", "\n", "out", "=", "f\"PRECISION AT N\\nCoarse@1\\n{res_co_at_1}\\nFine@1\\n{res_fi_at_1}\\n\"", "f\"UltraFine@1\\n{res_uf_at_1}\\nUltraFine@3\\n{res_uf_at_3}\\nUltraFine@5\\n{res_uf_at_5}\\n\"", "\n", "log", ".", "info", "(", "out", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.predictor.assign_types": [[8, 25], ["range", "torch.cuda.is_available", "len", "results.append", "len", "[].item", "torch.LongTensor().to", "torch.LongTensor", "predictions.max"], "function", ["None"], ["def", "assign_types", "(", "probability_predictions", ",", "type_indexes", ",", "threshold", "=", "0.5", ")", ":", "\n", "    ", "\"\"\"\n    :param probability_predictions: batch x total_type_len\n    :param type_indexes: batch x type_len\n    :return: list of pairs of true type indexes and predicted type indexes\n    \"\"\"", "\n", "device", "=", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", "\n", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "probability_predictions", ")", ")", ":", "\n", "        ", "predictions", "=", "probability_predictions", "[", "i", "]", "\n", "predicted_indexes", "=", "(", "predictions", ">=", "threshold", ")", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", ".", "tolist", "(", ")", "\n", "if", "len", "(", "predicted_indexes", ")", "==", "0", ":", "\n", "            ", "predicted_indexes", "=", "[", "predictions", ".", "max", "(", "0", ")", "[", "1", "]", ".", "item", "(", ")", "]", "\n", "\n", "", "results", ".", "append", "(", "[", "type_indexes", "[", "i", "]", ",", "torch", ".", "LongTensor", "(", "predicted_indexes", ")", ".", "to", "(", "device", ")", "]", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.predictor.assign_exactly_k_types": [[27, 50], ["len", "range", "torch.cuda.is_available", "type_dict.get_coarse_ids", "len", "len", "[].tolist", "results.append", "type_dict.get_fine_ids", "torch.LongTensor().to", "co_pred.topk", "fi_pred.topk", "uf_pred.topk", "torch.LongTensor"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TypeDict.get_coarse_ids", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TypeDict.get_fine_ids"], ["", "def", "assign_exactly_k_types", "(", "probability_predictions", ",", "type_indexes", ",", "type_dict", ",", "precision_at", ")", ":", "\n", "    ", "\"\"\"\n    It assigns the top precision_at predictions per granularity\n    \"\"\"", "\n", "device", "=", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", "\n", "coarse_slice", "=", "len", "(", "type_dict", ".", "get_coarse_ids", "(", ")", ")", "\n", "fine_slice", "=", "coarse_slice", "+", "len", "(", "type_dict", ".", "get_fine_ids", "(", ")", ")", "\n", "\n", "coarse_predictions", "=", "probability_predictions", "[", ":", ",", ":", "coarse_slice", "]", "\n", "fine_predictions", "=", "probability_predictions", "[", ":", ",", "coarse_slice", ":", "fine_slice", "]", "\n", "ultrafine_predictions", "=", "probability_predictions", "[", ":", ",", "fine_slice", ":", "]", "\n", "\n", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "probability_predictions", ")", ")", ":", "\n", "        ", "co_pred", ",", "fi_pred", ",", "uf_pred", "=", "coarse_predictions", "[", "i", "]", ",", "fine_predictions", "[", "i", "]", ",", "ultrafine_predictions", "[", "i", "]", "\n", "\n", "predicted_indexes", "=", "co_pred", ".", "topk", "(", "precision_at", ")", "[", "1", "]", ".", "tolist", "(", ")", "\n", "predicted_indexes", "+=", "(", "fi_pred", ".", "topk", "(", "precision_at", ")", "[", "1", "]", "+", "coarse_slice", ")", ".", "tolist", "(", ")", "\n", "predicted_indexes", "+=", "(", "uf_pred", ".", "topk", "(", "precision_at", ")", "[", "1", "]", "+", "fine_slice", ")", ".", "tolist", "(", ")", "\n", "\n", "results", ".", "append", "(", "[", "type_indexes", "[", "i", "]", ",", "torch", ".", "LongTensor", "(", "predicted_indexes", ")", ".", "to", "(", "device", ")", "]", ")", "\n", "\n", "", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.f1": [[8, 12], ["float"], "function", ["None"], ["def", "f1", "(", "p", ",", "r", ")", ":", "\n", "    ", "if", "r", "==", "0.", ":", "\n", "        ", "return", "0.", "\n", "", "return", "2", "*", "p", "*", "r", "/", "float", "(", "p", "+", "r", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.strict": [[14, 26], ["len", "torch.all().item", "evaluate.f1", "true_labels.size", "predicted_labels.size", "torch.all"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.f1", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "def", "strict", "(", "true_and_prediction", ")", ":", "\n", "    ", "\"\"\"\n    Correct: all types must be predicted exactly equal to the label\n    \"\"\"", "\n", "num_entities", "=", "len", "(", "true_and_prediction", ")", "\n", "correct_num", "=", "0.", "\n", "for", "true_labels", ",", "predicted_labels", "in", "true_and_prediction", ":", "\n", "        ", "if", "true_labels", ".", "size", "(", ")", "!=", "predicted_labels", ".", "size", "(", ")", ":", "\n", "            ", "continue", "\n", "", "correct_num", "+=", "torch", ".", "all", "(", "true_labels", "==", "predicted_labels", ")", ".", "item", "(", ")", "\n", "", "precision", "=", "recall", "=", "correct_num", "/", "num_entities", "\n", "return", "precision", ",", "recall", ",", "f1", "(", "precision", ",", "recall", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.loose_macro": [[28, 52], ["len", "len", "len", "evaluate.f1", "set().intersection", "set", "float", "float", "set", "len", "len", "j.item", "i.item"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.f1"], ["", "def", "loose_macro", "(", "true_and_prediction", ")", ":", "\n", "    ", "\"\"\"Metrics at mention level (dividing for the amount of instances/examples/mentions).\n    Takes an average of the metrics on the amount of mentions\n    Code taken from OpenType Repository (using the exact same metrics than them)\n    \"\"\"", "\n", "p", "=", "0.", "\n", "r", "=", "0.", "\n", "pred_count", "=", "0.", "\n", "gold_count", "=", "0.", "\n", "for", "true_labels", ",", "predicted_labels", "in", "true_and_prediction", ":", "\n", "        ", "numerator", "=", "len", "(", "set", "(", "[", "i", ".", "item", "(", ")", "for", "i", "in", "predicted_labels", "]", ")", ".", "intersection", "(", "set", "(", "[", "j", ".", "item", "(", ")", "for", "j", "in", "true_labels", "]", ")", ")", ")", "\n", "if", "len", "(", "predicted_labels", ")", ":", "\n", "            ", "pred_count", "+=", "1", "\n", "p", "+=", "numerator", "/", "float", "(", "len", "(", "predicted_labels", ")", ")", "\n", "", "if", "len", "(", "true_labels", ")", ":", "\n", "            ", "gold_count", "+=", "1", "\n", "r", "+=", "numerator", "/", "float", "(", "len", "(", "true_labels", ")", ")", "\n", "\n", "", "", "precision", ",", "recall", "=", "0.", ",", "0.", "\n", "if", "pred_count", ":", "\n", "        ", "precision", "=", "p", "/", "pred_count", "\n", "", "if", "gold_count", ":", "\n", "        ", "recall", "=", "r", "/", "gold_count", "\n", "", "return", "precision", ",", "recall", ",", "f1", "(", "precision", ",", "recall", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.loose_micro": [[54, 71], ["len", "len", "len", "evaluate.f1", "set().intersection", "set", "set", "j.item", "i.item"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.f1"], ["", "def", "loose_micro", "(", "true_and_prediction", ")", ":", "\n", "    ", "\"\"\"Metrics at type/class level.\n    Correct types of all types on all mentions\"\"\"", "\n", "num_predicted_labels", "=", "0.", "\n", "num_true_labels", "=", "0.", "\n", "num_correct_labels", "=", "0.", "\n", "for", "true_labels", ",", "predicted_labels", "in", "true_and_prediction", ":", "\n", "        ", "num_predicted_labels", "+=", "len", "(", "predicted_labels", ")", "\n", "num_true_labels", "+=", "len", "(", "true_labels", ")", "\n", "num_correct_labels", "+=", "len", "(", "set", "(", "[", "i", ".", "item", "(", ")", "for", "i", "in", "predicted_labels", "]", ")", ".", "intersection", "(", "set", "(", "[", "j", ".", "item", "(", ")", "for", "j", "in", "true_labels", "]", ")", ")", ")", "\n", "\n", "", "if", "num_predicted_labels", "==", "0", "or", "num_true_labels", "==", "0", ":", "\n", "        ", "return", "0.", ",", "0.", ",", "0.", "\n", "\n", "", "precision", "=", "num_correct_labels", "/", "num_predicted_labels", "\n", "recall", "=", "num_correct_labels", "/", "num_true_labels", "\n", "return", "precision", ",", "recall", ",", "f1", "(", "precision", ",", "recall", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.evaluate": [[73, 91], ["evaluate.strict", "evaluate.loose_macro", "evaluate.loose_micro"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.strict", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.loose_macro", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.loose_micro"], ["", "def", "evaluate", "(", "true_and_prediction", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "ret", "=", "\"\"", "\n", "p", ",", "r", ",", "f", "=", "strict", "(", "true_and_prediction", ")", "\n", "if", "verbose", ":", "\n", "        ", "ret", "+=", "\"| strict (%.2f, %.2f, %.2f) \"", "%", "(", "p", "*", "100", ",", "r", "*", "100", ",", "f", "*", "100", ")", "\n", "", "else", ":", "\n", "        ", "ret", "+=", "\"%.2f\\t%.2f\\t%.2f\\t\"", "%", "(", "p", "*", "100", ",", "r", "*", "100", ",", "f", "*", "100", ")", "\n", "", "p", ",", "r", ",", "f", "=", "loose_macro", "(", "true_and_prediction", ")", "\n", "if", "verbose", ":", "\n", "        ", "ret", "+=", "\"| macro (%.2f, %.2f, %.2f) \"", "%", "(", "p", "*", "100", ",", "r", "*", "100", ",", "f", "*", "100", ")", "\n", "", "else", ":", "\n", "        ", "ret", "+=", "\"%.2f\\t%.2f\\t%.2f\\t\"", "%", "(", "p", "*", "100", ",", "r", "*", "100", ",", "f", "*", "100", ")", "\n", "", "p", ",", "r", ",", "f", "=", "loose_micro", "(", "true_and_prediction", ")", "\n", "if", "verbose", ":", "\n", "        ", "ret", "+=", "\"| micro (%.2f, %.2f, %.2f) |\"", "%", "(", "p", "*", "100", ",", "r", "*", "100", ",", "f", "*", "100", ")", "\n", "", "else", ":", "\n", "        ", "ret", "+=", "\"%.2f\\t%.2f\\t%.2f\\t\"", "%", "(", "p", "*", "100", ",", "r", "*", "100", ",", "f", "*", "100", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.raw_evaluate": [[93, 100], ["metric", "res.append"], "function", ["None"], ["", "def", "raw_evaluate", "(", "true_and_prediction", ")", ":", "\n", "    ", "metrics", "=", "[", "strict", ",", "loose_macro", ",", "loose_micro", "]", "\n", "res", "=", "[", "]", "\n", "for", "metric", "in", "metrics", ":", "\n", "        ", "p", ",", "r", ",", "f", "=", "metric", "(", "true_and_prediction", ")", "\n", "res", ".", "append", "(", "(", "p", "*", "100", ",", "r", "*", "100", ",", "f", "*", "100", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.stratified_evaluate": [[102, 116], ["evaluate.stratify", "evaluate.stratify", "coarse_true_and_preds.append", "fine_true_and_preds.append", "ultrafine_true_and_preds.append", "evaluate.evaluate"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.stratify", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.stratify", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.evaluate"], ["", "def", "stratified_evaluate", "(", "true_and_prediction", ",", "type_dict", ")", ":", "\n", "    ", "coarse_true_and_preds", "=", "[", "]", "\n", "fine_true_and_preds", "=", "[", "]", "\n", "ultrafine_true_and_preds", "=", "[", "]", "\n", "\n", "for", "true_labels", ",", "predicted_labels", "in", "true_and_prediction", ":", "\n", "        ", "coarse_gold", ",", "fine_gold", ",", "ultrafine_gold", "=", "stratify", "(", "true_labels", ",", "type_dict", ")", "\n", "coarse_pred", ",", "fine_pred", ",", "ultrafine_pred", "=", "stratify", "(", "predicted_labels", ",", "type_dict", ")", "\n", "coarse_true_and_preds", ".", "append", "(", "(", "coarse_gold", ",", "coarse_pred", ")", ")", "\n", "fine_true_and_preds", ".", "append", "(", "(", "fine_gold", ",", "fine_pred", ")", ")", "\n", "ultrafine_true_and_preds", ".", "append", "(", "(", "ultrafine_gold", ",", "ultrafine_pred", ")", ")", "\n", "\n", "", "return", "[", "evaluate", "(", "true_and_preds", ")", "for", "true_and_preds", "in", "\n", "[", "coarse_true_and_preds", ",", "fine_true_and_preds", ",", "ultrafine_true_and_preds", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.evaluate.stratify": [[119, 135], ["list", "set", "set", "i.item", "torch.cuda.is_available", "map", "torch.LongTensor().to", "torch.LongTensor"], "function", ["None"], ["def", "stratify", "(", "labels", ",", "type_dict", ")", ":", "\n", "    ", "\"\"\"\n    Divide label into three categories.\n    \"\"\"", "\n", "global", "coarse_ids", ",", "fine_ids", "\n", "if", "coarse_ids", "is", "None", ":", "\n", "        ", "coarse_ids", "=", "set", "(", "[", "type_dict", ".", "label2idx", "[", "item", "]", "for", "item", "in", "COARSE", "if", "item", "in", "type_dict", ".", "label2idx", "]", ")", "\n", "fine_ids", "=", "set", "(", "[", "type_dict", ".", "label2idx", "[", "item", "]", "for", "item", "in", "FINE", "if", "item", "in", "type_dict", ".", "label2idx", "]", ")", "\n", "\n", "", "labels", "=", "[", "i", ".", "item", "(", ")", "for", "i", "in", "labels", "]", "\n", "strats", "=", "(", "[", "l", "for", "l", "in", "labels", "if", "l", "in", "coarse_ids", "]", ",", "\n", "[", "l", "for", "l", "in", "labels", "if", "(", "(", "l", "in", "fine_ids", ")", "and", "(", "l", "not", "in", "coarse_ids", ")", ")", "]", ",", "\n", "[", "l", "for", "l", "in", "labels", "if", "(", "l", "not", "in", "coarse_ids", ")", "and", "(", "l", "not", "in", "fine_ids", ")", "]", ")", "\n", "\n", "device", "=", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", "\n", "return", "list", "(", "map", "(", "lambda", "strat", ":", "torch", ".", "LongTensor", "(", "strat", ")", ".", "to", "(", "device", ")", ",", "strats", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.model_utils.CharEncoder.__init__": [[80, 86], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Conv1d", "torch.nn.Conv1d", "char_vocab.size"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["    ", "def", "__init__", "(", "self", ",", "char_vocab", ",", "args", ")", ":", "\n", "        ", "super", "(", "CharEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "conv_dim_input", "=", "100", "\n", "filters", "=", "5", "\n", "self", ".", "char_W", "=", "nn", ".", "Embedding", "(", "char_vocab", ".", "size", "(", ")", ",", "conv_dim_input", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "conv1d", "=", "nn", ".", "Conv1d", "(", "conv_dim_input", ",", "args", ".", "char_emb_size", ",", "filters", ")", "# input, output, filter_number", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.model_utils.CharEncoder.forward": [[87, 94], ["model_utils.CharEncoder.char_W().transpose", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "model_utils.CharEncoder.conv1d", "torch.relu", "torch.relu", "torch.max_pool1d", "torch.max_pool1d", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_utils.CharEncoder.char_W", "i.size"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "def", "forward", "(", "self", ",", "span_chars", ")", ":", "\n", "        ", "char_embed", "=", "self", ".", "char_W", "(", "span_chars", ")", ".", "transpose", "(", "1", ",", "2", ")", "# [batch_size, char_embedding, max_char_seq]", "\n", "conv_output", "=", "[", "self", ".", "conv1d", "(", "char_embed", ")", "]", "# list of [batch_size, filter_dim, max_char_seq, filter_number]", "\n", "conv_output", "=", "[", "F", ".", "relu", "(", "c", ")", "for", "c", "in", "conv_output", "]", "# batch_size, filter_dim, max_char_seq, filter_num", "\n", "cnn_rep", "=", "[", "F", ".", "max_pool1d", "(", "i", ",", "i", ".", "size", "(", "2", ")", ")", "for", "i", "in", "conv_output", "]", "# batch_size, filter_dim, 1, filter_num", "\n", "cnn_output", "=", "torch", ".", "squeeze", "(", "torch", ".", "cat", "(", "cnn_rep", ",", "1", ")", ",", "2", ")", "# batch_size, filter_num * filter_dim, 1", "\n", "return", "cnn_output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.model_utils.sort_batch_by_length": [[7, 46], ["sequence_lengths.sort", "tensor.index_select", "sequence_lengths.data.clone().copy_", "torch.autograd.Variable", "permutation_index.sort", "torch.autograd.Variable.index_select", "ValueError", "torch.arange", "torch.arange", "torch.autograd.Variable.long", "isinstance", "isinstance", "sequence_lengths.data.clone", "len"], "function", ["None"], ["def", "sort_batch_by_length", "(", "tensor", ":", "torch", ".", "autograd", ".", "Variable", ",", "sequence_lengths", ":", "torch", ".", "autograd", ".", "Variable", ")", ":", "\n", "    ", "\"\"\"\n    @ from allennlp\n    Sort a batch first tensor by some specified lengths.\n\n    Parameters\n    ----------\n    tensor : Variable(torch.FloatTensor), required.\n        A batch first Pytorch tensor.\n    sequence_lengths : Variable(torch.LongTensor), required.\n        A tensor representing the lengths of some dimension of the tensor which\n        we want to sort by.\n\n    Returns\n    -------\n    sorted_tensor : Variable(torch.FloatTensor)\n        The original tensor sorted along the batch dimension with respect to sequence_lengths.\n    sorted_sequence_lengths : Variable(torch.LongTensor)\n        The original sequence_lengths sorted by decreasing size.\n    restoration_indices : Variable(torch.LongTensor)\n        Indices into the sorted_tensor such that\n        ``sorted_tensor.index_select(0, restoration_indices) == original_tensor``\n    \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "tensor", ",", "Variable", ")", "or", "not", "isinstance", "(", "sequence_lengths", ",", "Variable", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Both the tensor and sequence lengths must be torch.autograd.Variables.\"", ")", "\n", "\n", "", "sorted_sequence_lengths", ",", "permutation_index", "=", "sequence_lengths", ".", "sort", "(", "0", ",", "descending", "=", "True", ")", "\n", "sorted_tensor", "=", "tensor", ".", "index_select", "(", "0", ",", "permutation_index", ")", "\n", "# This is ugly, but required - we are creating a new variable at runtime, so we", "\n", "# must ensure it has the correct CUDA vs non-CUDA type. We do this by cloning and", "\n", "# refilling one of the inputs to the function.", "\n", "index_range", "=", "sequence_lengths", ".", "data", ".", "clone", "(", ")", ".", "copy_", "(", "torch", ".", "arange", "(", "0", ",", "len", "(", "sequence_lengths", ")", ")", ")", "\n", "# This is the equivalent of zipping with index, sorting by the original", "\n", "# sequence lengths and returning the now sorted indices.", "\n", "index_range", "=", "Variable", "(", "index_range", ".", "long", "(", ")", ")", "\n", "_", ",", "reverse_mapping", "=", "permutation_index", ".", "sort", "(", "0", ",", "descending", "=", "False", ")", "\n", "restoration_indices", "=", "index_range", ".", "index_select", "(", "0", ",", "reverse_mapping", ")", "\n", "return", "sorted_tensor", ",", "sorted_sequence_lengths", ",", "restoration_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.model_utils.reverse_padded_sequence": [[48, 77], ["torch.autograd.Variable", "range", "ind.cuda.expand_as", "torch.gather", "torch.gather", "inputs.transpose.transpose", "inputs.transpose.size", "inputs.transpose.size", "len", "ValueError", "torch.LongTensor().transpose", "torch.LongTensor().transpose", "inputs.transpose.dim", "ind.cuda.unsqueeze", "ind.cuda.cuda", "reversed_inputs.transpose.transpose", "list", "list", "inputs.transpose.get_device", "reversed", "range", "torch.LongTensor", "torch.LongTensor", "range"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "def", "reverse_padded_sequence", "(", "inputs", ",", "lengths", ",", "batch_first", "=", "False", ")", ":", "\n", "    ", "\"\"\"Reverses sequences according to their lengths.\n    Inputs should have size ``T x B x *`` if ``batch_first`` is False, or\n    ``B x T x *`` if True. T is the length of the longest sequence (or larger),\n    B is the batch size, and * is any number of dimensions (including 0).\n    Arguments:\n        inputs (Variable): padded batch of variable length sequences.\n        lengths (list[int]): list of sequence lengths\n        batch_first (bool, optional): if True, inputs should be B x T x *.\n    Returns:\n        A Variable with the same size as inputs, but with each sequence\n        reversed according to its length.\n    \"\"\"", "\n", "if", "batch_first", ":", "\n", "        ", "inputs", "=", "inputs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "max_length", ",", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", ",", "inputs", ".", "size", "(", "1", ")", "\n", "if", "len", "(", "lengths", ")", "!=", "batch_size", ":", "\n", "        ", "raise", "ValueError", "(", "'inputs is incompatible with lengths.'", ")", "\n", "", "ind", "=", "[", "list", "(", "reversed", "(", "range", "(", "0", ",", "length", ")", ")", ")", "+", "list", "(", "range", "(", "length", ",", "max_length", ")", ")", "for", "length", "in", "lengths", "]", "\n", "ind", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "ind", ")", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "for", "dim", "in", "range", "(", "2", ",", "inputs", ".", "dim", "(", ")", ")", ":", "\n", "        ", "ind", "=", "ind", ".", "unsqueeze", "(", "dim", ")", "\n", "", "ind", "=", "ind", ".", "expand_as", "(", "inputs", ")", "\n", "if", "inputs", ".", "is_cuda", ":", "\n", "        ", "ind", "=", "ind", ".", "cuda", "(", "inputs", ".", "get_device", "(", ")", ")", "\n", "", "reversed_inputs", "=", "torch", ".", "gather", "(", "inputs", ",", "0", ",", "ind", ")", "\n", "if", "batch_first", ":", "\n", "        ", "reversed_inputs", "=", "reversed_inputs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "return", "reversed_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusRNN.__init__": [[17, 31], ["torch.Module.__init__", "geoopt.PoincareBall", "geoopt.PoincareBall", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "geoopt.ManifoldTensor().uniform_", "geoopt.ManifoldTensor().uniform_", "geoopt.ManifoldTensor().uniform_", "geoopt.ManifoldTensor().uniform_", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "geoopt.expmap0", "geoopt.expmap0", "geoopt.ManifoldTensor", "geoopt.ManifoldTensor", "geoopt.ManifoldTensor", "geoopt.ManifoldTensor"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ")", ":", "\n", "        ", "super", "(", "MobiusRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "ball", "=", "gt", ".", "PoincareBall", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "\n", "# k = (1 / hidden_size)**0.5", "\n", "k_w", "=", "(", "6", "/", "(", "self", ".", "hidden_size", "+", "self", ".", "hidden_size", ")", ")", "**", "0.5", "# xavier uniform", "\n", "k_u", "=", "(", "6", "/", "(", "self", ".", "input_size", "+", "self", ".", "hidden_size", ")", ")", "**", "0.5", "# xavier uniform", "\n", "self", ".", "w", "=", "gt", ".", "ManifoldParameter", "(", "gt", ".", "ManifoldTensor", "(", "hidden_size", ",", "hidden_size", ")", ".", "uniform_", "(", "-", "k_w", ",", "k_w", ")", ")", "\n", "self", ".", "u", "=", "gt", ".", "ManifoldParameter", "(", "gt", ".", "ManifoldTensor", "(", "input_size", ",", "hidden_size", ")", ".", "uniform_", "(", "-", "k_u", ",", "k_u", ")", ")", "\n", "bias", "=", "torch", ".", "randn", "(", "hidden_size", ")", "*", "1e-5", "\n", "self", ".", "b", "=", "gt", ".", "ManifoldParameter", "(", "pmath", ".", "expmap0", "(", "bias", ",", "k", "=", "self", ".", "ball", ".", "k", ")", ",", "manifold", "=", "self", ".", "ball", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusRNN.transition": [[32, 43], ["geoopt.mobius_matvec", "geoopt.mobius_matvec", "geoopt.mobius_matvec", "geoopt.mobius_matvec", "geoopt.mobius_add", "geoopt.mobius_add", "geoopt.mobius_add", "geoopt.mobius_add"], "methods", ["None"], ["", "def", "transition", "(", "self", ",", "x", ",", "h", ")", ":", "\n", "        ", "\"\"\"\n        :param x: batch x input\n        :param h: hidden x hidden\n        :return: batch x hidden\n        \"\"\"", "\n", "W_otimes_h", "=", "pmath", ".", "mobius_matvec", "(", "self", ".", "w", ",", "h", ",", "k", "=", "self", ".", "ball", ".", "k", ")", "\n", "U_otimes_x", "=", "pmath", ".", "mobius_matvec", "(", "self", ".", "u", ",", "x", ",", "k", "=", "self", ".", "ball", ".", "k", ")", "\n", "Wh_plus_Ux", "=", "pmath", ".", "mobius_add", "(", "W_otimes_h", ",", "U_otimes_x", ",", "k", "=", "self", ".", "ball", ".", "k", ")", "\n", "\n", "return", "pmath", ".", "mobius_add", "(", "Wh_plus_Ux", ",", "self", ".", "b", ",", "k", "=", "self", ".", "ball", ".", "k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusRNN.init_rnn_state": [[44, 46], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "init_rnn_state", "(", "self", ",", "batch_size", ",", "hidden_size", ")", ":", "\n", "        ", "return", "torch", ".", "zeros", "(", "(", "batch_size", ",", "hidden_size", ")", ",", "dtype", "=", "DEFAULT_DTYPE", ",", "device", "=", "DEVICE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusRNN.forward": [[47, 58], ["hypernn.MobiusRNN.init_rnn_state", "inputs.transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "hypernn.MobiusRNN.transition", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclRNN.init_rnn_state", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclRNN.transition"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        :param inputs: batch x seq_len x embed_dim\n        :return: batch x seq_len x hidden_size\n        \"\"\"", "\n", "hidden", "=", "self", ".", "init_rnn_state", "(", "inputs", ".", "shape", "[", "0", "]", ",", "self", ".", "hidden_size", ")", "# batch x hidden_size", "\n", "outputs", "=", "[", "]", "\n", "for", "x", "in", "inputs", ".", "transpose", "(", "0", ",", "1", ")", ":", "# seq_len x batch x dim transposes in order to iterate through words", "\n", "            ", "hidden", "=", "self", ".", "transition", "(", "x", ",", "hidden", ")", "# of the whole batch at each step", "\n", "outputs", "+=", "[", "hidden", "]", "\n", "", "return", "torch", ".", "stack", "(", "outputs", ")", ".", "transpose", "(", "0", ",", "1", ")", "# batch x seq_len x hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclRNN.__init__": [[62, 76], ["torch.Module.__init__", "geoopt.Euclidean", "geoopt.Euclidean", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "geoopt.ManifoldTensor().uniform_", "geoopt.ManifoldTensor().uniform_", "geoopt.ManifoldTensor().uniform_", "geoopt.ManifoldTensor().uniform_", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "geoopt.ManifoldTensor", "geoopt.ManifoldTensor", "geoopt.ManifoldTensor", "geoopt.ManifoldTensor"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ")", ":", "\n", "        ", "super", "(", "EuclRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "manifold", "=", "gt", ".", "Euclidean", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "\n", "# k = (1 / hidden_size)**0.5", "\n", "k_w", "=", "(", "6", "/", "(", "self", ".", "hidden_size", "+", "self", ".", "hidden_size", ")", ")", "**", "0.5", "# xavier uniform", "\n", "k_u", "=", "(", "6", "/", "(", "self", ".", "input_size", "+", "self", ".", "hidden_size", ")", ")", "**", "0.5", "# xavier uniform", "\n", "self", ".", "w", "=", "gt", ".", "ManifoldParameter", "(", "gt", ".", "ManifoldTensor", "(", "hidden_size", ",", "hidden_size", ")", ".", "uniform_", "(", "-", "k_w", ",", "k_w", ")", ")", "\n", "self", ".", "u", "=", "gt", ".", "ManifoldParameter", "(", "gt", ".", "ManifoldTensor", "(", "input_size", ",", "hidden_size", ")", ".", "uniform_", "(", "-", "k_u", ",", "k_u", ")", ")", "\n", "bias", "=", "torch", ".", "randn", "(", "hidden_size", ")", "*", "1e-5", "\n", "self", ".", "b", "=", "gt", ".", "ManifoldParameter", "(", "bias", ",", "manifold", "=", "self", ".", "manifold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclRNN.transition": [[77, 86], ["h.matmul", "x.matmul"], "methods", ["None"], ["", "def", "transition", "(", "self", ",", "x", ",", "h", ")", ":", "\n", "        ", "\"\"\"\n        :param x: batch x input\n        :param h: hidden x hidden\n        :return: batch x hidden\n        \"\"\"", "\n", "W_otimes_h", "=", "h", ".", "matmul", "(", "self", ".", "w", ")", "\n", "U_otimes_x", "=", "x", ".", "matmul", "(", "self", ".", "u", ")", "\n", "return", "W_otimes_h", "+", "U_otimes_x", "+", "self", ".", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclRNN.init_rnn_state": [[87, 89], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "init_rnn_state", "(", "self", ",", "batch_size", ",", "hidden_size", ")", ":", "\n", "        ", "return", "torch", ".", "zeros", "(", "(", "batch_size", ",", "hidden_size", ")", ",", "dtype", "=", "DEFAULT_DTYPE", ",", "device", "=", "DEVICE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclRNN.forward": [[90, 101], ["hypernn.EuclRNN.init_rnn_state", "inputs.transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "hypernn.EuclRNN.transition", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclRNN.init_rnn_state", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclRNN.transition"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        :param inputs: batch x seq_len x embed_dim\n        :return: batch x seq_len x hidden_size\n        \"\"\"", "\n", "hidden", "=", "self", ".", "init_rnn_state", "(", "inputs", ".", "shape", "[", "0", "]", ",", "self", ".", "hidden_size", ")", "# batch x hidden_size", "\n", "outputs", "=", "[", "]", "\n", "for", "x", "in", "inputs", ".", "transpose", "(", "0", ",", "1", ")", ":", "# seq_len x batch x dim transposes in order to iterate through words", "\n", "            ", "hidden", "=", "self", ".", "transition", "(", "x", ",", "hidden", ")", "# of the whole batch at each step", "\n", "outputs", "+=", "[", "hidden", "]", "\n", "", "return", "torch", ".", "stack", "(", "outputs", ")", ".", "transpose", "(", "0", ",", "1", ")", "# batch x seq_len x hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusGRU.__init__": [[104, 132], ["torch.Module.__init__", "geoopt.PoincareBall", "geoopt.PoincareBall", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "hypernn.MobiusGRU.reset_parameters", "range", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "hypernn.MobiusGRU.register_buffer", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "biases.append", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "range", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "geoopt.expmap0", "geoopt.expmap0"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclGRU.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "num_layers", "=", "1", ",", "bias", "=", "True", ",", "nonlin", "=", "None", ",", "hyperbolic_input", "=", "True", ",", "\n", "hyperbolic_hidden_state0", "=", "True", ",", "c", "=", "1.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ball", "=", "gt", ".", "PoincareBall", "(", "c", "=", "c", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "weight_ih", "=", "torch", ".", "nn", ".", "ParameterList", "(", "\n", "[", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "hidden_size", ",", "input_size", "if", "i", "==", "0", "else", "hidden_size", ")", ")", "\n", "for", "i", "in", "range", "(", "num_layers", ")", "]", "\n", ")", "\n", "self", ".", "weight_hh", "=", "torch", ".", "nn", ".", "ParameterList", "(", "\n", "[", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "hidden_size", ",", "hidden_size", ")", ")", "for", "_", "in", "range", "(", "num_layers", ")", "]", "\n", ")", "\n", "if", "bias", ":", "\n", "            ", "biases", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "                ", "bias", "=", "torch", ".", "randn", "(", "3", ",", "hidden_size", ")", "*", "1e-5", "\n", "bias", "=", "gt", ".", "ManifoldParameter", "(", "pmath", ".", "expmap0", "(", "bias", ",", "k", "=", "self", ".", "ball", ".", "k", ")", ",", "manifold", "=", "self", ".", "ball", ")", "\n", "biases", ".", "append", "(", "bias", ")", "\n", "", "self", ".", "bias", "=", "torch", ".", "nn", ".", "ParameterList", "(", "biases", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_buffer", "(", "\"bias\"", ",", "None", ")", "\n", "", "self", ".", "nonlin", "=", "nonlin", "\n", "self", ".", "hyperbolic_input", "=", "hyperbolic_input", "\n", "self", ".", "hyperbolic_hidden_state0", "=", "hyperbolic_hidden_state0", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusGRU.reset_parameters": [[133, 138], ["itertools.chain.from_iterable", "weight.size", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "weight", "in", "itertools", ".", "chain", ".", "from_iterable", "(", "[", "self", ".", "weight_ih", ",", "self", ".", "weight_hh", "]", ")", ":", "\n", "            ", "rows", ",", "cols", "=", "weight", ".", "size", "(", ")", "\n", "stdv", "=", "(", "6", "/", "(", "rows", "/", "3", "+", "cols", ")", ")", "**", "0.5", "# xavier uniform", "\n", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "weight", ",", "-", "stdv", ",", "stdv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusGRU.forward": [[139, 186], ["isinstance", "input.new_zeros.unbind", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "int", "input.size", "input.new_zeros", "hypernn.mobius_gru_loop", "outputs.append", "last_states.append", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.mobius_gru_loop"], ["", "", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ",", "h0", "=", "None", ")", ":", "\n", "# input shape: seq_len, batch, input_size", "\n", "# hx shape: batch, hidden_size", "\n", "        ", "is_packed", "=", "isinstance", "(", "input", ",", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "PackedSequence", ")", "\n", "if", "is_packed", ":", "\n", "            ", "input", ",", "batch_sizes", "=", "input", "[", ":", "2", "]", "\n", "max_batch_size", "=", "int", "(", "batch_sizes", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "batch_sizes", "=", "None", "\n", "max_batch_size", "=", "input", ".", "size", "(", "1", ")", "\n", "", "if", "h0", "is", "None", ":", "\n", "            ", "h0", "=", "input", ".", "new_zeros", "(", "\n", "self", ".", "num_layers", ",", "max_batch_size", ",", "self", ".", "hidden_size", ",", "requires_grad", "=", "False", "\n", ")", "\n", "", "h0", "=", "h0", ".", "unbind", "(", "0", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "biases", "=", "self", ".", "bias", "\n", "", "else", ":", "\n", "            ", "biases", "=", "(", "None", ",", ")", "*", "self", ".", "num_layers", "\n", "", "outputs", "=", "[", "]", "\n", "last_states", "=", "[", "]", "\n", "out", "=", "input", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "out", ",", "h_last", "=", "mobius_gru_loop", "(", "\n", "input", "=", "out", ",", "\n", "h0", "=", "h0", "[", "i", "]", ",", "\n", "weight_ih", "=", "self", ".", "weight_ih", "[", "i", "]", ",", "\n", "weight_hh", "=", "self", ".", "weight_hh", "[", "i", "]", ",", "\n", "bias", "=", "biases", "[", "i", "]", ",", "\n", "k", "=", "self", ".", "ball", ".", "k", ",", "\n", "hyperbolic_hidden_state0", "=", "self", ".", "hyperbolic_hidden_state0", "or", "i", ">", "0", ",", "\n", "hyperbolic_input", "=", "self", ".", "hyperbolic_input", "or", "i", ">", "0", ",", "\n", "nonlin", "=", "self", ".", "nonlin", ",", "\n", "batch_sizes", "=", "batch_sizes", ",", "\n", ")", "\n", "outputs", ".", "append", "(", "out", ")", "\n", "last_states", ".", "append", "(", "h_last", ")", "\n", "", "if", "is_packed", ":", "\n", "            ", "out", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "PackedSequence", "(", "out", ",", "batch_sizes", ")", "\n", "", "ht", "=", "torch", ".", "stack", "(", "last_states", ")", "\n", "# default api assumes", "\n", "# out: (seq_len, batch, num_directions * hidden_size)", "\n", "# ht: (num_layers * num_directions, batch, hidden_size)", "\n", "# if packed:", "\n", "# out: (sum(seq_len), num_directions * hidden_size)", "\n", "# ht: (num_layers * num_directions, batch, hidden_size)", "\n", "return", "out", ",", "ht", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusGRU.extra_repr": [[187, 194], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "\"{input_size}, {hidden_size}, {num_layers}, bias={bias}, \"", "\n", "\"hyperbolic_input={hyperbolic_input}, \"", "\n", "\"hyperbolic_hidden_state0={hyperbolic_hidden_state0}, \"", "\n", "\"c={self.ball.c}\"", "\n", ")", ".", "format", "(", "**", "self", ".", "__dict__", ",", "self", "=", "self", ",", "bias", "=", "self", ".", "bias", "is", "not", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclGRU.__init__": [[197, 222], ["torch.Module.__init__", "geoopt.Euclidean", "geoopt.Euclidean", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "hypernn.EuclGRU.reset_parameters", "range", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "hypernn.EuclGRU.register_buffer", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "biases.append", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "range", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclGRU.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "num_layers", "=", "1", ",", "bias", "=", "True", ",", "nonlin", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "manifold", "=", "gt", ".", "Euclidean", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "weight_ih", "=", "torch", ".", "nn", ".", "ParameterList", "(", "\n", "[", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "hidden_size", ",", "input_size", "if", "i", "==", "0", "else", "hidden_size", ")", ")", "\n", "for", "i", "in", "range", "(", "num_layers", ")", "]", "\n", ")", "\n", "self", ".", "weight_hh", "=", "torch", ".", "nn", ".", "ParameterList", "(", "\n", "[", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "hidden_size", ",", "hidden_size", ")", ")", "for", "_", "in", "range", "(", "num_layers", ")", "]", "\n", ")", "\n", "if", "bias", ":", "\n", "            ", "biases", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "                ", "bias", "=", "torch", ".", "randn", "(", "3", ",", "hidden_size", ")", "*", "1e-5", "\n", "bias", "=", "gt", ".", "ManifoldParameter", "(", "bias", ",", "manifold", "=", "self", ".", "manifold", ")", "\n", "biases", ".", "append", "(", "bias", ")", "\n", "", "self", ".", "bias", "=", "torch", ".", "nn", ".", "ParameterList", "(", "biases", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_buffer", "(", "\"bias\"", ",", "None", ")", "\n", "", "self", ".", "nonlin", "=", "nonlin", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclGRU.reset_parameters": [[223, 228], ["itertools.chain.from_iterable", "weight.size", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "weight", "in", "itertools", ".", "chain", ".", "from_iterable", "(", "[", "self", ".", "weight_ih", ",", "self", ".", "weight_hh", "]", ")", ":", "\n", "            ", "rows", ",", "cols", "=", "weight", ".", "size", "(", ")", "\n", "stdv", "=", "(", "6", "/", "(", "rows", "/", "3", "+", "cols", ")", ")", "**", "0.5", "# xavier uniform", "\n", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "weight", ",", "-", "stdv", ",", "stdv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclGRU.forward": [[229, 273], ["isinstance", "input.new_zeros.unbind", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "int", "input.size", "input.new_zeros", "hypernn.eucl_gru_loop", "outputs.append", "last_states.append", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.eucl_gru_loop"], ["", "", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ",", "h0", "=", "None", ")", ":", "\n", "# input shape: seq_len, batch, input_size", "\n", "# hx shape: batch, hidden_size", "\n", "        ", "is_packed", "=", "isinstance", "(", "input", ",", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "PackedSequence", ")", "\n", "if", "is_packed", ":", "\n", "            ", "input", ",", "batch_sizes", "=", "input", "[", ":", "2", "]", "\n", "max_batch_size", "=", "int", "(", "batch_sizes", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "batch_sizes", "=", "None", "\n", "max_batch_size", "=", "input", ".", "size", "(", "1", ")", "\n", "", "if", "h0", "is", "None", ":", "\n", "            ", "h0", "=", "input", ".", "new_zeros", "(", "\n", "self", ".", "num_layers", ",", "max_batch_size", ",", "self", ".", "hidden_size", ",", "requires_grad", "=", "False", "\n", ")", "\n", "", "h0", "=", "h0", ".", "unbind", "(", "0", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "biases", "=", "self", ".", "bias", "\n", "", "else", ":", "\n", "            ", "biases", "=", "(", "None", ",", ")", "*", "self", ".", "num_layers", "\n", "", "outputs", "=", "[", "]", "\n", "last_states", "=", "[", "]", "\n", "out", "=", "input", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "out", ",", "h_last", "=", "eucl_gru_loop", "(", "\n", "input", "=", "out", ",", "\n", "h0", "=", "h0", "[", "i", "]", ",", "\n", "weight_ih", "=", "self", ".", "weight_ih", "[", "i", "]", ",", "\n", "weight_hh", "=", "self", ".", "weight_hh", "[", "i", "]", ",", "\n", "bias", "=", "biases", "[", "i", "]", ",", "\n", "nonlin", "=", "self", ".", "nonlin", ",", "\n", "batch_sizes", "=", "batch_sizes", ",", "\n", ")", "\n", "outputs", ".", "append", "(", "out", ")", "\n", "last_states", ".", "append", "(", "h_last", ")", "\n", "", "if", "is_packed", ":", "\n", "            ", "out", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "PackedSequence", "(", "out", ",", "batch_sizes", ")", "\n", "", "ht", "=", "torch", ".", "stack", "(", "last_states", ")", "\n", "# default api assumes", "\n", "# out: (seq_len, batch, num_directions * hidden_size)", "\n", "# ht: (num_layers * num_directions, batch, hidden_size)", "\n", "# if packed:", "\n", "# out: (sum(seq_len), num_directions * hidden_size)", "\n", "# ht: (num_layers * num_directions, batch, hidden_size)", "\n", "return", "out", ",", "ht", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclGRU.extra_repr": [[274, 277], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "(", "\"{input_size}, {hidden_size}, {num_layers}, bias={bias}, \"", "\n", "\"\"", ")", ".", "format", "(", "**", "self", ".", "__dict__", ",", "self", "=", "self", ",", "bias", "=", "self", ".", "bias", "is", "not", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusLinear.__init__": [[280, 295], ["torch.Linear.__init__", "geoopt.PoincareBall", "geoopt.PoincareBall", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "hypernn.MobiusLinear.weight.size", "hypernn.MobiusLinear.weight.uniform_", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "hypernn.MobiusLinear.bias.set_", "geoopt.expmap0", "geoopt.expmap0", "hypernn.MobiusLinear.bias.normal_"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "hyperbolic_input", "=", "True", ",", "hyperbolic_bias", "=", "True", ",", "nonlin", "=", "None", ",", "c", "=", "1.0", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "ball", "=", "gt", ".", "PoincareBall", "(", "c", "=", "c", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "if", "hyperbolic_bias", ":", "\n", "                ", "self", ".", "bias", "=", "gt", ".", "ManifoldParameter", "(", "self", ".", "bias", ",", "manifold", "=", "self", ".", "ball", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "self", ".", "bias", ".", "set_", "(", "pmath", ".", "expmap0", "(", "self", ".", "bias", ".", "normal_", "(", ")", "*", "1e-3", ",", "k", "=", "self", ".", "ball", ".", "k", ")", ")", "\n", "", "", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "fin", ",", "fout", "=", "self", ".", "weight", ".", "size", "(", ")", "\n", "k", "=", "(", "6", "/", "(", "fin", "+", "fout", ")", ")", "**", "0.5", "# xavier uniform", "\n", "self", ".", "weight", ".", "uniform_", "(", "-", "k", ",", "k", ")", "\n", "", "self", ".", "hyperbolic_bias", "=", "hyperbolic_bias", "\n", "self", ".", "hyperbolic_input", "=", "hyperbolic_input", "\n", "self", ".", "nonlin", "=", "nonlin", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusLinear.forward": [[296, 305], ["hypernn.mobius_linear"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.mobius_linear"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "mobius_linear", "(", "\n", "input", ",", "\n", "weight", "=", "self", ".", "weight", ",", "\n", "bias", "=", "self", ".", "bias", ",", "\n", "hyperbolic_input", "=", "self", ".", "hyperbolic_input", ",", "\n", "nonlin", "=", "self", ".", "nonlin", ",", "\n", "hyperbolic_bias", "=", "self", ".", "hyperbolic_bias", ",", "\n", "k", "=", "self", ".", "ball", ".", "k", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusLinear.extra_repr": [[307, 313], ["super().extra_repr"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclMLR.extra_repr"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "info", "=", "super", "(", ")", ".", "extra_repr", "(", ")", "\n", "info", "+=", "\", hyperbolic_input={}\"", ".", "format", "(", "self", ".", "hyperbolic_input", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "info", "+=", "\", hyperbolic_bias={}\"", ".", "format", "(", "self", ".", "hyperbolic_bias", ")", "\n", "", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.__init__": [[316, 329], ["torch.Module.__init__", "hypernn.MobiusLinear", "hypernn.MobiusLinear", "geoopt.PoincareBall", "geoopt.PoincareBall", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "hypernn.MobiusLinear", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "geoopt.expmap0", "geoopt.expmap0"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_dim", ",", "input_dims", ",", "second_input_dim", "=", "None", ",", "third_input_dim", "=", "None", ",", "nonlin", "=", "None", ")", ":", "\n", "        ", "super", "(", "MobiusConcat", ",", "self", ")", ".", "__init__", "(", ")", "\n", "b_input_dims", "=", "second_input_dim", "if", "second_input_dim", "is", "not", "None", "else", "input_dims", "\n", "\n", "self", ".", "lin_a", "=", "MobiusLinear", "(", "input_dims", ",", "output_dim", ",", "bias", "=", "False", ",", "nonlin", "=", "nonlin", ")", "\n", "self", ".", "lin_b", "=", "MobiusLinear", "(", "b_input_dims", ",", "output_dim", ",", "bias", "=", "False", ",", "nonlin", "=", "nonlin", ")", "\n", "\n", "if", "third_input_dim", ":", "\n", "            ", "self", ".", "lin_c", "=", "MobiusLinear", "(", "third_input_dim", ",", "output_dim", ",", "bias", "=", "False", ",", "nonlin", "=", "nonlin", ")", "\n", "\n", "", "self", ".", "ball", "=", "gt", ".", "PoincareBall", "(", ")", "\n", "b", "=", "torch", ".", "randn", "(", "output_dim", ")", "*", "1e-5", "\n", "self", ".", "bias", "=", "gt", ".", "ManifoldParameter", "(", "pmath", ".", "expmap0", "(", "b", ",", "k", "=", "self", ".", "ball", ".", "k", ")", ",", "manifold", "=", "self", ".", "ball", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.forward": [[330, 346], ["hypernn.MobiusConcat.lin_a", "hypernn.MobiusConcat.lin_b", "hypernn.MobiusConcat.add", "hypernn.MobiusConcat.add", "hypernn.MobiusConcat.lin_c", "hypernn.MobiusConcat.add"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.add", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.add", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.add"], ["", "def", "forward", "(", "self", ",", "input_a", ",", "input_b", ",", "third_input", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param input_a: batch x * x input_dim_a\n        :param input_b: batch x * x input_dim_b\n        :return: batch x output_dim\n        \"\"\"", "\n", "out_a", "=", "self", ".", "lin_a", "(", "input_a", ")", "\n", "out_b", "=", "self", ".", "lin_b", "(", "input_b", ")", "\n", "out_total", "=", "self", ".", "add", "(", "out_a", ",", "out_b", ")", "\n", "\n", "if", "third_input", "is", "not", "None", ":", "\n", "            ", "out_c", "=", "self", ".", "lin_c", "(", "third_input", ")", "\n", "out_total", "=", "self", ".", "add", "(", "out_total", ",", "out_c", ")", "\n", "\n", "", "out_total", "=", "self", ".", "add", "(", "out_total", ",", "self", ".", "bias", ")", "\n", "return", "out_total", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusConcat.add": [[347, 350], ["geoopt.mobius_add", "geoopt.mobius_add", "geoopt.project", "geoopt.project"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "a", ",", "b", ")", ":", "\n", "        ", "out", "=", "pmath", ".", "mobius_add", "(", "a", ",", "b", ",", "k", "=", "self", ".", "ball", ".", "k", ")", "\n", "return", "pmath", ".", "project", "(", "out", ",", "k", "=", "self", ".", "ball", ".", "k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclConcat.__init__": [[353, 366], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "geoopt.Euclidean", "geoopt.Euclidean", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_dim", ",", "input_dims", ",", "second_input_dim", "=", "None", ",", "third_input_dim", "=", "None", ",", "nonlin", "=", "None", ")", ":", "\n", "        ", "super", "(", "EuclConcat", ",", "self", ")", ".", "__init__", "(", ")", "\n", "b_input_dims", "=", "second_input_dim", "if", "second_input_dim", "is", "not", "None", "else", "input_dims", "\n", "\n", "self", ".", "lin_a", "=", "nn", ".", "Linear", "(", "input_dims", ",", "output_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "lin_b", "=", "nn", ".", "Linear", "(", "b_input_dims", ",", "output_dim", ",", "bias", "=", "False", ")", "\n", "\n", "if", "third_input_dim", ":", "\n", "            ", "self", ".", "lin_c", "=", "nn", ".", "Linear", "(", "third_input_dim", ",", "output_dim", ",", "bias", "=", "False", ")", "\n", "\n", "", "self", ".", "manifold", "=", "gt", ".", "Euclidean", "(", ")", "\n", "self", ".", "bias", "=", "gt", ".", "ManifoldParameter", "(", "torch", ".", "randn", "(", "output_dim", ")", "*", "1e-5", ",", "manifold", "=", "self", ".", "manifold", ")", "\n", "self", ".", "nonlin", "=", "nonlin", "if", "nonlin", "is", "not", "None", "else", "lambda", "x", ":", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclConcat.forward": [[367, 383], ["hypernn.EuclConcat.nonlin", "hypernn.EuclConcat.nonlin", "hypernn.EuclConcat.lin_a", "hypernn.EuclConcat.lin_b", "hypernn.EuclConcat.nonlin", "hypernn.EuclConcat.lin_c"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_a", ",", "input_b", ",", "third_input", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param input_a: batch x * x input_dim_a\n        :param input_b: batch x * x input_dim_b\n        :return: batch x output_dim\n        \"\"\"", "\n", "out_a", "=", "self", ".", "nonlin", "(", "self", ".", "lin_a", "(", "input_a", ")", ")", "\n", "out_b", "=", "self", ".", "nonlin", "(", "self", ".", "lin_b", "(", "input_b", ")", ")", "\n", "out_total", "=", "out_a", "+", "out_b", "\n", "\n", "if", "third_input", "is", "not", "None", ":", "\n", "            ", "out_c", "=", "self", ".", "nonlin", "(", "self", ".", "lin_c", "(", "third_input", ")", ")", "\n", "out_total", "+=", "out_c", "\n", "\n", "", "out_total", "+=", "self", ".", "bias", "\n", "return", "out_total", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusMLR.__init__": [[406, 423], ["torch.Module.__init__", "geoopt.PoincareBall", "geoopt.PoincareBall", "geoopt.expmap0", "geoopt.expmap0", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "c", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"\n        :param in_features: number of dimensions of the input\n        :param out_features: number of classes\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "ball", "=", "gt", ".", "PoincareBall", "(", "c", "=", "c", ")", "\n", "points", "=", "torch", ".", "randn", "(", "out_features", ",", "in_features", ")", "*", "1e-5", "\n", "points", "=", "pmath", ".", "expmap0", "(", "points", ",", "k", "=", "self", ".", "ball", ".", "k", ")", "\n", "self", ".", "p_k", "=", "gt", ".", "ManifoldParameter", "(", "points", ",", "manifold", "=", "self", ".", "ball", ")", "\n", "\n", "tangent", "=", "torch", ".", "Tensor", "(", "out_features", ",", "in_features", ")", "\n", "stdv", "=", "(", "6", "/", "(", "out_features", "+", "in_features", ")", ")", "**", "0.5", "# xavier uniform", "\n", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "tangent", ",", "-", "stdv", ",", "stdv", ")", "\n", "self", ".", "a_k", "=", "torch", ".", "nn", ".", "Parameter", "(", "tangent", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusMLR.forward": [[424, 433], ["input.unsqueeze.unsqueeze.unsqueeze", "hypernn.MobiusMLR._dist2plane"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusMLR._dist2plane"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"\n        :param input: batch x space_dim: points (features) in the Poincar\u00e9 ball\n        :return: batch x classes: logit of probabilities for 'out_features' classes\n        \"\"\"", "\n", "input", "=", "input", ".", "unsqueeze", "(", "-", "2", ")", "# batch x aux x space_dim", "\n", "distance", ",", "a_norm", "=", "self", ".", "_dist2plane", "(", "x", "=", "input", ",", "p", "=", "self", ".", "p_k", ",", "a", "=", "self", ".", "a_k", ",", "c", "=", "self", ".", "ball", ".", "c", ",", "k", "=", "self", ".", "ball", ".", "k", ",", "signed", "=", "True", ")", "\n", "result", "=", "2", "*", "a_norm", "*", "distance", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusMLR._dist2plane": [[434, 448], ["geoopt.mobius_add", "geoopt.mobius_add", "geoopt.mobius_add.pow().sum().clamp_min", "a.norm().clamp_min", "mpx_dot_a.abs.abs.abs", "geoopt.mobius_add.pow().sum", "a.norm", "geoopt.arsinh", "geoopt.arsinh", "geoopt.mobius_add.pow", "denom.clamp_min"], "methods", ["None"], ["", "def", "_dist2plane", "(", "self", ",", "x", ",", "a", ",", "p", ",", "c", ",", "k", ",", "keepdim", ":", "bool", "=", "False", ",", "signed", ":", "bool", "=", "False", ",", "dim", ":", "int", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"\n        Taken from geoopt and corrected so it returns a_norm and this value does not have to be calculated twice\n        \"\"\"", "\n", "sqrt_c", "=", "c", "**", "0.5", "\n", "minus_p_plus_x", "=", "pmath", ".", "mobius_add", "(", "-", "p", ",", "x", ",", "k", "=", "k", ",", "dim", "=", "dim", ")", "\n", "mpx_sqnorm", "=", "minus_p_plus_x", ".", "pow", "(", "2", ")", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "keepdim", ")", ".", "clamp_min", "(", "MIN_NORM", ")", "\n", "mpx_dot_a", "=", "(", "minus_p_plus_x", "*", "a", ")", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "keepdim", ")", "\n", "if", "not", "signed", ":", "\n", "            ", "mpx_dot_a", "=", "mpx_dot_a", ".", "abs", "(", ")", "\n", "", "a_norm", "=", "a", ".", "norm", "(", "dim", "=", "dim", ",", "keepdim", "=", "keepdim", ",", "p", "=", "2", ")", ".", "clamp_min", "(", "MIN_NORM", ")", "\n", "num", "=", "2", "*", "sqrt_c", "*", "mpx_dot_a", "\n", "denom", "=", "(", "1", "-", "c", "*", "mpx_sqnorm", ")", "*", "a_norm", "\n", "return", "pmath", ".", "arsinh", "(", "num", "/", "denom", ".", "clamp_min", "(", "MIN_NORM", ")", ")", "/", "sqrt_c", ",", "a_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.MobiusMLR.extra_repr": [[449, 451], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "\"in_features={in_features}, out_features={out_features}\"", ".", "format", "(", "**", "self", ".", "__dict__", ")", "+", "f\" k={self.ball.k}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclMLR.__init__": [[456, 472], ["torch.Module.__init__", "geoopt.Euclidean", "geoopt.Euclidean", "geoopt.ManifoldParameter", "geoopt.ManifoldParameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ")", ":", "\n", "        ", "\"\"\"\n        :param in_features: number of dimensions of the input\n        :param out_features: number of classes\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "manifold", "=", "gt", ".", "Euclidean", "(", ")", "\n", "points", "=", "torch", ".", "randn", "(", "out_features", ",", "in_features", ")", "*", "1e-5", "\n", "self", ".", "p_k", "=", "gt", ".", "ManifoldParameter", "(", "points", ",", "manifold", "=", "self", ".", "manifold", ")", "\n", "\n", "tangent", "=", "torch", ".", "Tensor", "(", "out_features", ",", "in_features", ")", "\n", "stdv", "=", "(", "6", "/", "(", "out_features", "+", "in_features", ")", ")", "**", "0.5", "# xavier uniform", "\n", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "tangent", ",", "-", "stdv", ",", "stdv", ")", "\n", "self", ".", "a_k", "=", "torch", ".", "nn", ".", "Parameter", "(", "tangent", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclMLR.forward": [[473, 482], ["input.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"\n        :param input: batch x space_dim: points (features) in the Poincar\u00e9 ball\n        :return: batch x classes: logit of probabilities for 'out_features' classes\n        \"\"\"", "\n", "x", "=", "input", ".", "unsqueeze", "(", "dim", "=", "-", "2", ")", "\n", "minus_p_plus_x", "=", "-", "self", ".", "p_k", "+", "x", "\n", "result", "=", "(", "minus_p_plus_x", "*", "self", ".", "a_k", ")", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "False", ")", "\n", "return", "4", "*", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.EuclMLR.extra_repr": [[483, 485], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "\"in_features={in_features}, out_features={out_features}\"", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.mobius_linear": [[487, 509], ["geoopt.project", "geoopt.mobius_matvec", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "geoopt.expmap0", "geoopt.mobius_add", "geoopt.mobius_fn_apply", "geoopt.expmap0"], "function", ["None"], ["", "", "def", "mobius_linear", "(", "\n", "input", ",", "\n", "weight", ",", "\n", "bias", "=", "None", ",", "\n", "hyperbolic_input", "=", "True", ",", "\n", "hyperbolic_bias", "=", "True", ",", "\n", "nonlin", "=", "None", ",", "\n", "k", "=", "-", "1.0", ",", "\n", ")", ":", "\n", "    ", "if", "hyperbolic_input", ":", "\n", "        ", "output", "=", "pmath", ".", "mobius_matvec", "(", "weight", ",", "input", ",", "k", "=", "k", ")", "\n", "", "else", ":", "\n", "        ", "output", "=", "torch", ".", "nn", ".", "functional", ".", "linear", "(", "input", ",", "weight", ")", "\n", "output", "=", "pmath", ".", "expmap0", "(", "output", ",", "k", "=", "k", ")", "\n", "", "if", "bias", "is", "not", "None", ":", "\n", "        ", "if", "not", "hyperbolic_bias", ":", "\n", "            ", "bias", "=", "pmath", ".", "expmap0", "(", "bias", ",", "k", "=", "k", ")", "\n", "", "output", "=", "pmath", ".", "mobius_add", "(", "output", ",", "bias", ",", "k", "=", "k", ")", "\n", "", "if", "nonlin", "is", "not", "None", ":", "\n", "        ", "output", "=", "pmath", ".", "mobius_fn_apply", "(", "nonlin", ",", "output", ",", "k", "=", "k", ")", "\n", "", "output", "=", "pmath", ".", "project", "(", "output", ",", "k", "=", "k", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.one_hyperb_rnn_transform": [[511, 516], ["geoopt.mobius_matvec", "geoopt.mobius_matvec", "geoopt.mobius_add", "geoopt.mobius_add"], "function", ["None"], ["", "def", "one_hyperb_rnn_transform", "(", "W", ",", "h", ",", "U", ",", "x", ",", "b", ",", "k", ")", ":", "\n", "    ", "W_otimes_h", "=", "pmath", ".", "mobius_matvec", "(", "W", ",", "h", ",", "k", "=", "k", ")", "\n", "U_otimes_x", "=", "pmath", ".", "mobius_matvec", "(", "U", ",", "x", ",", "k", "=", "k", ")", "\n", "Wh_plus_Ux", "=", "pmath", ".", "mobius_add", "(", "W_otimes_h", ",", "U_otimes_x", ",", "k", "=", "k", ")", "\n", "return", "pmath", ".", "mobius_add", "(", "Wh_plus_Ux", ",", "b", ",", "k", "=", "k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.one_eucl_rnn_transform": [[518, 522], ["torch.tensordot", "torch.tensordot", "torch.tensordot", "torch.tensordot", "torch.tensordot", "torch.tensordot", "torch.tensordot", "torch.tensordot"], "function", ["None"], ["", "def", "one_eucl_rnn_transform", "(", "W", ",", "h", ",", "U", ",", "x", ",", "b", ")", ":", "\n", "    ", "W_otimes_h", "=", "torch", ".", "tensordot", "(", "h", ",", "W", ",", "dims", "=", "(", "[", "-", "1", "]", ",", "[", "1", "]", ")", ")", "\n", "U_otimes_x", "=", "torch", ".", "tensordot", "(", "x", ",", "U", ",", "dims", "=", "(", "[", "-", "1", "]", ",", "[", "1", "]", ")", ")", "\n", "return", "W_otimes_h", "+", "U_otimes_x", "+", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.mobius_gru_cell": [[524, 548], ["weight_ih.chunk", "weight_hh.chunk", "geoopt.logmap0().sigmoid", "geoopt.logmap0().sigmoid", "geoopt.mobius_pointwise_mul", "hypernn.one_hyperb_rnn_transform", "geoopt.mobius_add", "geoopt.mobius_add", "geoopt.mobius_fn_apply", "geoopt.mobius_pointwise_mul", "geoopt.logmap0", "geoopt.logmap0", "hypernn.one_hyperb_rnn_transform", "hypernn.one_hyperb_rnn_transform"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.one_hyperb_rnn_transform", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.one_hyperb_rnn_transform", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.one_hyperb_rnn_transform"], ["", "def", "mobius_gru_cell", "(", "\n", "input", ":", "torch", ".", "Tensor", ",", "\n", "hx", ":", "torch", ".", "Tensor", ",", "\n", "weight_ih", ":", "torch", ".", "Tensor", ",", "\n", "weight_hh", ":", "torch", ".", "Tensor", ",", "\n", "bias", ":", "torch", ".", "Tensor", ",", "\n", "k", ":", "torch", ".", "Tensor", ",", "\n", "nonlin", "=", "None", ",", "\n", ")", ":", "\n", "    ", "W_ir", ",", "W_ih", ",", "W_iz", "=", "weight_ih", ".", "chunk", "(", "3", ")", "\n", "b_r", ",", "b_h", ",", "b_z", "=", "bias", "\n", "W_hr", ",", "W_hh", ",", "W_hz", "=", "weight_hh", ".", "chunk", "(", "3", ")", "\n", "\n", "z_t", "=", "pmath", ".", "logmap0", "(", "one_hyperb_rnn_transform", "(", "W_hz", ",", "hx", ",", "W_iz", ",", "input", ",", "b_z", ",", "k", ")", ",", "k", "=", "k", ")", ".", "sigmoid", "(", ")", "\n", "r_t", "=", "pmath", ".", "logmap0", "(", "one_hyperb_rnn_transform", "(", "W_hr", ",", "hx", ",", "W_ir", ",", "input", ",", "b_r", ",", "k", ")", ",", "k", "=", "k", ")", ".", "sigmoid", "(", ")", "\n", "\n", "rh_t", "=", "pmath", ".", "mobius_pointwise_mul", "(", "r_t", ",", "hx", ",", "k", "=", "k", ")", "\n", "h_tilde", "=", "one_hyperb_rnn_transform", "(", "W_hh", ",", "rh_t", ",", "W_ih", ",", "input", ",", "b_h", ",", "k", ")", "\n", "\n", "if", "nonlin", "is", "not", "None", ":", "\n", "        ", "h_tilde", "=", "pmath", ".", "mobius_fn_apply", "(", "nonlin", ",", "h_tilde", ",", "k", "=", "k", ")", "\n", "", "delta_h", "=", "pmath", ".", "mobius_add", "(", "-", "hx", ",", "h_tilde", ",", "k", "=", "k", ")", "\n", "h_out", "=", "pmath", ".", "mobius_add", "(", "hx", ",", "pmath", ".", "mobius_pointwise_mul", "(", "z_t", ",", "delta_h", ",", "k", "=", "k", ")", ",", "k", "=", "k", ")", "\n", "return", "h_out", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.eucl_gru_cell": [[550, 574], ["weight_ih.chunk", "weight_hh.chunk", "one_eucl_rnn_transform().sigmoid", "one_eucl_rnn_transform().sigmoid", "hypernn.one_eucl_rnn_transform", "nonlin", "hypernn.one_eucl_rnn_transform", "hypernn.one_eucl_rnn_transform"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.one_eucl_rnn_transform", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.one_eucl_rnn_transform", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.one_eucl_rnn_transform"], ["", "def", "eucl_gru_cell", "(", "\n", "input", ":", "torch", ".", "Tensor", ",", "\n", "hx", ":", "torch", ".", "Tensor", ",", "\n", "weight_ih", ":", "torch", ".", "Tensor", ",", "\n", "weight_hh", ":", "torch", ".", "Tensor", ",", "\n", "bias", ":", "torch", ".", "Tensor", ",", "\n", "nonlin", "=", "None", "\n", ")", ":", "\n", "    ", "W_ir", ",", "W_ih", ",", "W_iz", "=", "weight_ih", ".", "chunk", "(", "3", ")", "\n", "b_r", ",", "b_h", ",", "b_z", "=", "bias", "\n", "W_hr", ",", "W_hh", ",", "W_hz", "=", "weight_hh", ".", "chunk", "(", "3", ")", "\n", "\n", "z_t", "=", "one_eucl_rnn_transform", "(", "W_hz", ",", "hx", ",", "W_iz", ",", "input", ",", "b_z", ")", ".", "sigmoid", "(", ")", "\n", "r_t", "=", "one_eucl_rnn_transform", "(", "W_hr", ",", "hx", ",", "W_ir", ",", "input", ",", "b_r", ")", ".", "sigmoid", "(", ")", "\n", "\n", "rh_t", "=", "r_t", "*", "hx", "\n", "h_tilde", "=", "one_eucl_rnn_transform", "(", "W_hh", ",", "rh_t", ",", "W_ih", ",", "input", ",", "b_h", ")", "\n", "\n", "if", "nonlin", "is", "not", "None", ":", "\n", "        ", "h_tilde", "=", "nonlin", "(", "h_tilde", ")", "\n", "\n", "", "delta_h", "=", "-", "hx", "+", "h_tilde", "\n", "h_out", "=", "hx", "+", "z_t", "*", "delta_h", "\n", "return", "h_out", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.mobius_gru_loop": [[576, 634], ["geoopt.expmap0", "geoopt.expmap0", "pmath.expmap0.unbind", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "enumerate", "torch.cat.reverse", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pmath.expmap0.size", "hypernn.mobius_gru_cell", "torch.cat.append", "len", "range", "hypernn.mobius_gru_cell", "torch.cat.append", "batch_sizes.size", "torch.cat.append", "torch.cat.append"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.mobius_gru_cell", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.mobius_gru_cell", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "def", "mobius_gru_loop", "(", "\n", "input", ":", "torch", ".", "Tensor", ",", "\n", "h0", ":", "torch", ".", "Tensor", ",", "\n", "weight_ih", ":", "torch", ".", "Tensor", ",", "\n", "weight_hh", ":", "torch", ".", "Tensor", ",", "\n", "bias", ":", "torch", ".", "Tensor", ",", "\n", "k", ":", "torch", ".", "Tensor", ",", "\n", "batch_sizes", "=", "None", ",", "\n", "hyperbolic_input", ":", "bool", "=", "False", ",", "\n", "hyperbolic_hidden_state0", ":", "bool", "=", "False", ",", "\n", "nonlin", "=", "None", ",", "\n", ")", ":", "\n", "    ", "if", "not", "hyperbolic_hidden_state0", ":", "\n", "        ", "hx", "=", "pmath", ".", "expmap0", "(", "h0", ",", "k", "=", "k", ")", "\n", "", "else", ":", "\n", "        ", "hx", "=", "h0", "\n", "", "if", "not", "hyperbolic_input", ":", "\n", "        ", "input", "=", "pmath", ".", "expmap0", "(", "input", ",", "k", "=", "k", ")", "\n", "", "outs", "=", "[", "]", "\n", "if", "batch_sizes", "is", "None", ":", "\n", "        ", "input_unbinded", "=", "input", ".", "unbind", "(", "0", ")", "\n", "for", "t", "in", "range", "(", "input", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "hx", "=", "mobius_gru_cell", "(", "\n", "input", "=", "input_unbinded", "[", "t", "]", ",", "\n", "hx", "=", "hx", ",", "\n", "weight_ih", "=", "weight_ih", ",", "\n", "weight_hh", "=", "weight_hh", ",", "\n", "bias", "=", "bias", ",", "\n", "nonlin", "=", "nonlin", ",", "\n", "k", "=", "k", ",", "\n", ")", "\n", "outs", ".", "append", "(", "hx", ")", "\n", "", "outs", "=", "torch", ".", "stack", "(", "outs", ")", "\n", "h_last", "=", "hx", "\n", "", "else", ":", "\n", "        ", "h_last", "=", "[", "]", "\n", "T", "=", "len", "(", "batch_sizes", ")", "-", "1", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "range", "(", "batch_sizes", ".", "size", "(", "0", ")", ")", ")", ":", "\n", "            ", "ix", ",", "input", "=", "input", "[", ":", "batch_sizes", "[", "t", "]", "]", ",", "input", "[", "batch_sizes", "[", "t", "]", ":", "]", "\n", "hx", "=", "mobius_gru_cell", "(", "\n", "input", "=", "ix", ",", "\n", "hx", "=", "hx", ",", "\n", "weight_ih", "=", "weight_ih", ",", "\n", "weight_hh", "=", "weight_hh", ",", "\n", "bias", "=", "bias", ",", "\n", "nonlin", "=", "nonlin", ",", "\n", "k", "=", "k", ",", "\n", ")", "\n", "outs", ".", "append", "(", "hx", ")", "\n", "if", "t", "<", "T", ":", "\n", "                ", "hx", ",", "ht", "=", "hx", "[", ":", "batch_sizes", "[", "t", "+", "1", "]", "]", ",", "hx", "[", "batch_sizes", "[", "t", "+", "1", "]", ":", "]", "\n", "h_last", ".", "append", "(", "ht", ")", "\n", "", "else", ":", "\n", "                ", "h_last", ".", "append", "(", "hx", ")", "\n", "", "", "h_last", ".", "reverse", "(", ")", "\n", "h_last", "=", "torch", ".", "cat", "(", "h_last", ")", "\n", "outs", "=", "torch", ".", "cat", "(", "outs", ")", "\n", "", "return", "outs", ",", "h_last", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.eucl_gru_loop": [[636, 683], ["input.unbind", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "enumerate", "torch.cat.reverse", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input.size", "hypernn.eucl_gru_cell", "torch.cat.append", "len", "range", "hypernn.eucl_gru_cell", "torch.cat.append", "batch_sizes.size", "torch.cat.append", "torch.cat.append"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.eucl_gru_cell", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.eucl_gru_cell", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "def", "eucl_gru_loop", "(", "\n", "input", ":", "torch", ".", "Tensor", ",", "\n", "h0", ":", "torch", ".", "Tensor", ",", "\n", "weight_ih", ":", "torch", ".", "Tensor", ",", "\n", "weight_hh", ":", "torch", ".", "Tensor", ",", "\n", "bias", ":", "torch", ".", "Tensor", ",", "\n", "batch_sizes", "=", "None", ",", "\n", "nonlin", "=", "None", ")", ":", "\n", "    ", "hx", "=", "h0", "\n", "outs", "=", "[", "]", "\n", "if", "batch_sizes", "is", "None", ":", "\n", "        ", "input_unbinded", "=", "input", ".", "unbind", "(", "0", ")", "\n", "for", "t", "in", "range", "(", "input", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "hx", "=", "eucl_gru_cell", "(", "\n", "input", "=", "input_unbinded", "[", "t", "]", ",", "\n", "hx", "=", "hx", ",", "\n", "weight_ih", "=", "weight_ih", ",", "\n", "weight_hh", "=", "weight_hh", ",", "\n", "bias", "=", "bias", ",", "\n", "nonlin", "=", "nonlin", "\n", ")", "\n", "outs", ".", "append", "(", "hx", ")", "\n", "", "outs", "=", "torch", ".", "stack", "(", "outs", ")", "\n", "h_last", "=", "hx", "\n", "", "else", ":", "\n", "        ", "h_last", "=", "[", "]", "\n", "T", "=", "len", "(", "batch_sizes", ")", "-", "1", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "range", "(", "batch_sizes", ".", "size", "(", "0", ")", ")", ")", ":", "\n", "            ", "ix", ",", "input", "=", "input", "[", ":", "batch_sizes", "[", "t", "]", "]", ",", "input", "[", "batch_sizes", "[", "t", "]", ":", "]", "\n", "hx", "=", "eucl_gru_cell", "(", "\n", "input", "=", "ix", ",", "\n", "hx", "=", "hx", ",", "\n", "weight_ih", "=", "weight_ih", ",", "\n", "weight_hh", "=", "weight_hh", ",", "\n", "bias", "=", "bias", ",", "\n", "nonlin", "=", "nonlin", "\n", ")", "\n", "outs", ".", "append", "(", "hx", ")", "\n", "if", "t", "<", "T", ":", "\n", "                ", "hx", ",", "ht", "=", "hx", "[", ":", "batch_sizes", "[", "t", "+", "1", "]", "]", ",", "hx", "[", "batch_sizes", "[", "t", "+", "1", "]", ":", "]", "\n", "h_last", ".", "append", "(", "ht", ")", "\n", "", "else", ":", "\n", "                ", "h_last", ".", "append", "(", "hx", ")", "\n", "", "", "h_last", ".", "reverse", "(", ")", "\n", "h_last", "=", "torch", ".", "cat", "(", "h_last", ")", "\n", "outs", "=", "torch", ".", "cat", "(", "outs", ")", "\n", "", "return", "outs", ",", "h_last", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.poincare2klein": [[685, 703], ["x.pow().sum", "x.pow"], "function", ["None"], ["", "def", "poincare2klein", "(", "x", ",", "c", "=", "1.0", ",", "dim", "=", "-", "1", ")", ":", "\n", "    ", "r\"\"\"\n    Maps points from Poincare model to Klein model\n    Parameters:\n    ----------\n    x : tensor\n        point on the Poincare ball\n    c : float|tensor\n        ball negative curvature\n    dim : int\n        reduction dimension for operations\n    Returns\n    -------\n    tensor\n        points in Klein model, :math:`\\mathbf{x}_{\\mathbb{K}}=\\frac{2 \\mathbf{x}_{\\mathbb{D}}}{1+c\\left\\|\\mathbf{x}_{\\mathbb{D}}\\right\\|^{2}}`\n    \"\"\"", "\n", "denom", "=", "1.0", "+", "c", "*", "x", ".", "pow", "(", "2", ")", ".", "sum", "(", "dim", ",", "keepdim", "=", "True", ")", "\n", "return", "2.0", "*", "x", "/", "denom", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.klein2poincare": [[705, 723], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "x.pow().sum", "x.pow"], "function", ["None"], ["", "def", "klein2poincare", "(", "x", ",", "c", "=", "1.0", ",", "dim", "=", "-", "1", ")", ":", "\n", "    ", "r\"\"\"\n    Maps points from Klein model to Poincare model\n    Parameters:\n    ----------\n    x : tensor\n        point on the Klein model\n    c : float|tensor\n        ball negative curvature\n    dim : int\n        reduction dimension for operations\n    Returns\n    -------\n    tensor\n        points in Poincare: \\mathbf{x}_{\\mathbb{D}}=\\frac{\\mathbf{X}_{\\mathbb{K}}}{1+\\sqrt{1-c\\left\\|\\mathbf{x}_{\\mathbb{K}}\\right\\|^{2}}}\n    \"\"\"", "\n", "denom", "=", "1.0", "+", "torch", ".", "sqrt", "(", "1.0", "-", "c", "*", "x", ".", "pow", "(", "2", ")", ".", "sum", "(", "dim", ",", "keepdim", "=", "True", ")", ")", "\n", "return", "x", "/", "denom", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.lorentz_factor": [[725, 744], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "x.pow().sum", "x.pow"], "function", ["None"], ["", "def", "lorentz_factor", "(", "x", ",", "c", "=", "1.0", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Parameters\n    ----------\n    x : tensor\n        point on Klein disk\n    c : float\n        negative curvature\n    dim : int\n        dimension to calculate Lorenz factor\n    keepdim : bool\n        retain the last dim? (default: false)\n\n    Returns\n    -------\n    tensor\n        Lorentz factor\n    \"\"\"", "\n", "return", "1", "/", "torch", ".", "sqrt", "(", "1", "-", "c", "*", "x", ".", "pow", "(", "2", ")", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "keepdim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.einstein_midpoint": [[746, 765], ["hypernn.poincare2klein", "hypernn.lorentz_factor", "hypernn.klein2poincare", "klein2poincare.squeeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.poincare2klein", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.lorentz_factor", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.klein2poincare"], ["", "def", "einstein_midpoint", "(", "x", ",", "c", "=", "1.0", ")", ":", "\n", "    ", "r\"\"\"\n    Finds the Einstein midpoint, analogue of finding average over features in Euclidean space\n    Parameters:\n    ----------\n    x : tensor\n        point on the Poincare ball. The points are assumed to be in the last dim\n    c : float|tensor\n        ball negative curvature\n    Returns\n    -------\n    tensor\n        midpoint\n    \"\"\"", "\n", "x", "=", "poincare2klein", "(", "x", ",", "c", ")", "\n", "factors", "=", "lorentz_factor", "(", "x", ",", "c", "=", "c", ",", "keepdim", "=", "True", ")", "\n", "midpoint", "=", "torch", ".", "sum", "(", "factors", "*", "x", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "/", "torch", ".", "sum", "(", "factors", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "midpoint", "=", "klein2poincare", "(", "midpoint", ",", "c", ")", "\n", "return", "midpoint", ".", "squeeze", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.weighted_einstein_midpoint": [[767, 791], ["hypernn.poincare2klein", "hypernn.lorentz_factor", "hypernn.klein2poincare", "klein2poincare.squeeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.poincare2klein", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.lorentz_factor", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.klein2poincare"], ["", "def", "weighted_einstein_midpoint", "(", "x", ",", "w", ",", "c", "=", "1.0", ")", ":", "\n", "    ", "r\"\"\"\n    Finds the Einstein midpoint, analogue of finding average over features in Euclidean space.\n    The input and output of this function are points in the Poincare ball, but internally the points are converted\n    to the klein model of hyperbolic space to calculate the einstein midpoint.\n    Parameters:\n    ----------\n    x : tensor\n        point on the Poincare ball. The points are assumed to be in the last dim: B x seq_len x space_dim\n    w : tensor\n        weights for midpoint. B x seq_len\n    c : float|tensor\n        ball negative curvature\n    Returns\n    -------\n    tensor\n        midpoint\n    \"\"\"", "\n", "x", "=", "poincare2klein", "(", "x", ",", "c", ")", "\n", "factors", "=", "lorentz_factor", "(", "x", ",", "c", "=", "c", ",", "keepdim", "=", "True", ")", "# batch x seq_len", "\n", "weighted_factors", "=", "factors", "*", "w", "\n", "midpoint", "=", "torch", ".", "sum", "(", "weighted_factors", "*", "x", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "/", "torch", ".", "sum", "(", "weighted_factors", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "midpoint", "=", "klein2poincare", "(", "midpoint", ",", "c", ")", "\n", "return", "midpoint", ".", "squeeze", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.mobius_midpoint": [[793, 811], ["geoopt.mobius_scalar_mul", "pmath.mobius_scalar_mul.squeeze", "hypernn.lorentz_factor", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.lorentz_factor"], ["", "def", "mobius_midpoint", "(", "x", ",", "c", "=", "1.0", ")", ":", "\n", "    ", "r\"\"\"\n    Finds the Mobius midpoint, analogue of finding average over features in Euclidean space\n    Parameters:\n    ----------\n    x : tensor\n        point on the Poincare ball. The points are assumed to be in the last dim\n    c : float|tensor\n        ball negative curvature\n    Returns\n    -------\n    tensor\n        midpoint\n    \"\"\"", "\n", "sq_factors", "=", "lorentz_factor", "(", "x", ",", "c", "=", "c", ",", "keepdim", "=", "True", ")", "**", "2", "# batch x seq_len", "\n", "midpoint", "=", "torch", ".", "sum", "(", "sq_factors", "*", "x", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "/", "torch", ".", "sum", "(", "sq_factors", "-", "0.5", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "midpoint", "=", "pmath", ".", "mobius_scalar_mul", "(", "torch", ".", "Tensor", "(", "[", "0.5", "]", ")", ".", "to", "(", "x", ".", "device", ")", ",", "midpoint", ",", "k", "=", "torch", ".", "Tensor", "(", "[", "-", "c", "]", ")", ".", "to", "(", "x", ".", "device", ")", ")", "\n", "return", "midpoint", ".", "squeeze", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.weighted_mobius_midpoint": [[813, 834], ["geoopt.mobius_scalar_mul", "pmath.mobius_scalar_mul.squeeze", "hypernn.lorentz_factor", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.lorentz_factor"], ["", "def", "weighted_mobius_midpoint", "(", "x", ",", "w", ",", "c", "=", "1.0", ")", ":", "\n", "    ", "r\"\"\"\n    Finds the Mobius midpoint, analogue of finding weighted average over features in Euclidean space\n    Parameters:\n    ----------\n    x : tensor\n        point on the Poincare ball. The points are assumed to be in the last dim\n    w : tensor\n        weights for midpoint. B x seq_len\n    c : float|tensor\n        ball negative curvature\n    Returns\n    -------\n    tensor\n        midpoint\n    \"\"\"", "\n", "sq_factors", "=", "lorentz_factor", "(", "x", ",", "c", "=", "c", ",", "keepdim", "=", "True", ")", "**", "2", "# batch x seq_len", "\n", "weighted_factors", "=", "w", "*", "sq_factors", "\n", "midpoint", "=", "torch", ".", "sum", "(", "weighted_factors", "*", "x", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "/", "torch", ".", "sum", "(", "w", "*", "(", "sq_factors", "-", "0.5", ")", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "midpoint", "=", "pmath", ".", "mobius_scalar_mul", "(", "torch", ".", "Tensor", "(", "[", "0.5", "]", ")", ".", "to", "(", "x", ".", "device", ")", ",", "midpoint", ",", "k", "=", "torch", ".", "Tensor", "(", "[", "-", "c", "]", ")", ".", "to", "(", "x", ".", "device", ")", ")", "\n", "return", "midpoint", ".", "squeeze", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.euclidean_midpoint": [[836, 843], ["x.size", "x.sum"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "def", "euclidean_midpoint", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    :param x: b x seq x dim\n    :return: b x dim\n    \"\"\"", "\n", "total", "=", "x", ".", "size", "(", "1", ")", "\n", "return", "x", ".", "sum", "(", "dim", "=", "1", ")", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.hypernn.weighted_euclidean_midpoint": [[845, 853], ["w.sum"], "function", ["None"], ["", "def", "weighted_euclidean_midpoint", "(", "x", ",", "w", ")", ":", "\n", "    ", "\"\"\"\n    :param x: b x seq x dim\n    :param w: b x seq x 1\n    :return: b x dim\n    \"\"\"", "\n", "total", "=", "w", ".", "sum", "(", "dim", "=", "1", ")", "\n", "return", "(", "x", "*", "w", ")", ".", "sum", "(", "dim", "=", "1", ")", "/", "total", "\n", "", ""]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.__init__": [[21, 33], ["dataset.Dataset.buckets[].append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "args", ",", "type_quantity", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "type_quantity", "=", "type_quantity", "\n", "self", ".", "device", "=", "None", "\n", "\n", "self", ".", "buckets", "=", "{", "}", "\n", "for", "mention", "in", "data", ":", "\n", "            ", "type_amount", "=", "1", "# mention.type_len()", "\n", "if", "type_amount", "in", "self", ".", "buckets", ":", "\n", "                ", "self", ".", "buckets", "[", "type_amount", "]", ".", "append", "(", "mention", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "buckets", "[", "type_amount", "]", "=", "[", "mention", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.to_matrix": [[34, 39], ["dataset.Dataset.buckets.items", "dataset.Dataset._bucket_to_matrix"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset._bucket_to_matrix"], ["", "", "", "def", "to_matrix", "(", "self", ",", "vocabs", ",", "args", ")", ":", "\n", "        ", "self", ".", "matrixes", "=", "{", "}", "\n", "for", "type_len", ",", "mentions", "in", "self", ".", "buckets", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "matrixes", "[", "type_len", "]", "=", "self", ".", "_bucket_to_matrix", "(", "mentions", ",", "vocabs", ",", "args", ")", "\n", "", "del", "self", ".", "buckets", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset._bucket_to_matrix": [[40, 75], ["len", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "torch.LongTensor", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "tqdm.tqdm.tqdm", "range", "tqdm.tqdm.tqdm.close", "tqdm.tqdm.tqdm.update", "item.preprocess", "ctx_tensor[].narrow().copy_", "ctx_position[].narrow().copy_", "item.context.size", "mention_tensor[].narrow().copy_", "mention_char_tensor[].narrow().copy_", "type_list.append", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "t.contiguous", "ctx_tensor[].narrow", "ctx_position[].narrow", "mention_tensor[].narrow", "mention_char_tensor[].narrow", "item.context.size", "item.context_positions.size", "item.mention.size", "item.mention_chars.size"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.preprocess", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "def", "_bucket_to_matrix", "(", "self", ",", "mentions", ",", "vocabs", ",", "args", ")", ":", "\n", "        ", "\"\"\"\n        Creates tensors: ctx, ctx_pos, ctx_len, mentions ids, mention chars and types\n\n        Used only on PREPROCESSING time\n        \"\"\"", "\n", "bucket_size", "=", "len", "(", "mentions", ")", "\n", "\n", "ctx_tensor", "=", "torch", ".", "LongTensor", "(", "bucket_size", ",", "args", ".", "context_length", ")", ".", "fill_", "(", "PAD", ")", "\n", "ctx_position", "=", "torch", ".", "LongTensor", "(", "bucket_size", ",", "args", ".", "context_length", ")", ".", "fill_", "(", "PAD", ")", "\n", "ctx_len_tensor", "=", "torch", ".", "LongTensor", "(", "bucket_size", ")", "\n", "mention_tensor", "=", "torch", ".", "LongTensor", "(", "bucket_size", ",", "args", ".", "mention_length", ")", ".", "fill_", "(", "PAD", ")", "\n", "mention_char_tensor", "=", "torch", ".", "LongTensor", "(", "bucket_size", ",", "args", ".", "mention_char_length", ")", ".", "fill_", "(", "PAD", ")", "\n", "type_list", "=", "[", "]", "\n", "\n", "bar", "=", "tqdm", "(", "desc", "=", "\"to_matrix\"", ",", "total", "=", "bucket_size", ")", "\n", "\n", "for", "i", "in", "range", "(", "bucket_size", ")", ":", "\n", "            ", "bar", ".", "update", "(", ")", "\n", "item", "=", "mentions", "[", "i", "]", "\n", "item", ".", "preprocess", "(", "vocabs", ",", "args", ")", "\n", "\n", "ctx_tensor", "[", "i", "]", ".", "narrow", "(", "0", ",", "0", ",", "item", ".", "context", ".", "size", "(", "0", ")", ")", ".", "copy_", "(", "item", ".", "context", ")", "\n", "\n", "ctx_position", "[", "i", "]", ".", "narrow", "(", "0", ",", "0", ",", "item", ".", "context_positions", ".", "size", "(", "0", ")", ")", ".", "copy_", "(", "item", ".", "context_positions", ")", "\n", "ctx_len_tensor", "[", "i", "]", "=", "item", ".", "context", ".", "size", "(", "0", ")", "\n", "\n", "mention_tensor", "[", "i", "]", ".", "narrow", "(", "0", ",", "0", ",", "item", ".", "mention", ".", "size", "(", "0", ")", ")", ".", "copy_", "(", "item", ".", "mention", ")", "\n", "mention_char_tensor", "[", "i", "]", ".", "narrow", "(", "0", ",", "0", ",", "item", ".", "mention_chars", ".", "size", "(", "0", ")", ")", ".", "copy_", "(", "item", ".", "mention_chars", ")", "\n", "type_list", ".", "append", "(", "item", ".", "types", ")", "\n", "\n", "", "bar", ".", "close", "(", ")", "\n", "\n", "return", "[", "t", ".", "contiguous", "(", ")", "for", "t", "in", "[", "ctx_tensor", ",", "ctx_position", ",", "ctx_len_tensor", ",", "mention_tensor", ",", "\n", "mention_char_tensor", "]", "]", ",", "type_list", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.get_mention_len": [[76, 78], ["[].size"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "def", "get_mention_len", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "matrixes", "[", "1", "]", "[", "0", "]", "[", "3", "]", ".", "size", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.get_context_len": [[79, 81], ["[].size"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "def", "get_context_len", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "matrixes", "[", "1", "]", "[", "0", "]", "[", "0", "]", ".", "size", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.__len__": [[82, 87], ["AttributeError"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "self", ".", "num_batches", "\n", "", "except", "AttributeError", "as", "e", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Dataset.set_batch_size must be invoked before to calculate the length\"", ")", "from", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.shuffle": [[88, 90], ["random.shuffle"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.shuffle"], ["", "", "def", "shuffle", "(", "self", ")", ":", "\n", "        ", "shuffle", "(", "self", ".", "iteration_order", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.set_batch_size": [[91, 104], ["dataset.Dataset.matrixes.items", "len", "math.ceil", "range", "dataset.Dataset.iteration_order.append"], "methods", ["None"], ["", "def", "set_batch_size", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "num_batches", "=", "0", "\n", "self", ".", "iteration_order", "=", "[", "]", "\n", "for", "type_len", ",", "(", "tensors", ",", "type_ids", ")", "in", "self", ".", "matrixes", ".", "items", "(", ")", ":", "\n", "            ", "len_tensor", "=", "len", "(", "tensors", "[", "0", "]", ")", "\n", "bucket_num_batches", "=", "math", ".", "ceil", "(", "len_tensor", "/", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "bucket_num_batches", ")", ":", "\n", "                ", "start_index", "=", "batch_size", "*", "i", "\n", "end_index", "=", "batch_size", "*", "(", "i", "+", "1", ")", "if", "batch_size", "*", "(", "i", "+", "1", ")", "<", "len_tensor", "else", "len_tensor", "\n", "self", ".", "iteration_order", ".", "append", "(", "(", "type_len", ",", "start_index", ",", "end_index", ")", ")", "\n", "\n", "", "self", ".", "num_batches", "+=", "bucket_num_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.create_one_hot_types": [[105, 111], ["torch.zeros", "range", "torch.zeros.contiguous", "len", "len"], "methods", ["None"], ["", "", "def", "create_one_hot_types", "(", "self", ",", "batch_type_ids", ")", ":", "\n", "        ", "one_hot_vectors", "=", "torch", ".", "zeros", "(", "(", "len", "(", "batch_type_ids", ")", ",", "self", ".", "type_quantity", ")", ",", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "batch_type_ids", ")", ")", ":", "\n", "            ", "one_hot_vectors", "[", "i", "]", "[", "batch_type_ids", "[", "i", "]", "]", "=", "1.0", "\n", "\n", "", "return", "one_hot_vectors", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.__getitem__": [[112, 127], ["dataset.Dataset.create_one_hot_types", "dataset.Dataset.process_batch", "t.to", "torch.autograd.Variable"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.create_one_hot_types", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.process_batch"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        :param index:\n        :return: Matrices of different parts (head string, contexts, types) of every instance\n        \"\"\"", "\n", "bucket", ",", "start_index", ",", "end_index", "=", "self", ".", "iteration_order", "[", "index", "]", "\n", "\n", "tensors", ",", "type_ids", "=", "self", ".", "matrixes", "[", "bucket", "]", "\n", "\n", "batch_tensors", "=", "[", "self", ".", "process_batch", "(", "tensor", ",", "start_index", ",", "end_index", ")", "for", "tensor", "in", "tensors", "]", "\n", "batch_type_ids", "=", "[", "t", ".", "to", "(", "self", ".", "device", ")", "for", "t", "in", "type_ids", "[", "start_index", ":", "end_index", "]", "]", "\n", "\n", "# one-hot matrix takes a lot of spaces so it creates it on the fly for each batch", "\n", "one_hot_types", "=", "self", ".", "create_one_hot_types", "(", "batch_type_ids", ")", "\n", "return", "batch_tensors", "+", "[", "batch_type_ids", ",", "Variable", "(", "one_hot_types", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.process_batch": [[128, 131], ["dataset.Dataset.to_cuda().contiguous", "dataset.Dataset.to_cuda"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.to_cuda"], ["", "def", "process_batch", "(", "self", ",", "data_tensor", ",", "start_index", ",", "end_index", ")", ":", "\n", "        ", "batch_data", "=", "data_tensor", "[", "start_index", ":", "end_index", "]", "\n", "return", "self", ".", "to_cuda", "(", "batch_data", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.to_cuda": [[132, 135], ["batch_data.to.to.to", "torch.autograd.Variable"], "methods", ["None"], ["", "def", "to_cuda", "(", "self", ",", "batch_data", ")", ":", "\n", "        ", "batch_data", "=", "batch_data", ".", "to", "(", "self", ".", "device", ")", "\n", "return", "Variable", "(", "batch_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.subsample": [[136, 153], ["dataset.Dataset", "dataset.Dataset.matrixes.items", "dataset.Dataset.set_batch_size"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dataset.Dataset.set_batch_size"], ["", "def", "subsample", "(", "self", ",", "length", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param length: of the subset. If None, then length is one batch size, at most.\n        :return: shuffled subset of self.\n        \"\"\"", "\n", "if", "not", "length", ":", "\n", "            ", "length", "=", "self", ".", "batch_size", "\n", "\n", "", "other", "=", "Dataset", "(", "[", "]", ",", "self", ".", "args", ",", "self", ".", "type_quantity", ")", "\n", "\n", "other", ".", "matrixes", "=", "{", "}", "\n", "for", "type_len", ",", "tensors", "in", "self", ".", "matrixes", ".", "items", "(", ")", ":", "\n", "            ", "other", ".", "matrixes", "[", "type_len", "]", "=", "[", "tensor", "[", ":", "length", "]", "for", "tensor", "in", "tensors", "]", "\n", "\n", "", "other", ".", "set_batch_size", "(", "self", ".", "batch_size", ")", "\n", "\n", "return", "other", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.loss.MultiTaskBCELoss.__init__": [[8, 13], ["torch.nn.BCEWithLogitsLoss", "len", "type_vocab.get_coarse_ids", "len", "type_vocab.get_fine_ids"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TypeDict.get_coarse_ids", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TypeDict.get_fine_ids"], ["    ", "def", "__init__", "(", "self", ",", "vocabs", ")", ":", "\n", "        ", "self", ".", "loss_function", "=", "BCEWithLogitsLoss", "(", ")", "\n", "type_vocab", "=", "vocabs", "[", "TYPE_VOCAB", "]", "\n", "self", ".", "coarse_slice", "=", "len", "(", "type_vocab", ".", "get_coarse_ids", "(", ")", ")", "\n", "self", ".", "fine_slice", "=", "self", ".", "coarse_slice", "+", "len", "(", "type_vocab", ".", "get_fine_ids", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.loss.MultiTaskBCELoss.calculate_loss": [[14, 22], ["loss.MultiTaskBCELoss.calculate_loss_by_granularity", "loss.MultiTaskBCELoss.calculate_loss_by_granularity", "loss.MultiTaskBCELoss.calculate_loss_by_granularity"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.loss.MultiTaskBCELoss.calculate_loss_by_granularity", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.loss.MultiTaskBCELoss.calculate_loss_by_granularity", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.loss.MultiTaskBCELoss.calculate_loss_by_granularity"], ["", "def", "calculate_loss", "(", "self", ",", "logits", ",", "one_hot_true_labels", ")", ":", "\n", "        ", "\"\"\"Calculates multitask loss introduced in 'Ultra-Fine Entity Typing' by Choi et al.\"\"\"", "\n", "loss", "=", "0.0", "\n", "loss", "+=", "self", ".", "calculate_loss_by_granularity", "(", "logits", ",", "one_hot_true_labels", ",", "end", "=", "self", ".", "coarse_slice", ")", "\n", "loss", "+=", "self", ".", "calculate_loss_by_granularity", "(", "logits", ",", "one_hot_true_labels", ",", "ini", "=", "self", ".", "coarse_slice", ",", "\n", "end", "=", "self", ".", "fine_slice", ")", "\n", "loss", "+=", "self", ".", "calculate_loss_by_granularity", "(", "logits", ",", "one_hot_true_labels", ",", "ini", "=", "self", ".", "fine_slice", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.loss.MultiTaskBCELoss.calculate_loss_by_granularity": [[23, 35], ["torch.sum", "torch.FloatTensor().to", "torch.min().nonzero().squeeze", "[].float", "loss.MultiTaskBCELoss.loss_function", "torch.sum", "torch.FloatTensor", "torch.min().nonzero", "torch.min"], "methods", ["None"], ["", "def", "calculate_loss_by_granularity", "(", "self", ",", "logits", ",", "one_hot_true_types", ",", "ini", "=", "0", ",", "end", "=", "None", ")", ":", "\n", "        ", "gran_targets", "=", "one_hot_true_types", "[", ":", ",", "ini", ":", "end", "]", "\n", "gran_target_sum", "=", "torch", ".", "sum", "(", "gran_targets", ",", "1", ")", "\n", "\n", "if", "torch", ".", "sum", "(", "gran_target_sum", ".", "data", ")", "<=", "0", ":", "# if there is no target in this granularity in this batch", "\n", "            ", "return", "0.", "\n", "\n", "", "comparison_tensor", "=", "torch", ".", "FloatTensor", "(", "[", "1.0", "]", ")", ".", "to", "(", "one_hot_true_types", ".", "device", ")", "\n", "gran_mask", "=", "torch", ".", "min", "(", "gran_target_sum", ".", "data", ",", "comparison_tensor", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "dim", "=", "1", ")", "\n", "gran_logit_masked", "=", "logits", "[", ":", ",", "ini", ":", "end", "]", "[", "gran_mask", ",", ":", "]", ".", "float", "(", ")", "\n", "gran_target_masked", "=", "gran_targets", "[", "gran_mask", "]", "\n", "return", "self", ".", "loss_function", "(", "gran_logit_masked", ",", "gran_target_masked", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.__init__": [[10, 12], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "fields", ")", ":", "\n", "        ", "self", ".", "fields", "=", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.preprocess": [[13, 24], ["mention.Mention.type_idx", "mention.Mention.get_mention_idx", "mention.Mention.get_mention_chars", "mention.Mention.get_context_idx", "mention.Mention.get_context_positions_idx"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.type_idx", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.get_mention_idx", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.get_mention_chars", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.get_context_idx", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.get_context_positions_idx"], ["", "def", "preprocess", "(", "self", ",", "vocabs", ",", "args", ")", ":", "\n", "        ", "self", ".", "vocabs", "=", "vocabs", "\n", "self", ".", "max_context_len", "=", "args", ".", "context_length", "\n", "self", ".", "max_mention_len", "=", "args", ".", "mention_length", "\n", "self", ".", "max_mention_char_len", "=", "args", ".", "mention_char_length", "\n", "\n", "self", ".", "types", "=", "self", ".", "type_idx", "(", ")", "# type index in vocab", "\n", "self", ".", "mention", "=", "self", ".", "get_mention_idx", "(", ")", "\n", "self", ".", "mention_chars", "=", "self", ".", "get_mention_chars", "(", ")", "\n", "self", ".", "context", "=", "self", ".", "get_context_idx", "(", ")", "\n", "self", ".", "context_positions", "=", "self", ".", "get_context_positions_idx", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.get_mention_idx": [[25, 30], ["mention.Mention.vocabs[].convert_to_idx", "mention.Mention.fields[].split", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.convert_to_idx"], ["", "def", "get_mention_idx", "(", "self", ")", ":", "\n", "        ", "head", "=", "self", ".", "fields", "[", "c", ".", "MENTION", "]", ".", "split", "(", ")", "[", ":", "self", ".", "max_mention_len", "]", "\n", "if", "not", "head", ":", "\n", "            ", "return", "torch", ".", "LongTensor", "(", "[", "c", ".", "PAD", "]", ")", "\n", "", "return", "self", ".", "vocabs", "[", "c", ".", "TOKEN_VOCAB", "]", ".", "convert_to_idx", "(", "head", ",", "c", ".", "UNK_WORD", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.get_context_idx": [[31, 57], ["len", "mention.Mention.fields[].split", "mention.Mention.vocabs[].convert_to_idx", "len", "mention.Mention.vocabs[].convert_to_idx", "torch.LongTensor", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.convert_to_idx", "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.convert_to_idx"], ["", "def", "get_context_idx", "(", "self", ")", ":", "\n", "        ", "\"\"\"Simple heuristic which will truncate one token at a time from each side of the context sentence, trying to\n        keep the mention in the center and the longest possible context information, within the 'max_content_len'.\"\"\"", "\n", "left_len", "=", "len", "(", "self", ".", "fields", "[", "c", ".", "LEFT_CTX", "]", ")", "\n", "mention_words", "=", "self", ".", "fields", "[", "c", ".", "MENTION", "]", ".", "split", "(", ")", "\n", "if", "len", "(", "mention_words", ")", ">", "self", ".", "max_context_len", ":", "\n", "            ", "self", ".", "mention_ini", "=", "0", "\n", "self", ".", "mention_end", "=", "self", ".", "max_context_len", "-", "1", "\n", "return", "self", ".", "vocabs", "[", "c", ".", "TOKEN_VOCAB", "]", ".", "convert_to_idx", "(", "mention_words", "[", ":", "self", ".", "max_context_len", "]", ",", "c", ".", "UNK_WORD", ")", "\n", "\n", "", "ctx_words", "=", "self", ".", "fields", "[", "c", ".", "LEFT_CTX", "]", "+", "mention_words", "+", "self", ".", "fields", "[", "c", ".", "RIGHT_CTX", "]", "\n", "mention_ini", ",", "mention_end", "=", "left_len", ",", "left_len", "+", "len", "(", "mention_words", ")", "-", "1", "\n", "\n", "if", "not", "ctx_words", ":", "\n", "            ", "return", "torch", ".", "LongTensor", "(", "[", "c", ".", "PAD", "]", ")", "\n", "\n", "", "while", "len", "(", "ctx_words", ")", ">", "self", ".", "max_context_len", ":", "\n", "            ", "if", "mention_ini", ">", "len", "(", "ctx_words", ")", "-", "(", "mention_end", "+", "1", ")", ":", "\n", "                ", "del", "ctx_words", "[", "0", "]", "\n", "mention_ini", "-=", "1", "\n", "mention_end", "-=", "1", "\n", "", "else", ":", "\n", "                ", "del", "ctx_words", "[", "-", "1", "]", "\n", "", "", "self", ".", "mention_ini", "=", "mention_ini", "\n", "self", ".", "mention_end", "=", "mention_end", "\n", "return", "self", ".", "vocabs", "[", "c", ".", "TOKEN_VOCAB", "]", ".", "convert_to_idx", "(", "ctx_words", ",", "c", ".", "UNK_WORD", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.get_context_positions_idx": [[58, 79], ["torch.LongTensor", "len", "range", "range"], "methods", ["None"], ["", "def", "get_context_positions_idx", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        We use different ids for left and right context positions.\n        Left is in the range [2:max_left_len]\n        Mention is 1's\n        Right is in the range: [max_left_len + 2, max_right_len]\n\n        Example: if max_left_len = max_right_len = 15,\n        Sentence: \"During the year of 1921 _Pablo Picasso_ painted large cubist compositions\", mention: \"Pablo Picasso\"\n        Pos_idx:     6     5   4   3   2     1       1        17     18    19        20\n        This ids are just the entry id in a lookup table of position embeddings.\n        \"\"\"", "\n", "mention_len", "=", "self", ".", "mention_end", "-", "self", ".", "mention_ini", "+", "1", "\n", "left_len", "=", "self", ".", "mention_ini", "\n", "right_len", "=", "len", "(", "self", ".", "context", ")", "-", "(", "self", ".", "mention_end", "+", "1", ")", "\n", "\n", "left_pos", "=", "[", "i", "for", "i", "in", "range", "(", "2", ",", "left_len", "+", "2", ")", "]", "[", ":", ":", "-", "1", "]", "\n", "mention_pos", "=", "[", "1", "]", "*", "mention_len", "\n", "right_pos", "=", "[", "i", "for", "i", "in", "range", "(", "self", ".", "max_context_len", "+", "2", ",", "self", ".", "max_context_len", "+", "2", "+", "right_len", ")", "]", "\n", "\n", "return", "torch", ".", "LongTensor", "(", "left_pos", "+", "mention_pos", "+", "right_pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.type_idx": [[80, 85], ["torch.LongTensor", "types.append", "mention.Mention.vocabs[].lookup"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.TokenDict.lookup"], ["", "def", "type_idx", "(", "self", ")", ":", "\n", "        ", "types", "=", "[", "]", "\n", "for", "mention_type", "in", "self", ".", "fields", "[", "c", ".", "TYPE", "]", ":", "\n", "            ", "types", ".", "append", "(", "self", ".", "vocabs", "[", "c", ".", "TYPE_VOCAB", "]", ".", "lookup", "(", "mention_type", ")", ")", "\n", "", "return", "torch", ".", "LongTensor", "(", "types", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.get_mention_chars": [[86, 91], ["mention.Mention.vocabs[].convert_to_idx", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.convert_to_idx"], ["", "def", "get_mention_chars", "(", "self", ")", ":", "\n", "        ", "chars", "=", "self", ".", "fields", "[", "c", ".", "MENTION", "]", "[", ":", "self", ".", "max_mention_char_len", "]", "\n", "if", "not", "chars", ":", "\n", "            ", "return", "torch", ".", "LongTensor", "(", "[", "c", ".", "PAD", "]", ")", "\n", "", "return", "self", ".", "vocabs", "[", "c", ".", "CHAR_VOCAB", "]", ".", "convert_to_idx", "(", "chars", ",", "c", ".", "UNK_WORD", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.type_len": [[92, 94], ["len"], "methods", ["None"], ["", "def", "type_len", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "fields", "[", "c", ".", "TYPE", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.mention.Mention.clear": [[95, 102], ["None"], "methods", ["None"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "del", "self", ".", "fields", "\n", "del", "self", ".", "mention", "\n", "del", "self", ".", "mention_chars", "\n", "del", "self", ".", "left_context", "\n", "del", "self", ".", "right_context", "\n", "del", "self", ".", "types", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.utils.set_seed": [[14, 21], ["torch.manual_seed", "torch.cuda.is_available", "random.seed", "numpy.random.seed", "torch.cuda.manual_seed"], "function", ["None"], ["def", "set_seed", "(", "seed", ")", ":", "\n", "    ", "\"\"\"Sets random seed everywhere.\"\"\"", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.utils.get_logging": [[23, 33], ["logging.getLogger", "logging.getLogger.setLevel", "logging.StreamHandler", "logging.Formatter", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler"], "function", ["None"], ["", "def", "get_logging", "(", "level", "=", "logging", ".", "DEBUG", ")", ":", "\n", "    ", "log", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "if", "log", ".", "handlers", ":", "\n", "        ", "return", "log", "\n", "", "log", ".", "setLevel", "(", "level", ")", "\n", "ch", "=", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "fmt", "=", "'%(asctime)s %(message)s'", ",", "datefmt", "=", "'%m/%d/%Y %I:%M:%S'", ")", "\n", "ch", ".", "setFormatter", "(", "formatter", ")", "\n", "log", ".", "addHandler", "(", "ch", ")", "\n", "return", "log", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.utils.wc": [[35, 39], ["sum", "isinstance", "isinstance", "sum", "open"], "function", ["None"], ["", "def", "wc", "(", "files", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "files", ",", "list", ")", "and", "not", "isinstance", "(", "files", ",", "tuple", ")", ":", "\n", "        ", "files", "=", "[", "files", "]", "\n", "", "return", "sum", "(", "[", "sum", "(", "[", "1", "for", "_", "in", "open", "(", "fp", ",", "buffering", "=", "constants", ".", "BUFFER_SIZE", ")", "]", ")", "for", "fp", "in", "files", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.utils.process_line": [[41, 45], ["json.loads", "utils.build_full_sentence"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.utils.build_full_sentence"], ["", "def", "process_line", "(", "line", ")", ":", "\n", "    ", "fields", "=", "json", ".", "loads", "(", "line", ")", "\n", "tokens", "=", "build_full_sentence", "(", "fields", ")", "\n", "return", "fields", ",", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.utils.build_full_sentence": [[47, 49], ["fields[].split"], "function", ["None"], ["", "def", "build_full_sentence", "(", "fields", ")", ":", "\n", "    ", "return", "fields", "[", "constants", ".", "LEFT_CTX", "]", "+", "fields", "[", "constants", ".", "MENTION", "]", ".", "split", "(", ")", "+", "fields", "[", "constants", ".", "RIGHT_CTX", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.utils.to_sparse": [[51, 54], ["torch.nonzero"], "function", ["None"], ["", "def", "to_sparse", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"Given a one-hot encoding vector returns a list of the indexes with nonzero values\"\"\"", "\n", "return", "torch", ".", "nonzero", "(", "tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.utils.expand_tensor": [[56, 65], ["tensor.size", "tensor.repeat", "tensor.repeat.view"], "function", ["home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.dicts.Dict.size"], ["", "def", "expand_tensor", "(", "tensor", ",", "length", ")", ":", "\n", "    ", "\"\"\"\n    :param tensor: dim: N x M\n    :param length: l\n    :return: tensor of (N * l) x M with every row intercalated and extended l times\n    \"\"\"", "\n", "rows", ",", "cols", "=", "tensor", ".", "size", "(", ")", "\n", "repeated", "=", "tensor", ".", "repeat", "(", "1", ",", "length", ")", "\n", "return", "repeated", ".", "view", "(", "rows", "*", "length", ",", "cols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.utils.euclidean_dot_product": [[67, 69], ["None"], "function", ["None"], ["", "def", "euclidean_dot_product", "(", "u", ",", "v", ")", ":", "\n", "    ", "return", "(", "u", "*", "v", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.utils.save_plot": [[80, 84], ["plt.hist", "plt.savefig", "plt.clf"], "function", ["None"], ["", "def", "save_plot", "(", "plt", ",", "data", ",", "filename", ",", "cumulative", "=", "False", ",", "density", "=", "False", ")", ":", "\n", "    ", "plt", ".", "hist", "(", "data", ",", "cumulative", "=", "cumulative", ",", "density", "=", "density", ",", "bins", "=", "50", ")", "\n", "plt", ".", "savefig", "(", "filename", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nlpAThits_hyfi.hyfi.utils.euclidean_distance": [[85, 87], ["torch.norm"], "function", ["None"], ["", "def", "euclidean_distance", "(", "u", ",", "v", ")", ":", "\n", "    ", "return", "torch", ".", "norm", "(", "u", "-", "v", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "False", ")", "\n", "\n"]]}