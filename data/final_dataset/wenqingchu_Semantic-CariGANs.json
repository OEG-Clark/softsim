{"home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.None.predict.test_transform": [[28, 37], ["transform_list.append", "torchvision.Compose", "transform_list.append", "transform_list.append", "torchvision.ToTensor", "torchvision.Resize", "torchvision.CenterCrop"], "function", ["None"], ["", "def", "test_transform", "(", "size", ",", "crop", ")", ":", "\n", "    ", "transform_list", "=", "[", "]", "\n", "if", "size", "!=", "0", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Resize", "(", "size", ")", ")", "\n", "", "if", "crop", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "CenterCrop", "(", "size", ")", ")", "\n", "", "transform_list", ".", "append", "(", "transforms", ".", "ToTensor", "(", ")", ")", "\n", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "return", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.None.predict.style_transfer": [[38, 53], ["vgg", "vgg", "decoder", "vgg.size", "torch.FloatTensor().zero_().to", "torch.FloatTensor().zero_().to", "AdaIn.function.adaptive_instance_normalization", "enumerate", "AdaIn.function.adaptive_instance_normalization", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor", "torch.FloatTensor"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function.adaptive_instance_normalization", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function.adaptive_instance_normalization"], ["", "def", "style_transfer", "(", "vgg", ",", "decoder", ",", "content", ",", "style", ",", "alpha", "=", "1.0", ",", "interpolation_weights", "=", "None", ")", ":", "\n", "    ", "assert", "(", "0.0", "<=", "alpha", "<=", "1.0", ")", "\n", "content_f", "=", "vgg", "(", "content", ")", "\n", "style_f", "=", "vgg", "(", "style", ")", "\n", "if", "interpolation_weights", ":", "\n", "        ", "_", ",", "C", ",", "H", ",", "W", "=", "content_f", ".", "size", "(", ")", "\n", "feat", "=", "torch", ".", "FloatTensor", "(", "1", ",", "C", ",", "H", ",", "W", ")", ".", "zero_", "(", ")", ".", "to", "(", "device", ")", "\n", "base_feat", "=", "adaptive_instance_normalization", "(", "content_f", ",", "style_f", ")", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "interpolation_weights", ")", ":", "\n", "            ", "feat", "=", "feat", "+", "w", "*", "base_feat", "[", "i", ":", "i", "+", "1", "]", "\n", "", "content_f", "=", "content_f", "[", "0", ":", "1", "]", "\n", "", "else", ":", "\n", "        ", "feat", "=", "adaptive_instance_normalization", "(", "content_f", ",", "style_f", ")", "\n", "", "feat", "=", "feat", "*", "alpha", "+", "content_f", "*", "(", "1", "-", "alpha", ")", "\n", "return", "decoder", "(", "feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.None.predict.takeSecond": [[54, 56], ["None"], "function", ["None"], ["", "def", "takeSecond", "(", "elem", ")", ":", "\n", "    ", "return", "elem", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.None.predict.channel_1toN": [[58, 68], ["torchvision.Compose", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "range", "torch.LongTensor().zero_.float", "torch.from_numpy", "torch.from_numpy", "torchvision.ToTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "numpy.logical_not().astype", "transforms.Compose.", "img.size", "img.size", "img.size", "img.size", "numpy.logical_not", "numpy.logical_xor", "layer.numpy", "torch.LongTensor().zero_.numpy"], "function", ["None"], ["", "def", "channel_1toN", "(", "img", ",", "num_channel", ")", ":", "\n", "    ", "transform1", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "]", ")", "\n", "img", "=", "(", "transform1", "(", "img", ")", "*", "255.0", ")", ".", "long", "(", ")", "\n", "T", "=", "torch", ".", "LongTensor", "(", "num_channel", ",", "img", ".", "size", "(", "1", ")", ",", "img", ".", "size", "(", "2", ")", ")", ".", "zero_", "(", ")", "\n", "mask", "=", "torch", ".", "LongTensor", "(", "img", ".", "size", "(", "1", ")", ",", "img", ".", "size", "(", "2", ")", ")", ".", "zero_", "(", ")", "\n", "for", "i", "in", "range", "(", "num_channel", ")", ":", "\n", "        ", "T", "[", "i", "]", "=", "T", "[", "i", "]", "+", "i", "\n", "layer", "=", "T", "[", "i", "]", "-", "img", "\n", "T", "[", "i", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "logical_not", "(", "np", ".", "logical_xor", "(", "layer", ".", "numpy", "(", ")", ",", "mask", ".", "numpy", "(", ")", ")", ")", ".", "astype", "(", "int", ")", ")", "\n", "", "return", "T", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.None.predict.parsing_img": [[69, 119], ["torchvision.Compose", "torch.Upsample", "torch.no_grad", "torch.no_grad", "img.resize", "transforms.Compose.", "torch.unsqueeze", "torch.unsqueeze", "img_384.cuda.cuda", "parsing_net", "nn.Upsample.", "img.resize.transpose", "transforms.Compose.", "torch.unsqueeze", "torch.unsqueeze", "img_flip.cuda.cuda", "parsing_net", "nn.Upsample.", "img.resize", "transforms.Compose.", "torch.unsqueeze", "torch.unsqueeze", "img_256.cuda.cuda", "parsing_net", "img.resize.transpose", "transforms.Compose.", "torch.unsqueeze", "torch.unsqueeze", "img_flip.cuda.cuda", "parsing_net", "nn.Upsample.", "out.squeeze().cpu().numpy", "out_flip.squeeze().cpu().numpy", "numpy.flip", "np.flip.copy", "parsing.argmax.argmax", "numpy.where", "torchvision.ToTensor", "torchvision.Normalize", "out.squeeze().cpu", "out_flip.squeeze().cpu", "out.squeeze", "out_flip.squeeze"], "function", ["None"], ["", "def", "parsing_img", "(", "parsing_net", ",", "img", ")", ":", "\n", "    ", "to_tensor", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "(", "0.229", ",", "0.224", ",", "0.225", ")", ")", ",", "]", ")", "\n", "resize", "=", "nn", ".", "Upsample", "(", "size", "=", "(", "256", ",", "256", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "image_384", "=", "img", ".", "resize", "(", "(", "384", ",", "384", ")", ",", "Image", ".", "BILINEAR", ")", "\n", "img_384", "=", "to_tensor", "(", "image_384", ")", "\n", "img_384", "=", "torch", ".", "unsqueeze", "(", "img_384", ",", "0", ")", "\n", "img_384", "=", "img_384", ".", "cuda", "(", ")", "\n", "out_384", ",", "_", "=", "parsing_net", "(", "img_384", ")", "\n", "out_384", "=", "resize", "(", "out_384", ")", "\n", "\n", "image_flip", "=", "image_384", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "img_flip", "=", "to_tensor", "(", "image_flip", ")", "\n", "img_flip", "=", "torch", ".", "unsqueeze", "(", "img_flip", ",", "0", ")", "\n", "img_flip", "=", "img_flip", ".", "cuda", "(", ")", "\n", "out_flip", ",", "_", "=", "parsing_net", "(", "img_flip", ")", "\n", "out_flip_384", "=", "resize", "(", "out_flip", ")", "\n", "\n", "image_256", "=", "img", ".", "resize", "(", "(", "256", ",", "256", ")", ",", "Image", ".", "BILINEAR", ")", "\n", "img_256", "=", "to_tensor", "(", "image_256", ")", "\n", "img_256", "=", "torch", ".", "unsqueeze", "(", "img_256", ",", "0", ")", "\n", "img_256", "=", "img_256", ".", "cuda", "(", ")", "\n", "out_256", ",", "_", "=", "parsing_net", "(", "img_256", ")", "\n", "out", "=", "(", "out_384", "+", "out_256", ")", "/", "4", "\n", "\n", "image_flip", "=", "image_256", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "img_flip", "=", "to_tensor", "(", "image_flip", ")", "\n", "img_flip", "=", "torch", ".", "unsqueeze", "(", "img_flip", ",", "0", ")", "\n", "img_flip", "=", "img_flip", ".", "cuda", "(", ")", "\n", "out_flip", ",", "_", "=", "parsing_net", "(", "img_flip", ")", "\n", "out_flip_256", "=", "resize", "(", "out_flip", ")", "\n", "out_flip", "=", "(", "out_flip_384", "+", "out_flip_256", ")", "/", "4", "\n", "\n", "parsing", "=", "out", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "parsing_flip", "=", "out_flip", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "parsing_flip", "=", "np", ".", "flip", "(", "parsing_flip", ",", "2", ")", "\n", "parsing_flip_tmp", "=", "parsing_flip", ".", "copy", "(", ")", "\n", "parsing_flip_tmp", "[", "2", "]", "=", "parsing_flip", "[", "3", "]", "\n", "parsing_flip_tmp", "[", "3", "]", "=", "parsing_flip", "[", "2", "]", "\n", "parsing_flip_tmp", "[", "4", "]", "=", "parsing_flip", "[", "5", "]", "\n", "parsing_flip_tmp", "[", "5", "]", "=", "parsing_flip", "[", "4", "]", "\n", "\n", "parsing", "=", "parsing", "+", "parsing_flip_tmp", "\n", "parsing", "=", "parsing", ".", "argmax", "(", "0", ")", "\n", "fg_pos", "=", "np", ".", "where", "(", "parsing", "==", "10", ")", "\n", "parsing", "[", "fg_pos", "[", "0", "]", ",", "fg_pos", "[", "1", "]", "]", "=", "0", "\n", "\n", "return", "parsing", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.train_siamese.DenseEncoder.__init__": [[39, 71], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "DAENet.DenseBlockEncoder", "DAENet.DenseTransitionBlockEncoder", "DAENet.DenseBlockEncoder", "DAENet.DenseTransitionBlockEncoder", "DAENet.DenseBlockEncoder", "DAENet.DenseTransitionBlockEncoder", "DAENet.DenseBlockEncoder", "DAENet.DenseTransitionBlockEncoder", "DAENet.DenseBlockEncoder", "DAENet.DenseTransitionBlockEncoder", "f_activation"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nc", "=", "10", ",", "ndf", "=", "32", ",", "ndim", "=", "128", ",", "activation", "=", "nn", ".", "LeakyReLU", ",", "args", "=", "[", "0.2", ",", "False", "]", ",", "f_activation", "=", "nn", ".", "Sigmoid", ",", "f_args", "=", "[", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ndim", "=", "ndim", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "# input is (nc) x 256 x 256", "\n", "nn", ".", "Conv2d", "(", "nc", ",", "ndf", ",", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "ndf", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "\n", "\n", "\n", "# input is (ndf) x 64 x 64", "\n", "DAENet", ".", "DenseBlockEncoder", "(", "ndf", ",", "4", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockEncoder", "(", "ndf", ",", "ndf", "*", "2", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# input is (ndf*2) x 32 x 32", "\n", "DAENet", ".", "DenseBlockEncoder", "(", "ndf", "*", "2", ",", "6", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockEncoder", "(", "ndf", "*", "2", ",", "ndf", "*", "4", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# input is (ndf*4) x 16 x 16", "\n", "DAENet", ".", "DenseBlockEncoder", "(", "ndf", "*", "4", ",", "12", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockEncoder", "(", "ndf", "*", "4", ",", "ndf", "*", "8", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# input is (ndf*8) x 8 x 8", "\n", "DAENet", ".", "DenseBlockEncoder", "(", "ndf", "*", "8", ",", "24", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockEncoder", "(", "ndf", "*", "8", ",", "ndf", "*", "8", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# input is (ndf*8) x 4 x 4", "\n", "DAENet", ".", "DenseBlockEncoder", "(", "ndf", "*", "8", ",", "16", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockEncoder", "(", "ndf", "*", "8", ",", "ndim", ",", "4", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "f_activation", "(", "*", "f_args", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.train_siamese.DenseEncoder.forward": [[73, 77], ["train_siamese.DenseEncoder.main", "output.view.view.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "output", "=", "self", ".", "main", "(", "input", ")", "\n", "output", "=", "output", ".", "view", "(", "-", "1", ",", "self", ".", "ndim", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.train_siamese.DenseDecoder.__init__": [[81, 119], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "DAENet.DenseBlockDecoder", "DAENet.DenseTransitionBlockDecoder", "DAENet.DenseBlockDecoder", "DAENet.DenseTransitionBlockDecoder", "DAENet.DenseBlockDecoder", "DAENet.DenseTransitionBlockDecoder", "DAENet.DenseBlockDecoder", "DAENet.DenseTransitionBlockDecoder", "DAENet.DenseBlockDecoder", "DAENet.DenseTransitionBlockDecoder", "DAENet.DenseBlockDecoder", "DAENet.DenseTransitionBlockDecoder", "norm_layer", "activation", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "f_activation"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nz", "=", "128", ",", "nc", "=", "10", ",", "ngf", "=", "32", ",", "lb", "=", "0", ",", "ub", "=", "1", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "f_activation", "=", "nn", ".", "Hardtanh", ",", "f_args", "=", "[", "0", ",", "1", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nz", "=", "nz", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "# input is Z, going into convolution", "\n", "nn", ".", "ConvTranspose2d", "(", "nz", ",", "ngf", "*", "8", ",", "4", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "\n", "# state size. (ngf*8) x 4 x 4", "\n", "DAENet", ".", "DenseBlockDecoder", "(", "ngf", "*", "8", ",", "16", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockDecoder", "(", "ngf", "*", "8", ",", "ngf", "*", "8", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# state size. (ngf*8) x 8 x 8", "\n", "DAENet", ".", "DenseBlockDecoder", "(", "ngf", "*", "8", ",", "24", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockDecoder", "(", "ngf", "*", "8", ",", "ngf", "*", "4", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# state size. (ngf*4) x 16 x 16", "\n", "DAENet", ".", "DenseBlockDecoder", "(", "ngf", "*", "4", ",", "12", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockDecoder", "(", "ngf", "*", "4", ",", "ngf", "*", "2", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# state size. (ngf*2) x 32 x 32", "\n", "DAENet", ".", "DenseBlockDecoder", "(", "ngf", "*", "2", ",", "6", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockDecoder", "(", "ngf", "*", "2", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# state size. (ngf) x 64 x 64", "\n", "DAENet", ".", "DenseBlockDecoder", "(", "ngf", ",", "4", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockDecoder", "(", "ngf", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "\n", "# state size. (ngf) x 128 x 128", "\n", "DAENet", ".", "DenseBlockDecoder", "(", "ngf", ",", "2", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockDecoder", "(", "ngf", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "\n", "# state size. (ngf) x 256 x 256", "\n", "norm_layer", "(", "ngf", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "ngf", ",", "nc", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "f_activation", "(", "*", "f_args", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.train_siamese.DenseDecoder.forward": [[121, 124], ["train_siamese.DenseDecoder.main", "inputs.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "output", "=", "self", ".", "main", "(", "inputs", ".", "view", "(", "-", "1", ",", "self", ".", "nz", ",", "1", ",", "1", ")", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.train_siamese.SiameseNetwork.__init__": [[127, 133], ["torch.Module.__init__", "train_siamese.DenseEncoder", "train_siamese.DenseEncoder", "train_siamese.DenseDecoder", "train_siamese.DenseDecoder"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "SiameseNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "photo_encoder", "=", "DenseEncoder", "(", ")", "\n", "self", ".", "cari_encoder", "=", "DenseEncoder", "(", ")", "\n", "self", ".", "photo_decoder", "=", "DenseDecoder", "(", ")", "\n", "self", ".", "cari_decoder", "=", "DenseDecoder", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.train_siamese.SiameseNetwork.forward_photo": [[134, 138], ["train_siamese.SiameseNetwork.photo_encoder", "train_siamese.SiameseNetwork.photo_decoder"], "methods", ["None"], ["", "def", "forward_photo", "(", "self", ",", "x", ")", ":", "\n", "        ", "z", "=", "self", ".", "photo_encoder", "(", "x", ")", "\n", "output", "=", "self", ".", "photo_decoder", "(", "z", ")", "\n", "return", "z", ",", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.train_siamese.SiameseNetwork.forward_cari": [[139, 143], ["train_siamese.SiameseNetwork.cari_encoder", "train_siamese.SiameseNetwork.cari_decoder"], "methods", ["None"], ["", "def", "forward_cari", "(", "self", ",", "x", ")", ":", "\n", "        ", "z", "=", "self", ".", "cari_encoder", "(", "x", ")", "\n", "output", "=", "self", ".", "cari_decoder", "(", "z", ")", "\n", "return", "z", ",", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.train_siamese.SiameseNetwork.forward": [[144, 148], ["train_siamese.SiameseNetwork.forward_photo", "train_siamese.SiameseNetwork.forward_cari"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.SiameseNetwork.forward_photo", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.SiameseNetwork.forward_cari"], ["", "def", "forward", "(", "self", ",", "input1", ",", "input2", ")", ":", "\n", "        ", "z1", ",", "output1", "=", "self", ".", "forward_photo", "(", "input1", ")", "\n", "z2", ",", "output2", "=", "self", ".", "forward_cari", "(", "input2", ")", "\n", "return", "z1", ",", "output1", ",", "z2", ",", "output2", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.train_siamese.ContrastiveLoss.__init__": [[150, 153], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "margin", "=", "2.0", ")", ":", "\n", "        ", "super", "(", "ContrastiveLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.train_siamese.ContrastiveLoss.forward": [[154, 159], ["torch.pairwise_distance", "torch.pairwise_distance", "torch.pairwise_distance", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "label.float", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "label.float", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output1", ",", "output2", ",", "label", ")", ":", "\n", "        ", "euclidean_distance", "=", "F", ".", "pairwise_distance", "(", "output1", ",", "output2", ",", "keepdim", "=", "True", ")", "\n", "loss_contrastive", "=", "torch", ".", "mean", "(", "torch", ".", "pow", "(", "euclidean_distance", ",", "2", ")", ".", "squeeze", "(", ")", "*", "(", "label", ".", "float", "(", ")", ")", "+", "torch", ".", "pow", "(", "torch", ".", "clamp", "(", "self", ".", "margin", "-", "euclidean_distance", ",", "min", "=", "0.0", ")", ",", "2", ")", ".", "squeeze", "(", ")", "*", "(", "1", "-", "label", ".", "float", "(", ")", ")", ")", "\n", "return", "loss_contrastive", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.train_siamese.get_norm_layer": [[25, 35], ["functools.partial", "functools.partial", "NotImplementedError"], "function", ["None"], ["def", "get_norm_layer", "(", "norm_type", "=", "'instance'", ")", ":", "\n", "    ", "if", "norm_type", "==", "'batch'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "BatchNorm2d", ",", "affine", "=", "True", ")", "\n", "", "elif", "norm_type", "==", "'instance'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "InstanceNorm2d", ",", "affine", "=", "False", ",", "track_running_stats", "=", "False", ")", "\n", "", "elif", "norm_type", "==", "'none'", ":", "\n", "        ", "norm_layer", "=", "None", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'normalization layer [%s] is not found'", "%", "norm_type", ")", "\n", "", "return", "norm_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.Self_Attn.__init__": [[25, 35], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "in_dim", ",", "activation", ")", ":", "\n", "        ", "super", "(", "Self_Attn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "chanel_in", "=", "in_dim", "\n", "self", ".", "activation", "=", "activation", "\n", "\n", "self", ".", "query_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", ",", "out_channels", "=", "in_dim", "//", "8", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "key_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", ",", "out_channels", "=", "in_dim", "//", "8", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "value_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", ",", "out_channels", "=", "in_dim", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "gamma", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "#", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.Self_Attn.forward": [[36, 54], ["x.size", "networks.Self_Attn.query_conv().view().permute", "networks.Self_Attn.key_conv().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "networks.Self_Attn.softmax", "networks.Self_Attn.value_conv().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "out.view.view.view", "networks.Self_Attn.permute", "networks.Self_Attn.query_conv().view", "networks.Self_Attn.key_conv", "networks.Self_Attn.value_conv", "networks.Self_Attn.query_conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        inputs :\n        x : input feature maps( B X C X W X H)\n        returns :\n        out : self attention value + input feature\n        attention: B X N X N (N is Width*Height)\n        \"\"\"", "\n", "m_batchsize", ",", "C", ",", "width", ",", "height", "=", "x", ".", "size", "(", ")", "\n", "proj_query", "=", "self", ".", "query_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "-", "1", ",", "width", "*", "height", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# B X CX(N)", "\n", "proj_key", "=", "self", ".", "key_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "-", "1", ",", "width", "*", "height", ")", "# B X C x (*W*H)", "\n", "energy", "=", "torch", ".", "bmm", "(", "proj_query", ",", "proj_key", ")", "# transpose check", "\n", "attention", "=", "self", ".", "softmax", "(", "energy", ")", "# BX (N) X (N)", "\n", "proj_value", "=", "self", ".", "value_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "-", "1", ",", "width", "*", "height", ")", "# B X C X N", "\n", "out", "=", "torch", ".", "bmm", "(", "proj_value", ",", "attention", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "out", "=", "out", ".", "view", "(", "m_batchsize", ",", "C", ",", "width", ",", "height", ")", "\n", "out", "=", "self", ".", "gamma", "*", "out", "+", "x", "\n", "return", "out", ",", "attention", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.PyramidPooling.__init__": [[56, 66], ["torch.nn.Module.__init__", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "int", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "PyramidPooling", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pool1", "=", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "self", ".", "pool2", "=", "AdaptiveAvgPool2d", "(", "2", ")", "\n", "#self.pool3 = AdaptiveAvgPool2d(4)", "\n", "#self.pool4 = AdaptiveAvgPool2d(8)", "\n", "\n", "out_channels", "=", "int", "(", "in_channels", "/", "2", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "bias", "=", "False", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "bias", "=", "False", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.PyramidPooling.forward": [[67, 72], ["x.size", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks.PyramidPooling.conv1", "networks.PyramidPooling.conv2", "networks.PyramidPooling.pool1", "networks.PyramidPooling.pool2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_", ",", "_", ",", "h", ",", "w", "=", "x", ".", "size", "(", ")", "\n", "feat1", "=", "F", ".", "upsample", "(", "self", ".", "conv1", "(", "self", ".", "pool1", "(", "x", ")", ")", ",", "(", "h", ",", "w", ")", ")", "\n", "feat2", "=", "F", ".", "upsample", "(", "self", ".", "conv2", "(", "self", ".", "pool2", "(", "x", ")", ")", ",", "(", "h", ",", "w", ")", ")", "\n", "return", "torch", ".", "cat", "(", "(", "x", ",", "feat1", ",", "feat2", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.DenseBlockEncoder.__init__": [[146, 158], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "networks.DenseBlockEncoder.layers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "norm_layer", "activation", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_channels", ",", "n_convs", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseBlockEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "(", "n_convs", ">", "0", ")", "\n", "\n", "self", ".", "n_channels", "=", "n_channels", "\n", "self", ".", "n_convs", "=", "n_convs", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "n_convs", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "Sequential", "(", "\n", "norm_layer", "(", "n_channels", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "Conv2d", "(", "n_channels", ",", "n_channels", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.DenseBlockEncoder.forward": [[159, 170], ["enumerate", "outputs.append", "outputs.append", "layer"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "outputs", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "if", "i", ">", "0", ":", "\n", "                ", "next_output", "=", "0", "\n", "for", "no", "in", "outputs", ":", "\n", "                    ", "next_output", "=", "next_output", "+", "no", "\n", "", "outputs", ".", "append", "(", "next_output", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ".", "append", "(", "layer", "(", "inputs", ")", ")", "\n", "", "", "return", "outputs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.DenseTransitionBlockEncoder.__init__": [[173, 183], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "norm_layer", "activation", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_channels_in", ",", "n_channels_out", ",", "mp", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseTransitionBlockEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_channels_in", "=", "n_channels_in", "\n", "self", ".", "n_channels_out", "=", "n_channels_out", "\n", "self", ".", "mp", "=", "mp", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "norm_layer", "(", "n_channels_in", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "Conv2d", "(", "n_channels_in", ",", "n_channels_out", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "mp", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.DenseTransitionBlockEncoder.forward": [[185, 187], ["networks.DenseTransitionBlockEncoder.main"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "self", ".", "main", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.waspDenseEncoder.__init__": [[190, 210], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "networks.DenseBlockEncoder", "networks.DenseTransitionBlockEncoder", "networks.DenseBlockEncoder", "networks.DenseTransitionBlockEncoder", "networks.DenseBlockEncoder", "networks.DenseTransitionBlockEncoder", "networks.DenseBlockEncoder", "networks.DenseTransitionBlockEncoder", "f_activation"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ngpu", "=", "1", ",", "nc", "=", "1", ",", "ndf", "=", "32", ",", "ndim", "=", "128", ",", "activation", "=", "nn", ".", "LeakyReLU", ",", "args", "=", "[", "0.2", ",", "False", "]", ",", "f_activation", "=", "nn", ".", "Sigmoid", ",", "f_args", "=", "[", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "waspDenseEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ngpu", "=", "ngpu", "\n", "self", ".", "ndim", "=", "ndim", "\n", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "nc", ",", "ndf", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "\n", "DenseBlockEncoder", "(", "ndf", ",", "6", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DenseTransitionBlockEncoder", "(", "ndf", ",", "ndf", "*", "2", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "DenseBlockEncoder", "(", "ndf", "*", "2", ",", "12", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DenseTransitionBlockEncoder", "(", "ndf", "*", "2", ",", "ndf", "*", "4", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "DenseBlockEncoder", "(", "ndf", "*", "4", ",", "24", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DenseTransitionBlockEncoder", "(", "ndf", "*", "4", ",", "ndf", "*", "8", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "DenseBlockEncoder", "(", "ndf", "*", "8", ",", "16", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DenseTransitionBlockEncoder", "(", "ndf", "*", "8", ",", "ndim", ",", "4", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "f_activation", "(", "*", "f_args", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.waspDenseEncoder.forward": [[212, 215], ["networks.waspDenseEncoder.main().view", "networks.waspDenseEncoder.main"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "output", "=", "self", ".", "main", "(", "input", ")", ".", "view", "(", "-", "1", ",", "self", ".", "ndim", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.waspWarper.__init__": [[217, 221], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "imgSize", "=", "256", ",", "batchSize", "=", "1", ")", ":", "\n", "        ", "super", "(", "waspWarper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "batchSize", "=", "batchSize", "\n", "self", ".", "imgSize", "=", "imgSize", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.waspWarper.forward": [[222, 226], ["input_grid.permute", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample"], ["", "def", "forward", "(", "self", ",", "input_img", ",", "input_grid", ")", ":", "\n", "        ", "self", ".", "warp", "=", "input_grid", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "self", ".", "output", "=", "F", ".", "grid_sample", "(", "input_img", ",", "self", ".", "warp", ")", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.waspGridSpatialIntegral.__init__": [[231, 241], ["torch.Module.__init__", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "networks.waspGridSpatialIntegral.filterx.cuda", "networks.waspGridSpatialIntegral.filtery.cuda", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "imgSize", "=", "256", ",", "cuda", "=", "True", ")", ":", "\n", "        ", "super", "(", "waspGridSpatialIntegral", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w", "=", "imgSize", "\n", "self", ".", "filterx", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "1", ",", "1", ",", "1", ",", "self", ".", "w", ")", ".", "fill_", "(", "1", ")", "\n", "self", ".", "filtery", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "1", ",", "1", ",", "self", ".", "w", ",", "1", ")", ".", "fill_", "(", "1", ")", "\n", "self", ".", "filterx", "=", "Variable", "(", "self", ".", "filterx", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "filtery", "=", "Variable", "(", "self", ".", "filtery", ",", "requires_grad", "=", "False", ")", "\n", "if", "cuda", ":", "\n", "            ", "self", ".", "filterx", ".", "cuda", "(", ")", "\n", "self", ".", "filtery", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.waspGridSpatialIntegral.forward": [[242, 247], ["torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_diffgrid[].unsqueeze", "input_diffgrid[].unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_diffgrid", ")", ":", "\n", "        ", "fullx", "=", "F", ".", "conv_transpose2d", "(", "input_diffgrid", "[", ":", ",", "0", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "filterx", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "fully", "=", "F", ".", "conv_transpose2d", "(", "input_diffgrid", "[", ":", ",", "1", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "filtery", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "output_grid", "=", "torch", ".", "cat", "(", "(", "fullx", "[", ":", ",", ":", ",", "0", ":", "self", ".", "w", ",", "0", ":", "self", ".", "w", "]", ",", "fully", "[", ":", ",", ":", ",", "0", ":", "self", ".", "w", ",", "0", ":", "self", ".", "w", "]", ")", ",", "1", ")", "\n", "return", "output_grid", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.waspGridSpatialIntegral2.__init__": [[250, 260], ["torch.Module.__init__", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "networks.waspGridSpatialIntegral2.filterx.cuda", "networks.waspGridSpatialIntegral2.filtery.cuda", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "imgSize", "=", "256", ",", "cuda", "=", "True", ")", ":", "\n", "        ", "super", "(", "waspGridSpatialIntegral2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w", "=", "imgSize", "\n", "self", ".", "filterx", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "1", ",", "1", ",", "1", ",", "self", ".", "w", ")", ".", "fill_", "(", "1", ")", "\n", "self", ".", "filtery", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "1", ",", "1", ",", "self", ".", "w", ",", "1", ")", ".", "fill_", "(", "1", ")", "\n", "self", ".", "filterx", "=", "Variable", "(", "self", ".", "filterx", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "filtery", "=", "Variable", "(", "self", ".", "filtery", ",", "requires_grad", "=", "False", ")", "\n", "if", "cuda", ":", "\n", "            ", "self", ".", "filterx", ".", "cuda", "(", ")", "\n", "self", ".", "filtery", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.waspGridSpatialIntegral2.forward": [[261, 266], ["torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_diffgrid[].unsqueeze", "input_diffgrid[].unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_diffgrid", ")", ":", "\n", "        ", "fullx", "=", "F", ".", "conv_transpose2d", "(", "input_diffgrid", "[", ":", ",", "0", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "filterx", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "fully", "=", "F", ".", "conv_transpose2d", "(", "input_diffgrid", "[", ":", ",", "1", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "filtery", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "output_grid", "=", "torch", ".", "cat", "(", "(", "fullx", "[", ":", ",", ":", ",", "0", ":", "self", ".", "w", ",", "-", "self", ".", "w", ":", "]", ",", "fully", "[", ":", ",", ":", ",", "-", "self", ".", "w", ":", ",", "0", ":", "self", ".", "w", "]", ")", ",", "1", ")", "\n", "return", "output_grid", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.DenseBlockDecoder.__init__": [[270, 282], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "networks.DenseBlockDecoder.layers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "norm_layer", "activation", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_channels", ",", "n_convs", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseBlockDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "(", "n_convs", ">", "0", ")", "\n", "\n", "self", ".", "n_channels", "=", "n_channels", "\n", "self", ".", "n_convs", "=", "n_convs", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "n_convs", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "Sequential", "(", "\n", "norm_layer", "(", "n_channels", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "n_channels", ",", "n_channels", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.DenseBlockDecoder.forward": [[283, 294], ["enumerate", "outputs.append", "outputs.append", "layer"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "outputs", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "if", "i", ">", "0", ":", "\n", "                ", "next_output", "=", "0", "\n", "for", "no", "in", "outputs", ":", "\n", "                    ", "next_output", "=", "next_output", "+", "no", "\n", "", "outputs", ".", "append", "(", "next_output", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ".", "append", "(", "layer", "(", "inputs", ")", ")", "\n", "", "", "return", "outputs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.DenseTransitionBlockDecoder.__init__": [[297, 305], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "norm_layer", "activation", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_channels_in", ",", "n_channels_out", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseTransitionBlockDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_channels_in", "=", "n_channels_in", "\n", "self", ".", "n_channels_out", "=", "n_channels_out", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "norm_layer", "(", "n_channels_in", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "n_channels_in", ",", "n_channels_out", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.DenseTransitionBlockDecoder.forward": [[307, 309], ["networks.DenseTransitionBlockDecoder.main"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "self", ".", "main", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.waspDenseDecoder.__init__": [[312, 334], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "networks.DenseBlockDecoder", "networks.DenseTransitionBlockDecoder", "networks.DenseBlockDecoder", "networks.DenseTransitionBlockDecoder", "networks.DenseBlockDecoder", "networks.DenseTransitionBlockDecoder", "networks.DenseBlockDecoder", "networks.DenseTransitionBlockDecoder", "norm_layer", "activation", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "f_activation"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ngpu", "=", "1", ",", "nz", "=", "128", ",", "nc", "=", "1", ",", "ngf", "=", "32", ",", "lb", "=", "0", ",", "ub", "=", "1", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "f_activation", "=", "nn", ".", "Hardtanh", ",", "f_args", "=", "[", "0", ",", "1", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "waspDenseDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ngpu", "=", "ngpu", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ConvTranspose2d", "(", "nz", ",", "ngf", "*", "8", ",", "4", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "\n", "DenseBlockDecoder", "(", "ngf", "*", "8", ",", "16", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DenseTransitionBlockDecoder", "(", "ngf", "*", "8", ",", "ngf", "*", "4", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "DenseBlockDecoder", "(", "ngf", "*", "4", ",", "24", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DenseTransitionBlockDecoder", "(", "ngf", "*", "4", ",", "ngf", "*", "2", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "DenseBlockDecoder", "(", "ngf", "*", "2", ",", "12", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DenseTransitionBlockDecoder", "(", "ngf", "*", "2", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "DenseBlockDecoder", "(", "ngf", ",", "6", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DenseTransitionBlockDecoder", "(", "ngf", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "norm_layer", "(", "ngf", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "ngf", ",", "nc", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "f_activation", "(", "*", "f_args", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.waspDenseDecoder.forward": [[336, 338], ["networks.waspDenseDecoder.main"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "self", ".", "main", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.Dense_DecodersIntegralWarper2.__init__": [[341, 354], ["torch.Module.__init__", "networks.waspDenseDecoder", "networks.waspDenseDecoder", "networks.waspDenseDecoder", "networks.waspWarper", "networks.waspGridSpatialIntegral", "networks.waspGridSpatialIntegral2", "torch.Hardtanh", "torch.Hardtanh", "torch.Hardtanh", "torch.Hardtanh"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ngpu", "=", "1", ",", "nc", "=", "3", ",", "ngf", "=", "32", ",", "ndf", "=", "32", ",", "wdim", "=", "128", ",", "imgSize", "=", "256", ",", "batch_size", "=", "1", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "Dense_DecodersIntegralWarper2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "imagedimension", "=", "imgSize", "\n", "self", ".", "ngpu", "=", "ngpu", "\n", "self", ".", "wdim", "=", "wdim", "\n", "self", ".", "decoderW_left", "=", "waspDenseDecoder", "(", "ngpu", "=", "self", ".", "ngpu", ",", "nz", "=", "wdim", ",", "nc", "=", "2", ",", "ngf", "=", "ngf", ",", "lb", "=", "0", ",", "ub", "=", "1", ",", "activation", "=", "nn", ".", "Tanh", ",", "args", "=", "[", "]", ",", "f_activation", "=", "nn", ".", "Sigmoid", ",", "f_args", "=", "[", "]", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "decoderW_right", "=", "waspDenseDecoder", "(", "ngpu", "=", "self", ".", "ngpu", ",", "nz", "=", "wdim", ",", "nc", "=", "2", ",", "ngf", "=", "ngf", ",", "lb", "=", "0", ",", "ub", "=", "1", ",", "activation", "=", "nn", ".", "Tanh", ",", "args", "=", "[", "]", ",", "f_activation", "=", "nn", ".", "Sigmoid", ",", "f_args", "=", "[", "]", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "decoderW_right", "=", "waspDenseDecoder", "(", "ngpu", "=", "self", ".", "ngpu", ",", "nz", "=", "wdim", ",", "nc", "=", "2", ",", "ngf", "=", "ngf", ",", "lb", "=", "0", ",", "ub", "=", "1", ",", "activation", "=", "nn", ".", "Tanh", ",", "args", "=", "[", "]", ",", "f_activation", "=", "nn", ".", "Sigmoid", ",", "f_args", "=", "[", "]", ",", "norm_layer", "=", "norm_layer", ")", "\n", "\n", "self", ".", "warper", "=", "waspWarper", "(", "imgSize", ",", "batch_size", ")", "\n", "self", ".", "integrator", "=", "waspGridSpatialIntegral", "(", "imgSize", "=", "imgSize", ")", "\n", "self", ".", "integrator2", "=", "waspGridSpatialIntegral2", "(", "imgSize", "=", "imgSize", ")", "\n", "self", ".", "cutter", "=", "nn", ".", "Hardtanh", "(", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.Dense_DecodersIntegralWarper2.forward": [[355, 365], ["networks.Dense_DecodersIntegralWarper2.cutter", "networks.Dense_DecodersIntegralWarper2.cutter", "networks.Dense_DecodersIntegralWarper2.integrator", "networks.Dense_DecodersIntegralWarper2.integrator2", "networks.Dense_DecodersIntegralWarper2.decoderW_left", "networks.Dense_DecodersIntegralWarper2.decoderW_right", "zW.view", "zW.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "zW", ")", ":", "\n", "        ", "self", ".", "diffentialWarping_left", "=", "(", "self", ".", "decoderW_left", "(", "zW", ".", "view", "(", "-", "1", ",", "self", ".", "wdim", ",", "1", ",", "1", ")", ")", "-", "0.5", ")", "*", "(", "4.0", "/", "self", ".", "imagedimension", ")", "+", "2.0", "/", "self", ".", "imagedimension", "\n", "self", ".", "diffentialWarping_right", "=", "(", "self", ".", "decoderW_right", "(", "zW", ".", "view", "(", "-", "1", ",", "self", ".", "wdim", ",", "1", ",", "1", ")", ")", "-", "0.5", ")", "*", "(", "4.0", "/", "self", ".", "imagedimension", ")", "+", "2.0", "/", "self", ".", "imagedimension", "\n", "\n", "self", ".", "warping_left", "=", "self", ".", "integrator", "(", "self", ".", "diffentialWarping_left", ")", "-", "1.0", "\n", "self", ".", "warping_right", "=", "1.0", "-", "self", ".", "integrator2", "(", "self", ".", "diffentialWarping_right", ")", "\n", "self", ".", "warping_left", "=", "self", ".", "cutter", "(", "self", ".", "warping_left", ")", "\n", "self", ".", "warping_right", "=", "self", ".", "cutter", "(", "self", ".", "warping_right", ")", "\n", "self", ".", "warping", "=", "(", "self", ".", "warping_left", "+", "self", ".", "warping_right", ")", "/", "2.0", "/", "63.0", "*", "64.0", "\n", "return", "self", ".", "warping", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.get_norm_layer": [[75, 85], ["functools.partial", "functools.partial", "NotImplementedError"], "function", ["None"], ["", "", "def", "get_norm_layer", "(", "norm_type", "=", "'instance'", ")", ":", "\n", "    ", "if", "norm_type", "==", "'batch'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "BatchNorm2d", ",", "affine", "=", "True", ")", "\n", "", "elif", "norm_type", "==", "'instance'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "InstanceNorm2d", ",", "affine", "=", "False", ",", "track_running_stats", "=", "False", ")", "\n", "", "elif", "norm_type", "==", "'none'", ":", "\n", "        ", "norm_layer", "=", "None", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'normalization layer [%s] is not found'", "%", "norm_type", ")", "\n", "", "return", "norm_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.get_scheduler": [[87, 102], ["torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.ReduceLROnPlateau", "max", "float", "torch.optim.lr_scheduler.CosineAnnealingLR", "NotImplementedError"], "function", ["None"], ["", "def", "get_scheduler", "(", "optimizer", ",", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "lr_policy", "==", "'lambda'", ":", "\n", "        ", "def", "lambda_rule", "(", "epoch", ")", ":", "\n", "            ", "lr_l", "=", "1.0", "-", "max", "(", "0", ",", "epoch", "+", "1", "+", "opt", ".", "epoch_count", "-", "opt", ".", "niter", ")", "/", "float", "(", "opt", ".", "niter_decay", "+", "1", ")", "\n", "return", "lr_l", "\n", "", "scheduler", "=", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lambda_rule", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'step'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "step_size", "=", "opt", ".", "lr_decay_iters", ",", "gamma", "=", "0.1", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'plateau'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "factor", "=", "0.2", ",", "threshold", "=", "0.01", ",", "patience", "=", "5", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'cosine'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "CosineAnnealingLR", "(", "optimizer", ",", "T_max", "=", "opt", ".", "niter", ",", "eta_min", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "return", "NotImplementedError", "(", "'learning rate policy [%s] is not implemented'", ",", "opt", ".", "lr_policy", ")", "\n", "", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.init_weights": [[104, 126], ["print", "net.apply", "hasattr", "torch.nn.init.normal_", "hasattr", "torch.nn.init.constant_", "classname.find", "torch.nn.init.normal_", "torch.nn.init.constant_", "classname.find", "classname.find", "torch.nn.init.xavier_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.orthogonal_", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.SpectralNorm.apply"], ["", "def", "init_weights", "(", "net", ",", "init_type", "=", "'normal'", ",", "gain", "=", "0.02", ")", ":", "\n", "    ", "def", "init_func", "(", "m", ")", ":", "\n", "        ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "(", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", "or", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ")", ":", "\n", "            ", "if", "init_type", "==", "'normal'", ":", "\n", "                ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "0.0", ",", "gain", ")", "\n", "", "elif", "init_type", "==", "'xavier'", ":", "\n", "                ", "init", ".", "xavier_normal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "gain", ")", "\n", "", "elif", "init_type", "==", "'kaiming'", ":", "\n", "                ", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ".", "data", ",", "a", "=", "0", ",", "mode", "=", "'fan_in'", ")", "\n", "", "elif", "init_type", "==", "'orthogonal'", ":", "\n", "                ", "init", ".", "orthogonal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "gain", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'initialization method [%s] is not implemented'", "%", "init_type", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'BatchNorm2d'", ")", "!=", "-", "1", ":", "\n", "            ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "1.0", ",", "gain", ")", "\n", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "\n", "", "", "print", "(", "'initialize network with %s'", "%", "init_type", ")", "\n", "net", ".", "apply", "(", "init_func", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.networks.init_net": [[128, 141], ["hasattr", "networks.init_weights", "hasattr", "len", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "net.to", "net.fc2.bias.data.copy_", "net.fc2.weight.data.zero_"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.init_weights"], ["", "def", "init_net", "(", "net", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "    ", "if", "hasattr", "(", "net", ",", "'which_model_netG'", ")", ":", "\n", "        ", "which_model_netG", "=", "net", ".", "which_model_netG", "\n", "fc2_bias", "=", "net", ".", "fc2_bias", "\n", "", "if", "len", "(", "gpu_ids", ")", ">", "0", ":", "\n", "        ", "assert", "(", "torch", ".", "cuda", ".", "is_available", "(", ")", ")", "\n", "net", ".", "to", "(", "gpu_ids", "[", "0", "]", ")", "\n", "", "init_weights", "(", "net", ",", "init_type", ",", "gain", "=", "init_gain", ")", "\n", "if", "hasattr", "(", "net", ",", "'which_model_netG'", ")", ":", "\n", "        ", "if", "which_model_netG", "==", "'unbounded_stn'", "or", "which_model_netG", "==", "'bounded_stn'", "or", "which_model_netG", "==", "'affine_stn'", ":", "\n", "            ", "net", ".", "fc2", ".", "bias", ".", "data", ".", "copy_", "(", "fc2_bias", ")", "\n", "net", ".", "fc2", ".", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.predict.DenseEncoder.__init__": [[51, 83], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "networks.DenseBlockEncoder", "networks.DenseTransitionBlockEncoder", "networks.DenseBlockEncoder", "networks.DenseTransitionBlockEncoder", "networks.DenseBlockEncoder", "networks.DenseTransitionBlockEncoder", "networks.DenseBlockEncoder", "networks.DenseTransitionBlockEncoder", "networks.DenseBlockEncoder", "networks.DenseTransitionBlockEncoder", "f_activation"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["", "feat", "=", "feat", "*", "alpha", "+", "content_f", "*", "(", "1", "-", "alpha", ")", "\n", "return", "decoder", "(", "feat", ")", "\n", "\n", "", "def", "takeSecond", "(", "elem", ")", ":", "\n", "    ", "return", "elem", "[", "1", "]", "\n", "\n", "\n", "", "def", "channel_1toN", "(", "img", ",", "num_channel", ")", ":", "\n", "    ", "transform1", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "]", ")", "\n", "img", "=", "(", "transform1", "(", "img", ")", "*", "255.0", ")", ".", "long", "(", ")", "\n", "T", "=", "torch", ".", "LongTensor", "(", "num_channel", ",", "img", ".", "size", "(", "1", ")", ",", "img", ".", "size", "(", "2", ")", ")", ".", "zero_", "(", ")", "\n", "mask", "=", "torch", ".", "LongTensor", "(", "img", ".", "size", "(", "1", ")", ",", "img", ".", "size", "(", "2", ")", ")", ".", "zero_", "(", ")", "\n", "for", "i", "in", "range", "(", "num_channel", ")", ":", "\n", "        ", "T", "[", "i", "]", "=", "T", "[", "i", "]", "+", "i", "\n", "layer", "=", "T", "[", "i", "]", "-", "img", "\n", "T", "[", "i", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "logical_not", "(", "np", ".", "logical_xor", "(", "layer", ".", "numpy", "(", ")", ",", "mask", ".", "numpy", "(", ")", ")", ")", ".", "astype", "(", "int", ")", ")", "\n", "", "return", "T", ".", "float", "(", ")", "\n", "\n", "", "def", "parsing_img", "(", "parsing_net", ",", "img", ")", ":", "\n", "    ", "to_tensor", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "(", "0.229", ",", "0.224", ",", "0.225", ")", ")", ",", "]", ")", "\n", "resize", "=", "nn", ".", "Upsample", "(", "size", "=", "(", "256", ",", "256", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "image_384", "=", "img", ".", "resize", "(", "(", "384", ",", "384", ")", ",", "Image", ".", "BILINEAR", ")", "\n", "img_384", "=", "to_tensor", "(", "image_384", ")", "\n", "img_384", "=", "torch", ".", "unsqueeze", "(", "img_384", ",", "0", ")", "\n", "img_384", "=", "img_384", ".", "cuda", "(", ")", "\n", "out_384", ",", "_", "=", "parsing_net", "(", "img_384", ")", "\n", "out_384", "=", "resize", "(", "out_384", ")", "\n", "\n", "image_flip", "=", "image_384", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "img_flip", "=", "to_tensor", "(", "image_flip", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.predict.DenseEncoder.forward": [[85, 89], ["predict.DenseEncoder.main", "output.view.view.view"], "methods", ["None"], ["img_flip", "=", "img_flip", ".", "cuda", "(", ")", "\n", "out_flip", ",", "_", "=", "parsing_net", "(", "img_flip", ")", "\n", "out_flip_384", "=", "resize", "(", "out_flip", ")", "\n", "\n", "image_256", "=", "img", ".", "resize", "(", "(", "256", ",", "256", ")", ",", "Image", ".", "BILINEAR", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.predict.DenseDecoder.__init__": [[93, 131], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "networks.DenseBlockDecoder", "networks.DenseTransitionBlockDecoder", "networks.DenseBlockDecoder", "networks.DenseTransitionBlockDecoder", "networks.DenseBlockDecoder", "networks.DenseTransitionBlockDecoder", "networks.DenseBlockDecoder", "networks.DenseTransitionBlockDecoder", "networks.DenseBlockDecoder", "networks.DenseTransitionBlockDecoder", "networks.DenseBlockDecoder", "networks.DenseTransitionBlockDecoder", "norm_layer", "activation", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "f_activation"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["out_256", ",", "_", "=", "parsing_net", "(", "img_256", ")", "\n", "out", "=", "(", "out_384", "+", "out_256", ")", "/", "4", "\n", "\n", "image_flip", "=", "image_256", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "img_flip", "=", "to_tensor", "(", "image_flip", ")", "\n", "img_flip", "=", "torch", ".", "unsqueeze", "(", "img_flip", ",", "0", ")", "\n", "img_flip", "=", "img_flip", ".", "cuda", "(", ")", "\n", "out_flip", ",", "_", "=", "parsing_net", "(", "img_flip", ")", "\n", "out_flip_256", "=", "resize", "(", "out_flip", ")", "\n", "out_flip", "=", "(", "out_flip_384", "+", "out_flip_256", ")", "/", "4", "\n", "\n", "parsing", "=", "out", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "parsing_flip", "=", "out_flip", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "parsing_flip", "=", "np", ".", "flip", "(", "parsing_flip", ",", "2", ")", "\n", "parsing_flip_tmp", "=", "parsing_flip", ".", "copy", "(", ")", "\n", "parsing_flip_tmp", "[", "2", "]", "=", "parsing_flip", "[", "3", "]", "\n", "parsing_flip_tmp", "[", "3", "]", "=", "parsing_flip", "[", "2", "]", "\n", "parsing_flip_tmp", "[", "4", "]", "=", "parsing_flip", "[", "5", "]", "\n", "parsing_flip_tmp", "[", "5", "]", "=", "parsing_flip", "[", "4", "]", "\n", "\n", "parsing", "=", "parsing", "+", "parsing_flip_tmp", "\n", "parsing", "=", "parsing", ".", "argmax", "(", "0", ")", "\n", "fg_pos", "=", "np", ".", "where", "(", "parsing", "==", "10", ")", "\n", "parsing", "[", "fg_pos", "[", "0", "]", ",", "fg_pos", "[", "1", "]", "]", "=", "0", "\n", "\n", "return", "parsing", "\n", "\n", "\n", "\n", "", "", "if", "__name__", "==", "'__main__'", ":", "\n", "# loading model", "\n", "\n", "    ", "opt", "=", "TestOptions", "(", ")", ".", "parse", "(", ")", "\n", "opt", ".", "num_threads", "=", "1", "# test code only supports num_threads = 1", "\n", "opt", ".", "batch_size", "=", "1", "# test code only supports batch_size = 1", "\n", "opt", ".", "serial_batches", "=", "True", "# no shuffle", "\n", "opt", ".", "no_flip", "=", "True", "# no flip", "\n", "opt", ".", "display_id", "=", "-", "1", "# no visdom display", "\n", "opt", ".", "test_phase", "=", "'single'", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.predict.DenseDecoder.forward": [[133, 136], ["predict.DenseDecoder.main", "inputs.view"], "methods", ["None"], ["dataset", "=", "data_loader", ".", "load_data", "(", ")", "\n", "model", "=", "create_model", "(", "opt", ")", "\n", "model", ".", "setup", "(", "opt", ")", "\n", "model", ".", "eval", "(", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.predict.SiameseNetwork.__init__": [[139, 145], ["torch.Module.__init__", "predict.DenseEncoder", "predict.DenseEncoder", "predict.DenseDecoder", "predict.DenseDecoder"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["\n", "print", "(", "'Parse the input image!'", ")", "\n", "n_classes", "=", "11", "\n", "parsing_net", "=", "PSP", "(", "n_classes", ",", "'resnet50'", ")", "\n", "parsing_net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "opt", ".", "parsing_model", ")", ")", "\n", "parsing_net", ".", "cuda", "(", ")", "\n", "parsing_net", ".", "eval", "(", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.predict.SiameseNetwork.forward_photo": [[146, 150], ["predict.SiameseNetwork.photo_encoder", "predict.SiameseNetwork.photo_decoder"], "methods", ["None"], ["\n", "transform", "=", "get_transform", "(", "opt", ")", "\n", "\n", "photo_face_name", "=", "opt", ".", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.predict.SiameseNetwork.forward_cari": [[151, 155], ["predict.SiameseNetwork.cari_encoder", "predict.SiameseNetwork.cari_decoder"], "methods", ["None"], ["sample_face_path", "=", "photo_face_name", "\n", "sample_face", "=", "Image", ".", "open", "(", "sample_face_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n", "\n", "sample_mask", "=", "parsing_img", "(", "parsing_net", ",", "sample_face", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.predict.SiameseNetwork.forward_cari_generation": [[156, 160], ["predict.SiameseNetwork.photo_encoder", "predict.SiameseNetwork.cari_decoder"], "methods", ["None"], ["\n", "sample_mask", "=", "sample_mask", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "sample_mask_large", "=", "sample_mask", ".", "copy", "(", ")", "\n", "\n", "sample_mask", "=", "Image", ".", "fromarray", "(", "sample_mask", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.predict.SiameseNetwork.forward": [[163, 167], ["predict.SiameseNetwork.forward_photo", "predict.SiameseNetwork.forward_cari"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.SiameseNetwork.forward_photo", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.SiameseNetwork.forward_cari"], ["sample_face", "=", "transform", "(", "sample_face", ")", "\n", "sample_mask_large", "=", "channel_1toN", "(", "sample_mask_large", ",", "opt", ".", "output_nc", ")", "\n", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.predict.ContrastiveLoss.__init__": [[169, 172], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["\n", "if", "opt", ".", "shape", "==", "None", ":", "\n", "#retrieval", "\n", "        ", "print", "(", "'Load the caricature gallery!'", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.predict.ContrastiveLoss.forward": [[173, 178], ["torch.pairwise_distance", "torch.pairwise_distance", "torch.pairwise_distance", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "label.float", "label.float", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["None"], ["retrieval_net", "=", "SiameseNetwork", "(", ")", "\n", "retrieval_net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "opt", ".", "retrieval_model", ")", ")", "\n", "retrieval_net", ".", "cuda", "(", ")", "\n", "retrieval_net", ".", "eval", "(", ")", "\n", "cari_name_gallery", "=", "[", "]", "\n", "cari_f", "=", "open", "(", "'examples/cari_gallery/cari.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.predict.takeSecond": [[22, 24], ["None"], "function", ["None"], ["0", ",", "0", ",", "230", ",", "0", ",", "80", ",", "100", ",", "152", ",", "251", ",", "152", ",", "0", ",", "255", ",", "255", ",", "0", ",", "0", ",", "142", ",", "119", ",", "11", ",", "32", "]", ")", "\n", "zero_pad", "=", "256", "*", "3", "-", "len", "(", "palette", ")", "\n", "for", "i", "in", "range", "(", "zero_pad", ")", ":", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.predict.channel_1toN": [[26, 36], ["torchvision.Compose", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "range", "torch.LongTensor().zero_.float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torchvision.ToTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "numpy.logical_not().astype", "transforms.Compose.", "img.size", "img.size", "img.size", "img.size", "numpy.logical_not", "numpy.logical_xor", "layer.numpy", "torch.LongTensor().zero_.numpy"], "function", ["None"], ["\n", "\n", "", "def", "test_transform", "(", "size", ",", "crop", ")", ":", "\n", "    ", "transform_list", "=", "[", "]", "\n", "if", "size", "!=", "0", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Resize", "(", "size", ")", ")", "\n", "", "if", "crop", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "CenterCrop", "(", "size", ")", ")", "\n", "", "transform_list", ".", "append", "(", "transforms", ".", "ToTensor", "(", ")", ")", "\n", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "return", "transform", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.predict.get_norm_layer": [[37, 47], ["functools.partial", "functools.partial", "NotImplementedError"], "function", ["None"], ["\n", "", "def", "style_transfer", "(", "vgg", ",", "decoder", ",", "content", ",", "style", ",", "alpha", "=", "1.0", ",", "interpolation_weights", "=", "None", ")", ":", "\n", "    ", "assert", "(", "0.0", "<=", "alpha", "<=", "1.0", ")", "\n", "content_f", "=", "vgg", "(", "content", ")", "\n", "style_f", "=", "vgg", "(", "style", ")", "\n", "if", "interpolation_weights", ":", "\n", "        ", "_", ",", "C", ",", "H", ",", "W", "=", "content_f", ".", "size", "(", ")", "\n", "feat", "=", "torch", ".", "FloatTensor", "(", "1", ",", "C", ",", "H", ",", "W", ")", ".", "zero_", "(", ")", ".", "to", "(", "device", ")", "\n", "base_feat", "=", "adaptive_instance_normalization", "(", "content_f", ",", "style_f", ")", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "interpolation_weights", ")", ":", "\n", "            ", "feat", "=", "feat", "+", "w", "*", "base_feat", "[", "i", ":", "i", "+", "1", "]", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.DAENet.DenseBlockEncoder.__init__": [[20, 32], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "DAENet.DenseBlockEncoder.layers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "norm_layer", "activation", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_channels", ",", "n_convs", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseBlockEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "(", "n_convs", ">", "0", ")", "\n", "\n", "self", ".", "n_channels", "=", "n_channels", "\n", "self", ".", "n_convs", "=", "n_convs", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "n_convs", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "Sequential", "(", "\n", "norm_layer", "(", "n_channels", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "Conv2d", "(", "n_channels", ",", "n_channels", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.DAENet.DenseBlockEncoder.forward": [[33, 45], ["enumerate", "outputs.append", "outputs.append", "layer"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "outputs", "=", "[", "]", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "if", "i", ">", "0", ":", "\n", "                ", "next_output", "=", "0", "\n", "for", "no", "in", "outputs", ":", "\n", "                    ", "next_output", "=", "next_output", "+", "no", "\n", "", "outputs", ".", "append", "(", "next_output", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ".", "append", "(", "layer", "(", "inputs", ")", ")", "\n", "", "", "return", "outputs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.DAENet.DenseBlockDecoder.__init__": [[48, 60], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "DAENet.DenseBlockDecoder.layers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "norm_layer", "activation", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_channels", ",", "n_convs", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseBlockDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "(", "n_convs", ">", "0", ")", "\n", "\n", "self", ".", "n_channels", "=", "n_channels", "\n", "self", ".", "n_convs", "=", "n_convs", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "n_convs", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "Sequential", "(", "\n", "norm_layer", "(", "n_channels", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "n_channels", ",", "n_channels", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.DAENet.DenseBlockDecoder.forward": [[61, 73], ["enumerate", "outputs.append", "outputs.append", "layer"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "outputs", "=", "[", "]", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "if", "i", ">", "0", ":", "\n", "                ", "next_output", "=", "0", "\n", "for", "no", "in", "outputs", ":", "\n", "                    ", "next_output", "=", "next_output", "+", "no", "\n", "", "outputs", ".", "append", "(", "next_output", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ".", "append", "(", "layer", "(", "inputs", ")", ")", "\n", "", "", "return", "outputs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.DAENet.DenseTransitionBlockEncoder.__init__": [[76, 86], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "norm_layer", "activation", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_channels_in", ",", "n_channels_out", ",", "mp", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseTransitionBlockEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_channels_in", "=", "n_channels_in", "\n", "self", ".", "n_channels_out", "=", "n_channels_out", "\n", "self", ".", "mp", "=", "mp", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "norm_layer", "(", "n_channels_in", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "Conv2d", "(", "n_channels_in", ",", "n_channels_out", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "mp", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.DAENet.DenseTransitionBlockEncoder.forward": [[87, 89], ["DAENet.DenseTransitionBlockEncoder.main"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "self", ".", "main", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.DAENet.DenseTransitionBlockDecoder.__init__": [[92, 100], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "norm_layer", "activation", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_channels_in", ",", "n_channels_out", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseTransitionBlockDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_channels_in", "=", "n_channels_in", "\n", "self", ".", "n_channels_out", "=", "n_channels_out", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "norm_layer", "(", "n_channels_in", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "n_channels_in", ",", "n_channels_out", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.DAENet.DenseTransitionBlockDecoder.forward": [[101, 103], ["DAENet.DenseTransitionBlockDecoder.main"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "self", ".", "main", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.base_dataset.BaseDataset.__init__": [[7, 9], ["torch.Dataset.__init__"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "BaseDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.base_dataset.BaseDataset.name": [[10, 12], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'BaseDataset'", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.base_dataset.BaseDataset.modify_commandline_options": [[13, 16], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.base_dataset.BaseDataset.initialize": [[17, 19], ["None"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "opt", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.base_dataset.BaseDataset.__len__": [[20, 22], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.base_dataset.get_transform": [[24, 53], ["torchvision.Compose", "transform_list.append", "transform_list.append", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Resize", "torchvision.RandomCrop", "transform_list.append", "torchvision.RandomCrop", "transform_list.append", "torchvision.Lambda", "transform_list.append", "transform_list.append", "torchvision.Lambda", "torchvision.RandomCrop", "transform_list.append", "ValueError", "base_dataset.__scale_width", "torchvision.Lambda", "base_dataset.__scale_width", "base_dataset.__adjust"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__scale_width", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__scale_width", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__adjust"], ["", "", "def", "get_transform", "(", "opt", ")", ":", "\n", "    ", "transform_list", "=", "[", "]", "\n", "if", "opt", ".", "resize_or_crop", "==", "'resize_and_crop'", ":", "\n", "        ", "osize", "=", "[", "opt", ".", "loadSize", ",", "opt", ".", "loadSize", "]", "\n", "transform_list", ".", "append", "(", "transforms", ".", "Resize", "(", "osize", ",", "Image", ".", "BICUBIC", ")", ")", "\n", "transform_list", ".", "append", "(", "transforms", ".", "RandomCrop", "(", "opt", ".", "fineSize", ")", ")", "\n", "", "elif", "opt", ".", "resize_or_crop", "==", "'crop'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "RandomCrop", "(", "opt", ".", "fineSize", ")", ")", "\n", "", "elif", "opt", ".", "resize_or_crop", "==", "'scale_width'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "\n", "lambda", "img", ":", "__scale_width", "(", "img", ",", "opt", ".", "fineSize", ")", ")", ")", "\n", "", "elif", "opt", ".", "resize_or_crop", "==", "'scale_width_and_crop'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "\n", "lambda", "img", ":", "__scale_width", "(", "img", ",", "opt", ".", "loadSize", ")", ")", ")", "\n", "transform_list", ".", "append", "(", "transforms", ".", "RandomCrop", "(", "opt", ".", "fineSize", ")", ")", "\n", "", "elif", "opt", ".", "resize_or_crop", "==", "'none'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "\n", "lambda", "img", ":", "__adjust", "(", "img", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'--resize_or_crop %s is not a valid option.'", "%", "opt", ".", "resize_or_crop", ")", "\n", "\n", "# Todo: implement flip for face", "\n", "#if opt.isTrain and not opt.no_flip:", "\n", "#    transform_list.append(transforms.RandomHorizontalFlip())", "\n", "\n", "", "transform_list", "+=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "\n", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "]", "\n", "return", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.base_dataset.get_target_transform": [[54, 81], ["torchvision.Compose", "transform_list.append", "transform_list.append", "transform_list.append", "torchvision.ToTensor", "torchvision.Resize", "torchvision.RandomCrop", "transform_list.append", "torchvision.RandomHorizontalFlip", "torchvision.RandomCrop", "transform_list.append", "torchvision.Lambda", "transform_list.append", "transform_list.append", "torchvision.Lambda", "torchvision.RandomCrop", "transform_list.append", "ValueError", "base_dataset.__scale_width", "torchvision.Lambda", "base_dataset.__scale_width", "base_dataset.__adjust"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__scale_width", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__scale_width", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__adjust"], ["", "def", "get_target_transform", "(", "opt", ")", ":", "\n", "    ", "transform_list", "=", "[", "]", "\n", "if", "opt", ".", "resize_or_crop", "==", "'resize_and_crop'", ":", "\n", "        ", "osize", "=", "[", "opt", ".", "loadSize", ",", "opt", ".", "loadSize", "]", "\n", "transform_list", ".", "append", "(", "transforms", ".", "Resize", "(", "osize", ",", "Image", ".", "BICUBIC", ")", ")", "\n", "transform_list", ".", "append", "(", "transforms", ".", "RandomCrop", "(", "opt", ".", "fineSize", ")", ")", "\n", "", "elif", "opt", ".", "resize_or_crop", "==", "'crop'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "RandomCrop", "(", "opt", ".", "fineSize", ")", ")", "\n", "", "elif", "opt", ".", "resize_or_crop", "==", "'scale_width'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "\n", "lambda", "img", ":", "__scale_width", "(", "img", ",", "opt", ".", "fineSize", ")", ")", ")", "\n", "", "elif", "opt", ".", "resize_or_crop", "==", "'scale_width_and_crop'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "\n", "lambda", "img", ":", "__scale_width", "(", "img", ",", "opt", ".", "loadSize", ")", ")", ")", "\n", "transform_list", ".", "append", "(", "transforms", ".", "RandomCrop", "(", "opt", ".", "fineSize", ")", ")", "\n", "", "elif", "opt", ".", "resize_or_crop", "==", "'none'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "\n", "lambda", "img", ":", "__adjust", "(", "img", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'--resize_or_crop %s is not a valid option.'", "%", "opt", ".", "resize_or_crop", ")", "\n", "\n", "# Todo: implement flip for face", "\n", "", "if", "opt", ".", "isTrain", "and", "not", "opt", ".", "no_flip", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "RandomHorizontalFlip", "(", ")", ")", "\n", "\n", "", "transform_list", "+=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "]", "\n", "return", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.base_dataset.__adjust": [[84, 102], ["img.resize", "base_dataset.__print_size_warning"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__print_size_warning"], ["", "def", "__adjust", "(", "img", ")", ":", "\n", "    ", "ow", ",", "oh", "=", "img", ".", "size", "\n", "\n", "# the size needs to be a multiple of this number,", "\n", "# because going through generator network may change img size", "\n", "# and eventually cause size mismatch error", "\n", "mult", "=", "4", "\n", "if", "ow", "%", "mult", "==", "0", "and", "oh", "%", "mult", "==", "0", ":", "\n", "        ", "return", "img", "\n", "", "w", "=", "(", "ow", "-", "1", ")", "//", "mult", "\n", "w", "=", "(", "w", "+", "1", ")", "*", "mult", "\n", "h", "=", "(", "oh", "-", "1", ")", "//", "mult", "\n", "h", "=", "(", "h", "+", "1", ")", "*", "mult", "\n", "\n", "if", "ow", "!=", "w", "or", "oh", "!=", "h", ":", "\n", "        ", "__print_size_warning", "(", "ow", ",", "oh", ",", "w", ",", "h", ")", "\n", "\n", "", "return", "img", ".", "resize", "(", "(", "w", ",", "h", ")", ",", "Image", ".", "BICUBIC", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.base_dataset.__scale_width": [[104, 123], ["int", "img.resize", "base_dataset.__print_size_warning"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__print_size_warning"], ["", "def", "__scale_width", "(", "img", ",", "target_width", ")", ":", "\n", "    ", "ow", ",", "oh", "=", "img", ".", "size", "\n", "\n", "# the size needs to be a multiple of this number,", "\n", "# because going through generator network may change img size", "\n", "# and eventually cause size mismatch error", "\n", "mult", "=", "4", "\n", "assert", "target_width", "%", "mult", "==", "0", ",", "\"the target width needs to be multiple of %d.\"", "%", "mult", "\n", "if", "(", "ow", "==", "target_width", "and", "oh", "%", "mult", "==", "0", ")", ":", "\n", "        ", "return", "img", "\n", "", "w", "=", "target_width", "\n", "target_height", "=", "int", "(", "target_width", "*", "oh", "/", "ow", ")", "\n", "m", "=", "(", "target_height", "-", "1", ")", "//", "mult", "\n", "h", "=", "(", "m", "+", "1", ")", "*", "mult", "\n", "\n", "if", "target_height", "!=", "h", ":", "\n", "        ", "__print_size_warning", "(", "target_width", ",", "target_height", ",", "w", ",", "h", ")", "\n", "\n", "", "return", "img", ".", "resize", "(", "(", "w", ",", "h", ")", ",", "Image", ".", "BICUBIC", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.base_dataset.__print_size_warning": [[125, 132], ["hasattr", "print"], "function", ["None"], ["", "def", "__print_size_warning", "(", "ow", ",", "oh", ",", "w", ",", "h", ")", ":", "\n", "    ", "if", "not", "hasattr", "(", "__print_size_warning", ",", "'has_printed'", ")", ":", "\n", "        ", "print", "(", "\"The image size needs to be a multiple of 4. \"", "\n", "\"The loaded image size was (%d, %d), so it was adjusted to \"", "\n", "\"(%d, %d). This adjustment will be done to all images \"", "\n", "\"whose sizes are not multiples of 4\"", "%", "(", "ow", ",", "oh", ",", "w", ",", "h", ")", ")", "\n", "__print_size_warning", ".", "has_printed", "=", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese.DenseEncoder.__init__": [[51, 83], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "retrieval.DenseBlockEncoder", "retrieval.DenseTransitionBlockEncoder", "retrieval.DenseBlockEncoder", "retrieval.DenseTransitionBlockEncoder", "retrieval.DenseBlockEncoder", "retrieval.DenseTransitionBlockEncoder", "retrieval.DenseBlockEncoder", "retrieval.DenseTransitionBlockEncoder", "retrieval.DenseBlockEncoder", "retrieval.DenseTransitionBlockEncoder", "f_activation"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nc", "=", "10", ",", "ndf", "=", "32", ",", "ndim", "=", "128", ",", "activation", "=", "nn", ".", "LeakyReLU", ",", "args", "=", "[", "0.2", ",", "False", "]", ",", "f_activation", "=", "nn", ".", "Sigmoid", ",", "f_args", "=", "[", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ndim", "=", "ndim", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "# input is (nc) x 256 x 256", "\n", "nn", ".", "Conv2d", "(", "nc", ",", "ndf", ",", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "ndf", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "\n", "\n", "\n", "# input is (ndf) x 64 x 64", "\n", "networks", ".", "DenseBlockEncoder", "(", "ndf", ",", "4", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "networks", ".", "DenseTransitionBlockEncoder", "(", "ndf", ",", "ndf", "*", "2", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# input is (ndf*2) x 32 x 32", "\n", "networks", ".", "DenseBlockEncoder", "(", "ndf", "*", "2", ",", "6", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "networks", ".", "DenseTransitionBlockEncoder", "(", "ndf", "*", "2", ",", "ndf", "*", "4", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# input is (ndf*4) x 16 x 16", "\n", "networks", ".", "DenseBlockEncoder", "(", "ndf", "*", "4", ",", "12", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "networks", ".", "DenseTransitionBlockEncoder", "(", "ndf", "*", "4", ",", "ndf", "*", "8", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# input is (ndf*8) x 8 x 8", "\n", "networks", ".", "DenseBlockEncoder", "(", "ndf", "*", "8", ",", "24", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "networks", ".", "DenseTransitionBlockEncoder", "(", "ndf", "*", "8", ",", "ndf", "*", "8", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# input is (ndf*8) x 4 x 4", "\n", "networks", ".", "DenseBlockEncoder", "(", "ndf", "*", "8", ",", "16", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "networks", ".", "DenseTransitionBlockEncoder", "(", "ndf", "*", "8", ",", "ndim", ",", "4", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "f_activation", "(", "*", "f_args", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese.DenseEncoder.forward": [[85, 89], ["siamese.DenseEncoder.main", "output.view.view.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "output", "=", "self", ".", "main", "(", "input", ")", "\n", "output", "=", "output", ".", "view", "(", "-", "1", ",", "self", ".", "ndim", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese.DenseDecoder.__init__": [[93, 131], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "retrieval.DenseBlockDecoder", "retrieval.DenseTransitionBlockDecoder", "retrieval.DenseBlockDecoder", "retrieval.DenseTransitionBlockDecoder", "retrieval.DenseBlockDecoder", "retrieval.DenseTransitionBlockDecoder", "retrieval.DenseBlockDecoder", "retrieval.DenseTransitionBlockDecoder", "retrieval.DenseBlockDecoder", "retrieval.DenseTransitionBlockDecoder", "retrieval.DenseBlockDecoder", "retrieval.DenseTransitionBlockDecoder", "norm_layer", "activation", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "f_activation"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nz", "=", "128", ",", "nc", "=", "10", ",", "ngf", "=", "32", ",", "lb", "=", "0", ",", "ub", "=", "1", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "f_activation", "=", "nn", ".", "Hardtanh", ",", "f_args", "=", "[", "0", ",", "1", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nz", "=", "nz", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "# input is Z, going into convolution", "\n", "nn", ".", "ConvTranspose2d", "(", "nz", ",", "ngf", "*", "8", ",", "4", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "\n", "# state size. (ngf*8) x 4 x 4", "\n", "networks", ".", "DenseBlockDecoder", "(", "ngf", "*", "8", ",", "16", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "networks", ".", "DenseTransitionBlockDecoder", "(", "ngf", "*", "8", ",", "ngf", "*", "8", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# state size. (ngf*8) x 8 x 8", "\n", "networks", ".", "DenseBlockDecoder", "(", "ngf", "*", "8", ",", "24", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "networks", ".", "DenseTransitionBlockDecoder", "(", "ngf", "*", "8", ",", "ngf", "*", "4", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# state size. (ngf*4) x 16 x 16", "\n", "networks", ".", "DenseBlockDecoder", "(", "ngf", "*", "4", ",", "12", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "networks", ".", "DenseTransitionBlockDecoder", "(", "ngf", "*", "4", ",", "ngf", "*", "2", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# state size. (ngf*2) x 32 x 32", "\n", "networks", ".", "DenseBlockDecoder", "(", "ngf", "*", "2", ",", "6", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "networks", ".", "DenseTransitionBlockDecoder", "(", "ngf", "*", "2", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# state size. (ngf) x 64 x 64", "\n", "networks", ".", "DenseBlockDecoder", "(", "ngf", ",", "4", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "networks", ".", "DenseTransitionBlockDecoder", "(", "ngf", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "\n", "# state size. (ngf) x 128 x 128", "\n", "networks", ".", "DenseBlockDecoder", "(", "ngf", ",", "2", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "networks", ".", "DenseTransitionBlockDecoder", "(", "ngf", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "\n", "# state size. (ngf) x 256 x 256", "\n", "norm_layer", "(", "ngf", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "ngf", ",", "nc", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "f_activation", "(", "*", "f_args", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese.DenseDecoder.forward": [[133, 136], ["siamese.DenseDecoder.main", "inputs.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "output", "=", "self", ".", "main", "(", "inputs", ".", "view", "(", "-", "1", ",", "self", ".", "nz", ",", "1", ",", "1", ")", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese.SiameseNetwork.__init__": [[139, 145], ["torch.Module.__init__", "siamese.DenseEncoder", "siamese.DenseEncoder", "siamese.DenseDecoder", "siamese.DenseDecoder"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "SiameseNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "photo_encoder", "=", "DenseEncoder", "(", ")", "\n", "self", ".", "cari_encoder", "=", "DenseEncoder", "(", ")", "\n", "self", ".", "photo_decoder", "=", "DenseDecoder", "(", ")", "\n", "self", ".", "cari_decoder", "=", "DenseDecoder", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese.SiameseNetwork.forward_photo": [[146, 150], ["siamese.SiameseNetwork.photo_encoder", "siamese.SiameseNetwork.photo_decoder"], "methods", ["None"], ["", "def", "forward_photo", "(", "self", ",", "x", ")", ":", "\n", "        ", "z", "=", "self", ".", "photo_encoder", "(", "x", ")", "\n", "output", "=", "self", ".", "photo_decoder", "(", "z", ")", "\n", "return", "z", ",", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese.SiameseNetwork.forward_cari": [[151, 155], ["siamese.SiameseNetwork.cari_encoder", "siamese.SiameseNetwork.cari_decoder"], "methods", ["None"], ["", "def", "forward_cari", "(", "self", ",", "x", ")", ":", "\n", "        ", "z", "=", "self", ".", "cari_encoder", "(", "x", ")", "\n", "output", "=", "self", ".", "cari_decoder", "(", "z", ")", "\n", "return", "z", ",", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese.SiameseNetwork.forward_cari_generation": [[156, 160], ["siamese.SiameseNetwork.photo_encoder", "siamese.SiameseNetwork.cari_decoder"], "methods", ["None"], ["", "def", "forward_cari_generation", "(", "self", ",", "x", ")", ":", "\n", "        ", "z", "=", "self", ".", "photo_encoder", "(", "x", ")", "\n", "output", "=", "self", ".", "cari_decoder", "(", "z", ")", "\n", "return", "z", ",", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese.SiameseNetwork.forward": [[163, 167], ["siamese.SiameseNetwork.forward_photo", "siamese.SiameseNetwork.forward_cari"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.SiameseNetwork.forward_photo", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.SiameseNetwork.forward_cari"], ["", "def", "forward", "(", "self", ",", "input1", ",", "input2", ")", ":", "\n", "        ", "z1", ",", "output1", "=", "self", ".", "forward_photo", "(", "input1", ")", "\n", "z2", ",", "output2", "=", "self", ".", "forward_cari", "(", "input2", ")", "\n", "return", "z1", ",", "output1", ",", "z2", ",", "output2", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese.takeSecond": [[22, 24], ["None"], "function", ["None"], ["def", "takeSecond", "(", "elem", ")", ":", "\n", "    ", "return", "elem", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese.channel_1toN": [[26, 36], ["torchvision.Compose", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "range", "torch.LongTensor().zero_.float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torchvision.ToTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "numpy.logical_not().astype", "transforms.Compose.", "img.size", "img.size", "img.size", "img.size", "numpy.logical_not", "numpy.logical_xor", "layer.numpy", "torch.LongTensor().zero_.numpy"], "function", ["None"], ["", "def", "channel_1toN", "(", "img", ",", "num_channel", ")", ":", "\n", "    ", "transform1", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "]", ")", "\n", "img", "=", "(", "transform1", "(", "img", ")", "*", "255.0", ")", ".", "long", "(", ")", "\n", "T", "=", "torch", ".", "LongTensor", "(", "num_channel", ",", "img", ".", "size", "(", "1", ")", ",", "img", ".", "size", "(", "2", ")", ")", ".", "zero_", "(", ")", "\n", "mask", "=", "torch", ".", "LongTensor", "(", "img", ".", "size", "(", "1", ")", ",", "img", ".", "size", "(", "2", ")", ")", ".", "zero_", "(", ")", "\n", "for", "i", "in", "range", "(", "num_channel", ")", ":", "\n", "        ", "T", "[", "i", "]", "=", "T", "[", "i", "]", "+", "i", "\n", "layer", "=", "T", "[", "i", "]", "-", "img", "\n", "T", "[", "i", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "logical_not", "(", "np", ".", "logical_xor", "(", "layer", ".", "numpy", "(", ")", ",", "mask", ".", "numpy", "(", ")", ")", ")", ".", "astype", "(", "int", ")", ")", "\n", "", "return", "T", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese.get_norm_layer": [[37, 47], ["functools.partial", "functools.partial", "NotImplementedError"], "function", ["None"], ["", "def", "get_norm_layer", "(", "norm_type", "=", "'instance'", ")", ":", "\n", "    ", "if", "norm_type", "==", "'batch'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "BatchNorm2d", ",", "affine", "=", "True", ")", "\n", "", "elif", "norm_type", "==", "'instance'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "InstanceNorm2d", ",", "affine", "=", "False", ",", "track_running_stats", "=", "False", ")", "\n", "", "elif", "norm_type", "==", "'none'", ":", "\n", "        ", "norm_layer", "=", "None", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'normalization layer [%s] is not found'", "%", "norm_type", ")", "\n", "", "return", "norm_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.image_folder.ImageFolder.__init__": [[43, 56], ["image_folder.make_dataset", "len", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.image_folder.make_dataset"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "transform", "=", "None", ",", "return_paths", "=", "False", ",", "\n", "loader", "=", "default_loader", ")", ":", "\n", "        ", "imgs", "=", "make_dataset", "(", "root", ")", "\n", "if", "len", "(", "imgs", ")", "==", "0", ":", "\n", "            ", "raise", "(", "RuntimeError", "(", "\"Found 0 images in: \"", "+", "root", "+", "\"\\n\"", "\n", "\"Supported image extensions are: \"", "+", "\n", "\",\"", ".", "join", "(", "IMG_EXTENSIONS", ")", ")", ")", "\n", "\n", "", "self", ".", "root", "=", "root", "\n", "self", ".", "imgs", "=", "imgs", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "return_paths", "=", "return_paths", "\n", "self", ".", "loader", "=", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.image_folder.ImageFolder.__getitem__": [[57, 66], ["image_folder.ImageFolder.loader", "image_folder.ImageFolder.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "imgs", "[", "index", "]", "\n", "img", "=", "self", ".", "loader", "(", "path", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "if", "self", ".", "return_paths", ":", "\n", "            ", "return", "img", ",", "path", "\n", "", "else", ":", "\n", "            ", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.image_folder.ImageFolder.__len__": [[67, 69], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "imgs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.image_folder.is_image_file": [[20, 22], ["any", "filename.endswith"], "function", ["None"], ["def", "is_image_file", "(", "filename", ")", ":", "\n", "    ", "return", "any", "(", "filename", ".", "endswith", "(", "extension", ")", "for", "extension", "in", "IMG_EXTENSIONS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.image_folder.make_dataset": [[24, 35], ["os.path.isdir", "os.path.isdir", "sorted", "os.walk", "os.walk", "image_folder.is_image_file", "os.path.join", "os.path.join", "images.append"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.image_folder.is_image_file"], ["", "def", "make_dataset", "(", "dir", ")", ":", "\n", "    ", "images", "=", "[", "]", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "dir", ")", ",", "'%s is not a valid directory'", "%", "dir", "\n", "\n", "for", "root", ",", "_", ",", "fnames", "in", "sorted", "(", "os", ".", "walk", "(", "dir", ")", ")", ":", "\n", "        ", "for", "fname", "in", "fnames", ":", "\n", "            ", "if", "is_image_file", "(", "fname", ")", ":", "\n", "                ", "path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "fname", ")", "\n", "images", ".", "append", "(", "path", ")", "\n", "\n", "", "", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.image_folder.default_loader": [[37, 39], ["PIL.Image.open().convert", "PIL.Image.open"], "function", ["None"], ["", "def", "default_loader", "(", "path", ")", ":", "\n", "    ", "return", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese_dataset.SiameseDataset.modify_commandline_options": [[27, 30], ["None"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese_dataset.SiameseDataset.__init__": [[31, 74], ["base_dataset.BaseDataset.__init__", "image_folder.make_dataset", "sorted", "len", "image_folder.make_dataset", "sorted", "len", "image_folder.make_dataset", "sorted", "len", "torchvision.Compose", "torchvision.ToTensor", "img_name.split", "siamese_dataset.SiameseDataset.train_dict.keys", "siamese_dataset.SiameseDataset.train_dict[].append", "img_name.split", "siamese_dataset.SiameseDataset.cari_dict.keys", "siamese_dataset.SiameseDataset.cari_dict[].append"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.image_folder.make_dataset", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.image_folder.make_dataset", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.image_folder.make_dataset"], ["", "def", "__init__", "(", "self", ",", "mode", "=", "'Train'", ")", ":", "\n", "        ", "super", "(", "SiameseDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "train_dir", "=", "'./data/photo_parse_train/'", "\n", "self", ".", "test_dir", "=", "'./data/photo_parse_test/'", "\n", "self", ".", "cari_dir", "=", "'./data/caricature_parse/'", "\n", "\n", "self", ".", "train_path", "=", "make_dataset", "(", "self", ".", "train_dir", ")", "\n", "self", ".", "train_paths", "=", "sorted", "(", "self", ".", "train_path", ")", "\n", "self", ".", "train_dict", "=", "{", "}", "\n", "for", "img_name", "in", "self", ".", "train_paths", ":", "\n", "            ", "person_name", "=", "img_name", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "person_name", "=", "person_name", "[", ":", "-", "11", "]", "\n", "if", "person_name", "not", "in", "self", ".", "train_dict", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "train_dict", "[", "person_name", "]", "=", "[", "img_name", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "train_dict", "[", "person_name", "]", ".", "append", "(", "img_name", ")", "\n", "", "", "self", ".", "train_size", "=", "len", "(", "self", ".", "train_path", ")", "\n", "\n", "self", ".", "test_path", "=", "make_dataset", "(", "self", ".", "test_dir", ")", "\n", "self", ".", "test_paths", "=", "sorted", "(", "self", ".", "test_path", ")", "\n", "self", ".", "test_size", "=", "len", "(", "self", ".", "test_path", ")", "\n", "\n", "self", ".", "cari_path", "=", "make_dataset", "(", "self", ".", "cari_dir", ")", "\n", "self", ".", "cari_paths", "=", "sorted", "(", "self", ".", "cari_path", ")", "\n", "self", ".", "cari_dict", "=", "{", "}", "\n", "for", "img_name", "in", "self", ".", "cari_paths", ":", "\n", "            ", "person_name", "=", "img_name", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "person_name", "=", "person_name", "[", ":", "-", "11", "]", "\n", "if", "person_name", "not", "in", "self", ".", "cari_dict", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "cari_dict", "[", "person_name", "]", "=", "[", "img_name", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "cari_dict", "[", "person_name", "]", ".", "append", "(", "img_name", ")", "\n", "", "", "self", ".", "cari_size", "=", "len", "(", "self", ".", "cari_path", ")", "\n", "\n", "transform_list", "=", "[", "]", "\n", "transform_list", "+=", "[", "transforms", ".", "ToTensor", "(", ")", "]", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "self", ".", "target_transform", "=", "self", ".", "transform", "\n", "if", "self", ".", "mode", "==", "'Val'", ":", "\n", "            ", "self", ".", "train_size", "=", "self", ".", "test_size", "\n", "self", ".", "train_path", "=", "self", ".", "test_path", "\n", "self", ".", "train_paths", "=", "self", ".", "test_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese_dataset.SiameseDataset.__getitem__": [[75, 111], ["random.randint", "random.randint", "PIL.Image.open", "siamese_dataset.channel_1toN", "PIL.Image.open", "siamese_dataset.channel_1toN", "photo_train_path.split", "siamese_dataset.SiameseDataset.cari_dict.keys", "len", "random.randint", "random.randint", "cari_path.split"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.parseref_dataset.channel_1toN", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.parseref_dataset.channel_1toN"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "\n", "        ", "index_A", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "train_size", "-", "1", ")", "\n", "photo_train_path", "=", "self", ".", "train_paths", "[", "index_A", "]", "\n", "person_name", "=", "photo_train_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "person_name", "=", "person_name", "[", ":", "-", "11", "]", "\n", "should_get_same_class", "=", "random", ".", "randint", "(", "0", ",", "1", ")", "\n", "if", "person_name", "not", "in", "self", ".", "cari_dict", ".", "keys", "(", ")", ":", "\n", "            ", "cari_num", "=", "0", "\n", "", "else", ":", "\n", "            ", "cari_num", "=", "len", "(", "self", ".", "cari_dict", "[", "person_name", "]", ")", "\n", "", "same_id", "=", "0", "\n", "if", "should_get_same_class", "and", "cari_num", ">", "0", ":", "\n", "            ", "same_id", "=", "1", "\n", "cari_number", "=", "random", ".", "randint", "(", "0", ",", "cari_num", "-", "1", ")", "\n", "cari_path", "=", "self", ".", "cari_dict", "[", "person_name", "]", "[", "cari_number", "]", "\n", "", "else", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "index_B", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "cari_size", "-", "1", ")", "\n", "cari_path", "=", "self", ".", "cari_paths", "[", "index_B", "]", "\n", "cari_name", "=", "cari_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "if", "cari_name", "[", ":", "-", "11", "]", "!=", "person_name", ":", "\n", "                    ", "same_id", "=", "0", "\n", "break", "\n", "\n", "\n", "\n", "", "", "", "A", "=", "Image", ".", "open", "(", "photo_train_path", ")", "\n", "A", "=", "channel_1toN", "(", "A", ",", "10", ")", "\n", "\n", "B", "=", "Image", ".", "open", "(", "cari_path", ")", "\n", "B", "=", "channel_1toN", "(", "B", ",", "10", ")", "\n", "\n", "\n", "return", "{", "'A'", ":", "A", ",", "'B'", ":", "B", ",", "'label'", ":", "same_id", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese_dataset.SiameseDataset.__len__": [[112, 116], ["max"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "max_size", "=", "0", "\n", "max_size", "=", "max", "(", "self", ".", "train_size", ",", "self", ".", "cari_size", ")", "\n", "return", "self", ".", "train_size", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese_dataset.SiameseDataset.name": [[117, 119], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'SiameseDataset'", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.siamese_dataset.channel_1toN": [[13, 23], ["torchvision.Compose", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "range", "torch.LongTensor().zero_.float", "torch.from_numpy", "torch.from_numpy", "torchvision.ToTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "numpy.logical_not().astype", "transforms.Compose.", "img.size", "img.size", "img.size", "img.size", "numpy.logical_not", "numpy.logical_xor", "layer.numpy", "torch.LongTensor().zero_.numpy"], "function", ["None"], ["def", "channel_1toN", "(", "img", ",", "num_channel", ")", ":", "\n", "    ", "transform1", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "]", ")", "\n", "img", "=", "(", "transform1", "(", "img", ")", "*", "255.0", ")", ".", "long", "(", ")", "\n", "T", "=", "torch", ".", "LongTensor", "(", "num_channel", ",", "img", ".", "size", "(", "1", ")", ",", "img", ".", "size", "(", "2", ")", ")", ".", "zero_", "(", ")", "\n", "mask", "=", "torch", ".", "LongTensor", "(", "img", ".", "size", "(", "1", ")", ",", "img", ".", "size", "(", "2", ")", ")", ".", "zero_", "(", ")", "\n", "for", "i", "in", "range", "(", "num_channel", ")", ":", "\n", "        ", "T", "[", "i", "]", "=", "T", "[", "i", "]", "+", "i", "\n", "layer", "=", "T", "[", "i", "]", "-", "img", "\n", "T", "[", "i", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "logical_not", "(", "np", ".", "logical_xor", "(", "layer", ".", "numpy", "(", ")", ",", "mask", ".", "numpy", "(", ")", ")", ")", ".", "astype", "(", "int", ")", ")", "\n", "", "return", "T", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.DenseEncoder.__init__": [[50, 82], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "DAENet.DenseBlockEncoder", "DAENet.DenseTransitionBlockEncoder", "DAENet.DenseBlockEncoder", "DAENet.DenseTransitionBlockEncoder", "DAENet.DenseBlockEncoder", "DAENet.DenseTransitionBlockEncoder", "DAENet.DenseBlockEncoder", "DAENet.DenseTransitionBlockEncoder", "DAENet.DenseBlockEncoder", "DAENet.DenseTransitionBlockEncoder", "f_activation"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nc", "=", "10", ",", "ndf", "=", "32", ",", "ndim", "=", "128", ",", "activation", "=", "nn", ".", "LeakyReLU", ",", "args", "=", "[", "0.2", ",", "False", "]", ",", "f_activation", "=", "nn", ".", "Sigmoid", ",", "f_args", "=", "[", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ndim", "=", "ndim", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "# input is (nc) x 256 x 256", "\n", "nn", ".", "Conv2d", "(", "nc", ",", "ndf", ",", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "ndf", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "\n", "\n", "\n", "# input is (ndf) x 64 x 64", "\n", "DAENet", ".", "DenseBlockEncoder", "(", "ndf", ",", "4", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockEncoder", "(", "ndf", ",", "ndf", "*", "2", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# input is (ndf*2) x 32 x 32", "\n", "DAENet", ".", "DenseBlockEncoder", "(", "ndf", "*", "2", ",", "6", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockEncoder", "(", "ndf", "*", "2", ",", "ndf", "*", "4", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# input is (ndf*4) x 16 x 16", "\n", "DAENet", ".", "DenseBlockEncoder", "(", "ndf", "*", "4", ",", "12", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockEncoder", "(", "ndf", "*", "4", ",", "ndf", "*", "8", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# input is (ndf*8) x 8 x 8", "\n", "DAENet", ".", "DenseBlockEncoder", "(", "ndf", "*", "8", ",", "24", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockEncoder", "(", "ndf", "*", "8", ",", "ndf", "*", "8", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# input is (ndf*8) x 4 x 4", "\n", "DAENet", ".", "DenseBlockEncoder", "(", "ndf", "*", "8", ",", "16", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockEncoder", "(", "ndf", "*", "8", ",", "ndim", ",", "4", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "f_activation", "(", "*", "f_args", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.DenseEncoder.forward": [[84, 88], ["test_siamese_celeba.DenseEncoder.main", "output.view.view.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "output", "=", "self", ".", "main", "(", "input", ")", "\n", "output", "=", "output", ".", "view", "(", "-", "1", ",", "self", ".", "ndim", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.DenseDecoder.__init__": [[92, 130], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "DAENet.DenseBlockDecoder", "DAENet.DenseTransitionBlockDecoder", "DAENet.DenseBlockDecoder", "DAENet.DenseTransitionBlockDecoder", "DAENet.DenseBlockDecoder", "DAENet.DenseTransitionBlockDecoder", "DAENet.DenseBlockDecoder", "DAENet.DenseTransitionBlockDecoder", "DAENet.DenseBlockDecoder", "DAENet.DenseTransitionBlockDecoder", "DAENet.DenseBlockDecoder", "DAENet.DenseTransitionBlockDecoder", "norm_layer", "activation", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "f_activation"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nz", "=", "128", ",", "nc", "=", "10", ",", "ngf", "=", "32", ",", "lb", "=", "0", ",", "ub", "=", "1", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "f_activation", "=", "nn", ".", "Hardtanh", ",", "f_args", "=", "[", "0", ",", "1", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nz", "=", "nz", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "# input is Z, going into convolution", "\n", "nn", ".", "ConvTranspose2d", "(", "nz", ",", "ngf", "*", "8", ",", "4", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "\n", "# state size. (ngf*8) x 4 x 4", "\n", "DAENet", ".", "DenseBlockDecoder", "(", "ngf", "*", "8", ",", "16", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockDecoder", "(", "ngf", "*", "8", ",", "ngf", "*", "8", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# state size. (ngf*8) x 8 x 8", "\n", "DAENet", ".", "DenseBlockDecoder", "(", "ngf", "*", "8", ",", "24", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockDecoder", "(", "ngf", "*", "8", ",", "ngf", "*", "4", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# state size. (ngf*4) x 16 x 16", "\n", "DAENet", ".", "DenseBlockDecoder", "(", "ngf", "*", "4", ",", "12", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockDecoder", "(", "ngf", "*", "4", ",", "ngf", "*", "2", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# state size. (ngf*2) x 32 x 32", "\n", "DAENet", ".", "DenseBlockDecoder", "(", "ngf", "*", "2", ",", "6", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockDecoder", "(", "ngf", "*", "2", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "# state size. (ngf) x 64 x 64", "\n", "DAENet", ".", "DenseBlockDecoder", "(", "ngf", ",", "4", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockDecoder", "(", "ngf", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "\n", "# state size. (ngf) x 128 x 128", "\n", "DAENet", ".", "DenseBlockDecoder", "(", "ngf", ",", "2", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DAENet", ".", "DenseTransitionBlockDecoder", "(", "ngf", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "\n", "# state size. (ngf) x 256 x 256", "\n", "norm_layer", "(", "ngf", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "ngf", ",", "nc", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "f_activation", "(", "*", "f_args", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.DenseDecoder.forward": [[132, 135], ["test_siamese_celeba.DenseDecoder.main", "inputs.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "output", "=", "self", ".", "main", "(", "inputs", ".", "view", "(", "-", "1", ",", "self", ".", "nz", ",", "1", ",", "1", ")", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.SiameseNetwork.__init__": [[138, 144], ["torch.Module.__init__", "test_siamese_celeba.DenseEncoder", "test_siamese_celeba.DenseEncoder", "test_siamese_celeba.DenseDecoder", "test_siamese_celeba.DenseDecoder"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "SiameseNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "photo_encoder", "=", "DenseEncoder", "(", ")", "\n", "self", ".", "cari_encoder", "=", "DenseEncoder", "(", ")", "\n", "self", ".", "photo_decoder", "=", "DenseDecoder", "(", ")", "\n", "self", ".", "cari_decoder", "=", "DenseDecoder", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.SiameseNetwork.forward_photo": [[145, 149], ["test_siamese_celeba.SiameseNetwork.photo_encoder", "test_siamese_celeba.SiameseNetwork.photo_decoder"], "methods", ["None"], ["", "def", "forward_photo", "(", "self", ",", "x", ")", ":", "\n", "        ", "z", "=", "self", ".", "photo_encoder", "(", "x", ")", "\n", "output", "=", "self", ".", "photo_decoder", "(", "z", ")", "\n", "return", "z", ",", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.SiameseNetwork.forward_cari": [[150, 154], ["test_siamese_celeba.SiameseNetwork.cari_encoder", "test_siamese_celeba.SiameseNetwork.cari_decoder"], "methods", ["None"], ["", "def", "forward_cari", "(", "self", ",", "x", ")", ":", "\n", "        ", "z", "=", "self", ".", "cari_encoder", "(", "x", ")", "\n", "output", "=", "self", ".", "cari_decoder", "(", "z", ")", "\n", "return", "z", ",", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.SiameseNetwork.forward_cari_generation": [[155, 159], ["test_siamese_celeba.SiameseNetwork.photo_encoder", "test_siamese_celeba.SiameseNetwork.cari_decoder"], "methods", ["None"], ["", "def", "forward_cari_generation", "(", "self", ",", "x", ")", ":", "\n", "        ", "z", "=", "self", ".", "photo_encoder", "(", "x", ")", "\n", "output", "=", "self", ".", "cari_decoder", "(", "z", ")", "\n", "return", "z", ",", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.SiameseNetwork.forward": [[162, 166], ["test_siamese_celeba.SiameseNetwork.forward_photo", "test_siamese_celeba.SiameseNetwork.forward_cari"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.SiameseNetwork.forward_photo", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.SiameseNetwork.forward_cari"], ["", "def", "forward", "(", "self", ",", "input1", ",", "input2", ")", ":", "\n", "        ", "z1", ",", "output1", "=", "self", ".", "forward_photo", "(", "input1", ")", "\n", "z2", ",", "output2", "=", "self", ".", "forward_cari", "(", "input2", ")", "\n", "return", "z1", ",", "output1", ",", "z2", ",", "output2", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.ContrastiveLoss.__init__": [[168, 171], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "margin", "=", "2.0", ")", ":", "\n", "        ", "super", "(", "ContrastiveLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.ContrastiveLoss.forward": [[172, 177], ["torch.pairwise_distance", "torch.pairwise_distance", "torch.pairwise_distance", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "torch.pow().squeeze", "label.float", "label.float", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output1", ",", "output2", ",", "label", ")", ":", "\n", "        ", "euclidean_distance", "=", "F", ".", "pairwise_distance", "(", "output1", ",", "output2", ",", "keepdim", "=", "True", ")", "\n", "loss_contrastive", "=", "torch", ".", "mean", "(", "torch", ".", "pow", "(", "euclidean_distance", ",", "2", ")", ".", "squeeze", "(", ")", "*", "(", "1", "-", "label", ".", "float", "(", ")", ")", "+", "torch", ".", "pow", "(", "torch", ".", "clamp", "(", "self", ".", "margin", "-", "euclidean_distance", ",", "min", "=", "0.0", ")", ",", "2", ")", ".", "squeeze", "(", ")", "*", "label", ".", "float", "(", ")", ")", "\n", "return", "loss_contrastive", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.takeSecond": [[21, 23], ["None"], "function", ["None"], ["def", "takeSecond", "(", "elem", ")", ":", "\n", "    ", "return", "elem", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.channel_1toN": [[25, 35], ["torchvision.Compose", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "range", "torch.LongTensor().zero_.float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torchvision.ToTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "numpy.logical_not().astype", "transforms.Compose.", "img.size", "img.size", "img.size", "img.size", "numpy.logical_not", "numpy.logical_xor", "layer.numpy", "torch.LongTensor().zero_.numpy"], "function", ["None"], ["", "def", "channel_1toN", "(", "img", ",", "num_channel", ")", ":", "\n", "    ", "transform1", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "]", ")", "\n", "img", "=", "(", "transform1", "(", "img", ")", "*", "255.0", ")", ".", "long", "(", ")", "\n", "T", "=", "torch", ".", "LongTensor", "(", "num_channel", ",", "img", ".", "size", "(", "1", ")", ",", "img", ".", "size", "(", "2", ")", ")", ".", "zero_", "(", ")", "\n", "mask", "=", "torch", ".", "LongTensor", "(", "img", ".", "size", "(", "1", ")", ",", "img", ".", "size", "(", "2", ")", ")", ".", "zero_", "(", ")", "\n", "for", "i", "in", "range", "(", "num_channel", ")", ":", "\n", "        ", "T", "[", "i", "]", "=", "T", "[", "i", "]", "+", "i", "\n", "layer", "=", "T", "[", "i", "]", "-", "img", "\n", "T", "[", "i", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "logical_not", "(", "np", ".", "logical_xor", "(", "layer", ".", "numpy", "(", ")", ",", "mask", ".", "numpy", "(", ")", ")", ")", ".", "astype", "(", "int", ")", ")", "\n", "", "return", "T", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.retrieval.test_siamese_celeba.get_norm_layer": [[36, 46], ["functools.partial", "functools.partial", "NotImplementedError"], "function", ["None"], ["", "def", "get_norm_layer", "(", "norm_type", "=", "'instance'", ")", ":", "\n", "    ", "if", "norm_type", "==", "'batch'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "BatchNorm2d", ",", "affine", "=", "True", ")", "\n", "", "elif", "norm_type", "==", "'instance'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "InstanceNorm2d", ",", "affine", "=", "False", ",", "track_running_stats", "=", "False", ")", "\n", "", "elif", "norm_type", "==", "'none'", ":", "\n", "        ", "norm_layer", "=", "None", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'normalization layer [%s] is not found'", "%", "norm_type", ")", "\n", "", "return", "norm_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.base.BaseNet.__init__": [[22, 51], ["torch.Module.__init__", "parsing.mobilenet", "parsing.resnet50", "parsing.resnet101", "parsing.resnet101coco", "parsing.resnet152", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.resnet50", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.resnet101", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.resnet101coco", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.resnet152"], ["    ", "def", "__init__", "(", "self", ",", "nclass", ",", "backbone", ",", "aux", ",", "se_loss", ",", "dilated", "=", "True", ",", "norm_layer", "=", "None", ",", "\n", "mean", "=", "[", ".485", ",", ".456", ",", ".406", "]", ",", "std", "=", "[", ".229", ",", ".224", ",", ".225", "]", ",", "root", "=", "'~/.encoding/models'", ")", ":", "\n", "        ", "super", "(", "BaseNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nclass", "=", "nclass", "\n", "self", ".", "aux", "=", "aux", "\n", "self", ".", "se_loss", "=", "se_loss", "\n", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "self", ".", "backbone", "=", "backbone", "\n", "# copying modules from pretrained models", "\n", "if", "backbone", "==", "'mobilenet'", ":", "\n", "            ", "self", ".", "pretrained", "=", "resnet", ".", "mobilenet", "(", "pretrained", "=", "False", ",", "dilated", "=", "dilated", ",", "\n", "norm_layer", "=", "norm_layer", ",", "root", "=", "root", ")", "\n", "", "elif", "backbone", "==", "'resnet50'", ":", "\n", "            ", "self", ".", "pretrained", "=", "resnet", ".", "resnet50", "(", "pretrained", "=", "False", ",", "dilated", "=", "dilated", ",", "\n", "norm_layer", "=", "norm_layer", ",", "root", "=", "root", ")", "\n", "", "elif", "backbone", "==", "'resnet101'", ":", "\n", "            ", "self", ".", "pretrained", "=", "resnet", ".", "resnet101", "(", "pretrained", "=", "False", ",", "dilated", "=", "dilated", ",", "\n", "norm_layer", "=", "norm_layer", ",", "root", "=", "root", ")", "\n", "", "elif", "backbone", "==", "'resnet101coco'", ":", "\n", "            ", "self", ".", "pretrained", "=", "resnet", ".", "resnet101coco", "(", "pretrained", "=", "False", ",", "dilated", "=", "dilated", ",", "\n", "norm_layer", "=", "norm_layer", ",", "root", "=", "root", ")", "\n", "", "elif", "backbone", "==", "'resnet152'", ":", "\n", "            ", "self", ".", "pretrained", "=", "resnet", ".", "resnet152", "(", "pretrained", "=", "False", ",", "dilated", "=", "dilated", ",", "\n", "norm_layer", "=", "norm_layer", ",", "root", "=", "root", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "'unknown backbone: {}'", ".", "format", "(", "backbone", ")", ")", "\n", "# bilinear upsample options", "\n", "", "self", ".", "_up_kwargs", "=", "up_kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.base.BaseNet.base_forward": [[52, 69], ["base.BaseNet.pretrained.features", "base.BaseNet.pretrained.conv1", "base.BaseNet.pretrained.bn1", "base.BaseNet.pretrained.relu", "base.BaseNet.pretrained.maxpool", "base.BaseNet.pretrained.layer1", "base.BaseNet.pretrained.layer2", "base.BaseNet.pretrained.layer3", "base.BaseNet.pretrained.layer4"], "methods", ["None"], ["", "def", "base_forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "backbone", "==", "'mobilenet'", ":", "\n", "            ", "x", "=", "self", ".", "pretrained", ".", "features", "(", "x", ")", "\n", "c1", "=", "x", "\n", "c2", "=", "x", "\n", "c3", "=", "x", "\n", "c4", "=", "x", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "pretrained", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "pretrained", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "pretrained", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "pretrained", ".", "maxpool", "(", "x", ")", "\n", "c1", "=", "self", ".", "pretrained", ".", "layer1", "(", "x", ")", "\n", "c2", "=", "self", ".", "pretrained", ".", "layer2", "(", "c1", ")", "\n", "c3", "=", "self", ".", "pretrained", ".", "layer3", "(", "c2", ")", "\n", "c4", "=", "self", ".", "pretrained", ".", "layer4", "(", "c3", ")", "\n", "", "return", "c1", ",", "c2", ",", "c3", ",", "c4", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.psp.PyramidPooling.__init__": [[21, 33], ["torch.nn.Module.__init__", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "int", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "norm_layer", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "norm_layer", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "norm_layer", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "norm_layer", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "norm_layer", ")", ":", "\n", "        ", "super", "(", "PyramidPooling", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pool1", "=", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "self", ".", "pool2", "=", "AdaptiveAvgPool2d", "(", "2", ")", "\n", "self", ".", "pool3", "=", "AdaptiveAvgPool2d", "(", "3", ")", "\n", "self", ".", "pool4", "=", "AdaptiveAvgPool2d", "(", "6", ")", "\n", "\n", "out_channels", "=", "int", "(", "in_channels", "/", "4", ")", "\n", "self", ".", "conv1", "=", "Sequential", "(", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "bias", "=", "False", ")", ",", "norm_layer", "(", "out_channels", ")", ",", "ReLU", "(", "True", ")", ")", "\n", "self", ".", "conv2", "=", "Sequential", "(", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "bias", "=", "False", ")", ",", "norm_layer", "(", "out_channels", ")", ",", "ReLU", "(", "True", ")", ")", "\n", "self", ".", "conv3", "=", "Sequential", "(", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "bias", "=", "False", ")", ",", "norm_layer", "(", "out_channels", ")", ",", "ReLU", "(", "True", ")", ")", "\n", "self", ".", "conv4", "=", "Sequential", "(", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "bias", "=", "False", ")", ",", "norm_layer", "(", "out_channels", ")", ",", "ReLU", "(", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.psp.PyramidPooling.forward": [[35, 42], ["x.size", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "psp.PyramidPooling.conv1", "psp.PyramidPooling.conv2", "psp.PyramidPooling.conv3", "psp.PyramidPooling.conv4", "psp.PyramidPooling.pool1", "psp.PyramidPooling.pool2", "psp.PyramidPooling.pool3", "psp.PyramidPooling.pool4"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_", ",", "_", ",", "h", ",", "w", "=", "x", ".", "size", "(", ")", "\n", "feat1", "=", "F", ".", "upsample", "(", "self", ".", "conv1", "(", "self", ".", "pool1", "(", "x", ")", ")", ",", "(", "h", ",", "w", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "feat2", "=", "F", ".", "upsample", "(", "self", ".", "conv2", "(", "self", ".", "pool2", "(", "x", ")", ")", ",", "(", "h", ",", "w", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "feat3", "=", "F", ".", "upsample", "(", "self", ".", "conv3", "(", "self", ".", "pool3", "(", "x", ")", ")", ",", "(", "h", ",", "w", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "feat4", "=", "F", ".", "upsample", "(", "self", ".", "conv4", "(", "self", ".", "pool4", "(", "x", ")", ")", ",", "(", "h", ",", "w", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "return", "torch", ".", "cat", "(", "(", "x", ",", "feat1", ",", "feat2", ",", "feat3", ",", "feat4", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.psp.FCNHead.__init__": [[47, 51], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "norm_layer", ")", ":", "\n", "        ", "super", "(", "FCNHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "inter_channels", "=", "in_channels", "//", "4", "\n", "self", ".", "conv5", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "in_channels", ",", "inter_channels", ",", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "norm_layer", "(", "inter_channels", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Dropout2d", "(", "0.1", ",", "False", ")", ",", "nn", ".", "Conv2d", "(", "inter_channels", ",", "out_channels", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.psp.FCNHead.forward": [[52, 54], ["psp.FCNHead.conv5"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "conv5", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.psp.PSP.__init__": [[58, 64], ["parsing.base.BaseNet.__init__", "psp.PSPHead", "psp.FCNHead"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nclass", ",", "backbone", ",", "aux", "=", "True", ",", "se_loss", "=", "False", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "PSP", ",", "self", ")", ".", "__init__", "(", "nclass", ",", "backbone", ",", "aux", ",", "se_loss", ",", "norm_layer", "=", "norm_layer", ")", "\n", "#self.head = PSPHead(1280, nclass, norm_layer)", "\n", "self", ".", "head", "=", "PSPHead", "(", "2048", ",", "nclass", ",", "norm_layer", ")", "\n", "if", "aux", ":", "\n", "            ", "self", ".", "auxlayer", "=", "FCNHead", "(", "1024", ",", "nclass", ",", "norm_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.psp.PSP.forward": [[65, 78], ["torch.nn.functional.upsample.size", "torch.nn.functional.upsample.size", "torch.nn.functional.upsample.size", "psp.PSP.base_forward", "psp.PSP.head", "torch.nn.functional.upsample", "torch.nn.functional.upsample", "torch.nn.functional.upsample", "outputs.append", "psp.PSP.auxlayer", "torch.nn.functional.upsample", "torch.nn.functional.upsample", "torch.nn.functional.upsample", "outputs.append"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.base.BaseNet.base_forward"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_", ",", "_", ",", "h", ",", "w", "=", "x", ".", "size", "(", ")", "\n", "_", ",", "_", ",", "c3", ",", "c4", "=", "self", ".", "base_forward", "(", "x", ")", "\n", "\n", "outputs", "=", "[", "]", "\n", "x", "=", "self", ".", "head", "(", "c4", ")", "\n", "x", "=", "upsample", "(", "x", ",", "(", "h", ",", "w", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "outputs", ".", "append", "(", "x", ")", "\n", "if", "self", ".", "aux", ":", "\n", "            ", "auxout", "=", "self", ".", "auxlayer", "(", "c3", ")", "\n", "auxout", "=", "upsample", "(", "auxout", ",", "(", "h", ",", "w", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "outputs", ".", "append", "(", "auxout", ")", "\n", "", "return", "x", ",", "auxout", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.psp.PSPHead.__init__": [[82, 91], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "psp.PyramidPooling", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "norm_layer", ")", ":", "\n", "        ", "super", "(", "PSPHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "inter_channels", "=", "in_channels", "//", "4", "\n", "self", ".", "conv5", "=", "nn", ".", "Sequential", "(", "PyramidPooling", "(", "in_channels", ",", "norm_layer", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", "*", "2", ",", "inter_channels", ",", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "norm_layer", "(", "inter_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout2d", "(", "0.1", ",", "False", ")", ",", "\n", "nn", ".", "Conv2d", "(", "inter_channels", ",", "out_channels", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.psp.PSPHead.forward": [[92, 94], ["psp.PSPHead.conv5"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "conv5", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.psp.get_psp": [[96, 114], ["psp.PSP", "PSP.load_state_dict", "torch.load", "torch.load", "torch.load", "get_model_file", "dataset.lower"], "function", ["None"], ["", "", "def", "get_psp", "(", "dataset", "=", "'pascal_voc'", ",", "backbone", "=", "'resnet50'", ",", "pretrained", "=", "False", ",", "\n", "root", "=", "'~/.encoding/models'", ",", "**", "kwargs", ")", ":", "\n", "    ", "acronyms", "=", "{", "\n", "'pascal_voc'", ":", "'voc'", ",", "\n", "'pascal_aug'", ":", "'voc'", ",", "\n", "'ade20k'", ":", "'ade'", ",", "\n", "'pcontext'", ":", "'pcontext'", ",", "\n", "'cityscapes'", ":", "'cityscapes'", ",", "\n", "'gta5'", ":", "'gta5'", ",", "\n", "}", "\n", "# infer number of classes", "\n", "from", ".", ".", "datasets", "import", "datasets", ",", "VOCSegmentation", ",", "VOCAugSegmentation", ",", "ADE20KSegmentation", ",", "ContextSegmentation", ",", "GTA5Segmentation", "\n", "model", "=", "PSP", "(", "datasets", "[", "dataset", ".", "lower", "(", ")", "]", ".", "NUM_CLASS", ",", "backbone", "=", "backbone", ",", "root", "=", "root", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "from", ".", "model_store", "import", "get_model_file", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\n", "get_model_file", "(", "'psp_%s_%s'", "%", "(", "backbone", ",", "acronyms", "[", "dataset", "]", ")", ",", "root", "=", "root", ")", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.logger.setup_logger": [[13, 22], ["os.join", "logging.basicConfig", "logging.root.addHandler", "time.strftime", "torch.is_initialized", "logging.StreamHandler", "torch.get_rank"], "function", ["None"], ["def", "setup_logger", "(", "logpth", ")", ":", "\n", "    ", "logfile", "=", "'BiSeNet-{}.log'", ".", "format", "(", "time", ".", "strftime", "(", "'%Y-%m-%d-%H-%M-%S'", ")", ")", "\n", "logfile", "=", "osp", ".", "join", "(", "logpth", ",", "logfile", ")", "\n", "FORMAT", "=", "'%(levelname)s %(filename)s(%(lineno)d): %(message)s'", "\n", "log_level", "=", "logging", ".", "INFO", "\n", "if", "dist", ".", "is_initialized", "(", ")", "and", "not", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "        ", "log_level", "=", "logging", ".", "ERROR", "\n", "", "logging", ".", "basicConfig", "(", "level", "=", "log_level", ",", "format", "=", "FORMAT", ",", "filename", "=", "logfile", ")", "\n", "logging", ".", "root", ".", "addHandler", "(", "logging", ".", "StreamHandler", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.celeba_dataset.FaceMask.__init__": [[20, 49], ["torch.utils.data.Dataset.__init__", "open", "open.readlines", "torchvision.Compose", "transform.Compose", "line.strip.strip.strip", "line.strip.strip.split", "celeba_dataset.FaceMask.imgs.append", "celeba_dataset.FaceMask.labels.append", "torchvision.ToTensor", "torchvision.Normalize", "transform.ColorJitter", "transform.HorizontalFlip", "transform.RandomScale", "transform.RandomCrop"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "listpth", ",", "cropsize", "=", "(", "320", ",", "240", ")", ",", "mode", "=", "'train'", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "FaceMask", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "assert", "mode", "in", "(", "'train'", ",", "'val'", ",", "'test'", ")", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "ignore_lb", "=", "255", "\n", "self", ".", "listpth", "=", "listpth", "\n", "\n", "f", "=", "open", "(", "self", ".", "listpth", ")", "\n", "self", ".", "imgs", "=", "[", "]", "\n", "self", ".", "labels", "=", "[", "]", "\n", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "line1", ",", "line2", "=", "line", ".", "split", "(", "','", ")", "\n", "self", ".", "imgs", ".", "append", "(", "line1", ")", "\n", "self", ".", "labels", ".", "append", "(", "line2", ")", "\n", "\n", "#  pre-processing", "\n", "", "self", ".", "to_tensor", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "(", "0.229", ",", "0.224", ",", "0.225", ")", ")", ",", "\n", "]", ")", "\n", "self", ".", "trans_train", "=", "Compose", "(", "[", "\n", "ColorJitter", "(", "\n", "brightness", "=", "0.5", ",", "\n", "contrast", "=", "0.5", ",", "\n", "saturation", "=", "0.5", ")", ",", "\n", "HorizontalFlip", "(", ")", ",", "\n", "RandomScale", "(", "(", "0.75", ",", "1.0", ",", "1.25", ",", "1.5", ",", "1.75", ",", "2.0", ",", "2.25", ",", "2.5", ")", ")", ",", "\n", "RandomCrop", "(", "cropsize", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.celeba_dataset.FaceMask.__getitem__": [[51, 64], ["PIL.Image.open", "PIL.Image.open().convert", "celeba_dataset.FaceMask.to_tensor", "dict", "celeba_dataset.FaceMask.trans_train", "numpy.array().astype", "PIL.Image.open", "numpy.array"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "impth", "=", "self", ".", "imgs", "[", "idx", "]", "\n", "label_path", "=", "self", ".", "labels", "[", "idx", "]", "\n", "img", "=", "Image", ".", "open", "(", "impth", ")", "\n", "label", "=", "Image", ".", "open", "(", "label_path", ")", ".", "convert", "(", "'P'", ")", "\n", "\n", "if", "self", ".", "mode", "==", "'train'", ":", "\n", "            ", "im_lb", "=", "dict", "(", "im", "=", "img", ",", "lb", "=", "label", ")", "\n", "im_lb", "=", "self", ".", "trans_train", "(", "im_lb", ")", "\n", "img", ",", "label", "=", "im_lb", "[", "'im'", "]", ",", "im_lb", "[", "'lb'", "]", "\n", "", "img", "=", "self", ".", "to_tensor", "(", "img", ")", "\n", "label", "=", "np", ".", "array", "(", "label", ")", ".", "astype", "(", "np", ".", "int64", ")", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "return", "img", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.celeba_dataset.FaceMask.__len__": [[65, 67], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "imgs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.train.adjust_learning_rate": [[38, 47], ["float", "float"], "function", ["None"], ["", "if", "total_steps", "%", "opt", ".", "print_freq", "==", "0", ":", "\n", "                ", "losses", "=", "model", ".", "get_current_losses", "(", ")", "\n", "t", "=", "(", "time", ".", "time", "(", ")", "-", "iter_start_time", ")", "/", "opt", ".", "batch_size", "\n", "#visualizer.print_current_losses(epoch, epoch_iter, losses, t, t_data)", "\n", "#if opt.display_id > 0:", "\n", "#visualizer.plot_current_losses(epoch, float(epoch_iter) / dataset_size, opt, losses)", "\n", "\n", "", "if", "total_steps", "%", "opt", ".", "save_latest_freq", "==", "0", ":", "\n", "                ", "print", "(", "'saving the latest model (epoch %d, total_steps %d)'", "%", "\n", "(", "epoch", ",", "total_steps", ")", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.train.reduce_tensor": [[48, 53], ["tensor.clone", "torch.all_reduce"], "function", ["None"], ["#model.save_networks('latest')", "\n", "\n", "", "iter_data_time", "=", "time", ".", "time", "(", ")", "\n", "", "if", "epoch", "%", "opt", ".", "save_epoch_freq", "==", "0", ":", "\n", "            ", "print", "(", "'saving the model at the end of epoch %d, iters %d'", "%", "\n", "(", "epoch", ",", "total_steps", ")", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.train.parse_args": [[54, 63], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.train.parse_args"], ["model", ".", "save_networks", "(", "'latest'", ")", "\n", "model", ".", "save_networks", "(", "epoch", ")", "\n", "\n", "", "print", "(", "'End of epoch %d / %d \\t Time Taken: %d sec'", "%", "\n", "(", "epoch", ",", "opt", ".", "niter", "+", "opt", ".", "niter_decay", ",", "time", ".", "time", "(", ")", "-", "epoch_start_time", ")", ")", "\n", "model", ".", "print_loss", "(", ")", "\n", "model", ".", "update_learning_rate", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.train.train": [[66, 159], ["train.parse_args", "celeba_dataset.FaceMask", "torch.utils.data.DataLoader", "psp.PSP", "net.cuda.cuda", "loss.OhemCELoss().cuda", "loss.OhemCELoss().cuda", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "iter", "net.cuda.train", "range", "os.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "logger.info", "net.cuda.parameters", "train.adjust_learning_rate", "im.cuda.cuda", "torch.squeeze.cuda", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.optim.Adam.zero_grad", "net.cuda.", "OhemCELoss().cuda.", "OhemCELoss().cuda.", "loss.backward", "torch.optim.Adam.step", "loss_avg.append", "hasattr", "net.cuda.module.state_dict", "net.cuda.state_dict", "loss.OhemCELoss", "loss.OhemCELoss", "next", "im.cuda.size", "loss.item", "print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "iter", "next", "sum", "len", "hasattr", "net.cuda.module.state_dict", "net.cuda.state_dict", "im.cuda.size"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.train.parse_args", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.train.train", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.train.adjust_learning_rate", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.fcn.FCN.__init__": [[41, 46], ["parsing.base.BaseNet.__init__", "fcn.FCNHead", "fcn.FCNHead"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "nclass", ",", "backbone", ",", "aux", "=", "True", ",", "se_loss", "=", "False", ",", "lateral", "=", "False", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "FCN", ",", "self", ")", ".", "__init__", "(", "nclass", ",", "backbone", ",", "aux", ",", "se_loss", ",", "norm_layer", "=", "norm_layer", ",", "**", "kwargs", ")", "\n", "self", ".", "head", "=", "FCNHead", "(", "2048", ",", "nclass", ",", "norm_layer", "=", "norm_layer", ")", "\n", "if", "aux", ":", "\n", "            ", "self", ".", "auxlayer", "=", "FCNHead", "(", "1024", ",", "nclass", ",", "norm_layer", "=", "norm_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.fcn.FCN.forward": [[47, 59], ["fcn.FCN.base_forward", "fcn.FCN.head", "torch.nn.functional.upsample", "torch.nn.functional.upsample", "tuple", "torch.nn.functional.upsample.size", "torch.nn.functional.upsample.size", "fcn.FCN.auxlayer", "torch.nn.functional.upsample", "torch.nn.functional.upsample", "outputs.append"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.base.BaseNet.base_forward"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "imsize", "=", "x", ".", "size", "(", ")", "[", "2", ":", "]", "\n", "_", ",", "_", ",", "c3", ",", "c4", "=", "self", ".", "base_forward", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "head", "(", "c4", ")", "\n", "x", "=", "upsample", "(", "x", ",", "imsize", ",", "**", "self", ".", "_up_kwargs", ")", "\n", "outputs", "=", "[", "x", "]", "\n", "if", "self", ".", "aux", ":", "\n", "            ", "auxout", "=", "self", ".", "auxlayer", "(", "c3", ")", "\n", "auxout", "=", "upsample", "(", "auxout", ",", "imsize", ",", "**", "self", ".", "_up_kwargs", ")", "\n", "outputs", ".", "append", "(", "auxout", ")", "\n", "", "return", "tuple", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.fcn.FCNHead.__init__": [[62, 70], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.Dropout2d", "torch.Dropout2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "norm_layer", ")", ":", "\n", "        ", "super", "(", "FCNHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "inter_channels", "=", "in_channels", "//", "4", "\n", "self", ".", "conv5", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "in_channels", ",", "inter_channels", ",", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "norm_layer", "(", "inter_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout2d", "(", "0.1", ",", "False", ")", ",", "\n", "nn", ".", "Conv2d", "(", "inter_channels", ",", "out_channels", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.fcn.FCNHead.forward": [[71, 73], ["fcn.FCNHead.conv5"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "conv5", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.fcn.get_fcn": [[75, 109], ["fcn.FCN", "FCN.load_state_dict", "dataset.lower", "torch.load", "torch.load", "get_model_file", "dataset.lower"], "function", ["None"], ["", "", "def", "get_fcn", "(", "dataset", "=", "'pascal_voc'", ",", "backbone", "=", "'resnet50'", ",", "pretrained", "=", "False", ",", "\n", "root", "=", "'~/.encoding/models'", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"FCN model from the paper `\"Fully Convolutional Network for semantic segmentation\"\n    <https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf>`_\n    Parameters\n    ----------\n    dataset : str, default pascal_voc\n        The dataset that model pretrained on. (pascal_voc, ade20k)\n    pretrained : bool, default False\n        Whether to load the pretrained weights for model.\n    root : str, default '~/.encoding/models'\n        Location for keeping the model parameters.\n    Examples\n    --------\n    >>> model = get_fcn(dataset='pascal_voc', backbone='resnet50', pretrained=False)\n    >>> print(model)\n    \"\"\"", "\n", "acronyms", "=", "{", "\n", "'pascal_voc'", ":", "'voc'", ",", "\n", "'pascal_aug'", ":", "'voc'", ",", "\n", "'pcontext'", ":", "'pcontext'", ",", "\n", "'ade20k'", ":", "'ade'", ",", "\n", "'cityscapes'", ":", "'cityscapes'", ",", "\n", "}", "\n", "kwargs", "[", "'lateral'", "]", "=", "True", "if", "dataset", ".", "lower", "(", ")", "==", "'pcontext'", "else", "False", "\n", "# infer number of classes", "\n", "from", ".", ".", "datasets", "import", "datasets", ",", "VOCSegmentation", ",", "VOCAugSegmentation", ",", "ADE20KSegmentation", ",", "CityscapesSegmentation", ",", "ContextSegmentation", "\n", "model", "=", "FCN", "(", "datasets", "[", "dataset", ".", "lower", "(", ")", "]", ".", "NUM_CLASS", ",", "backbone", "=", "backbone", ",", "root", "=", "root", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "from", ".", "model_store", "import", "get_model_file", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\n", "get_model_file", "(", "'fcn_%s_%s'", "%", "(", "backbone", ",", "acronyms", "[", "dataset", "]", ")", ",", "root", "=", "root", ")", ")", ",", "\n", "strict", "=", "False", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.fcn.get_fcn_resnet50_pcontext": [[110, 128], ["fcn.get_fcn"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.fcn.get_fcn"], ["", "def", "get_fcn_resnet50_pcontext", "(", "pretrained", "=", "False", ",", "root", "=", "'~/.encoding/models'", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"EncNet-PSP model from the paper `\"Context Encoding for Semantic Segmentation\"\n    <https://arxiv.org/pdf/1803.08904.pdf>`_\n\n    Parameters\n    ----------\n    pretrained : bool, default False\n        Whether to load the pretrained weights for model.\n    root : str, default '~/.encoding/models'\n        Location for keeping the model parameters.\n\n\n    Examples\n    --------\n    >>> model = get_fcn_resnet50_pcontext(pretrained=True)\n    >>> print(model)\n    \"\"\"", "\n", "return", "get_fcn", "(", "'pcontext'", ",", "'resnet50'", ",", "pretrained", ",", "root", "=", "root", ",", "aux", "=", "False", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.fcn.get_fcn_resnet50_ade": [[129, 147], ["fcn.get_fcn"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.fcn.get_fcn"], ["", "def", "get_fcn_resnet50_ade", "(", "pretrained", "=", "False", ",", "root", "=", "'~/.encoding/models'", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"EncNet-PSP model from the paper `\"Context Encoding for Semantic Segmentation\"\n    <https://arxiv.org/pdf/1803.08904.pdf>`_\n\n    Parameters\n    ----------\n    pretrained : bool, default False\n        Whether to load the pretrained weights for model.\n    root : str, default '~/.encoding/models'\n        Location for keeping the model parameters.\n\n\n    Examples\n    --------\n    >>> model = get_fcn_resnet50_ade(pretrained=True)\n    >>> print(model)\n    \"\"\"", "\n", "return", "get_fcn", "(", "'ade20k'", ",", "'resnet50'", ",", "pretrained", ",", "root", "=", "root", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.loss.OhemCELoss.__init__": [[13, 19], ["torch.Module.__init__", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.log().cuda", "torch.log().cuda", "torch.log().cuda", "torch.log().cuda", "torch.log().cuda", "torch.log().cuda", "torch.log().cuda", "torch.log().cuda", "torch.log().cuda", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "thresh", ",", "n_min", ",", "ignore_lb", "=", "255", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "OhemCELoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "thresh", "=", "-", "torch", ".", "log", "(", "torch", ".", "tensor", "(", "thresh", ",", "dtype", "=", "torch", ".", "float", ")", ")", ".", "cuda", "(", ")", "\n", "self", ".", "n_min", "=", "n_min", "\n", "self", ".", "ignore_lb", "=", "ignore_lb", "\n", "self", ".", "criteria", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "ignore_lb", ",", "reduction", "=", "'none'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.loss.OhemCELoss.forward": [[20, 29], ["logits.size", "loss.OhemCELoss.OhemCELoss.criteria().view", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "loss.OhemCELoss.OhemCELoss.criteria"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "logits", ",", "labels", ")", ":", "\n", "        ", "N", ",", "C", ",", "H", ",", "W", "=", "logits", ".", "size", "(", ")", "\n", "loss", "=", "self", ".", "criteria", "(", "logits", ",", "labels", ")", ".", "view", "(", "-", "1", ")", "\n", "loss", ",", "_", "=", "torch", ".", "sort", "(", "loss", ",", "descending", "=", "True", ")", "\n", "if", "loss", "[", "self", ".", "n_min", "]", ">", "self", ".", "thresh", ":", "\n", "            ", "loss", "=", "loss", "[", "loss", ">", "self", ".", "thresh", "]", "\n", "", "else", ":", "\n", "            ", "loss", "=", "loss", "[", ":", "self", ".", "n_min", "]", "\n", "", "return", "torch", ".", "mean", "(", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.loss.SoftmaxFocalLoss.__init__": [[32, 36], ["torch.Module.__init__", "torch.NLLLoss", "torch.NLLLoss", "torch.NLLLoss"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "gamma", ",", "ignore_lb", "=", "255", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SoftmaxFocalLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "nll", "=", "nn", ".", "NLLLoss", "(", "ignore_index", "=", "ignore_lb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.loss.SoftmaxFocalLoss.forward": [[37, 44], ["torch.softmax", "torch.softmax", "torch.softmax", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "loss.SoftmaxFocalLoss.SoftmaxFocalLoss.nll"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "logits", ",", "labels", ")", ":", "\n", "        ", "scores", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "factor", "=", "torch", ".", "pow", "(", "1.", "-", "scores", ",", "self", ".", "gamma", ")", "\n", "log_score", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "log_score", "=", "factor", "*", "log_score", "\n", "loss", "=", "self", ".", "nll", "(", "log_score", ",", "labels", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.BasicBlock.__init__": [[29, 41], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "downsample", "=", "None", ",", "previous_dilation", "=", "1", ",", "\n", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "dilation", ",", "dilation", "=", "dilation", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "previous_dilation", ",", "dilation", "=", "previous_dilation", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.BasicBlock.forward": [[42, 59], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.bn1", "resnet.BasicBlock.relu", "resnet.BasicBlock.conv2", "resnet.BasicBlock.bn2", "resnet.BasicBlock.relu", "resnet.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.Bottleneck.__init__": [[66, 82], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "\n", "downsample", "=", "None", ",", "previous_dilation", "=", "1", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "\n", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "dilation", ",", "dilation", "=", "dilation", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "\n", "planes", ",", "planes", "*", "4", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "norm_layer", "(", "planes", "*", "4", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.Bottleneck._sum_each": [[83, 89], ["range", "len", "len", "len", "z.append"], "methods", ["None"], ["", "def", "_sum_each", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "assert", "(", "len", "(", "x", ")", "==", "len", "(", "y", ")", ")", "\n", "z", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "x", ")", ")", ":", "\n", "            ", "z", ".", "append", "(", "x", "[", "i", "]", "+", "y", "[", "i", "]", ")", "\n", "", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.Bottleneck.forward": [[90, 111], ["resnet.Bottleneck.conv1", "resnet.Bottleneck.bn1", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv2", "resnet.Bottleneck.bn2", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv3", "resnet.Bottleneck.bn3", "resnet.Bottleneck.relu", "resnet.Bottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.ResNet.__init__": [[138, 180], ["torch.Module.__init__", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Linear", "torch.Linear", "torch.Linear", "resnet.ResNet.modules", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "isinstance", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.ResNet._make_layer"], ["def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "num_classes", "=", "1000", ",", "dilated", "=", "True", ",", "deep_base", "=", "True", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "128", "if", "deep_base", "else", "64", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "deep_base", ":", "\n", "            ", "self", ".", "conv1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "", "self", ".", "bn1", "=", "norm_layer", "(", "self", ".", "inplanes", ",", "affine", "=", "True", ")", "\n", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ",", "norm_layer", "=", "norm_layer", ")", "\n", "if", "dilated", ":", "\n", "            ", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "1", ",", "\n", "dilation", "=", "2", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "stride", "=", "1", ",", "\n", "dilation", "=", "4", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ",", "\n", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ",", "\n", "norm_layer", "=", "norm_layer", ")", "\n", "", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "7", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "norm_layer", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.ResNet._make_layer": [[181, 206], ["range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.append", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "block", "layers.append", "RuntimeError", "block", "block"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "norm_layer", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "if", "dilation", "==", "1", "or", "dilation", "==", "2", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "dilation", "=", "1", ",", "\n", "downsample", "=", "downsample", ",", "previous_dilation", "=", "dilation", ",", "norm_layer", "=", "norm_layer", ")", ")", "\n", "", "elif", "dilation", "==", "4", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "dilation", "=", "2", ",", "\n", "downsample", "=", "downsample", ",", "previous_dilation", "=", "dilation", ",", "norm_layer", "=", "norm_layer", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"=> unknown dilation size: {}\"", ".", "format", "(", "dilation", ")", ")", "\n", "\n", "", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "dilation", "=", "dilation", ",", "previous_dilation", "=", "dilation", ",", "\n", "norm_layer", "=", "norm_layer", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.ResNet.forward": [[207, 223], ["resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.relu", "resnet.ResNet.maxpool", "resnet.ResNet.layer1", "resnet.ResNet.layer2", "resnet.ResNet.layer3", "resnet.ResNet.layer4", "resnet.ResNet.avgpool", "resnet.ResNet.view", "resnet.ResNet.fc", "resnet.ResNet.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.conv3x3": [[19, 23], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"3x3 convolution with padding\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.resnet18": [[225, 235], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "", "def", "resnet18", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet18'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.resnet34": [[237, 247], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet34", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-34 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet34'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.resnet50": [[249, 261], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load", "torch.load", "torch.load", "get_model_file"], "function", ["None"], ["", "def", "resnet50", "(", "pretrained", "=", "False", ",", "root", "=", "'~/.encoding/models'", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "from", ".", ".", "models", ".", "model_store", "import", "get_model_file", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\n", "get_model_file", "(", "'resnet50'", ",", "root", "=", "root", ")", ")", ",", "strict", "=", "False", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.resnet101": [[263, 275], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load", "torch.load", "torch.load", "get_model_file"], "function", ["None"], ["", "def", "resnet101", "(", "pretrained", "=", "False", ",", "root", "=", "'~/.encoding/models'", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "from", ".", ".", "models", ".", "model_store", "import", "get_model_file", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\n", "get_model_file", "(", "'resnet101'", ",", "root", "=", "root", ")", ")", ",", "strict", "=", "False", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.resnet101coco": [[277, 290], ["resnet.ResNet", "os.path.expanduser", "ResNet.load_state_dict", "torch.load", "torch.load", "torch.load", "os.path.join"], "function", ["None"], ["", "def", "resnet101coco", "(", "pretrained", "=", "False", ",", "root", "=", "'~/.encoding/models'", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "from", ".", ".", "models", ".", "model_store", "import", "get_model_file", "\n", "root", "=", "os", ".", "path", ".", "expanduser", "(", "root", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root", ",", "'MS_DeepLab_resnet_pretrained_COCO_init.pth'", ")", ")", ",", "strict", "=", "False", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.resnet.resnet152": [[292, 302], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet152", "(", "pretrained", "=", "False", ",", "root", "=", "'~/.encoding/models'", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-152 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet152'", "]", ")", ")", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.transform.RandomCrop.__init__": [[11, 13], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.transform.RandomCrop.__call__": [[14, 32], ["dict", "dict", "im.resize.resize.resize", "lb.resize.resize.resize", "int", "int", "int", "int", "random.random", "random.random", "int", "int", "im.resize.resize.crop", "lb.resize.resize.crop", "float", "float"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "im_lb", ")", ":", "\n", "        ", "im", "=", "im_lb", "[", "'im'", "]", "\n", "lb", "=", "im_lb", "[", "'lb'", "]", "\n", "assert", "im", ".", "size", "==", "lb", ".", "size", "\n", "W", ",", "H", "=", "self", ".", "size", "\n", "w", ",", "h", "=", "im", ".", "size", "\n", "\n", "if", "(", "W", ",", "H", ")", "==", "(", "w", ",", "h", ")", ":", "return", "dict", "(", "im", "=", "im", ",", "lb", "=", "lb", ")", "\n", "if", "w", "<", "W", "or", "h", "<", "H", ":", "\n", "            ", "scale", "=", "float", "(", "W", ")", "/", "w", "if", "w", "<", "h", "else", "float", "(", "H", ")", "/", "h", "\n", "w", ",", "h", "=", "int", "(", "scale", "*", "w", "+", "1", ")", ",", "int", "(", "scale", "*", "h", "+", "1", ")", "\n", "im", "=", "im", ".", "resize", "(", "(", "w", ",", "h", ")", ",", "Image", ".", "BILINEAR", ")", "\n", "lb", "=", "lb", ".", "resize", "(", "(", "w", ",", "h", ")", ",", "Image", ".", "NEAREST", ")", "\n", "", "sw", ",", "sh", "=", "random", ".", "random", "(", ")", "*", "(", "w", "-", "W", ")", ",", "random", ".", "random", "(", ")", "*", "(", "h", "-", "H", ")", "\n", "crop", "=", "int", "(", "sw", ")", ",", "int", "(", "sh", ")", ",", "int", "(", "sw", ")", "+", "W", ",", "int", "(", "sh", ")", "+", "H", "\n", "return", "dict", "(", "\n", "im", "=", "im", ".", "crop", "(", "crop", ")", ",", "\n", "lb", "=", "lb", ".", "crop", "(", "crop", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.transform.HorizontalFlip.__init__": [[36, 38], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "p", "=", "0.5", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "p", "=", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.transform.HorizontalFlip.__call__": [[39, 55], ["random.random", "numpy.array", "PIL.Image.fromarray.copy", "PIL.Image.fromarray", "dict", "im.transpose", "PIL.Image.fromarray.transpose"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "im_lb", ")", ":", "\n", "        ", "if", "random", ".", "random", "(", ")", ">", "self", ".", "p", ":", "\n", "            ", "return", "im_lb", "\n", "", "else", ":", "\n", "            ", "im", "=", "im_lb", "[", "'im'", "]", "\n", "lb", "=", "im_lb", "[", "'lb'", "]", "\n", "\n", "flip_lb", "=", "np", ".", "array", "(", "lb", ")", "\n", "flip_lb_tmp", "=", "flip_lb", ".", "copy", "(", ")", "\n", "flip_lb", "[", "flip_lb_tmp", "==", "2", "]", "=", "3", "\n", "flip_lb", "[", "flip_lb_tmp", "==", "3", "]", "=", "2", "\n", "flip_lb", "[", "flip_lb_tmp", "==", "4", "]", "=", "5", "\n", "flip_lb", "[", "flip_lb_tmp", "==", "5", "]", "=", "4", "\n", "flip_lb", "=", "Image", ".", "fromarray", "(", "flip_lb", ")", "\n", "return", "dict", "(", "im", "=", "im", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", ",", "\n", "lb", "=", "flip_lb", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.transform.RandomScale.__init__": [[59, 61], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "scales", "=", "(", "1", ",", ")", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "scales", "=", "scales", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.transform.RandomScale.__call__": [[62, 70], ["random.choice", "dict", "int", "int", "im.resize", "lb.resize"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "im_lb", ")", ":", "\n", "        ", "im", "=", "im_lb", "[", "'im'", "]", "\n", "lb", "=", "im_lb", "[", "'lb'", "]", "\n", "W", ",", "H", "=", "im", ".", "size", "\n", "scale", "=", "random", ".", "choice", "(", "self", ".", "scales", ")", "\n", "w", ",", "h", "=", "int", "(", "W", "*", "scale", ")", ",", "int", "(", "H", "*", "scale", ")", "\n", "return", "dict", "(", "im", "=", "im", ".", "resize", "(", "(", "w", ",", "h", ")", ",", "Image", ".", "BILINEAR", ")", ",", "\n", "lb", "=", "lb", ".", "resize", "(", "(", "w", ",", "h", ")", ",", "Image", ".", "NEAREST", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.transform.ColorJitter.__init__": [[74, 81], ["max", "max", "max"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "brightness", "=", "None", ",", "contrast", "=", "None", ",", "saturation", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "brightness", "is", "None", "and", "brightness", ">", "0", ":", "\n", "            ", "self", ".", "brightness", "=", "[", "max", "(", "1", "-", "brightness", ",", "0", ")", ",", "1", "+", "brightness", "]", "\n", "", "if", "not", "contrast", "is", "None", "and", "contrast", ">", "0", ":", "\n", "            ", "self", ".", "contrast", "=", "[", "max", "(", "1", "-", "contrast", ",", "0", ")", ",", "1", "+", "contrast", "]", "\n", "", "if", "not", "saturation", "is", "None", "and", "saturation", ">", "0", ":", "\n", "            ", "self", ".", "saturation", "=", "[", "max", "(", "1", "-", "saturation", ",", "0", ")", ",", "1", "+", "saturation", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.transform.ColorJitter.__call__": [[82, 93], ["random.uniform", "random.uniform", "random.uniform", "PIL.Brightness().enhance", "PIL.Contrast().enhance", "PIL.Color().enhance", "dict", "PIL.Brightness", "PIL.Contrast", "PIL.Color"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "im_lb", ")", ":", "\n", "        ", "im", "=", "im_lb", "[", "'im'", "]", "\n", "lb", "=", "im_lb", "[", "'lb'", "]", "\n", "r_brightness", "=", "random", ".", "uniform", "(", "self", ".", "brightness", "[", "0", "]", ",", "self", ".", "brightness", "[", "1", "]", ")", "\n", "r_contrast", "=", "random", ".", "uniform", "(", "self", ".", "contrast", "[", "0", "]", ",", "self", ".", "contrast", "[", "1", "]", ")", "\n", "r_saturation", "=", "random", ".", "uniform", "(", "self", ".", "saturation", "[", "0", "]", ",", "self", ".", "saturation", "[", "1", "]", ")", "\n", "im", "=", "ImageEnhance", ".", "Brightness", "(", "im", ")", ".", "enhance", "(", "r_brightness", ")", "\n", "im", "=", "ImageEnhance", ".", "Contrast", "(", "im", ")", ".", "enhance", "(", "r_contrast", ")", "\n", "im", "=", "ImageEnhance", ".", "Color", "(", "im", ")", ".", "enhance", "(", "r_saturation", ")", "\n", "return", "dict", "(", "im", "=", "im", ",", "\n", "lb", "=", "lb", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.transform.MultiScale.__init__": [[97, 99], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "scales", ")", ":", "\n", "        ", "self", ".", "scales", "=", "scales", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.transform.MultiScale.__call__": [[100, 106], ["imgs.append", "int", "int", "img.resize"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "W", ",", "H", "=", "img", ".", "size", "\n", "sizes", "=", "[", "(", "int", "(", "W", "*", "ratio", ")", ",", "int", "(", "H", "*", "ratio", ")", ")", "for", "ratio", "in", "self", ".", "scales", "]", "\n", "imgs", "=", "[", "]", "\n", "[", "imgs", ".", "append", "(", "img", ".", "resize", "(", "size", ",", "Image", ".", "BILINEAR", ")", ")", "for", "size", "in", "sizes", "]", "\n", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.transform.Compose.__init__": [[109, 111], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "do_list", ")", ":", "\n", "        ", "self", ".", "do_list", "=", "do_list", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.transform.Compose.__call__": [[112, 116], ["comp"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "im_lb", ")", ":", "\n", "        ", "for", "comp", "in", "self", ".", "do_list", ":", "\n", "            ", "im_lb", "=", "comp", "(", "im_lb", ")", "\n", "", "return", "im_lb", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.scripts.test_before_push.run": [[7, 12], ["print", "os.system", "exit"], "function", ["None"], ["def", "run", "(", "command", ")", ":", "\n", "    ", "print", "(", "command", ")", "\n", "exit_status", "=", "os", ".", "system", "(", "command", ")", "\n", "if", "exit_status", ">", "0", ":", "\n", "        ", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.__init__": [[7, 21], ["os.path.join", "dominate.document", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "meta", "str"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "web_dir", ",", "title", ",", "reflesh", "=", "0", ")", ":", "\n", "        ", "self", ".", "title", "=", "title", "\n", "self", ".", "web_dir", "=", "web_dir", "\n", "self", ".", "img_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "web_dir", ",", "'images'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "web_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "web_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "img_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "img_dir", ")", "\n", "# print(self.img_dir)", "\n", "\n", "", "self", ".", "doc", "=", "dominate", ".", "document", "(", "title", "=", "title", ")", "\n", "if", "reflesh", ">", "0", ":", "\n", "            ", "with", "self", ".", "doc", ".", "head", ":", "\n", "                ", "meta", "(", "http_equiv", "=", "\"reflesh\"", ",", "content", "=", "str", "(", "reflesh", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.get_image_dir": [[22, 24], ["None"], "methods", ["None"], ["", "", "", "def", "get_image_dir", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "img_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.add_header": [[25, 28], ["h3"], "methods", ["None"], ["", "def", "add_header", "(", "self", ",", "str", ")", ":", "\n", "        ", "with", "self", ".", "doc", ":", "\n", "            ", "h3", "(", "str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.add_table": [[29, 32], ["table", "html.HTML.doc.add"], "methods", ["None"], ["", "", "def", "add_table", "(", "self", ",", "border", "=", "1", ")", ":", "\n", "        ", "self", ".", "t", "=", "table", "(", "border", "=", "border", ",", "style", "=", "\"table-layout: fixed;\"", ")", "\n", "self", ".", "doc", ".", "add", "(", "self", ".", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.add_images": [[33, 44], ["html.HTML.add_table", "tr", "zip", "td", "p", "br", "p", "a", "img", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.add_table"], ["", "def", "add_images", "(", "self", ",", "ims", ",", "txts", ",", "links", ",", "width", "=", "400", ")", ":", "\n", "        ", "self", ".", "add_table", "(", ")", "\n", "with", "self", ".", "t", ":", "\n", "            ", "with", "tr", "(", ")", ":", "\n", "                ", "for", "im", ",", "txt", ",", "link", "in", "zip", "(", "ims", ",", "txts", ",", "links", ")", ":", "\n", "                    ", "with", "td", "(", "style", "=", "\"word-wrap: break-word;\"", ",", "halign", "=", "\"center\"", ",", "valign", "=", "\"top\"", ")", ":", "\n", "                        ", "with", "p", "(", ")", ":", "\n", "                            ", "with", "a", "(", "href", "=", "os", ".", "path", ".", "join", "(", "'images'", ",", "link", ")", ")", ":", "\n", "                                ", "img", "(", "style", "=", "\"width:%dpx\"", "%", "width", ",", "src", "=", "os", ".", "path", ".", "join", "(", "'images'", ",", "im", ")", ")", "\n", "", "br", "(", ")", "\n", "p", "(", "txt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save": [[45, 50], ["open", "open.write", "open.close", "html.HTML.doc.render"], "methods", ["None"], ["", "", "", "", "", "", "def", "save", "(", "self", ")", ":", "\n", "        ", "html_file", "=", "'%s/index.html'", "%", "self", ".", "web_dir", "\n", "f", "=", "open", "(", "html_file", ",", "'wt'", ")", "\n", "f", ".", "write", "(", "self", ".", "doc", ".", "render", "(", ")", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.image_pool.ImagePool.__init__": [[6, 11], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "pool_size", ")", ":", "\n", "        ", "self", ".", "pool_size", "=", "pool_size", "\n", "if", "self", ".", "pool_size", ">", "0", ":", "\n", "            ", "self", ".", "num_imgs", "=", "0", "\n", "self", ".", "images", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.image_pool.ImagePool.query": [[12, 33], ["torch.cat", "torch.unsqueeze", "image_pool.ImagePool.images.append", "torch.cat.append", "random.uniform", "random.randint", "image_pool.ImagePool.images[].clone", "torch.cat.append", "torch.cat.append"], "methods", ["None"], ["", "", "def", "query", "(", "self", ",", "images", ")", ":", "\n", "        ", "if", "self", ".", "pool_size", "==", "0", ":", "\n", "            ", "return", "images", "\n", "", "return_images", "=", "[", "]", "\n", "for", "image", "in", "images", ":", "\n", "            ", "image", "=", "torch", ".", "unsqueeze", "(", "image", ".", "data", ",", "0", ")", "\n", "if", "self", ".", "num_imgs", "<", "self", ".", "pool_size", ":", "\n", "                ", "self", ".", "num_imgs", "=", "self", ".", "num_imgs", "+", "1", "\n", "self", ".", "images", ".", "append", "(", "image", ")", "\n", "return_images", ".", "append", "(", "image", ")", "\n", "", "else", ":", "\n", "                ", "p", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "p", ">", "0.5", ":", "\n", "                    ", "random_id", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "pool_size", "-", "1", ")", "# randint is inclusive", "\n", "tmp", "=", "self", ".", "images", "[", "random_id", "]", ".", "clone", "(", ")", "\n", "self", ".", "images", "[", "random_id", "]", "=", "image", "\n", "return_images", ".", "append", "(", "tmp", ")", "\n", "", "else", ":", "\n", "                    ", "return_images", ".", "append", "(", "image", ")", "\n", "", "", "", "return_images", "=", "torch", ".", "cat", "(", "return_images", ",", "0", ")", "\n", "return", "return_images", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.visualizer.Visualizer.__init__": [[43, 64], ["os.path.join", "visdom.Visdom", "os.path.join", "os.path.join", "print", "util.mkdirs", "open", "time.strftime", "log_file.write"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.mkdirs"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "display_id", "=", "opt", ".", "display_id", "\n", "self", ".", "use_html", "=", "opt", ".", "isTrain", "and", "not", "opt", ".", "no_html", "\n", "self", ".", "win_size", "=", "opt", ".", "display_winsize", "\n", "self", ".", "name", "=", "opt", ".", "name", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "saved", "=", "False", "\n", "if", "self", ".", "display_id", ">", "0", ":", "\n", "            ", "import", "visdom", "\n", "self", ".", "ncols", "=", "opt", ".", "display_ncols", "\n", "self", ".", "vis", "=", "visdom", ".", "Visdom", "(", "server", "=", "opt", ".", "display_server", ",", "port", "=", "opt", ".", "display_port", ",", "env", "=", "opt", ".", "display_env", ",", "raise_exceptions", "=", "True", ")", "\n", "\n", "", "if", "self", ".", "use_html", ":", "\n", "            ", "self", ".", "web_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ",", "'web'", ")", "\n", "self", ".", "img_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "web_dir", ",", "'images'", ")", "\n", "print", "(", "'create web directory %s...'", "%", "self", ".", "web_dir", ")", "\n", "util", ".", "mkdirs", "(", "[", "self", ".", "web_dir", ",", "self", ".", "img_dir", "]", ")", "\n", "", "self", ".", "log_name", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ",", "'loss_log.txt'", ")", "\n", "with", "open", "(", "self", ".", "log_name", ",", "\"a\"", ")", "as", "log_file", ":", "\n", "            ", "now", "=", "time", ".", "strftime", "(", "\"%c\"", ")", "\n", "log_file", ".", "write", "(", "'================ Training Loss (%s) ================\\n'", "%", "now", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.visualizer.Visualizer.reset": [[65, 67], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "saved", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.visualizer.Visualizer.throw_visdom_connection_error": [[68, 71], ["print", "exit"], "methods", ["None"], ["", "def", "throw_visdom_connection_error", "(", "self", ")", ":", "\n", "        ", "print", "(", "'\\n\\nCould not connect to Visdom server (https://github.com/facebookresearch/visdom) for displaying training progress.\\nYou can suppress connection to Visdom using the option --display_id -1. To install visdom, run \\n$ pip install visdom\\n, and start the server by \\n$ python -m visdom.server.\\n\\n'", ")", "\n", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.visualizer.Visualizer.display_current_results": [[73, 141], ["visuals.items", "html.HTML", "range", "html.HTML.save", "min", "visuals.items", "visuals.items", "util.tensor2im", "os.path.join", "util.save_image", "html.HTML.add_header", "visuals.items", "html.HTML.add_images", "len", "util.tensor2im", "images.append", "numpy.ones_like", "images.append", "visualizer.Visualizer.vis.images", "visualizer.Visualizer.vis.text", "util.tensor2im", "visualizer.Visualizer.vis.image", "util.tensor2im", "ims.append", "txts.append", "links.append", "next", "util.tensor2im.transpose", "util.tensor2im.transpose", "visualizer.Visualizer.throw_visdom_connection_error", "util.tensor2im.transpose", "iter", "dict", "dict", "dict", "visuals.values"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.tensor2im", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.save_image", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.add_header", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.add_images", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.tensor2im", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.tensor2im", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.tensor2im", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.visualizer.Visualizer.throw_visdom_connection_error"], ["", "def", "display_current_results", "(", "self", ",", "visuals", ",", "epoch", ",", "save_result", ")", ":", "\n", "        ", "if", "self", ".", "display_id", ">", "0", ":", "# show images in the browser", "\n", "            ", "ncols", "=", "self", ".", "ncols", "\n", "if", "ncols", ">", "0", ":", "\n", "                ", "ncols", "=", "min", "(", "ncols", ",", "len", "(", "visuals", ")", ")", "\n", "h", ",", "w", "=", "next", "(", "iter", "(", "visuals", ".", "values", "(", ")", ")", ")", ".", "shape", "[", ":", "2", "]", "\n", "table_css", "=", "\"\"\"<style>\n                        table {border-collapse: separate; border-spacing:4px; white-space:nowrap; text-align:center}\n                        table td {width: %dpx; height: %dpx; padding: 4px; outline: 4px solid black}\n                        </style>\"\"\"", "%", "(", "w", ",", "h", ")", "\n", "title", "=", "self", ".", "name", "\n", "label_html", "=", "''", "\n", "label_html_row", "=", "''", "\n", "images", "=", "[", "]", "\n", "idx", "=", "0", "\n", "for", "label", ",", "image", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                    ", "image_numpy", "=", "util", ".", "tensor2im", "(", "image", ")", "\n", "label_html_row", "+=", "'<td>%s</td>'", "%", "label", "\n", "images", ".", "append", "(", "image_numpy", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ")", "\n", "idx", "+=", "1", "\n", "if", "idx", "%", "ncols", "==", "0", ":", "\n", "                        ", "label_html", "+=", "'<tr>%s</tr>'", "%", "label_html_row", "\n", "label_html_row", "=", "''", "\n", "", "", "white_image", "=", "np", ".", "ones_like", "(", "image_numpy", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ")", "*", "255", "\n", "while", "idx", "%", "ncols", "!=", "0", ":", "\n", "                    ", "images", ".", "append", "(", "white_image", ")", "\n", "label_html_row", "+=", "'<td></td>'", "\n", "idx", "+=", "1", "\n", "", "if", "label_html_row", "!=", "''", ":", "\n", "                    ", "label_html", "+=", "'<tr>%s</tr>'", "%", "label_html_row", "\n", "# pane col = image row", "\n", "", "try", ":", "\n", "                    ", "self", ".", "vis", ".", "images", "(", "images", ",", "nrow", "=", "ncols", ",", "win", "=", "self", ".", "display_id", "+", "1", ",", "\n", "padding", "=", "2", ",", "opts", "=", "dict", "(", "title", "=", "title", "+", "' images'", ")", ")", "\n", "label_html", "=", "'<table>%s</table>'", "%", "label_html", "\n", "self", ".", "vis", ".", "text", "(", "table_css", "+", "label_html", ",", "win", "=", "self", ".", "display_id", "+", "2", ",", "\n", "opts", "=", "dict", "(", "title", "=", "title", "+", "' labels'", ")", ")", "\n", "", "except", "VisdomExceptionBase", ":", "\n", "                    ", "self", ".", "throw_visdom_connection_error", "(", ")", "\n", "\n", "", "", "else", ":", "\n", "                ", "idx", "=", "1", "\n", "for", "label", ",", "image", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                    ", "image_numpy", "=", "util", ".", "tensor2im", "(", "image", ")", "\n", "self", ".", "vis", ".", "image", "(", "image_numpy", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ",", "opts", "=", "dict", "(", "title", "=", "label", ")", ",", "\n", "win", "=", "self", ".", "display_id", "+", "idx", ")", "\n", "idx", "+=", "1", "\n", "\n", "", "", "", "if", "self", ".", "use_html", "and", "(", "save_result", "or", "not", "self", ".", "saved", ")", ":", "# save images to a html file", "\n", "            ", "self", ".", "saved", "=", "True", "\n", "for", "label", ",", "image", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                ", "image_numpy", "=", "util", ".", "tensor2im", "(", "image", ")", "\n", "img_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "img_dir", ",", "'epoch%.3d_%s.png'", "%", "(", "epoch", ",", "label", ")", ")", "\n", "util", ".", "save_image", "(", "image_numpy", ",", "img_path", ")", "\n", "# update website", "\n", "", "webpage", "=", "html", ".", "HTML", "(", "self", ".", "web_dir", ",", "'Experiment name = %s'", "%", "self", ".", "name", ",", "reflesh", "=", "1", ")", "\n", "for", "n", "in", "range", "(", "epoch", ",", "0", ",", "-", "1", ")", ":", "\n", "                ", "webpage", ".", "add_header", "(", "'epoch [%d]'", "%", "n", ")", "\n", "ims", ",", "txts", ",", "links", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "label", ",", "image_numpy", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                    ", "image_numpy", "=", "util", ".", "tensor2im", "(", "image", ")", "\n", "img_path", "=", "'epoch%.3d_%s.png'", "%", "(", "n", ",", "label", ")", "\n", "ims", ".", "append", "(", "img_path", ")", "\n", "txts", ".", "append", "(", "label", ")", "\n", "links", ".", "append", "(", "img_path", ")", "\n", "", "webpage", ".", "add_images", "(", "ims", ",", "txts", ",", "links", ",", "width", "=", "self", ".", "win_size", ")", "\n", "", "webpage", ".", "save", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.visualizer.Visualizer.plot_current_losses": [[143, 160], ["visualizer.Visualizer.plot_data[].append", "visualizer.Visualizer.plot_data[].append", "hasattr", "visualizer.Visualizer.vis.line", "list", "visualizer.Visualizer.throw_visdom_connection_error", "losses.keys", "numpy.stack", "numpy.array", "len", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.visualizer.Visualizer.throw_visdom_connection_error"], ["", "", "def", "plot_current_losses", "(", "self", ",", "epoch", ",", "counter_ratio", ",", "opt", ",", "losses", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'plot_data'", ")", ":", "\n", "            ", "self", ".", "plot_data", "=", "{", "'X'", ":", "[", "]", ",", "'Y'", ":", "[", "]", ",", "'legend'", ":", "list", "(", "losses", ".", "keys", "(", ")", ")", "}", "\n", "", "self", ".", "plot_data", "[", "'X'", "]", ".", "append", "(", "epoch", "+", "counter_ratio", ")", "\n", "self", ".", "plot_data", "[", "'Y'", "]", ".", "append", "(", "[", "losses", "[", "k", "]", "for", "k", "in", "self", ".", "plot_data", "[", "'legend'", "]", "]", ")", "\n", "try", ":", "\n", "            ", "self", ".", "vis", ".", "line", "(", "\n", "X", "=", "np", ".", "stack", "(", "[", "np", ".", "array", "(", "self", ".", "plot_data", "[", "'X'", "]", ")", "]", "*", "len", "(", "self", ".", "plot_data", "[", "'legend'", "]", ")", ",", "1", ")", ",", "\n", "Y", "=", "np", ".", "array", "(", "self", ".", "plot_data", "[", "'Y'", "]", ")", ",", "\n", "opts", "=", "{", "\n", "'title'", ":", "self", ".", "name", "+", "' loss over time'", ",", "\n", "'legend'", ":", "self", ".", "plot_data", "[", "'legend'", "]", ",", "\n", "'xlabel'", ":", "'epoch'", ",", "\n", "'ylabel'", ":", "'loss'", "}", ",", "\n", "win", "=", "self", ".", "display_id", ")", "\n", "", "except", "VisdomExceptionBase", ":", "\n", "            ", "self", ".", "throw_visdom_connection_error", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.visualizer.Visualizer.print_current_losses": [[162, 170], ["losses.items", "print", "open", "log_file.write"], "methods", ["None"], ["", "", "def", "print_current_losses", "(", "self", ",", "epoch", ",", "i", ",", "losses", ",", "t", ",", "t_data", ")", ":", "\n", "        ", "message", "=", "'(epoch: %d, iters: %d, time: %.3f, data: %.3f) '", "%", "(", "epoch", ",", "i", ",", "t", ",", "t_data", ")", "\n", "for", "k", ",", "v", "in", "losses", ".", "items", "(", ")", ":", "\n", "            ", "message", "+=", "'%s: %.3f '", "%", "(", "k", ",", "v", ")", "\n", "\n", "", "print", "(", "message", ")", "\n", "with", "open", "(", "self", ".", "log_name", ",", "\"a\"", ")", "as", "log_file", ":", "\n", "            ", "log_file", ".", "write", "(", "'%s\\n'", "%", "message", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.visualizer.save_images": [[17, 35], ["webpage.get_image_dir", "ntpath.basename", "webpage.add_header", "visuals.items", "os.path.splitext", "util.tensor2im", "os.path.join", "util.save_image", "scipy.misc.imresize", "scipy.misc.imresize", "int", "int"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.get_image_dir", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.add_header", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.tensor2im", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.save_image"], ["", "def", "save_images", "(", "webpage", ",", "visuals", ",", "image_path", ",", "aspect_ratio", "=", "1.0", ",", "width", "=", "256", ")", ":", "\n", "    ", "image_dir", "=", "webpage", ".", "get_image_dir", "(", ")", "\n", "short_path", "=", "ntpath", ".", "basename", "(", "image_path", "[", "0", "]", ")", "\n", "name", "=", "os", ".", "path", ".", "splitext", "(", "short_path", ")", "[", "0", "]", "\n", "\n", "webpage", ".", "add_header", "(", "name", ")", "\n", "ims", ",", "txts", ",", "links", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "label", ",", "im_data", "in", "visuals", ".", "items", "(", ")", ":", "\n", "        ", "im", "=", "util", ".", "tensor2im", "(", "im_data", ")", "\n", "image_name", "=", "'%s_%s.png'", "%", "(", "name", ",", "label", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "image_name", ")", "\n", "h", ",", "w", ",", "_", "=", "im", ".", "shape", "\n", "if", "aspect_ratio", ">", "1.0", ":", "\n", "            ", "im", "=", "imresize", "(", "im", ",", "(", "h", ",", "int", "(", "w", "*", "aspect_ratio", ")", ")", ",", "interp", "=", "'bicubic'", ")", "\n", "", "if", "aspect_ratio", "<", "1.0", ":", "\n", "            ", "im", "=", "imresize", "(", "im", ",", "(", "int", "(", "h", "/", "aspect_ratio", ")", ",", "w", ")", ",", "interp", "=", "'bicubic'", ")", "\n", "", "util", ".", "save_image", "(", "im", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.get_data.GetData.__init__": [[29, 36], ["url_dict.get", "technique.lower"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.get_data.GetData.get"], ["def", "__init__", "(", "self", ",", "technique", "=", "'cyclegan'", ",", "verbose", "=", "True", ")", ":", "\n", "        ", "url_dict", "=", "{", "\n", "'pix2pix'", ":", "'https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets'", ",", "\n", "'cyclegan'", ":", "'https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets'", "\n", "}", "\n", "self", ".", "url", "=", "url_dict", ".", "get", "(", "technique", ".", "lower", "(", ")", ")", "\n", "self", ".", "_verbose", "=", "verbose", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.get_data.GetData._print": [[37, 40], ["print"], "methods", ["None"], ["", "def", "_print", "(", "self", ",", "text", ")", ":", "\n", "        ", "if", "self", ".", "_verbose", ":", "\n", "            ", "print", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.get_data.GetData._get_options": [[41, 47], ["bs4.BeautifulSoup", "bs4.BeautifulSoup.find_all", "h.text.endswith"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_get_options", "(", "r", ")", ":", "\n", "        ", "soup", "=", "BeautifulSoup", "(", "r", ".", "text", ",", "'lxml'", ")", "\n", "options", "=", "[", "h", ".", "text", "for", "h", "in", "soup", ".", "find_all", "(", "'a'", ",", "href", "=", "True", ")", "\n", "if", "h", ".", "text", ".", "endswith", "(", "(", "'.zip'", ",", "'tar.gz'", ")", ")", "]", "\n", "return", "options", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.get_data.GetData._present_options": [[48, 57], ["requests.get", "get_data.GetData._get_options", "print", "enumerate", "input", "print", "int"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.get_data.GetData.get", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.get_data.GetData._get_options"], ["", "def", "_present_options", "(", "self", ")", ":", "\n", "        ", "r", "=", "requests", ".", "get", "(", "self", ".", "url", ")", "\n", "options", "=", "self", ".", "_get_options", "(", "r", ")", "\n", "print", "(", "'Options:\\n'", ")", "\n", "for", "i", ",", "o", "in", "enumerate", "(", "options", ")", ":", "\n", "            ", "print", "(", "\"{0}: {1}\"", ".", "format", "(", "i", ",", "o", ")", ")", "\n", "", "choice", "=", "input", "(", "\"\\nPlease enter the number of the \"", "\n", "\"dataset above you wish to download:\"", ")", "\n", "return", "options", "[", "int", "(", "choice", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.get_data.GetData._download_data": [[58, 80], ["os.path.basename", "os.path.join", "os.path.basename.endswith", "get_data.GetData._print", "zipfile.ZipFile.extractall", "zipfile.ZipFile.close", "os.remove", "os.path.isdir", "os.makedirs", "open", "requests.get", "f.write", "tarfile.open", "os.path.basename.endswith", "zipfile.ZipFile", "ValueError"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.get_data.GetData._print", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.SpectralNorm.remove", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.get_data.GetData.get"], ["", "def", "_download_data", "(", "self", ",", "dataset_url", ",", "save_path", ")", ":", "\n", "        ", "if", "not", "isdir", "(", "save_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_path", ")", "\n", "\n", "", "base", "=", "basename", "(", "dataset_url", ")", "\n", "temp_save_path", "=", "join", "(", "save_path", ",", "base", ")", "\n", "\n", "with", "open", "(", "temp_save_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "r", "=", "requests", ".", "get", "(", "dataset_url", ")", "\n", "f", ".", "write", "(", "r", ".", "content", ")", "\n", "\n", "", "if", "base", ".", "endswith", "(", "'.tar.gz'", ")", ":", "\n", "            ", "obj", "=", "tarfile", ".", "open", "(", "temp_save_path", ")", "\n", "", "elif", "base", ".", "endswith", "(", "'.zip'", ")", ":", "\n", "            ", "obj", "=", "ZipFile", "(", "temp_save_path", ",", "'r'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown File Type: {0}.\"", ".", "format", "(", "base", ")", ")", "\n", "\n", "", "self", ".", "_print", "(", "\"Unpacking Data...\"", ")", "\n", "obj", ".", "extractall", "(", "save_path", ")", "\n", "obj", ".", "close", "(", ")", "\n", "os", ".", "remove", "(", "temp_save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.get_data.GetData.get": [[81, 116], ["os.path.join", "os.path.isdir", "os.path.abspath", "get_data.GetData._present_options", "warnings.warn", "get_data.GetData._print", "get_data.GetData._download_data", "get_data.GetData.split"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.get_data.GetData._present_options", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.get_data.GetData._print", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.get_data.GetData._download_data"], ["", "def", "get", "(", "self", ",", "save_path", ",", "dataset", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Download a dataset.\n\n        Args:\n            save_path : str\n                A directory to save the data to.\n            dataset : str, optional\n                A specific dataset to download.\n                Note: this must include the file extension.\n                If None, options will be presented for you\n                to choose from.\n\n        Returns:\n            save_path_full : str\n                The absolute path to the downloaded data.\n\n        \"\"\"", "\n", "if", "dataset", "is", "None", ":", "\n", "            ", "selected_dataset", "=", "self", ".", "_present_options", "(", ")", "\n", "", "else", ":", "\n", "            ", "selected_dataset", "=", "dataset", "\n", "\n", "", "save_path_full", "=", "join", "(", "save_path", ",", "selected_dataset", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "\n", "\n", "if", "isdir", "(", "save_path_full", ")", ":", "\n", "            ", "warn", "(", "\"\\n'{0}' already exists. Voiding Download.\"", ".", "format", "(", "\n", "save_path_full", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_print", "(", "'Downloading Data...'", ")", "\n", "url", "=", "\"{0}/{1}\"", ".", "format", "(", "self", ".", "url", ",", "selected_dataset", ")", "\n", "self", ".", "_download_data", "(", "url", ",", "save_path", "=", "save_path", ")", "\n", "\n", "", "return", "abspath", "(", "save_path_full", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.tensor2im": [[10, 21], ["isinstance", "image_tensor[].cpu().float().numpy", "np.tile.astype", "torch.upsample", "numpy.tile", "image_tensor[].cpu().float", "numpy.transpose", "image_tensor[].cpu"], "function", ["None"], ["def", "tensor2im", "(", "input_image", ",", "imtype", "=", "np", ".", "uint8", ")", ":", "\n", "    ", "if", "isinstance", "(", "input_image", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "input_image", "=", "F", ".", "upsample", "(", "input_image", ",", "size", "=", "(", "256", ",", "256", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "image_tensor", "=", "input_image", ".", "data", "\n", "", "else", ":", "\n", "        ", "return", "input_image", "\n", "", "image_numpy", "=", "image_tensor", "[", "0", "]", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "\n", "if", "image_numpy", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "        ", "image_numpy", "=", "np", ".", "tile", "(", "image_numpy", ",", "(", "3", ",", "1", ",", "1", ")", ")", "\n", "", "image_numpy", "=", "(", "np", ".", "transpose", "(", "image_numpy", ",", "(", "1", ",", "2", ",", "0", ")", ")", "+", "1", ")", "/", "2.0", "*", "255.0", "\n", "return", "image_numpy", ".", "astype", "(", "imtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.diagnose_network": [[23, 34], ["net.parameters", "print", "print", "torch.mean", "torch.mean", "torch.abs", "torch.abs"], "function", ["None"], ["", "def", "diagnose_network", "(", "net", ",", "name", "=", "'network'", ")", ":", "\n", "    ", "mean", "=", "0.0", "\n", "count", "=", "0", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "        ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "            ", "mean", "+=", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "param", ".", "grad", ".", "data", ")", ")", "\n", "count", "+=", "1", "\n", "", "", "if", "count", ">", "0", ":", "\n", "        ", "mean", "=", "mean", "/", "count", "\n", "", "print", "(", "name", ")", "\n", "print", "(", "mean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.save_image": [[36, 39], ["PIL.Image.fromarray", "Image.fromarray.save"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save"], ["", "def", "save_image", "(", "image_numpy", ",", "image_path", ")", ":", "\n", "    ", "image_pil", "=", "Image", ".", "fromarray", "(", "image_numpy", ")", "\n", "image_pil", ".", "save", "(", "image_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.print_numpy": [[41, 49], ["x.flatten.astype", "print", "x.flatten.flatten", "print", "numpy.mean", "numpy.min", "numpy.max", "numpy.median", "numpy.std"], "function", ["None"], ["", "def", "print_numpy", "(", "x", ",", "val", "=", "True", ",", "shp", "=", "False", ")", ":", "\n", "    ", "x", "=", "x", ".", "astype", "(", "np", ".", "float64", ")", "\n", "if", "shp", ":", "\n", "        ", "print", "(", "'shape,'", ",", "x", ".", "shape", ")", "\n", "", "if", "val", ":", "\n", "        ", "x", "=", "x", ".", "flatten", "(", ")", "\n", "print", "(", "'mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f'", "%", "(", "\n", "np", ".", "mean", "(", "x", ")", ",", "np", ".", "min", "(", "x", ")", ",", "np", ".", "max", "(", "x", ")", ",", "np", ".", "median", "(", "x", ")", ",", "np", ".", "std", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.mkdirs": [[51, 57], ["isinstance", "util.mkdir", "isinstance", "util.mkdir"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.mkdir", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.mkdir"], ["", "", "def", "mkdirs", "(", "paths", ")", ":", "\n", "    ", "if", "isinstance", "(", "paths", ",", "list", ")", "and", "not", "isinstance", "(", "paths", ",", "str", ")", ":", "\n", "        ", "for", "path", "in", "paths", ":", "\n", "            ", "mkdir", "(", "path", ")", "\n", "", "", "else", ":", "\n", "        ", "mkdir", "(", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.mkdir": [[59, 62], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "def", "mkdir", "(", "path", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.adain.test_transform": [[16, 25], ["transform_list.append", "torchvision.transforms.Compose", "transform_list.append", "transform_list.append", "torchvision.transforms.ToTensor", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop"], "function", ["None"], ["def", "test_transform", "(", "size", ",", "crop", ")", ":", "\n", "    ", "transform_list", "=", "[", "]", "\n", "if", "size", "!=", "0", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Resize", "(", "size", ")", ")", "\n", "", "if", "crop", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "CenterCrop", "(", "size", ")", ")", "\n", "", "transform_list", ".", "append", "(", "transforms", ".", "ToTensor", "(", ")", ")", "\n", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "return", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.adain.style_transfer": [[27, 43], ["vgg", "vgg", "decoder", "vgg.size", "torch.FloatTensor().zero_().to", "torch.FloatTensor().zero_().to", "torch.FloatTensor().zero_().to", "AdaIn.function.adaptive_instance_normalization", "enumerate", "AdaIn.function.adaptive_instance_normalization", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function.adaptive_instance_normalization", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function.adaptive_instance_normalization"], ["", "def", "style_transfer", "(", "vgg", ",", "decoder", ",", "content", ",", "style", ",", "alpha", "=", "1.0", ",", "\n", "interpolation_weights", "=", "None", ")", ":", "\n", "    ", "assert", "(", "0.0", "<=", "alpha", "<=", "1.0", ")", "\n", "content_f", "=", "vgg", "(", "content", ")", "\n", "style_f", "=", "vgg", "(", "style", ")", "\n", "if", "interpolation_weights", ":", "\n", "        ", "_", ",", "C", ",", "H", ",", "W", "=", "content_f", ".", "size", "(", ")", "\n", "feat", "=", "torch", ".", "FloatTensor", "(", "1", ",", "C", ",", "H", ",", "W", ")", ".", "zero_", "(", ")", ".", "to", "(", "device", ")", "\n", "base_feat", "=", "adaptive_instance_normalization", "(", "content_f", ",", "style_f", ")", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "interpolation_weights", ")", ":", "\n", "            ", "feat", "=", "feat", "+", "w", "*", "base_feat", "[", "i", ":", "i", "+", "1", "]", "\n", "", "content_f", "=", "content_f", "[", "0", ":", "1", "]", "\n", "", "else", ":", "\n", "        ", "feat", "=", "adaptive_instance_normalization", "(", "content_f", ",", "style_f", ")", "\n", "", "feat", "=", "feat", "*", "alpha", "+", "content_f", "*", "(", "1", "-", "alpha", ")", "\n", "return", "decoder", "(", "feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.LambdaBase.__init__": [[13, 16], ["torch.Sequential.__init__"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "fn", ",", "*", "args", ")", ":", "\n", "        ", "super", "(", "LambdaBase", ",", "self", ")", ".", "__init__", "(", "*", "args", ")", "\n", "self", ".", "lambda_func", "=", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.LambdaBase.forward_prepare": [[17, 22], ["torch_to_pytorch.LambdaBase._modules.values", "output.append", "module"], "methods", ["None"], ["", "def", "forward_prepare", "(", "self", ",", "input", ")", ":", "\n", "        ", "output", "=", "[", "]", "\n", "for", "module", "in", "self", ".", "_modules", ".", "values", "(", ")", ":", "\n", "            ", "output", ".", "append", "(", "module", "(", "input", ")", ")", "\n", "", "return", "output", "if", "output", "else", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.Lambda.forward": [[25, 27], ["torch_to_pytorch.Lambda.lambda_func", "torch_to_pytorch.Lambda.forward_prepare"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.LambdaBase.forward_prepare"], ["    ", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "self", ".", "lambda_func", "(", "self", ".", "forward_prepare", "(", "input", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.LambdaMap.forward": [[30, 33], ["list", "map", "torch_to_pytorch.LambdaMap.forward_prepare"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.LambdaBase.forward_prepare"], ["    ", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# result is Variables list [Variable1, Variable2, ...]", "\n", "        ", "return", "list", "(", "map", "(", "self", ".", "lambda_func", ",", "self", ".", "forward_prepare", "(", "input", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.LambdaReduce.forward": [[36, 39], ["functools.reduce", "torch_to_pytorch.LambdaReduce.forward_prepare"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.LambdaBase.forward_prepare"], ["    ", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# result is a Variable", "\n", "        ", "return", "reduce", "(", "self", ".", "lambda_func", ",", "self", ".", "forward_prepare", "(", "input", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.copy_param": [[41, 46], ["hasattr", "hasattr", "n.weight.data.copy_", "n.bias.data.copy_", "n.running_mean.copy_", "n.running_var.copy_"], "function", ["None"], ["", "", "def", "copy_param", "(", "m", ",", "n", ")", ":", "\n", "    ", "if", "m", ".", "weight", "is", "not", "None", ":", "n", ".", "weight", ".", "data", ".", "copy_", "(", "m", ".", "weight", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "n", ".", "bias", ".", "data", ".", "copy_", "(", "m", ".", "bias", ")", "\n", "if", "hasattr", "(", "n", ",", "'running_mean'", ")", ":", "n", ".", "running_mean", ".", "copy_", "(", "m", ".", "running_mean", ")", "\n", "if", "hasattr", "(", "n", ",", "'running_var'", ")", ":", "n", ".", "running_var", ".", "copy_", "(", "m", ".", "running_var", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule": [[48, 51], ["seq.add_module", "str", "len"], "function", ["None"], ["", "def", "add_submodule", "(", "seq", ",", "*", "args", ")", ":", "\n", "    ", "for", "n", "in", "args", ":", "\n", "        ", "seq", ".", "add_module", "(", "str", "(", "len", "(", "seq", ".", "_modules", ")", ")", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.lua_recursive_model": [[53, 150], ["type", "m._typename.replace", "torch.Conv2d", "torch_to_pytorch.copy_param", "torch_to_pytorch.add_submodule", "hasattr", "torch.BatchNorm2d", "torch_to_pytorch.copy_param", "torch_to_pytorch.add_submodule", "m.running_mean.size", "torch.ReLU", "torch_to_pytorch.add_submodule", "torch.MaxPool2d", "torch_to_pytorch.add_submodule", "torch.AvgPool2d", "torch_to_pytorch.add_submodule", "torch.UpsamplingNearest2d", "torch_to_pytorch.add_submodule", "torch_to_pytorch.Lambda", "torch_to_pytorch.add_submodule", "torch_to_pytorch.Lambda", "torch.Linear", "torch_to_pytorch.copy_param", "torch.Sequential", "torch_to_pytorch.add_submodule", "x.view", "m.weight.size", "m.weight.size", "torch.Dropout", "torch_to_pytorch.add_submodule", "x.size", "torch.Softmax", "torch_to_pytorch.add_submodule", "x.view", "torch_to_pytorch.Lambda", "torch_to_pytorch.add_submodule", "len", "torch.ConvTranspose2d", "torch_to_pytorch.add_submodule", "x.size", "torch.ReplicationPad2d", "torch_to_pytorch.add_submodule", "torch.ReflectionPad2d", "torch_to_pytorch.add_submodule", "torch_to_pytorch.Lambda", "torch_to_pytorch.add_submodule", "torch_to_pytorch.Lambda", "torch_to_pytorch.add_submodule", "torch.legacy.nn.SpatialCrossMapLRN", "torch.legacy.nn.SpatialCrossMapLRN", "torch_to_pytorch.Lambda", "torch_to_pytorch.add_submodule", "x.narrow", "torch.Sequential", "torch_to_pytorch.lua_recursive_model", "torch_to_pytorch.add_submodule", "torch.legacy.nn.SpatialCrossMapLRN.forward", "torch_to_pytorch.LambdaMap", "torch_to_pytorch.lua_recursive_model", "torch_to_pytorch.add_submodule", "torch_to_pytorch.LambdaReduce", "torch_to_pytorch.add_submodule", "torch_to_pytorch.LambdaReduce", "torch_to_pytorch.lua_recursive_model", "torch_to_pytorch.add_submodule", "print", "print", "torch.cat", "torch.cat"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.copy_param", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.copy_param", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.copy_param", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.lua_recursive_model", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.pix2pix_model.Pix2PixModel.forward", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.lua_recursive_model", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.lua_recursive_model", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.add_submodule"], ["", "", "def", "lua_recursive_model", "(", "module", ",", "seq", ")", ":", "\n", "    ", "for", "m", "in", "module", ".", "modules", ":", "\n", "        ", "name", "=", "type", "(", "m", ")", ".", "__name__", "\n", "real", "=", "m", "\n", "if", "name", "==", "'TorchObject'", ":", "\n", "            ", "name", "=", "m", ".", "_typename", ".", "replace", "(", "'cudnn.'", ",", "''", ")", "\n", "m", "=", "m", ".", "_obj", "\n", "\n", "", "if", "name", "==", "'SpatialConvolution'", ":", "\n", "            ", "if", "not", "hasattr", "(", "m", ",", "'groups'", ")", ":", "m", ".", "groups", "=", "1", "\n", "n", "=", "nn", ".", "Conv2d", "(", "m", ".", "nInputPlane", ",", "m", ".", "nOutputPlane", ",", "(", "m", ".", "kW", ",", "m", ".", "kH", ")", ",", "\n", "(", "m", ".", "dW", ",", "m", ".", "dH", ")", ",", "(", "m", ".", "padW", ",", "m", ".", "padH", ")", ",", "1", ",", "m", ".", "groups", ",", "\n", "bias", "=", "(", "m", ".", "bias", "is", "not", "None", ")", ")", "\n", "copy_param", "(", "m", ",", "n", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'SpatialBatchNormalization'", ":", "\n", "            ", "n", "=", "nn", ".", "BatchNorm2d", "(", "m", ".", "running_mean", ".", "size", "(", "0", ")", ",", "m", ".", "eps", ",", "m", ".", "momentum", ",", "\n", "m", ".", "affine", ")", "\n", "copy_param", "(", "m", ",", "n", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'ReLU'", ":", "\n", "            ", "n", "=", "nn", ".", "ReLU", "(", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'SpatialMaxPooling'", ":", "\n", "            ", "n", "=", "nn", ".", "MaxPool2d", "(", "(", "m", ".", "kW", ",", "m", ".", "kH", ")", ",", "(", "m", ".", "dW", ",", "m", ".", "dH", ")", ",", "(", "m", ".", "padW", ",", "m", ".", "padH", ")", ",", "\n", "ceil_mode", "=", "m", ".", "ceil_mode", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'SpatialAveragePooling'", ":", "\n", "            ", "n", "=", "nn", ".", "AvgPool2d", "(", "(", "m", ".", "kW", ",", "m", ".", "kH", ")", ",", "(", "m", ".", "dW", ",", "m", ".", "dH", ")", ",", "(", "m", ".", "padW", ",", "m", ".", "padH", ")", ",", "\n", "ceil_mode", "=", "m", ".", "ceil_mode", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'SpatialUpSamplingNearest'", ":", "\n", "            ", "n", "=", "nn", ".", "UpsamplingNearest2d", "(", "scale_factor", "=", "m", ".", "scale_factor", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'View'", ":", "\n", "            ", "n", "=", "Lambda", "(", "lambda", "x", ":", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'Linear'", ":", "\n", "# Linear in pytorch only accept 2D input", "\n", "            ", "n1", "=", "Lambda", "(", "lambda", "x", ":", "x", ".", "view", "(", "1", ",", "-", "1", ")", "if", "1", "==", "len", "(", "x", ".", "size", "(", ")", ")", "else", "x", ")", "\n", "n2", "=", "nn", ".", "Linear", "(", "m", ".", "weight", ".", "size", "(", "1", ")", ",", "m", ".", "weight", ".", "size", "(", "0", ")", ",", "\n", "bias", "=", "(", "m", ".", "bias", "is", "not", "None", ")", ")", "\n", "copy_param", "(", "m", ",", "n2", ")", "\n", "n", "=", "nn", ".", "Sequential", "(", "n1", ",", "n2", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'Dropout'", ":", "\n", "            ", "m", ".", "inplace", "=", "False", "\n", "n", "=", "nn", ".", "Dropout", "(", "m", ".", "p", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'SoftMax'", ":", "\n", "            ", "n", "=", "nn", ".", "Softmax", "(", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'Identity'", ":", "\n", "            ", "n", "=", "Lambda", "(", "lambda", "x", ":", "x", ")", "# do nothing", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'SpatialFullConvolution'", ":", "\n", "            ", "n", "=", "nn", ".", "ConvTranspose2d", "(", "m", ".", "nInputPlane", ",", "m", ".", "nOutputPlane", ",", "(", "m", ".", "kW", ",", "m", ".", "kH", ")", ",", "\n", "(", "m", ".", "dW", ",", "m", ".", "dH", ")", ",", "(", "m", ".", "padW", ",", "m", ".", "padH", ")", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'SpatialReplicationPadding'", ":", "\n", "            ", "n", "=", "nn", ".", "ReplicationPad2d", "(", "(", "m", ".", "pad_l", ",", "m", ".", "pad_r", ",", "m", ".", "pad_t", ",", "m", ".", "pad_b", ")", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'SpatialReflectionPadding'", ":", "\n", "            ", "n", "=", "nn", ".", "ReflectionPad2d", "(", "(", "m", ".", "pad_l", ",", "m", ".", "pad_r", ",", "m", ".", "pad_t", ",", "m", ".", "pad_b", ")", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'Copy'", ":", "\n", "            ", "n", "=", "Lambda", "(", "lambda", "x", ":", "x", ")", "# do nothing", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'Narrow'", ":", "\n", "            ", "n", "=", "Lambda", "(", "\n", "lambda", "x", ",", "a", "=", "(", "m", ".", "dimension", ",", "m", ".", "index", ",", "m", ".", "length", ")", ":", "x", ".", "narrow", "(", "*", "a", ")", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'SpatialCrossMapLRN'", ":", "\n", "            ", "lrn", "=", "torch", ".", "legacy", ".", "nn", ".", "SpatialCrossMapLRN", "(", "m", ".", "size", ",", "m", ".", "alpha", ",", "m", ".", "beta", ",", "\n", "m", ".", "k", ")", "\n", "n", "=", "Lambda", "(", "lambda", "x", ",", "lrn", "=", "lrn", ":", "lrn", ".", "forward", "(", "x", ")", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'Sequential'", ":", "\n", "            ", "n", "=", "nn", ".", "Sequential", "(", ")", "\n", "lua_recursive_model", "(", "m", ",", "n", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'ConcatTable'", ":", "# output is list", "\n", "            ", "n", "=", "LambdaMap", "(", "lambda", "x", ":", "x", ")", "\n", "lua_recursive_model", "(", "m", ",", "n", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'CAddTable'", ":", "# input is list", "\n", "            ", "n", "=", "LambdaReduce", "(", "lambda", "x", ",", "y", ":", "x", "+", "y", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'Concat'", ":", "\n", "            ", "dim", "=", "m", ".", "dimension", "\n", "n", "=", "LambdaReduce", "(", "lambda", "x", ",", "y", ",", "dim", "=", "dim", ":", "torch", ".", "cat", "(", "(", "x", ",", "y", ")", ",", "dim", ")", ")", "\n", "lua_recursive_model", "(", "m", ",", "n", ")", "\n", "add_submodule", "(", "seq", ",", "n", ")", "\n", "", "elif", "name", "==", "'TorchObject'", ":", "\n", "            ", "print", "(", "'Not Implement'", ",", "name", ",", "real", ".", "_typename", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Not Implement'", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.lua_recursive_source": [[152, 240], ["map", "type", "m._typename.replace", "hasattr", "m.running_mean.size", "m.weight.size", "m.weight.size", "torch_to_pytorch.lua_recursive_source", "torch_to_pytorch.lua_recursive_source", "torch_to_pytorch.lua_recursive_source"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.lua_recursive_source", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.lua_recursive_source", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.lua_recursive_source"], ["", "", "", "def", "lua_recursive_source", "(", "module", ")", ":", "\n", "    ", "s", "=", "[", "]", "\n", "for", "m", "in", "module", ".", "modules", ":", "\n", "        ", "name", "=", "type", "(", "m", ")", ".", "__name__", "\n", "real", "=", "m", "\n", "if", "name", "==", "'TorchObject'", ":", "\n", "            ", "name", "=", "m", ".", "_typename", ".", "replace", "(", "'cudnn.'", ",", "''", ")", "\n", "m", "=", "m", ".", "_obj", "\n", "\n", "", "if", "name", "==", "'SpatialConvolution'", ":", "\n", "            ", "if", "not", "hasattr", "(", "m", ",", "'groups'", ")", ":", "m", ".", "groups", "=", "1", "\n", "s", "+=", "[", "'nn.Conv2d({},{},{},{},{},{},{},bias={}),#Conv2d'", ".", "format", "(", "\n", "m", ".", "nInputPlane", ",", "\n", "m", ".", "nOutputPlane", ",", "(", "m", ".", "kW", ",", "m", ".", "kH", ")", ",", "(", "m", ".", "dW", ",", "m", ".", "dH", ")", ",", "(", "m", ".", "padW", ",", "m", ".", "padH", ")", ",", "\n", "1", ",", "m", ".", "groups", ",", "m", ".", "bias", "is", "not", "None", ")", "]", "\n", "", "elif", "name", "==", "'SpatialBatchNormalization'", ":", "\n", "            ", "s", "+=", "[", "'nn.BatchNorm2d({},{},{},{}),#BatchNorm2d'", ".", "format", "(", "\n", "m", ".", "running_mean", ".", "size", "(", "0", ")", ",", "m", ".", "eps", ",", "m", ".", "momentum", ",", "m", ".", "affine", ")", "]", "\n", "", "elif", "name", "==", "'ReLU'", ":", "\n", "            ", "s", "+=", "[", "'nn.ReLU()'", "]", "\n", "", "elif", "name", "==", "'SpatialMaxPooling'", ":", "\n", "            ", "s", "+=", "[", "'nn.MaxPool2d({},{},{},ceil_mode={}),#MaxPool2d'", ".", "format", "(", "\n", "(", "m", ".", "kW", ",", "m", ".", "kH", ")", ",", "(", "m", ".", "dW", ",", "m", ".", "dH", ")", ",", "(", "m", ".", "padW", ",", "m", ".", "padH", ")", ",", "m", ".", "ceil_mode", ")", "]", "\n", "", "elif", "name", "==", "'SpatialAveragePooling'", ":", "\n", "            ", "s", "+=", "[", "'nn.AvgPool2d({},{},{},ceil_mode={}),#AvgPool2d'", ".", "format", "(", "\n", "(", "m", ".", "kW", ",", "m", ".", "kH", ")", ",", "(", "m", ".", "dW", ",", "m", ".", "dH", ")", ",", "(", "m", ".", "padW", ",", "m", ".", "padH", ")", ",", "m", ".", "ceil_mode", ")", "]", "\n", "", "elif", "name", "==", "'SpatialUpSamplingNearest'", ":", "\n", "            ", "s", "+=", "[", "'nn.UpsamplingNearest2d(scale_factor={})'", ".", "format", "(", "\n", "m", ".", "scale_factor", ")", "]", "\n", "", "elif", "name", "==", "'View'", ":", "\n", "            ", "s", "+=", "[", "'Lambda(lambda x: x.view(x.size(0),-1)), # View'", "]", "\n", "", "elif", "name", "==", "'Linear'", ":", "\n", "            ", "s1", "=", "'Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x )'", "\n", "s2", "=", "'nn.Linear({},{},bias={})'", ".", "format", "(", "m", ".", "weight", ".", "size", "(", "1", ")", ",", "\n", "m", ".", "weight", ".", "size", "(", "0", ")", ",", "\n", "(", "m", ".", "bias", "is", "not", "None", ")", ")", "\n", "s", "+=", "[", "'nn.Sequential({},{}),#Linear'", ".", "format", "(", "s1", ",", "s2", ")", "]", "\n", "", "elif", "name", "==", "'Dropout'", ":", "\n", "            ", "s", "+=", "[", "'nn.Dropout({})'", ".", "format", "(", "m", ".", "p", ")", "]", "\n", "", "elif", "name", "==", "'SoftMax'", ":", "\n", "            ", "s", "+=", "[", "'nn.Softmax()'", "]", "\n", "", "elif", "name", "==", "'Identity'", ":", "\n", "            ", "s", "+=", "[", "'Lambda(lambda x: x), # Identity'", "]", "\n", "", "elif", "name", "==", "'SpatialFullConvolution'", ":", "\n", "            ", "s", "+=", "[", "'nn.ConvTranspose2d({},{},{},{},{})'", ".", "format", "(", "m", ".", "nInputPlane", ",", "\n", "m", ".", "nOutputPlane", ",", "\n", "(", "m", ".", "kW", ",", "m", ".", "kH", ")", ",", "\n", "(", "m", ".", "dW", ",", "m", ".", "dH", ")", ",", "(", "\n", "m", ".", "padW", ",", "m", ".", "padH", ")", ")", "]", "\n", "", "elif", "name", "==", "'SpatialReplicationPadding'", ":", "\n", "            ", "s", "+=", "[", "'nn.ReplicationPad2d({})'", ".", "format", "(", "\n", "(", "m", ".", "pad_l", ",", "m", ".", "pad_r", ",", "m", ".", "pad_t", ",", "m", ".", "pad_b", ")", ")", "]", "\n", "", "elif", "name", "==", "'SpatialReflectionPadding'", ":", "\n", "            ", "s", "+=", "[", "'nn.ReflectionPad2d({})'", ".", "format", "(", "\n", "(", "m", ".", "pad_l", ",", "m", ".", "pad_r", ",", "m", ".", "pad_t", ",", "m", ".", "pad_b", ")", ")", "]", "\n", "", "elif", "name", "==", "'Copy'", ":", "\n", "            ", "s", "+=", "[", "'Lambda(lambda x: x), # Copy'", "]", "\n", "", "elif", "name", "==", "'Narrow'", ":", "\n", "            ", "s", "+=", "[", "'Lambda(lambda x,a={}: x.narrow(*a))'", ".", "format", "(", "\n", "(", "m", ".", "dimension", ",", "m", ".", "index", ",", "m", ".", "length", ")", ")", "]", "\n", "", "elif", "name", "==", "'SpatialCrossMapLRN'", ":", "\n", "            ", "lrn", "=", "'torch.legacy.nn.SpatialCrossMapLRN(*{})'", ".", "format", "(", "\n", "(", "m", ".", "size", ",", "m", ".", "alpha", ",", "m", ".", "beta", ",", "m", ".", "k", ")", ")", "\n", "s", "+=", "[", "\n", "'Lambda(lambda x,lrn={}: Variable(lrn.forward(x)))'", ".", "format", "(", "\n", "lrn", ")", "]", "\n", "\n", "", "elif", "name", "==", "'Sequential'", ":", "\n", "            ", "s", "+=", "[", "'nn.Sequential( # Sequential'", "]", "\n", "s", "+=", "lua_recursive_source", "(", "m", ")", "\n", "s", "+=", "[", "')'", "]", "\n", "", "elif", "name", "==", "'ConcatTable'", ":", "\n", "            ", "s", "+=", "[", "'LambdaMap(lambda x: x, # ConcatTable'", "]", "\n", "s", "+=", "lua_recursive_source", "(", "m", ")", "\n", "s", "+=", "[", "')'", "]", "\n", "", "elif", "name", "==", "'CAddTable'", ":", "\n", "            ", "s", "+=", "[", "'LambdaReduce(lambda x,y: x+y), # CAddTable'", "]", "\n", "", "elif", "name", "==", "'Concat'", ":", "\n", "            ", "dim", "=", "m", ".", "dimension", "\n", "s", "+=", "[", "\n", "'LambdaReduce(lambda x,y,dim={}: torch.cat((x,y),dim), # Concat'", ".", "format", "(", "\n", "m", ".", "dimension", ")", "]", "\n", "s", "+=", "lua_recursive_source", "(", "m", ")", "\n", "s", "+=", "[", "')'", "]", "\n", "", "else", ":", "\n", "            ", "s", "+=", "'# '", "+", "name", "+", "' Not Implement,\\n'", "\n", "", "", "s", "=", "map", "(", "lambda", "x", ":", "'\\t{}'", ".", "format", "(", "x", ")", ",", "s", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.simplify_source": [[242, 263], ["map", "map", "map", "map", "map", "map", "map", "map", "map", "map", "map", "map", "map", "map", "map", "map", "functools.reduce", "x.replace", "x.replace", "x.replace", "x.replace", "x.replace", "x.replace", "x.replace", "x.replace", "x.replace", "x.replace", "x.replace", "x.replace", "x.replace", "x.replace"], "function", ["None"], ["", "def", "simplify_source", "(", "s", ")", ":", "\n", "    ", "s", "=", "map", "(", "lambda", "x", ":", "x", ".", "replace", "(", "',(1, 1),(0, 0),1,1,bias=True),#Conv2d'", ",", "')'", ")", ",", "\n", "s", ")", "\n", "s", "=", "map", "(", "lambda", "x", ":", "x", ".", "replace", "(", "',(0, 0),1,1,bias=True),#Conv2d'", ",", "')'", ")", ",", "s", ")", "\n", "s", "=", "map", "(", "lambda", "x", ":", "x", ".", "replace", "(", "',1,1,bias=True),#Conv2d'", ",", "')'", ")", ",", "s", ")", "\n", "s", "=", "map", "(", "lambda", "x", ":", "x", ".", "replace", "(", "',bias=True),#Conv2d'", ",", "')'", ")", ",", "s", ")", "\n", "s", "=", "map", "(", "lambda", "x", ":", "x", ".", "replace", "(", "'),#Conv2d'", ",", "')'", ")", ",", "s", ")", "\n", "s", "=", "map", "(", "lambda", "x", ":", "x", ".", "replace", "(", "',1e-05,0.1,True),#BatchNorm2d'", ",", "')'", ")", ",", "s", ")", "\n", "s", "=", "map", "(", "lambda", "x", ":", "x", ".", "replace", "(", "'),#BatchNorm2d'", ",", "')'", ")", ",", "s", ")", "\n", "s", "=", "map", "(", "lambda", "x", ":", "x", ".", "replace", "(", "',(0, 0),ceil_mode=False),#MaxPool2d'", ",", "')'", ")", ",", "s", ")", "\n", "s", "=", "map", "(", "lambda", "x", ":", "x", ".", "replace", "(", "',ceil_mode=False),#MaxPool2d'", ",", "')'", ")", ",", "s", ")", "\n", "s", "=", "map", "(", "lambda", "x", ":", "x", ".", "replace", "(", "'),#MaxPool2d'", ",", "')'", ")", ",", "s", ")", "\n", "s", "=", "map", "(", "lambda", "x", ":", "x", ".", "replace", "(", "',(0, 0),ceil_mode=False),#AvgPool2d'", ",", "')'", ")", ",", "s", ")", "\n", "s", "=", "map", "(", "lambda", "x", ":", "x", ".", "replace", "(", "',ceil_mode=False),#AvgPool2d'", ",", "')'", ")", ",", "s", ")", "\n", "s", "=", "map", "(", "lambda", "x", ":", "x", ".", "replace", "(", "',bias=True)),#Linear'", ",", "')), # Linear'", ")", ",", "s", ")", "\n", "s", "=", "map", "(", "lambda", "x", ":", "x", ".", "replace", "(", "')),#Linear'", ",", "')), # Linear'", ")", ",", "s", ")", "\n", "\n", "s", "=", "map", "(", "lambda", "x", ":", "'{},\\n'", ".", "format", "(", "x", ")", ",", "s", ")", "\n", "s", "=", "map", "(", "lambda", "x", ":", "x", "[", "1", ":", "]", ",", "s", ")", "\n", "s", "=", "reduce", "(", "lambda", "x", ",", "y", ":", "x", "+", "y", ",", "s", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.torch_to_pytorch": [[265, 311], ["torch.utils.serialization.load_lua", "torch_to_pytorch.lua_recursive_source", "torch_to_pytorch.simplify_source", "t7_filename.replace().replace().replace", "torch.Sequential", "torch_to_pytorch.lua_recursive_model", "torch.save", "torch.save", "torch.legacy.nn.Sequential().add", "torch.legacy.nn.Sequential().add", "open", "pyfile.write", "nn.Sequential.state_dict", "type", "t7_filename.replace().replace", "torch.legacy.nn.Sequential", "torch.legacy.nn.Sequential", "t7_filename.replace"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.lua_recursive_source", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.simplify_source", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.torch_to_pytorch.lua_recursive_model", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save"], ["", "def", "torch_to_pytorch", "(", "t7_filename", ",", "outputname", "=", "None", ")", ":", "\n", "    ", "model", "=", "load_lua", "(", "t7_filename", ",", "unknown_classes", "=", "True", ")", "\n", "if", "type", "(", "model", ")", ".", "__name__", "==", "'hashable_uniq_dict'", ":", "model", "=", "model", ".", "model", "\n", "model", ".", "gradInput", "=", "None", "\n", "slist", "=", "lua_recursive_source", "(", "torch", ".", "legacy", ".", "nn", ".", "Sequential", "(", ")", ".", "add", "(", "model", ")", ")", "\n", "s", "=", "simplify_source", "(", "slist", ")", "\n", "header", "=", "'''\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n'''", "\n", "varname", "=", "t7_filename", ".", "replace", "(", "'.t7'", ",", "''", ")", ".", "replace", "(", "'.'", ",", "'_'", ")", ".", "replace", "(", "'-'", ",", "\n", "'_'", ")", "\n", "s", "=", "'{}\\n\\n{} = {}'", ".", "format", "(", "header", ",", "varname", ",", "s", "[", ":", "-", "2", "]", ")", "\n", "\n", "if", "outputname", "is", "None", ":", "outputname", "=", "varname", "\n", "with", "open", "(", "outputname", "+", "'.py'", ",", "\"w\"", ")", "as", "pyfile", ":", "\n", "        ", "pyfile", ".", "write", "(", "s", ")", "\n", "\n", "", "n", "=", "nn", ".", "Sequential", "(", ")", "\n", "lua_recursive_model", "(", "model", ",", "n", ")", "\n", "torch", ".", "save", "(", "n", ".", "state_dict", "(", ")", ",", "outputname", "+", "'.pth'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.predict.test_transform": [[16, 25], ["transform_list.append", "torchvision.transforms.Compose", "transform_list.append", "transform_list.append", "torchvision.transforms.ToTensor", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop"], "function", ["None"], ["import", "AdaIn", ".", "net", "as", "StyleNet", "\n", "from", "AdaIn", ".", "function", "import", "adaptive_instance_normalization", "\n", "from", "torch", ".", "nn", "import", "functional", "as", "F", "\n", "import", "pdb", "\n", "\n", "palette", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "244", ",", "35", ",", "232", ",", "70", ",", "70", ",", "70", ",", "102", ",", "102", ",", "156", ",", "190", ",", "153", ",", "153", ",", "255", ",", "0", ",", "0", ",", "250", ",", "170", ",", "30", ",", "\n", "0", ",", "0", ",", "230", ",", "0", ",", "80", ",", "100", ",", "152", ",", "251", ",", "152", ",", "0", ",", "255", ",", "255", ",", "0", ",", "0", ",", "142", ",", "119", ",", "11", ",", "32", "]", ")", "\n", "zero_pad", "=", "256", "*", "3", "-", "len", "(", "palette", ")", "\n", "for", "i", "in", "range", "(", "zero_pad", ")", ":", "\n", "    ", "palette", "=", "np", ".", "append", "(", "palette", ",", "0", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.predict.style_transfer": [[27, 43], ["vgg", "vgg", "decoder", "vgg.size", "torch.FloatTensor().zero_().to", "torch.FloatTensor().zero_().to", "torch.FloatTensor().zero_().to", "function.adaptive_instance_normalization", "enumerate", "function.adaptive_instance_normalization", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function.adaptive_instance_normalization", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function.adaptive_instance_normalization"], ["\n", "", "def", "test_transform", "(", "size", ",", "crop", ")", ":", "\n", "    ", "transform_list", "=", "[", "]", "\n", "if", "size", "!=", "0", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Resize", "(", "size", ")", ")", "\n", "", "if", "crop", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "CenterCrop", "(", "size", ")", ")", "\n", "", "transform_list", ".", "append", "(", "transforms", ".", "ToTensor", "(", ")", ")", "\n", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "return", "transform", "\n", "\n", "", "def", "style_transfer", "(", "vgg", ",", "decoder", ",", "content", ",", "style", ",", "alpha", "=", "1.0", ",", "interpolation_weights", "=", "None", ")", ":", "\n", "    ", "assert", "(", "0.0", "<=", "alpha", "<=", "1.0", ")", "\n", "content_f", "=", "vgg", "(", "content", ")", "\n", "style_f", "=", "vgg", "(", "style", ")", "\n", "if", "interpolation_weights", ":", "\n", "        ", "_", ",", "C", ",", "H", ",", "W", "=", "content_f", ".", "size", "(", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.net.Net.__init__": [[97, 111], ["torch.Module.__init__", "list", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.MSELoss", "encoder.children", "getattr().parameters", "getattr"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "enc_layers", "=", "list", "(", "encoder", ".", "children", "(", ")", ")", "\n", "self", ".", "enc_1", "=", "nn", ".", "Sequential", "(", "*", "enc_layers", "[", ":", "4", "]", ")", "# input -> relu1_1", "\n", "self", ".", "enc_2", "=", "nn", ".", "Sequential", "(", "*", "enc_layers", "[", "4", ":", "11", "]", ")", "# relu1_1 -> relu2_1", "\n", "self", ".", "enc_3", "=", "nn", ".", "Sequential", "(", "*", "enc_layers", "[", "11", ":", "18", "]", ")", "# relu2_1 -> relu3_1", "\n", "self", ".", "enc_4", "=", "nn", ".", "Sequential", "(", "*", "enc_layers", "[", "18", ":", "31", "]", ")", "# relu3_1 -> relu4_1", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "mse_loss", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "# fix the encoder", "\n", "for", "name", "in", "[", "'enc_1'", ",", "'enc_2'", ",", "'enc_3'", ",", "'enc_4'", "]", ":", "\n", "            ", "for", "param", "in", "getattr", "(", "self", ",", "name", ")", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.net.Net.encode_with_intermediate": [[113, 119], ["range", "getattr", "results.append", "getattr."], "methods", ["None"], ["", "", "", "def", "encode_with_intermediate", "(", "self", ",", "input", ")", ":", "\n", "        ", "results", "=", "[", "input", "]", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "            ", "func", "=", "getattr", "(", "self", ",", "'enc_{:d}'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "results", ".", "append", "(", "func", "(", "results", "[", "-", "1", "]", ")", ")", "\n", "", "return", "results", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.net.Net.encode": [[121, 125], ["range", "getattr"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "input", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "            ", "input", "=", "getattr", "(", "self", ",", "'enc_{:d}'", ".", "format", "(", "i", "+", "1", ")", ")", "(", "input", ")", "\n", "", "return", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.net.Net.calc_content_loss": [[126, 130], ["net.Net.mse_loss", "input.size", "target.size"], "methods", ["None"], ["", "def", "calc_content_loss", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "assert", "(", "input", ".", "size", "(", ")", "==", "target", ".", "size", "(", ")", ")", "\n", "assert", "(", "target", ".", "requires_grad", "is", "False", ")", "\n", "return", "self", ".", "mse_loss", "(", "input", ",", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.net.Net.calc_style_loss": [[131, 138], ["AdaIn.function.calc_mean_std", "AdaIn.function.calc_mean_std", "input.size", "target.size", "net.Net.mse_loss", "net.Net.mse_loss"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function.calc_mean_std", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function.calc_mean_std"], ["", "def", "calc_style_loss", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "assert", "(", "input", ".", "size", "(", ")", "==", "target", ".", "size", "(", ")", ")", "\n", "assert", "(", "target", ".", "requires_grad", "is", "False", ")", "\n", "input_mean", ",", "input_std", "=", "calc_mean_std", "(", "input", ")", "\n", "target_mean", ",", "target_std", "=", "calc_mean_std", "(", "target", ")", "\n", "return", "self", ".", "mse_loss", "(", "input_mean", ",", "target_mean", ")", "+", "self", ".", "mse_loss", "(", "input_std", ",", "target_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.net.Net.forward": [[139, 155], ["net.Net.encode_with_intermediate", "net.Net.encode", "AdaIn.function.adaptive_instance_normalization", "net.Net.decoder", "net.Net.encode_with_intermediate", "net.Net.calc_content_loss", "net.Net.calc_style_loss", "range", "net.Net.calc_style_loss"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.net.Net.encode_with_intermediate", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.net.Net.encode", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function.adaptive_instance_normalization", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.net.Net.encode_with_intermediate", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.net.Net.calc_content_loss", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.net.Net.calc_style_loss", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.net.Net.calc_style_loss"], ["", "def", "forward", "(", "self", ",", "content", ",", "style", ",", "alpha", "=", "1.0", ")", ":", "\n", "        ", "assert", "0", "<=", "alpha", "<=", "1", "\n", "style_feats", "=", "self", ".", "encode_with_intermediate", "(", "style", ")", "\n", "content_feat", "=", "self", ".", "encode", "(", "content", ")", "\n", "t", "=", "adain", "(", "content_feat", ",", "style_feats", "[", "-", "1", "]", ")", "\n", "t", "=", "alpha", "*", "t", "+", "(", "1", "-", "alpha", ")", "*", "content_feat", "\n", "\n", "g_t", "=", "self", ".", "decoder", "(", "t", ")", "\n", "g_t_feats", "=", "self", ".", "encode_with_intermediate", "(", "g_t", ")", "\n", "\n", "#loss_c = self.calc_content_loss(g_t_feats[-1], t)", "\n", "loss_c", "=", "self", ".", "calc_content_loss", "(", "g_t_feats", "[", "-", "1", "]", ",", "content_feat", ")", "\n", "loss_s", "=", "self", ".", "calc_style_loss", "(", "g_t_feats", "[", "0", "]", ",", "style_feats", "[", "0", "]", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "4", ")", ":", "\n", "            ", "loss_s", "+=", "self", ".", "calc_style_loss", "(", "g_t_feats", "[", "i", "]", ",", "style_feats", "[", "i", "]", ")", "\n", "", "return", "loss_c", ",", "loss_s", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.train.FlatFolderDataset.__init__": [[31, 36], ["torch.Dataset.__init__", "os.listdir"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["model", ".", "set_input", "(", "data", ")", "\n", "model", ".", "optimize_parameters", "(", ")", "\n", "\n", "if", "total_steps", "%", "opt", ".", "display_freq", "==", "0", ":", "\n", "                ", "save_result", "=", "total_steps", "%", "opt", ".", "update_html_freq", "==", "0", "\n", "#visualizer.display_current_results(model.get_current_visuals(), epoch, save_result)", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.train.FlatFolderDataset.__getitem__": [[37, 42], ["PIL.Image.open().convert", "train.FlatFolderDataset.transform", "PIL.Image.open", "os.path.join"], "methods", ["None"], ["\n", "", "if", "total_steps", "%", "opt", ".", "print_freq", "==", "0", ":", "\n", "                ", "losses", "=", "model", ".", "get_current_losses", "(", ")", "\n", "t", "=", "(", "time", ".", "time", "(", ")", "-", "iter_start_time", ")", "/", "opt", ".", "batch_size", "\n", "#visualizer.print_current_losses(epoch, epoch_iter, losses, t, t_data)", "\n", "#if opt.display_id > 0:", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.train.FlatFolderDataset.__len__": [[43, 45], ["len"], "methods", ["None"], ["#visualizer.plot_current_losses(epoch, float(epoch_iter) / dataset_size, opt, losses)", "\n", "\n", "", "if", "total_steps", "%", "opt", ".", "save_latest_freq", "==", "0", ":", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.train.FlatFolderDataset.name": [[46, 48], ["None"], "methods", ["None"], ["                ", "print", "(", "'saving the latest model (epoch %d, total_steps %d)'", "%", "\n", "(", "epoch", ",", "total_steps", ")", ")", "\n", "#model.save_networks('latest')", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.train.train_transform": [[21, 28], ["torchvision.transforms.Compose", "torchvision.transforms.ToTensor"], "function", ["None"], ["iter_data_time", "=", "time", ".", "time", "(", ")", "\n", "epoch_iter", "=", "0", "\n", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "dataset", ")", ":", "\n", "            ", "iter_start_time", "=", "time", ".", "time", "(", ")", "\n", "if", "total_steps", "%", "opt", ".", "print_freq", "==", "0", ":", "\n", "                ", "t_data", "=", "iter_start_time", "-", "iter_data_time", "\n", "#visualizer.reset()", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.train.adjust_learning_rate": [[50, 55], ["None"], "function", ["None"], ["", "iter_data_time", "=", "time", ".", "time", "(", ")", "\n", "", "if", "epoch", "%", "opt", ".", "save_epoch_freq", "==", "0", ":", "\n", "            ", "print", "(", "'saving the model at the end of epoch %d, iters %d'", "%", "\n", "(", "epoch", ",", "total_steps", ")", ")", "\n", "model", ".", "save_networks", "(", "'latest'", ")", "\n", "model", ".", "save_networks", "(", "epoch", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.sampler.InfiniteSamplerWrapper.__init__": [[19, 21], ["len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_source", ")", ":", "\n", "        ", "self", ".", "num_samples", "=", "len", "(", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.sampler.InfiniteSamplerWrapper.__iter__": [[22, 24], ["iter", "sampler.InfiniteSampler"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.sampler.InfiniteSampler"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "InfiniteSampler", "(", "self", ".", "num_samples", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.sampler.InfiniteSamplerWrapper.__len__": [[25, 27], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "2", "**", "31", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.sampler.InfiniteSampler": [[5, 16], ["numpy.random.permutation", "numpy.random.seed", "numpy.random.permutation"], "function", ["None"], ["def", "InfiniteSampler", "(", "n", ")", ":", "\n", "# i = 0", "\n", "    ", "i", "=", "n", "-", "1", "\n", "order", "=", "np", ".", "random", ".", "permutation", "(", "n", ")", "\n", "while", "True", ":", "\n", "        ", "yield", "order", "[", "i", "]", "\n", "i", "+=", "1", "\n", "if", "i", ">=", "n", ":", "\n", "            ", "np", ".", "random", ".", "seed", "(", ")", "\n", "order", "=", "np", ".", "random", ".", "permutation", "(", "n", ")", "\n", "i", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function.calc_mean_std": [[4, 13], ["feat.size", "feat_var.sqrt().view", "feat.view().mean().view", "len", "feat.view().var", "feat_var.sqrt", "feat.view().mean", "feat.view", "feat.view"], "function", ["None"], ["def", "calc_mean_std", "(", "feat", ",", "eps", "=", "1e-5", ")", ":", "\n", "# eps is a small value added to the variance to avoid divide-by-zero.", "\n", "    ", "size", "=", "feat", ".", "size", "(", ")", "\n", "assert", "(", "len", "(", "size", ")", "==", "4", ")", "\n", "N", ",", "C", "=", "size", "[", ":", "2", "]", "\n", "feat_var", "=", "feat", ".", "view", "(", "N", ",", "C", ",", "-", "1", ")", ".", "var", "(", "dim", "=", "2", ")", "+", "eps", "\n", "feat_std", "=", "feat_var", ".", "sqrt", "(", ")", ".", "view", "(", "N", ",", "C", ",", "1", ",", "1", ")", "\n", "feat_mean", "=", "feat", ".", "view", "(", "N", ",", "C", ",", "-", "1", ")", ".", "mean", "(", "dim", "=", "2", ")", ".", "view", "(", "N", ",", "C", ",", "1", ",", "1", ")", "\n", "return", "feat_mean", ",", "feat_std", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function.adaptive_instance_normalization": [[15, 24], ["content_feat.size", "function.calc_mean_std", "function.calc_mean_std", "content_std.expand", "style_mean.expand", "content_feat.size", "style_feat.size", "content_mean.expand", "style_std.expand"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function.calc_mean_std", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function.calc_mean_std"], ["", "def", "adaptive_instance_normalization", "(", "content_feat", ",", "style_feat", ")", ":", "\n", "    ", "assert", "(", "content_feat", ".", "size", "(", ")", "[", ":", "2", "]", "==", "style_feat", ".", "size", "(", ")", "[", ":", "2", "]", ")", "\n", "size", "=", "content_feat", ".", "size", "(", ")", "\n", "style_mean", ",", "style_std", "=", "calc_mean_std", "(", "style_feat", ")", "\n", "content_mean", ",", "content_std", "=", "calc_mean_std", "(", "content_feat", ")", "\n", "\n", "normalized_feat", "=", "(", "content_feat", "-", "content_mean", ".", "expand", "(", "\n", "size", ")", ")", "/", "content_std", ".", "expand", "(", "size", ")", "\n", "return", "normalized_feat", "*", "style_std", ".", "expand", "(", "size", ")", "+", "style_mean", ".", "expand", "(", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function._calc_feat_flatten_mean_std": [[26, 34], ["isinstance", "feat.view", "feat.view.mean", "feat.view.std", "feat.size"], "function", ["None"], ["", "def", "_calc_feat_flatten_mean_std", "(", "feat", ")", ":", "\n", "# takes 3D feat (C, H, W), return mean and std of array within channels", "\n", "    ", "assert", "(", "feat", ".", "size", "(", ")", "[", "0", "]", "==", "3", ")", "\n", "assert", "(", "isinstance", "(", "feat", ",", "torch", ".", "FloatTensor", ")", ")", "\n", "feat_flatten", "=", "feat", ".", "view", "(", "3", ",", "-", "1", ")", "\n", "mean", "=", "feat_flatten", ".", "mean", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "std", "=", "feat_flatten", ".", "std", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "feat_flatten", ",", "mean", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function._mat_sqrt": [[36, 39], ["torch.svd", "torch.mm", "torch.mm", "V.t", "D.pow().diag", "D.pow"], "function", ["None"], ["", "def", "_mat_sqrt", "(", "x", ")", ":", "\n", "    ", "U", ",", "D", ",", "V", "=", "torch", ".", "svd", "(", "x", ")", "\n", "return", "torch", ".", "mm", "(", "torch", ".", "mm", "(", "U", ",", "D", ".", "pow", "(", "0.5", ")", ".", "diag", "(", ")", ")", ",", "V", ".", "t", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function.coral": [[41, 68], ["function._calc_feat_flatten_mean_std", "function._calc_feat_flatten_mean_std", "torch.mm", "source_f_transfer.view", "source_f_std.expand_as", "torch.mm", "torch.eye", "target_f_std.expand_as", "torch.mm", "torch.eye", "function._mat_sqrt", "torch.mm", "target_f_mean.expand_as", "source.size", "source_f_mean.expand_as", "source_f_norm.t", "target_f_mean.expand_as", "target_f_norm.t", "torch.inverse", "target_f_std.expand_as", "function._mat_sqrt"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function._calc_feat_flatten_mean_std", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function._calc_feat_flatten_mean_std", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function._mat_sqrt", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function._mat_sqrt"], ["", "def", "coral", "(", "source", ",", "target", ")", ":", "\n", "# assume both source and target are 3D array (C, H, W)", "\n", "# Note: flatten -> f", "\n", "\n", "    ", "source_f", ",", "source_f_mean", ",", "source_f_std", "=", "_calc_feat_flatten_mean_std", "(", "source", ")", "\n", "source_f_norm", "=", "(", "source_f", "-", "source_f_mean", ".", "expand_as", "(", "\n", "source_f", ")", ")", "/", "source_f_std", ".", "expand_as", "(", "source_f", ")", "\n", "source_f_cov_eye", "=", "torch", ".", "mm", "(", "source_f_norm", ",", "source_f_norm", ".", "t", "(", ")", ")", "+", "torch", ".", "eye", "(", "3", ")", "\n", "\n", "target_f", ",", "target_f_mean", ",", "target_f_std", "=", "_calc_feat_flatten_mean_std", "(", "target", ")", "\n", "target_f_norm", "=", "(", "target_f", "-", "target_f_mean", ".", "expand_as", "(", "\n", "target_f", ")", ")", "/", "target_f_std", ".", "expand_as", "(", "target_f", ")", "\n", "target_f_cov_eye", "=", "torch", ".", "mm", "(", "target_f_norm", ",", "target_f_norm", ".", "t", "(", ")", ")", "+", "torch", ".", "eye", "(", "3", ")", "\n", "\n", "source_f_norm_transfer", "=", "torch", ".", "mm", "(", "\n", "_mat_sqrt", "(", "target_f_cov_eye", ")", ",", "\n", "torch", ".", "mm", "(", "torch", ".", "inverse", "(", "_mat_sqrt", "(", "source_f_cov_eye", ")", ")", ",", "\n", "source_f_norm", ")", "\n", ")", "\n", "\n", "source_f_transfer", "=", "source_f_norm_transfer", "*", "target_f_std", ".", "expand_as", "(", "source_f_norm", ")", "+", "target_f_mean", ".", "expand_as", "(", "source_f_norm", ")", "\n", "\n", "return", "source_f_transfer", ".", "view", "(", "source", ".", "size", "(", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.test.test_transform": [[17, 26], ["transform_list.append", "torchvision.transforms.Compose", "transform_list.append", "transform_list.append", "torchvision.transforms.ToTensor", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop"], "function", ["None"], ["palette", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "244", ",", "35", ",", "232", ",", "70", ",", "70", ",", "70", ",", "102", ",", "102", ",", "156", ",", "190", ",", "153", ",", "153", ",", "255", ",", "0", ",", "0", ",", "250", ",", "170", ",", "30", ",", "0", ",", "0", ",", "230", ",", "0", ",", "80", ",", "100", ",", "152", ",", "251", ",", "152", ",", "0", ",", "255", ",", "255", ",", "0", ",", "0", ",", "142", ",", "119", ",", "11", ",", "32", "]", ")", "\n", "\n", "zero_pad", "=", "256", "*", "3", "-", "len", "(", "palette", ")", "\n", "for", "i", "in", "range", "(", "zero_pad", ")", ":", "\n", "    ", "palette", "=", "np", ".", "append", "(", "palette", ",", "0", ")", "\n", "\n", "\n", "", "n_classes", "=", "11", "\n", "dspth", "=", "'./data/'", "\n", "spth", "=", "'./results/'", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.test.style_transfer": [[28, 44], ["vgg", "vgg", "decoder", "vgg.size", "torch.FloatTensor().zero_().to", "torch.FloatTensor().zero_().to", "torch.FloatTensor().zero_().to", "function.adaptive_instance_normalization", "enumerate", "function.adaptive_instance_normalization", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function.adaptive_instance_normalization", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.AdaIn.function.adaptive_instance_normalization"], ["net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "'models/model_best.pth.tar'", ")", "[", "\"state_dict\"", "]", ")", "\n", "#net.load_state_dict(torch.load('res/cp/39999_iter.pth'))", "\n", "net", ".", "cuda", "(", ")", "\n", "net", ".", "eval", "(", ")", "\n", "\n", "to_tensor", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "(", "0.229", ",", "0.224", ",", "0.225", ")", ")", ",", "]", ")", "\n", "resize", "=", "nn", ".", "Upsample", "(", "size", "=", "(", "256", ",", "256", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "    ", "for", "i", ",", "image_path", "in", "enumerate", "(", "os", ".", "listdir", "(", "dspth", ")", ")", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "osp", ".", "join", "(", "dspth", ",", "image_path", ")", ")", "\n", "image_384", "=", "img", ".", "resize", "(", "(", "384", ",", "384", ")", ",", "Image", ".", "BILINEAR", ")", "\n", "img_384", "=", "to_tensor", "(", "image_384", ")", "\n", "img_384", "=", "torch", ".", "unsqueeze", "(", "img_384", ",", "0", ")", "\n", "img_384", "=", "img_384", ".", "cuda", "(", ")", "\n", "out_384", ",", "_", "=", "net", "(", "img_384", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.Self_Attn.__init__": [[28, 38], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["self", ".", "activation", "=", "activation", "\n", "\n", "self", ".", "query_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", ",", "out_channels", "=", "in_dim", "//", "8", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "key_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", ",", "out_channels", "=", "in_dim", "//", "8", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "value_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", ",", "out_channels", "=", "in_dim", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "gamma", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "#", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.Self_Attn.forward": [[39, 57], ["x.size", "networks.Self_Attn.query_conv().view().permute", "networks.Self_Attn.key_conv().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "networks.Self_Attn.softmax", "networks.Self_Attn.value_conv().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "out.view.view.view", "networks.Self_Attn.permute", "networks.Self_Attn.query_conv().view", "networks.Self_Attn.key_conv", "networks.Self_Attn.value_conv", "networks.Self_Attn.query_conv"], "methods", ["None"], ["\n", "m_batchsize", ",", "C", ",", "width", ",", "height", "=", "x", ".", "size", "(", ")", "\n", "proj_query", "=", "self", ".", "query_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "-", "1", ",", "width", "*", "height", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# B X CX(N)", "\n", "proj_key", "=", "self", ".", "key_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "-", "1", ",", "width", "*", "height", ")", "# B X C x (*W*H)", "\n", "energy", "=", "torch", ".", "bmm", "(", "proj_query", ",", "proj_key", ")", "# transpose check", "\n", "attention", "=", "self", ".", "softmax", "(", "energy", ")", "# BX (N) X (N)", "\n", "proj_value", "=", "self", ".", "value_conv", "(", "x", ")", ".", "view", "(", "m_batchsize", ",", "-", "1", ",", "width", "*", "height", ")", "# B X C X N", "\n", "out", "=", "torch", ".", "bmm", "(", "proj_value", ",", "attention", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "out", "=", "out", ".", "view", "(", "m_batchsize", ",", "C", ",", "width", ",", "height", ")", "\n", "out", "=", "self", ".", "gamma", "*", "out", "+", "x", "\n", "return", "out", ",", "attention", "\n", "\n", "", "", "class", "PyramidPooling", "(", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "PyramidPooling", ",", "self", ")", ".", "__init__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.PyramidPooling.__init__": [[59, 69], ["torch.nn.Module.__init__", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "int", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["self", ".", "pool2", "=", "AdaptiveAvgPool2d", "(", "2", ")", "\n", "#self.pool3 = AdaptiveAvgPool2d(4)", "\n", "#self.pool4 = AdaptiveAvgPool2d(8)", "\n", "\n", "out_channels", "=", "int", "(", "in_channels", "/", "2", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "bias", "=", "False", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ",", "bias", "=", "False", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_", ",", "_", ",", "h", ",", "w", "=", "x", ".", "size", "(", ")", "\n", "feat1", "=", "F", ".", "upsample", "(", "self", ".", "conv1", "(", "self", ".", "pool1", "(", "x", ")", ")", ",", "(", "h", ",", "w", ")", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.PyramidPooling.forward": [[70, 75], ["x.size", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.upsample", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks.PyramidPooling.conv1", "networks.PyramidPooling.conv2", "networks.PyramidPooling.pool1", "networks.PyramidPooling.pool2"], "methods", ["None"], ["feat2", "=", "F", ".", "upsample", "(", "self", ".", "conv2", "(", "self", ".", "pool2", "(", "x", ")", ")", ",", "(", "h", ",", "w", ")", ")", "\n", "return", "torch", ".", "cat", "(", "(", "x", ",", "feat1", ",", "feat2", ")", ",", "1", ")", "\n", "\n", "\n", "\n", "", "", "def", "get_norm_layer", "(", "norm_type", "=", "'instance'", ")", ":", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.LocationAwareReconstructedLoss.__init__": [[217, 233], ["torch.Module.__init__", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "range", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "range", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "networks.LocationAwareReconstructedLoss.filterx.cuda", "networks.LocationAwareReconstructedLoss.filtery.cuda", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "single_filtery.view", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "imgSize", "=", "256", ",", "batchSize", "=", "1", ")", ":", "\n", "        ", "super", "(", "waspWarper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "batchSize", "=", "batchSize", "\n", "self", ".", "imgSize", "=", "imgSize", "\n", "\n", "", "def", "forward", "(", "self", ",", "input_img", ",", "input_grid", ")", ":", "\n", "        ", "self", ".", "warp", "=", "input_grid", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "self", ".", "output", "=", "F", ".", "grid_sample", "(", "input_img", ",", "self", ".", "warp", ")", "\n", "return", "self", ".", "output", "\n", "\n", "\n", "\n", "\n", "", "", "class", "waspGridSpatialIntegral", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "imgSize", "=", "256", ",", "cuda", "=", "True", ")", ":", "\n", "        ", "super", "(", "waspGridSpatialIntegral", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w", "=", "imgSize", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.LocationAwareReconstructedLoss.forward": [[234, 243], ["torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul"], "methods", ["None"], ["self", ".", "filterx", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "1", ",", "1", ",", "1", ",", "self", ".", "w", ")", ".", "fill_", "(", "1", ")", "\n", "self", ".", "filtery", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "1", ",", "1", ",", "self", ".", "w", ",", "1", ")", ".", "fill_", "(", "1", ")", "\n", "self", ".", "filterx", "=", "Variable", "(", "self", ".", "filterx", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "filtery", "=", "Variable", "(", "self", ".", "filtery", ",", "requires_grad", "=", "False", ")", "\n", "if", "cuda", ":", "\n", "            ", "self", ".", "filterx", ".", "cuda", "(", ")", "\n", "self", ".", "filtery", ".", "cuda", "(", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "input_diffgrid", ")", ":", "\n", "        ", "fullx", "=", "F", ".", "conv_transpose2d", "(", "input_diffgrid", "[", ":", ",", "0", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "filterx", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.BiasReduceLoss.__init__": [[246, 250], ["torch.Module.__init__", "torch.L1Loss", "torch.L1Loss", "torch.L1Loss", "torch.L1Loss"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["return", "output_grid", "\n", "\n", "\n", "", "", "class", "waspGridSpatialIntegral2", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "imgSize", "=", "256", ",", "cuda", "=", "True", ")", ":", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.BiasReduceLoss.forward": [[251, 258], ["torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "networks.BiasReduceLoss.criterion", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["None"], ["        ", "super", "(", "waspGridSpatialIntegral2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w", "=", "imgSize", "\n", "self", ".", "filterx", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "1", ",", "1", ",", "1", ",", "self", ".", "w", ")", ".", "fill_", "(", "1", ")", "\n", "self", ".", "filtery", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "1", ",", "1", ",", "self", ".", "w", ",", "1", ")", ".", "fill_", "(", "1", ")", "\n", "self", ".", "filterx", "=", "Variable", "(", "self", ".", "filterx", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "filtery", "=", "Variable", "(", "self", ".", "filtery", ",", "requires_grad", "=", "False", ")", "\n", "if", "cuda", ":", "\n", "            ", "self", ".", "filterx", ".", "cuda", "(", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.TotalVaryLoss.__init__": [[260, 263], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["\n", "", "", "def", "forward", "(", "self", ",", "input_diffgrid", ")", ":", "\n", "        ", "fullx", "=", "F", ".", "conv_transpose2d", "(", "input_diffgrid", "[", ":", ",", "0", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "filterx", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "fully", "=", "F", ".", "conv_transpose2d", "(", "input_diffgrid", "[", ":", ",", "1", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "filtery", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.TotalVaryLoss.forward": [[264, 270], ["torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["None"], ["output_grid", "=", "torch", ".", "cat", "(", "(", "fullx", "[", ":", ",", ":", ",", "0", ":", "self", ".", "w", ",", "-", "self", ".", "w", ":", "]", ",", "fully", "[", ":", ",", ":", ",", "-", "self", ".", "w", ":", ",", "0", ":", "self", ".", "w", "]", ")", ",", "1", ")", "\n", "return", "output_grid", "\n", "\n", "\n", "\n", "", "", "class", "DenseBlockDecoder", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "n_channels", ",", "n_convs", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.SelfSmoothLoss2.__init__": [[273, 276], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["\n", "self", ".", "n_channels", "=", "n_channels", "\n", "self", ".", "n_convs", "=", "n_convs", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.SelfSmoothLoss2.forward": [[277, 287], ["torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul"], "methods", ["None"], ["for", "i", "in", "range", "(", "n_convs", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "Sequential", "(", "\n", "norm_layer", "(", "n_channels", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "n_channels", ",", "n_channels", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", ")", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "outputs", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "if", "i", ">", "0", ":", "\n", "                ", "next_output", "=", "0", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.GANLoss.__init__": [[297, 305], ["torch.Module.__init__", "networks.GANLoss.register_buffer", "networks.GANLoss.register_buffer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_channels_in", ",", "n_channels_out", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseTransitionBlockDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_channels_in", "=", "n_channels_in", "\n", "self", ".", "n_channels_out", "=", "n_channels_out", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "norm_layer", "(", "n_channels_in", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "n_channels_in", ",", "n_channels_out", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.GANLoss.get_target_tensor": [[306, 312], ["target_tensor.expand_as"], "methods", ["None"], ["\n", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "self", ".", "main", "(", "inputs", ")", "\n", "\n", "\n", "", "", "class", "waspDenseDecoder", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "ngpu", "=", "1", ",", "nz", "=", "128", ",", "nc", "=", "1", ",", "ngf", "=", "32", ",", "lb", "=", "0", ",", "ub", "=", "1", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "f_activation", "=", "nn", ".", "Hardtanh", ",", "f_args", "=", "[", "0", ",", "1", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.GANLoss.__call__": [[313, 316], ["networks.GANLoss.get_target_tensor", "networks.GANLoss.loss"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.GANLoss.get_target_tensor"], ["        ", "super", "(", "waspDenseDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ngpu", "=", "ngpu", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ConvTranspose2d", "(", "nz", ",", "ngf", "*", "8", ",", "4", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.TpsGenerator.__init__": [[319, 394], ["torch.Module.__init__", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cat.split", "torch.cat.split", "torch.cat.split", "torch.cat.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "tps_grid_gen.TPSGridGen", "list", "type", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "itertools.product", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "networks.ResnetBlock", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.tensor.view", "torch.tensor.view", "torch.tensor.view", "torch.tensor.view", "numpy.arange", "numpy.arange", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "numpy.arctanh", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.cat.numpy", "torch.cat.numpy", "torch.cat.numpy", "torch.cat.numpy"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["DenseTransitionBlockDecoder", "(", "ngf", "*", "8", ",", "ngf", "*", "4", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "DenseBlockDecoder", "(", "ngf", "*", "4", ",", "24", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DenseTransitionBlockDecoder", "(", "ngf", "*", "4", ",", "ngf", "*", "2", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "DenseBlockDecoder", "(", "ngf", "*", "2", ",", "12", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DenseTransitionBlockDecoder", "(", "ngf", "*", "2", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "DenseBlockDecoder", "(", "ngf", ",", "6", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DenseTransitionBlockDecoder", "(", "ngf", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "norm_layer", "(", "ngf", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "ngf", ",", "nc", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "f_activation", "(", "*", "f_args", ")", ",", "\n", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "self", ".", "main", "(", "inputs", ")", "\n", "\n", "\n", "", "", "class", "Dense_DecodersIntegralWarper2", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "ngpu", "=", "1", ",", "nc", "=", "3", ",", "ngf", "=", "32", ",", "ndf", "=", "32", ",", "wdim", "=", "128", ",", "imgSize", "=", "256", ",", "batch_size", "=", "1", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "Dense_DecodersIntegralWarper2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "imagedimension", "=", "imgSize", "\n", "self", ".", "ngpu", "=", "ngpu", "\n", "self", ".", "wdim", "=", "wdim", "\n", "self", ".", "decoderW_left", "=", "waspDenseDecoder", "(", "ngpu", "=", "self", ".", "ngpu", ",", "nz", "=", "wdim", ",", "nc", "=", "2", ",", "ngf", "=", "ngf", ",", "lb", "=", "0", ",", "ub", "=", "1", ",", "activation", "=", "nn", ".", "Tanh", ",", "args", "=", "[", "]", ",", "f_activation", "=", "nn", ".", "Sigmoid", ",", "f_args", "=", "[", "]", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "decoderW_right", "=", "waspDenseDecoder", "(", "ngpu", "=", "self", ".", "ngpu", ",", "nz", "=", "wdim", ",", "nc", "=", "2", ",", "ngf", "=", "ngf", ",", "lb", "=", "0", ",", "ub", "=", "1", ",", "activation", "=", "nn", ".", "Tanh", ",", "args", "=", "[", "]", ",", "f_activation", "=", "nn", ".", "Sigmoid", ",", "f_args", "=", "[", "]", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "decoderW_right", "=", "waspDenseDecoder", "(", "ngpu", "=", "self", ".", "ngpu", ",", "nz", "=", "wdim", ",", "nc", "=", "2", ",", "ngf", "=", "ngf", ",", "lb", "=", "0", ",", "ub", "=", "1", ",", "activation", "=", "nn", ".", "Tanh", ",", "args", "=", "[", "]", ",", "f_activation", "=", "nn", ".", "Sigmoid", ",", "f_args", "=", "[", "]", ",", "norm_layer", "=", "norm_layer", ")", "\n", "\n", "self", ".", "warper", "=", "waspWarper", "(", "imgSize", ",", "batch_size", ")", "\n", "self", ".", "integrator", "=", "waspGridSpatialIntegral", "(", "imgSize", "=", "imgSize", ")", "\n", "self", ".", "integrator2", "=", "waspGridSpatialIntegral2", "(", "imgSize", "=", "imgSize", ")", "\n", "self", ".", "cutter", "=", "nn", ".", "Hardtanh", "(", "-", "1", ",", "1", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "zW", ")", ":", "\n", "        ", "self", ".", "diffentialWarping_left", "=", "(", "self", ".", "decoderW_left", "(", "zW", ".", "view", "(", "-", "1", ",", "self", ".", "wdim", ",", "1", ",", "1", ")", ")", "-", "0.5", ")", "*", "(", "4.0", "/", "self", ".", "imagedimension", ")", "+", "2.0", "/", "self", ".", "imagedimension", "\n", "self", ".", "diffentialWarping_right", "=", "(", "self", ".", "decoderW_right", "(", "zW", ".", "view", "(", "-", "1", ",", "self", ".", "wdim", ",", "1", ",", "1", ")", ")", "-", "0.5", ")", "*", "(", "4.0", "/", "self", ".", "imagedimension", ")", "+", "2.0", "/", "self", ".", "imagedimension", "\n", "\n", "self", ".", "warping_left", "=", "self", ".", "integrator", "(", "self", ".", "diffentialWarping_left", ")", "-", "1.0", "\n", "self", ".", "warping_right", "=", "1.0", "-", "self", ".", "integrator2", "(", "self", ".", "diffentialWarping_right", ")", "\n", "self", ".", "warping_left", "=", "self", ".", "cutter", "(", "self", ".", "warping_left", ")", "\n", "self", ".", "warping_right", "=", "self", ".", "cutter", "(", "self", ".", "warping_right", ")", "\n", "self", ".", "warping", "=", "(", "self", ".", "warping_left", "+", "self", ".", "warping_right", ")", "/", "2.0", "/", "63.0", "*", "64.0", "\n", "return", "self", ".", "warping", "\n", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.TpsGenerator.forward": [[395, 416], ["input.size", "networks.TpsGenerator.model", "networks.TpsGenerator.view", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "networks.TpsGenerator.fc2", "torch.tanh.view", "networks.TpsGenerator.tps", "networks.TpsGenerator.view", "networks.TpsGenerator.fc1", "networks.TpsGenerator.view", "torch.affine_grid", "torch.affine_grid", "torch.affine_grid", "torch.affine_grid", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "input.size"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.InverseTpsGenerator.__init__": [[422, 494], ["torch.Module.__init__", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cat.split", "torch.cat.split", "torch.cat.split", "torch.cat.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "list", "type", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "itertools.product", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "networks.ResnetBlock", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.tensor.view", "torch.tensor.view", "torch.tensor.view", "torch.tensor.view", "numpy.arange", "numpy.arange", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "numpy.arctanh", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.cat.numpy", "torch.cat.numpy", "torch.cat.numpy", "torch.cat.numpy"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.InverseTpsGenerator.forward": [[495, 515], ["input.size", "networks.InverseTpsGenerator.model", "networks.InverseTpsGenerator.view", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "networks.InverseTpsGenerator.fc2", "torch.hardtanh", "torch.hardtanh", "torch.hardtanh", "torch.hardtanh", "torch.hardtanh.view", "inverse_tps_grid_gen.InverseTPSGridGen", "source_control_points.view.view.view", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inverse_tps_grid_gen.InverseTPSGridGen.view", "networks.InverseTpsGenerator.fc1", "inverse_tps_grid_gen.InverseTPSGridGen.", "source_coordinate_list.append", "tuple", "source_control_points[].unsqueeze"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.DenseBlockEncoder.__init__": [[518, 530], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "networks.DenseBlockEncoder.layers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "norm_layer", "activation", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.DenseBlockEncoder.forward": [[531, 542], ["enumerate", "outputs.append", "outputs.append", "layer"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.DenseTransitionBlockEncoder.__init__": [[545, 555], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "norm_layer", "activation", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.DenseTransitionBlockEncoder.forward": [[557, 559], ["networks.DenseTransitionBlockEncoder.main"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.waspDenseEncoder.__init__": [[562, 582], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "networks.DenseBlockEncoder", "networks.DenseTransitionBlockEncoder", "networks.DenseBlockEncoder", "networks.DenseTransitionBlockEncoder", "networks.DenseBlockEncoder", "networks.DenseTransitionBlockEncoder", "networks.DenseBlockEncoder", "networks.DenseTransitionBlockEncoder", "f_activation"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.waspDenseEncoder.forward": [[584, 587], ["networks.waspDenseEncoder.main().view", "networks.waspDenseEncoder.main"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.waspWarper.__init__": [[589, 593], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.waspWarper.forward": [[594, 598], ["input_grid.permute", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.waspGridSpatialIntegral.__init__": [[603, 613], ["torch.Module.__init__", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "networks.waspGridSpatialIntegral.filterx.cuda", "networks.waspGridSpatialIntegral.filtery.cuda", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.waspGridSpatialIntegral.forward": [[614, 619], ["torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_diffgrid[].unsqueeze", "input_diffgrid[].unsqueeze"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.waspGridSpatialIntegral2.__init__": [[622, 632], ["torch.Module.__init__", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "networks.waspGridSpatialIntegral2.filterx.cuda", "networks.waspGridSpatialIntegral2.filtery.cuda", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.waspGridSpatialIntegral2.forward": [[633, 638], ["torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_diffgrid[].unsqueeze", "input_diffgrid[].unsqueeze"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.DenseBlockDecoder.__init__": [[642, 654], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "networks.DenseBlockDecoder.layers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "norm_layer", "activation", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.DenseBlockDecoder.forward": [[655, 666], ["enumerate", "outputs.append", "outputs.append", "layer"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.DenseTransitionBlockDecoder.__init__": [[669, 677], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "norm_layer", "activation", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.DenseTransitionBlockDecoder.forward": [[679, 681], ["networks.DenseTransitionBlockDecoder.main"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.waspDenseDecoder.__init__": [[684, 706], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "networks.DenseBlockDecoder", "networks.DenseTransitionBlockDecoder", "networks.DenseBlockDecoder", "networks.DenseTransitionBlockDecoder", "networks.DenseBlockDecoder", "networks.DenseTransitionBlockDecoder", "networks.DenseBlockDecoder", "networks.DenseTransitionBlockDecoder", "norm_layer", "activation", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "f_activation"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.waspDenseDecoder.forward": [[708, 710], ["networks.waspDenseDecoder.main"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.Dense_DecodersIntegralWarper2.__init__": [[713, 726], ["torch.Module.__init__", "networks.waspDenseDecoder", "networks.waspDenseDecoder", "networks.waspDenseDecoder", "networks.waspWarper", "networks.waspGridSpatialIntegral", "networks.waspGridSpatialIntegral2", "torch.Hardtanh", "torch.Hardtanh", "torch.Hardtanh", "torch.Hardtanh"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.Dense_DecodersIntegralWarper2.forward": [[727, 737], ["networks.Dense_DecodersIntegralWarper2.cutter", "networks.Dense_DecodersIntegralWarper2.cutter", "networks.Dense_DecodersIntegralWarper2.integrator", "networks.Dense_DecodersIntegralWarper2.integrator2", "networks.Dense_DecodersIntegralWarper2.decoderW_left", "networks.Dense_DecodersIntegralWarper2.decoderW_right", "zW.view", "zW.view"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.StarGenerator.__init__": [[744, 748], ["torch.Module.__init__", "networks.waspDenseEncoder", "networks.Dense_DecodersIntegralWarper2"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.StarGenerator.forward": [[749, 759], ["c.view", "input_c.repeat.repeat.repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks.StarGenerator.decoders", "dp0_Wact.permute.permute.permute", "c.size", "c.size", "x.size", "x.size"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.ParserefGenerator.__init__": [[762, 768], ["torch.Module.__init__", "networks.waspDenseEncoder", "networks.waspDenseEncoder", "networks.Dense_DecodersIntegralWarper2", "networks.Dense_DecodersIntegralWarper2"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.ParserefGenerator.forward": [[769, 789], ["networks.ParserefGenerator.photo_encoders", "networks.ParserefGenerator.cari_encoders", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks.ParserefGenerator.permute", "networks.ParserefGenerator.cari_encoders", "networks.ParserefGenerator.cari_encoders", "networks.ParserefGenerator.cari_encoders", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks.ParserefGenerator.cari_decoders", "networks.ParserefGenerator.photo_decoders"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.ResnetGeneratorUnit.__init__": [[797, 854], ["torch.Module.__init__", "range", "range", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "networks.ResnetBlock", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "int", "int"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.ResnetGeneratorUnit.forward": [[855, 863], ["networks.ResnetGeneratorUnit.view", "networks.ResnetGeneratorUnit.repeat", "networks.ResnetGeneratorUnit.model1", "networks.ResnetGeneratorUnit.model2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks.ResnetGeneratorUnit.model3", "networks.ResnetGeneratorUnit.size", "networks.ResnetGeneratorUnit.size", "networks.ResnetGeneratorUnit.size", "networks.ResnetGeneratorUnit.size"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.ResnetGenerator.__init__": [[870, 912], ["torch.Module.__init__", "range", "range", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "networks.ResnetBlock", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "int", "int"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.ResnetGenerator.forward": [[913, 915], ["networks.ResnetGenerator.model"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.ResnetBlock.__init__": [[919, 922], ["torch.Module.__init__", "networks.ResnetBlock.build_conv_block"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.ResnetBlock.build_conv_block"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.ResnetBlock.build_conv_block": [[923, 962], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "NotImplementedError", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.ResnetBlock.forward": [[963, 966], ["networks.ResnetBlock.conv_block"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.UnetGenerator.__init__": [[973, 987], ["torch.Module.__init__", "networks.UnetSkipConnectionBlock", "range", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.UnetGenerator.forward": [[988, 990], ["networks.UnetGenerator.model"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.UnetSkipConnectionBlock.__init__": [[996, 1040], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "norm_layer", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.UnetSkipConnectionBlock.forward": [[1041, 1046], ["networks.UnetSkipConnectionBlock.model", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks.UnetSkipConnectionBlock.model"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.NLayerDiscriminator.__init__": [[1055, 1118], ["torch.Module.__init__", "min", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "range", "range", "min", "min", "networks.spectral_norm", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "networks.spectral_norm", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "networks.spectral_norm", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.spectral_norm", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.spectral_norm", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.spectral_norm"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.NLayerDiscriminator.forward": [[1119, 1121], ["networks.NLayerDiscriminator.model"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.DilatedDiscriminator.__init__": [[1128, 1188], ["torch.Module.__init__", "range", "min", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "min", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.DilatedDiscriminator.forward": [[1189, 1195], ["networks.DilatedDiscriminator.layer1", "networks.DilatedDiscriminator.layer2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks.DilatedDiscriminator.layer3"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.PixelDiscriminator.__init__": [[1199, 1218], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "networks.PixelDiscriminator.net.append", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.PixelDiscriminator.forward": [[1219, 1221], ["networks.PixelDiscriminator.net"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.SpectralNorm.__init__": [[1228, 1236], ["ValueError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.SpectralNorm.compute_weight": [[1236, 1253], ["getattr", "getattr", "weight_mat.permute.permute.size", "weight_mat.permute.permute.reshape", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "weight_mat.permute.permute.permute", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "weight_mat.permute.permute.t", "range", "weight_mat.permute.permute.dim"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.SpectralNorm.remove": [[1253, 1259], ["getattr", "delattr", "delattr", "delattr", "module.register_parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.SpectralNorm.__call__": [[1259, 1267], ["networks.SpectralNorm.compute_weight", "setattr", "setattr", "getattr().detach_().requires_grad_", "getattr", "getattr().detach_", "getattr"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.SpectralNorm.compute_weight"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.SpectralNorm.apply": [[1268, 1280], ["networks.SpectralNorm", "weight.size", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "delattr", "module.register_parameter", "module.register_buffer", "module.register_buffer", "module.register_forward_pre_hook", "weight.new_empty().normal_", "weight.new_empty"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.ResidualBlock.__init__": [[1304, 1312], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.ResidualBlock.forward": [[1313, 1315], ["networks.ResidualBlock.main"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.Discriminator.__init__": [[1319, 1337], ["torch.Module.__init__", "layers.append", "layers.append", "range", "int", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "networks.spectral_norm", "networks.spectral_norm", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "layers.append", "layers.append", "networks.PyramidPooling", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "numpy.power"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.spectral_norm", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.spectral_norm"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.Discriminator.forward": [[1338, 1344], ["networks.Discriminator.main", "networks.Discriminator.psp", "networks.Discriminator.conv1", "networks.Discriminator.conv2"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.Generator.__init__": [[1347, 1377], ["torch.Module.__init__", "layers.append", "layers.append", "layers.append", "range", "range", "range", "layers.append", "layers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "layers.append", "layers.append", "layers.append", "layers.append", "layers.append", "layers.append", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "networks.ResidualBlock", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.Generator.forward": [[1378, 1384], ["c.repeat.repeat.view", "c.repeat.repeat.repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks.Generator.main", "c.repeat.repeat.size", "c.repeat.repeat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.get_norm_layer": [[78, 88], ["functools.partial", "functools.partial", "NotImplementedError"], "function", ["None"], ["", "elif", "norm_type", "==", "'instance'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "InstanceNorm2d", ",", "affine", "=", "False", ",", "track_running_stats", "=", "False", ")", "\n", "", "elif", "norm_type", "==", "'none'", ":", "\n", "        ", "norm_layer", "=", "None", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'normalization layer [%s] is not found'", "%", "norm_type", ")", "\n", "", "return", "norm_layer", "\n", "\n", "\n", "", "def", "get_scheduler", "(", "optimizer", ",", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "lr_policy", "==", "'lambda'", ":", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.get_scheduler": [[90, 105], ["torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.ReduceLROnPlateau", "max", "float", "torch.optim.lr_scheduler.CosineAnnealingLR", "NotImplementedError"], "function", ["None"], ["            ", "lr_l", "=", "1.0", "-", "max", "(", "0", ",", "epoch", "+", "1", "+", "opt", ".", "epoch_count", "-", "opt", ".", "niter", ")", "/", "float", "(", "opt", ".", "niter_decay", "+", "1", ")", "\n", "return", "lr_l", "\n", "", "scheduler", "=", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lambda_rule", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'step'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "step_size", "=", "opt", ".", "lr_decay_iters", ",", "gamma", "=", "0.1", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'plateau'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "factor", "=", "0.2", ",", "threshold", "=", "0.01", ",", "patience", "=", "5", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'cosine'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "CosineAnnealingLR", "(", "optimizer", ",", "T_max", "=", "opt", ".", "niter", ",", "eta_min", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "return", "NotImplementedError", "(", "'learning rate policy [%s] is not implemented'", ",", "opt", ".", "lr_policy", ")", "\n", "", "return", "scheduler", "\n", "\n", "\n", "", "def", "init_weights", "(", "net", ",", "init_type", "=", "'normal'", ",", "gain", "=", "0.02", ")", ":", "\n", "    ", "def", "init_func", "(", "m", ")", ":", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.init_weights": [[107, 129], ["print", "net.apply", "hasattr", "torch.nn.init.normal_", "hasattr", "torch.nn.init.constant_", "classname.find", "torch.nn.init.normal_", "torch.nn.init.constant_", "classname.find", "classname.find", "torch.nn.init.xavier_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.orthogonal_", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.SpectralNorm.apply"], ["if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "(", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", "or", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ")", ":", "\n", "            ", "if", "init_type", "==", "'normal'", ":", "\n", "                ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "0.0", ",", "gain", ")", "\n", "", "elif", "init_type", "==", "'xavier'", ":", "\n", "                ", "init", ".", "xavier_normal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "gain", ")", "\n", "", "elif", "init_type", "==", "'kaiming'", ":", "\n", "                ", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ".", "data", ",", "a", "=", "0", ",", "mode", "=", "'fan_in'", ")", "\n", "", "elif", "init_type", "==", "'orthogonal'", ":", "\n", "                ", "init", ".", "orthogonal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "gain", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'initialization method [%s] is not implemented'", "%", "init_type", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'BatchNorm2d'", ")", "!=", "-", "1", ":", "\n", "            ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "1.0", ",", "gain", ")", "\n", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "\n", "", "", "print", "(", "'initialize network with %s'", "%", "init_type", ")", "\n", "net", ".", "apply", "(", "init_func", ")", "\n", "\n", "\n", "", "def", "init_net", "(", "net", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "    ", "if", "hasattr", "(", "net", ",", "'which_model_netG'", ")", ":", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.init_net": [[131, 144], ["hasattr", "networks.init_weights", "hasattr", "len", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "net.to", "net.fc2.bias.data.copy_", "net.fc2.weight.data.zero_"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.init_weights"], ["fc2_bias", "=", "net", ".", "fc2_bias", "\n", "", "if", "len", "(", "gpu_ids", ")", ">", "0", ":", "\n", "        ", "assert", "(", "torch", ".", "cuda", ".", "is_available", "(", ")", ")", "\n", "net", ".", "to", "(", "gpu_ids", "[", "0", "]", ")", "\n", "", "init_weights", "(", "net", ",", "init_type", ",", "gain", "=", "init_gain", ")", "\n", "if", "hasattr", "(", "net", ",", "'which_model_netG'", ")", ":", "\n", "        ", "if", "which_model_netG", "==", "'unbounded_stn'", "or", "which_model_netG", "==", "'bounded_stn'", "or", "which_model_netG", "==", "'affine_stn'", ":", "\n", "            ", "net", ".", "fc2", ".", "bias", ".", "data", ".", "copy_", "(", "fc2_bias", ")", "\n", "net", ".", "fc2", ".", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "return", "net", "\n", "\n", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.define_G": [[146, 163], ["networks.get_norm_layer", "networks.init_net", "networks.ResnetGenerator", "networks.ResnetGenerator", "networks.UnetGenerator", "networks.UnetGenerator", "networks.ResnetGeneratorUnit", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.init_net"], ["    ", "def", "__init__", "(", "self", ",", "n_channels", ",", "n_convs", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseBlockEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "(", "n_convs", ">", "0", ")", "\n", "\n", "self", ".", "n_channels", "=", "n_channels", "\n", "self", ".", "n_convs", "=", "n_convs", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "n_convs", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "Sequential", "(", "\n", "norm_layer", "(", "n_channels", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "Conv2d", "(", "n_channels", ",", "n_channels", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", ")", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "outputs", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "if", "i", ">", "0", ":", "\n", "                ", "next_output", "=", "0", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.getBaseGrid": [[164, 174], ["torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange.repeat", "a.repeat.t", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "grid.unsqueeze().repeat.float", "grid.unsqueeze().repeat.unsqueeze().repeat", "a.repeat.unsqueeze", "x.t.unsqueeze", "grid.unsqueeze().repeat.unsqueeze"], "function", ["None"], ["for", "no", "in", "outputs", ":", "\n", "                    ", "next_output", "=", "next_output", "+", "no", "\n", "", "outputs", ".", "append", "(", "next_output", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ".", "append", "(", "layer", "(", "inputs", ")", ")", "\n", "", "", "return", "outputs", "[", "-", "1", "]", "\n", "\n", "\n", "", "", "class", "DenseTransitionBlockEncoder", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "n_channels_in", ",", "n_channels_out", ",", "mp", ",", "activation", "=", "nn", ".", "ReLU", ",", "args", "=", "[", "False", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "DenseTransitionBlockEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.define_S": [[177, 191], ["networks.get_norm_layer", "networks.init_net", "networks.TpsGenerator", "networks.InverseTpsGenerator", "networks.StarGenerator", "networks.ParserefGenerator", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.init_net"], ["self", ".", "mp", "=", "mp", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "norm_layer", "(", "n_channels_in", ")", ",", "\n", "activation", "(", "*", "args", ")", ",", "\n", "nn", ".", "Conv2d", "(", "n_channels_in", ",", "n_channels_out", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "mp", ")", ",", "\n", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "self", ".", "main", "(", "inputs", ")", "\n", "\n", "\n", "", "", "class", "waspDenseEncoder", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "ngpu", "=", "1", ",", "nc", "=", "1", ",", "ndf", "=", "32", ",", "ndim", "=", "128", ",", "activation", "=", "nn", ".", "LeakyReLU", ",", "args", "=", "[", "0.2", ",", "False", "]", ",", "f_activation", "=", "nn", ".", "Sigmoid", ",", "f_args", "=", "[", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "super", "(", "waspDenseEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.define_D": [[193, 209], ["networks.get_norm_layer", "networks.init_net", "networks.NLayerDiscriminator", "networks.DilatedDiscriminator", "networks.NLayerDiscriminator", "networks.PixelDiscriminator", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.init_net"], ["self", ".", "ndim", "=", "ndim", "\n", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "nc", ",", "ndf", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "\n", "DenseBlockEncoder", "(", "ndf", ",", "6", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DenseTransitionBlockEncoder", "(", "ndf", ",", "ndf", "*", "2", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "DenseBlockEncoder", "(", "ndf", "*", "2", ",", "12", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DenseTransitionBlockEncoder", "(", "ndf", "*", "2", ",", "ndf", "*", "4", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "DenseBlockEncoder", "(", "ndf", "*", "4", ",", "24", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DenseTransitionBlockEncoder", "(", "ndf", "*", "4", ",", "ndf", "*", "8", ",", "2", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "\n", "DenseBlockEncoder", "(", "ndf", "*", "8", ",", "16", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "DenseTransitionBlockEncoder", "(", "ndf", "*", "8", ",", "ndim", ",", "4", ",", "activation", "=", "activation", ",", "args", "=", "args", ",", "norm_layer", "=", "norm_layer", ")", ",", "\n", "f_activation", "(", "*", "f_args", ")", ",", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.print_grad": [[417, 420], ["print", "print", "grad.data.cpu"], "function", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.spectral_norm": [[1281, 1291], ["networks.SpectralNorm.apply", "isinstance"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.SpectralNorm.apply"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.remove_spectral_norm": [[1292, 1299], ["module._forward_pre_hooks.items", "ValueError", "isinstance", "hook.remove"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.SpectralNorm.remove"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.name": [[21, 23], ["None"], "methods", ["None"], ["    ", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'ParserefGANModel'", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.modify_commandline_options": [[24, 36], ["parser.set_defaults", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", "=", "True", ")", ":", "\n", "# default DeformingGAN did not use dropout", "\n", "        ", "parser", ".", "set_defaults", "(", "no_dropout", "=", "True", ")", "\n", "if", "is_train", ":", "\n", "            ", "parser", ".", "add_argument", "(", "'--lambda_A'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'weight for cycle loss (A -> B -> A)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_B'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'weight for cycle loss (B -> A -> B)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_identity'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "'use identity mapping. Setting lambda_identity other than 0 has an effect of scaling the weight of the identity mapping loss. For example, if the weight of the identity loss should be 10 times smaller than the weight of the reconstruction loss, please set lambda_identity = 0.1'", ")", "\n", "\n", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.initialize": [[37, 122], ["base_model.BaseModel.initialize", "numpy.array", "range", "parseref_gan_model.ParserefGANModel.palette.reshape", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "coord_x.unsqueeze.unsqueeze.repeat", "coord_x.unsqueeze.unsqueeze.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "coord_y.unsqueeze.unsqueeze.repeat", "torch.t", "torch.t", "torch.t", "torch.t", "coord_y.unsqueeze.unsqueeze.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "coord_embedding.repeat.repeat.repeat", "coord_embedding.repeat.repeat.float().cuda", "networks.define_S", "networks.Discriminator", "torch.cuda.FloatTensor().fill_().to", "torch.cuda.FloatTensor().fill_().to", "torch.cuda.FloatTensor().fill_().to", "torch.cuda.FloatTensor().fill_().to", "networks.getBaseGrid().to", "networks.TotalVaryLoss", "networks.BiasReduceLoss", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "parseref_gan_model.ParserefGANModel.netG.to", "parseref_gan_model.ParserefGANModel.netD.to", "parseref_gan_model.ParserefGANModel.optimizers.append", "parseref_gan_model.ParserefGANModel.optimizers.append", "len", "numpy.append", "parseref_gan_model.ParserefGANModel.netG.parameters", "parseref_gan_model.ParserefGANModel.netD.parameters", "coord_embedding.repeat.repeat.float", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "networks.getBaseGrid", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.initialize", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.define_S", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.getBaseGrid"], ["", "def", "initialize", "(", "self", ",", "opt", ")", ":", "\n", "        ", "BaseModel", ".", "initialize", "(", "self", ",", "opt", ")", "\n", "self", ".", "palette", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "244", ",", "35", ",", "232", ",", "70", ",", "70", ",", "70", ",", "102", ",", "102", ",", "156", ",", "190", ",", "153", ",", "153", ",", "255", ",", "0", ",", "0", ",", "250", ",", "170", ",", "30", ",", "\n", "0", ",", "0", ",", "230", ",", "0", ",", "80", ",", "100", ",", "152", ",", "251", ",", "152", ",", "0", ",", "255", ",", "255", ",", "0", ",", "0", ",", "142", ",", "119", ",", "11", ",", "32", "]", ")", "\n", "zero_pad", "=", "256", "*", "3", "-", "len", "(", "self", ".", "palette", ")", "\n", "for", "i", "in", "range", "(", "zero_pad", ")", ":", "\n", "            ", "self", ".", "palette", "=", "np", ".", "append", "(", "self", ".", "palette", ",", "0", ")", "\n", "", "self", ".", "palette", "=", "self", ".", "palette", ".", "reshape", "(", "(", "256", ",", "3", ")", ")", "\n", "\n", "# Model configurations.", "\n", "self", ".", "c_dim", "=", "9", "\n", "self", ".", "image_size", "=", "64", "\n", "self", ".", "g_conv_dim", "=", "64", "\n", "self", ".", "d_conv_dim", "=", "32", "\n", "self", ".", "g_repeat_num", "=", "5", "\n", "self", ".", "d_repeat_num", "=", "3", "\n", "self", ".", "lambda_cls", "=", "1", "\n", "self", ".", "lambda_rec", "=", "10", "\n", "self", ".", "lambda_gp", "=", "10", "\n", "\n", "self", ".", "g_lr", "=", "0.0001", "\n", "self", ".", "d_lr", "=", "0.0001", "\n", "self", ".", "beta1", "=", "0.5", "\n", "self", ".", "beta2", "=", "0.999", "\n", "self", ".", "CLSloss", "=", "CrossEntropyLoss", "(", ")", "\n", "coord_x", "=", "torch", ".", "arange", "(", "64", ")", "\n", "coord_x", "=", "coord_x", ".", "repeat", "(", "64", ",", "1", ")", "\n", "coord_x", "=", "coord_x", ".", "unsqueeze", "(", "0", ")", "\n", "coord_y", "=", "torch", ".", "arange", "(", "64", ")", "\n", "coord_y", "=", "coord_y", ".", "repeat", "(", "64", ",", "1", ")", "\n", "coord_y", "=", "torch", ".", "t", "(", "coord_y", ")", "\n", "coord_y", "=", "coord_y", ".", "unsqueeze", "(", "0", ")", "\n", "coord_embedding", "=", "torch", ".", "cat", "(", "(", "coord_x", ",", "coord_y", ")", ",", "0", ")", "\n", "coord_embedding", "=", "coord_embedding", ".", "repeat", "(", "opt", ".", "batch_size", ",", "1", ",", "1", ",", "1", ")", "\n", "self", ".", "coord_embedding", "=", "coord_embedding", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "# specify the training losses you want to print out. The program will call base_model.get_current_losses", "\n", "loss_d_names", "=", "[", "'d_real'", ",", "'d_fake'", ",", "'d_gp'", "]", "\n", "loss_g_names", "=", "[", "'g_fake'", ",", "'g_rec'", ",", "'g_rec_embedding'", ",", "'g_ref'", "]", "\n", "loss_grid_names", "=", "[", "'tvw_parse_in'", ",", "'tvw_rec'", ",", "'br_parse_in'", ",", "'br_rec'", "]", "\n", "self", ".", "loss_names", "=", "loss_d_names", "+", "loss_g_names", "+", "loss_grid_names", "\n", "# specify the images you want to save/display. The program will call base_model.get_current_visuals", "\n", "visual_names_in", "=", "[", "'parse_ref_color'", ",", "'parse_in_color'", ",", "'transformed_parse_in_color'", ",", "'rec_in_color'", "]", "\n", "visual_names_grid", "=", "[", "'parse_in_color_grid'", ",", "'rec_in_color_grid'", "]", "\n", "visual_names_in_faces", "=", "[", "'parse_ref_face'", ",", "'parse_in_face'", ",", "'transformed_parse_in_face'", ",", "'rec_in_face'", "]", "\n", "visual_names_val_faces", "=", "[", "'parse_ref_color'", ",", "'parse_ref_face'", ",", "'val_in_color'", ",", "'val_in_face'", ",", "'transformed_val_in_color'", ",", "'transformed_val_in_face'", "]", "\n", "blend_visual_names_val_faces", "=", "[", "'parse_ref_A_color'", ",", "'parse_ref_A_face'", ",", "'parse_ref_B_color'", ",", "'parse_ref_B_face'", ",", "'val_in_color'", ",", "'val_in_face'", ",", "'transformed_val_in_color'", ",", "'transformed_val_in_face'", "]", "\n", "\n", "if", "opt", ".", "phase", "==", "'train'", ":", "\n", "            ", "self", ".", "visual_names", "=", "visual_names_in", "+", "visual_names_grid", "+", "visual_names_in_faces", "\n", "", "else", ":", "\n", "            ", "self", ".", "visual_names", "=", "visual_names_val_faces", "\n", "if", "opt", ".", "test_phase", "==", "'blend'", ":", "\n", "                ", "self", ".", "visual_names", "=", "blend_visual_names_val_faces", "\n", "\n", "# specify the models you want to save to the disk. The program will call base_model.save_networks and base_model.load_networks", "\n", "", "", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "model_names", "=", "[", "'G'", ",", "'D'", "]", "\n", "", "else", ":", "# during test time, only load Gs", "\n", "            ", "self", ".", "model_names", "=", "[", "'G'", "]", "\n", "\n", "# load/define networks", "\n", "", "self", ".", "netG", "=", "networks", ".", "define_S", "(", "opt", ".", "input_nc", ",", "opt", ".", "output_nc", ",", "opt", ".", "ngf", ",", "'parseref_gan'", ",", "opt", ".", "norm", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "self", ".", "netD", "=", "networks", ".", "Discriminator", "(", "opt", ".", "output_nc", ",", "self", ".", "image_size", ",", "self", ".", "d_conv_dim", ",", "self", ".", "c_dim", ",", "self", ".", "d_repeat_num", ")", "\n", "\n", "self", ".", "zeroWarp", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "1", ",", "2", ",", "64", ",", "64", ")", ".", "fill_", "(", "0", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "baseg", "=", "networks", ".", "getBaseGrid", "(", "N", "=", "64", ",", "getbatch", "=", "True", ",", "batchSize", "=", "opt", ".", "batch_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "# criteria/loss", "\n", "self", ".", "criterionTVWarp", "=", "networks", ".", "TotalVaryLoss", "(", "opt", ")", "\n", "self", ".", "criterionBiasReduce", "=", "networks", ".", "BiasReduceLoss", "(", "opt", ")", "\n", "\n", "# initialize optimizers", "\n", "\n", "self", ".", "optimizer_G", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "netG", ".", "parameters", "(", ")", ",", "self", ".", "g_lr", ",", "[", "self", ".", "beta1", ",", "self", ".", "beta2", "]", ")", "\n", "self", ".", "optimizer_D", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "netD", ".", "parameters", "(", ")", ",", "self", ".", "d_lr", ",", "[", "self", ".", "beta1", ",", "self", ".", "beta2", "]", ")", "\n", "\n", "self", ".", "netG", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "netD", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "optimizers", "=", "[", "]", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_G", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_D", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.label2onehot": [[123, 129], ["labels.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.arange", "labels.long"], "methods", ["None"], ["", "def", "label2onehot", "(", "self", ",", "labels", ",", "dim", ")", ":", "\n", "        ", "\"\"\"Convert label indices to one-hot vectors.\"\"\"", "\n", "batch_size", "=", "labels", ".", "size", "(", "0", ")", "\n", "out", "=", "torch", ".", "zeros", "(", "batch_size", ",", "dim", ")", "\n", "out", "[", "np", ".", "arange", "(", "batch_size", ")", ",", "labels", ".", "long", "(", ")", "]", "=", "1", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.gradient_penalty": [[131, 144], ["torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "dydx.view.view.view", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "dydx.view.view.size", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "y.size"], "methods", ["None"], ["", "def", "gradient_penalty", "(", "self", ",", "y", ",", "x", ")", ":", "\n", "        ", "\"\"\"Compute gradient penalty: (L2_norm(dy/dx) - 1)**2.\"\"\"", "\n", "weight", "=", "torch", ".", "ones", "(", "y", ".", "size", "(", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "dydx", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "y", ",", "\n", "inputs", "=", "x", ",", "\n", "grad_outputs", "=", "weight", ",", "\n", "retain_graph", "=", "True", ",", "\n", "create_graph", "=", "True", ",", "\n", "only_inputs", "=", "True", ")", "[", "0", "]", "\n", "\n", "dydx", "=", "dydx", ".", "view", "(", "dydx", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "dydx_l2norm", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "dydx", "**", "2", ",", "dim", "=", "1", ")", ")", "\n", "return", "torch", ".", "mean", "(", "(", "dydx_l2norm", "-", "1", ")", "**", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.reset_grad": [[145, 149], ["parseref_gan_model.ParserefGANModel.optimizer_G.zero_grad", "parseref_gan_model.ParserefGANModel.optimizer_D.zero_grad"], "methods", ["None"], ["", "def", "reset_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset the gradient buffers.\"\"\"", "\n", "self", ".", "optimizer_G", ".", "zero_grad", "(", ")", "\n", "self", ".", "optimizer_D", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.set_input": [[150, 211], ["parse_ref.to", "parse_in.to", "parse_in_face.to", "parse_ref_face.to", "val_in.to", "val_in_face.to", "[].numpy().copy", "val_in_color.transpose.transpose.transpose", "numpy.asarray", "numpy.zeros", "range", "numpy.zeros.astype", "val_in_color.transpose.transpose.transpose", "[].numpy().copy", "parse_ref_color.transpose.transpose.transpose", "numpy.asarray", "numpy.zeros", "range", "numpy.zeros.astype", "parse_ref_color.transpose.transpose.transpose", "[].numpy().copy", "parse_in_color.transpose.transpose.transpose", "numpy.asarray", "numpy.zeros", "range", "numpy.zeros.astype", "parse_in_color.transpose.transpose.transpose", "numpy.argmax", "numpy.argmax", "numpy.argmax", "[].numpy", "[].numpy", "[].numpy", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "self", ".", "image_paths", "=", "input", "[", "'val_path'", "]", "\n", "\n", "parse_ref", "=", "input", "[", "'A'", "]", "\n", "parse_ref_face", "=", "input", "[", "'A_face'", "]", "\n", "\n", "\n", "parse_in", "=", "input", "[", "'B'", "]", "\n", "parse_in_face", "=", "input", "[", "'B_face'", "]", "\n", "\n", "self", ".", "parse_ref", "=", "parse_ref", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "parse_in", "=", "parse_in", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "parse_in_face", "=", "parse_in_face", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "parse_ref_face", "=", "parse_ref_face", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "val_in", "=", "input", "[", "'val'", "]", "\n", "val_in_face", "=", "input", "[", "'val_face'", "]", "\n", "self", ".", "val_in", "=", "val_in", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "val_in_face", "=", "val_in_face", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "#  visualize the val_in", "\n", "val_in_color", "=", "input", "[", "'val'", "]", "[", "0", "]", ".", "numpy", "(", ")", ".", "copy", "(", ")", "\n", "val_in_color", "=", "val_in_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "val_in_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "val_in_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "val_in_color_numpy", "=", "np", ".", "zeros", "(", "(", "val_in_color", ".", "shape", "[", "0", "]", ",", "val_in_color", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "13", ")", ":", "\n", "            ", "val_in_color_numpy", "[", "val_in_color", "==", "i", "]", "=", "self", ".", "palette", "[", "i", "]", "\n", "", "val_in_color", "=", "val_in_color_numpy", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "val_in_color", "=", "val_in_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "val_in_color", "=", "val_in_color", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "val_in_color", "=", "(", "torch", ".", "from_numpy", "(", "val_in_color", ")", ".", "float", "(", ")", "/", "255.0", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "\n", "\n", "\n", "#  visualize the parse_ref", "\n", "parse_ref_color", "=", "input", "[", "'A'", "]", "[", "0", "]", ".", "numpy", "(", ")", ".", "copy", "(", ")", "\n", "parse_ref_color", "=", "parse_ref_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "parse_ref_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "parse_ref_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "parse_ref_color_numpy", "=", "np", ".", "zeros", "(", "(", "parse_ref_color", ".", "shape", "[", "0", "]", ",", "parse_ref_color", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "13", ")", ":", "\n", "            ", "parse_ref_color_numpy", "[", "parse_ref_color", "==", "i", "]", "=", "self", ".", "palette", "[", "i", "]", "\n", "", "parse_ref_color", "=", "parse_ref_color_numpy", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "parse_ref_color", "=", "parse_ref_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "parse_ref_color", "=", "parse_ref_color", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "parse_ref_color", "=", "(", "torch", ".", "from_numpy", "(", "parse_ref_color", ")", ".", "float", "(", ")", "/", "255.0", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "#  visualize the parse_in", "\n", "parse_in_color", "=", "input", "[", "'B'", "]", "[", "0", "]", ".", "numpy", "(", ")", ".", "copy", "(", ")", "\n", "parse_in_color", "=", "parse_in_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "parse_in_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "parse_in_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "parse_in_color_numpy", "=", "np", ".", "zeros", "(", "(", "parse_in_color", ".", "shape", "[", "0", "]", ",", "parse_in_color", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "13", ")", ":", "\n", "            ", "parse_in_color_numpy", "[", "parse_in_color", "==", "i", "]", "=", "self", ".", "palette", "[", "i", "]", "\n", "", "parse_in_color", "=", "parse_in_color_numpy", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "parse_in_color", "=", "parse_in_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "parse_in_color", "=", "parse_in_color", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "parse_in_color", "=", "(", "torch", ".", "from_numpy", "(", "parse_in_color", ")", ".", "float", "(", ")", "/", "255.0", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.set_input_val": [[214, 273], ["parse_ref.to", "parse_ref_face.to", "val_in.to", "val_in_large.to", "val_in_face.to", "[].numpy().copy", "val_in_color.transpose.transpose.transpose", "numpy.asarray", "numpy.zeros", "range", "numpy.zeros.astype", "val_in_color.transpose.transpose.transpose", "[].numpy().copy", "val_in_large_color.transpose.transpose.transpose", "numpy.asarray", "numpy.zeros", "range", "numpy.zeros.astype", "val_in_large_color.transpose.transpose.transpose", "[].numpy().copy", "parse_ref_color.transpose.transpose.transpose", "numpy.asarray", "numpy.zeros", "range", "numpy.zeros.astype", "parse_ref_color.transpose.transpose.transpose", "numpy.argmax", "numpy.argmax", "numpy.argmax", "[].numpy", "[].numpy", "[].numpy", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "def", "set_input_val", "(", "self", ",", "input", ")", ":", "\n", "        ", "self", ".", "image_paths", "=", "input", "[", "'val_path'", "]", "\n", "\n", "parse_ref", "=", "input", "[", "'A'", "]", "\n", "parse_ref_face", "=", "input", "[", "'A_face'", "]", "\n", "\n", "\n", "self", ".", "parse_ref", "=", "parse_ref", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "parse_ref_face", "=", "parse_ref_face", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "val_in", "=", "input", "[", "'val'", "]", "\n", "val_in_large", "=", "input", "[", "'val_large'", "]", "\n", "val_in_face", "=", "input", "[", "'val_face'", "]", "\n", "self", ".", "val_in", "=", "val_in", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "val_in_large", "=", "val_in_large", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "val_in_face", "=", "val_in_face", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "\n", "#  visualize the val_in", "\n", "val_in_color", "=", "input", "[", "'val'", "]", "[", "0", "]", ".", "numpy", "(", ")", ".", "copy", "(", ")", "\n", "val_in_color", "=", "val_in_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "val_in_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "val_in_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "val_in_color_numpy", "=", "np", ".", "zeros", "(", "(", "val_in_color", ".", "shape", "[", "0", "]", ",", "val_in_color", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "13", ")", ":", "\n", "            ", "val_in_color_numpy", "[", "val_in_color", "==", "i", "]", "=", "self", ".", "palette", "[", "i", "]", "\n", "", "val_in_color", "=", "val_in_color_numpy", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "val_in_color", "=", "val_in_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "val_in_color", "=", "val_in_color", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "val_in_color", "=", "(", "torch", ".", "from_numpy", "(", "val_in_color", ")", ".", "float", "(", ")", "/", "255.0", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "#  visualize the val_in", "\n", "val_in_large_color", "=", "input", "[", "'val_large'", "]", "[", "0", "]", ".", "numpy", "(", ")", ".", "copy", "(", ")", "\n", "val_in_large_color", "=", "val_in_large_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "val_in_large_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "val_in_large_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "val_in_large_color_numpy", "=", "np", ".", "zeros", "(", "(", "val_in_large_color", ".", "shape", "[", "0", "]", ",", "val_in_large_color", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "13", ")", ":", "\n", "            ", "val_in_large_color_numpy", "[", "val_in_large_color", "==", "i", "]", "=", "self", ".", "palette", "[", "i", "]", "\n", "", "val_in_large_color", "=", "val_in_large_color_numpy", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "val_in_large_color", "=", "val_in_large_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "val_in_large_color", "=", "val_in_large_color", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "val_in_large_color", "=", "(", "torch", ".", "from_numpy", "(", "val_in_large_color", ")", ".", "float", "(", ")", "/", "255.0", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "\n", "\n", "\n", "#  visualize the parse_ref", "\n", "parse_ref_color", "=", "input", "[", "'A'", "]", "[", "0", "]", ".", "numpy", "(", ")", ".", "copy", "(", ")", "\n", "parse_ref_color", "=", "parse_ref_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "parse_ref_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "parse_ref_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "parse_ref_color_numpy", "=", "np", ".", "zeros", "(", "(", "parse_ref_color", ".", "shape", "[", "0", "]", ",", "parse_ref_color", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "13", ")", ":", "\n", "            ", "parse_ref_color_numpy", "[", "parse_ref_color", "==", "i", "]", "=", "self", ".", "palette", "[", "i", "]", "\n", "", "parse_ref_color", "=", "parse_ref_color_numpy", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "parse_ref_color", "=", "parse_ref_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "parse_ref_color", "=", "parse_ref_color", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "parse_ref_color", "=", "(", "torch", ".", "from_numpy", "(", "parse_ref_color", ")", ".", "float", "(", ")", "/", "255.0", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.set_input_blend": [[276, 342], ["parse_ref_A.to", "parse_ref_B.to", "parse_ref_C.to", "parse_ref_A_face.to", "parse_ref_B_face.to", "parse_ref_C_face.to", "val_in.to", "val_in_face.to", "[].numpy().copy", "val_in_color.transpose.transpose.transpose", "numpy.asarray", "numpy.zeros", "range", "numpy.zeros.astype", "val_in_color.transpose.transpose.transpose", "[].numpy().copy", "parse_ref_A_color.transpose.transpose.transpose", "numpy.asarray", "numpy.zeros", "range", "numpy.zeros.astype", "parse_ref_A_color.transpose.transpose.transpose", "[].numpy().copy", "parse_ref_B_color.transpose.transpose.transpose", "numpy.asarray", "numpy.zeros", "range", "numpy.zeros.astype", "parse_ref_B_color.transpose.transpose.transpose", "numpy.argmax", "numpy.argmax", "numpy.argmax", "[].numpy", "[].numpy", "[].numpy", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "def", "set_input_blend", "(", "self", ",", "input", ")", ":", "\n", "        ", "self", ".", "image_paths", "=", "input", "[", "'val_path'", "]", "\n", "\n", "parse_ref_A", "=", "input", "[", "'A'", "]", "\n", "parse_ref_A_face", "=", "input", "[", "'A_face'", "]", "\n", "\n", "parse_ref_B", "=", "input", "[", "'B'", "]", "\n", "parse_ref_B_face", "=", "input", "[", "'B_face'", "]", "\n", "\n", "parse_ref_C", "=", "input", "[", "'C'", "]", "\n", "parse_ref_C_face", "=", "input", "[", "'C_face'", "]", "\n", "\n", "\n", "self", ".", "parse_ref_A", "=", "parse_ref_A", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "parse_ref_B", "=", "parse_ref_B", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "parse_ref_C", "=", "parse_ref_C", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "parse_ref_A_face", "=", "parse_ref_A_face", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "parse_ref_B_face", "=", "parse_ref_B_face", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "parse_ref_C_face", "=", "parse_ref_C_face", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "val_in", "=", "input", "[", "'val'", "]", "\n", "val_in_face", "=", "input", "[", "'val_face'", "]", "\n", "self", ".", "val_in", "=", "val_in", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "val_in_face", "=", "val_in_face", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "\n", "#  visualize the val_in", "\n", "val_in_color", "=", "input", "[", "'val'", "]", "[", "0", "]", ".", "numpy", "(", ")", ".", "copy", "(", ")", "\n", "val_in_color", "=", "val_in_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "val_in_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "val_in_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "val_in_color_numpy", "=", "np", ".", "zeros", "(", "(", "val_in_color", ".", "shape", "[", "0", "]", ",", "val_in_color", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "13", ")", ":", "\n", "            ", "val_in_color_numpy", "[", "val_in_color", "==", "i", "]", "=", "self", ".", "palette", "[", "i", "]", "\n", "", "val_in_color", "=", "val_in_color_numpy", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "val_in_color", "=", "val_in_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "val_in_color", "=", "val_in_color", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "val_in_color", "=", "(", "torch", ".", "from_numpy", "(", "val_in_color", ")", ".", "float", "(", ")", "/", "255.0", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "\n", "\n", "\n", "#  visualize the parse_ref_A", "\n", "parse_ref_A_color", "=", "input", "[", "'A'", "]", "[", "0", "]", ".", "numpy", "(", ")", ".", "copy", "(", ")", "\n", "parse_ref_A_color", "=", "parse_ref_A_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "parse_ref_A_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "parse_ref_A_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "parse_ref_A_color_numpy", "=", "np", ".", "zeros", "(", "(", "parse_ref_A_color", ".", "shape", "[", "0", "]", ",", "parse_ref_A_color", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "13", ")", ":", "\n", "            ", "parse_ref_A_color_numpy", "[", "parse_ref_A_color", "==", "i", "]", "=", "self", ".", "palette", "[", "i", "]", "\n", "", "parse_ref_A_color", "=", "parse_ref_A_color_numpy", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "parse_ref_A_color", "=", "parse_ref_A_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "parse_ref_A_color", "=", "parse_ref_A_color", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "parse_ref_A_color", "=", "(", "torch", ".", "from_numpy", "(", "parse_ref_A_color", ")", ".", "float", "(", ")", "/", "255.0", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "#  visualize the parse_ref_B", "\n", "parse_ref_B_color", "=", "input", "[", "'B'", "]", "[", "0", "]", ".", "numpy", "(", ")", ".", "copy", "(", ")", "\n", "parse_ref_B_color", "=", "parse_ref_B_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "parse_ref_B_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "parse_ref_B_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "parse_ref_B_color_numpy", "=", "np", ".", "zeros", "(", "(", "parse_ref_B_color", ".", "shape", "[", "0", "]", ",", "parse_ref_B_color", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "13", ")", ":", "\n", "            ", "parse_ref_B_color_numpy", "[", "parse_ref_B_color", "==", "i", "]", "=", "self", ".", "palette", "[", "i", "]", "\n", "", "parse_ref_B_color", "=", "parse_ref_B_color_numpy", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "parse_ref_B_color", "=", "parse_ref_B_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "parse_ref_B_color", "=", "parse_ref_B_color", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "parse_ref_B_color", "=", "(", "torch", ".", "from_numpy", "(", "parse_ref_B_color", ")", ".", "float", "(", ")", "/", "255.0", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.backward_D": [[344, 370], ["parseref_gan_model.ParserefGANModel.netD", "parseref_gan_model.ParserefGANModel.netG", "torch.grid_sample", "torch.grid_sample", "parseref_gan_model.ParserefGANModel.netD", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "parseref_gan_model.ParserefGANModel.netD", "parseref_gan_model.ParserefGANModel.gradient_penalty", "parseref_gan_model.ParserefGANModel.reset_grad", "d_loss.backward", "parseref_gan_model.ParserefGANModel.optimizer_D.step", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.grid_sample.detach", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "parseref_gan_model.ParserefGANModel.parse_ref.size"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.gradient_penalty", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.reset_grad"], ["", "def", "backward_D", "(", "self", ")", ":", "\n", "# Compute loss with real images.", "\n", "        ", "out_src", ",", "out_cls", "=", "self", ".", "netD", "(", "self", ".", "parse_ref", ")", "\n", "d_loss_real", "=", "-", "torch", ".", "mean", "(", "out_src", ")", "\n", "\n", "transformed_parse_in_Wact", "=", "self", ".", "netG", "(", "self", ".", "parse_in", ",", "self", ".", "parse_ref", ")", "\n", "x_fake", "=", "F", ".", "grid_sample", "(", "self", ".", "parse_in", ",", "transformed_parse_in_Wact", ",", "padding_mode", "=", "'border'", ")", "\n", "\n", "out_src", ",", "out_cls", "=", "self", ".", "netD", "(", "x_fake", ".", "detach", "(", ")", ")", "\n", "d_loss_fake", "=", "torch", ".", "mean", "(", "out_src", ")", "\n", "\n", "# Compute loss for gradient penalty.", "\n", "alpha", "=", "torch", ".", "rand", "(", "self", ".", "parse_ref", ".", "size", "(", "0", ")", ",", "1", ",", "1", ",", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "x_hat", "=", "(", "alpha", "*", "self", ".", "parse_ref", ".", "data", "+", "(", "1", "-", "alpha", ")", "*", "x_fake", ".", "data", ")", ".", "requires_grad_", "(", "True", ")", "\n", "out_src", ",", "_", "=", "self", ".", "netD", "(", "x_hat", ")", "\n", "d_loss_gp", "=", "self", ".", "gradient_penalty", "(", "out_src", ",", "x_hat", ")", "\n", "\n", "# Backward and optimize.", "\n", "d_loss", "=", "d_loss_real", "+", "d_loss_fake", "+", "self", ".", "lambda_gp", "*", "d_loss_gp", "\n", "self", ".", "reset_grad", "(", ")", "\n", "d_loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_D", ".", "step", "(", ")", "\n", "# Logging.", "\n", "self", ".", "loss_d_real", "=", "d_loss_real", "\n", "self", ".", "loss_d_fake", "=", "d_loss_fake", "\n", "self", ".", "loss_d_gp", "=", "d_loss_gp", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.backward_G": [[372, 586], ["parseref_gan_model.ParserefGANModel.parse_in.size", "parseref_gan_model.ParserefGANModel.netG", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "torch.upsample", "torch.upsample", "torch.grid_sample", "torch.grid_sample", "parseref_gan_model.ParserefGANModel.netG", "torch.grid_sample", "torch.grid_sample", "torch.upsample", "torch.upsample", "torch.grid_sample", "torch.grid_sample", "parseref_gan_model.ParserefGANModel.netD", "parseref_gan_model.ParserefGANModel.netG", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.upsample", "torch.upsample", "torch.grid_sample", "torch.grid_sample", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "tmp_x.unsqueeze.unsqueeze.repeat", "tmp_x.unsqueeze.unsqueeze.unsqueeze", "tmp_x.unsqueeze.unsqueeze.repeat().cuda().float", "tmp_y.unsqueeze.unsqueeze.repeat", "torch.t", "torch.t", "torch.t", "torch.t", "tmp_y.unsqueeze.unsqueeze.unsqueeze", "tmp_y.unsqueeze.unsqueeze.repeat().cuda().float", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "parseref_gan_model.ParserefGANModel.criterionTVWarp", "parseref_gan_model.ParserefGANModel.criterionTVWarp", "parseref_gan_model.ParserefGANModel.criterionBiasReduce", "parseref_gan_model.ParserefGANModel.criterionBiasReduce", "parseref_gan_model.ParserefGANModel.reset_grad", "g_loss.backward", "parseref_gan_model.ParserefGANModel.optimizer_G.step", "transformed_parse_in_Wact[].cpu().float().detach", "parseref_gan_model.ParserefGANModel.parse_in_color[].cpu().float().numpy", "PIL.Image.fromarray().convert().resize", "PIL.Image.new", "PIL.Image.new.paste", "PIL.ImageDraw.Draw", "int", "range", "source_points.view.view.view", "range", "numpy.asarray", "numpy.asarray.transpose", "torch.grid_sample.data[].cpu().numpy", "transformed_parse_in_color.transpose.transpose.transpose", "numpy.asarray", "numpy.zeros", "range", "numpy.zeros.astype", "transformed_parse_in_color.transpose.transpose.transpose", "torch.grid_sample.data[].cpu().numpy", "transformed_val_in_color.transpose.transpose.transpose", "numpy.asarray", "numpy.zeros", "range", "numpy.zeros.astype", "transformed_val_in_color.transpose.transpose.transpose", "rec_in_Wact[].cpu().float().detach", "parseref_gan_model.ParserefGANModel.transformed_parse_in_color[].cpu().float().numpy", "PIL.Image.fromarray().convert().resize", "PIL.Image.new", "PIL.Image.new.paste", "PIL.ImageDraw.Draw", "range", "source_points.view.view.view", "range", "numpy.asarray", "numpy.asarray.transpose", "torch.grid_sample.data[].cpu().numpy", "rec_in_color.transpose.transpose.transpose", "numpy.asarray", "numpy.zeros", "range", "numpy.zeros.astype", "rec_in_color.transpose.transpose.transpose", "parseref_gan_model.ParserefGANModel.permute", "torch.upsample.permute", "parseref_gan_model.ParserefGANModel.permute", "torch.upsample.permute", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "parseref_gan_model.ParserefGANModel.permute", "torch.upsample.permute", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "range", "range", "numpy.argmax", "numpy.argmax", "range", "range", "numpy.argmax", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "tmp_x.unsqueeze.unsqueeze.repeat().cuda", "tmp_y.unsqueeze.unsqueeze.repeat().cuda", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "parseref_gan_model.ParserefGANModel.permute", "parseref_gan_model.ParserefGANModel.permute", "parseref_gan_model.ParserefGANModel.permute", "parseref_gan_model.ParserefGANModel.permute", "transformed_parse_in_Wact[].cpu().float", "parseref_gan_model.ParserefGANModel.parse_in_color[].cpu().float", "PIL.Image.fromarray().convert", "PIL.ImageDraw.Draw.rectangle", "torch.grid_sample.data[].cpu", "torch.grid_sample.data[].cpu", "rec_in_Wact[].cpu().float", "parseref_gan_model.ParserefGANModel.transformed_parse_in_color[].cpu().float", "PIL.Image.fromarray().convert", "PIL.ImageDraw.Draw.rectangle", "torch.grid_sample.data[].cpu", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "PIL.ImageDraw.Draw.line", "PIL.ImageDraw.Draw.line", "PIL.ImageDraw.Draw.line", "PIL.ImageDraw.Draw.line", "tmp_x.unsqueeze.unsqueeze.repeat", "tmp_y.unsqueeze.unsqueeze.repeat", "transformed_parse_in_Wact[].cpu", "parseref_gan_model.ParserefGANModel.parse_in_color[].cpu", "PIL.Image.fromarray", "rec_in_Wact[].cpu", "parseref_gan_model.ParserefGANModel.transformed_parse_in_color[].cpu", "PIL.Image.fromarray", "parseref_gan_model.ParserefGANModel.parse_ref.size", "parseref_gan_model.ParserefGANModel.parse_ref.size", "numpy.asarray.transpose().astype", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "numpy.asarray.transpose().astype", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "numpy.asarray.transpose", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.asarray.transpose", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.reset_grad"], ["", "def", "backward_G", "(", "self", ")", ":", "\n", "        ", "batch_size", "=", "self", ".", "parse_in", ".", "size", "(", "0", ")", "\n", "coord_embedding", "=", "self", ".", "coord_embedding", "[", ":", "batch_size", "]", "\n", "\n", "transformed_parse_in_Wact", "=", "self", ".", "netG", "(", "self", ".", "parse_in", ",", "self", ".", "parse_ref", ")", "\n", "transformed_parse_in", "=", "F", ".", "grid_sample", "(", "self", ".", "parse_in", ",", "transformed_parse_in_Wact", ",", "padding_mode", "=", "'border'", ")", "\n", "transformed_parse_in_coord_embedding", "=", "F", ".", "grid_sample", "(", "coord_embedding", ",", "transformed_parse_in_Wact", ",", "padding_mode", "=", "'border'", ")", "\n", "parse_in_face_Wact", "=", "F", ".", "upsample", "(", "transformed_parse_in_Wact", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ",", "size", "=", "(", "256", ",", "256", ")", ",", "\n", "mode", "=", "'bilinear'", ")", "\n", "transformed_parse_in_face", "=", "F", ".", "grid_sample", "(", "self", ".", "parse_in_face", ",", "parse_in_face_Wact", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "\n", "transformed_val_in_Wact", "=", "self", ".", "netG", "(", "self", ".", "val_in", ",", "self", ".", "parse_ref", ")", "\n", "transformed_val_in", "=", "F", ".", "grid_sample", "(", "self", ".", "val_in", ",", "transformed_val_in_Wact", ",", "padding_mode", "=", "'border'", ")", "\n", "val_in_face_Wact", "=", "F", ".", "upsample", "(", "transformed_val_in_Wact", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ",", "size", "=", "(", "256", ",", "256", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "transformed_val_in_face", "=", "F", ".", "grid_sample", "(", "self", ".", "val_in_face", ",", "val_in_face_Wact", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "self", ".", "transformed_val_in", "=", "transformed_val_in", "\n", "self", ".", "transformed_val_in_face", "=", "transformed_val_in_face", "\n", "\n", "\n", "out_src", ",", "out_cls", "=", "self", ".", "netD", "(", "transformed_parse_in", ")", "\n", "g_loss_fake", "=", "-", "torch", ".", "mean", "(", "out_src", ")", "\n", "rec_in_Wact", "=", "self", ".", "netG", "(", "transformed_parse_in", ",", "self", ".", "parse_in", ")", "\n", "rec_in", "=", "F", ".", "grid_sample", "(", "transformed_parse_in", ",", "rec_in_Wact", ",", "padding_mode", "=", "'border'", ")", "\n", "rec_coord_embedding", "=", "F", ".", "grid_sample", "(", "transformed_parse_in_coord_embedding", ",", "\n", "rec_in_Wact", ",", "padding_mode", "=", "'border'", ")", "\n", "\n", "g_loss_rec", "=", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "self", ".", "parse_in", "-", "rec_in", ")", ")", "\n", "g_loss_rec_embedding", "=", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "coord_embedding", "-", "rec_coord_embedding", ")", ")", "\n", "rec_face_Wact", "=", "F", ".", "upsample", "(", "rec_in_Wact", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ",", "size", "=", "(", "256", ",", "256", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "rec_face", "=", "F", ".", "grid_sample", "(", "transformed_parse_in_face", ",", "rec_face_Wact", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "\n", "back_weight", "=", "torch", ".", "ones", "(", "self", ".", "parse_ref", ".", "size", "(", "0", ")", ",", "1", ",", "self", ".", "parse_ref", ".", "size", "(", "2", ")", ",", "self", ".", "parse_ref", ".", "size", "(", "3", ")", ")", "\n", "skin_weight", "=", "torch", ".", "ones", "(", "self", ".", "parse_ref", ".", "size", "(", "0", ")", ",", "1", ",", "self", ".", "parse_ref", ".", "size", "(", "2", ")", ",", "self", ".", "parse_ref", ".", "size", "(", "3", ")", ")", "\n", "#component_eye_weight = torch.ones(self.parse_ref.size(0), 4, self.parse_ref.size(2), self.parse_ref.size(3)) * 20", "\n", "component_eye_weight", "=", "torch", ".", "ones", "(", "self", ".", "parse_ref", ".", "size", "(", "0", ")", ",", "4", ",", "self", ".", "parse_ref", ".", "size", "(", "2", ")", ",", "self", ".", "parse_ref", ".", "size", "(", "3", ")", ")", "*", "10", "\n", "component_nose_weight", "=", "torch", ".", "ones", "(", "self", ".", "parse_ref", ".", "size", "(", "0", ")", ",", "1", ",", "self", ".", "parse_ref", ".", "size", "(", "2", ")", ",", "self", ".", "parse_ref", ".", "size", "(", "3", ")", ")", "*", "4", "\n", "component_up_mouth_weight", "=", "torch", ".", "ones", "(", "self", ".", "parse_ref", ".", "size", "(", "0", ")", ",", "1", ",", "self", ".", "parse_ref", ".", "size", "(", "2", ")", ",", "self", ".", "parse_ref", ".", "size", "(", "3", ")", ")", "*", "10", "\n", "component_middle_mouth_weight", "=", "torch", ".", "ones", "(", "self", ".", "parse_ref", ".", "size", "(", "0", ")", ",", "1", ",", "self", ".", "parse_ref", ".", "size", "(", "2", ")", ",", "self", ".", "parse_ref", ".", "size", "(", "3", ")", ")", "*", "2", "\n", "component_down_mouth_weight", "=", "torch", ".", "ones", "(", "self", ".", "parse_ref", ".", "size", "(", "0", ")", ",", "1", ",", "self", ".", "parse_ref", ".", "size", "(", "2", ")", ",", "self", ".", "parse_ref", ".", "size", "(", "3", ")", ")", "*", "10", "\n", "face_weight", "=", "torch", ".", "cat", "(", "(", "back_weight", ",", "skin_weight", ",", "component_eye_weight", ",", "component_nose_weight", ",", "component_up_mouth_weight", ",", "component_middle_mouth_weight", ",", "component_down_mouth_weight", ")", ",", "1", ")", ".", "cuda", "(", ")", "\n", "g_loss_ref_rec", "=", "torch", ".", "mean", "(", "face_weight", "*", "torch", ".", "abs", "(", "self", ".", "parse_ref", "-", "transformed_parse_in", ")", ")", "\n", "parse_ref_sum", "=", "F", ".", "avg_pool2d", "(", "face_weight", "*", "self", ".", "parse_ref", ",", "kernel_size", "=", "(", "self", ".", "parse_ref", ".", "size", "(", "2", ")", ",", "self", ".", "parse_ref", ".", "size", "(", "3", ")", ")", ")", "\n", "\n", "transformed_parse_in_sum", "=", "F", ".", "avg_pool2d", "(", "face_weight", "*", "transformed_parse_in", ",", "kernel_size", "=", "(", "self", ".", "parse_ref", ".", "size", "(", "2", ")", ",", "self", ".", "parse_ref", ".", "size", "(", "3", ")", ")", ")", "\n", "g_loss_ref_sum", "=", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "parse_ref_sum", "-", "transformed_parse_in_sum", ")", ")", "\n", "g_loss_ref_rec", "=", "g_loss_ref_rec", "+", "2", "*", "g_loss_ref_sum", "\n", "\n", "\n", "\n", "tmp_x", "=", "torch", ".", "arange", "(", "64", ")", "/", "64.0", "\n", "tmp_x", "=", "tmp_x", ".", "repeat", "(", "64", ",", "1", ")", "\n", "tmp_x", "=", "tmp_x", ".", "unsqueeze", "(", "0", ")", "\n", "pixel_location_x", "=", "tmp_x", ".", "repeat", "(", "self", ".", "parse_ref", ".", "size", "(", "0", ")", ",", "1", ",", "1", ",", "1", ")", ".", "cuda", "(", ")", ".", "float", "(", ")", "\n", "tmp_y", "=", "torch", ".", "arange", "(", "64", ")", "/", "64.0", "\n", "tmp_y", "=", "tmp_y", ".", "repeat", "(", "64", ",", "1", ")", "\n", "tmp_y", "=", "torch", ".", "t", "(", "tmp_y", ")", "\n", "tmp_y", "=", "tmp_y", ".", "unsqueeze", "(", "0", ")", "\n", "pixel_location_y", "=", "tmp_y", ".", "repeat", "(", "self", ".", "parse_ref", ".", "size", "(", "0", ")", ",", "1", ",", "1", ",", "1", ")", ".", "cuda", "(", ")", ".", "float", "(", ")", "\n", "\n", "parse_ref_loc_x", "=", "F", ".", "avg_pool2d", "(", "face_weight", "*", "pixel_location_x", "*", "self", ".", "parse_ref", ",", "kernel_size", "=", "(", "self", ".", "parse_ref", ".", "size", "(", "2", ")", ",", "self", ".", "parse_ref", ".", "size", "(", "3", ")", ")", ")", "\n", "parse_ref_loc_y", "=", "F", ".", "avg_pool2d", "(", "face_weight", "*", "pixel_location_y", "*", "self", ".", "parse_ref", ",", "kernel_size", "=", "(", "self", ".", "parse_ref", ".", "size", "(", "2", ")", ",", "self", ".", "parse_ref", ".", "size", "(", "3", ")", ")", ")", "\n", "transformed_parse_in_loc_x", "=", "F", ".", "avg_pool2d", "(", "face_weight", "*", "pixel_location_x", "*", "transformed_parse_in", ",", "kernel_size", "=", "(", "self", ".", "parse_ref", ".", "size", "(", "2", ")", ",", "self", ".", "parse_ref", ".", "size", "(", "3", ")", ")", ")", "\n", "transformed_parse_in_loc_y", "=", "F", ".", "avg_pool2d", "(", "face_weight", "*", "pixel_location_y", "*", "transformed_parse_in", ",", "kernel_size", "=", "(", "self", ".", "parse_ref", ".", "size", "(", "2", ")", ",", "self", ".", "parse_ref", ".", "size", "(", "3", ")", ")", ")", "\n", "g_loss_ref_loc", "=", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "parse_ref_loc_x", "-", "transformed_parse_in_loc_x", ")", ")", "\n", "g_loss_ref_loc", "=", "g_loss_ref_loc", "+", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "parse_ref_loc_y", "-", "transformed_parse_in_loc_y", ")", ")", "\n", "g_loss_ref_rec", "=", "g_loss_ref_rec", "+", "2", "*", "g_loss_ref_loc", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "tvw_weight", "=", "1e-3", "\n", "loss_tvw_parse_in", "=", "self", ".", "criterionTVWarp", "(", "transformed_parse_in_Wact", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "-", "self", ".", "baseg", "[", ":", "batch_size", "]", ",", "weight", "=", "tvw_weight", ")", "\n", "loss_tvw_rec", "=", "self", ".", "criterionTVWarp", "(", "rec_in_Wact", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "-", "self", ".", "baseg", "[", ":", "batch_size", "]", ",", "weight", "=", "tvw_weight", ")", "\n", "loss_br_parse_in", "=", "self", ".", "criterionBiasReduce", "(", "transformed_parse_in_Wact", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "-", "self", ".", "baseg", "[", ":", "batch_size", "]", ",", "\n", "self", ".", "zeroWarp", "[", ":", "batch_size", "]", ",", "weight", "=", "1", ")", "\n", "loss_br_rec", "=", "self", ".", "criterionBiasReduce", "(", "\n", "rec_in_Wact", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "-", "self", ".", "baseg", "[", ":", "batch_size", "]", ",", "self", ".", "zeroWarp", "[", ":", "batch_size", "]", ",", "weight", "=", "1", ")", "\n", "\n", "# all loss functions", "\n", "\n", "# Backward and optimize.", "\n", "self", ".", "g_loss_fake", "=", "g_loss_fake", "*", "1", "\n", "self", ".", "g_loss_rec", "=", "g_loss_rec", "*", "2", "\n", "self", ".", "g_loss_rec_embedding", "=", "g_loss_rec_embedding", "*", "2", "\n", "self", ".", "g_loss_ref", "=", "g_loss_ref_rec", "*", "500", "\n", "self", ".", "loss_tvw_parse_in", "=", "loss_tvw_parse_in", "*", "0.1", "\n", "self", ".", "loss_tvw_rec", "=", "loss_tvw_rec", "*", "0.1", "\n", "self", ".", "loss_br_parse_in", "=", "loss_br_parse_in", "\n", "self", ".", "loss_br_rec", "=", "loss_br_rec", "\n", "\n", "\n", "g_loss", "=", "self", ".", "g_loss_fake", "+", "self", ".", "lambda_rec", "*", "self", ".", "g_loss_rec", "+", "self", ".", "lambda_rec", "*", "self", ".", "g_loss_rec_embedding", "+", "self", ".", "loss_tvw_parse_in", "+", "self", ".", "loss_tvw_rec", "+", "self", ".", "loss_br_parse_in", "+", "self", ".", "loss_br_rec", "+", "self", ".", "g_loss_ref", "\n", "\n", "self", ".", "reset_grad", "(", ")", "\n", "g_loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_G", ".", "step", "(", ")", "\n", "# Logging.", "\n", "self", ".", "loss_g_fake", "=", "self", ".", "g_loss_fake", "\n", "self", ".", "loss_g_rec", "=", "self", ".", "g_loss_rec", "\n", "self", ".", "loss_g_rec_embedding", "=", "self", ".", "g_loss_rec_embedding", "\n", "self", ".", "loss_g_ref", "=", "self", ".", "g_loss_ref", "\n", "\n", "\n", "source_control_points", "=", "transformed_parse_in_Wact", "[", "0", "]", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "detach", "(", ")", "\n", "parse_in_color", "=", "self", ".", "parse_in_color", "[", "0", "]", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "\n", "parse_in_color", "=", "(", "parse_in_color", "+", "1.0", ")", "/", "2", "*", "255", "\n", "parse_in_color", "=", "Image", ".", "fromarray", "(", "parse_in_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", ".", "astype", "(", "np", ".", "uint8", ")", ")", ".", "convert", "(", "'RGB'", ")", ".", "resize", "(", "(", "128", ",", "128", ")", ")", "\n", "canvas", "=", "Image", ".", "new", "(", "mode", "=", "'RGB'", ",", "size", "=", "(", "64", "*", "4", ",", "64", "*", "4", ")", ",", "color", "=", "(", "128", ",", "128", ",", "128", ")", ")", "\n", "canvas", ".", "paste", "(", "parse_in_color", ",", "(", "64", ",", "64", ")", ")", "\n", "source_points", "=", "(", "source_control_points", "+", "1", ")", "/", "2", "*", "128", "+", "64", "\n", "draw", "=", "ImageDraw", ".", "Draw", "(", "canvas", ")", "\n", "\n", "grid_size", "=", "8", "\n", "grid_step", "=", "int", "(", "64", "/", "8", ")", "\n", "for", "j", "in", "range", "(", "grid_size", ")", ":", "\n", "            ", "for", "k", "in", "range", "(", "grid_size", ")", ":", "\n", "                ", "x", ",", "y", "=", "source_points", "[", "j", "*", "grid_step", "+", "4", "]", "[", "k", "*", "grid_step", "+", "4", "]", "\n", "draw", ".", "rectangle", "(", "[", "x", "-", "2", ",", "y", "-", "2", ",", "x", "+", "2", ",", "y", "+", "2", "]", ",", "fill", "=", "(", "255", ",", "0", ",", "0", ")", ")", "\n", "\n", "", "", "source_points", "=", "source_points", ".", "view", "(", "64", ",", "64", ",", "2", ")", "\n", "for", "j", "in", "range", "(", "grid_size", ")", ":", "\n", "            ", "for", "k", "in", "range", "(", "grid_size", ")", ":", "\n", "                ", "x1", ",", "y1", "=", "source_points", "[", "j", "*", "grid_step", "+", "4", ",", "k", "*", "grid_step", "+", "4", "]", "\n", "if", "j", ">", "0", ":", "# connect to left", "\n", "                    ", "x2", ",", "y2", "=", "source_points", "[", "(", "j", "-", "1", ")", "*", "grid_step", "+", "4", ",", "k", "*", "grid_step", "+", "4", "]", "\n", "draw", ".", "line", "(", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", ",", "fill", "=", "(", "255", ",", "0", ",", "0", ")", ")", "\n", "", "if", "k", ">", "0", ":", "# connect to up", "\n", "                    ", "x2", ",", "y2", "=", "source_points", "[", "j", "*", "grid_step", "+", "4", ",", "(", "k", "-", "1", ")", "*", "grid_step", "+", "4", "]", "\n", "draw", ".", "line", "(", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", ",", "fill", "=", "(", "255", ",", "0", ",", "0", ")", ")", "\n", "", "", "", "parse_in_color", "=", "np", ".", "asarray", "(", "canvas", ",", "np", ".", "uint8", ")", "\n", "parse_in_color_grid", "=", "parse_in_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "parse_in_color_grid", "=", "parse_in_color_grid", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "parse_in_color_grid", "=", "(", "torch", ".", "from_numpy", "(", "parse_in_color_grid", ")", ".", "float", "(", ")", "/", "255", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "# visualize the fake_B", "\n", "transformed_parse_in_color", "=", "transformed_parse_in", ".", "data", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "transformed_parse_in_color", "=", "transformed_parse_in_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "transformed_parse_in_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "transformed_parse_in_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "transformed_parse_in_color_numpy", "=", "np", ".", "zeros", "(", "(", "transformed_parse_in_color", ".", "shape", "[", "0", "]", ",", "transformed_parse_in_color", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "13", ")", ":", "\n", "            ", "transformed_parse_in_color_numpy", "[", "transformed_parse_in_color", "==", "i", "]", "=", "self", ".", "palette", "[", "i", "]", "\n", "", "transformed_parse_in_color", "=", "transformed_parse_in_color_numpy", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "transformed_parse_in_color", "=", "transformed_parse_in_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "transformed_parse_in_color", "=", "transformed_parse_in_color", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "transformed_parse_in_color", "=", "(", "torch", ".", "from_numpy", "(", "transformed_parse_in_color", ")", ".", "float", "(", ")", "/", "255", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "transformed_parse_in_face", "=", "transformed_parse_in_face", "\n", "\n", "\n", "\n", "\n", "# visualize the val fake_B", "\n", "transformed_val_in_color", "=", "transformed_val_in", ".", "data", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "transformed_val_in_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "transformed_val_in_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "transformed_val_in_color_numpy", "=", "np", ".", "zeros", "(", "(", "transformed_val_in_color", ".", "shape", "[", "0", "]", ",", "transformed_val_in_color", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "13", ")", ":", "\n", "            ", "transformed_val_in_color_numpy", "[", "transformed_val_in_color", "==", "i", "]", "=", "self", ".", "palette", "[", "i", "]", "\n", "", "transformed_val_in_color", "=", "transformed_val_in_color_numpy", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "transformed_val_in_color", "=", "(", "torch", ".", "from_numpy", "(", "transformed_val_in_color", ")", ".", "float", "(", ")", "/", "255", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "\n", "# visualize the rec_A", "\n", "\n", "source_control_points", "=", "rec_in_Wact", "[", "0", "]", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "detach", "(", ")", "\n", "real_A_color", "=", "self", ".", "transformed_parse_in_color", "[", "0", "]", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "\n", "real_A_color", "=", "(", "real_A_color", "+", "1.0", ")", "/", "2", "*", "255", "\n", "real_A_color", "=", "Image", ".", "fromarray", "(", "real_A_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", ".", "astype", "(", "np", ".", "uint8", ")", ")", ".", "convert", "(", "'RGB'", ")", ".", "resize", "(", "(", "128", ",", "128", ")", ")", "\n", "canvas", "=", "Image", ".", "new", "(", "mode", "=", "'RGB'", ",", "size", "=", "(", "64", "*", "4", ",", "64", "*", "4", ")", ",", "color", "=", "(", "128", ",", "128", ",", "128", ")", ")", "\n", "canvas", ".", "paste", "(", "real_A_color", ",", "(", "64", ",", "64", ")", ")", "\n", "source_points", "=", "(", "source_control_points", "+", "1", ")", "/", "2", "*", "128", "+", "64", "\n", "draw", "=", "ImageDraw", ".", "Draw", "(", "canvas", ")", "\n", "\n", "for", "j", "in", "range", "(", "grid_size", ")", ":", "\n", "            ", "for", "k", "in", "range", "(", "grid_size", ")", ":", "\n", "                ", "x", ",", "y", "=", "source_points", "[", "j", "*", "grid_step", "+", "4", "]", "[", "k", "*", "grid_step", "+", "4", "]", "\n", "draw", ".", "rectangle", "(", "[", "x", "-", "2", ",", "y", "-", "2", ",", "x", "+", "2", ",", "y", "+", "2", "]", ",", "fill", "=", "(", "255", ",", "0", ",", "0", ")", ")", "\n", "\n", "", "", "source_points", "=", "source_points", ".", "view", "(", "64", ",", "64", ",", "2", ")", "\n", "for", "j", "in", "range", "(", "grid_size", ")", ":", "\n", "            ", "for", "k", "in", "range", "(", "grid_size", ")", ":", "\n", "                ", "x1", ",", "y1", "=", "source_points", "[", "j", "*", "grid_step", "+", "4", ",", "k", "*", "grid_step", "+", "4", "]", "\n", "if", "j", ">", "0", ":", "# connect to left", "\n", "                    ", "x2", ",", "y2", "=", "source_points", "[", "(", "j", "-", "1", ")", "*", "grid_step", "+", "4", ",", "k", "*", "grid_step", "+", "4", "]", "\n", "draw", ".", "line", "(", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", ",", "fill", "=", "(", "255", ",", "0", ",", "0", ")", ")", "\n", "", "if", "k", ">", "0", ":", "# connect to up", "\n", "                    ", "x2", ",", "y2", "=", "source_points", "[", "j", "*", "grid_step", "+", "4", ",", "(", "k", "-", "1", ")", "*", "grid_step", "+", "4", "]", "\n", "draw", ".", "line", "(", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", ",", "fill", "=", "(", "255", ",", "0", ",", "0", ")", ")", "\n", "", "", "", "real_A_color", "=", "np", ".", "asarray", "(", "canvas", ",", "np", ".", "uint8", ")", "\n", "real_A_color_grid", "=", "real_A_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "real_A_color_grid", "=", "real_A_color_grid", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "rec_in_color_grid", "=", "(", "torch", ".", "from_numpy", "(", "real_A_color_grid", ")", ".", "float", "(", ")", "/", "255", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "\n", "# visualize the rec", "\n", "rec_in_color", "=", "rec_in", ".", "data", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "rec_in_color", "=", "rec_in_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "rec_in_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "rec_in_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "rec_in_color_numpy", "=", "np", ".", "zeros", "(", "(", "rec_in_color", ".", "shape", "[", "0", "]", ",", "rec_in_color", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "13", ")", ":", "\n", "            ", "rec_in_color_numpy", "[", "rec_in_color", "==", "i", "]", "=", "self", ".", "palette", "[", "i", "]", "\n", "", "rec_in_color", "=", "rec_in_color_numpy", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "rec_in_color", "=", "rec_in_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "rec_in_color", "=", "rec_in_color", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "rec_in_color", "=", "(", "torch", ".", "from_numpy", "(", "rec_in_color", ")", ".", "float", "(", ")", "/", "255", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "rec_in_face", "=", "rec_face", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.print_loss": [[588, 590], ["print", "parseref_gan_model.ParserefGANModel.loss_g_ref.item", "parseref_gan_model.ParserefGANModel.loss_g_rec.item", "parseref_gan_model.ParserefGANModel.loss_g_rec_embedding.item", "parseref_gan_model.ParserefGANModel.loss_g_fake.item"], "methods", ["None"], ["", "def", "print_loss", "(", "self", ")", ":", "\n", "        ", "print", "(", "self", ".", "loss_g_ref", ".", "item", "(", ")", ",", "self", ".", "loss_g_rec", ".", "item", "(", ")", ",", "self", ".", "loss_g_rec_embedding", ".", "item", "(", ")", ",", "self", ".", "loss_g_fake", ".", "item", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.optimize_parameters": [[592, 595], ["parseref_gan_model.ParserefGANModel.backward_D", "parseref_gan_model.ParserefGANModel.backward_G"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.pix2pix_model.Pix2PixModel.backward_D", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.pix2pix_model.Pix2PixModel.backward_G"], ["", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "backward_D", "(", ")", "\n", "self", ".", "backward_G", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.forward": [[598, 618], ["parseref_gan_model.ParserefGANModel.netG", "torch.grid_sample", "torch.grid_sample", "torch.upsample", "torch.upsample", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample.data[].cpu().numpy", "transformed_val_in_color.transpose.transpose.transpose", "numpy.asarray", "numpy.zeros", "range", "numpy.zeros.astype", "transformed_val_in_color.transpose.transpose.transpose", "parseref_gan_model.ParserefGANModel.permute", "torch.upsample.permute", "numpy.argmax", "torch.grid_sample.data[].cpu", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample"], ["", "def", "forward", "(", "self", ")", ":", "\n", "#self.netG.eval()", "\n", "        ", "transformed_val_in_Wact", "=", "self", ".", "netG", "(", "self", ".", "val_in", ",", "self", ".", "parse_ref", ")", "\n", "transformed_val_in", "=", "F", ".", "grid_sample", "(", "self", ".", "val_in", ",", "transformed_val_in_Wact", ",", "padding_mode", "=", "'border'", ")", "\n", "val_in_face_Wact", "=", "F", ".", "upsample", "(", "transformed_val_in_Wact", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ",", "size", "=", "(", "256", ",", "256", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "transformed_val_in_face", "=", "F", ".", "grid_sample", "(", "self", ".", "val_in_face", ",", "val_in_face_Wact", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "self", ".", "transformed_val_in", "=", "transformed_val_in", "\n", "self", ".", "transformed_val_in_face", "=", "transformed_val_in_face", "\n", "\n", "# visualize the val fake_B", "\n", "transformed_val_in_color", "=", "transformed_val_in", ".", "data", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "transformed_val_in_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "transformed_val_in_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "transformed_val_in_color_numpy", "=", "np", ".", "zeros", "(", "(", "transformed_val_in_color", ".", "shape", "[", "0", "]", ",", "transformed_val_in_color", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "13", ")", ":", "\n", "            ", "transformed_val_in_color_numpy", "[", "transformed_val_in_color", "==", "i", "]", "=", "self", ".", "palette", "[", "i", "]", "\n", "", "transformed_val_in_color", "=", "transformed_val_in_color_numpy", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "transformed_val_in_color", "=", "(", "torch", ".", "from_numpy", "(", "transformed_val_in_color", ")", ".", "float", "(", ")", "/", "255", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.test_single": [[620, 640], ["parseref_gan_model.ParserefGANModel.netG.eval", "parseref_gan_model.ParserefGANModel.netG", "torch.grid_sample", "torch.grid_sample", "torch.upsample", "torch.upsample", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample.data[].cpu().numpy", "transformed_val_in_color.transpose.transpose.transpose", "numpy.asarray", "numpy.zeros", "range", "numpy.zeros.astype", "transformed_val_in_color.transpose.transpose.transpose", "parseref_gan_model.ParserefGANModel.permute", "torch.upsample.permute", "numpy.argmax", "torch.grid_sample.data[].cpu", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.eval", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample"], ["", "def", "test_single", "(", "self", ")", ":", "\n", "        ", "self", ".", "netG", ".", "eval", "(", ")", "\n", "transformed_val_in_Wact", "=", "self", ".", "netG", "(", "self", ".", "val_in", ",", "self", ".", "parse_ref", ")", "\n", "transformed_val_in", "=", "F", ".", "grid_sample", "(", "self", ".", "val_in", ",", "transformed_val_in_Wact", ",", "padding_mode", "=", "'border'", ")", "\n", "val_in_face_Wact", "=", "F", ".", "upsample", "(", "transformed_val_in_Wact", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ",", "size", "=", "(", "256", ",", "256", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "transformed_val_in_face", "=", "F", ".", "grid_sample", "(", "self", ".", "val_in_face", ",", "val_in_face_Wact", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "self", ".", "transformed_val_in", "=", "transformed_val_in", "\n", "self", ".", "transformed_val_in_face", "=", "transformed_val_in_face", "\n", "\n", "# visualize the val fake_B", "\n", "transformed_val_in_color", "=", "transformed_val_in", ".", "data", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "transformed_val_in_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "transformed_val_in_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "transformed_val_in_color_numpy", "=", "np", ".", "zeros", "(", "(", "transformed_val_in_color", ".", "shape", "[", "0", "]", ",", "transformed_val_in_color", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "13", ")", ":", "\n", "            ", "transformed_val_in_color_numpy", "[", "transformed_val_in_color", "==", "i", "]", "=", "self", ".", "palette", "[", "i", "]", "\n", "", "transformed_val_in_color", "=", "transformed_val_in_color_numpy", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "transformed_val_in_color", "=", "(", "torch", ".", "from_numpy", "(", "transformed_val_in_color", ")", ".", "float", "(", ")", "/", "255", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.test_val": [[643, 658], ["parseref_gan_model.ParserefGANModel.netG.eval", "parseref_gan_model.ParserefGANModel.netG", "torch.grid_sample", "torch.grid_sample", "torch.upsample", "torch.upsample", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample.data[].cpu().numpy", "numpy.asarray.transpose", "numpy.asarray", "parseref_gan_model.ParserefGANModel.permute", "torch.upsample.permute", "torch.upsample.permute", "numpy.argmax", "torch.grid_sample.data[].cpu"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.eval", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample"], ["", "def", "test_val", "(", "self", ")", ":", "\n", "        ", "self", ".", "netG", ".", "eval", "(", ")", "\n", "transformed_val_in_Wact", "=", "self", ".", "netG", "(", "self", ".", "val_in", ",", "self", ".", "parse_ref", ")", "\n", "transformed_val_in", "=", "F", ".", "grid_sample", "(", "self", ".", "val_in", ",", "transformed_val_in_Wact", ",", "padding_mode", "=", "'border'", ")", "\n", "val_in_face_Wact", "=", "F", ".", "upsample", "(", "transformed_val_in_Wact", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ",", "size", "=", "(", "256", ",", "256", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "transformed_val_in_face", "=", "F", ".", "grid_sample", "(", "self", ".", "val_in_face", ",", "val_in_face_Wact", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "transformed_val_in", "=", "F", ".", "grid_sample", "(", "self", ".", "val_in_large", ",", "val_in_face_Wact", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "self", ".", "transformed_val_in", "=", "transformed_val_in", "\n", "self", ".", "transformed_val_in_face", "=", "transformed_val_in_face", "\n", "\n", "# visualize the val fake_B", "\n", "transformed_val_in_color", "=", "transformed_val_in", ".", "data", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "transformed_val_in_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "transformed_val_in_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "return", "transformed_val_in_color", ",", "transformed_val_in_face", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.test_single_control": [[659, 698], ["parseref_gan_model.ParserefGANModel.netG.eval", "parseref_gan_model.ParserefGANModel.netG", "torch.grid_sample", "torch.grid_sample", "torch.upsample", "torch.upsample", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "transformed_val_in_Wact[].cpu().float().detach", "parseref_gan_model.ParserefGANModel.val_in_large_color[].cpu().float().numpy", "PIL.Image.fromarray().convert().resize", "PIL.Image.new", "PIL.Image.new.paste", "PIL.ImageDraw.Draw", "int", "range", "source_points.view.view.view", "range", "numpy.asarray", "torch.grid_sample.data[].cpu().numpy", "numpy.asarray.transpose", "numpy.asarray", "parseref_gan_model.ParserefGANModel.permute", "torch.upsample.permute", "torch.upsample.permute", "range", "range", "numpy.argmax", "transformed_val_in_Wact[].cpu().float", "parseref_gan_model.ParserefGANModel.val_in_large_color[].cpu().float", "PIL.Image.fromarray().convert", "PIL.ImageDraw.Draw.rectangle", "torch.grid_sample.data[].cpu", "PIL.ImageDraw.Draw.line", "PIL.ImageDraw.Draw.line", "transformed_val_in_Wact[].cpu", "parseref_gan_model.ParserefGANModel.val_in_large_color[].cpu", "PIL.Image.fromarray", "PIL.Image.fromarray().convert().resize.transpose().astype", "PIL.Image.fromarray().convert().resize.transpose"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.eval", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample"], ["", "def", "test_single_control", "(", "self", ")", ":", "\n", "        ", "self", ".", "netG", ".", "eval", "(", ")", "\n", "transformed_val_in_Wact", "=", "self", ".", "netG", "(", "self", ".", "val_in", ",", "self", ".", "parse_ref", ")", "\n", "transformed_val_in", "=", "F", ".", "grid_sample", "(", "self", ".", "val_in", ",", "transformed_val_in_Wact", ",", "padding_mode", "=", "'border'", ")", "\n", "val_in_face_Wact", "=", "F", ".", "upsample", "(", "transformed_val_in_Wact", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ",", "size", "=", "(", "256", ",", "256", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "transformed_val_in_face", "=", "F", ".", "grid_sample", "(", "self", ".", "val_in_face", ",", "val_in_face_Wact", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "transformed_val_in", "=", "F", ".", "grid_sample", "(", "self", ".", "val_in_large", ",", "val_in_face_Wact", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "self", ".", "transformed_val_in", "=", "transformed_val_in", "\n", "self", ".", "transformed_val_in_face", "=", "transformed_val_in_face", "\n", "\n", "source_control_points", "=", "transformed_val_in_Wact", "[", "0", "]", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "detach", "(", ")", "\n", "parse_in_color", "=", "self", ".", "val_in_large_color", "[", "0", "]", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "\n", "parse_in_color", "=", "(", "parse_in_color", "+", "1.0", ")", "/", "2", "*", "255", "\n", "parse_in_color", "=", "Image", ".", "fromarray", "(", "parse_in_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", ".", "astype", "(", "np", ".", "uint8", ")", ")", ".", "convert", "(", "'RGB'", ")", ".", "resize", "(", "(", "256", ",", "256", ")", ")", "\n", "canvas", "=", "Image", ".", "new", "(", "mode", "=", "'RGB'", ",", "size", "=", "(", "64", "*", "4", ",", "64", "*", "4", ")", ",", "color", "=", "(", "128", ",", "128", ",", "128", ")", ")", "\n", "canvas", ".", "paste", "(", "parse_in_color", ",", "(", "0", ",", "0", ")", ")", "\n", "source_points", "=", "(", "source_control_points", "+", "1", ")", "/", "2", "*", "256", "\n", "draw", "=", "ImageDraw", ".", "Draw", "(", "canvas", ")", "\n", "grid_size", "=", "8", "\n", "grid_step", "=", "int", "(", "64", "/", "8", ")", "\n", "for", "j", "in", "range", "(", "grid_size", ")", ":", "\n", "            ", "for", "k", "in", "range", "(", "grid_size", ")", ":", "\n", "                ", "x", ",", "y", "=", "source_points", "[", "j", "*", "grid_step", "+", "4", "]", "[", "k", "*", "grid_step", "+", "4", "]", "\n", "draw", ".", "rectangle", "(", "[", "x", "-", "3", ",", "y", "-", "3", ",", "x", "+", "3", ",", "y", "+", "3", "]", ",", "fill", "=", "(", "255", ",", "0", ",", "0", ")", ")", "\n", "", "", "source_points", "=", "source_points", ".", "view", "(", "64", ",", "64", ",", "2", ")", "\n", "for", "j", "in", "range", "(", "grid_size", ")", ":", "\n", "            ", "for", "k", "in", "range", "(", "grid_size", ")", ":", "\n", "                ", "x1", ",", "y1", "=", "source_points", "[", "j", "*", "grid_step", "+", "4", ",", "k", "*", "grid_step", "+", "4", "]", "\n", "if", "j", ">", "0", ":", "# connect to left", "\n", "                    ", "x2", ",", "y2", "=", "source_points", "[", "(", "j", "-", "1", ")", "*", "grid_step", "+", "4", ",", "k", "*", "grid_step", "+", "4", "]", "\n", "draw", ".", "line", "(", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", ",", "fill", "=", "(", "255", ",", "0", ",", "0", ")", ")", "\n", "", "if", "k", ">", "0", ":", "# connect to up", "\n", "                    ", "x2", ",", "y2", "=", "source_points", "[", "j", "*", "grid_step", "+", "4", ",", "(", "k", "-", "1", ")", "*", "grid_step", "+", "4", "]", "\n", "draw", ".", "line", "(", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", ",", "fill", "=", "(", "255", ",", "0", ",", "0", ")", ")", "\n", "", "", "", "parse_in_color_grid", "=", "np", ".", "asarray", "(", "canvas", ",", "np", ".", "uint8", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in", ".", "data", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "transformed_val_in_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "transformed_val_in_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "return", "transformed_val_in_color", ",", "parse_in_color_grid", ",", "transformed_val_in_face", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.generate_feature": [[702, 723], ["parseref_gan_model.ParserefGANModel.netG.eval", "parseref_gan_model.ParserefGANModel.netG", "torch.grid_sample", "torch.grid_sample", "torch.upsample", "torch.upsample", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample.data[].cpu().numpy", "transformed_val_in_color.transpose.transpose.transpose", "numpy.asarray", "numpy.zeros", "range", "numpy.zeros.astype", "transformed_val_in_color.transpose.transpose.transpose", "transformed_val_in_Wact.permute", "torch.upsample.permute", "numpy.argmax", "torch.grid_sample.data[].cpu", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.eval", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample"], ["", "def", "generate_feature", "(", "self", ")", ":", "\n", "        ", "self", ".", "netG", ".", "eval", "(", ")", "\n", "transformed_val_in_Wact", ",", "cari_feature", "=", "self", ".", "netG", "(", "self", ".", "val_in", ",", "self", ".", "parse_ref", ")", "\n", "transformed_val_in", "=", "F", ".", "grid_sample", "(", "self", ".", "val_in", ",", "transformed_val_in_Wact", ",", "padding_mode", "=", "'border'", ")", "\n", "val_in_face_Wact", "=", "F", ".", "upsample", "(", "transformed_val_in_Wact", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ",", "size", "=", "(", "256", ",", "256", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "transformed_val_in_face", "=", "F", ".", "grid_sample", "(", "self", ".", "val_in_face", ",", "val_in_face_Wact", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "self", ".", "transformed_val_in", "=", "transformed_val_in", "\n", "self", ".", "transformed_val_in_face", "=", "transformed_val_in_face", "\n", "\n", "# visualize the val fake_B", "\n", "transformed_val_in_color", "=", "transformed_val_in", ".", "data", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "transformed_val_in_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "transformed_val_in_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "transformed_val_in_color_numpy", "=", "np", ".", "zeros", "(", "(", "transformed_val_in_color", ".", "shape", "[", "0", "]", ",", "transformed_val_in_color", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "13", ")", ":", "\n", "            ", "transformed_val_in_color_numpy", "[", "transformed_val_in_color", "==", "i", "]", "=", "self", ".", "palette", "[", "i", "]", "\n", "", "transformed_val_in_color", "=", "transformed_val_in_color_numpy", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "transformed_val_in_color", "=", "(", "torch", ".", "from_numpy", "(", "transformed_val_in_color", ")", ".", "float", "(", ")", "/", "255", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "return", "cari_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.parseref_gan_model.ParserefGANModel.test_blend": [[728, 748], ["parseref_gan_model.ParserefGANModel.netG.eval", "parseref_gan_model.ParserefGANModel.netG", "torch.grid_sample", "torch.grid_sample", "torch.upsample", "torch.upsample", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample.data[].cpu().numpy", "transformed_val_in_color.transpose.transpose.transpose", "numpy.asarray", "numpy.zeros", "range", "numpy.zeros.astype", "transformed_val_in_color.transpose.transpose.transpose", "parseref_gan_model.ParserefGANModel.permute", "torch.upsample.permute", "numpy.argmax", "torch.grid_sample.data[].cpu", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.eval", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample"], ["", "def", "test_blend", "(", "self", ")", ":", "\n", "        ", "self", ".", "netG", ".", "eval", "(", ")", "\n", "transformed_val_in_Wact", "=", "self", ".", "netG", "(", "self", ".", "val_in", ",", "self", ".", "parse_ref_A", ",", "True", ",", "True", ",", "self", ".", "parse_ref_B", ",", "self", ".", "parse_ref_C", ")", "\n", "transformed_val_in", "=", "F", ".", "grid_sample", "(", "self", ".", "val_in", ",", "transformed_val_in_Wact", ",", "padding_mode", "=", "'border'", ")", "\n", "val_in_face_Wact", "=", "F", ".", "upsample", "(", "transformed_val_in_Wact", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ",", "size", "=", "(", "256", ",", "256", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "transformed_val_in_face", "=", "F", ".", "grid_sample", "(", "self", ".", "val_in_face", ",", "val_in_face_Wact", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "self", ".", "transformed_val_in", "=", "transformed_val_in", "\n", "self", ".", "transformed_val_in_face", "=", "transformed_val_in_face", "\n", "\n", "# visualize the val fake_B", "\n", "transformed_val_in_color", "=", "transformed_val_in", ".", "data", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "transformed_val_in_color", "=", "np", ".", "asarray", "(", "np", ".", "argmax", "(", "transformed_val_in_color", ",", "axis", "=", "2", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "transformed_val_in_color_numpy", "=", "np", ".", "zeros", "(", "(", "transformed_val_in_color", ".", "shape", "[", "0", "]", ",", "transformed_val_in_color", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "i", "in", "range", "(", "13", ")", ":", "\n", "            ", "transformed_val_in_color_numpy", "[", "transformed_val_in_color", "==", "i", "]", "=", "self", ".", "palette", "[", "i", "]", "\n", "", "transformed_val_in_color", "=", "transformed_val_in_color_numpy", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "transformed_val_in_color", "=", "transformed_val_in_color", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "self", ".", "transformed_val_in_color", "=", "(", "torch", ".", "from_numpy", "(", "transformed_val_in_color", ")", ".", "float", "(", ")", "/", "255", "*", "2", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample": [[6, 15], ["torch.grid_sample", "torch.autograd.Variable", "torch.grid_sample", "input.data.new().fill_", "input.data.new", "input.size"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.grid_sample.grid_sample"], ["def", "grid_sample", "(", "input", ",", "grid", ",", "canvas", "=", "None", ")", ":", "\n", "    ", "output", "=", "F", ".", "grid_sample", "(", "input", ",", "grid", ")", "\n", "if", "canvas", "is", "None", ":", "\n", "        ", "return", "output", "\n", "", "else", ":", "\n", "        ", "input_mask", "=", "Variable", "(", "input", ".", "data", ".", "new", "(", "input", ".", "size", "(", ")", ")", ".", "fill_", "(", "1", ")", ")", "\n", "output_mask", "=", "F", ".", "grid_sample", "(", "input_mask", ",", "grid", ")", "\n", "padded_output", "=", "output", "*", "output_mask", "+", "canvas", "*", "(", "1", "-", "output_mask", ")", "\n", "return", "padded_output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.lr_scheduler.LR_Scheduler.__init__": [[29, 41], ["print"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mode", ",", "base_lr", ",", "num_epochs", ",", "iters_per_epoch", "=", "0", ",", "\n", "lr_step", "=", "0", ",", "warmup_epochs", "=", "0", ")", ":", "\n", "        ", "self", ".", "mode", "=", "mode", "\n", "print", "(", "'Using {} LR Scheduler!'", ".", "format", "(", "self", ".", "mode", ")", ")", "\n", "self", ".", "lr", "=", "base_lr", "\n", "if", "mode", "==", "'step'", ":", "\n", "            ", "assert", "lr_step", "\n", "", "self", ".", "lr_step", "=", "lr_step", "\n", "self", ".", "iters_per_epoch", "=", "iters_per_epoch", "\n", "self", ".", "N", "=", "num_epochs", "*", "iters_per_epoch", "\n", "self", ".", "epoch", "=", "-", "1", "\n", "self", ".", "warmup_iters", "=", "warmup_epochs", "*", "iters_per_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.lr_scheduler.LR_Scheduler.__call__": [[42, 61], ["lr_scheduler.LR_Scheduler._adjust_learning_rate", "print", "math.cos", "pow"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.lr_scheduler.LR_Scheduler._adjust_learning_rate"], ["", "def", "__call__", "(", "self", ",", "optimizer", ",", "i", ",", "epoch", ",", "best_pred", ")", ":", "\n", "        ", "T", "=", "epoch", "*", "self", ".", "iters_per_epoch", "+", "i", "\n", "if", "self", ".", "mode", "==", "'cos'", ":", "\n", "            ", "lr", "=", "0.5", "*", "self", ".", "lr", "*", "(", "1", "+", "math", ".", "cos", "(", "1.0", "*", "T", "/", "self", ".", "N", "*", "math", ".", "pi", ")", ")", "\n", "", "elif", "self", ".", "mode", "==", "'poly'", ":", "\n", "            ", "lr", "=", "self", ".", "lr", "*", "pow", "(", "(", "1", "-", "1.0", "*", "T", "/", "self", ".", "N", ")", ",", "0.9", ")", "\n", "", "elif", "self", ".", "mode", "==", "'step'", ":", "\n", "            ", "lr", "=", "self", ".", "lr", "*", "(", "0.1", "**", "(", "epoch", "//", "self", ".", "lr_step", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplemented", "\n", "# warm up lr schedule", "\n", "", "if", "self", ".", "warmup_iters", ">", "0", "and", "T", "<", "self", ".", "warmup_iters", ":", "\n", "            ", "lr", "=", "lr", "*", "1.0", "*", "T", "/", "self", ".", "warmup_iters", "\n", "", "if", "epoch", ">", "self", ".", "epoch", ":", "\n", "            ", "print", "(", "'\\n=>Epoches %i, learning rate = %.4f, \\\n                previous best = %.4f'", "%", "(", "epoch", ",", "lr", ",", "best_pred", ")", ")", "\n", "self", ".", "epoch", "=", "epoch", "\n", "", "assert", "lr", ">=", "0", "\n", "self", ".", "_adjust_learning_rate", "(", "optimizer", ",", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.lr_scheduler.LR_Scheduler._adjust_learning_rate": [[62, 70], ["len", "range", "len"], "methods", ["None"], ["", "def", "_adjust_learning_rate", "(", "self", ",", "optimizer", ",", "lr", ")", ":", "\n", "        ", "if", "len", "(", "optimizer", ".", "param_groups", ")", "==", "1", ":", "\n", "            ", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr", "\n", "", "else", ":", "\n", "# enlarge the lr at the head", "\n", "            ", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "optimizer", ".", "param_groups", ")", ")", ":", "\n", "                ", "optimizer", ".", "param_groups", "[", "i", "]", "[", "'lr'", "]", "=", "lr", "*", "10", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.tps_grid_gen.TPSGridGen.__init__": [[25, 61], ["torch.Module.__init__", "target_control_points.float.float.size", "target_control_points.float.float.float", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "tps_grid_gen.compute_partial_repr", "forward_kernel[].copy_", "forward_kernel[].fill_", "forward_kernel[].fill_", "forward_kernel[].copy_", "forward_kernel[].copy_", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "list", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cat.split", "torch.cat.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tps_grid_gen.compute_partial_repr", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tps_grid_gen.TPSGridGen.register_buffer", "tps_grid_gen.TPSGridGen.register_buffer", "tps_grid_gen.TPSGridGen.register_buffer", "target_control_points.float.float.ndimension", "target_control_points.float.float.size", "target_control_points.float.float.transpose", "itertools.product", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "range", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.inverse_tps_grid_gen.compute_partial_repr", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.inverse_tps_grid_gen.compute_partial_repr"], ["    ", "def", "__init__", "(", "self", ",", "target_height", ",", "target_width", ",", "target_control_points", ")", ":", "\n", "        ", "super", "(", "TPSGridGen", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "target_control_points", ".", "ndimension", "(", ")", "==", "2", "\n", "assert", "target_control_points", ".", "size", "(", "1", ")", "==", "2", "\n", "N", "=", "target_control_points", ".", "size", "(", "0", ")", "\n", "self", ".", "num_points", "=", "N", "\n", "target_control_points", "=", "target_control_points", ".", "float", "(", ")", "\n", "\n", "# create padded kernel matrix", "\n", "forward_kernel", "=", "torch", ".", "zeros", "(", "N", "+", "3", ",", "N", "+", "3", ")", "\n", "target_control_partial_repr", "=", "compute_partial_repr", "(", "target_control_points", ",", "target_control_points", ")", "\n", "forward_kernel", "[", ":", "N", ",", ":", "N", "]", ".", "copy_", "(", "target_control_partial_repr", ")", "\n", "forward_kernel", "[", ":", "N", ",", "-", "3", "]", ".", "fill_", "(", "1", ")", "\n", "forward_kernel", "[", "-", "3", ",", ":", "N", "]", ".", "fill_", "(", "1", ")", "\n", "forward_kernel", "[", ":", "N", ",", "-", "2", ":", "]", ".", "copy_", "(", "target_control_points", ")", "\n", "forward_kernel", "[", "-", "2", ":", ",", ":", "N", "]", ".", "copy_", "(", "target_control_points", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "# compute inverse matrix", "\n", "inverse_kernel", "=", "torch", ".", "inverse", "(", "forward_kernel", ")", "\n", "\n", "# create target cordinate matrix", "\n", "HW", "=", "target_height", "*", "target_width", "\n", "target_coordinate", "=", "list", "(", "itertools", ".", "product", "(", "range", "(", "target_height", ")", ",", "range", "(", "target_width", ")", ")", ")", "\n", "target_coordinate", "=", "torch", ".", "Tensor", "(", "target_coordinate", ")", "# HW x 2", "\n", "Y", ",", "X", "=", "target_coordinate", ".", "split", "(", "1", ",", "dim", "=", "1", ")", "\n", "Y", "=", "Y", "*", "2", "/", "(", "target_height", "-", "1", ")", "-", "1", "\n", "X", "=", "X", "*", "2", "/", "(", "target_width", "-", "1", ")", "-", "1", "\n", "target_coordinate", "=", "torch", ".", "cat", "(", "[", "X", ",", "Y", "]", ",", "dim", "=", "1", ")", "# convert from (y, x) to (x, y)", "\n", "target_coordinate_partial_repr", "=", "compute_partial_repr", "(", "target_coordinate", ",", "target_control_points", ")", "\n", "target_coordinate_repr", "=", "torch", ".", "cat", "(", "[", "\n", "target_coordinate_partial_repr", ",", "torch", ".", "ones", "(", "HW", ",", "1", ")", ",", "target_coordinate", "\n", "]", ",", "dim", "=", "1", ")", "\n", "\n", "# register precomputed matrices", "\n", "self", ".", "register_buffer", "(", "'inverse_kernel'", ",", "inverse_kernel", ")", "\n", "self", ".", "register_buffer", "(", "'padding_matrix'", ",", "torch", ".", "zeros", "(", "3", ",", "2", ")", ")", "\n", "self", ".", "register_buffer", "(", "'target_coordinate_repr'", ",", "target_coordinate_repr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.tps_grid_gen.TPSGridGen.forward": [[62, 72], ["source_control_points.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "source_control_points.ndimension", "source_control_points.size", "source_control_points.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "tps_grid_gen.TPSGridGen.padding_matrix.expand"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "source_control_points", ")", ":", "\n", "        ", "assert", "source_control_points", ".", "ndimension", "(", ")", "==", "3", "\n", "assert", "source_control_points", ".", "size", "(", "1", ")", "==", "self", ".", "num_points", "\n", "assert", "source_control_points", ".", "size", "(", "2", ")", "==", "2", "\n", "batch_size", "=", "source_control_points", ".", "size", "(", "0", ")", "\n", "\n", "Y", "=", "torch", ".", "cat", "(", "[", "source_control_points", ",", "Variable", "(", "self", ".", "padding_matrix", ".", "expand", "(", "batch_size", ",", "3", ",", "2", ")", ")", "]", ",", "1", ")", "\n", "mapping_matrix", "=", "torch", ".", "matmul", "(", "Variable", "(", "self", ".", "inverse_kernel", ")", ",", "Y", ")", "\n", "source_coordinate", "=", "torch", ".", "matmul", "(", "Variable", "(", "self", ".", "target_coordinate_repr", ")", ",", "mapping_matrix", ")", "\n", "return", "source_coordinate", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.tps_grid_gen.compute_partial_repr": [[9, 22], ["input_points.size", "control_points.size", "repr_matrix.masked_fill_", "input_points.view", "control_points.view", "torch.log", "torch.log"], "function", ["None"], ["def", "compute_partial_repr", "(", "input_points", ",", "control_points", ")", ":", "\n", "    ", "N", "=", "input_points", ".", "size", "(", "0", ")", "\n", "M", "=", "control_points", ".", "size", "(", "0", ")", "\n", "pairwise_diff", "=", "input_points", ".", "view", "(", "N", ",", "1", ",", "2", ")", "-", "control_points", ".", "view", "(", "1", ",", "M", ",", "2", ")", "\n", "# original implementation, very slow", "\n", "# pairwise_dist = torch.sum(pairwise_diff ** 2, dim = 2) # square of distance", "\n", "pairwise_diff_square", "=", "pairwise_diff", "*", "pairwise_diff", "\n", "pairwise_dist", "=", "pairwise_diff_square", "[", ":", ",", ":", ",", "0", "]", "+", "pairwise_diff_square", "[", ":", ",", ":", ",", "1", "]", "\n", "repr_matrix", "=", "0.5", "*", "pairwise_dist", "*", "torch", ".", "log", "(", "pairwise_dist", ")", "\n", "# fix numerical error for 0 * log(0), substitute all nan with 0", "\n", "mask", "=", "repr_matrix", "!=", "repr_matrix", "\n", "repr_matrix", ".", "masked_fill_", "(", "mask", ",", "0", ")", "\n", "return", "repr_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.__init__.find_model_using_name": [[5, 27], ["importlib.import_module", "importlib.import_module.__dict__.items", "model_name.replace", "print", "exit", "issubclass", "name.lower", "target_model_name.lower"], "function", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.__init__.get_option_setter": [[29, 33], ["__init__.find_model_using_name"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.__init__.find_model_using_name"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.__init__.create_model": [[35, 41], ["__init__.find_model_using_name", "find_model_using_name.", "model.initialize", "print", "model.name"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.__init__.find_model_using_name", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.initialize", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.parseref_dataset.ParserefDataset.name"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.inverse_tps_grid_gen.InverseTPSGridGen.__init__": [[28, 35], ["torch.Module.__init__", "inverse_tps_grid_gen.InverseTPSGridGen.register_buffer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "InverseTPSGridGen", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "\n", "\n", "# register precomputed matrices", "\n", "self", ".", "register_buffer", "(", "'padding_matrix'", ",", "torch", ".", "zeros", "(", "3", ",", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.inverse_tps_grid_gen.InverseTPSGridGen.forward": [[36, 84], ["target_control_points.float.float.size", "target_control_points.float.float.float", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "inverse_tps_grid_gen.compute_partial_repr", "forward_kernel[].copy_", "forward_kernel[].fill_", "forward_kernel[].fill_", "forward_kernel[].copy_", "forward_kernel[].copy_", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "list", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "target_coordinate.cuda.cuda.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "target_coordinate.cuda.cuda.cuda", "inverse_tps_grid_gen.compute_partial_repr", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "source_control_points.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "target_control_points.float.float.ndimension", "target_control_points.float.float.size", "target_control_points.float.float.get_device", "target_control_points.float.float.transpose", "itertools.product", "target_control_points.float.float.get_device", "target_coordinate.cuda.cuda.cuda", "source_control_points.ndimension", "source_control_points.size", "source_control_points.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "range", "target_control_points.float.float.get_device", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "inverse_tps_grid_gen.InverseTPSGridGen.padding_matrix.expand().cuda", "target_control_points.float.float.get_device", "source_control_points.get_device", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "inverse_tps_grid_gen.InverseTPSGridGen.padding_matrix.expand"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.inverse_tps_grid_gen.compute_partial_repr", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.inverse_tps_grid_gen.compute_partial_repr"], ["", "def", "forward", "(", "self", ",", "target_height", ",", "target_width", ",", "source_control_points", ",", "target_control_points", ")", ":", "\n", "        ", "assert", "target_control_points", ".", "ndimension", "(", ")", "==", "2", "\n", "assert", "target_control_points", ".", "size", "(", "1", ")", "==", "2", "\n", "N", "=", "target_control_points", ".", "size", "(", "0", ")", "\n", "self", ".", "num_points", "=", "N", "\n", "target_control_points", "=", "target_control_points", ".", "float", "(", ")", "\n", "\n", "# create padded kernel matrix", "\n", "forward_kernel", "=", "torch", ".", "zeros", "(", "N", "+", "3", ",", "N", "+", "3", ")", ".", "cuda", "(", "target_control_points", ".", "get_device", "(", ")", ")", "\n", "target_control_partial_repr", "=", "compute_partial_repr", "(", "target_control_points", ",", "target_control_points", ")", "\n", "\n", "forward_kernel", "[", ":", "N", ",", ":", "N", "]", ".", "copy_", "(", "target_control_partial_repr", ")", "\n", "forward_kernel", "[", ":", "N", ",", "-", "3", "]", ".", "fill_", "(", "1", ")", "\n", "forward_kernel", "[", "-", "3", ",", ":", "N", "]", ".", "fill_", "(", "1", ")", "\n", "forward_kernel", "[", ":", "N", ",", "-", "2", ":", "]", ".", "copy_", "(", "target_control_points", ")", "\n", "forward_kernel", "[", "-", "2", ":", ",", ":", "N", "]", ".", "copy_", "(", "target_control_points", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "\n", "# compute inverse matrix", "\n", "inverse_kernel", "=", "torch", ".", "inverse", "(", "forward_kernel", ")", "\n", "\n", "# create target cordinate matrix", "\n", "HW", "=", "target_height", "*", "target_width", "\n", "target_coordinate", "=", "list", "(", "itertools", ".", "product", "(", "range", "(", "target_height", ")", ",", "range", "(", "target_width", ")", ")", ")", "\n", "target_coordinate", "=", "torch", ".", "Tensor", "(", "target_coordinate", ")", "# HW x 2", "\n", "Y", ",", "X", "=", "target_coordinate", ".", "split", "(", "1", ",", "dim", "=", "1", ")", "\n", "Y", "=", "Y", "*", "2", "/", "(", "target_height", "-", "1", ")", "-", "1", "\n", "X", "=", "X", "*", "2", "/", "(", "target_width", "-", "1", ")", "-", "1", "\n", "target_coordinate", "=", "torch", ".", "cat", "(", "[", "X", ",", "Y", "]", ",", "dim", "=", "1", ")", "# convert from (y, x) to (x, y)", "\n", "target_coordinate", "=", "target_coordinate", ".", "cuda", "(", "target_control_points", ".", "get_device", "(", ")", ")", "\n", "target_coordinate_partial_repr", "=", "compute_partial_repr", "(", "target_coordinate", ".", "cuda", "(", "target_control_points", ".", "get_device", "(", ")", ")", ",", "target_control_points", ")", "\n", "target_coordinate_repr", "=", "torch", ".", "cat", "(", "[", "\n", "target_coordinate_partial_repr", ",", "torch", ".", "ones", "(", "HW", ",", "1", ")", ".", "cuda", "(", "target_control_points", ".", "get_device", "(", ")", ")", ",", "target_coordinate", "\n", "]", ",", "dim", "=", "1", ")", "\n", "\n", "\n", "\n", "assert", "source_control_points", ".", "ndimension", "(", ")", "==", "3", "\n", "assert", "source_control_points", ".", "size", "(", "1", ")", "==", "self", ".", "num_points", "\n", "assert", "source_control_points", ".", "size", "(", "2", ")", "==", "2", "\n", "batch_size", "=", "source_control_points", ".", "size", "(", "0", ")", "\n", "\n", "Y", "=", "torch", ".", "cat", "(", "[", "source_control_points", ",", "self", ".", "padding_matrix", ".", "expand", "(", "batch_size", ",", "3", ",", "2", ")", ".", "cuda", "(", "source_control_points", ".", "get_device", "(", ")", ")", "]", ",", "1", ")", "\n", "\n", "\n", "mapping_matrix", "=", "torch", ".", "matmul", "(", "inverse_kernel", ",", "Y", ")", "\n", "\n", "source_coordinate", "=", "torch", ".", "matmul", "(", "target_coordinate_repr", ",", "mapping_matrix", ")", "\n", "return", "source_coordinate", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.inverse_tps_grid_gen.compute_partial_repr": [[9, 21], ["input_points.size", "control_points.size", "repr_matrix.masked_fill_", "input_points.view", "control_points.view", "torch.log", "torch.log"], "function", ["None"], ["def", "compute_partial_repr", "(", "input_points", ",", "control_points", ")", ":", "\n", "    ", "N", "=", "input_points", ".", "size", "(", "0", ")", "\n", "M", "=", "control_points", ".", "size", "(", "0", ")", "\n", "pairwise_diff", "=", "input_points", ".", "view", "(", "N", ",", "1", ",", "2", ")", "-", "control_points", ".", "view", "(", "1", ",", "M", ",", "2", ")", "\n", "# original implementation, very slow", "\n", "pairwise_diff_square", "=", "pairwise_diff", "*", "pairwise_diff", "\n", "pairwise_dist", "=", "pairwise_diff_square", "[", ":", ",", ":", ",", "0", "]", "+", "pairwise_diff_square", "[", ":", ",", ":", ",", "1", "]", "\n", "repr_matrix", "=", "0.5", "*", "pairwise_dist", "*", "torch", ".", "log", "(", "pairwise_dist", "+", "0.0001", ")", "\n", "# fix numerical error for 0 * log(0), substitute all nan with 0", "\n", "mask", "=", "repr_matrix", "!=", "repr_matrix", "\n", "repr_matrix", ".", "masked_fill_", "(", "mask", ",", "0", ")", "\n", "return", "repr_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.inverse_tps_grid_gen.print_grad": [[22, 25], ["print", "print", "grad.data.cpu"], "function", ["None"], ["", "def", "print_grad", "(", "grad", ")", ":", "\n", "    ", "print", "(", "'inverse_tps_grid_gen'", ")", "\n", "print", "(", "grad", ".", "data", ".", "cpu", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.modify_commandline_options": [[11, 14], ["None"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.name": [[15, 17], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'BaseModel'", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.initialize": [[18, 30], ["os.path.join", "torch.device", "torch.device"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "gpu_ids", "=", "opt", ".", "gpu_ids", "\n", "self", ".", "isTrain", "=", "opt", ".", "isTrain", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:{}'", ".", "format", "(", "self", ".", "gpu_ids", "[", "0", "]", ")", ")", "if", "self", ".", "gpu_ids", "else", "torch", ".", "device", "(", "'cpu'", ")", "\n", "self", ".", "save_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "\n", "if", "opt", ".", "resize_or_crop", "!=", "'scale_width'", ":", "\n", "            ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "", "self", ".", "loss_names", "=", "[", "]", "\n", "self", ".", "model_names", "=", "[", "]", "\n", "self", ".", "visual_names", "=", "[", "]", "\n", "self", ".", "image_paths", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.set_input": [[31, 33], ["None"], "methods", ["None"], ["", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "self", ".", "input", "=", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.forward": [[34, 36], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.setup": [[38, 45], ["base_model.BaseModel.print_networks", "base_model.BaseModel.load_networks", "networks.get_scheduler"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.print_networks", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.load_networks", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.get_scheduler"], ["", "def", "setup", "(", "self", ",", "opt", ",", "parser", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "schedulers", "=", "[", "networks", ".", "get_scheduler", "(", "optimizer", ",", "opt", ")", "for", "optimizer", "in", "self", ".", "optimizers", "]", "\n", "\n", "", "if", "not", "self", ".", "isTrain", "or", "opt", ".", "continue_train", ":", "\n", "            ", "self", ".", "load_networks", "(", "opt", ".", "epoch", ")", "\n", "", "self", ".", "print_networks", "(", "opt", ".", "verbose", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.eval": [[47, 52], ["isinstance", "getattr", "getattr.eval"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.eval"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "net", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.test": [[55, 58], ["torch.no_grad", "base_model.BaseModel.forward"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.pix2pix_model.Pix2PixModel.forward"], ["", "", "", "def", "test", "(", "self", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "forward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.get_image_paths": [[60, 62], ["None"], "methods", ["None"], ["", "", "def", "get_image_paths", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "image_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.optimize_parameters": [[63, 65], ["None"], "methods", ["None"], ["", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.update_learning_rate": [[67, 72], ["print", "scheduler.step"], "methods", ["None"], ["", "def", "update_learning_rate", "(", "self", ")", ":", "\n", "        ", "for", "scheduler", "in", "self", ".", "schedulers", ":", "\n", "            ", "scheduler", ".", "step", "(", ")", "\n", "", "lr", "=", "self", ".", "optimizers", "[", "0", "]", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "print", "(", "'learning rate = %.7f'", "%", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.get_current_visuals": [[74, 80], ["collections.OrderedDict", "isinstance", "getattr"], "methods", ["None"], ["", "def", "get_current_visuals", "(", "self", ")", ":", "\n", "        ", "visual_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "visual_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "visual_ret", "[", "name", "]", "=", "getattr", "(", "self", ",", "name", ")", "\n", "", "", "return", "visual_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.get_current_losses": [[82, 89], ["collections.OrderedDict", "isinstance", "float", "getattr"], "methods", ["None"], ["", "def", "get_current_losses", "(", "self", ")", ":", "\n", "        ", "errors_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "loss_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "# float(...) works for both scalar tensor and float number", "\n", "                ", "errors_ret", "[", "name", "]", "=", "float", "(", "getattr", "(", "self", ",", "'loss_'", "+", "name", ")", ")", "\n", "", "", "return", "errors_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.save_networks": [[91, 104], ["isinstance", "os.path.join", "getattr", "torch.cuda.is_available", "torch.save", "getattr.cuda", "torch.save", "len", "getattr.cpu().state_dict", "getattr.cpu().state_dict", "getattr.cpu", "getattr.cpu"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.html.HTML.save"], ["", "def", "save_networks", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "save_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch", ",", "name", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "save_filename", ")", "\n", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "\n", "if", "len", "(", "self", ".", "gpu_ids", ")", ">", "0", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "#torch.save(net.module.cpu().state_dict(), save_path)", "\n", "                    ", "torch", ".", "save", "(", "net", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "net", ".", "cuda", "(", "self", ".", "gpu_ids", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "save", "(", "net", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.__patch_instance_norm_state_dict": [[105, 117], ["len", "base_model.BaseModel.__patch_instance_norm_state_dict", "module.__class__.__name__.startswith", "module.__class__.__name__.startswith", "state_dict.pop", "getattr", "getattr", "state_dict.pop"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.__patch_instance_norm_state_dict"], ["", "", "", "", "def", "__patch_instance_norm_state_dict", "(", "self", ",", "state_dict", ",", "module", ",", "keys", ",", "i", "=", "0", ")", ":", "\n", "        ", "key", "=", "keys", "[", "i", "]", "\n", "if", "i", "+", "1", "==", "len", "(", "keys", ")", ":", "# at the end, pointing to a parameter/buffer", "\n", "            ", "if", "module", ".", "__class__", ".", "__name__", ".", "startswith", "(", "'InstanceNorm'", ")", "and", "(", "key", "==", "'running_mean'", "or", "key", "==", "'running_var'", ")", ":", "\n", "                ", "if", "getattr", "(", "module", ",", "key", ")", "is", "None", ":", "\n", "                    ", "state_dict", ".", "pop", "(", "'.'", ".", "join", "(", "keys", ")", ")", "\n", "", "", "if", "module", ".", "__class__", ".", "__name__", ".", "startswith", "(", "'InstanceNorm'", ")", "and", "(", "key", "==", "'num_batches_tracked'", ")", ":", "\n", "                ", "state_dict", ".", "pop", "(", "'.'", ".", "join", "(", "keys", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "__patch_instance_norm_state_dict", "(", "state_dict", ",", "getattr", "(", "module", ",", "key", ")", ",", "keys", ",", "i", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.load_networks": [[119, 138], ["isinstance", "os.path.join", "getattr", "isinstance", "print", "torch.load", "hasattr", "list", "getattr.load_state_dict", "torch.load.keys", "base_model.BaseModel.__patch_instance_norm_state_dict", "str", "key.split"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.__patch_instance_norm_state_dict"], ["", "", "def", "load_networks", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "load_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch", ",", "name", ")", "\n", "load_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "load_filename", ")", "\n", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "if", "isinstance", "(", "net", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "                    ", "net", "=", "net", ".", "module", "\n", "", "print", "(", "'loading the model from %s'", "%", "load_path", ")", "\n", "# if you are using PyTorch newer than 0.4 (e.g., built from", "\n", "# GitHub source), you can remove str() on self.device", "\n", "state_dict", "=", "torch", ".", "load", "(", "load_path", ",", "map_location", "=", "str", "(", "self", ".", "device", ")", ")", "\n", "if", "hasattr", "(", "state_dict", ",", "'_metadata'", ")", ":", "\n", "                    ", "del", "state_dict", ".", "_metadata", "\n", "\n", "# patch InstanceNorm checkpoints prior to 0.4", "\n", "", "for", "key", "in", "list", "(", "state_dict", ".", "keys", "(", ")", ")", ":", "# need to copy keys here because we mutate in loop", "\n", "                    ", "self", ".", "__patch_instance_norm_state_dict", "(", "state_dict", ",", "net", ",", "key", ".", "split", "(", "'.'", ")", ")", "\n", "", "net", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.print_networks": [[140, 152], ["print", "print", "isinstance", "getattr", "getattr.parameters", "print", "param.numel", "print"], "methods", ["None"], ["", "", "", "def", "print_networks", "(", "self", ",", "verbose", ")", ":", "\n", "        ", "print", "(", "'---------- Networks initialized -------------'", ")", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "num_params", "=", "0", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "                    ", "num_params", "+=", "param", ".", "numel", "(", ")", "\n", "", "if", "verbose", ":", "\n", "                    ", "print", "(", "net", ")", "\n", "", "print", "(", "'[Network %s] Total number of parameters : %.3f M'", "%", "(", "name", ",", "num_params", "/", "1e6", ")", ")", "\n", "", "", "print", "(", "'-----------------------------------------------'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.set_requires_grad": [[154, 161], ["isinstance", "net.parameters"], "methods", ["None"], ["", "def", "set_requires_grad", "(", "self", ",", "nets", ",", "requires_grad", "=", "False", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "nets", ",", "list", ")", ":", "\n", "            ", "nets", "=", "[", "nets", "]", "\n", "", "for", "net", "in", "nets", ":", "\n", "            ", "if", "net", "is", "not", "None", ":", "\n", "                ", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.pix2pix_model.Pix2PixModel.name": [[8, 10], ["None"], "methods", ["None"], ["    ", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'Pix2PixModel'", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.pix2pix_model.Pix2PixModel.modify_commandline_options": [[11, 23], ["parser.set_defaults", "parser.set_defaults", "parser.set_defaults", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", "=", "True", ")", ":", "\n", "\n", "# changing the default values to match the pix2pix paper", "\n", "# (https://phillipi.github.io/pix2pix/)", "\n", "        ", "parser", ".", "set_defaults", "(", "pool_size", "=", "0", ",", "no_lsgan", "=", "True", ",", "norm", "=", "'batch'", ")", "\n", "parser", ".", "set_defaults", "(", "dataset_mode", "=", "'aligned'", ")", "\n", "parser", ".", "set_defaults", "(", "netG", "=", "'unet_256'", ")", "\n", "if", "is_train", ":", "\n", "            ", "parser", ".", "add_argument", "(", "'--lambda_L1'", ",", "type", "=", "float", ",", "default", "=", "100.0", ",", "help", "=", "'weight for L1 loss'", ")", "\n", "\n", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.pix2pix_model.Pix2PixModel.initialize": [[24, 59], ["base_model.BaseModel.initialize", "networks.define_G", "networks.define_D", "util.image_pool.ImagePool", "networks.GANLoss().to", "torch.nn.L1Loss", "torch.optim.Adam", "torch.optim.Adam", "pix2pix_model.Pix2PixModel.optimizers.append", "pix2pix_model.Pix2PixModel.optimizers.append", "pix2pix_model.Pix2PixModel.netG.parameters", "pix2pix_model.Pix2PixModel.netD.parameters", "networks.GANLoss"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.initialize", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.define_G", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.networks.define_D"], ["", "def", "initialize", "(", "self", ",", "opt", ")", ":", "\n", "        ", "BaseModel", ".", "initialize", "(", "self", ",", "opt", ")", "\n", "self", ".", "isTrain", "=", "opt", ".", "isTrain", "\n", "# specify the training losses you want to print out. The program will call base_model.get_current_losses", "\n", "self", ".", "loss_names", "=", "[", "'G_GAN'", ",", "'G_L1'", ",", "'D_real'", ",", "'D_fake'", "]", "\n", "# specify the images you want to save/display. The program will call base_model.get_current_visuals", "\n", "self", ".", "visual_names", "=", "[", "'real_A'", ",", "'fake_B'", ",", "'real_B'", "]", "\n", "# specify the models you want to save to the disk. The program will call base_model.save_networks and base_model.load_networks", "\n", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "model_names", "=", "[", "'G'", ",", "'D'", "]", "\n", "", "else", ":", "# during test time, only load Gs", "\n", "            ", "self", ".", "model_names", "=", "[", "'G'", "]", "\n", "# load/define networks", "\n", "", "self", ".", "netG", "=", "networks", ".", "define_G", "(", "opt", ".", "input_nc", ",", "opt", ".", "output_nc", ",", "opt", ".", "ngf", ",", "opt", ".", "netG", ",", "opt", ".", "norm", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "\n", "if", "self", ".", "isTrain", ":", "\n", "            ", "use_sigmoid", "=", "opt", ".", "no_lsgan", "\n", "self", ".", "netD", "=", "networks", ".", "define_D", "(", "opt", ".", "input_nc", "+", "opt", ".", "output_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "opt", ".", "n_layers_D", ",", "opt", ".", "norm", ",", "use_sigmoid", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "\n", "", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "fake_AB_pool", "=", "ImagePool", "(", "opt", ".", "pool_size", ")", "\n", "# define loss functions", "\n", "self", ".", "criterionGAN", "=", "networks", ".", "GANLoss", "(", "use_lsgan", "=", "not", "opt", ".", "no_lsgan", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "criterionL1", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "\n", "\n", "# initialize optimizers", "\n", "self", ".", "optimizers", "=", "[", "]", "\n", "self", ".", "optimizer_G", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "netG", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "self", ".", "optimizer_D", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "netD", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_G", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_D", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.pix2pix_model.Pix2PixModel.set_input": [[60, 65], ["input[].to", "input[].to"], "methods", ["None"], ["", "", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "AtoB", "=", "self", ".", "opt", ".", "direction", "==", "'AtoB'", "\n", "self", ".", "real_A", "=", "input", "[", "'A'", "if", "AtoB", "else", "'B'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "real_B", "=", "input", "[", "'B'", "if", "AtoB", "else", "'A'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "image_paths", "=", "input", "[", "'A_paths'", "if", "AtoB", "else", "'B_paths'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.pix2pix_model.Pix2PixModel.forward": [[66, 68], ["pix2pix_model.Pix2PixModel.netG"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "self", ".", "fake_B", "=", "self", ".", "netG", "(", "self", ".", "real_A", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.pix2pix_model.Pix2PixModel.backward_D": [[69, 85], ["pix2pix_model.Pix2PixModel.fake_AB_pool.query", "pix2pix_model.Pix2PixModel.netD", "pix2pix_model.Pix2PixModel.criterionGAN", "torch.cat", "pix2pix_model.Pix2PixModel.netD", "pix2pix_model.Pix2PixModel.criterionGAN", "pix2pix_model.Pix2PixModel.loss_D.backward", "torch.cat", "pix2pix_model.Pix2PixModel.detach"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.image_pool.ImagePool.query"], ["", "def", "backward_D", "(", "self", ")", ":", "\n", "# Fake", "\n", "# stop backprop to the generator by detaching fake_B", "\n", "        ", "fake_AB", "=", "self", ".", "fake_AB_pool", ".", "query", "(", "torch", ".", "cat", "(", "(", "self", ".", "real_A", ",", "self", ".", "fake_B", ")", ",", "1", ")", ")", "\n", "pred_fake", "=", "self", ".", "netD", "(", "fake_AB", ".", "detach", "(", ")", ")", "\n", "self", ".", "loss_D_fake", "=", "self", ".", "criterionGAN", "(", "pred_fake", ",", "False", ")", "\n", "\n", "# Real", "\n", "real_AB", "=", "torch", ".", "cat", "(", "(", "self", ".", "real_A", ",", "self", ".", "real_B", ")", ",", "1", ")", "\n", "pred_real", "=", "self", ".", "netD", "(", "real_AB", ")", "\n", "self", ".", "loss_D_real", "=", "self", ".", "criterionGAN", "(", "pred_real", ",", "True", ")", "\n", "\n", "# Combined loss", "\n", "self", ".", "loss_D", "=", "(", "self", ".", "loss_D_fake", "+", "self", ".", "loss_D_real", ")", "*", "0.5", "\n", "\n", "self", ".", "loss_D", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.pix2pix_model.Pix2PixModel.backward_G": [[86, 98], ["torch.cat", "pix2pix_model.Pix2PixModel.netD", "pix2pix_model.Pix2PixModel.criterionGAN", "pix2pix_model.Pix2PixModel.loss_G.backward", "pix2pix_model.Pix2PixModel.criterionL1"], "methods", ["None"], ["", "def", "backward_G", "(", "self", ")", ":", "\n", "# First, G(A) should fake the discriminator", "\n", "        ", "fake_AB", "=", "torch", ".", "cat", "(", "(", "self", ".", "real_A", ",", "self", ".", "fake_B", ")", ",", "1", ")", "\n", "pred_fake", "=", "self", ".", "netD", "(", "fake_AB", ")", "\n", "self", ".", "loss_G_GAN", "=", "self", ".", "criterionGAN", "(", "pred_fake", ",", "True", ")", "\n", "\n", "# Second, G(A) = B", "\n", "self", ".", "loss_G_L1", "=", "self", ".", "criterionL1", "(", "self", ".", "fake_B", ",", "self", ".", "real_B", ")", "*", "self", ".", "opt", ".", "lambda_L1", "\n", "\n", "self", ".", "loss_G", "=", "self", ".", "loss_G_GAN", "+", "self", ".", "loss_G_L1", "\n", "\n", "self", ".", "loss_G", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.pix2pix_model.Pix2PixModel.optimize_parameters": [[99, 112], ["pix2pix_model.Pix2PixModel.forward", "pix2pix_model.Pix2PixModel.set_requires_grad", "pix2pix_model.Pix2PixModel.optimizer_D.zero_grad", "pix2pix_model.Pix2PixModel.backward_D", "pix2pix_model.Pix2PixModel.optimizer_D.step", "pix2pix_model.Pix2PixModel.set_requires_grad", "pix2pix_model.Pix2PixModel.optimizer_G.zero_grad", "pix2pix_model.Pix2PixModel.backward_G", "pix2pix_model.Pix2PixModel.optimizer_G.step"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.pix2pix_model.Pix2PixModel.forward", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.pix2pix_model.Pix2PixModel.backward_D", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.models.pix2pix_model.Pix2PixModel.backward_G"], ["", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "forward", "(", ")", "\n", "# update D", "\n", "self", ".", "set_requires_grad", "(", "self", ".", "netD", ",", "True", ")", "\n", "self", ".", "optimizer_D", ".", "zero_grad", "(", ")", "\n", "self", ".", "backward_D", "(", ")", "\n", "self", ".", "optimizer_D", ".", "step", "(", ")", "\n", "\n", "# update G", "\n", "self", ".", "set_requires_grad", "(", "self", ".", "netD", ",", "False", ")", "\n", "self", ".", "optimizer_G", ".", "zero_grad", "(", ")", "\n", "self", ".", "backward_G", "(", ")", "\n", "self", ".", "optimizer_G", ".", "step", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.BaseDataset.__init__": [[7, 9], ["torch.Dataset.__init__"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "BaseDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.BaseDataset.name": [[10, 12], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'BaseDataset'", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.BaseDataset.modify_commandline_options": [[13, 16], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.BaseDataset.initialize": [[17, 19], ["None"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "opt", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.BaseDataset.__len__": [[20, 22], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.get_transform": [[24, 53], ["torchvision.Compose", "transform_list.append", "transform_list.append", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Resize", "torchvision.RandomCrop", "transform_list.append", "torchvision.RandomCrop", "transform_list.append", "torchvision.Lambda", "transform_list.append", "transform_list.append", "torchvision.Lambda", "torchvision.RandomCrop", "transform_list.append", "ValueError", "base_dataset.__scale_width", "torchvision.Lambda", "base_dataset.__scale_width", "base_dataset.__adjust"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__scale_width", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__scale_width", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__adjust"], ["", "", "def", "get_transform", "(", "opt", ")", ":", "\n", "    ", "transform_list", "=", "[", "]", "\n", "if", "opt", ".", "resize_or_crop", "==", "'resize_and_crop'", ":", "\n", "        ", "osize", "=", "[", "opt", ".", "loadSize", ",", "opt", ".", "loadSize", "]", "\n", "transform_list", ".", "append", "(", "transforms", ".", "Resize", "(", "osize", ",", "Image", ".", "BICUBIC", ")", ")", "\n", "transform_list", ".", "append", "(", "transforms", ".", "RandomCrop", "(", "opt", ".", "fineSize", ")", ")", "\n", "", "elif", "opt", ".", "resize_or_crop", "==", "'crop'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "RandomCrop", "(", "opt", ".", "fineSize", ")", ")", "\n", "", "elif", "opt", ".", "resize_or_crop", "==", "'scale_width'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "\n", "lambda", "img", ":", "__scale_width", "(", "img", ",", "opt", ".", "fineSize", ")", ")", ")", "\n", "", "elif", "opt", ".", "resize_or_crop", "==", "'scale_width_and_crop'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "\n", "lambda", "img", ":", "__scale_width", "(", "img", ",", "opt", ".", "loadSize", ")", ")", ")", "\n", "transform_list", ".", "append", "(", "transforms", ".", "RandomCrop", "(", "opt", ".", "fineSize", ")", ")", "\n", "", "elif", "opt", ".", "resize_or_crop", "==", "'none'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "\n", "lambda", "img", ":", "__adjust", "(", "img", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'--resize_or_crop %s is not a valid option.'", "%", "opt", ".", "resize_or_crop", ")", "\n", "\n", "# Todo: implement flip for face", "\n", "#if opt.isTrain and not opt.no_flip:", "\n", "#    transform_list.append(transforms.RandomHorizontalFlip())", "\n", "\n", "", "transform_list", "+=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "\n", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "]", "\n", "return", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.get_target_transform": [[54, 81], ["torchvision.Compose", "transform_list.append", "transform_list.append", "transform_list.append", "torchvision.ToTensor", "torchvision.Resize", "torchvision.RandomCrop", "transform_list.append", "torchvision.RandomHorizontalFlip", "torchvision.RandomCrop", "transform_list.append", "torchvision.Lambda", "transform_list.append", "transform_list.append", "torchvision.Lambda", "torchvision.RandomCrop", "transform_list.append", "ValueError", "base_dataset.__scale_width", "torchvision.Lambda", "base_dataset.__scale_width", "base_dataset.__adjust"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__scale_width", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__scale_width", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__adjust"], ["", "def", "get_target_transform", "(", "opt", ")", ":", "\n", "    ", "transform_list", "=", "[", "]", "\n", "if", "opt", ".", "resize_or_crop", "==", "'resize_and_crop'", ":", "\n", "        ", "osize", "=", "[", "opt", ".", "loadSize", ",", "opt", ".", "loadSize", "]", "\n", "transform_list", ".", "append", "(", "transforms", ".", "Resize", "(", "osize", ",", "Image", ".", "BICUBIC", ")", ")", "\n", "transform_list", ".", "append", "(", "transforms", ".", "RandomCrop", "(", "opt", ".", "fineSize", ")", ")", "\n", "", "elif", "opt", ".", "resize_or_crop", "==", "'crop'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "RandomCrop", "(", "opt", ".", "fineSize", ")", ")", "\n", "", "elif", "opt", ".", "resize_or_crop", "==", "'scale_width'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "\n", "lambda", "img", ":", "__scale_width", "(", "img", ",", "opt", ".", "fineSize", ")", ")", ")", "\n", "", "elif", "opt", ".", "resize_or_crop", "==", "'scale_width_and_crop'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "\n", "lambda", "img", ":", "__scale_width", "(", "img", ",", "opt", ".", "loadSize", ")", ")", ")", "\n", "transform_list", ".", "append", "(", "transforms", ".", "RandomCrop", "(", "opt", ".", "fineSize", ")", ")", "\n", "", "elif", "opt", ".", "resize_or_crop", "==", "'none'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "\n", "lambda", "img", ":", "__adjust", "(", "img", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'--resize_or_crop %s is not a valid option.'", "%", "opt", ".", "resize_or_crop", ")", "\n", "\n", "# Todo: implement flip for face", "\n", "", "if", "opt", ".", "isTrain", "and", "not", "opt", ".", "no_flip", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "RandomHorizontalFlip", "(", ")", ")", "\n", "\n", "", "transform_list", "+=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "]", "\n", "return", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__adjust": [[84, 102], ["img.resize", "base_dataset.__print_size_warning"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__print_size_warning"], ["", "def", "__adjust", "(", "img", ")", ":", "\n", "    ", "ow", ",", "oh", "=", "img", ".", "size", "\n", "\n", "# the size needs to be a multiple of this number,", "\n", "# because going through generator network may change img size", "\n", "# and eventually cause size mismatch error", "\n", "mult", "=", "4", "\n", "if", "ow", "%", "mult", "==", "0", "and", "oh", "%", "mult", "==", "0", ":", "\n", "        ", "return", "img", "\n", "", "w", "=", "(", "ow", "-", "1", ")", "//", "mult", "\n", "w", "=", "(", "w", "+", "1", ")", "*", "mult", "\n", "h", "=", "(", "oh", "-", "1", ")", "//", "mult", "\n", "h", "=", "(", "h", "+", "1", ")", "*", "mult", "\n", "\n", "if", "ow", "!=", "w", "or", "oh", "!=", "h", ":", "\n", "        ", "__print_size_warning", "(", "ow", ",", "oh", ",", "w", ",", "h", ")", "\n", "\n", "", "return", "img", ".", "resize", "(", "(", "w", ",", "h", ")", ",", "Image", ".", "BICUBIC", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__scale_width": [[104, 123], ["int", "img.resize", "base_dataset.__print_size_warning"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__print_size_warning"], ["", "def", "__scale_width", "(", "img", ",", "target_width", ")", ":", "\n", "    ", "ow", ",", "oh", "=", "img", ".", "size", "\n", "\n", "# the size needs to be a multiple of this number,", "\n", "# because going through generator network may change img size", "\n", "# and eventually cause size mismatch error", "\n", "mult", "=", "4", "\n", "assert", "target_width", "%", "mult", "==", "0", ",", "\"the target width needs to be multiple of %d.\"", "%", "mult", "\n", "if", "(", "ow", "==", "target_width", "and", "oh", "%", "mult", "==", "0", ")", ":", "\n", "        ", "return", "img", "\n", "", "w", "=", "target_width", "\n", "target_height", "=", "int", "(", "target_width", "*", "oh", "/", "ow", ")", "\n", "m", "=", "(", "target_height", "-", "1", ")", "//", "mult", "\n", "h", "=", "(", "m", "+", "1", ")", "*", "mult", "\n", "\n", "if", "target_height", "!=", "h", ":", "\n", "        ", "__print_size_warning", "(", "target_width", ",", "target_height", ",", "w", ",", "h", ")", "\n", "\n", "", "return", "img", ".", "resize", "(", "(", "w", ",", "h", ")", ",", "Image", ".", "BICUBIC", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.__print_size_warning": [[125, 132], ["hasattr", "print"], "function", ["None"], ["", "def", "__print_size_warning", "(", "ow", ",", "oh", ",", "w", ",", "h", ")", ":", "\n", "    ", "if", "not", "hasattr", "(", "__print_size_warning", ",", "'has_printed'", ")", ":", "\n", "        ", "print", "(", "\"The image size needs to be a multiple of 4. \"", "\n", "\"The loaded image size was (%d, %d), so it was adjusted to \"", "\n", "\"(%d, %d). This adjustment will be done to all images \"", "\n", "\"whose sizes are not multiples of 4\"", "%", "(", "ow", ",", "oh", ",", "w", ",", "h", ")", ")", "\n", "__print_size_warning", ".", "has_printed", "=", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.image_folder.ImageFolder.__init__": [[43, 56], ["image_folder.make_dataset", "len", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.image_folder.make_dataset"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "transform", "=", "None", ",", "return_paths", "=", "False", ",", "\n", "loader", "=", "default_loader", ")", ":", "\n", "        ", "imgs", "=", "make_dataset", "(", "root", ")", "\n", "if", "len", "(", "imgs", ")", "==", "0", ":", "\n", "            ", "raise", "(", "RuntimeError", "(", "\"Found 0 images in: \"", "+", "root", "+", "\"\\n\"", "\n", "\"Supported image extensions are: \"", "+", "\n", "\",\"", ".", "join", "(", "IMG_EXTENSIONS", ")", ")", ")", "\n", "\n", "", "self", ".", "root", "=", "root", "\n", "self", ".", "imgs", "=", "imgs", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "return_paths", "=", "return_paths", "\n", "self", ".", "loader", "=", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.image_folder.ImageFolder.__getitem__": [[57, 66], ["image_folder.ImageFolder.loader", "image_folder.ImageFolder.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "imgs", "[", "index", "]", "\n", "img", "=", "self", ".", "loader", "(", "path", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "if", "self", ".", "return_paths", ":", "\n", "            ", "return", "img", ",", "path", "\n", "", "else", ":", "\n", "            ", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.image_folder.ImageFolder.__len__": [[67, 69], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "imgs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.image_folder.is_image_file": [[20, 22], ["any", "filename.endswith"], "function", ["None"], ["def", "is_image_file", "(", "filename", ")", ":", "\n", "    ", "return", "any", "(", "filename", ".", "endswith", "(", "extension", ")", "for", "extension", "in", "IMG_EXTENSIONS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.image_folder.make_dataset": [[24, 35], ["os.path.isdir", "os.path.isdir", "sorted", "os.walk", "os.walk", "image_folder.is_image_file", "os.path.join", "os.path.join", "images.append"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.image_folder.is_image_file"], ["", "def", "make_dataset", "(", "dir", ")", ":", "\n", "    ", "images", "=", "[", "]", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "dir", ")", ",", "'%s is not a valid directory'", "%", "dir", "\n", "\n", "for", "root", ",", "_", ",", "fnames", "in", "sorted", "(", "os", ".", "walk", "(", "dir", ")", ")", ":", "\n", "        ", "for", "fname", "in", "fnames", ":", "\n", "            ", "if", "is_image_file", "(", "fname", ")", ":", "\n", "                ", "path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "fname", ")", "\n", "images", ".", "append", "(", "path", ")", "\n", "\n", "", "", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.image_folder.default_loader": [[37, 39], ["PIL.Image.open().convert", "PIL.Image.open"], "function", ["None"], ["", "def", "default_loader", "(", "path", ")", ":", "\n", "    ", "return", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.__init__.CustomDatasetDataLoader.name": [[53, 55], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.__init__.CustomDatasetDataLoader.initialize": [[56, 64], ["data.base_data_loader.BaseDataLoader.initialize", "__init__.create_dataset", "torch.utils.data.DataLoader", "int"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.initialize", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.__init__.create_dataset"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.__init__.CustomDatasetDataLoader.load_data": [[65, 67], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.__init__.CustomDatasetDataLoader.__len__": [[68, 70], ["min", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.__init__.CustomDatasetDataLoader.__iter__": [[71, 76], ["enumerate"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.__init__.find_dataset_using_name": [[7, 29], ["importlib.import_module", "importlib.import_module.__dict__.items", "dataset_name.replace", "print", "exit", "issubclass", "name.lower", "target_dataset_name.lower"], "function", ["None"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.__init__.get_option_setter": [[31, 34], ["__init__.find_dataset_using_name"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.__init__.find_dataset_using_name"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.__init__.create_dataset": [[36, 42], ["__init__.find_dataset_using_name", "find_dataset_using_name.", "dataset.initialize", "print", "dataset.name"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.__init__.find_dataset_using_name", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.initialize", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.parseref_dataset.ParserefDataset.name"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.__init__.CreateDataLoader": [[44, 48], ["__init__.CustomDatasetDataLoader", "__init__.CustomDatasetDataLoader.initialize"], "function", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.initialize"], []], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_data_loader.BaseDataLoader.__init__": [[2, 4], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_data_loader.BaseDataLoader.initialize": [[5, 8], ["None"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_data_loader.BaseDataLoader.load_data": [[9, 11], ["None"], "methods", ["None"], ["", "def", "load_data", "(", ")", ":", "\n", "        ", "return", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.parseref_dataset.ParserefDataset.modify_commandline_options": [[25, 28], ["None"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.parseref_dataset.ParserefDataset.initialize": [[29, 49], ["os.path.join", "data.image_folder.make_dataset", "sorted", "len", "data.image_folder.make_dataset", "sorted", "len", "data.image_folder.make_dataset", "sorted", "len", "data.base_dataset.get_transform", "data.base_dataset.get_target_transform", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.image_folder.make_dataset", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.image_folder.make_dataset", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.image_folder.make_dataset", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.get_transform", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.base_dataset.get_target_transform"], ["", "def", "initialize", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "root", "=", "opt", ".", "dataroot", "\n", "\n", "self", ".", "dir_val", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "dataroot", ",", "'val'", ")", "\n", "self", ".", "val_path", "=", "make_dataset", "(", "self", ".", "dir_val", ")", "\n", "self", ".", "val_paths", "=", "sorted", "(", "self", ".", "val_path", ")", "\n", "self", ".", "val_size", "=", "len", "(", "self", ".", "val_path", ")", "\n", "\n", "self", ".", "A_path", "=", "make_dataset", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "dataroot", ",", "opt", ".", "phase", "+", "'A'", ")", ")", "\n", "self", ".", "A_path", "=", "sorted", "(", "self", ".", "A_path", ")", "\n", "self", ".", "A_size", "=", "len", "(", "self", ".", "A_path", ")", "\n", "\n", "self", ".", "B_path", "=", "make_dataset", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "dataroot", ",", "opt", ".", "phase", "+", "'B'", ")", ")", "\n", "self", ".", "B_path", "=", "sorted", "(", "self", ".", "B_path", ")", "\n", "self", ".", "B_size", "=", "len", "(", "self", ".", "B_path", ")", "\n", "\n", "\n", "self", ".", "transform", "=", "get_transform", "(", "opt", ")", "\n", "self", ".", "target_transform", "=", "get_target_transform", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.parseref_dataset.ParserefDataset.__getitem__": [[50, 104], ["A_path.replace", "A_face_path.replace.replace.replace", "B_path.replace", "B_face_path.replace.replace.replace", "val_path.replace", "val_path_face.replace.replace.replace", "PIL.Image.open().convert", "PIL.Image.open().convert", "PIL.Image.open", "channel_1toN.resize", "parseref_dataset.channel_1toN", "parseref_dataset.ParserefDataset.transform", "PIL.Image.open", "channel_1toN.resize", "parseref_dataset.channel_1toN", "PIL.Image.open().convert", "parseref_dataset.ParserefDataset.transform", "PIL.Image.open", "channel_1toN.resize", "parseref_dataset.channel_1toN", "parseref_dataset.ParserefDataset.transform", "random.randint", "random.randint", "random.randint", "PIL.Image.open", "PIL.Image.open", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.parseref_dataset.channel_1toN", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.parseref_dataset.channel_1toN", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.parseref_dataset.channel_1toN"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "\n", "        ", "if", "self", ".", "opt", ".", "serial_batches", ":", "\n", "            ", "index_A", "=", "index", "%", "self", ".", "A_size", "\n", "", "else", ":", "\n", "            ", "index_A", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "A_size", "-", "1", ")", "\n", "", "A_path", "=", "self", ".", "A_path", "[", "index_A", "]", "\n", "A_face_path", "=", "A_path", ".", "replace", "(", "'.png'", ",", "'.jpg'", ")", "\n", "A_face_path", "=", "A_face_path", ".", "replace", "(", "'train'", ",", "'face'", ")", "\n", "\n", "\n", "\n", "\n", "if", "self", ".", "opt", ".", "serial_batches", ":", "\n", "            ", "index_B", "=", "index", "%", "self", ".", "B_size", "\n", "", "else", ":", "\n", "            ", "index_B", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "B_size", "-", "1", ")", "\n", "", "B_path", "=", "self", ".", "B_path", "[", "index_B", "]", "\n", "B_face_path", "=", "B_path", ".", "replace", "(", "'.png'", ",", "'.jpg'", ")", "\n", "B_face_path", "=", "B_face_path", ".", "replace", "(", "'train'", ",", "'face'", ")", "\n", "\n", "\n", "\n", "if", "self", ".", "opt", ".", "serial_batches", ":", "\n", "            ", "index_val", "=", "index", "%", "self", ".", "val_size", "\n", "", "else", ":", "\n", "            ", "index_val", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "val_size", "-", "1", ")", "\n", "", "val_path", "=", "self", ".", "val_paths", "[", "index_val", "]", "\n", "val_path_face", "=", "val_path", ".", "replace", "(", "'.png'", ",", "'.jpg'", ")", "\n", "val_path_face", "=", "val_path_face", ".", "replace", "(", "'val'", ",", "'face'", ")", "\n", "\n", "\n", "A_img_face", "=", "Image", ".", "open", "(", "A_face_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "val_img_face", "=", "Image", ".", "open", "(", "val_path_face", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n", "A", "=", "Image", ".", "open", "(", "A_path", ")", "\n", "A", "=", "A", ".", "resize", "(", "(", "64", ",", "64", ")", ",", "Image", ".", "NEAREST", ")", "\n", "A", "=", "channel_1toN", "(", "A", ",", "self", ".", "opt", ".", "output_nc", ")", "\n", "A_face", "=", "self", ".", "transform", "(", "A_img_face", ")", "\n", "\n", "B", "=", "Image", ".", "open", "(", "B_path", ")", "\n", "B", "=", "B", ".", "resize", "(", "(", "64", ",", "64", ")", ",", "Image", ".", "NEAREST", ")", "\n", "B", "=", "channel_1toN", "(", "B", ",", "self", ".", "opt", ".", "output_nc", ")", "\n", "B_img_face", "=", "Image", ".", "open", "(", "B_face_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "B_face", "=", "self", ".", "transform", "(", "B_img_face", ")", "\n", "\n", "val", "=", "Image", ".", "open", "(", "val_path", ")", "\n", "val", "=", "val", ".", "resize", "(", "(", "64", ",", "64", ")", ",", "Image", ".", "NEAREST", ")", "\n", "val", "=", "channel_1toN", "(", "val", ",", "self", ".", "opt", ".", "output_nc", ")", "\n", "val_face", "=", "self", ".", "transform", "(", "val_img_face", ")", "\n", "val_label", "=", "0", "\n", "\n", "return", "{", "'A'", ":", "A", ",", "'A_face'", ":", "A_face", ",", "'B'", ":", "B", ",", "'B_face'", ":", "B_face", ",", "'val'", ":", "val", ",", "'val_face'", ":", "val_face", ",", "'val_label'", ":", "val_label", ",", "'A_path'", ":", "A_path", ",", "'val_path'", ":", "val_path", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.parseref_dataset.ParserefDataset.__len__": [[105, 109], ["max"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "max_size", "=", "0", "\n", "max_size", "=", "max", "(", "self", ".", "B_size", ",", "self", ".", "A_size", ")", "\n", "return", "max_size", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.parseref_dataset.ParserefDataset.name": [[110, 112], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'ParserefDataset'", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.parseref_dataset.channel_1toN": [[12, 22], ["torchvision.Compose", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "range", "torch.LongTensor().zero_.float", "torch.from_numpy", "torch.from_numpy", "torchvision.ToTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "numpy.logical_not().astype", "transforms.Compose.", "img.size", "img.size", "img.size", "img.size", "numpy.logical_not", "numpy.logical_xor", "layer.numpy", "torch.LongTensor().zero_.numpy"], "function", ["None"], ["def", "channel_1toN", "(", "img", ",", "num_channel", ")", ":", "\n", "    ", "transform1", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "]", ")", "\n", "img", "=", "(", "transform1", "(", "img", ")", "*", "255.0", ")", ".", "long", "(", ")", "\n", "T", "=", "torch", ".", "LongTensor", "(", "num_channel", ",", "img", ".", "size", "(", "1", ")", ",", "img", ".", "size", "(", "2", ")", ")", ".", "zero_", "(", ")", "\n", "mask", "=", "torch", ".", "LongTensor", "(", "img", ".", "size", "(", "1", ")", ",", "img", ".", "size", "(", "2", ")", ")", ".", "zero_", "(", ")", "\n", "for", "i", "in", "range", "(", "num_channel", ")", ":", "\n", "        ", "T", "[", "i", "]", "=", "T", "[", "i", "]", "+", "i", "\n", "layer", "=", "T", "[", "i", "]", "-", "img", "\n", "T", "[", "i", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "logical_not", "(", "np", ".", "logical_xor", "(", "layer", ".", "numpy", "(", ")", ",", "mask", ".", "numpy", "(", ")", ")", ")", ".", "astype", "(", "int", ")", ")", "\n", "", "return", "T", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.test_options.TestOptions.initialize": [[5, 25], ["base_options.BaseOptions.initialize", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.set_defaults", "float", "base_options.BaseOptions.initialize.get_default"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.initialize"], ["    ", "def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "parser", "=", "BaseOptions", ".", "initialize", "(", "self", ",", "parser", ")", "\n", "parser", ".", "add_argument", "(", "'--ntest'", ",", "type", "=", "int", ",", "default", "=", "float", "(", "\"inf\"", ")", ",", "help", "=", "'# of test examples.'", ")", "\n", "parser", ".", "add_argument", "(", "'--results_dir'", ",", "type", "=", "str", ",", "default", "=", "'./results/'", ",", "help", "=", "'saves results here.'", ")", "\n", "parser", ".", "add_argument", "(", "'--aspect_ratio'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'aspect ratio of result images'", ")", "\n", "parser", ".", "add_argument", "(", "'--phase'", ",", "type", "=", "str", ",", "default", "=", "'test'", ",", "help", "=", "'train, val, test, etc'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_phase'", ",", "type", "=", "str", ",", "default", "=", "'test'", ",", "help", "=", "'train, val, test, etc'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_test'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "help", "=", "'how many test images to run'", ")", "\n", "parser", ".", "add_argument", "(", "'--input'", ",", "type", "=", "str", ",", "default", "=", "'examples/photo_examples/Scarlett_Johansson_P00002.jpg'", ",", "help", "=", "'input image path'", ")", "\n", "parser", ".", "add_argument", "(", "'--shape'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'shape image name'", ")", "\n", "parser", ".", "add_argument", "(", "'--style_path'", ",", "type", "=", "str", ",", "default", "=", "'examples/style_imgs/Angela_Merkel_C00012.jpg'", ",", "help", "=", "'style image path'", ")", "\n", "parser", ".", "add_argument", "(", "'--parsing_model'", ",", "type", "=", "str", ",", "default", "=", "'checkpoints/parsing.pth'", ",", "help", "=", "'parsing model path'", ")", "\n", "parser", ".", "add_argument", "(", "'--retrieval_model'", ",", "type", "=", "str", ",", "default", "=", "'checkpoints/retrieval.pth.tar'", ",", "help", "=", "'retrieval model path'", ")", "\n", "parser", ".", "add_argument", "(", "'--style_decoder_model'", ",", "type", "=", "str", ",", "default", "=", "'checkpoints/style_decoder.pth.tar'", ",", "help", "=", "'style decoder model path'", ")", "\n", "parser", ".", "add_argument", "(", "'--style_encoder_model'", ",", "type", "=", "str", ",", "default", "=", "'checkpoints/vgg_normalised.pth'", ",", "help", "=", "'style encoder model path'", ")", "\n", "\n", "# To avoid cropping, the loadSize should be the same as fineSize", "\n", "parser", ".", "set_defaults", "(", "loadSize", "=", "parser", ".", "get_default", "(", "'fineSize'", ")", ")", "\n", "self", ".", "isTrain", "=", "False", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.train_options.TrainOptions.initialize": [[5, 33], ["base_options.BaseOptions.initialize", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.initialize"], ["    ", "def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "parser", "=", "BaseOptions", ".", "initialize", "(", "self", ",", "parser", ")", "\n", "parser", ".", "add_argument", "(", "'--display_freq'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'frequency of showing training results on screen'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_ncols'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'if positive, display all images in a single visdom web panel with certain number of images per row.'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_id'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'window id of the web display'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_server'", ",", "type", "=", "str", ",", "default", "=", "\"http://localhost\"", ",", "help", "=", "'visdom server of the web display'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_env'", ",", "type", "=", "str", ",", "default", "=", "'main'", ",", "help", "=", "'visdom display environment name (default is \"main\")'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_port'", ",", "type", "=", "int", ",", "default", "=", "8097", ",", "help", "=", "'visdom port of the web display'", ")", "\n", "parser", ".", "add_argument", "(", "'--update_html_freq'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'frequency of saving training results to html'", ")", "\n", "parser", ".", "add_argument", "(", "'--print_freq'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'frequency of showing training results on console'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_latest_freq'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "help", "=", "'frequency of saving the latest results'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_epoch_freq'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'frequency of saving checkpoints at the end of epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--continue_train'", ",", "action", "=", "'store_true'", ",", "help", "=", "'continue training: load the latest model'", ")", "\n", "parser", ".", "add_argument", "(", "'--epoch_count'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'the starting epoch count, we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>, ...'", ")", "\n", "parser", ".", "add_argument", "(", "'--phase'", ",", "type", "=", "str", ",", "default", "=", "'train'", ",", "help", "=", "'train, val, test, etc'", ")", "\n", "#parser.add_argument('--niter', type=int, default=200, help='# of iter at starting learning rate')", "\n", "parser", ".", "add_argument", "(", "'--niter'", ",", "type", "=", "int", ",", "default", "=", "300", ",", "help", "=", "'# of iter at starting learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--niter_decay'", ",", "type", "=", "int", ",", "default", "=", "300", ",", "help", "=", "'# of iter to linearly decay learning rate to zero'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta1'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'momentum term of adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.0002", ",", "help", "=", "'initial learning rate for adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_lsgan'", ",", "action", "=", "'store_true'", ",", "help", "=", "'do *not* use least square GAN, if false, use vanilla GAN'", ")", "\n", "parser", ".", "add_argument", "(", "'--pool_size'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'the size of image buffer that stores previously generated images'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_html'", ",", "action", "=", "'store_true'", ",", "help", "=", "'do not save intermediate training results to [opt.checkpoints_dir]/[opt.name]/web/'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_policy'", ",", "type", "=", "str", ",", "default", "=", "'lambda'", ",", "help", "=", "'learning rate policy: lambda|step|plateau|cosine'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_decay_iters'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'multiply by a gamma every lr_decay_iters iterations'", ")", "\n", "\n", "self", ".", "isTrain", "=", "True", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.__init__": [[10, 12], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "initialized", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.initialize": [[13, 51], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "float"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "'--dataroot'", ",", "type", "=", "str", ",", "default", "=", "'datasets/carigan/'", ",", "help", "=", "'path to images (should have subfolders trainA, trainB, valA, valB, etc)'", ")", "\n", "#parser.add_argument('--batch_size', type=int, default=1, help='input batch size')", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "'input batch size'", ")", "\n", "#parser.add_argument('--batch_size', type=int, default=16, help='input batch size')", "\n", "#parser.add_argument('--loadSize', type=int, default=286, help='scale images to this size')", "\n", "parser", ".", "add_argument", "(", "'--loadSize'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'scale images to this size'", ")", "\n", "parser", ".", "add_argument", "(", "'--fineSize'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'then crop to this size'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_winsize'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'display window size for both visdom and HTML'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_nc'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "'# of input image channels'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_nc'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "'# of output image channels'", ")", "\n", "parser", ".", "add_argument", "(", "'--ngf'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'# of gen filters in first conv layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--ndf'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "help", "=", "'# of discrim filters in first conv layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--netD'", ",", "type", "=", "str", ",", "default", "=", "'basic'", ",", "help", "=", "'selects model to use for netD'", ")", "\n", "parser", ".", "add_argument", "(", "'--netG'", ",", "type", "=", "str", ",", "default", "=", "'resnet_9blocks'", ",", "help", "=", "'selects model to use for netG'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_layers_D'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'only used if netD==n_layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_ids'", ",", "type", "=", "str", ",", "default", "=", "'0'", ",", "help", "=", "'gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU'", ")", "\n", "parser", ".", "add_argument", "(", "'--name'", ",", "type", "=", "str", ",", "default", "=", "'parseref_gan'", ",", "help", "=", "'name of the experiment. It decides where to store samples and models'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_mode'", ",", "type", "=", "str", ",", "default", "=", "'parseref'", ",", "help", "=", "'chooses how datasets are loaded. [unaligned | aligned | single | star | style | aug]'", ")", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "'parseref_gan'", ",", "\n", "help", "=", "'chooses which model to use. cycle_gan, pix2pix, test, cari_gan, aug_gan, style_gan'", ")", "\n", "parser", ".", "add_argument", "(", "'--direction'", ",", "type", "=", "str", ",", "default", "=", "'AtoB'", ",", "help", "=", "'AtoB or BtoA'", ")", "\n", "parser", ".", "add_argument", "(", "'--epoch'", ",", "type", "=", "str", ",", "default", "=", "'latest'", ",", "help", "=", "'which epoch to load? set to latest to use latest cached model'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_threads'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "'# threads for loading data'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_style'", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "'# num for style types'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoints_dir'", ",", "type", "=", "str", ",", "default", "=", "'./checkpoints'", ",", "help", "=", "'models are saved here'", ")", "\n", "parser", ".", "add_argument", "(", "'--norm'", ",", "type", "=", "str", ",", "default", "=", "'instance'", ",", "help", "=", "'instance normalization or batch normalization'", ")", "\n", "parser", ".", "add_argument", "(", "'--serial_batches'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if true, takes images in order to make batches, otherwise takes them randomly'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_dropout'", ",", "action", "=", "'store_true'", ",", "help", "=", "'no dropout for the generator'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_dataset_size'", ",", "type", "=", "int", ",", "default", "=", "float", "(", "\"inf\"", ")", ",", "help", "=", "'Maximum number of samples allowed per dataset. If the dataset directory contains more than max_dataset_size, only a subset is loaded.'", ")", "\n", "parser", ".", "add_argument", "(", "'--resize_or_crop'", ",", "type", "=", "str", ",", "default", "=", "'scale_width'", ",", "help", "=", "'scaling and cropping of images at load time [resize_and_crop|crop|scale_width|scale_width_and_crop]'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_flip'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, do not flip the images for data augmentation'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_type'", ",", "type", "=", "str", ",", "default", "=", "'normal'", ",", "help", "=", "'network initialization [normal|xavier|kaiming|orthogonal]'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_gain'", ",", "type", "=", "float", ",", "default", "=", "0.02", ",", "help", "=", "'scaling factor for normal, xavier and orthogonal.'", ")", "\n", "parser", ".", "add_argument", "(", "'--verbose'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, print more debugging information'", ")", "\n", "parser", ".", "add_argument", "(", "'--suffix'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "help", "=", "'customized suffix: opt.name = opt.name + suffix: e.g., {model}_{netG}_size{loadSize}'", ")", "\n", "self", ".", "initialized", "=", "True", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.gather_options": [[52, 76], ["base_options.BaseOptions.parse_known_args", "models.get_option_setter", "models.get_option_setter.", "base_options.BaseOptions.parse_known_args", "data.get_option_setter", "data.get_option_setter.", "base_options.BaseOptions.parse_args", "argparse.ArgumentParser", "base_options.BaseOptions.initialize"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.__init__.get_option_setter", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.data.__init__.get_option_setter", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.parsing.train.parse_args", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.initialize"], ["", "def", "gather_options", "(", "self", ")", ":", "\n", "# initialize parser with basic options", "\n", "        ", "if", "not", "self", ".", "initialized", ":", "\n", "            ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", "=", "self", ".", "initialize", "(", "parser", ")", "\n", "\n", "# get the basic options", "\n", "", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "\n", "# modify model-related parser options", "\n", "model_name", "=", "opt", ".", "model", "\n", "model_option_setter", "=", "models", ".", "get_option_setter", "(", "model_name", ")", "\n", "parser", "=", "model_option_setter", "(", "parser", ",", "self", ".", "isTrain", ")", "\n", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "# parse again with the new defaults", "\n", "\n", "# modify dataset-related parser options", "\n", "dataset_name", "=", "opt", ".", "dataset_mode", "\n", "dataset_option_setter", "=", "data", ".", "get_option_setter", "(", "dataset_name", ")", "\n", "parser", "=", "dataset_option_setter", "(", "parser", ",", "self", ".", "isTrain", ")", "\n", "\n", "self", ".", "parser", "=", "parser", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.print_options": [[77, 96], ["sorted", "print", "os.path.join", "util.util.util.mkdirs", "os.path.join", "vars().items", "base_options.BaseOptions.parser.get_default", "open", "opt_file.write", "opt_file.write", "str", "str", "vars", "str"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.util.util.mkdirs"], ["", "def", "print_options", "(", "self", ",", "opt", ")", ":", "\n", "        ", "message", "=", "''", "\n", "message", "+=", "'----------------- Options ---------------\\n'", "\n", "for", "k", ",", "v", "in", "sorted", "(", "vars", "(", "opt", ")", ".", "items", "(", ")", ")", ":", "\n", "            ", "comment", "=", "''", "\n", "default", "=", "self", ".", "parser", ".", "get_default", "(", "k", ")", "\n", "if", "v", "!=", "default", ":", "\n", "                ", "comment", "=", "'\\t[default: %s]'", "%", "str", "(", "default", ")", "\n", "", "message", "+=", "'{:>25}: {:<30}{}\\n'", ".", "format", "(", "str", "(", "k", ")", ",", "str", "(", "v", ")", ",", "comment", ")", "\n", "", "message", "+=", "'----------------- End -------------------'", "\n", "print", "(", "message", ")", "\n", "\n", "# save to the disk", "\n", "expr_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "\n", "util", ".", "mkdirs", "(", "expr_dir", ")", "\n", "file_name", "=", "os", ".", "path", ".", "join", "(", "expr_dir", ",", "'opt.txt'", ")", "\n", "with", "open", "(", "file_name", ",", "'wt'", ")", "as", "opt_file", ":", "\n", "            ", "opt_file", ".", "write", "(", "message", ")", "\n", "opt_file", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.parse": [[97, 121], ["base_options.BaseOptions.gather_options", "base_options.BaseOptions.print_options", "base_options.BaseOptions.gpu_ids.split", "int", "len", "torch.cuda.set_device", "base_options.BaseOptions.gpu_ids.append", "base_options.BaseOptions.suffix.format", "vars"], "methods", ["home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.gather_options", "home.repos.pwc.inspect_result.wenqingchu_Semantic-CariGANs.options.base_options.BaseOptions.print_options"], ["", "", "def", "parse", "(", "self", ")", ":", "\n", "\n", "        ", "opt", "=", "self", ".", "gather_options", "(", ")", "\n", "opt", ".", "isTrain", "=", "self", ".", "isTrain", "# train or test", "\n", "\n", "# process opt.suffix", "\n", "if", "opt", ".", "suffix", ":", "\n", "            ", "suffix", "=", "(", "'_'", "+", "opt", ".", "suffix", ".", "format", "(", "**", "vars", "(", "opt", ")", ")", ")", "if", "opt", ".", "suffix", "!=", "''", "else", "''", "\n", "opt", ".", "name", "=", "opt", ".", "name", "+", "suffix", "\n", "\n", "", "self", ".", "print_options", "(", "opt", ")", "\n", "\n", "# set gpu ids", "\n", "str_ids", "=", "opt", ".", "gpu_ids", ".", "split", "(", "','", ")", "\n", "opt", ".", "gpu_ids", "=", "[", "]", "\n", "for", "str_id", "in", "str_ids", ":", "\n", "            ", "id", "=", "int", "(", "str_id", ")", "\n", "if", "id", ">=", "0", ":", "\n", "                ", "opt", ".", "gpu_ids", ".", "append", "(", "id", ")", "\n", "", "", "if", "len", "(", "opt", ".", "gpu_ids", ")", ">", "0", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu_ids", "[", "0", "]", ")", "\n", "\n", "", "self", ".", "opt", "=", "opt", "\n", "return", "self", ".", "opt", "\n", "", "", ""]]}