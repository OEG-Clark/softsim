{"home.repos.pwc.inspect_result.hongwang600_DocRed.None.gen_data.sents_2_idx": [[34, 42], ["enumerate", "sents_idx.append", "len", "list", "range", "len"], "function", ["None"], ["def", "sents_2_idx", "(", "sents", ",", "word2id", ")", ":", "\n", "#sents_idx = np.zeros([sent_limit, word_size]) + word2id['BLANK']", "\n", "    ", "sents_idx", "=", "[", "]", "\n", "start_idx", "=", "0", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "sents", "[", ":", "sent_limit", "]", ")", ":", "\n", "        ", "sents_idx", ".", "append", "(", "list", "(", "range", "(", "start_idx", ",", "start_idx", "+", "len", "(", "sent", ")", ")", ")", ")", "\n", "start_idx", "+=", "len", "(", "sent", ")", "\n", "", "return", "sents_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.None.gen_data.init": [[43, 213], ["json.load", "json.load", "range", "print", "print", "json.dump", "json.load", "json.load", "json.load", "len", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "print", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "print", "open", "open", "len", "range", "ori_data[].get", "set", "range", "gen_data.sents_2_idx", "data.append", "max", "max", "len", "open", "open", "open", "open", "len", "bert.subword_tokenize_to_ids", "enumerate", "range", "enumerate", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "Ls.append", "len", "range", "set.add", "new_labels.append", "len", "range", "len", "len", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "word.lower.lower", "enumerate", "len", "int", "len", "list", "json.load.get", "fact_in_dev_train.add", "fact_in_train.add", "na_triple.append"], "function", ["home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.get", "home.repos.pwc.inspect_result.hongwang600_DocRed.None.gen_data.sents_2_idx", "home.repos.pwc.inspect_result.hongwang600_DocRed.models.bert.Bert.subword_tokenize_to_ids", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.add", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.get", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.add", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.add"], ["", "def", "init", "(", "data_file_name", ",", "rel2id", ",", "max_length", "=", "512", ",", "is_training", "=", "True", ",", "suffix", "=", "''", ")", ":", "\n", "\n", "    ", "ori_data", "=", "json", ".", "load", "(", "open", "(", "data_file_name", ")", ")", "\n", "\n", "\n", "Ma", "=", "0", "\n", "Ma_e", "=", "0", "\n", "data", "=", "[", "]", "\n", "intrain", "=", "notintrain", "=", "notindevtrain", "=", "indevtrain", "=", "0", "\n", "word2id", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "\"word2id.json\"", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ori_data", ")", ")", ":", "\n", "        ", "Ls", "=", "[", "0", "]", "\n", "L", "=", "0", "\n", "for", "x", "in", "ori_data", "[", "i", "]", "[", "'sents'", "]", ":", "\n", "            ", "L", "+=", "len", "(", "x", ")", "\n", "Ls", ".", "append", "(", "L", ")", "\n", "\n", "", "vertexSet", "=", "ori_data", "[", "i", "]", "[", "'vertexSet'", "]", "\n", "# point position added with sent start position", "\n", "for", "j", "in", "range", "(", "len", "(", "vertexSet", ")", ")", ":", "\n", "            ", "for", "k", "in", "range", "(", "len", "(", "vertexSet", "[", "j", "]", ")", ")", ":", "\n", "                ", "vertexSet", "[", "j", "]", "[", "k", "]", "[", "'sent_id'", "]", "=", "int", "(", "vertexSet", "[", "j", "]", "[", "k", "]", "[", "'sent_id'", "]", ")", "\n", "\n", "sent_id", "=", "vertexSet", "[", "j", "]", "[", "k", "]", "[", "'sent_id'", "]", "\n", "dl", "=", "Ls", "[", "sent_id", "]", "\n", "pos1", "=", "vertexSet", "[", "j", "]", "[", "k", "]", "[", "'pos'", "]", "[", "0", "]", "\n", "pos2", "=", "vertexSet", "[", "j", "]", "[", "k", "]", "[", "'pos'", "]", "[", "1", "]", "\n", "vertexSet", "[", "j", "]", "[", "k", "]", "[", "'pos'", "]", "=", "(", "pos1", "+", "dl", ",", "pos2", "+", "dl", ")", "\n", "\n", "", "", "ori_data", "[", "i", "]", "[", "'vertexSet'", "]", "=", "vertexSet", "\n", "\n", "item", "=", "{", "}", "\n", "item", "[", "'vertexSet'", "]", "=", "vertexSet", "\n", "labels", "=", "ori_data", "[", "i", "]", ".", "get", "(", "'labels'", ",", "[", "]", ")", "\n", "\n", "train_triple", "=", "set", "(", "[", "]", ")", "\n", "new_labels", "=", "[", "]", "\n", "for", "label", "in", "labels", ":", "\n", "            ", "rel", "=", "label", "[", "'r'", "]", "\n", "assert", "(", "rel", "in", "rel2id", ")", "\n", "label", "[", "'r'", "]", "=", "rel2id", "[", "label", "[", "'r'", "]", "]", "\n", "\n", "train_triple", ".", "add", "(", "(", "label", "[", "'h'", "]", ",", "label", "[", "'t'", "]", ")", ")", "\n", "\n", "\n", "if", "suffix", "==", "'_train'", ":", "\n", "                ", "for", "n1", "in", "vertexSet", "[", "label", "[", "'h'", "]", "]", ":", "\n", "                    ", "for", "n2", "in", "vertexSet", "[", "label", "[", "'t'", "]", "]", ":", "\n", "                        ", "fact_in_dev_train", ".", "add", "(", "(", "n1", "[", "'name'", "]", ",", "n2", "[", "'name'", "]", ",", "rel", ")", ")", "\n", "\n", "\n", "", "", "", "if", "is_training", ":", "\n", "                ", "for", "n1", "in", "vertexSet", "[", "label", "[", "'h'", "]", "]", ":", "\n", "                    ", "for", "n2", "in", "vertexSet", "[", "label", "[", "'t'", "]", "]", ":", "\n", "                        ", "fact_in_train", ".", "add", "(", "(", "n1", "[", "'name'", "]", ",", "n2", "[", "'name'", "]", ",", "rel", ")", ")", "\n", "\n", "", "", "", "else", ":", "\n", "# fix a bug here", "\n", "                ", "label", "[", "'intrain'", "]", "=", "False", "\n", "label", "[", "'indev_train'", "]", "=", "False", "\n", "\n", "for", "n1", "in", "vertexSet", "[", "label", "[", "'h'", "]", "]", ":", "\n", "                    ", "for", "n2", "in", "vertexSet", "[", "label", "[", "'t'", "]", "]", ":", "\n", "                        ", "if", "(", "n1", "[", "'name'", "]", ",", "n2", "[", "'name'", "]", ",", "rel", ")", "in", "fact_in_train", ":", "\n", "                            ", "label", "[", "'intrain'", "]", "=", "True", "\n", "\n", "", "if", "suffix", "==", "'_dev'", "or", "suffix", "==", "'_test'", ":", "\n", "                            ", "if", "(", "n1", "[", "'name'", "]", ",", "n2", "[", "'name'", "]", ",", "rel", ")", "in", "fact_in_dev_train", ":", "\n", "                                ", "label", "[", "'indev_train'", "]", "=", "True", "\n", "\n", "\n", "", "", "", "", "", "new_labels", ".", "append", "(", "label", ")", "\n", "\n", "", "item", "[", "'labels'", "]", "=", "new_labels", "\n", "item", "[", "'title'", "]", "=", "ori_data", "[", "i", "]", "[", "'title'", "]", "\n", "\n", "na_triple", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "vertexSet", ")", ")", ":", "\n", "            ", "for", "k", "in", "range", "(", "len", "(", "vertexSet", ")", ")", ":", "\n", "                ", "if", "(", "j", "!=", "k", ")", ":", "\n", "                    ", "if", "(", "j", ",", "k", ")", "not", "in", "train_triple", ":", "\n", "                        ", "na_triple", ".", "append", "(", "(", "j", ",", "k", ")", ")", "\n", "\n", "", "", "", "", "item", "[", "'na_triple'", "]", "=", "na_triple", "\n", "item", "[", "'Ls'", "]", "=", "Ls", "\n", "item", "[", "'sents'", "]", "=", "ori_data", "[", "i", "]", "[", "'sents'", "]", "\n", "item", "[", "'sents_idx'", "]", "=", "sents_2_idx", "(", "ori_data", "[", "i", "]", "[", "'sents'", "]", ",", "word2id", ")", "\n", "data", ".", "append", "(", "item", ")", "\n", "\n", "Ma", "=", "max", "(", "Ma", ",", "len", "(", "vertexSet", ")", ")", "\n", "Ma_e", "=", "max", "(", "Ma_e", ",", "len", "(", "item", "[", "'labels'", "]", ")", ")", "\n", "\n", "\n", "", "print", "(", "'data_len:'", ",", "len", "(", "ori_data", ")", ")", "\n", "# print ('Ma_V', Ma)", "\n", "# print ('Ma_e', Ma_e)", "\n", "# print (suffix)", "\n", "# print ('fact_in_train', len(fact_in_train))", "\n", "# print (intrain, notintrain)", "\n", "# print ('fact_in_devtrain', len(fact_in_dev_train))", "\n", "# print (indevtrain, notindevtrain)", "\n", "\n", "\n", "# saving", "\n", "print", "(", "\"Saving files\"", ")", "\n", "if", "is_training", ":", "\n", "        ", "name_prefix", "=", "\"train\"", "\n", "", "else", ":", "\n", "        ", "name_prefix", "=", "\"dev\"", "\n", "\n", "", "json", ".", "dump", "(", "data", ",", "open", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "name_prefix", "+", "suffix", "+", "'.json'", ")", ",", "\"w\"", ")", ")", "\n", "\n", "char2id", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "\"char2id.json\"", ")", ")", ")", "\n", "# id2char= {v:k for k,v in char2id.items()}", "\n", "# json.dump(id2char, open(\"data/id2char.json\", \"w\"))", "\n", "\n", "word2id", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "\"word2id.json\"", ")", ")", ")", "\n", "ner2id", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "\"ner2id.json\"", ")", ")", ")", "\n", "\n", "sen_tot", "=", "len", "(", "ori_data", ")", "\n", "sen_word", "=", "np", ".", "zeros", "(", "(", "sen_tot", ",", "max_length", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "sen_pos", "=", "np", ".", "zeros", "(", "(", "sen_tot", ",", "max_length", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "sen_ner", "=", "np", ".", "zeros", "(", "(", "sen_tot", ",", "max_length", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "sen_char", "=", "np", ".", "zeros", "(", "(", "sen_tot", ",", "max_length", ",", "char_limit", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "bert_token", "=", "np", ".", "zeros", "(", "(", "sen_tot", ",", "max_length", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "bert_mask", "=", "np", ".", "zeros", "(", "(", "sen_tot", ",", "max_length", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "bert_starts", "=", "np", ".", "zeros", "(", "(", "sen_tot", ",", "max_length", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "ori_data", ")", ")", ":", "\n", "        ", "item", "=", "ori_data", "[", "i", "]", "\n", "words", "=", "[", "]", "\n", "for", "sent", "in", "item", "[", "'sents'", "]", ":", "\n", "            ", "words", "+=", "sent", "\n", "\n", "", "bert_token", "[", "i", "]", ",", "bert_mask", "[", "i", "]", ",", "bert_starts", "[", "i", "]", "=", "bert", ".", "subword_tokenize_to_ids", "(", "words", ")", "\n", "\n", "for", "j", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "            ", "word", "=", "word", ".", "lower", "(", ")", "\n", "\n", "if", "j", "<", "max_length", ":", "\n", "                ", "if", "word", "in", "word2id", ":", "\n", "                    ", "sen_word", "[", "i", "]", "[", "j", "]", "=", "word2id", "[", "word", "]", "\n", "", "else", ":", "\n", "                    ", "sen_word", "[", "i", "]", "[", "j", "]", "=", "word2id", "[", "'UNK'", "]", "\n", "\n", "", "", "for", "c_idx", ",", "k", "in", "enumerate", "(", "list", "(", "word", ")", ")", ":", "\n", "                ", "if", "c_idx", ">=", "char_limit", ":", "\n", "                    ", "break", "\n", "", "sen_char", "[", "i", ",", "j", ",", "c_idx", "]", "=", "char2id", ".", "get", "(", "k", ",", "char2id", "[", "'UNK'", "]", ")", "\n", "\n", "", "", "for", "j", "in", "range", "(", "j", "+", "1", ",", "max_length", ")", ":", "\n", "            ", "sen_word", "[", "i", "]", "[", "j", "]", "=", "word2id", "[", "'BLANK'", "]", "\n", "\n", "", "vertexSet", "=", "item", "[", "'vertexSet'", "]", "\n", "\n", "for", "idx", ",", "vertex", "in", "enumerate", "(", "vertexSet", ",", "1", ")", ":", "\n", "            ", "for", "v", "in", "vertex", ":", "\n", "                ", "sen_pos", "[", "i", "]", "[", "v", "[", "'pos'", "]", "[", "0", "]", ":", "v", "[", "'pos'", "]", "[", "1", "]", "]", "=", "idx", "\n", "sen_ner", "[", "i", "]", "[", "v", "[", "'pos'", "]", "[", "0", "]", ":", "v", "[", "'pos'", "]", "[", "1", "]", "]", "=", "ner2id", "[", "v", "[", "'type'", "]", "]", "\n", "\n", "", "", "", "print", "(", "\"Finishing processing\"", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "name_prefix", "+", "suffix", "+", "'_word.npy'", ")", ",", "sen_word", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "name_prefix", "+", "suffix", "+", "'_pos.npy'", ")", ",", "sen_pos", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "name_prefix", "+", "suffix", "+", "'_ner.npy'", ")", ",", "sen_ner", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "name_prefix", "+", "suffix", "+", "'_char.npy'", ")", ",", "sen_char", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "name_prefix", "+", "suffix", "+", "'_bert_word.npy'", ")", ",", "bert_token", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "name_prefix", "+", "suffix", "+", "'_bert_mask.npy'", ")", ",", "bert_mask", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "name_prefix", "+", "suffix", "+", "'_bert_starts.npy'", ")", ",", "bert_starts", ")", "\n", "print", "(", "\"Finish saving\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.None.evaluation.gen_train_facts": [[7, 31], ["os.path.join", "os.path.join", "os.path.exists", "os.path.exists", "set", "json.load", "json.dump", "os.path.join.replace", "set", "json.load", "open", "list", "open", "data_file_name.find", "open", "set.add", "tuple", "set.add"], "function", ["home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.add", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.add"], ["def", "gen_train_facts", "(", "data_file_name", ",", "truth_dir", ")", ":", "\n", "    ", "fact_file_name", "=", "data_file_name", "[", "data_file_name", ".", "find", "(", "\"train_\"", ")", ":", "]", "\n", "fact_file_name", "=", "os", ".", "path", ".", "join", "(", "truth_dir", ",", "fact_file_name", ".", "replace", "(", "\".json\"", ",", "\".fact\"", ")", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "fact_file_name", ")", ":", "\n", "        ", "fact_in_train", "=", "set", "(", "[", "]", ")", "\n", "triples", "=", "json", ".", "load", "(", "open", "(", "fact_file_name", ")", ")", "\n", "for", "x", "in", "triples", ":", "\n", "            ", "fact_in_train", ".", "add", "(", "tuple", "(", "x", ")", ")", "\n", "", "return", "fact_in_train", "\n", "\n", "", "fact_in_train", "=", "set", "(", "[", "]", ")", "\n", "ori_data", "=", "json", ".", "load", "(", "open", "(", "data_file_name", ")", ")", "\n", "for", "data", "in", "ori_data", ":", "\n", "        ", "vertexSet", "=", "data", "[", "'vertexSet'", "]", "\n", "for", "label", "in", "data", "[", "'labels'", "]", ":", "\n", "            ", "rel", "=", "label", "[", "'r'", "]", "\n", "for", "n1", "in", "vertexSet", "[", "label", "[", "'h'", "]", "]", ":", "\n", "                ", "for", "n2", "in", "vertexSet", "[", "label", "[", "'t'", "]", "]", ":", "\n", "                    ", "fact_in_train", ".", "add", "(", "(", "n1", "[", "'name'", "]", ",", "n2", "[", "'name'", "]", ",", "rel", ")", ")", "\n", "\n", "", "", "", "", "json", ".", "dump", "(", "list", "(", "fact_in_train", ")", ",", "open", "(", "fact_file_name", ",", "\"w\"", ")", ")", "\n", "\n", "return", "fact_in_train", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.Accuracy.__init__": [[27, 30], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "correct", "=", "0", "\n", "self", ".", "total", "=", "0", "\n", "", "def", "add", "(", "self", ",", "is_correct", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.Accuracy.add": [[30, 34], ["None"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "is_correct", ")", ":", "\n", "        ", "self", ".", "total", "+=", "1", "\n", "if", "is_correct", ":", "\n", "            ", "self", ".", "correct", "+=", "1", "\n", "", "", "def", "get", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.Accuracy.get": [[34, 39], ["float"], "methods", ["None"], ["", "", "def", "get", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "total", "==", "0", ":", "\n", "            ", "return", "0.0", "\n", "", "else", ":", "\n", "            ", "return", "float", "(", "self", ".", "correct", ")", "/", "self", ".", "total", "\n", "", "", "def", "clear", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.Accuracy.clear": [[39, 42], ["None"], "methods", ["None"], ["", "", "def", "clear", "(", "self", ")", ":", "\n", "        ", "self", ".", "correct", "=", "0", "\n", "self", ".", "total", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.__init__": [[44, 96], ["EviConfig.Accuracy", "EviConfig.Accuracy", "EviConfig.Accuracy", "numpy.zeros"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "acc_NA", "=", "Accuracy", "(", ")", "\n", "self", ".", "acc_not_NA", "=", "Accuracy", "(", ")", "\n", "self", ".", "acc_total", "=", "Accuracy", "(", ")", "\n", "self", ".", "data_path", "=", "'./prepro_data'", "\n", "self", ".", "use_bag", "=", "False", "\n", "self", ".", "use_gpu", "=", "True", "\n", "self", ".", "is_training", "=", "True", "\n", "self", ".", "max_length", "=", "512", "\n", "self", ".", "pos_num", "=", "2", "*", "self", ".", "max_length", "\n", "self", ".", "entity_num", "=", "self", ".", "max_length", "\n", "self", ".", "relation_num", "=", "97", "\n", "self", ".", "coref_size", "=", "20", "\n", "self", ".", "entity_type_size", "=", "20", "\n", "self", ".", "max_epoch", "=", "20", "\n", "self", ".", "opt_method", "=", "'Adam'", "\n", "self", ".", "optimizer", "=", "None", "\n", "self", ".", "drop_prob", "=", "0.5", "# for cnn", "\n", "self", ".", "keep_prob", "=", "0.8", "# for lstm", "\n", "self", ".", "checkpoint_dir", "=", "'./checkpoint'", "\n", "self", ".", "test_result_dir", "=", "'./test_result'", "\n", "self", ".", "test_epoch", "=", "5", "\n", "self", ".", "pretrain_model", "=", "None", "\n", "\n", "\n", "self", ".", "word_size", "=", "100", "\n", "self", ".", "epoch_range", "=", "None", "\n", "self", ".", "dropout", "=", "0.5", "\n", "self", ".", "period", "=", "50", "\n", "\n", "self", ".", "ins_batch_size", "=", "40", "\n", "self", ".", "test_ins_batch_size", "=", "self", ".", "ins_batch_size", "\n", "self", ".", "batch_size", "=", "4000", "\n", "\n", "\n", "self", ".", "char_limit", "=", "16", "\n", "self", ".", "sent_limit", "=", "25", "\n", "self", ".", "dis2idx", "=", "np", ".", "zeros", "(", "(", "512", ")", ",", "dtype", "=", "'int64'", ")", "\n", "self", ".", "dis2idx", "[", "1", "]", "=", "1", "\n", "self", ".", "dis2idx", "[", "2", ":", "]", "=", "2", "\n", "self", ".", "dis2idx", "[", "4", ":", "]", "=", "3", "\n", "self", ".", "dis2idx", "[", "8", ":", "]", "=", "4", "\n", "self", ".", "dis2idx", "[", "16", ":", "]", "=", "5", "\n", "self", ".", "dis2idx", "[", "32", ":", "]", "=", "6", "\n", "self", ".", "dis2idx", "[", "64", ":", "]", "=", "7", "\n", "self", ".", "dis2idx", "[", "128", ":", "]", "=", "8", "\n", "self", ".", "dis2idx", "[", "256", ":", "]", "=", "9", "\n", "self", ".", "dis_size", "=", "20", "\n", "\n", "self", ".", "train_prefix", "=", "args", ".", "train_prefix", "\n", "self", ".", "test_prefix", "=", "args", ".", "test_prefix", "\n", "self", ".", "output_file", "=", "args", ".", "output_file", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_data_path": [[98, 100], ["None"], "methods", ["None"], ["", "def", "set_data_path", "(", "self", ",", "data_path", ")", ":", "\n", "        ", "self", ".", "data_path", "=", "data_path", "\n", "", "def", "set_max_length", "(", "self", ",", "max_length", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_max_length": [[100, 103], ["None"], "methods", ["None"], ["", "def", "set_max_length", "(", "self", ",", "max_length", ")", ":", "\n", "        ", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "pos_num", "=", "2", "*", "self", ".", "max_length", "\n", "", "def", "set_num_classes", "(", "self", ",", "num_classes", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_num_classes": [[103, 105], ["None"], "methods", ["None"], ["", "def", "set_num_classes", "(", "self", ",", "num_classes", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "", "def", "set_window_size", "(", "self", ",", "window_size", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_window_size": [[105, 107], ["None"], "methods", ["None"], ["", "def", "set_window_size", "(", "self", ",", "window_size", ")", ":", "\n", "        ", "self", ".", "window_size", "=", "window_size", "\n", "", "def", "set_pos_size", "(", "self", ",", "pos_size", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_pos_size": [[107, 109], ["None"], "methods", ["None"], ["", "def", "set_pos_size", "(", "self", ",", "pos_size", ")", ":", "\n", "        ", "self", ".", "pos_size", "=", "pos_size", "\n", "", "def", "set_word_size", "(", "self", ",", "word_size", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_word_size": [[109, 111], ["None"], "methods", ["None"], ["", "def", "set_word_size", "(", "self", ",", "word_size", ")", ":", "\n", "        ", "self", ".", "word_size", "=", "word_size", "\n", "", "def", "set_max_epoch", "(", "self", ",", "max_epoch", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_max_epoch": [[111, 113], ["None"], "methods", ["None"], ["", "def", "set_max_epoch", "(", "self", ",", "max_epoch", ")", ":", "\n", "        ", "self", ".", "max_epoch", "=", "max_epoch", "\n", "", "def", "set_batch_size", "(", "self", ",", "batch_size", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_batch_size": [[113, 115], ["None"], "methods", ["None"], ["", "def", "set_batch_size", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "self", ".", "batch_size", "=", "batch_size", "\n", "", "def", "set_opt_method", "(", "self", ",", "opt_method", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_opt_method": [[115, 117], ["None"], "methods", ["None"], ["", "def", "set_opt_method", "(", "self", ",", "opt_method", ")", ":", "\n", "        ", "self", ".", "opt_method", "=", "opt_method", "\n", "", "def", "set_drop_prob", "(", "self", ",", "drop_prob", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_drop_prob": [[117, 119], ["None"], "methods", ["None"], ["", "def", "set_drop_prob", "(", "self", ",", "drop_prob", ")", ":", "\n", "        ", "self", ".", "drop_prob", "=", "drop_prob", "\n", "", "def", "set_checkpoint_dir", "(", "self", ",", "checkpoint_dir", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_checkpoint_dir": [[119, 121], ["None"], "methods", ["None"], ["", "def", "set_checkpoint_dir", "(", "self", ",", "checkpoint_dir", ")", ":", "\n", "        ", "self", ".", "checkpoint_dir", "=", "checkpoint_dir", "\n", "", "def", "set_test_epoch", "(", "self", ",", "test_epoch", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_test_epoch": [[121, 123], ["None"], "methods", ["None"], ["", "def", "set_test_epoch", "(", "self", ",", "test_epoch", ")", ":", "\n", "        ", "self", ".", "test_epoch", "=", "test_epoch", "\n", "", "def", "set_pretrain_model", "(", "self", ",", "pretrain_model", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_pretrain_model": [[123, 125], ["None"], "methods", ["None"], ["", "def", "set_pretrain_model", "(", "self", ",", "pretrain_model", ")", ":", "\n", "        ", "self", ".", "pretrain_model", "=", "pretrain_model", "\n", "", "def", "set_is_training", "(", "self", ",", "is_training", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_is_training": [[125, 127], ["None"], "methods", ["None"], ["", "def", "set_is_training", "(", "self", ",", "is_training", ")", ":", "\n", "        ", "self", ".", "is_training", "=", "is_training", "\n", "", "def", "set_use_bag", "(", "self", ",", "use_bag", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_use_bag": [[127, 129], ["None"], "methods", ["None"], ["", "def", "set_use_bag", "(", "self", ",", "use_bag", ")", ":", "\n", "        ", "self", ".", "use_bag", "=", "use_bag", "\n", "", "def", "set_use_gpu", "(", "self", ",", "use_gpu", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_use_gpu": [[129, 131], ["None"], "methods", ["None"], ["", "def", "set_use_gpu", "(", "self", ",", "use_gpu", ")", ":", "\n", "        ", "self", ".", "use_gpu", "=", "use_gpu", "\n", "", "def", "set_epoch_range", "(", "self", ",", "epoch_range", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.set_epoch_range": [[131, 133], ["None"], "methods", ["None"], ["", "def", "set_epoch_range", "(", "self", ",", "epoch_range", ")", ":", "\n", "        ", "self", ".", "epoch_range", "=", "epoch_range", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.load_train_data": [[134, 153], ["print", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "json.load", "print", "list", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "len", "range", "os.path.join"], "methods", ["None"], ["", "def", "load_train_data", "(", "self", ")", ":", "\n", "        ", "print", "(", "\"Reading training data...\"", ")", "\n", "\n", "prefix", "=", "'dev_train'", "\n", "self", ".", "data_train_word", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_word.npy'", ")", ")", "\n", "self", ".", "data_train_pos", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_pos.npy'", ")", ")", "\n", "self", ".", "data_train_ner", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_ner.npy'", ")", ")", "\n", "self", ".", "data_train_char", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_char.npy'", ")", ")", "\n", "self", ".", "train_file", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'.json'", ")", ")", ")", "\n", "\n", "print", "(", "\"Finish reading\"", ")", "\n", "\n", "self", ".", "train_len", "=", "ins_num", "=", "self", ".", "data_train_word", ".", "shape", "[", "0", "]", "\n", "assert", "(", "self", ".", "train_len", "==", "len", "(", "self", ".", "train_file", ")", ")", "\n", "\n", "self", ".", "train_order", "=", "list", "(", "range", "(", "ins_num", ")", ")", "\n", "self", ".", "train_batches", "=", "ins_num", "//", "self", ".", "ins_batch_size", "\n", "if", "ins_num", "%", "self", ".", "ins_batch_size", "!=", "0", ":", "\n", "            ", "self", ".", "train_batches", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.load_test_data": [[154, 207], ["print", "numpy.load", "numpy.load", "json.load", "print", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "json.load", "json.load", "print", "print", "list", "list.sort", "os.path.join", "os.path.join", "open", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "len", "open", "range", "EviConfig.EviConfig.test_order.append", "EviConfig.EviConfig.test_order.append", "len", "os.path.join", "EviConfig.EviConfig.rel2id.items", "os.path.join", "len", "int", "len"], "methods", ["None"], ["", "", "def", "load_test_data", "(", "self", ")", ":", "\n", "        ", "print", "(", "\"Reading testing data...\"", ")", "\n", "\n", "self", ".", "data_char_vec", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "'char_vec.npy'", ")", ")", "\n", "self", ".", "data_word_vec", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "'vec.npy'", ")", ")", "\n", "self", ".", "rel2id", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "'rel2id.json'", ")", ")", ")", "\n", "self", ".", "id2rel", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "rel2id", ".", "items", "(", ")", "}", "\n", "\n", "prefix", "=", "self", ".", "test_prefix", "\n", "print", "(", "prefix", ")", "\n", "self", ".", "data_test_word", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_word.npy'", ")", ")", "\n", "self", ".", "data_test_pos", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_pos.npy'", ")", ")", "\n", "self", ".", "data_test_ner", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_ner.npy'", ")", ")", "\n", "self", ".", "data_test_char", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_char.npy'", ")", ")", "\n", "self", ".", "test_file", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'.json'", ")", ")", ")", "\n", "\n", "self", ".", "test_len", "=", "self", ".", "data_test_word", ".", "shape", "[", "0", "]", "\n", "assert", "(", "self", ".", "test_len", "==", "len", "(", "self", ".", "test_file", ")", ")", "\n", "\n", "\n", "self", ".", "test_index", "=", "json", ".", "load", "(", "open", "(", "prefix", "+", "\"_index.json\"", ")", ")", "\n", "\n", "\n", "self", ".", "total_evidence_recall", "=", "0", "\n", "for", "ins", "in", "self", ".", "test_file", ":", "\n", "            ", "for", "label", "in", "ins", "[", "'labels'", "]", ":", "\n", "                ", "evidence", "=", "[", "int", "(", "e", ")", "for", "e", "in", "label", "[", "'evidence'", "]", "]", "\n", "self", ".", "total_evidence_recall", "+=", "len", "(", "evidence", ")", "\n", "\n", "", "", "print", "(", "\"total_evidence_recall:\"", ",", "self", ".", "total_evidence_recall", ")", "\n", "print", "(", "\"Finish reading\"", ")", "\n", "\n", "self", ".", "test_batches", "=", "self", ".", "data_test_word", ".", "shape", "[", "0", "]", "//", "self", ".", "test_ins_batch_size", "\n", "if", "self", ".", "data_test_word", ".", "shape", "[", "0", "]", "%", "self", ".", "test_ins_batch_size", "!=", "0", ":", "\n", "            ", "self", ".", "test_batches", "+=", "1", "\n", "\n", "\n", "", "cur_batch", "=", "list", "(", "range", "(", "self", ".", "test_len", ")", ")", "\n", "cur_batch", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "self", ".", "test_file", "[", "x", "]", "[", "'vertexSet'", "]", ")", ")", "\n", "i", "=", "0", "\n", "j", "=", "self", ".", "test_len", "-", "1", "\n", "# small vertexSet + big vertexSet as a pair", "\n", "self", ".", "test_order", "=", "[", "]", "\n", "while", "i", "<=", "j", ":", "\n", "            ", "self", ".", "test_order", ".", "append", "(", "cur_batch", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "if", "i", ">", "j", ":", "\n", "                ", "break", "\n", "\n", "", "self", ".", "test_order", ".", "append", "(", "cur_batch", "[", "j", "]", ")", "\n", "j", "-=", "1", "\n", "\n", "", "assert", "(", "len", "(", "self", ".", "test_order", ")", "==", "self", ".", "test_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.get_N2_train_batch": [[209, 291], ["random.shuffle", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "range", "min", "list", "list.sort", "enumerate", "int", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "mapping.zero_", "max", "random.shuffle", "input_lengths.max", "context_idxs[].copy_", "context_char_idxs[].copy_", "context_ner[].copy_", "range", "context_idxs[].contiguous", "context_pos[].contiguous", "relation_label[].contiguous", "context_ner[].contiguous", "context_char_idxs[].contiguous", "numpy.sum", "len", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "len", "int"], "methods", ["None"], ["", "def", "get_N2_train_batch", "(", "self", ")", ":", "\n", "        ", "random", ".", "shuffle", "(", "self", ".", "train_order", ")", "\n", "\n", "context_idxs", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "context_pos", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "\n", "context_ner", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "context_char_idxs", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ",", "self", ".", "char_limit", ")", ".", "cuda", "(", ")", "\n", "\n", "relation_label", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ")", ".", "cuda", "(", ")", "\n", "evidence_label", "=", "torch", ".", "Tensor", "(", "self", ".", "batch_size", ",", "self", ".", "sent_limit", ")", ".", "cuda", "(", ")", "\n", "sent_mask", "=", "torch", ".", "Tensor", "(", "self", ".", "batch_size", ",", "self", ".", "sent_limit", ")", ".", "cuda", "(", ")", "\n", "\n", "sent_h_mapping", "=", "torch", ".", "Tensor", "(", "self", ".", "batch_size", ",", "self", ".", "sent_limit", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "sent_t_mapping", "=", "torch", ".", "Tensor", "(", "self", ".", "batch_size", ",", "self", ".", "sent_limit", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "\n", "\n", "for", "b", "in", "range", "(", "self", ".", "train_batches", ")", ":", "\n", "            ", "start_id", "=", "b", "*", "self", ".", "ins_batch_size", "\n", "cur_bsz", "=", "min", "(", "self", ".", "ins_batch_size", ",", "self", ".", "train_len", "-", "start_id", ")", "\n", "cur_batch", "=", "list", "(", "self", ".", "train_order", "[", "start_id", ":", "start_id", "+", "cur_bsz", "]", ")", "\n", "cur_batch", ".", "sort", "(", "key", "=", "lambda", "x", ":", "np", ".", "sum", "(", "self", ".", "data_train_word", "[", "x", "]", ">", "0", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "for", "mapping", "in", "[", "sent_h_mapping", ",", "sent_t_mapping", ",", "sent_mask", ",", "evidence_label", ",", "context_pos", ",", "relation_label", "]", ":", "\n", "                ", "mapping", ".", "zero_", "(", ")", "\n", "\n", "", "max_sents", "=", "0", "\n", "i", "=", "0", "\n", "for", "w", ",", "index", "in", "enumerate", "(", "cur_batch", ")", ":", "\n", "                ", "ins", "=", "self", ".", "train_file", "[", "index", "]", "\n", "Ls", "=", "ins", "[", "'Ls'", "]", "\n", "max_sents", "=", "max", "(", "max_sents", ",", "len", "(", "Ls", ")", "-", "1", ")", "\n", "random", ".", "shuffle", "(", "ins", "[", "'labels'", "]", ")", "\n", "for", "label", "in", "ins", "[", "'labels'", "]", ":", "\n", "                    ", "context_idxs", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_train_word", "[", "index", ",", ":", "]", ")", ")", "\n", "context_char_idxs", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_train_char", "[", "index", ",", ":", "]", ")", ")", "\n", "context_ner", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_train_ner", "[", "index", ",", ":", "]", ")", ")", "\n", "relation_label", "[", "i", "]", "=", "label", "[", "'r'", "]", "\n", "\n", "h_idx", "=", "label", "[", "'h'", "]", "\n", "t_idx", "=", "label", "[", "'t'", "]", "\n", "\n", "hlist", "=", "ins", "[", "'vertexSet'", "]", "[", "h_idx", "]", "\n", "tlist", "=", "ins", "[", "'vertexSet'", "]", "[", "t_idx", "]", "\n", "\n", "for", "h", "in", "hlist", ":", "\n", "                        ", "context_pos", "[", "i", ",", "h", "[", "'pos'", "]", "[", "0", "]", ":", "h", "[", "'pos'", "]", "[", "1", "]", "]", "=", "1", "\n", "\n", "", "for", "t", "in", "tlist", ":", "\n", "                        ", "context_pos", "[", "i", ",", "t", "[", "'pos'", "]", "[", "0", "]", ":", "t", "[", "'pos'", "]", "[", "1", "]", "]", "=", "2", "\n", "\n", "", "for", "e", "in", "label", "[", "'evidence'", "]", ":", "\n", "                        ", "evidence_label", "[", "i", ",", "int", "(", "e", ")", "]", "=", "1", "\n", "\n", "", "for", "j", "in", "range", "(", "len", "(", "Ls", ")", "-", "1", ")", ":", "\n", "                        ", "sent_h_mapping", "[", "i", ",", "j", ",", "Ls", "[", "j", "]", "]", "=", "1", "\n", "sent_t_mapping", "[", "i", ",", "j", ",", "Ls", "[", "j", "+", "1", "]", "-", "1", "]", "=", "1", "\n", "sent_mask", "[", "i", ",", "j", "]", "=", "1", "\n", "\n", "\n", "", "i", "+=", "1", "\n", "if", "i", "==", "self", ".", "batch_size", ":", "\n", "                        ", "break", "\n", "", "", "if", "i", "==", "self", ".", "batch_size", ":", "\n", "                    ", "break", "\n", "\n", "\n", "\n", "", "", "cur_bsz", "=", "i", "\n", "input_lengths", "=", "(", "context_idxs", "[", ":", "cur_bsz", "]", ">", "0", ")", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "max_c_len", "=", "int", "(", "input_lengths", ".", "max", "(", ")", ")", "\n", "\n", "yield", "{", "'context_idxs'", ":", "context_idxs", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'context_pos'", ":", "context_pos", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'relation_label'", ":", "relation_label", "[", ":", "cur_bsz", "]", ".", "contiguous", "(", ")", ",", "\n", "'input_lengths'", ":", "input_lengths", ",", "\n", "'context_ner'", ":", "context_ner", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'context_char_idxs'", ":", "context_char_idxs", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'sent_h_mapping'", ":", "sent_h_mapping", "[", ":", "cur_bsz", ",", ":", "max_sents", ",", ":", "max_c_len", "]", ",", "\n", "'sent_t_mapping'", ":", "sent_t_mapping", "[", ":", "cur_bsz", ",", ":", "max_sents", ",", ":", "max_c_len", "]", ",", "\n", "'sent_mask'", ":", "sent_mask", "[", ":", "cur_bsz", ",", ":", "max_sents", "]", ",", "\n", "'evidence_label'", ":", "evidence_label", "[", ":", "cur_bsz", ",", ":", "max_sents", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.get_real_test_batch": [[294, 391], ["len", "list", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "range", "range", "min", "list", "list.sort", "enumerate", "int", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "mapping.zero_", "max", "infos.append", "context_idxs[].copy_", "context_char_idxs[].copy_", "context_ner[].copy_", "evidences.append", "range", "sents_num.append", "input_lengths.max", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "context_idxs[].contiguous", "context_pos[].contiguous", "relation_label[].contiguous", "context_ner[].contiguous", "context_char_idxs[].contiguous", "numpy.sum", "len", "len", "len", "int"], "methods", ["None"], ["", "", "def", "get_real_test_batch", "(", "self", ")", ":", "\n", "\n", "\n", "        ", "self", ".", "test_len", "=", "len", "(", "self", ".", "test_index", ")", "\n", "\n", "self", ".", "test_order", "=", "list", "(", "range", "(", "self", ".", "test_len", ")", ")", "\n", "self", ".", "test_batches", "=", "self", ".", "test_len", "//", "self", ".", "batch_size", "\n", "if", "self", ".", "test_len", "%", "self", ".", "batch_size", "!=", "0", ":", "\n", "            ", "self", ".", "test_batches", "+=", "1", "\n", "\n", "", "context_idxs", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "context_pos", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "\n", "context_ner", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "context_char_idxs", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ",", "self", ".", "char_limit", ")", ".", "cuda", "(", ")", "\n", "\n", "relation_label", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ")", ".", "cuda", "(", ")", "\n", "\n", "sent_mask", "=", "torch", ".", "Tensor", "(", "self", ".", "batch_size", ",", "self", ".", "sent_limit", ")", ".", "cuda", "(", ")", "\n", "\n", "sent_h_mapping", "=", "torch", ".", "Tensor", "(", "self", ".", "batch_size", ",", "self", ".", "sent_limit", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "sent_t_mapping", "=", "torch", ".", "Tensor", "(", "self", ".", "batch_size", ",", "self", ".", "sent_limit", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "\n", "\n", "for", "b", "in", "range", "(", "self", ".", "test_batches", ")", ":", "\n", "            ", "start_id", "=", "b", "*", "self", ".", "batch_size", "\n", "cur_bsz", "=", "min", "(", "self", ".", "batch_size", ",", "self", ".", "test_len", "-", "start_id", ")", "\n", "cur_batch", "=", "list", "(", "self", ".", "test_order", "[", "start_id", ":", "start_id", "+", "cur_bsz", "]", ")", "\n", "\n", "cur_batch", ".", "sort", "(", "key", "=", "lambda", "x", ":", "np", ".", "sum", "(", "self", ".", "data_test_word", "[", "self", ".", "test_index", "[", "x", "]", "[", "'index'", "]", "]", ">", "0", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "for", "mapping", "in", "[", "sent_h_mapping", ",", "sent_t_mapping", ",", "sent_mask", ",", "context_pos", ",", "relation_label", "]", ":", "\n", "                ", "mapping", ".", "zero_", "(", ")", "\n", "\n", "", "max_sents", "=", "0", "\n", "evidences", "=", "[", "]", "\n", "sents_num", "=", "[", "]", "\n", "infos", "=", "[", "]", "\n", "\n", "\n", "for", "i", ",", "t_index", "in", "enumerate", "(", "cur_batch", ")", ":", "\n", "                ", "pos_ins", "=", "self", ".", "test_index", "[", "t_index", "]", "\n", "index", "=", "pos_ins", "[", "'index'", "]", "\n", "h_idx", "=", "pos_ins", "[", "'h_idx'", "]", "\n", "t_idx", "=", "pos_ins", "[", "'t_idx'", "]", "\n", "r", "=", "pos_ins", "[", "'r_idx'", "]", "\n", "\n", "ins", "=", "self", ".", "test_file", "[", "index", "]", "\n", "Ls", "=", "ins", "[", "'Ls'", "]", "\n", "max_sents", "=", "max", "(", "max_sents", ",", "len", "(", "Ls", ")", "-", "1", ")", "\n", "infos", ".", "append", "(", "(", "ins", "[", "'title'", "]", ",", "h_idx", ",", "t_idx", ",", "self", ".", "id2rel", "[", "r", "]", ")", ")", "\n", "\n", "\n", "context_idxs", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_test_word", "[", "index", ",", ":", "]", ")", ")", "\n", "context_char_idxs", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_test_char", "[", "index", ",", ":", "]", ")", ")", "\n", "context_ner", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_test_ner", "[", "index", ",", ":", "]", ")", ")", "\n", "relation_label", "[", "i", "]", "=", "r", "\n", "\n", "hlist", "=", "ins", "[", "'vertexSet'", "]", "[", "h_idx", "]", "\n", "tlist", "=", "ins", "[", "'vertexSet'", "]", "[", "t_idx", "]", "\n", "\n", "for", "h", "in", "hlist", ":", "\n", "                    ", "context_pos", "[", "i", ",", "h", "[", "'pos'", "]", "[", "0", "]", ":", "h", "[", "'pos'", "]", "[", "1", "]", "]", "=", "1", "\n", "\n", "", "for", "t", "in", "tlist", ":", "\n", "                    ", "context_pos", "[", "i", ",", "t", "[", "'pos'", "]", "[", "0", "]", ":", "t", "[", "'pos'", "]", "[", "1", "]", "]", "=", "2", "\n", "\n", "\n", "", "evidence", "=", "[", "]", "\n", "for", "label", "in", "ins", "[", "'labels'", "]", ":", "\n", "                    ", "if", "(", "label", "[", "'h'", "]", ",", "label", "[", "'t'", "]", ",", "label", "[", "'r'", "]", ")", "==", "(", "h_idx", ",", "t_idx", ",", "r", ")", ":", "\n", "                        ", "evidence", "=", "[", "int", "(", "e", ")", "for", "e", "in", "label", "[", "'evidence'", "]", "]", "\n", "\n", "", "", "evidences", ".", "append", "(", "evidence", ")", "\n", "\n", "for", "j", "in", "range", "(", "len", "(", "Ls", ")", "-", "1", ")", ":", "\n", "                    ", "sent_h_mapping", "[", "i", ",", "j", ",", "Ls", "[", "j", "]", "]", "=", "1", "\n", "sent_t_mapping", "[", "i", ",", "j", ",", "Ls", "[", "j", "+", "1", "]", "-", "1", "]", "=", "1", "\n", "sent_mask", "[", "i", ",", "j", "]", "=", "1", "\n", "\n", "", "sents_num", ".", "append", "(", "len", "(", "Ls", ")", "-", "1", ")", "\n", "\n", "", "input_lengths", "=", "(", "context_idxs", "[", ":", "cur_bsz", "]", ">", "0", ")", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "max_c_len", "=", "int", "(", "input_lengths", ".", "max", "(", ")", ")", "\n", "\n", "yield", "{", "'context_idxs'", ":", "context_idxs", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'context_pos'", ":", "context_pos", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'relation_label'", ":", "relation_label", "[", ":", "cur_bsz", "]", ".", "contiguous", "(", ")", ",", "\n", "'input_lengths'", ":", "input_lengths", ",", "\n", "'context_ner'", ":", "context_ner", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'context_char_idxs'", ":", "context_char_idxs", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'sent_h_mapping'", ":", "sent_h_mapping", "[", ":", "cur_bsz", ",", ":", "max_sents", ",", ":", "max_c_len", "]", ",", "\n", "'sent_t_mapping'", ":", "sent_t_mapping", "[", ":", "cur_bsz", ",", ":", "max_sents", ",", ":", "max_c_len", "]", ",", "\n", "'sent_mask'", ":", "sent_mask", "[", ":", "cur_bsz", ",", ":", "max_sents", "]", ",", "\n", "'evidences'", ":", "evidences", ",", "\n", "'sents_num'", ":", "sents_num", ",", "\n", "'infos'", ":", "infos", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.train": [[394, 484], ["model_pattern", "model_pattern.cuda", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.DataParallel.train", "time.time", "range", "print", "print", "print", "print", "model_pattern.load_state_dict", "filter", "os.path.exists", "os.mkdir", "EviConfig.EviConfig.acc_NA.clear", "EviConfig.EviConfig.acc_not_NA.clear", "EviConfig.EviConfig.acc_total.clear", "EviConfig.EviConfig.get_N2_train_batch", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.DataParallel.parameters", "print", "torch.DataParallel.", "torch.Adam.zero_grad", "loss.backward", "torch.Adam.step", "loss.item", "EviConfig.EviConfig.train.logging"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.train", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.clear", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.clear", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.clear", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.get_N2_train_batch"], ["", "", "def", "train", "(", "self", ",", "model_pattern", ",", "model_name", ")", ":", "\n", "        ", "ori_model", "=", "model_pattern", "(", "config", "=", "self", ")", "\n", "if", "self", ".", "pretrain_model", "!=", "None", ":", "\n", "            ", "ori_model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "pretrain_model", ")", ")", "\n", "", "ori_model", ".", "cuda", "(", ")", "\n", "model", "=", "nn", ".", "DataParallel", "(", "ori_model", ")", "\n", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", ")", "\n", "\n", "BCE", "=", "nn", ".", "BCEWithLogitsLoss", "(", "reduction", "=", "'none'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "checkpoint_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "self", ".", "checkpoint_dir", ")", "\n", "\n", "", "best_auc", "=", "0.0", "\n", "best_f1", "=", "0.0", "\n", "best_epoch", "=", "0", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "global_step", "=", "0", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "def", "logging", "(", "s", ",", "print_", "=", "True", ",", "log_", "=", "True", ")", ":", "\n", "            ", "if", "print_", ":", "\n", "                ", "print", "(", "s", ")", "\n", "", "if", "log_", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "\"log\"", ",", "model_name", ")", ")", ",", "'a+'", ")", "as", "f_log", ":", "\n", "                    ", "f_log", ".", "write", "(", "s", "+", "'\\n'", ")", "\n", "\n", "", "", "", "for", "epoch", "in", "range", "(", "self", ".", "max_epoch", ")", ":", "\n", "\n", "            ", "self", ".", "acc_NA", ".", "clear", "(", ")", "\n", "self", ".", "acc_not_NA", ".", "clear", "(", ")", "\n", "self", ".", "acc_total", ".", "clear", "(", ")", "\n", "\n", "for", "data", "in", "self", ".", "get_N2_train_batch", "(", ")", ":", "\n", "\n", "                ", "context_idxs", "=", "data", "[", "'context_idxs'", "]", "\n", "context_pos", "=", "data", "[", "'context_pos'", "]", "\n", "relation_label", "=", "data", "[", "'relation_label'", "]", "\n", "input_lengths", "=", "data", "[", "'input_lengths'", "]", "\n", "context_ner", "=", "data", "[", "'context_ner'", "]", "\n", "context_char_idxs", "=", "data", "[", "'context_char_idxs'", "]", "\n", "sent_h_mapping", "=", "data", "[", "'sent_h_mapping'", "]", "\n", "sent_t_mapping", "=", "data", "[", "'sent_t_mapping'", "]", "\n", "sent_mask", "=", "data", "[", "'sent_mask'", "]", "\n", "evidence_label", "=", "data", "[", "'evidence_label'", "]", "\n", "\n", "predict_sent", "=", "model", "(", "context_idxs", ",", "context_pos", ",", "context_ner", ",", "context_char_idxs", ",", "input_lengths", ",", "sent_h_mapping", ",", "sent_t_mapping", ",", "relation_label", ")", "\n", "loss", "=", "torch", ".", "sum", "(", "BCE", "(", "predict_sent", ",", "evidence_label", ")", "*", "sent_mask", ")", "/", "torch", ".", "sum", "(", "sent_mask", ")", "\n", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "global_step", "+=", "1", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "if", "global_step", "%", "self", ".", "period", "==", "0", ":", "\n", "                    ", "cur_loss", "=", "total_loss", "/", "self", ".", "period", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "logging", "(", "'| epoch {:2d} | step {:4d} |  ms/b {:5.2f} | train loss {:5.3f} '", ".", "format", "(", "epoch", ",", "global_step", ",", "elapsed", "*", "1000", "/", "self", ".", "period", ",", "cur_loss", ")", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "\n", "\n", "", "", "if", "(", "epoch", "+", "1", ")", "%", "self", ".", "test_epoch", "==", "0", ":", "\n", "                ", "logging", "(", "'-'", "*", "89", ")", "\n", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "f1", "=", "self", ".", "test", "(", "model", ",", "model_name", ")", "\n", "model", ".", "train", "(", ")", "\n", "logging", "(", "'| epoch {:3d} | time: {:5.2f}s | F1 {:.4f}'", ".", "format", "(", "epoch", ",", "time", ".", "time", "(", ")", "-", "eval_start_time", ",", "f1", ")", ")", "\n", "logging", "(", "'-'", "*", "89", ")", "\n", "\n", "\n", "if", "f1", ">", "best_f1", ":", "\n", "                    ", "best_f1", "=", "f1", "\n", "best_epoch", "=", "epoch", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoint_dir", ",", "model_name", ")", "\n", "torch", ".", "save", "(", "ori_model", ".", "state_dict", "(", ")", ",", "path", ")", "\n", "\n", "", "", "", "print", "(", "\"Finish training\"", ")", "\n", "print", "(", "\"Best epoch = %d | auc = %f\"", "%", "(", "best_epoch", ",", "best_auc", ")", ")", "\n", "print", "(", "\"Storing best result...\"", ")", "\n", "print", "(", "\"Finish storing\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.test": [[485, 581], ["EviConfig.EviConfig.get_real_test_batch", "test_evidence_result.sort", "enumerate", "numpy.asarray", "numpy.asarray", "f1_arr.argmax", "f1_arr.max", "sklearn.metrics.auc", "EviConfig.EviConfig.train.logging"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.get_real_test_batch"], ["", "def", "test", "(", "self", ",", "model", ",", "model_name", ",", "output", "=", "False", ",", "input_theta", "=", "-", "1", ")", ":", "\n", "        ", "test_evidence_result", "=", "[", "]", "\n", "\n", "def", "logging", "(", "s", ",", "print_", "=", "True", ",", "log_", "=", "True", ")", ":", "\n", "            ", "if", "print_", ":", "\n", "                ", "print", "(", "s", ")", "\n", "", "if", "log_", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "\"log\"", ",", "model_name", ")", ")", ",", "'a+'", ")", "as", "f_log", ":", "\n", "                    ", "f_log", ".", "write", "(", "s", "+", "'\\n'", ")", "\n", "\n", "", "", "", "for", "data", "in", "self", ".", "get_real_test_batch", "(", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "context_idxs", "=", "data", "[", "'context_idxs'", "]", "\n", "context_pos", "=", "data", "[", "'context_pos'", "]", "\n", "relation_label", "=", "data", "[", "'relation_label'", "]", "\n", "input_lengths", "=", "data", "[", "'input_lengths'", "]", "\n", "context_ner", "=", "data", "[", "'context_ner'", "]", "\n", "context_char_idxs", "=", "data", "[", "'context_char_idxs'", "]", "\n", "sent_h_mapping", "=", "data", "[", "'sent_h_mapping'", "]", "\n", "sent_t_mapping", "=", "data", "[", "'sent_t_mapping'", "]", "\n", "evidences", "=", "data", "[", "'evidences'", "]", "\n", "sents_num", "=", "data", "[", "'sents_num'", "]", "\n", "infos", "=", "data", "[", "'infos'", "]", "\n", "\n", "\n", "predict_sent", "=", "model", "(", "context_idxs", ",", "context_pos", ",", "context_ner", ",", "context_char_idxs", ",", "input_lengths", ",", "sent_h_mapping", ",", "sent_t_mapping", ",", "relation_label", ")", "\n", "\n", "predict_sent", "=", "torch", ".", "sigmoid", "(", "predict_sent", ")", "\n", "\n", "\n", "", "predict_sent", "=", "predict_sent", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "evidences", ")", ")", ":", "\n", "                ", "evi", "=", "evidences", "[", "i", "]", "\n", "for", "j", "in", "range", "(", "sents_num", "[", "i", "]", ")", ":", "\n", "                    ", "test_evidence_result", ".", "append", "(", "(", "j", "in", "evi", ",", "float", "(", "predict_sent", "[", "i", ",", "j", "]", ")", ",", "infos", "[", "i", "]", ",", "j", ")", ")", "\n", "\n", "\n", "\n", "", "", "", "test_evidence_result", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "total_evidence_recall", "=", "self", ".", "total_evidence_recall", "\n", "if", "total_evidence_recall", "==", "0", ":", "# for test", "\n", "            ", "total_evidence_recall", "=", "1", "\n", "\n", "", "pr_x", "=", "[", "]", "\n", "pr_y", "=", "[", "]", "\n", "correct", "=", "0", "\n", "w", "=", "0", "\n", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "test_evidence_result", ")", ":", "\n", "            ", "correct", "+=", "item", "[", "0", "]", "\n", "pr_y", ".", "append", "(", "float", "(", "correct", ")", "/", "(", "i", "+", "1", ")", ")", "\n", "pr_x", ".", "append", "(", "float", "(", "correct", ")", "/", "total_evidence_recall", ")", "\n", "if", "item", "[", "1", "]", ">", "input_theta", ":", "\n", "                ", "w", "=", "i", "\n", "\n", "\n", "", "", "pr_x", "=", "np", ".", "asarray", "(", "pr_x", ",", "dtype", "=", "'float32'", ")", "\n", "pr_y", "=", "np", ".", "asarray", "(", "pr_y", ",", "dtype", "=", "'float32'", ")", "\n", "f1_arr", "=", "(", "2", "*", "pr_x", "*", "pr_y", "/", "(", "pr_x", "+", "pr_y", "+", "1e-20", ")", ")", "\n", "f1_pos", "=", "f1_arr", ".", "argmax", "(", ")", "\n", "evidence_f1", "=", "f1_arr", ".", "max", "(", ")", "\n", "auc", "=", "sklearn", ".", "metrics", ".", "auc", "(", "x", "=", "pr_x", ",", "y", "=", "pr_y", ")", "\n", "\n", "if", "input_theta", "==", "-", "1", ":", "\n", "            ", "w", "=", "f1_pos", "\n", "input_theta", "=", "test_evidence_result", "[", "w", "]", "[", "1", "]", "\n", "\n", "", "logging", "(", "'ma_f1{:3.4f} | input_theta {:3.4f} test_evidence_result F1 {:3.4f} | AUC {:3.4f}'", ".", "format", "(", "evidence_f1", ",", "input_theta", ",", "f1_arr", "[", "w", "]", ",", "auc", ")", ")", "\n", "\n", "if", "output", ":", "\n", "            ", "info2evi", "=", "{", "}", "\n", "\n", "for", "x", "in", "self", ".", "test_index", ":", "\n", "                ", "info2evi", "[", "(", "x", "[", "'title'", "]", ",", "x", "[", "'h_idx'", "]", ",", "x", "[", "'t_idx'", "]", ",", "x", "[", "'r'", "]", ")", "]", "=", "[", "]", "\n", "\n", "\n", "", "for", "i", "in", "range", "(", "w", "+", "1", ")", ":", "\n", "                ", "info", "=", "test_evidence_result", "[", "i", "]", "[", "-", "2", "]", "\n", "sent_id", "=", "test_evidence_result", "[", "i", "]", "[", "-", "1", "]", "\n", "info2evi", "[", "info", "]", ".", "append", "(", "sent_id", ")", "\n", "\n", "\n", "", "output", "=", "[", "]", "\n", "for", "u", ",", "v", "in", "info2evi", ".", "items", "(", ")", ":", "\n", "                ", "title", "=", "u", "[", "0", "]", "\n", "h_idx", "=", "u", "[", "1", "]", "\n", "t_idx", "=", "u", "[", "2", "]", "\n", "r", "=", "u", "[", "3", "]", "\n", "evidence", "=", "v", "\n", "output", ".", "append", "(", "{", "'title'", ":", "title", ",", "'h_idx'", ":", "h_idx", ",", "'t_idx'", ":", "t_idx", ",", "'r'", ":", "r", ",", "'evidence'", ":", "evidence", "}", ")", "\n", "\n", "", "json", ".", "dump", "(", "output", ",", "open", "(", "self", ".", "output_file", ",", "\"w\"", ")", ")", "\n", "\n", "", "return", "evidence_f1", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.EviConfig.EviConfig.testall": [[584, 591], ["model_pattern", "model_pattern.load_state_dict", "model_pattern.cuda", "model_pattern.eval", "EviConfig.EviConfig.test", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.test"], ["", "def", "testall", "(", "self", ",", "model_pattern", ",", "model_name", ",", "input_theta", "=", "-", "1", ")", ":", "\n", "        ", "model", "=", "model_pattern", "(", "config", "=", "self", ")", "\n", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoint_dir", ",", "model_name", ")", ")", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "self", ".", "test", "(", "model", ",", "model_name", ",", "True", ",", "input_theta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.__init__": [[26, 29], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "correct", "=", "0", "\n", "self", ".", "total", "=", "0", "\n", "", "def", "add", "(", "self", ",", "is_correct", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.add": [[29, 33], ["None"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "is_correct", ")", ":", "\n", "        ", "self", ".", "total", "+=", "1", "\n", "if", "is_correct", ":", "\n", "            ", "self", ".", "correct", "+=", "1", "\n", "", "", "def", "get", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.get": [[33, 38], ["float"], "methods", ["None"], ["", "", "def", "get", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "total", "==", "0", ":", "\n", "            ", "return", "0.0", "\n", "", "else", ":", "\n", "            ", "return", "float", "(", "self", ".", "correct", ")", "/", "self", ".", "total", "\n", "", "", "def", "clear", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.clear": [[38, 41], ["None"], "methods", ["None"], ["", "", "def", "clear", "(", "self", ")", ":", "\n", "        ", "self", ".", "correct", "=", "0", "\n", "self", ".", "total", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.__init__": [[43, 102], ["Config.Accuracy", "Config.Accuracy", "Config.Accuracy", "numpy.zeros", "os.path.exists", "os.mkdir"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "acc_NA", "=", "Accuracy", "(", ")", "\n", "self", ".", "acc_not_NA", "=", "Accuracy", "(", ")", "\n", "self", ".", "acc_total", "=", "Accuracy", "(", ")", "\n", "self", ".", "data_path", "=", "'./prepro_data'", "\n", "self", ".", "use_bag", "=", "False", "\n", "self", ".", "use_gpu", "=", "True", "\n", "self", ".", "is_training", "=", "True", "\n", "self", ".", "max_length", "=", "512", "\n", "self", ".", "pos_num", "=", "2", "*", "self", ".", "max_length", "\n", "self", ".", "entity_num", "=", "self", ".", "max_length", "\n", "self", ".", "relation_num", "=", "97", "\n", "\n", "self", ".", "coref_size", "=", "20", "\n", "self", ".", "entity_type_size", "=", "20", "\n", "self", ".", "max_epoch", "=", "20", "\n", "self", ".", "opt_method", "=", "'Adam'", "\n", "self", ".", "optimizer", "=", "None", "\n", "\n", "self", ".", "checkpoint_dir", "=", "'./checkpoint'", "\n", "self", ".", "fig_result_dir", "=", "'./fig_result'", "\n", "self", ".", "test_epoch", "=", "5", "\n", "self", ".", "pretrain_model", "=", "None", "\n", "\n", "\n", "self", ".", "word_size", "=", "100", "\n", "self", ".", "epoch_range", "=", "None", "\n", "self", ".", "cnn_drop_prob", "=", "0.5", "# for cnn", "\n", "self", ".", "keep_prob", "=", "0.8", "# for lstm", "\n", "\n", "self", ".", "period", "=", "50", "\n", "\n", "self", ".", "batch_size", "=", "30", "\n", "#self.test_batch_size = 40", "\n", "self", ".", "h_t_limit", "=", "1800", "\n", "\n", "self", ".", "test_batch_size", "=", "self", ".", "batch_size", "\n", "self", ".", "test_relation_limit", "=", "1800", "\n", "self", ".", "char_limit", "=", "16", "\n", "self", ".", "sent_limit", "=", "25", "\n", "#self.combined_sent_limit = 200", "\n", "self", ".", "dis2idx", "=", "np", ".", "zeros", "(", "(", "512", ")", ",", "dtype", "=", "'int64'", ")", "\n", "self", ".", "dis2idx", "[", "1", "]", "=", "1", "\n", "self", ".", "dis2idx", "[", "2", ":", "]", "=", "2", "\n", "self", ".", "dis2idx", "[", "4", ":", "]", "=", "3", "\n", "self", ".", "dis2idx", "[", "8", ":", "]", "=", "4", "\n", "self", ".", "dis2idx", "[", "16", ":", "]", "=", "5", "\n", "self", ".", "dis2idx", "[", "32", ":", "]", "=", "6", "\n", "self", ".", "dis2idx", "[", "64", ":", "]", "=", "7", "\n", "self", ".", "dis2idx", "[", "128", ":", "]", "=", "8", "\n", "self", ".", "dis2idx", "[", "256", ":", "]", "=", "9", "\n", "self", ".", "dis_size", "=", "20", "\n", "\n", "self", ".", "train_prefix", "=", "args", ".", "train_prefix", "\n", "self", ".", "test_prefix", "=", "args", ".", "test_prefix", "\n", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "\"log\"", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "\"log\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.set_data_path": [[103, 105], ["None"], "methods", ["None"], ["", "", "def", "set_data_path", "(", "self", ",", "data_path", ")", ":", "\n", "        ", "self", ".", "data_path", "=", "data_path", "\n", "", "def", "set_max_length", "(", "self", ",", "max_length", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.set_max_length": [[105, 108], ["None"], "methods", ["None"], ["", "def", "set_max_length", "(", "self", ",", "max_length", ")", ":", "\n", "        ", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "pos_num", "=", "2", "*", "self", ".", "max_length", "\n", "", "def", "set_num_classes", "(", "self", ",", "num_classes", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.set_num_classes": [[108, 110], ["None"], "methods", ["None"], ["", "def", "set_num_classes", "(", "self", ",", "num_classes", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "", "def", "set_window_size", "(", "self", ",", "window_size", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.set_window_size": [[110, 112], ["None"], "methods", ["None"], ["", "def", "set_window_size", "(", "self", ",", "window_size", ")", ":", "\n", "        ", "self", ".", "window_size", "=", "window_size", "\n", "", "def", "set_word_size", "(", "self", ",", "word_size", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.set_word_size": [[112, 114], ["None"], "methods", ["None"], ["", "def", "set_word_size", "(", "self", ",", "word_size", ")", ":", "\n", "        ", "self", ".", "word_size", "=", "word_size", "\n", "", "def", "set_max_epoch", "(", "self", ",", "max_epoch", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.set_max_epoch": [[114, 116], ["None"], "methods", ["None"], ["", "def", "set_max_epoch", "(", "self", ",", "max_epoch", ")", ":", "\n", "        ", "self", ".", "max_epoch", "=", "max_epoch", "\n", "", "def", "set_batch_size", "(", "self", ",", "batch_size", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.set_batch_size": [[116, 118], ["None"], "methods", ["None"], ["", "def", "set_batch_size", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "self", ".", "batch_size", "=", "batch_size", "\n", "", "def", "set_opt_method", "(", "self", ",", "opt_method", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.set_opt_method": [[118, 120], ["None"], "methods", ["None"], ["", "def", "set_opt_method", "(", "self", ",", "opt_method", ")", ":", "\n", "        ", "self", ".", "opt_method", "=", "opt_method", "\n", "", "def", "set_drop_prob", "(", "self", ",", "drop_prob", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.set_drop_prob": [[120, 122], ["None"], "methods", ["None"], ["", "def", "set_drop_prob", "(", "self", ",", "drop_prob", ")", ":", "\n", "        ", "self", ".", "drop_prob", "=", "drop_prob", "\n", "", "def", "set_checkpoint_dir", "(", "self", ",", "checkpoint_dir", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.set_checkpoint_dir": [[122, 124], ["None"], "methods", ["None"], ["", "def", "set_checkpoint_dir", "(", "self", ",", "checkpoint_dir", ")", ":", "\n", "        ", "self", ".", "checkpoint_dir", "=", "checkpoint_dir", "\n", "", "def", "set_test_epoch", "(", "self", ",", "test_epoch", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.set_test_epoch": [[124, 126], ["None"], "methods", ["None"], ["", "def", "set_test_epoch", "(", "self", ",", "test_epoch", ")", ":", "\n", "        ", "self", ".", "test_epoch", "=", "test_epoch", "\n", "", "def", "set_pretrain_model", "(", "self", ",", "pretrain_model", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.set_pretrain_model": [[126, 128], ["None"], "methods", ["None"], ["", "def", "set_pretrain_model", "(", "self", ",", "pretrain_model", ")", ":", "\n", "        ", "self", ".", "pretrain_model", "=", "pretrain_model", "\n", "", "def", "set_is_training", "(", "self", ",", "is_training", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.set_is_training": [[128, 130], ["None"], "methods", ["None"], ["", "def", "set_is_training", "(", "self", ",", "is_training", ")", ":", "\n", "        ", "self", ".", "is_training", "=", "is_training", "\n", "", "def", "set_use_bag", "(", "self", ",", "use_bag", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.set_use_bag": [[130, 132], ["None"], "methods", ["None"], ["", "def", "set_use_bag", "(", "self", ",", "use_bag", ")", ":", "\n", "        ", "self", ".", "use_bag", "=", "use_bag", "\n", "", "def", "set_use_gpu", "(", "self", ",", "use_gpu", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.set_use_gpu": [[132, 134], ["None"], "methods", ["None"], ["", "def", "set_use_gpu", "(", "self", ",", "use_gpu", ")", ":", "\n", "        ", "self", ".", "use_gpu", "=", "use_gpu", "\n", "", "def", "set_epoch_range", "(", "self", ",", "epoch_range", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.set_epoch_range": [[134, 136], ["None"], "methods", ["None"], ["", "def", "set_epoch_range", "(", "self", ",", "epoch_range", ")", ":", "\n", "        ", "self", ".", "epoch_range", "=", "epoch_range", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.load_train_data": [[137, 161], ["print", "print", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "json.load", "numpy.load", "numpy.load", "numpy.load", "print", "list", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "os.path.join", "os.path.join", "os.path.join", "len", "range", "os.path.join"], "methods", ["None"], ["", "def", "load_train_data", "(", "self", ")", ":", "\n", "        ", "print", "(", "\"Reading training data...\"", ")", "\n", "prefix", "=", "self", ".", "train_prefix", "\n", "\n", "print", "(", "'train'", ",", "prefix", ")", "\n", "self", ".", "data_train_word", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_word.npy'", ")", ")", "\n", "self", ".", "data_train_pos", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_pos.npy'", ")", ")", "\n", "self", ".", "data_train_ner", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_ner.npy'", ")", ")", "\n", "self", ".", "data_train_char", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_char.npy'", ")", ")", "\n", "self", ".", "train_file", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'.json'", ")", ")", ")", "\n", "\n", "self", ".", "data_train_bert_word", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_bert_word.npy'", ")", ")", "\n", "self", ".", "data_train_bert_mask", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_bert_mask.npy'", ")", ")", "\n", "self", ".", "data_train_bert_starts", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_bert_starts.npy'", ")", ")", "\n", "\n", "print", "(", "\"Finish reading\"", ")", "\n", "\n", "self", ".", "train_len", "=", "ins_num", "=", "self", ".", "data_train_word", ".", "shape", "[", "0", "]", "\n", "assert", "(", "self", ".", "train_len", "==", "len", "(", "self", ".", "train_file", ")", ")", "\n", "\n", "self", ".", "train_order", "=", "list", "(", "range", "(", "ins_num", ")", ")", "\n", "self", ".", "train_batches", "=", "ins_num", "//", "self", ".", "batch_size", "\n", "if", "ins_num", "%", "self", ".", "batch_size", "!=", "0", ":", "\n", "            ", "self", ".", "train_batches", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.load_test_data": [[162, 195], ["print", "numpy.load", "numpy.load", "json.load", "print", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "json.load", "numpy.load", "numpy.load", "numpy.load", "print", "list", "Config.Config.test_order.sort", "os.path.join", "os.path.join", "open", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "os.path.join", "os.path.join", "os.path.join", "len", "range", "os.path.join", "Config.Config.rel2id.items", "os.path.join", "numpy.sum"], "methods", ["None"], ["", "", "def", "load_test_data", "(", "self", ")", ":", "\n", "        ", "print", "(", "\"Reading testing data...\"", ")", "\n", "self", ".", "data_word_vec", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "'vec.npy'", ")", ")", "\n", "self", ".", "data_char_vec", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "'char_vec.npy'", ")", ")", "\n", "self", ".", "rel2id", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "'rel2id.json'", ")", ")", ")", "\n", "self", ".", "id2rel", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "rel2id", ".", "items", "(", ")", "}", "\n", "\n", "prefix", "=", "self", ".", "test_prefix", "\n", "print", "(", "prefix", ")", "\n", "self", ".", "is_test", "=", "(", "'dev_test'", "==", "prefix", ")", "\n", "self", ".", "data_test_word", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_word.npy'", ")", ")", "\n", "self", ".", "data_test_pos", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_pos.npy'", ")", ")", "\n", "self", ".", "data_test_ner", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_ner.npy'", ")", ")", "\n", "self", ".", "data_test_char", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_char.npy'", ")", ")", "\n", "self", ".", "test_file", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'.json'", ")", ")", ")", "\n", "\n", "self", ".", "data_test_bert_word", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_bert_word.npy'", ")", ")", "\n", "self", ".", "data_test_bert_mask", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_bert_mask.npy'", ")", ")", "\n", "self", ".", "data_test_bert_starts", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "prefix", "+", "'_bert_starts.npy'", ")", ")", "\n", "\n", "\n", "self", ".", "test_len", "=", "self", ".", "data_test_word", ".", "shape", "[", "0", "]", "\n", "assert", "(", "self", ".", "test_len", "==", "len", "(", "self", ".", "test_file", ")", ")", "\n", "\n", "\n", "print", "(", "\"Finish reading\"", ")", "\n", "\n", "self", ".", "test_batches", "=", "self", ".", "data_test_word", ".", "shape", "[", "0", "]", "//", "self", ".", "test_batch_size", "\n", "if", "self", ".", "data_test_word", ".", "shape", "[", "0", "]", "%", "self", ".", "test_batch_size", "!=", "0", ":", "\n", "            ", "self", ".", "test_batches", "+=", "1", "\n", "\n", "", "self", ".", "test_order", "=", "list", "(", "range", "(", "self", ".", "test_len", ")", ")", "\n", "self", ".", "test_order", ".", "sort", "(", "key", "=", "lambda", "x", ":", "np", ".", "sum", "(", "self", ".", "data_test_word", "[", "x", "]", ">", "0", ")", ",", "reverse", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.combine_sents": [[196, 212], ["sorted", "numpy.zeros", "sorted.append", "len"], "methods", ["None"], ["", "def", "combine_sents", "(", "self", ",", "h_idx", ",", "t_idx", ",", "vertexSet", ",", "sents_idx", ")", ":", "\n", "        ", "h_t_sent", "=", "[", "]", "\n", "for", "ins", "in", "vertexSet", "[", "h_idx", "]", "+", "vertexSet", "[", "t_idx", "]", ":", "\n", "            ", "sent_id", "=", "ins", "[", "'sent_id'", "]", "\n", "if", "sent_id", "not", "in", "h_t_sent", ":", "\n", "                ", "h_t_sent", ".", "append", "(", "sent_id", ")", "\n", "", "", "h_t_sent", "=", "sorted", "(", "h_t_sent", ")", "\n", "#print(sents_idx, h_t_sent)", "\n", "combined_sents", "=", "[", "]", "\n", "for", "idx", "in", "h_t_sent", ":", "\n", "            ", "combined_sents", "+=", "sents_idx", "[", "idx", "]", "\n", "", "combined_sents", "=", "combined_sents", "[", ":", "self", ".", "combined_sent_limit", "]", "\n", "ret_sent", "=", "np", ".", "zeros", "(", "self", ".", "combined_sent_limit", ")", "-", "1", "\n", "ret_sent", "[", ":", "len", "(", "combined_sents", ")", "]", "=", "combined_sents", "\n", "#print(ret_sent)", "\n", "return", "ret_sent", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.load_sent_idx": [[213, 224], ["enumerate", "numpy.zeros", "numpy.zeros", "list", "len", "range", "len", "len", "len"], "methods", ["None"], ["", "def", "load_sent_idx", "(", "self", ",", "ins", ")", ":", "\n", "        ", "loaded_sent_idx", "=", "ins", "[", "'sents_idx'", "]", "\n", "ret_np", "=", "np", ".", "zeros", "(", "(", "self", ".", "sent_limit", ",", "self", ".", "word_size", ")", ")", "-", "1", "\n", "reverse_sent_idx", "=", "np", ".", "zeros", "(", "(", "self", ".", "max_length", ")", ")", "-", "1", "\n", "start_idx", "=", "0", "\n", "for", "i", ",", "_", "in", "enumerate", "(", "loaded_sent_idx", ")", ":", "\n", "            ", "_", "=", "_", "[", ":", "self", ".", "word_size", "]", "\n", "ret_np", "[", "i", ",", ":", "len", "(", "_", ")", "]", "=", "_", "\n", "reverse_sent_idx", "[", "start_idx", ":", "start_idx", "+", "len", "(", "_", ")", "]", "=", "list", "(", "range", "(", "i", "*", "self", ".", "word_size", ",", "i", "*", "self", ".", "word_size", "+", "len", "(", "_", ")", ")", ")", "\n", "start_idx", "+=", "len", "(", "_", ")", "\n", "", "return", "ret_np", ",", "reverse_sent_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.get_train_batch": [[225, 391], ["random.shuffle", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "range", "min", "list", "list.sort", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.fill_", "torch.LongTensor().cuda.fill_", "torch.LongTensor().cuda.fill_", "torch.LongTensor().cuda.fill_", "enumerate", "int", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "mapping.zero_", "mapping.zero_", "context_idxs[].copy_", "context_pos[].copy_", "context_char_idxs[].copy_", "context_ner[].copy_", "context_masks[].copy_", "context_starts[].copy_", "range", "Config.Config.load_sent_idx", "sent_idxs[].copy_", "reverse_sent_idxs[].copy_", "collections.defaultdict", "list", "enumerate", "len", "min", "random.sample", "enumerate", "max", "input_lengths.max", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "idx2label[].append", "collections.defaultdict.keys", "numpy.random.randint", "len", "list", "min", "len", "context_idxs[].contiguous", "context_pos[].contiguous", "relation_label[].contiguous", "pos_idx[].contiguous", "context_ner[].contiguous", "context_char_idxs[].contiguous", "context_masks[].contiguous", "context_starts[].contiguous", "numpy.sum", "int", "len", "len", "range", "len", "int", "len", "int", "len", "int", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.load_sent_idx"], ["", "def", "get_train_batch", "(", "self", ")", ":", "\n", "        ", "random", ".", "shuffle", "(", "self", ".", "train_order", ")", "\n", "\n", "context_idxs", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "context_pos", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "h_mapping", "=", "torch", ".", "Tensor", "(", "self", ".", "batch_size", ",", "self", ".", "h_t_limit", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "t_mapping", "=", "torch", ".", "Tensor", "(", "self", ".", "batch_size", ",", "self", ".", "h_t_limit", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "relation_multi_label", "=", "torch", ".", "Tensor", "(", "self", ".", "batch_size", ",", "self", ".", "h_t_limit", ",", "self", ".", "relation_num", ")", ".", "cuda", "(", ")", "\n", "relation_mask", "=", "torch", ".", "Tensor", "(", "self", ".", "batch_size", ",", "self", ".", "h_t_limit", ")", ".", "cuda", "(", ")", "\n", "\n", "context_masks", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "context_starts", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "\n", "pos_idx", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "\n", "context_ner", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "context_char_idxs", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ",", "self", ".", "char_limit", ")", ".", "cuda", "(", ")", "\n", "\n", "relation_label", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "h_t_limit", ")", ".", "cuda", "(", ")", "\n", "\n", "\n", "ht_pair_pos", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "h_t_limit", ")", ".", "cuda", "(", ")", "\n", "\n", "sent_idxs", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "sent_limit", ",", "self", ".", "word_size", ")", ".", "cuda", "(", ")", "\n", "reverse_sent_idxs", "=", "torch", ".", "LongTensor", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "\n", "for", "b", "in", "range", "(", "self", ".", "train_batches", ")", ":", "\n", "            ", "start_id", "=", "b", "*", "self", ".", "batch_size", "\n", "cur_bsz", "=", "min", "(", "self", ".", "batch_size", ",", "self", ".", "train_len", "-", "start_id", ")", "\n", "cur_batch", "=", "list", "(", "self", ".", "train_order", "[", "start_id", ":", "start_id", "+", "cur_bsz", "]", ")", "\n", "cur_batch", ".", "sort", "(", "key", "=", "lambda", "x", ":", "np", ".", "sum", "(", "self", ".", "data_train_word", "[", "x", "]", ">", "0", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "for", "mapping", "in", "[", "h_mapping", ",", "t_mapping", "]", ":", "\n", "                ", "mapping", ".", "zero_", "(", ")", "\n", "\n", "", "for", "mapping", "in", "[", "relation_multi_label", ",", "relation_mask", ",", "pos_idx", "]", ":", "\n", "                ", "mapping", ".", "zero_", "(", ")", "\n", "\n", "", "ht_pair_pos", ".", "zero_", "(", ")", "\n", "\n", "sent_idxs", ".", "zero_", "(", ")", "\n", "sent_idxs", "-=", "1", "\n", "reverse_sent_idxs", ".", "zero_", "(", ")", "\n", "reverse_sent_idxs", "-=", "1", "\n", "\n", "\n", "relation_label", ".", "fill_", "(", "IGNORE_INDEX", ")", "\n", "\n", "max_h_t_cnt", "=", "1", "\n", "\n", "\n", "for", "i", ",", "index", "in", "enumerate", "(", "cur_batch", ")", ":", "\n", "#context_idxs[i].copy_(torch.from_numpy(self.data_train_word[index, :]))", "\n", "                ", "context_idxs", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_train_bert_word", "[", "index", ",", ":", "]", ")", ")", "\n", "context_pos", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_train_pos", "[", "index", ",", ":", "]", ")", ")", "\n", "context_char_idxs", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_train_char", "[", "index", ",", ":", "]", ")", ")", "\n", "context_ner", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_train_ner", "[", "index", ",", ":", "]", ")", ")", "\n", "\n", "context_masks", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_train_bert_mask", "[", "index", ",", ":", "]", ")", ")", "\n", "context_starts", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_train_bert_starts", "[", "index", ",", ":", "]", ")", ")", "\n", "\n", "for", "j", "in", "range", "(", "self", ".", "max_length", ")", ":", "\n", "                    ", "if", "self", ".", "data_train_word", "[", "index", ",", "j", "]", "==", "0", ":", "\n", "                        ", "break", "\n", "", "pos_idx", "[", "i", ",", "j", "]", "=", "j", "+", "1", "\n", "\n", "", "ins", "=", "self", ".", "train_file", "[", "index", "]", "\n", "this_sent_idxs", ",", "this_reverse_sent_idxs", "=", "self", ".", "load_sent_idx", "(", "ins", ")", "\n", "sent_idxs", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "this_sent_idxs", ")", ")", "\n", "reverse_sent_idxs", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "this_reverse_sent_idxs", ")", ")", "\n", "labels", "=", "ins", "[", "'labels'", "]", "\n", "idx2label", "=", "defaultdict", "(", "list", ")", "\n", "\n", "for", "label", "in", "labels", ":", "\n", "                    ", "idx2label", "[", "(", "label", "[", "'h'", "]", ",", "label", "[", "'t'", "]", ")", "]", ".", "append", "(", "label", "[", "'r'", "]", ")", "\n", "\n", "\n", "", "train_tripe", "=", "list", "(", "idx2label", ".", "keys", "(", ")", ")", "\n", "for", "j", ",", "(", "h_idx", ",", "t_idx", ")", "in", "enumerate", "(", "train_tripe", ")", ":", "\n", "                    ", "if", "j", "==", "self", ".", "h_t_limit", ":", "\n", "                        ", "break", "\n", "", "hlist", "=", "ins", "[", "'vertexSet'", "]", "[", "h_idx", "]", "\n", "tlist", "=", "ins", "[", "'vertexSet'", "]", "[", "t_idx", "]", "\n", "\n", "for", "h", "in", "hlist", ":", "\n", "                        ", "h_mapping", "[", "i", ",", "j", ",", "h", "[", "'pos'", "]", "[", "0", "]", ":", "h", "[", "'pos'", "]", "[", "1", "]", "]", "=", "1.0", "/", "len", "(", "hlist", ")", "/", "(", "h", "[", "'pos'", "]", "[", "1", "]", "-", "h", "[", "'pos'", "]", "[", "0", "]", ")", "\n", "\n", "", "for", "t", "in", "tlist", ":", "\n", "                        ", "t_mapping", "[", "i", ",", "j", ",", "t", "[", "'pos'", "]", "[", "0", "]", ":", "t", "[", "'pos'", "]", "[", "1", "]", "]", "=", "1.0", "/", "len", "(", "tlist", ")", "/", "(", "t", "[", "'pos'", "]", "[", "1", "]", "-", "t", "[", "'pos'", "]", "[", "0", "]", ")", "\n", "\n", "", "label", "=", "idx2label", "[", "(", "h_idx", ",", "t_idx", ")", "]", "\n", "\n", "delta_dis", "=", "hlist", "[", "0", "]", "[", "'pos'", "]", "[", "0", "]", "-", "tlist", "[", "0", "]", "[", "'pos'", "]", "[", "0", "]", "\n", "if", "delta_dis", "<", "0", ":", "\n", "                        ", "ht_pair_pos", "[", "i", ",", "j", "]", "=", "-", "int", "(", "self", ".", "dis2idx", "[", "-", "delta_dis", "]", ")", "\n", "", "else", ":", "\n", "                        ", "ht_pair_pos", "[", "i", ",", "j", "]", "=", "int", "(", "self", ".", "dis2idx", "[", "delta_dis", "]", ")", "\n", "\n", "\n", "", "for", "r", "in", "label", ":", "\n", "                        ", "relation_multi_label", "[", "i", ",", "j", ",", "r", "]", "=", "1", "\n", "\n", "", "relation_mask", "[", "i", ",", "j", "]", "=", "1", "\n", "rt", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "label", ")", ")", "\n", "relation_label", "[", "i", ",", "j", "]", "=", "label", "[", "rt", "]", "\n", "\n", "\n", "\n", "", "lower_bound", "=", "len", "(", "ins", "[", "'na_triple'", "]", ")", "\n", "# random.shuffle(ins['na_triple'])", "\n", "# lower_bound = max(20, len(train_tripe)*3)", "\n", "\n", "lower_bound", "=", "min", "(", "len", "(", "ins", "[", "'na_triple'", "]", ")", ",", "len", "(", "train_tripe", ")", "*", "3", ")", "\n", "sel_idx", "=", "random", ".", "sample", "(", "list", "(", "range", "(", "len", "(", "ins", "[", "'na_triple'", "]", ")", ")", ")", ",", "min", "(", "len", "(", "ins", "[", "'na_triple'", "]", ")", ",", "lower_bound", ")", ")", "\n", "sel_ins", "=", "[", "ins", "[", "'na_triple'", "]", "[", "s_i", "]", "for", "s_i", "in", "sel_idx", "]", "\n", "#sel_ins = []", "\n", "#for j, (h_idx, t_idx) in enumerate(ins['na_triple'], len(train_tripe)):", "\n", "for", "j", ",", "(", "h_idx", ",", "t_idx", ")", "in", "enumerate", "(", "sel_ins", ",", "len", "(", "train_tripe", ")", ")", ":", "\n", "                    ", "if", "j", "==", "self", ".", "h_t_limit", ":", "\n", "                        ", "break", "\n", "", "hlist", "=", "ins", "[", "'vertexSet'", "]", "[", "h_idx", "]", "\n", "tlist", "=", "ins", "[", "'vertexSet'", "]", "[", "t_idx", "]", "\n", "\n", "for", "h", "in", "hlist", ":", "\n", "                        ", "h_mapping", "[", "i", ",", "j", ",", "h", "[", "'pos'", "]", "[", "0", "]", ":", "h", "[", "'pos'", "]", "[", "1", "]", "]", "=", "1.0", "/", "len", "(", "hlist", ")", "/", "(", "h", "[", "'pos'", "]", "[", "1", "]", "-", "h", "[", "'pos'", "]", "[", "0", "]", ")", "\n", "\n", "", "for", "t", "in", "tlist", ":", "\n", "                        ", "t_mapping", "[", "i", ",", "j", ",", "t", "[", "'pos'", "]", "[", "0", "]", ":", "t", "[", "'pos'", "]", "[", "1", "]", "]", "=", "1.0", "/", "len", "(", "tlist", ")", "/", "(", "t", "[", "'pos'", "]", "[", "1", "]", "-", "t", "[", "'pos'", "]", "[", "0", "]", ")", "\n", "\n", "", "relation_multi_label", "[", "i", ",", "j", ",", "0", "]", "=", "1", "\n", "relation_label", "[", "i", ",", "j", "]", "=", "0", "\n", "relation_mask", "[", "i", ",", "j", "]", "=", "1", "\n", "delta_dis", "=", "hlist", "[", "0", "]", "[", "'pos'", "]", "[", "0", "]", "-", "tlist", "[", "0", "]", "[", "'pos'", "]", "[", "0", "]", "\n", "if", "delta_dis", "<", "0", ":", "\n", "                        ", "ht_pair_pos", "[", "i", ",", "j", "]", "=", "-", "int", "(", "self", ".", "dis2idx", "[", "-", "delta_dis", "]", ")", "\n", "", "else", ":", "\n", "                        ", "ht_pair_pos", "[", "i", ",", "j", "]", "=", "int", "(", "self", ".", "dis2idx", "[", "delta_dis", "]", ")", "\n", "#print(max_h_t_cnt)", "\n", "\n", "", "", "max_h_t_cnt", "=", "max", "(", "max_h_t_cnt", ",", "len", "(", "train_tripe", ")", "+", "lower_bound", ")", "\n", "\n", "\n", "", "input_lengths", "=", "(", "context_idxs", "[", ":", "cur_bsz", "]", ">", "0", ")", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "max_c_len", "=", "int", "(", "input_lengths", ".", "max", "(", ")", ")", "\n", "sent_lengths", "=", "(", "sent_idxs", "[", ":", "cur_bsz", "]", ">", "0", ")", ".", "long", "(", ")", ".", "sum", "(", "-", "1", ")", "\n", "#print(reverse_sent_idxs[0])", "\n", "#print(sent_idxs, sent_idxs.size())", "\n", "#print(sent_lengths, sent_lengths.size())", "\n", "\n", "yield", "{", "'context_idxs'", ":", "context_idxs", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'context_pos'", ":", "context_pos", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'h_mapping'", ":", "h_mapping", "[", ":", "cur_bsz", ",", ":", "max_h_t_cnt", ",", ":", "max_c_len", "]", ",", "\n", "'t_mapping'", ":", "t_mapping", "[", ":", "cur_bsz", ",", ":", "max_h_t_cnt", ",", ":", "max_c_len", "]", ",", "\n", "'relation_label'", ":", "relation_label", "[", ":", "cur_bsz", ",", ":", "max_h_t_cnt", "]", ".", "contiguous", "(", ")", ",", "\n", "'input_lengths'", ":", "input_lengths", ",", "\n", "'pos_idx'", ":", "pos_idx", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'relation_multi_label'", ":", "relation_multi_label", "[", ":", "cur_bsz", ",", ":", "max_h_t_cnt", "]", ",", "\n", "'relation_mask'", ":", "relation_mask", "[", ":", "cur_bsz", ",", ":", "max_h_t_cnt", "]", ",", "\n", "'context_ner'", ":", "context_ner", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'context_char_idxs'", ":", "context_char_idxs", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'ht_pair_pos'", ":", "ht_pair_pos", "[", ":", "cur_bsz", ",", ":", "max_h_t_cnt", "]", ",", "\n", "'sent_idxs'", ":", "sent_idxs", "[", ":", "cur_bsz", "]", ",", "\n", "'sent_lengths'", ":", "sent_lengths", "[", ":", "cur_bsz", "]", ",", "\n", "'reverse_sent_idxs'", ":", "reverse_sent_idxs", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ",", "\n", "'context_masks'", ":", "context_masks", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'context_starts'", ":", "context_starts", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.get_test_batch": [[393, 522], ["torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "range", "min", "list", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "torch.LongTensor().cuda.zero_", "list.sort", "enumerate", "int", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "mapping.zero_", "context_idxs[].copy_", "context_pos[].copy_", "context_char_idxs[].copy_", "context_ner[].copy_", "context_masks[].copy_", "context_starts[].copy_", "collections.defaultdict", "Config.Config.load_sent_idx", "sent_idxs[].copy_", "reverse_sent_idxs[].copy_", "len", "titles.append", "range", "max", "labels.append", "evi_nums.append", "L_vertex.append", "indexes.append", "input_lengths.max", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "idx2label[].append", "range", "len", "context_idxs[].contiguous", "context_pos[].contiguous", "context_ner[].contiguous", "context_char_idxs[].contiguous", "context_masks[].contiguous", "context_starts[].contiguous", "numpy.sum", "int", "int", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.load_sent_idx"], ["", "", "def", "get_test_batch", "(", "self", ")", ":", "\n", "        ", "context_idxs", "=", "torch", ".", "LongTensor", "(", "self", ".", "test_batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "context_pos", "=", "torch", ".", "LongTensor", "(", "self", ".", "test_batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "h_mapping", "=", "torch", ".", "Tensor", "(", "self", ".", "test_batch_size", ",", "self", ".", "test_relation_limit", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "t_mapping", "=", "torch", ".", "Tensor", "(", "self", ".", "test_batch_size", ",", "self", ".", "test_relation_limit", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "context_ner", "=", "torch", ".", "LongTensor", "(", "self", ".", "test_batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "context_char_idxs", "=", "torch", ".", "LongTensor", "(", "self", ".", "test_batch_size", ",", "self", ".", "max_length", ",", "self", ".", "char_limit", ")", ".", "cuda", "(", ")", "\n", "relation_mask", "=", "torch", ".", "Tensor", "(", "self", ".", "test_batch_size", ",", "self", ".", "h_t_limit", ")", ".", "cuda", "(", ")", "\n", "ht_pair_pos", "=", "torch", ".", "LongTensor", "(", "self", ".", "test_batch_size", ",", "self", ".", "h_t_limit", ")", ".", "cuda", "(", ")", "\n", "sent_idxs", "=", "torch", ".", "LongTensor", "(", "self", ".", "test_batch_size", ",", "self", ".", "sent_limit", ",", "self", ".", "word_size", ")", ".", "cuda", "(", ")", "\n", "reverse_sent_idxs", "=", "torch", ".", "LongTensor", "(", "self", ".", "test_batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "\n", "context_masks", "=", "torch", ".", "LongTensor", "(", "self", ".", "test_batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "context_starts", "=", "torch", ".", "LongTensor", "(", "self", ".", "test_batch_size", ",", "self", ".", "max_length", ")", ".", "cuda", "(", ")", "\n", "\n", "for", "b", "in", "range", "(", "self", ".", "test_batches", ")", ":", "\n", "            ", "start_id", "=", "b", "*", "self", ".", "test_batch_size", "\n", "cur_bsz", "=", "min", "(", "self", ".", "test_batch_size", ",", "self", ".", "test_len", "-", "start_id", ")", "\n", "cur_batch", "=", "list", "(", "self", ".", "test_order", "[", "start_id", ":", "start_id", "+", "cur_bsz", "]", ")", "\n", "\n", "for", "mapping", "in", "[", "h_mapping", ",", "t_mapping", ",", "relation_mask", "]", ":", "\n", "                ", "mapping", ".", "zero_", "(", ")", "\n", "\n", "\n", "", "ht_pair_pos", ".", "zero_", "(", ")", "\n", "\n", "sent_idxs", ".", "zero_", "(", ")", "\n", "sent_idxs", "-=", "1", "\n", "reverse_sent_idxs", ".", "zero_", "(", ")", "\n", "reverse_sent_idxs", "-=", "1", "\n", "\n", "max_h_t_cnt", "=", "1", "\n", "\n", "cur_batch", ".", "sort", "(", "key", "=", "lambda", "x", ":", "np", ".", "sum", "(", "self", ".", "data_test_word", "[", "x", "]", ">", "0", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "labels", "=", "[", "]", "\n", "\n", "L_vertex", "=", "[", "]", "\n", "titles", "=", "[", "]", "\n", "indexes", "=", "[", "]", "\n", "\n", "evi_nums", "=", "[", "]", "\n", "\n", "for", "i", ",", "index", "in", "enumerate", "(", "cur_batch", ")", ":", "\n", "#context_idxs[i].copy_(torch.from_numpy(self.data_test_word[index, :]))", "\n", "                ", "context_idxs", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_test_bert_word", "[", "index", ",", ":", "]", ")", ")", "\n", "context_pos", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_test_pos", "[", "index", ",", ":", "]", ")", ")", "\n", "context_char_idxs", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_test_char", "[", "index", ",", ":", "]", ")", ")", "\n", "context_ner", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_test_ner", "[", "index", ",", ":", "]", ")", ")", "\n", "\n", "context_masks", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_test_bert_mask", "[", "index", ",", ":", "]", ")", ")", "\n", "context_starts", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "data_test_bert_starts", "[", "index", ",", ":", "]", ")", ")", "\n", "\n", "idx2label", "=", "defaultdict", "(", "list", ")", "\n", "ins", "=", "self", ".", "test_file", "[", "index", "]", "\n", "this_sent_idxs", ",", "this_reverse_sent_idxs", "=", "self", ".", "load_sent_idx", "(", "ins", ")", "\n", "sent_idxs", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "this_sent_idxs", ")", ")", "\n", "reverse_sent_idxs", "[", "i", "]", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "this_reverse_sent_idxs", ")", ")", "\n", "\n", "for", "label", "in", "ins", "[", "'labels'", "]", ":", "\n", "                    ", "idx2label", "[", "(", "label", "[", "'h'", "]", ",", "label", "[", "'t'", "]", ")", "]", ".", "append", "(", "label", "[", "'r'", "]", ")", "\n", "\n", "\n", "", "L", "=", "len", "(", "ins", "[", "'vertexSet'", "]", ")", "\n", "titles", ".", "append", "(", "ins", "[", "'title'", "]", ")", "\n", "\n", "j", "=", "0", "\n", "for", "h_idx", "in", "range", "(", "L", ")", ":", "\n", "                    ", "for", "t_idx", "in", "range", "(", "L", ")", ":", "\n", "                        ", "if", "h_idx", "!=", "t_idx", ":", "\n", "                            ", "hlist", "=", "ins", "[", "'vertexSet'", "]", "[", "h_idx", "]", "\n", "tlist", "=", "ins", "[", "'vertexSet'", "]", "[", "t_idx", "]", "\n", "\n", "\n", "for", "h", "in", "hlist", ":", "\n", "                                ", "h_mapping", "[", "i", ",", "j", ",", "h", "[", "'pos'", "]", "[", "0", "]", ":", "h", "[", "'pos'", "]", "[", "1", "]", "]", "=", "1.0", "/", "len", "(", "hlist", ")", "/", "(", "h", "[", "'pos'", "]", "[", "1", "]", "-", "h", "[", "'pos'", "]", "[", "0", "]", ")", "\n", "", "for", "t", "in", "tlist", ":", "\n", "                                ", "t_mapping", "[", "i", ",", "j", ",", "t", "[", "'pos'", "]", "[", "0", "]", ":", "t", "[", "'pos'", "]", "[", "1", "]", "]", "=", "1.0", "/", "len", "(", "tlist", ")", "/", "(", "t", "[", "'pos'", "]", "[", "1", "]", "-", "t", "[", "'pos'", "]", "[", "0", "]", ")", "\n", "\n", "", "relation_mask", "[", "i", ",", "j", "]", "=", "1", "\n", "\n", "delta_dis", "=", "hlist", "[", "0", "]", "[", "'pos'", "]", "[", "0", "]", "-", "tlist", "[", "0", "]", "[", "'pos'", "]", "[", "0", "]", "\n", "if", "delta_dis", "<", "0", ":", "\n", "                                ", "ht_pair_pos", "[", "i", ",", "j", "]", "=", "-", "int", "(", "self", ".", "dis2idx", "[", "-", "delta_dis", "]", ")", "\n", "", "else", ":", "\n", "                                ", "ht_pair_pos", "[", "i", ",", "j", "]", "=", "int", "(", "self", ".", "dis2idx", "[", "delta_dis", "]", ")", "\n", "", "j", "+=", "1", "\n", "\n", "\n", "", "", "", "max_h_t_cnt", "=", "max", "(", "max_h_t_cnt", ",", "j", ")", "\n", "label_set", "=", "{", "}", "\n", "evi_num_set", "=", "{", "}", "\n", "for", "label", "in", "ins", "[", "'labels'", "]", ":", "\n", "                    ", "label_set", "[", "(", "label", "[", "'h'", "]", ",", "label", "[", "'t'", "]", ",", "label", "[", "'r'", "]", ")", "]", "=", "label", "[", "'in'", "+", "self", ".", "train_prefix", "]", "\n", "evi_num_set", "[", "(", "label", "[", "'h'", "]", ",", "label", "[", "'t'", "]", ",", "label", "[", "'r'", "]", ")", "]", "=", "len", "(", "label", "[", "'evidence'", "]", ")", "\n", "\n", "", "labels", ".", "append", "(", "label_set", ")", "\n", "evi_nums", ".", "append", "(", "evi_num_set", ")", "\n", "\n", "\n", "L_vertex", ".", "append", "(", "L", ")", "\n", "indexes", ".", "append", "(", "index", ")", "\n", "\n", "\n", "\n", "", "input_lengths", "=", "(", "context_idxs", "[", ":", "cur_bsz", "]", ">", "0", ")", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "max_c_len", "=", "int", "(", "input_lengths", ".", "max", "(", ")", ")", "\n", "sent_lengths", "=", "(", "sent_idxs", "[", ":", "cur_bsz", "]", ">", "0", ")", ".", "long", "(", ")", ".", "sum", "(", "-", "1", ")", "\n", "\n", "\n", "yield", "{", "'context_idxs'", ":", "context_idxs", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'context_pos'", ":", "context_pos", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'h_mapping'", ":", "h_mapping", "[", ":", "cur_bsz", ",", ":", "max_h_t_cnt", ",", ":", "max_c_len", "]", ",", "\n", "'t_mapping'", ":", "t_mapping", "[", ":", "cur_bsz", ",", ":", "max_h_t_cnt", ",", ":", "max_c_len", "]", ",", "\n", "'labels'", ":", "labels", ",", "\n", "'L_vertex'", ":", "L_vertex", ",", "\n", "'input_lengths'", ":", "input_lengths", ",", "\n", "'context_ner'", ":", "context_ner", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'context_char_idxs'", ":", "context_char_idxs", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'relation_mask'", ":", "relation_mask", "[", ":", "cur_bsz", ",", ":", "max_h_t_cnt", "]", ",", "\n", "'titles'", ":", "titles", ",", "\n", "'ht_pair_pos'", ":", "ht_pair_pos", "[", ":", "cur_bsz", ",", ":", "max_h_t_cnt", "]", ",", "\n", "'indexes'", ":", "indexes", ",", "\n", "'sent_idxs'", ":", "sent_idxs", "[", ":", "cur_bsz", "]", ",", "\n", "'sent_lengths'", ":", "sent_lengths", "[", ":", "cur_bsz", "]", ",", "\n", "'reverse_sent_idxs'", ":", "reverse_sent_idxs", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ",", "\n", "'context_masks'", ":", "context_masks", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'context_starts'", ":", "context_starts", "[", ":", "cur_bsz", ",", ":", "max_c_len", "]", ".", "contiguous", "(", ")", ",", "\n", "'evi_num_set'", ":", "evi_nums", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.train": [[524, 660], ["model_pattern", "model_pattern.cuda", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.DataParallel.train", "time.time", "matplotlib.xlabel", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.ylabel", "matplotlib.ylim", "matplotlib.ylim", "matplotlib.xlim", "matplotlib.xlim", "matplotlib.title", "matplotlib.title", "matplotlib.grid", "matplotlib.grid", "range", "print", "print", "print", "print", "model_pattern.load_state_dict", "filter", "os.path.exists", "os.mkdir", "Config.Config.acc_NA.clear", "Config.Config.acc_not_NA.clear", "Config.Config.acc_total.clear", "Config.Config.get_train_batch", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.DataParallel.parameters", "print", "torch.DataParallel.", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "output.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "torch.Adam.zero_grad", "loss.backward", "torch.Adam.step", "relation_label.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "range", "loss.item", "Config.Config.train.logging"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.train", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.clear", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.clear", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Accuracy.clear", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.get_train_batch"], ["", "", "def", "train", "(", "self", ",", "model_pattern", ",", "model_name", ")", ":", "\n", "\n", "        ", "ori_model", "=", "model_pattern", "(", "config", "=", "self", ")", "\n", "if", "self", ".", "pretrain_model", "!=", "None", ":", "\n", "            ", "ori_model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "pretrain_model", ")", ")", "\n", "", "ori_model", ".", "cuda", "(", ")", "\n", "model", "=", "nn", ".", "DataParallel", "(", "ori_model", ")", "\n", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", ",", "lr", "=", "1e-5", ")", "\n", "# nll_average = nn.CrossEntropyLoss(size_average=True, ignore_index=IGNORE_INDEX)", "\n", "BCE", "=", "nn", ".", "BCEWithLogitsLoss", "(", "reduction", "=", "'none'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "checkpoint_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "self", ".", "checkpoint_dir", ")", "\n", "\n", "", "best_auc", "=", "0.0", "\n", "best_f1", "=", "0.0", "\n", "best_epoch", "=", "0", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "global_step", "=", "0", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "def", "logging", "(", "s", ",", "print_", "=", "True", ",", "log_", "=", "True", ")", ":", "\n", "            ", "if", "print_", ":", "\n", "                ", "print", "(", "s", ")", "\n", "", "if", "log_", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "\"log\"", ",", "model_name", ")", ")", ",", "'a+'", ")", "as", "f_log", ":", "\n", "                    ", "f_log", ".", "write", "(", "s", "+", "'\\n'", ")", "\n", "\n", "", "", "", "plt", ".", "xlabel", "(", "'Recall'", ")", "\n", "plt", ".", "ylabel", "(", "'Precision'", ")", "\n", "plt", ".", "ylim", "(", "0.3", ",", "1.0", ")", "\n", "plt", ".", "xlim", "(", "0.0", ",", "0.4", ")", "\n", "plt", ".", "title", "(", "'Precision-Recall'", ")", "\n", "plt", ".", "grid", "(", "True", ")", "\n", "\n", "#model.eval()", "\n", "#f1, auc, pr_x, pr_y = self.test(model, model_name)", "\n", "\n", "for", "epoch", "in", "range", "(", "self", ".", "max_epoch", ")", ":", "\n", "\n", "            ", "self", ".", "acc_NA", ".", "clear", "(", ")", "\n", "self", ".", "acc_not_NA", ".", "clear", "(", ")", "\n", "self", ".", "acc_total", ".", "clear", "(", ")", "\n", "\n", "for", "data", "in", "self", ".", "get_train_batch", "(", ")", ":", "\n", "\n", "                ", "context_idxs", "=", "data", "[", "'context_idxs'", "]", "\n", "context_pos", "=", "data", "[", "'context_pos'", "]", "\n", "h_mapping", "=", "data", "[", "'h_mapping'", "]", "\n", "t_mapping", "=", "data", "[", "'t_mapping'", "]", "\n", "relation_label", "=", "data", "[", "'relation_label'", "]", "\n", "input_lengths", "=", "data", "[", "'input_lengths'", "]", "\n", "relation_multi_label", "=", "data", "[", "'relation_multi_label'", "]", "\n", "relation_mask", "=", "data", "[", "'relation_mask'", "]", "\n", "context_ner", "=", "data", "[", "'context_ner'", "]", "\n", "context_char_idxs", "=", "data", "[", "'context_char_idxs'", "]", "\n", "ht_pair_pos", "=", "data", "[", "'ht_pair_pos'", "]", "\n", "sent_idxs", "=", "data", "[", "'sent_idxs'", "]", "\n", "sent_lengths", "=", "data", "[", "'sent_lengths'", "]", "\n", "reverse_sent_idxs", "=", "data", "[", "'reverse_sent_idxs'", "]", "\n", "\n", "context_masks", "=", "data", "[", "'context_masks'", "]", "\n", "context_starts", "=", "data", "[", "'context_starts'", "]", "\n", "\n", "\n", "dis_h_2_t", "=", "ht_pair_pos", "+", "10", "\n", "dis_t_2_h", "=", "-", "ht_pair_pos", "+", "10", "\n", "\n", "\n", "predict_re", "=", "model", "(", "context_idxs", ",", "context_pos", ",", "context_ner", ",", "context_char_idxs", ",", "input_lengths", ",", "h_mapping", ",", "t_mapping", ",", "relation_mask", ",", "dis_h_2_t", ",", "dis_t_2_h", ",", "sent_idxs", ",", "sent_lengths", ",", "reverse_sent_idxs", ",", "context_masks", ",", "context_starts", ")", "\n", "loss", "=", "torch", ".", "sum", "(", "BCE", "(", "predict_re", ",", "relation_multi_label", ")", "*", "relation_mask", ".", "unsqueeze", "(", "2", ")", ")", "/", "(", "self", ".", "relation_num", "*", "torch", ".", "sum", "(", "relation_mask", ")", ")", "\n", "\n", "\n", "output", "=", "torch", ".", "argmax", "(", "predict_re", ",", "dim", "=", "-", "1", ")", "\n", "output", "=", "output", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "relation_label", "=", "relation_label", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "output", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "for", "j", "in", "range", "(", "output", ".", "shape", "[", "1", "]", ")", ":", "\n", "                        ", "label", "=", "relation_label", "[", "i", "]", "[", "j", "]", "\n", "if", "label", "<", "0", ":", "\n", "                            ", "break", "\n", "\n", "", "if", "label", "==", "0", ":", "\n", "                            ", "self", ".", "acc_NA", ".", "add", "(", "output", "[", "i", "]", "[", "j", "]", "==", "label", ")", "\n", "", "else", ":", "\n", "                            ", "self", ".", "acc_not_NA", ".", "add", "(", "output", "[", "i", "]", "[", "j", "]", "==", "label", ")", "\n", "\n", "", "self", ".", "acc_total", ".", "add", "(", "output", "[", "i", "]", "[", "j", "]", "==", "label", ")", "\n", "\n", "", "", "global_step", "+=", "1", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "if", "global_step", "%", "self", ".", "period", "==", "0", ":", "\n", "                    ", "cur_loss", "=", "total_loss", "/", "self", ".", "period", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "logging", "(", "'| epoch {:2d} | step {:4d} |  ms/b {:5.2f} | train loss {:5.3f} | NA acc: {:4.2f} | not NA acc: {:4.2f}  | tot acc: {:4.2f} '", ".", "format", "(", "epoch", ",", "global_step", ",", "elapsed", "*", "1000", "/", "self", ".", "period", ",", "cur_loss", ",", "self", ".", "acc_NA", ".", "get", "(", ")", ",", "self", ".", "acc_not_NA", ".", "get", "(", ")", ",", "self", ".", "acc_total", ".", "get", "(", ")", ")", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "\n", "\n", "", "", "if", "(", "epoch", "+", "1", ")", "%", "self", ".", "test_epoch", "==", "0", ":", "\n", "                ", "logging", "(", "'-'", "*", "89", ")", "\n", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "f1", ",", "auc", ",", "pr_x", ",", "pr_y", "=", "self", ".", "test", "(", "model", ",", "model_name", ")", "\n", "model", ".", "train", "(", ")", "\n", "logging", "(", "'| epoch {:3d} | time: {:5.2f}s'", ".", "format", "(", "epoch", ",", "time", ".", "time", "(", ")", "-", "eval_start_time", ")", ")", "\n", "logging", "(", "'-'", "*", "89", ")", "\n", "\n", "\n", "if", "f1", ">", "best_f1", ":", "\n", "                    ", "best_f1", "=", "f1", "\n", "best_auc", "=", "auc", "\n", "best_epoch", "=", "epoch", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoint_dir", ",", "model_name", ")", "\n", "torch", ".", "save", "(", "ori_model", ".", "state_dict", "(", ")", ",", "path", ")", "\n", "\n", "plt", ".", "plot", "(", "pr_x", ",", "pr_y", ",", "lw", "=", "2", ",", "label", "=", "str", "(", "epoch", ")", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "\"upper right\"", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "\"fig_result\"", ",", "model_name", ")", ")", "\n", "\n", "", "", "", "print", "(", "\"Finish training\"", ")", "\n", "print", "(", "\"Best epoch = %d | auc = %f\"", "%", "(", "best_epoch", ",", "best_auc", ")", ")", "\n", "print", "(", "\"Storing best result...\"", ")", "\n", "print", "(", "\"Finish storing\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.test": [[661, 863], ["time.time", "Config.Config.get_test_batch", "test_result.sort", "print", "print", "print", "print", "matplotlib.xlabel", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.ylabel", "matplotlib.ylim", "matplotlib.ylim", "matplotlib.xlim", "matplotlib.xlim", "matplotlib.title", "matplotlib.title", "matplotlib.grid", "matplotlib.grid", "enumerate", "numpy.asarray", "numpy.asarray", "f1_arr.max", "f1_arr.argmax", "sklearn.metrics.auc", "matplotlib.plot", "matplotlib.plot", "matplotlib.legend", "matplotlib.legend", "matplotlib.savefig", "matplotlib.savefig", "enumerate", "numpy.asarray", "numpy.asarray", "f1_arr.max", "sklearn.metrics.auc", "Config.Config.train.logging"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.get_test_batch"], ["", "def", "test", "(", "self", ",", "model", ",", "model_name", ",", "output", "=", "False", ",", "input_theta", "=", "-", "1", ",", "two_phase", "=", "False", ",", "pretrain_model", "=", "None", ")", ":", "\n", "        ", "data_idx", "=", "0", "\n", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "# test_result_ignore = []", "\n", "total_recall_ignore", "=", "0", "\n", "\n", "test_result", "=", "[", "]", "\n", "total_recall", "=", "0", "\n", "top1_acc", "=", "have_label", "=", "0", "\n", "\n", "predicted_as_zero", "=", "0", "\n", "total_ins_num", "=", "0", "\n", "\n", "def", "logging", "(", "s", ",", "print_", "=", "True", ",", "log_", "=", "True", ")", ":", "\n", "            ", "if", "print_", ":", "\n", "                ", "print", "(", "s", ")", "\n", "", "if", "log_", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "\"log\"", ",", "model_name", ")", ")", ",", "'a+'", ")", "as", "f_log", ":", "\n", "                    ", "f_log", ".", "write", "(", "s", "+", "'\\n'", ")", "\n", "\n", "\n", "\n", "", "", "", "for", "data", "in", "self", ".", "get_test_batch", "(", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "context_idxs", "=", "data", "[", "'context_idxs'", "]", "\n", "context_pos", "=", "data", "[", "'context_pos'", "]", "\n", "h_mapping", "=", "data", "[", "'h_mapping'", "]", "\n", "t_mapping", "=", "data", "[", "'t_mapping'", "]", "\n", "labels", "=", "data", "[", "'labels'", "]", "\n", "L_vertex", "=", "data", "[", "'L_vertex'", "]", "\n", "input_lengths", "=", "data", "[", "'input_lengths'", "]", "\n", "context_ner", "=", "data", "[", "'context_ner'", "]", "\n", "context_char_idxs", "=", "data", "[", "'context_char_idxs'", "]", "\n", "relation_mask", "=", "data", "[", "'relation_mask'", "]", "\n", "ht_pair_pos", "=", "data", "[", "'ht_pair_pos'", "]", "\n", "sent_idxs", "=", "data", "[", "'sent_idxs'", "]", "\n", "sent_lengths", "=", "data", "[", "'sent_lengths'", "]", "\n", "reverse_sent_idxs", "=", "data", "[", "'reverse_sent_idxs'", "]", "\n", "context_masks", "=", "data", "[", "'context_masks'", "]", "\n", "context_starts", "=", "data", "[", "'context_starts'", "]", "\n", "\n", "titles", "=", "data", "[", "'titles'", "]", "\n", "indexes", "=", "data", "[", "'indexes'", "]", "\n", "\n", "dis_h_2_t", "=", "ht_pair_pos", "+", "10", "\n", "dis_t_2_h", "=", "-", "ht_pair_pos", "+", "10", "\n", "\n", "if", "two_phase", ":", "\n", "                    ", "is_rel_exist", "=", "pretrain_model", "(", "context_idxs", ",", "context_pos", ",", "context_ner", ",", "context_char_idxs", ",", "input_lengths", ",", "\n", "h_mapping", ",", "t_mapping", ",", "relation_mask", ",", "dis_h_2_t", ",", "dis_t_2_h", ",", "sent_idxs", ",", "sent_lengths", ",", "reverse_sent_idxs", ",", "context_masks", ",", "context_starts", ")", "\n", "\n", "", "predict_re", "=", "model", "(", "context_idxs", ",", "context_pos", ",", "context_ner", ",", "context_char_idxs", ",", "input_lengths", ",", "\n", "h_mapping", ",", "t_mapping", ",", "relation_mask", ",", "dis_h_2_t", ",", "dis_t_2_h", ",", "sent_idxs", ",", "sent_lengths", ",", "reverse_sent_idxs", ",", "context_masks", ",", "context_starts", ")", "\n", "\n", "predict_re", "=", "torch", ".", "sigmoid", "(", "predict_re", ")", "\n", "\n", "", "predict_re", "=", "predict_re", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "two_phase", ":", "\n", "                ", "is_rel_exist", "=", "is_rel_exist", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "                ", "label", "=", "labels", "[", "i", "]", "\n", "index", "=", "indexes", "[", "i", "]", "\n", "\n", "\n", "total_recall", "+=", "len", "(", "label", ")", "\n", "for", "l", "in", "label", ".", "values", "(", ")", ":", "\n", "                    ", "if", "not", "l", ":", "\n", "                        ", "total_recall_ignore", "+=", "1", "\n", "\n", "", "", "L", "=", "L_vertex", "[", "i", "]", "\n", "j", "=", "0", "\n", "\n", "for", "h_idx", "in", "range", "(", "L", ")", ":", "\n", "                    ", "for", "t_idx", "in", "range", "(", "L", ")", ":", "\n", "                        ", "if", "h_idx", "!=", "t_idx", ":", "\n", "                            ", "r", "=", "np", ".", "argmax", "(", "predict_re", "[", "i", ",", "j", "]", ")", "\n", "predicted_as_zero", "+=", "r", "==", "0", "\n", "total_ins_num", "+=", "1", "\n", "if", "(", "h_idx", ",", "t_idx", ",", "r", ")", "in", "label", ":", "\n", "                                ", "top1_acc", "+=", "1", "\n", "\n", "", "flag", "=", "False", "\n", "\n", "for", "r", "in", "range", "(", "1", ",", "self", ".", "relation_num", ")", ":", "\n", "                                ", "intrain", "=", "False", "\n", "\n", "if", "(", "h_idx", ",", "t_idx", ",", "r", ")", "in", "label", ":", "\n", "                                    ", "flag", "=", "True", "\n", "if", "label", "[", "(", "h_idx", ",", "t_idx", ",", "r", ")", "]", "==", "True", ":", "\n", "                                        ", "intrain", "=", "True", "\n", "\n", "\n", "# if not intrain:", "\n", "#     test_result_ignore.append( ((h_idx, t_idx, r) in label, float(predict_re[i,j,r]),  titles[i], self.id2rel[r], index, h_idx, t_idx, r) )", "\n", "\n", "", "", "if", "two_phase", ":", "\n", "                                    ", "if", "is_rel_exist", "[", "i", ",", "j", ",", "1", "]", ">", "is_rel_exist", "[", "i", ",", "j", ",", "0", "]", ":", "\n", "                                        ", "test_result", ".", "append", "(", "(", "(", "h_idx", ",", "t_idx", ",", "r", ")", "in", "label", ",", "float", "(", "predict_re", "[", "i", ",", "j", ",", "r", "]", ")", ",", "intrain", ",", "titles", "[", "i", "]", ",", "self", ".", "id2rel", "[", "r", "]", ",", "index", ",", "h_idx", ",", "t_idx", ",", "r", ")", ")", "\n", "", "else", ":", "\n", "                                        ", "test_result", ".", "append", "(", "(", "(", "h_idx", ",", "t_idx", ",", "r", ")", "in", "label", ",", "-", "100.0", ",", "intrain", ",", "titles", "[", "i", "]", ",", "self", ".", "id2rel", "[", "r", "]", ",", "index", ",", "h_idx", ",", "t_idx", ",", "r", ")", ")", "\n", "", "", "else", ":", "\n", "                                    ", "test_result", ".", "append", "(", "(", "(", "h_idx", ",", "t_idx", ",", "r", ")", "in", "label", ",", "float", "(", "predict_re", "[", "i", ",", "j", ",", "r", "]", ")", ",", "intrain", ",", "titles", "[", "i", "]", ",", "self", ".", "id2rel", "[", "r", "]", ",", "index", ",", "h_idx", ",", "t_idx", ",", "r", ")", ")", "\n", "\n", "", "", "if", "flag", ":", "\n", "                                ", "have_label", "+=", "1", "\n", "\n", "", "j", "+=", "1", "\n", "\n", "\n", "", "", "", "", "data_idx", "+=", "1", "\n", "\n", "if", "data_idx", "%", "self", ".", "period", "==", "0", ":", "\n", "                ", "print", "(", "'| step {:3d} | time: {:5.2f}'", ".", "format", "(", "data_idx", "//", "self", ".", "period", ",", "(", "time", ".", "time", "(", ")", "-", "eval_start_time", ")", ")", ")", "\n", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# test_result_ignore.sort(key=lambda x: x[1], reverse=True)", "\n", "", "", "test_result", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "print", "(", "'total_recall'", ",", "total_recall", ")", "\n", "print", "(", "'predicted as zero'", ",", "predicted_as_zero", ")", "\n", "print", "(", "'total ins num'", ",", "total_ins_num", ")", "\n", "print", "(", "'top1_acc'", ",", "top1_acc", ")", "\n", "plt", ".", "xlabel", "(", "'Recall'", ")", "\n", "plt", ".", "ylabel", "(", "'Precision'", ")", "\n", "plt", ".", "ylim", "(", "0.2", ",", "1.0", ")", "\n", "plt", ".", "xlim", "(", "0.0", ",", "0.6", ")", "\n", "plt", ".", "title", "(", "'Precision-Recall'", ")", "\n", "plt", ".", "grid", "(", "True", ")", "\n", "\n", "pr_x", "=", "[", "]", "\n", "pr_y", "=", "[", "]", "\n", "correct", "=", "0", "\n", "w", "=", "0", "\n", "\n", "if", "total_recall", "==", "0", ":", "\n", "            ", "total_recall", "=", "1", "# for test", "\n", "\n", "", "for", "i", ",", "item", "in", "enumerate", "(", "test_result", ")", ":", "\n", "            ", "correct", "+=", "item", "[", "0", "]", "\n", "pr_y", ".", "append", "(", "float", "(", "correct", ")", "/", "(", "i", "+", "1", ")", ")", "\n", "pr_x", ".", "append", "(", "float", "(", "correct", ")", "/", "total_recall", ")", "\n", "if", "item", "[", "1", "]", ">", "input_theta", ":", "\n", "                ", "w", "=", "i", "\n", "\n", "\n", "", "", "pr_x", "=", "np", ".", "asarray", "(", "pr_x", ",", "dtype", "=", "'float32'", ")", "\n", "pr_y", "=", "np", ".", "asarray", "(", "pr_y", ",", "dtype", "=", "'float32'", ")", "\n", "f1_arr", "=", "(", "2", "*", "pr_x", "*", "pr_y", "/", "(", "pr_x", "+", "pr_y", "+", "1e-20", ")", ")", "\n", "f1", "=", "f1_arr", ".", "max", "(", ")", "\n", "f1_pos", "=", "f1_arr", ".", "argmax", "(", ")", "\n", "#print(pr_x[f1_pos], pr_y[f1_pos])", "\n", "theta", "=", "test_result", "[", "f1_pos", "]", "[", "1", "]", "\n", "\n", "if", "input_theta", "==", "-", "1", ":", "\n", "            ", "w", "=", "f1_pos", "\n", "input_theta", "=", "theta", "\n", "\n", "", "auc", "=", "sklearn", ".", "metrics", ".", "auc", "(", "x", "=", "pr_x", ",", "y", "=", "pr_y", ")", "\n", "if", "not", "self", ".", "is_test", ":", "\n", "            ", "logging", "(", "'ALL  : Theta {:3.4f} | F1 {:3.4f} | AUC {:3.4f}'", ".", "format", "(", "theta", ",", "f1", ",", "auc", ")", ")", "\n", "", "else", ":", "\n", "            ", "logging", "(", "'ma_f1 {:3.4f} | input_theta {:3.4f} test_result F1 {:3.4f} | AUC {:3.4f}'", ".", "format", "(", "f1", ",", "input_theta", ",", "f1_arr", "[", "w", "]", ",", "auc", ")", ")", "\n", "\n", "", "if", "output", ":", "\n", "# output = [x[-4:] for x in test_result[:w+1]]", "\n", "            ", "output", "=", "[", "{", "'index'", ":", "x", "[", "-", "4", "]", ",", "'h_idx'", ":", "x", "[", "-", "3", "]", ",", "'t_idx'", ":", "x", "[", "-", "2", "]", ",", "'r_idx'", ":", "x", "[", "-", "1", "]", ",", "'r'", ":", "x", "[", "-", "5", "]", ",", "'title'", ":", "x", "[", "-", "6", "]", "}", "for", "x", "in", "test_result", "[", ":", "w", "+", "1", "]", "]", "\n", "json", ".", "dump", "(", "output", ",", "open", "(", "self", ".", "test_prefix", "+", "\"_index.json\"", ",", "\"w\"", ")", ")", "\n", "\n", "", "plt", ".", "plot", "(", "pr_x", ",", "pr_y", ",", "lw", "=", "2", ",", "label", "=", "model_name", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "\"upper right\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "fig_result_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "self", ".", "fig_result_dir", ")", "\n", "", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "self", ".", "fig_result_dir", ",", "model_name", ")", ")", "\n", "\n", "pr_x", "=", "[", "]", "\n", "pr_y", "=", "[", "]", "\n", "correct", "=", "correct_in_train", "=", "0", "\n", "w", "=", "0", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "test_result", ")", ":", "\n", "            ", "correct", "+=", "item", "[", "0", "]", "\n", "if", "item", "[", "0", "]", "&", "item", "[", "2", "]", ":", "\n", "                ", "correct_in_train", "+=", "1", "\n", "", "if", "correct_in_train", "==", "correct", ":", "\n", "                ", "p", "=", "0", "\n", "", "else", ":", "\n", "                ", "p", "=", "float", "(", "correct", "-", "correct_in_train", ")", "/", "(", "i", "+", "1", "-", "correct_in_train", ")", "\n", "", "pr_y", ".", "append", "(", "p", ")", "\n", "pr_x", ".", "append", "(", "float", "(", "correct", ")", "/", "total_recall", ")", "\n", "if", "item", "[", "1", "]", ">", "input_theta", ":", "\n", "                ", "w", "=", "i", "\n", "\n", "", "", "pr_x", "=", "np", ".", "asarray", "(", "pr_x", ",", "dtype", "=", "'float32'", ")", "\n", "pr_y", "=", "np", ".", "asarray", "(", "pr_y", ",", "dtype", "=", "'float32'", ")", "\n", "f1_arr", "=", "(", "2", "*", "pr_x", "*", "pr_y", "/", "(", "pr_x", "+", "pr_y", "+", "1e-20", ")", ")", "\n", "f1", "=", "f1_arr", ".", "max", "(", ")", "\n", "\n", "auc", "=", "sklearn", ".", "metrics", ".", "auc", "(", "x", "=", "pr_x", ",", "y", "=", "pr_y", ")", "\n", "\n", "logging", "(", "'Ignore ma_f1 {:3.4f} | input_theta {:3.4f} test_result F1 {:3.4f} | AUC {:3.4f}'", ".", "format", "(", "f1", ",", "input_theta", ",", "f1_arr", "[", "w", "]", ",", "auc", ")", ")", "\n", "\n", "return", "f1", ",", "auc", ",", "pr_x", ",", "pr_y", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.testall": [[866, 881], ["model_pattern", "model_pattern.load_state_dict", "model_pattern.cuda", "model_pattern.eval", "Config.Config.test", "model_pattern", "model_pattern.load_state_dict", "model_pattern.cuda", "model_pattern.eval", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.test"], ["", "def", "testall", "(", "self", ",", "model_pattern", ",", "model_name", ",", "input_theta", ",", "two_phase", "=", "False", ",", "pretrain_model_name", "=", "None", ")", ":", "#, ignore_input_theta):", "\n", "        ", "pretrain_model", "=", "None", "\n", "if", "two_phase", ":", "\n", "            ", "pretrain_model", "=", "model_pattern", "(", "config", "=", "self", ")", "\n", "pretrain_model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoint_dir", ",", "pretrain_model_name", ")", ")", ")", "\n", "pretrain_model", ".", "cuda", "(", ")", "\n", "pretrain_model", ".", "eval", "(", ")", "\n", "\n", "", "model", "=", "model_pattern", "(", "config", "=", "self", ")", "\n", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoint_dir", ",", "model_name", ")", ")", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "#self.test_anylyse(model, model_name, True, input_theta)", "\n", "f1", ",", "auc", ",", "pr_x", ",", "pr_y", "=", "self", ".", "test", "(", "model", ",", "model_name", ",", "True", ",", "input_theta", ",", "two_phase", ",", "pretrain_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.add_attr": [[882, 885], ["enumerate", "[].append"], "methods", ["None"], ["", "def", "add_attr", "(", "self", ",", "attr_list", ",", "key", ",", "values", ")", ":", "\n", "        ", "for", "i", ",", "v", "in", "enumerate", "(", "values", ")", ":", "\n", "            ", "attr_list", "[", "key", "]", "[", "i", "]", ".", "append", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.test_anylyse": [[886, 1014], ["time.time", "range", "range", "range", "Config.Config.get_test_batch", "test_result.sort", "print", "print", "print", "print", "json.dump", "torch.sigmoid.data.cpu().numpy", "torch.sigmoid.data.cpu().numpy", "torch.sigmoid.data.cpu().numpy", "torch.sigmoid.data.cpu().numpy", "abs", "range", "print", "print", "open", "print", "range", "range", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "ht_pair_pos.cpu().numpy", "len", "len", "label.values", "range", "print", "time.time", "print", "len", "open", "f_log.write", "range", "torch.sigmoid.data.cpu", "torch.sigmoid.data.cpu", "torch.sigmoid.data.cpu", "torch.sigmoid.data.cpu", "range", "numpy.mean", "os.path.join", "str", "str", "ht_pair_pos.cpu", "os.path.join", "numpy.argmax", "range", "time.time", "[].append", "[].append", "test_result.append", "Config.Config.add_attr", "Config.Config.add_attr", "Config.Config.add_attr", "Config.Config.add_attr", "float", "str", "str", "min"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.get_test_batch", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.add_attr", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.add_attr", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.add_attr", "home.repos.pwc.inspect_result.hongwang600_DocRed.config.Config.Config.add_attr"], ["", "", "def", "test_anylyse", "(", "self", ",", "model", ",", "model_name", ",", "output", "=", "False", ",", "input_theta", "=", "-", "1", ")", ":", "\n", "        ", "data_idx", "=", "0", "\n", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "# test_result_ignore = []", "\n", "total_recall_ignore", "=", "0", "\n", "\n", "test_result", "=", "[", "]", "\n", "total_recall", "=", "0", "\n", "top1_acc", "=", "have_label", "=", "0", "\n", "\n", "total_pairs", "=", "0", "\n", "predicted_as_zero", "=", "0", "\n", "\n", "def", "logging", "(", "s", ",", "print_", "=", "True", ",", "log_", "=", "True", ")", ":", "\n", "            ", "if", "print_", ":", "\n", "                ", "print", "(", "s", ")", "\n", "", "if", "log_", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "\"log\"", ",", "model_name", ")", ")", ",", "'a+'", ")", "as", "f_log", ":", "\n", "                    ", "f_log", ".", "write", "(", "s", "+", "'\\n'", ")", "\n", "\n", "", "", "", "attr_list", "=", "{", "}", "\n", "attr_num", "=", "4", "\n", "attr_list", "[", "'correct'", "]", "=", "[", "[", "]", "for", "a_i", "in", "range", "(", "attr_num", ")", "]", "\n", "attr_list", "[", "'wrong'", "]", "=", "[", "[", "]", "for", "a_i", "in", "range", "(", "attr_num", ")", "]", "\n", "for", "r_i", "in", "range", "(", "self", ".", "relation_num", ")", ":", "\n", "            ", "attr_list", "[", "r_i", "]", "=", "[", "[", "]", "for", "a_i", "in", "range", "(", "attr_num", ")", "]", "\n", "", "for", "d_i", "in", "range", "(", "10", ")", ":", "\n", "            ", "attr_list", "[", "'dis_'", "+", "str", "(", "d_i", ")", "]", "=", "[", "[", "]", "]", "\n", "", "for", "e_i", "in", "range", "(", "5", ")", ":", "\n", "            ", "attr_list", "[", "'evi_'", "+", "str", "(", "e_i", ")", "]", "=", "[", "[", "]", "]", "\n", "\n", "\n", "", "for", "data", "in", "self", ".", "get_test_batch", "(", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "context_idxs", "=", "data", "[", "'context_idxs'", "]", "\n", "context_pos", "=", "data", "[", "'context_pos'", "]", "\n", "h_mapping", "=", "data", "[", "'h_mapping'", "]", "\n", "t_mapping", "=", "data", "[", "'t_mapping'", "]", "\n", "labels", "=", "data", "[", "'labels'", "]", "\n", "L_vertex", "=", "data", "[", "'L_vertex'", "]", "\n", "input_lengths", "=", "data", "[", "'input_lengths'", "]", "\n", "context_ner", "=", "data", "[", "'context_ner'", "]", "\n", "context_char_idxs", "=", "data", "[", "'context_char_idxs'", "]", "\n", "relation_mask", "=", "data", "[", "'relation_mask'", "]", "\n", "ht_pair_pos", "=", "data", "[", "'ht_pair_pos'", "]", "\n", "\n", "evi_num_set", "=", "data", "[", "'evi_num_set'", "]", "\n", "\n", "sent_idxs", "=", "data", "[", "'sent_idxs'", "]", "\n", "sent_lengths", "=", "data", "[", "'sent_lengths'", "]", "\n", "reverse_sent_idxs", "=", "data", "[", "'reverse_sent_idxs'", "]", "\n", "context_masks", "=", "data", "[", "'context_masks'", "]", "\n", "context_starts", "=", "data", "[", "'context_starts'", "]", "\n", "\n", "titles", "=", "data", "[", "'titles'", "]", "\n", "indexes", "=", "data", "[", "'indexes'", "]", "\n", "\n", "dis_h_2_t", "=", "ht_pair_pos", "+", "10", "\n", "dis_t_2_h", "=", "-", "ht_pair_pos", "+", "10", "\n", "\n", "predict_re", "=", "model", "(", "context_idxs", ",", "context_pos", ",", "context_ner", ",", "context_char_idxs", ",", "input_lengths", ",", "\n", "h_mapping", ",", "t_mapping", ",", "relation_mask", ",", "dis_h_2_t", ",", "dis_t_2_h", ",", "sent_idxs", ",", "sent_lengths", ",", "reverse_sent_idxs", ",", "context_masks", ",", "context_starts", ")", "\n", "\n", "\n", "predict_re", "=", "torch", ".", "sigmoid", "(", "predict_re", ")", "\n", "\n", "", "predict_re", "=", "predict_re", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "dis_h_2_t", "=", "abs", "(", "ht_pair_pos", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "                ", "label", "=", "labels", "[", "i", "]", "\n", "index", "=", "indexes", "[", "i", "]", "\n", "evi_num", "=", "evi_num_set", "[", "i", "]", "\n", "\n", "\n", "total_recall", "+=", "len", "(", "label", ")", "\n", "for", "l", "in", "label", ".", "values", "(", ")", ":", "\n", "                    ", "if", "not", "l", ":", "\n", "                        ", "total_recall_ignore", "+=", "1", "\n", "\n", "", "", "L", "=", "L_vertex", "[", "i", "]", "\n", "j", "=", "0", "\n", "\n", "for", "h_idx", "in", "range", "(", "L", ")", ":", "\n", "                    ", "for", "t_idx", "in", "range", "(", "L", ")", ":", "\n", "                        ", "if", "h_idx", "!=", "t_idx", ":", "\n", "                            ", "pred_r", "=", "np", ".", "argmax", "(", "predict_re", "[", "i", ",", "j", "]", ")", "\n", "\n", "total_pairs", "+=", "1", "\n", "predicted_as_zero", "+=", "pred_r", "==", "0", "\n", "\n", "for", "r", "in", "range", "(", "1", ",", "self", ".", "relation_num", ")", ":", "\n", "                                ", "if", "(", "h_idx", ",", "t_idx", ",", "r", ")", "in", "label", ":", "\n", "                                    ", "if", "r", "==", "pred_r", ":", "\n", "                                        ", "top1_acc", "+=", "1", "\n", "self", ".", "add_attr", "(", "attr_list", ",", "'correct'", ",", "[", "1", ",", "0", ",", "dis_h_2_t", "[", "i", ",", "j", "]", ",", "evi_num", "[", "(", "h_idx", ",", "t_idx", ",", "r", ")", "]", "]", ")", "\n", "self", ".", "add_attr", "(", "attr_list", ",", "r", ",", "[", "1", ",", "0", ",", "dis_h_2_t", "[", "i", ",", "j", "]", ",", "evi_num", "[", "(", "h_idx", ",", "t_idx", ",", "r", ")", "]", "]", ")", "\n", "", "else", ":", "\n", "                                        ", "self", ".", "add_attr", "(", "attr_list", ",", "'wrong'", ",", "[", "0", ",", "pred_r", "==", "0", ",", "dis_h_2_t", "[", "i", ",", "j", "]", ",", "evi_num", "[", "(", "h_idx", ",", "t_idx", ",", "r", ")", "]", "]", ")", "\n", "self", ".", "add_attr", "(", "attr_list", ",", "r", ",", "[", "0", ",", "pred_r", "==", "0", ",", "dis_h_2_t", "[", "i", ",", "j", "]", ",", "evi_num", "[", "(", "h_idx", ",", "t_idx", ",", "r", ")", "]", "]", ")", "\n", "", "attr_list", "[", "'dis_'", "+", "str", "(", "dis_h_2_t", "[", "i", ",", "j", "]", ")", "]", "[", "0", "]", ".", "append", "(", "pred_r", "==", "r", ")", "\n", "attr_list", "[", "'evi_'", "+", "str", "(", "min", "(", "4", ",", "evi_num", "[", "(", "h_idx", ",", "t_idx", ",", "r", ")", "]", ")", ")", "]", "[", "0", "]", ".", "append", "(", "pred_r", "==", "r", ")", "\n", "", "if", "predict_re", "[", "i", ",", "j", ",", "r", "]", ">=", "0.99999", ":", "\n", "                                    ", "test_result", ".", "append", "(", "(", "(", "h_idx", ",", "t_idx", ",", "r", ")", "in", "label", ",", "float", "(", "predict_re", "[", "i", ",", "j", ",", "r", "]", ")", ",", "self", ".", "id2rel", "[", "r", "]", ",", "h_idx", ",", "t_idx", ",", "r", ",", "titles", "[", "i", "]", ")", ")", "\n", "\n", "", "", "j", "+=", "1", "\n", "\n", "\n", "", "", "", "", "data_idx", "+=", "1", "\n", "\n", "if", "data_idx", "%", "self", ".", "period", "==", "0", ":", "\n", "                ", "print", "(", "'| step {:3d} | time: {:5.2f}'", ".", "format", "(", "data_idx", "//", "self", ".", "period", ",", "(", "time", ".", "time", "(", ")", "-", "eval_start_time", ")", ")", ")", "\n", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# test_result_ignore.sort(key=lambda x: x[1], reverse=True)", "\n", "", "", "test_result", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "print", "(", "'total_recall'", ",", "total_recall", ")", "\n", "print", "(", "'all pairs'", ",", "total_pairs", ")", "\n", "print", "(", "'predicted as zeros'", ",", "predicted_as_zero", ")", "\n", "print", "(", "'top one accuracy'", ",", "top1_acc", ")", "\n", "for", "k", "in", "attr_list", ":", "\n", "            ", "print", "(", "k", ")", "\n", "for", "attr", "in", "attr_list", "[", "k", "]", ":", "\n", "#print(attr)", "\n", "                ", "print", "(", "np", ".", "mean", "(", "attr", ")", ")", "\n", "", "print", "(", "len", "(", "attr_list", "[", "k", "]", "[", "0", "]", ")", ")", "\n", "", "json", ".", "dump", "(", "test_result", ",", "open", "(", "'analyse_result.json'", ",", "'w'", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.CNN3.CNN3.__init__": [[9, 45], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "CNN3.CNN3.word_emb.weight.data.copy_", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "int", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "CNN3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "word_emb", "=", "nn", ".", "Embedding", "(", "config", ".", "data_word_vec", ".", "shape", "[", "0", "]", ",", "config", ".", "data_word_vec", ".", "shape", "[", "1", "]", ")", "\n", "self", ".", "word_emb", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "config", ".", "data_word_vec", ")", ")", "\n", "self", ".", "word_emb", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n", "\n", "# self.char_emb = nn.Embedding(config.data_char_vec.shape[0], config.data_char_vec.shape[1])", "\n", "# self.char_emb.weight.data.copy_(torch.from_numpy(config.data_char_vec))", "\n", "# char_dim = config.data_char_vec.shape[1]", "\n", "# char_hidden = 100", "\n", "# self.char_cnn = nn.Conv1d(char_dim,  char_hidden, 5)", "\n", "\n", "self", ".", "coref_embed", "=", "nn", ".", "Embedding", "(", "config", ".", "max_length", ",", "config", ".", "coref_size", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "ner_emb", "=", "nn", ".", "Embedding", "(", "7", ",", "config", ".", "entity_type_size", ",", "padding_idx", "=", "0", ")", "\n", "\n", "input_size", "=", "config", ".", "data_word_vec", ".", "shape", "[", "1", "]", "+", "config", ".", "coref_size", "+", "config", ".", "entity_type_size", "#+ char_hidden", "\n", "\n", "self", ".", "out_channels", "=", "200", "\n", "self", ".", "in_channels", "=", "input_size", "\n", "\n", "self", ".", "kernel_size", "=", "3", "\n", "self", ".", "stride", "=", "1", "\n", "self", ".", "padding", "=", "int", "(", "(", "self", ".", "kernel_size", "-", "1", ")", "/", "2", ")", "\n", "\n", "self", ".", "cnn_1", "=", "nn", ".", "Conv1d", "(", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", ",", "self", ".", "padding", ")", "\n", "self", ".", "cnn_2", "=", "nn", ".", "Conv1d", "(", "self", ".", "out_channels", ",", "self", ".", "out_channels", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", ",", "self", ".", "padding", ")", "\n", "self", ".", "cnn_3", "=", "nn", ".", "Conv1d", "(", "self", ".", "out_channels", ",", "self", ".", "out_channels", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", ",", "self", ".", "padding", ")", "\n", "self", ".", "max_pooling", "=", "nn", ".", "MaxPool1d", "(", "self", ".", "kernel_size", ",", "stride", "=", "self", ".", "stride", ",", "padding", "=", "self", ".", "padding", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "cnn_drop_prob", ")", "\n", "\n", "self", ".", "bili", "=", "torch", ".", "nn", ".", "Bilinear", "(", "self", ".", "out_channels", "+", "config", ".", "dis_size", ",", "self", ".", "out_channels", "+", "config", ".", "dis_size", ",", "config", ".", "relation_num", ")", "\n", "self", ".", "dis_embed", "=", "nn", ".", "Embedding", "(", "20", ",", "config", ".", "dis_size", ",", "padding_idx", "=", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.CNN3.CNN3.forward": [[47, 82], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sent.permute.permute.permute", "CNN3.CNN3.cnn_1", "CNN3.CNN3.max_pooling", "CNN3.CNN3.relu", "CNN3.CNN3.dropout", "CNN3.CNN3.cnn_2", "CNN3.CNN3.max_pooling", "CNN3.CNN3.relu", "CNN3.CNN3.dropout", "CNN3.CNN3.cnn_3", "CNN3.CNN3.max_pooling", "CNN3.CNN3.relu", "CNN3.CNN3.dropout", "CNN3.CNN3.permute", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "CNN3.CNN3.bili", "CNN3.CNN3.word_emb", "CNN3.CNN3.coref_embed", "CNN3.CNN3.ner_emb", "CNN3.CNN3.dis_embed", "CNN3.CNN3.dis_embed"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "context_idxs", ",", "pos", ",", "context_ner", ",", "context_char_idxs", ",", "context_lens", ",", "h_mapping", ",", "t_mapping", ",", "relation_mask", ",", "dis_h_2_t", ",", "dis_t_2_h", ")", ":", "\n", "# para_size, char_size, bsz = context_idxs.size(1), context_char_idxs.size(2), context_idxs.size(0)", "\n", "# context_ch = self.char_emb(context_char_idxs.contiguous().view(-1, char_size)).view(bsz * para_size, char_size, -1)", "\n", "# context_ch = self.char_cnn(context_ch.permute(0, 2, 1).contiguous()).max(dim=-1)[0].view(bsz, para_size, -1)", "\n", "\n", "        ", "sent", "=", "torch", ".", "cat", "(", "[", "self", ".", "word_emb", "(", "context_idxs", ")", ",", "self", ".", "coref_embed", "(", "pos", ")", ",", "self", ".", "ner_emb", "(", "context_ner", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "sent", "=", "sent", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "# batch * embedding_size * max_len", "\n", "x", "=", "self", ".", "cnn_1", "(", "sent", ")", "\n", "x", "=", "self", ".", "max_pooling", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "cnn_2", "(", "x", ")", "\n", "x", "=", "self", ".", "max_pooling", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "cnn_3", "(", "x", ")", "\n", "x", "=", "self", ".", "max_pooling", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "\n", "context_output", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "start_re_output", "=", "torch", ".", "matmul", "(", "h_mapping", ",", "context_output", ")", "\n", "end_re_output", "=", "torch", ".", "matmul", "(", "t_mapping", ",", "context_output", ")", "\n", "\n", "s_rep", "=", "torch", ".", "cat", "(", "[", "start_re_output", ",", "self", ".", "dis_embed", "(", "dis_h_2_t", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "t_rep", "=", "torch", ".", "cat", "(", "[", "end_re_output", ",", "self", ".", "dis_embed", "(", "dis_t_2_h", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "predict_re", "=", "self", ".", "bili", "(", "s_rep", ",", "t_rep", ")", "\n", "\n", "return", "predict_re", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.bert.Bert.__init__": [[21, 28], ["super().__init__", "BertTokenizer.from_pretrained", "model_class.from_pretrained().cuda", "bert.Bert.model.embeddings.position_embeddings.weight.size", "bert.Bert.model.embeddings.position_embeddings.weight.size", "model_class.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["def", "__init__", "(", "self", ",", "model_class", ",", "model_name", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model_name", "=", "model_name", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "self", ".", "model_name", ")", "\n", "self", ".", "model", "=", "model_class", ".", "from_pretrained", "(", "model_name", ")", ".", "cuda", "(", ")", "\n", "self", ".", "max_len", "=", "self", ".", "model", ".", "embeddings", ".", "position_embeddings", ".", "weight", ".", "size", "(", "0", ")", "\n", "self", ".", "dim", "=", "self", ".", "model", ".", "embeddings", ".", "position_embeddings", ".", "weight", ".", "size", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.bert.Bert.tokenize": [[29, 38], ["bert.Bert.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.bert.Bert.tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ",", "masked_idxs", "=", "None", ")", ":", "\n", "        ", "tokenized_text", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "if", "masked_idxs", "is", "not", "None", ":", "\n", "            ", "for", "idx", "in", "masked_idxs", ":", "\n", "                ", "tokenized_text", "[", "idx", "]", "=", "self", ".", "MASK", "\n", "# prepend [CLS] and append [SEP]", "\n", "# see https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_classifier.py#L195  # NOQA", "\n", "", "", "tokenized", "=", "[", "self", ".", "CLS", "]", "+", "tokenized_text", "+", "[", "self", ".", "SEP", "]", "\n", "return", "tokenized", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.bert.Bert.tokenize_to_ids": [[39, 42], ["bert.Bert.tokenize", "bert.Bert.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.bert.Bert.tokenize", "home.repos.pwc.inspect_result.hongwang600_DocRed.models.bert.Bert.convert_tokens_to_ids"], ["", "def", "tokenize_to_ids", "(", "self", ",", "text", ",", "masked_idxs", "=", "None", ",", "pad", "=", "True", ")", ":", "\n", "        ", "tokens", "=", "self", ".", "tokenize", "(", "text", ",", "masked_idxs", ")", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "tokens", ",", "pad", "=", "pad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.bert.Bert.convert_tokens_to_ids": [[43, 55], ["bert.Bert.tokenizer.convert_tokens_to_ids", "torch.tensor", "torch.tensor.size", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.tensor.size", "torch.tensor.size"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.bert.Bert.convert_tokens_to_ids"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ",", "pad", "=", "True", ")", ":", "\n", "        ", "token_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "ids", "=", "torch", ".", "tensor", "(", "[", "token_ids", "]", ")", "\n", "assert", "ids", ".", "size", "(", "1", ")", "<", "self", ".", "max_len", "\n", "if", "pad", ":", "\n", "            ", "padded_ids", "=", "torch", ".", "zeros", "(", "1", ",", "self", ".", "max_len", ")", ".", "to", "(", "ids", ")", "\n", "padded_ids", "[", "0", ",", ":", "ids", ".", "size", "(", "1", ")", "]", "=", "ids", "\n", "mask", "=", "torch", ".", "zeros", "(", "1", ",", "self", ".", "max_len", ")", ".", "to", "(", "ids", ")", "\n", "mask", "[", "0", ",", ":", "ids", ".", "size", "(", "1", ")", "]", "=", "1", "\n", "return", "padded_ids", ",", "mask", "\n", "", "else", ":", "\n", "            ", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.bert.Bert.flatten": [[56, 60], ["None"], "methods", ["None"], ["", "", "def", "flatten", "(", "self", ",", "list_of_lists", ")", ":", "\n", "        ", "for", "list", "in", "list_of_lists", ":", "\n", "            ", "for", "item", "in", "list", ":", "\n", "                ", "yield", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.bert.Bert.subword_tokenize": [[61, 89], ["list", "list", "map", "map", "numpy.cumsum", "list", "bert.Bert.flatten"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.bert.Bert.flatten"], ["", "", "", "def", "subword_tokenize", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Segment each token into subwords while keeping track of\n        token boundaries.\n\n        Parameters\n        ----------\n        tokens: A sequence of strings, representing input tokens.\n\n        Returns\n        -------\n        A tuple consisting of:\n            - A list of subwords, flanked by the special symbols required\n                by Bert (CLS and SEP).\n            - An array of indices into the list of subwords, indicating\n                that the corresponding subword is the start of a new\n                token. For example, [1, 3, 4, 7] means that the subwords\n                1, 3, 4, 7 are token starts, while all other subwords\n                (0, 2, 5, 6, 8...) are in or at the end of tokens.\n                This list allows selecting Bert hidden states that\n                represent tokens, which is necessary in sequence\n                labeling.\n        \"\"\"", "\n", "subwords", "=", "list", "(", "map", "(", "self", ".", "tokenizer", ".", "tokenize", ",", "tokens", ")", ")", "\n", "subword_lengths", "=", "list", "(", "map", "(", "len", ",", "subwords", ")", ")", "\n", "subwords", "=", "[", "self", ".", "CLS", "]", "+", "list", "(", "self", ".", "flatten", "(", "subwords", ")", ")", "[", ":", "509", "]", "+", "[", "self", ".", "SEP", "]", "\n", "token_start_idxs", "=", "1", "+", "np", ".", "cumsum", "(", "[", "0", "]", "+", "subword_lengths", "[", ":", "-", "1", "]", ")", "\n", "token_start_idxs", "[", "token_start_idxs", ">", "509", "]", "=", "509", "\n", "return", "subwords", ",", "token_start_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.bert.Bert.subword_tokenize_to_ids": [[90, 112], ["bert.Bert.subword_tokenize", "bert.Bert.convert_tokens_to_ids", "torch.zeros().to", "subword_ids.numpy", "mask.numpy", "torch.zeros().to.numpy", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.bert.Bert.subword_tokenize", "home.repos.pwc.inspect_result.hongwang600_DocRed.models.bert.Bert.convert_tokens_to_ids"], ["", "def", "subword_tokenize_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Segment each token into subwords while keeping track of\n        token boundaries and convert subwords into IDs.\n\n        Parameters\n        ----------\n        tokens: A sequence of strings, representing input tokens.\n\n        Returns\n        -------\n        A tuple consisting of:\n            - A list of subword IDs, including IDs of the special\n                symbols (CLS and SEP) required by Bert.\n            - A mask indicating padding tokens.\n            - An array of indices into the list of subwords. See\n                doc of subword_tokenize.\n        \"\"\"", "\n", "subwords", ",", "token_start_idxs", "=", "self", ".", "subword_tokenize", "(", "tokens", ")", "\n", "subword_ids", ",", "mask", "=", "self", ".", "convert_tokens_to_ids", "(", "subwords", ")", "\n", "token_starts", "=", "torch", ".", "zeros", "(", "1", ",", "self", ".", "max_len", ")", ".", "to", "(", "subword_ids", ")", "\n", "token_starts", "[", "0", ",", "token_start_idxs", "]", "=", "1", "\n", "return", "subword_ids", ".", "numpy", "(", ")", ",", "mask", ".", "numpy", "(", ")", ",", "token_starts", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.bert.Bert.segment_ids": [[113, 116], ["torch.tensor"], "methods", ["None"], ["", "def", "segment_ids", "(", "self", ",", "segment1_len", ",", "segment2_len", ")", ":", "\n", "        ", "ids", "=", "[", "0", "]", "*", "segment1_len", "+", "[", "1", "]", "*", "segment2_len", "\n", "return", "torch", ".", "tensor", "(", "[", "ids", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM.LSTM.__init__": [[15, 46], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "LSTM.LSTM.word_emb.weight.data.copy_", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "LSTM.EncoderLSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "LSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "word_vec_size", "=", "config", ".", "data_word_vec", ".", "shape", "[", "0", "]", "\n", "self", ".", "word_emb", "=", "nn", ".", "Embedding", "(", "word_vec_size", ",", "config", ".", "data_word_vec", ".", "shape", "[", "1", "]", ")", "\n", "self", ".", "word_emb", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "config", ".", "data_word_vec", ")", ")", "\n", "self", ".", "word_emb", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n", "# self.char_emb = nn.Embedding(config.data_char_vec.shape[0], config.data_char_vec.shape[1])", "\n", "# self.char_emb.weight.data.copy_(torch.from_numpy(config.data_char_vec))", "\n", "# char_dim = config.data_char_vec.shape[1]", "\n", "# char_hidden = 100", "\n", "# self.char_cnn = nn.Conv1d(char_dim,  char_hidden, 5)", "\n", "self", ".", "coref_embed", "=", "nn", ".", "Embedding", "(", "config", ".", "max_length", ",", "config", ".", "coref_size", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "ner_emb", "=", "nn", ".", "Embedding", "(", "7", ",", "config", ".", "entity_type_size", ",", "padding_idx", "=", "0", ")", "\n", "\n", "input_size", "=", "config", ".", "data_word_vec", ".", "shape", "[", "1", "]", "+", "config", ".", "coref_size", "+", "config", ".", "entity_type_size", "#+ char_hidden", "\n", "hidden_size", "=", "128", "\n", "\n", "# self.rnn = EncoderLSTM(input_size, hidden_size, 1, True, True, 1 - config.keep_prob, False)", "\n", "# self.linear_re = nn.Linear(hidden_size*2, hidden_size)  # *4 for 2layer", "\n", "\n", "self", ".", "rnn", "=", "EncoderLSTM", "(", "input_size", ",", "hidden_size", ",", "1", ",", "True", ",", "False", ",", "1", "-", "config", ".", "keep_prob", ",", "False", ")", "\n", "self", ".", "linear_re", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", "# *4 for 2layer", "\n", "\n", "self", ".", "bili", "=", "torch", ".", "nn", ".", "Bilinear", "(", "hidden_size", "+", "config", ".", "dis_size", ",", "hidden_size", "+", "config", ".", "dis_size", ",", "config", ".", "relation_num", ")", "\n", "\n", "\n", "\n", "self", ".", "dis_embed", "=", "nn", ".", "Embedding", "(", "20", ",", "config", ".", "dis_size", ",", "padding_idx", "=", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM.LSTM.forward": [[49, 75], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "LSTM.LSTM.rnn", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "LSTM.LSTM.bili", "LSTM.LSTM.linear_re", "LSTM.LSTM.word_emb", "LSTM.LSTM.coref_embed", "LSTM.LSTM.ner_emb", "LSTM.LSTM.dis_embed", "LSTM.LSTM.dis_embed"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "context_idxs", ",", "pos", ",", "context_ner", ",", "context_char_idxs", ",", "context_lens", ",", "h_mapping", ",", "t_mapping", ",", "\n", "relation_mask", ",", "dis_h_2_t", ",", "dis_t_2_h", ")", ":", "\n", "# para_size, char_size, bsz = context_idxs.size(1), context_char_idxs.size(2), context_idxs.size(0)", "\n", "# context_ch = self.char_emb(context_char_idxs.contiguous().view(-1, char_size)).view(bsz * para_size, char_size, -1)", "\n", "# context_ch = self.char_cnn(context_ch.permute(0, 2, 1).contiguous()).max(dim=-1)[0].view(bsz, para_size, -1)", "\n", "\n", "        ", "sent", "=", "torch", ".", "cat", "(", "[", "self", ".", "word_emb", "(", "context_idxs", ")", ",", "self", ".", "coref_embed", "(", "pos", ")", ",", "self", ".", "ner_emb", "(", "context_ner", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "# sent = torch.cat([self.word_emb(context_idxs), context_ch], dim=-1)", "\n", "\n", "# context_mask = (context_idxs > 0).float()", "\n", "context_output", "=", "self", ".", "rnn", "(", "sent", ",", "context_lens", ")", "\n", "\n", "context_output", "=", "torch", ".", "relu", "(", "self", ".", "linear_re", "(", "context_output", ")", ")", "\n", "\n", "\n", "start_re_output", "=", "torch", ".", "matmul", "(", "h_mapping", ",", "context_output", ")", "\n", "end_re_output", "=", "torch", ".", "matmul", "(", "t_mapping", ",", "context_output", ")", "\n", "# predict_re = self.bili(start_re_output, end_re_output)", "\n", "\n", "s_rep", "=", "torch", ".", "cat", "(", "[", "start_re_output", ",", "self", ".", "dis_embed", "(", "dis_h_2_t", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "t_rep", "=", "torch", ".", "cat", "(", "[", "end_re_output", ",", "self", ".", "dis_embed", "(", "dis_t_2_h", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "predict_re", "=", "self", ".", "bili", "(", "s_rep", ",", "t_rep", ")", "\n", "\n", "\n", "\n", "return", "predict_re", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM.LockedDropout.__init__": [[78, 81], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM.LockedDropout.forward": [[82, 90], ["x.data.new().bernoulli_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "mask.expand_as.expand_as.expand_as", "x.data.new().bernoulli_.div_", "x.data.new", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "dropout", "=", "self", ".", "dropout", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "return", "x", "\n", "", "m", "=", "x", ".", "data", ".", "new", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "x", ".", "size", "(", "2", ")", ")", ".", "bernoulli_", "(", "1", "-", "dropout", ")", "\n", "mask", "=", "Variable", "(", "m", ".", "div_", "(", "1", "-", "dropout", ")", ",", "requires_grad", "=", "False", ")", "\n", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "return", "mask", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM.EncoderRNN.__init__": [[92, 109], ["torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "LSTM.LockedDropout", "LSTM.EncoderRNN.rnns.append", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "num_units", ",", "nlayers", ",", "concat", ",", "bidir", ",", "dropout", ",", "return_last", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnns", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nlayers", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "input_size_", "=", "input_size", "\n", "output_size_", "=", "num_units", "\n", "", "else", ":", "\n", "                ", "input_size_", "=", "num_units", "if", "not", "bidir", "else", "num_units", "*", "2", "\n", "output_size_", "=", "num_units", "\n", "", "self", ".", "rnns", ".", "append", "(", "nn", ".", "GRU", "(", "input_size_", ",", "output_size_", ",", "1", ",", "bidirectional", "=", "bidir", ",", "batch_first", "=", "True", ")", ")", "\n", "", "self", ".", "rnns", "=", "nn", ".", "ModuleList", "(", "self", ".", "rnns", ")", "\n", "self", ".", "init_hidden", "=", "nn", ".", "ParameterList", "(", "[", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "2", "if", "bidir", "else", "1", ",", "1", ",", "num_units", ")", ".", "zero_", "(", ")", ")", "for", "_", "in", "range", "(", "nlayers", ")", "]", ")", "\n", "self", ".", "dropout", "=", "LockedDropout", "(", "dropout", ")", "\n", "self", ".", "concat", "=", "concat", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "return_last", "=", "return_last", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM.EncoderRNN.reset_parameters": [[112, 119], ["torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "p.data.normal_", "p.data.zero_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "rnn", "in", "self", ".", "rnns", ":", "\n", "            ", "for", "name", ",", "p", "in", "rnn", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'weight'", "in", "name", ":", "\n", "                    ", "p", ".", "data", ".", "normal_", "(", "std", "=", "0.1", ")", "\n", "", "else", ":", "\n", "                    ", "p", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM.EncoderRNN.get_init": [[120, 122], ["LSTM.EncoderRNN.init_hidden[].expand().contiguous", "LSTM.EncoderRNN.init_hidden[].expand"], "methods", ["None"], ["", "", "", "", "def", "get_init", "(", "self", ",", "bsz", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "init_hidden", "[", "i", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM.EncoderRNN.forward": [[123, 150], ["range", "input.size", "input.size", "input_lengths.data.cpu().numpy", "LSTM.EncoderRNN.get_init", "LSTM.EncoderRNN.dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "outputs.append", "outputs.append", "input_lengths.data.cpu", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "LSTM.EncoderRNN.permute().contiguous().view", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "LSTM.EncoderRNN.permute().contiguous", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "LSTM.EncoderRNN.permute"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.EncoderLSTM.get_init"], ["", "def", "forward", "(", "self", ",", "input", ",", "input_lengths", "=", "None", ")", ":", "\n", "        ", "bsz", ",", "slen", "=", "input", ".", "size", "(", "0", ")", ",", "input", ".", "size", "(", "1", ")", "\n", "output", "=", "input", "\n", "outputs", "=", "[", "]", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "            ", "lens", "=", "input_lengths", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "nlayers", ")", ":", "\n", "            ", "hidden", "=", "self", ".", "get_init", "(", "bsz", ",", "i", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "                ", "output", "=", "rnn", ".", "pack_padded_sequence", "(", "output", ",", "lens", ",", "batch_first", "=", "True", ")", "\n", "\n", "", "output", ",", "hidden", "=", "self", ".", "rnns", "[", "i", "]", "(", "output", ",", "hidden", ")", "\n", "\n", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "                ", "output", ",", "_", "=", "rnn", ".", "pad_packed_sequence", "(", "output", ",", "batch_first", "=", "True", ")", "\n", "if", "output", ".", "size", "(", "1", ")", "<", "slen", ":", "# used for parallel", "\n", "                    ", "padding", "=", "Variable", "(", "output", ".", "data", ".", "new", "(", "1", ",", "1", ",", "1", ")", ".", "zero_", "(", ")", ")", "\n", "output", "=", "torch", ".", "cat", "(", "[", "output", ",", "padding", ".", "expand", "(", "output", ".", "size", "(", "0", ")", ",", "slen", "-", "output", ".", "size", "(", "1", ")", ",", "output", ".", "size", "(", "2", ")", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "", "if", "self", ".", "return_last", ":", "\n", "                ", "outputs", ".", "append", "(", "hidden", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ".", "append", "(", "output", ")", "\n", "", "", "if", "self", ".", "concat", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "2", ")", "\n", "", "return", "outputs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM.EncoderLSTM.__init__": [[155, 175], ["torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "LSTM.LockedDropout", "LSTM.EncoderLSTM.rnns.append", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "range", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "num_units", ",", "nlayers", ",", "concat", ",", "bidir", ",", "dropout", ",", "return_last", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnns", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nlayers", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "input_size_", "=", "input_size", "\n", "output_size_", "=", "num_units", "\n", "", "else", ":", "\n", "                ", "input_size_", "=", "num_units", "if", "not", "bidir", "else", "num_units", "*", "2", "\n", "output_size_", "=", "num_units", "\n", "", "self", ".", "rnns", ".", "append", "(", "nn", ".", "LSTM", "(", "input_size_", ",", "output_size_", ",", "1", ",", "bidirectional", "=", "bidir", ",", "batch_first", "=", "True", ")", ")", "\n", "", "self", ".", "rnns", "=", "nn", ".", "ModuleList", "(", "self", ".", "rnns", ")", "\n", "\n", "self", ".", "init_hidden", "=", "nn", ".", "ParameterList", "(", "[", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "2", "if", "bidir", "else", "1", ",", "1", ",", "num_units", ")", ".", "zero_", "(", ")", ")", "for", "_", "in", "range", "(", "nlayers", ")", "]", ")", "\n", "self", ".", "init_c", "=", "nn", ".", "ParameterList", "(", "[", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "2", "if", "bidir", "else", "1", ",", "1", ",", "num_units", ")", ".", "zero_", "(", ")", ")", "for", "_", "in", "range", "(", "nlayers", ")", "]", ")", "\n", "\n", "self", ".", "dropout", "=", "LockedDropout", "(", "dropout", ")", "\n", "self", ".", "concat", "=", "concat", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "return_last", "=", "return_last", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM.EncoderLSTM.reset_parameters": [[178, 185], ["torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "p.data.normal_", "p.data.zero_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "rnn", "in", "self", ".", "rnns", ":", "\n", "            ", "for", "name", ",", "p", "in", "rnn", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'weight'", "in", "name", ":", "\n", "                    ", "p", ".", "data", ".", "normal_", "(", "std", "=", "0.1", ")", "\n", "", "else", ":", "\n", "                    ", "p", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM.EncoderLSTM.get_init": [[186, 188], ["LSTM.EncoderLSTM.init_hidden[].expand().contiguous", "LSTM.EncoderLSTM.init_c[].expand().contiguous", "LSTM.EncoderLSTM.init_hidden[].expand", "LSTM.EncoderLSTM.init_c[].expand"], "methods", ["None"], ["", "", "", "", "def", "get_init", "(", "self", ",", "bsz", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "init_hidden", "[", "i", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", ".", "contiguous", "(", ")", ",", "self", ".", "init_c", "[", "i", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM.EncoderLSTM.forward": [[189, 218], ["range", "input.size", "input.size", "input_lengths.data.cpu().numpy", "LSTM.EncoderLSTM.get_init", "LSTM.EncoderLSTM.dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "outputs.append", "outputs.append", "input_lengths.data.cpu", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "hidden.permute().contiguous().view", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "hidden.permute().contiguous", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "hidden.permute"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.EncoderLSTM.get_init"], ["", "def", "forward", "(", "self", ",", "input", ",", "input_lengths", "=", "None", ")", ":", "\n", "        ", "bsz", ",", "slen", "=", "input", ".", "size", "(", "0", ")", ",", "input", ".", "size", "(", "1", ")", "\n", "output", "=", "input", "\n", "outputs", "=", "[", "]", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "            ", "lens", "=", "input_lengths", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "nlayers", ")", ":", "\n", "            ", "hidden", ",", "c", "=", "self", ".", "get_init", "(", "bsz", ",", "i", ")", "\n", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "                ", "output", "=", "rnn", ".", "pack_padded_sequence", "(", "output", ",", "lens", ",", "batch_first", "=", "True", ")", "\n", "\n", "", "output", ",", "hidden", "=", "self", ".", "rnns", "[", "i", "]", "(", "output", ",", "(", "hidden", ",", "c", ")", ")", "\n", "\n", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "                ", "output", ",", "_", "=", "rnn", ".", "pad_packed_sequence", "(", "output", ",", "batch_first", "=", "True", ")", "\n", "if", "output", ".", "size", "(", "1", ")", "<", "slen", ":", "# used for parallel", "\n", "                    ", "padding", "=", "Variable", "(", "output", ".", "data", ".", "new", "(", "1", ",", "1", ",", "1", ")", ".", "zero_", "(", ")", ")", "\n", "output", "=", "torch", ".", "cat", "(", "[", "output", ",", "padding", ".", "expand", "(", "output", ".", "size", "(", "0", ")", ",", "slen", "-", "output", ".", "size", "(", "1", ")", ",", "output", ".", "size", "(", "2", ")", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "", "if", "self", ".", "return_last", ":", "\n", "                ", "outputs", ".", "append", "(", "hidden", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ".", "append", "(", "output", ")", "\n", "", "", "if", "self", ".", "concat", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "2", ")", "\n", "", "return", "outputs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM.BiAttention.__init__": [[220, 227], ["torch.Module.__init__", "LSTM.LockedDropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "LockedDropout", "(", "dropout", ")", "\n", "self", ".", "input_linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "memory_linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "dot_scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ".", "uniform_", "(", "1.0", "/", "(", "input_size", "**", "0.5", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM.BiAttention.forward": [[228, 246], ["LSTM.BiAttention.dropout", "LSTM.BiAttention.dropout", "LSTM.BiAttention.input_linear", "LSTM.BiAttention.memory_linear().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "LSTM.BiAttention.size", "LSTM.BiAttention.size", "LSTM.BiAttention.size", "LSTM.BiAttention.permute().contiguous", "LSTM.BiAttention.memory_linear", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "LSTM.BiAttention.permute", "att.max"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "memory", ",", "mask", ")", ":", "\n", "        ", "bsz", ",", "input_len", ",", "memory_len", "=", "input", ".", "size", "(", "0", ")", ",", "input", ".", "size", "(", "1", ")", ",", "memory", ".", "size", "(", "1", ")", "\n", "\n", "input", "=", "self", ".", "dropout", "(", "input", ")", "\n", "memory", "=", "self", ".", "dropout", "(", "memory", ")", "\n", "\n", "input_dot", "=", "self", ".", "input_linear", "(", "input", ")", "\n", "memory_dot", "=", "self", ".", "memory_linear", "(", "memory", ")", ".", "view", "(", "bsz", ",", "1", ",", "memory_len", ")", "\n", "cross_dot", "=", "torch", ".", "bmm", "(", "input", "*", "self", ".", "dot_scale", ",", "memory", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", ")", "\n", "att", "=", "input_dot", "+", "memory_dot", "+", "cross_dot", "\n", "att", "=", "att", "-", "1e30", "*", "(", "1", "-", "mask", "[", ":", ",", "None", "]", ")", "\n", "\n", "weight_one", "=", "F", ".", "softmax", "(", "att", ",", "dim", "=", "-", "1", ")", "\n", "output_one", "=", "torch", ".", "bmm", "(", "weight_one", ",", "memory", ")", "\n", "weight_two", "=", "F", ".", "softmax", "(", "att", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "0", "]", ",", "dim", "=", "-", "1", ")", ".", "view", "(", "bsz", ",", "1", ",", "input_len", ")", "\n", "output_two", "=", "torch", ".", "bmm", "(", "weight_two", ",", "input", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "[", "input", ",", "output_one", ",", "input", "*", "output_one", ",", "output_two", "*", "output_one", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.MultiHeadedAttention.__init__": [[27, 37], ["torch.Module.__init__", "attention.clones", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__", "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.clones"], ["    ", "def", "__init__", "(", "self", ",", "h", ",", "d_model", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "\"Take in model size and number of heads.\"", "\n", "super", "(", "MultiHeadedAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "d_model", "%", "h", "==", "0", "\n", "# We assume d_v always equals d_k", "\n", "self", ".", "d_k", "=", "d_model", "//", "h", "\n", "self", ".", "h", "=", "h", "\n", "self", ".", "linears", "=", "clones", "(", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ")", ",", "4", ")", "\n", "self", ".", "attn", "=", "None", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.MultiHeadedAttention.forward": [[38, 58], ["query.size", "attention.attention", "x.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "mask.unsqueeze.unsqueeze.unsqueeze", "l().view().transpose", "zip", "x.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "l().view", "x.transpose().contiguous().view.transpose().contiguous().view.transpose", "l"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.attention"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"Implements Figure 2\"", "\n", "if", "mask", "is", "not", "None", ":", "\n", "# Same mask applied to all h heads.", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "", "nbatches", "=", "query", ".", "size", "(", "0", ")", "\n", "\n", "# 1) Do all the linear projections in batch from d_model => h x d_k", "\n", "query", ",", "key", ",", "value", "=", "[", "l", "(", "x", ")", ".", "view", "(", "nbatches", ",", "-", "1", ",", "self", ".", "h", ",", "self", ".", "d_k", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "for", "l", ",", "x", "in", "zip", "(", "self", ".", "linears", ",", "(", "query", ",", "key", ",", "value", ")", ")", "]", "\n", "\n", "# 2) Apply attention on all the projected vectors in batch.", "\n", "x", ",", "self", ".", "attn", "=", "attention", "(", "query", ",", "key", ",", "value", ",", "mask", "=", "mask", ",", "\n", "dropout", "=", "self", ".", "dropout", ")", "\n", "\n", "# 3) \"Concat\" using a view and apply a final linear.", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "nbatches", ",", "-", "1", ",", "self", ".", "h", "*", "self", ".", "d_k", ")", "\n", "return", "self", ".", "linears", "[", "-", "1", "]", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.PositionwiseFeedForward.__init__": [[61, 66], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "d_ff", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "PositionwiseFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_ff", ")", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_ff", ",", "d_model", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.PositionwiseFeedForward.forward": [[67, 69], ["attention.PositionwiseFeedForward.w_2", "attention.PositionwiseFeedForward.dropout", "torch.relu", "torch.relu", "torch.relu", "attention.PositionwiseFeedForward.w_1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "w_2", "(", "self", ".", "dropout", "(", "F", ".", "relu", "(", "self", ".", "w_1", "(", "x", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.PositionalEncoding.__init__": [[72, 85], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze().float", "torch.arange().unsqueeze().float", "torch.arange().unsqueeze().float", "torch.arange().unsqueeze().float", "torch.arange().unsqueeze().float", "torch.arange().unsqueeze().float", "torch.arange().unsqueeze().float", "torch.arange().unsqueeze().float", "torch.arange().unsqueeze().float", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "pe.unsqueeze.unsqueeze.unsqueeze", "attention.PositionalEncoding.register_buffer", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "math.log"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "dropout", ",", "max_len", "=", "5000", ")", ":", "\n", "        ", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n", "# Compute the positional encodings once in log space.", "\n", "pe", "=", "torch", ".", "zeros", "(", "max_len", ",", "d_model", ")", "\n", "position", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "unsqueeze", "(", "1", ")", ".", "float", "(", ")", "\n", "div_term", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "0", ",", "d_model", ",", "2", ")", ".", "float", "(", ")", "*", "\n", "-", "(", "math", ".", "log", "(", "10000.0", ")", "/", "d_model", ")", ")", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", "*", "div_term", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", "*", "div_term", ")", "\n", "pe", "=", "pe", ".", "unsqueeze", "(", "0", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.PositionalEncoding.forward": [[86, 90], ["attention.PositionalEncoding.dropout", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "Variable", "(", "self", ".", "pe", "[", ":", ",", ":", "x", ".", "size", "(", "1", ")", "]", ",", "\n", "requires_grad", "=", "False", ")", "\n", "return", "self", ".", "dropout", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.LayerNorm.__init__": [[93, 98], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["def", "__init__", "(", "self", ",", "features", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", "LayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "a_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "features", ")", ")", "\n", "self", ".", "b_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "features", ")", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.LayerNorm.forward": [[99, 103], ["x.mean", "x.std"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "mean", "=", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "std", "=", "x", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "self", ".", "a_2", "*", "(", "x", "-", "mean", ")", "/", "(", "std", "+", "self", ".", "eps", ")", "+", "self", ".", "b_2", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.SublayerConnection.__init__": [[109, 113], ["torch.Module.__init__", "attention.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["def", "__init__", "(", "self", ",", "size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "SublayerConnection", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm", "=", "LayerNorm", "(", "size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.SublayerConnection.forward": [[114, 117], ["attention.SublayerConnection.dropout", "sublayer", "attention.SublayerConnection.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "sublayer", ")", ":", "\n", "        ", "\"Apply residual connection to any sublayer with the same size.\"", "\n", "return", "x", "+", "self", ".", "dropout", "(", "sublayer", "(", "self", ".", "norm", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.EncoderLayer.__init__": [[120, 126], ["torch.Module.__init__", "attention.clones", "attention.SublayerConnection"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__", "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.clones"], ["def", "__init__", "(", "self", ",", "size", ",", "self_attn", ",", "feed_forward", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "EncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "self_attn", "\n", "self", ".", "feed_forward", "=", "feed_forward", "\n", "self", ".", "sublayer", "=", "clones", "(", "SublayerConnection", "(", "size", ",", "dropout", ")", ",", "2", ")", "\n", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.EncoderLayer.forward": [[127, 131], ["attention.EncoderLayer.self_attn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "\"Follow Figure 1 (left) for connections.\"", "\n", "x", "=", "self", ".", "sublayer", "[", "0", "]", "(", "x", ",", "lambda", "x", ":", "self", ".", "self_attn", "(", "x", ",", "x", ",", "x", ",", "mask", ")", ")", "\n", "return", "self", ".", "sublayer", "[", "1", "]", "(", "x", ",", "self", ".", "feed_forward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.Encoder.__init__": [[134, 138], ["torch.Module.__init__", "attention.clones", "attention.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__", "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.clones"], ["def", "__init__", "(", "self", ",", "layer", ",", "N", ")", ":", "\n", "        ", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "clones", "(", "layer", ",", "N", ")", "\n", "self", ".", "norm", "=", "LayerNorm", "(", "layer", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.Encoder.forward": [[139, 144], ["attention.Encoder.norm", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "\"Pass the input (and mask) through each layer in turn.\"", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ",", "mask", ")", "\n", "", "return", "self", ".", "norm", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.SimpleEncoder.__init__": [[150, 158], ["torch.Module.__init__", "attention.PositionalEncoding", "attention.MultiHeadedAttention", "attention.PositionwiseFeedForward", "attention.Encoder", "attention.EncoderLayer"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["def", "__init__", "(", "self", ",", "embed_dim", ",", "head", "=", "4", ",", "layer", "=", "1", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "SimpleEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "d_ff", "=", "2", "*", "embed_dim", "\n", "\n", "self", ".", "position", "=", "PositionalEncoding", "(", "embed_dim", ",", "dropout", ")", "\n", "attn", "=", "MultiHeadedAttention", "(", "head", ",", "embed_dim", ")", "\n", "ff", "=", "PositionwiseFeedForward", "(", "embed_dim", ",", "d_ff", ")", "\n", "self", ".", "encoder", "=", "Encoder", "(", "EncoderLayer", "(", "embed_dim", ",", "attn", ",", "ff", ",", "dropout", ")", ",", "layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.SimpleEncoder.forward": [[159, 164], ["mask.unsqueeze.unsqueeze.unsqueeze", "attention.SimpleEncoder.position", "attention.SimpleEncoder.encoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "mask", "=", "mask", ".", "unsqueeze", "(", "-", "2", ")", "\n", "x", "=", "self", ".", "position", "(", "x", ")", "\n", "x", "=", "self", ".", "encoder", "(", "x", ",", "mask", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.attention": [[8, 19], ["query.size", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "math.sqrt", "scores.masked_fill.masked_fill", "dropout", "torch.matmul", "torch.matmul", "torch.matmul", "key.transpose"], "function", ["None"], ["def", "attention", "(", "query", ",", "key", ",", "value", ",", "mask", "=", "None", ",", "dropout", "=", "None", ")", ":", "\n", "    ", "\"Compute 'Scaled Dot Product Attention'\"", "\n", "d_k", "=", "query", ".", "size", "(", "-", "1", ")", "\n", "scores", "=", "torch", ".", "matmul", "(", "query", ",", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "/", "math", ".", "sqrt", "(", "d_k", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "scores", "=", "scores", ".", "masked_fill", "(", "mask", "==", "0", ",", "-", "1e9", ")", "\n", "", "p_attn", "=", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "\n", "if", "dropout", "is", "not", "None", ":", "\n", "        ", "p_attn", "=", "dropout", "(", "p_attn", ")", "\n", "", "return", "torch", ".", "matmul", "(", "p_attn", ",", "value", ")", ",", "p_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.attention.clones": [[21, 24], ["torch.ModuleList", "copy.deepcopy", "range"], "function", ["None"], ["", "def", "clones", "(", "module", ",", "N", ")", ":", "\n", "    ", "\"Produce N identical layers.\"", "\n", "return", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "module", ")", "for", "_", "in", "range", "(", "N", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM_SP.LSTM_SP.__init__": [[15, 47], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "LSTM_SP.LSTM_SP.word_emb.weight.data.copy_", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "LSTM_SP.EncoderLSTM", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "LSTM_SP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "word_vec_size", "=", "config", ".", "data_word_vec", ".", "shape", "[", "0", "]", "\n", "self", ".", "word_emb", "=", "nn", ".", "Embedding", "(", "word_vec_size", ",", "config", ".", "data_word_vec", ".", "shape", "[", "1", "]", ")", "\n", "self", ".", "word_emb", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "config", ".", "data_word_vec", ")", ")", "\n", "self", ".", "word_emb", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n", "# char_size = config.data_char_vec.shape[0]", "\n", "# self.char_emb = nn.Embedding(char_size, config.data_char_vec.shape[1])", "\n", "# self.char_emb.weight.data.copy_(torch.from_numpy(config.data_char_vec))", "\n", "# char_dim = config.data_char_vec.shape[1]", "\n", "# char_hidden = 100", "\n", "# self.char_cnn = nn.Conv1d(char_dim,  char_hidden, 5)", "\n", "\n", "self", ".", "coref_embed", "=", "nn", ".", "Embedding", "(", "config", ".", "max_length", ",", "config", ".", "coref_size", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "ner_emb", "=", "nn", ".", "Embedding", "(", "7", ",", "config", ".", "entity_type_size", ",", "padding_idx", "=", "0", ")", "\n", "\n", "\n", "hidden_size", "=", "128", "\n", "input_size", "=", "config", ".", "data_word_vec", ".", "shape", "[", "1", "]", "+", "config", ".", "coref_size", "+", "config", ".", "entity_type_size", "# + char_hidden", "\n", "\n", "self", ".", "rnn", "=", "EncoderLSTM", "(", "input_size", ",", "hidden_size", ",", "1", ",", "True", ",", "True", ",", "1", "-", "config", ".", "keep_prob", ",", "False", ")", "\n", "\n", "self", ".", "relation_embed", "=", "nn", ".", "Embedding", "(", "config", ".", "relation_num", ",", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "\n", "\n", "self", ".", "linear_t", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", ",", "hidden_size", ")", "# *4 for 2layer", "\n", "# self.bili = torch.nn.Bilinear(hidden_size, hidden_size, hidden_size)", "\n", "\n", "self", ".", "linear_re", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "3", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM_SP.LSTM_SP.forward": [[49, 70], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sent_h_mapping.size", "LSTM_SP.LSTM_SP.relation_embed().unsqueeze().expand", "LSTM_SP.LSTM_SP.rnn", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "LSTM_SP.LSTM_SP.linear_re().squeeze", "LSTM_SP.LSTM_SP.linear_t", "LSTM_SP.LSTM_SP.word_emb", "LSTM_SP.LSTM_SP.coref_embed", "LSTM_SP.LSTM_SP.ner_emb", "LSTM_SP.LSTM_SP.relation_embed().unsqueeze", "LSTM_SP.LSTM_SP.linear_re", "LSTM_SP.LSTM_SP.relation_embed"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "context_idxs", ",", "pos", ",", "context_ner", ",", "context_char_idxs", ",", "context_lens", ",", "sent_h_mapping", ",", "sent_t_mapping", ",", "relation_label", ")", ":", "\n", "# para_size, char_size, bsz = context_idxs.size(1), context_char_idxs.size(2), context_idxs.size(0)", "\n", "# context_ch = self.char_emb(context_char_idxs.contiguous().view(-1, char_size)).view(bsz * para_size, char_size, -1)", "\n", "# context_ch = self.char_cnn(context_ch.permute(0, 2, 1).contiguous()).max(dim=-1)[0].view(bsz, para_size, -1)", "\n", "\n", "        ", "sent", "=", "torch", ".", "cat", "(", "[", "self", ".", "word_emb", "(", "context_idxs", ")", ",", "self", ".", "coref_embed", "(", "pos", ")", ",", "self", ".", "ner_emb", "(", "context_ner", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "el", "=", "sent_h_mapping", ".", "size", "(", "1", ")", "\n", "re_embed", "=", "(", "self", ".", "relation_embed", "(", "relation_label", ")", ".", "unsqueeze", "(", "1", ")", ")", ".", "expand", "(", "-", "1", ",", "el", ",", "-", "1", ")", "\n", "\n", "context_output", "=", "self", ".", "rnn", "(", "sent", ",", "context_lens", ")", "\n", "context_output", "=", "torch", ".", "relu", "(", "self", ".", "linear_t", "(", "context_output", ")", ")", "\n", "start_re_output", "=", "torch", ".", "matmul", "(", "sent_h_mapping", ",", "context_output", ")", "\n", "end_re_output", "=", "torch", ".", "matmul", "(", "sent_t_mapping", ",", "context_output", ")", "\n", "\n", "sent_output", "=", "torch", ".", "cat", "(", "[", "start_re_output", ",", "end_re_output", ",", "re_embed", "]", ",", "dim", "=", "-", "1", ")", "\n", "predict_sent", "=", "self", ".", "linear_re", "(", "sent_output", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "# predict_sent = torch.sum(self.bili(start_re_output, end_re_output)*re_embed, dim=-1)", "\n", "\n", "return", "predict_sent", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM_SP.LockedDropout.__init__": [[73, 76], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM_SP.LockedDropout.forward": [[77, 85], ["x.data.new().bernoulli_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "mask.expand_as.expand_as.expand_as", "x.data.new().bernoulli_.div_", "x.data.new", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "dropout", "=", "self", ".", "dropout", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "return", "x", "\n", "", "m", "=", "x", ".", "data", ".", "new", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "x", ".", "size", "(", "2", ")", ")", ".", "bernoulli_", "(", "1", "-", "dropout", ")", "\n", "mask", "=", "Variable", "(", "m", ".", "div_", "(", "1", "-", "dropout", ")", ",", "requires_grad", "=", "False", ")", "\n", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "return", "mask", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM_SP.EncoderRNN.__init__": [[87, 104], ["torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "LSTM_SP.LockedDropout", "LSTM_SP.EncoderRNN.rnns.append", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "num_units", ",", "nlayers", ",", "concat", ",", "bidir", ",", "dropout", ",", "return_last", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnns", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nlayers", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "input_size_", "=", "input_size", "\n", "output_size_", "=", "num_units", "\n", "", "else", ":", "\n", "                ", "input_size_", "=", "num_units", "if", "not", "bidir", "else", "num_units", "*", "2", "\n", "output_size_", "=", "num_units", "\n", "", "self", ".", "rnns", ".", "append", "(", "nn", ".", "GRU", "(", "input_size_", ",", "output_size_", ",", "1", ",", "bidirectional", "=", "bidir", ",", "batch_first", "=", "True", ")", ")", "\n", "", "self", ".", "rnns", "=", "nn", ".", "ModuleList", "(", "self", ".", "rnns", ")", "\n", "self", ".", "init_hidden", "=", "nn", ".", "ParameterList", "(", "[", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "2", "if", "bidir", "else", "1", ",", "1", ",", "num_units", ")", ".", "zero_", "(", ")", ")", "for", "_", "in", "range", "(", "nlayers", ")", "]", ")", "\n", "self", ".", "dropout", "=", "LockedDropout", "(", "dropout", ")", "\n", "self", ".", "concat", "=", "concat", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "return_last", "=", "return_last", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM_SP.EncoderRNN.reset_parameters": [[107, 114], ["torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "p.data.normal_", "p.data.zero_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "rnn", "in", "self", ".", "rnns", ":", "\n", "            ", "for", "name", ",", "p", "in", "rnn", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'weight'", "in", "name", ":", "\n", "                    ", "p", ".", "data", ".", "normal_", "(", "std", "=", "0.1", ")", "\n", "", "else", ":", "\n", "                    ", "p", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM_SP.EncoderRNN.get_init": [[115, 117], ["LSTM_SP.EncoderRNN.init_hidden[].expand().contiguous", "LSTM_SP.EncoderRNN.init_hidden[].expand"], "methods", ["None"], ["", "", "", "", "def", "get_init", "(", "self", ",", "bsz", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "init_hidden", "[", "i", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM_SP.EncoderRNN.forward": [[118, 145], ["range", "input.size", "input.size", "input_lengths.data.cpu().numpy", "LSTM_SP.EncoderRNN.get_init", "LSTM_SP.EncoderRNN.dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "outputs.append", "outputs.append", "input_lengths.data.cpu", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "LSTM_SP.EncoderRNN.permute().contiguous().view", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "LSTM_SP.EncoderRNN.permute().contiguous", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "LSTM_SP.EncoderRNN.permute"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.EncoderLSTM.get_init"], ["", "def", "forward", "(", "self", ",", "input", ",", "input_lengths", "=", "None", ")", ":", "\n", "        ", "bsz", ",", "slen", "=", "input", ".", "size", "(", "0", ")", ",", "input", ".", "size", "(", "1", ")", "\n", "output", "=", "input", "\n", "outputs", "=", "[", "]", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "            ", "lens", "=", "input_lengths", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "nlayers", ")", ":", "\n", "            ", "hidden", "=", "self", ".", "get_init", "(", "bsz", ",", "i", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "                ", "output", "=", "rnn", ".", "pack_padded_sequence", "(", "output", ",", "lens", ",", "batch_first", "=", "True", ")", "\n", "\n", "", "output", ",", "hidden", "=", "self", ".", "rnns", "[", "i", "]", "(", "output", ",", "hidden", ")", "\n", "\n", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "                ", "output", ",", "_", "=", "rnn", ".", "pad_packed_sequence", "(", "output", ",", "batch_first", "=", "True", ")", "\n", "if", "output", ".", "size", "(", "1", ")", "<", "slen", ":", "# used for parallel", "\n", "                    ", "padding", "=", "Variable", "(", "output", ".", "data", ".", "new", "(", "1", ",", "1", ",", "1", ")", ".", "zero_", "(", ")", ")", "\n", "output", "=", "torch", ".", "cat", "(", "[", "output", ",", "padding", ".", "expand", "(", "output", ".", "size", "(", "0", ")", ",", "slen", "-", "output", ".", "size", "(", "1", ")", ",", "output", ".", "size", "(", "2", ")", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "", "if", "self", ".", "return_last", ":", "\n", "                ", "outputs", ".", "append", "(", "hidden", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ".", "append", "(", "output", ")", "\n", "", "", "if", "self", ".", "concat", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "2", ")", "\n", "", "return", "outputs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM_SP.EncoderLSTM.__init__": [[150, 170], ["torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "LSTM_SP.LockedDropout", "LSTM_SP.EncoderLSTM.rnns.append", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "range", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "num_units", ",", "nlayers", ",", "concat", ",", "bidir", ",", "dropout", ",", "return_last", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnns", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nlayers", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "input_size_", "=", "input_size", "\n", "output_size_", "=", "num_units", "\n", "", "else", ":", "\n", "                ", "input_size_", "=", "num_units", "if", "not", "bidir", "else", "num_units", "*", "2", "\n", "output_size_", "=", "num_units", "\n", "", "self", ".", "rnns", ".", "append", "(", "nn", ".", "LSTM", "(", "input_size_", ",", "output_size_", ",", "1", ",", "bidirectional", "=", "bidir", ",", "batch_first", "=", "True", ")", ")", "\n", "", "self", ".", "rnns", "=", "nn", ".", "ModuleList", "(", "self", ".", "rnns", ")", "\n", "\n", "self", ".", "init_hidden", "=", "nn", ".", "ParameterList", "(", "[", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "2", "if", "bidir", "else", "1", ",", "1", ",", "num_units", ")", ".", "zero_", "(", ")", ")", "for", "_", "in", "range", "(", "nlayers", ")", "]", ")", "\n", "self", ".", "init_c", "=", "nn", ".", "ParameterList", "(", "[", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "2", "if", "bidir", "else", "1", ",", "1", ",", "num_units", ")", ".", "zero_", "(", ")", ")", "for", "_", "in", "range", "(", "nlayers", ")", "]", ")", "\n", "\n", "self", ".", "dropout", "=", "LockedDropout", "(", "dropout", ")", "\n", "self", ".", "concat", "=", "concat", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "return_last", "=", "return_last", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM_SP.EncoderLSTM.reset_parameters": [[173, 180], ["torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "p.data.normal_", "p.data.zero_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "rnn", "in", "self", ".", "rnns", ":", "\n", "            ", "for", "name", ",", "p", "in", "rnn", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'weight'", "in", "name", ":", "\n", "                    ", "p", ".", "data", ".", "normal_", "(", "std", "=", "0.1", ")", "\n", "", "else", ":", "\n", "                    ", "p", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM_SP.EncoderLSTM.get_init": [[181, 183], ["LSTM_SP.EncoderLSTM.init_hidden[].expand().contiguous", "LSTM_SP.EncoderLSTM.init_c[].expand().contiguous", "LSTM_SP.EncoderLSTM.init_hidden[].expand", "LSTM_SP.EncoderLSTM.init_c[].expand"], "methods", ["None"], ["", "", "", "", "def", "get_init", "(", "self", ",", "bsz", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "init_hidden", "[", "i", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", ".", "contiguous", "(", ")", ",", "self", ".", "init_c", "[", "i", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM_SP.EncoderLSTM.forward": [[184, 213], ["range", "input.size", "input.size", "input_lengths.data.cpu().numpy", "LSTM_SP.EncoderLSTM.get_init", "LSTM_SP.EncoderLSTM.dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "outputs.append", "outputs.append", "input_lengths.data.cpu", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "hidden.permute().contiguous().view", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "hidden.permute().contiguous", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "hidden.permute"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.EncoderLSTM.get_init"], ["", "def", "forward", "(", "self", ",", "input", ",", "input_lengths", "=", "None", ")", ":", "\n", "        ", "bsz", ",", "slen", "=", "input", ".", "size", "(", "0", ")", ",", "input", ".", "size", "(", "1", ")", "\n", "output", "=", "input", "\n", "outputs", "=", "[", "]", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "            ", "lens", "=", "input_lengths", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "nlayers", ")", ":", "\n", "            ", "hidden", ",", "c", "=", "self", ".", "get_init", "(", "bsz", ",", "i", ")", "\n", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "                ", "output", "=", "rnn", ".", "pack_padded_sequence", "(", "output", ",", "lens", ",", "batch_first", "=", "True", ")", "\n", "\n", "", "output", ",", "hidden", "=", "self", ".", "rnns", "[", "i", "]", "(", "output", ",", "(", "hidden", ",", "c", ")", ")", "\n", "\n", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "                ", "output", ",", "_", "=", "rnn", ".", "pad_packed_sequence", "(", "output", ",", "batch_first", "=", "True", ")", "\n", "if", "output", ".", "size", "(", "1", ")", "<", "slen", ":", "# used for parallel", "\n", "                    ", "padding", "=", "Variable", "(", "output", ".", "data", ".", "new", "(", "1", ",", "1", ",", "1", ")", ".", "zero_", "(", ")", ")", "\n", "output", "=", "torch", ".", "cat", "(", "[", "output", ",", "padding", ".", "expand", "(", "output", ".", "size", "(", "0", ")", ",", "slen", "-", "output", ".", "size", "(", "1", ")", ",", "output", ".", "size", "(", "2", ")", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "", "if", "self", ".", "return_last", ":", "\n", "                ", "outputs", ".", "append", "(", "hidden", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ".", "append", "(", "output", ")", "\n", "", "", "if", "self", ".", "concat", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "2", ")", "\n", "", "return", "outputs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM_SP.BiAttention.__init__": [[215, 222], ["torch.Module.__init__", "LSTM_SP.LockedDropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "LockedDropout", "(", "dropout", ")", "\n", "self", ".", "input_linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "memory_linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "dot_scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ".", "uniform_", "(", "1.0", "/", "(", "input_size", "**", "0.5", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.LSTM_SP.BiAttention.forward": [[223, 241], ["LSTM_SP.BiAttention.dropout", "LSTM_SP.BiAttention.dropout", "LSTM_SP.BiAttention.input_linear", "LSTM_SP.BiAttention.memory_linear().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "LSTM_SP.BiAttention.size", "LSTM_SP.BiAttention.size", "LSTM_SP.BiAttention.size", "LSTM_SP.BiAttention.permute().contiguous", "LSTM_SP.BiAttention.memory_linear", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "LSTM_SP.BiAttention.permute", "att.max"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "memory", ",", "mask", ")", ":", "\n", "        ", "bsz", ",", "input_len", ",", "memory_len", "=", "input", ".", "size", "(", "0", ")", ",", "input", ".", "size", "(", "1", ")", ",", "memory", ".", "size", "(", "1", ")", "\n", "\n", "input", "=", "self", ".", "dropout", "(", "input", ")", "\n", "memory", "=", "self", ".", "dropout", "(", "memory", ")", "\n", "\n", "input_dot", "=", "self", ".", "input_linear", "(", "input", ")", "\n", "memory_dot", "=", "self", ".", "memory_linear", "(", "memory", ")", ".", "view", "(", "bsz", ",", "1", ",", "memory_len", ")", "\n", "cross_dot", "=", "torch", ".", "bmm", "(", "input", "*", "self", ".", "dot_scale", ",", "memory", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", ")", "\n", "att", "=", "input_dot", "+", "memory_dot", "+", "cross_dot", "\n", "att", "=", "att", "-", "1e30", "*", "(", "1", "-", "mask", "[", ":", ",", "None", "]", ")", "\n", "\n", "weight_one", "=", "F", ".", "softmax", "(", "att", ",", "dim", "=", "-", "1", ")", "\n", "output_one", "=", "torch", ".", "bmm", "(", "weight_one", ",", "memory", ")", "\n", "weight_two", "=", "F", ".", "softmax", "(", "att", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "0", "]", ",", "dim", "=", "-", "1", ")", ".", "view", "(", "bsz", ",", "1", ",", "input_len", ")", "\n", "output_two", "=", "torch", ".", "bmm", "(", "weight_two", ",", "input", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "[", "input", ",", "output_one", ",", "input", "*", "output_one", ",", "output_two", "*", "output_one", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.BiLSTM.BiLSTM.__init__": [[18, 71], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "BiLSTM.BiLSTM.word_emb.weight.data.copy_", "BertModel.from_pretrained", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BiLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "word_vec_size", "=", "config", ".", "data_word_vec", ".", "shape", "[", "0", "]", "\n", "self", ".", "word_emb", "=", "nn", ".", "Embedding", "(", "word_vec_size", ",", "config", ".", "data_word_vec", ".", "shape", "[", "1", "]", ")", "\n", "self", ".", "word_emb", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "config", ".", "data_word_vec", ")", ")", "\n", "\n", "self", ".", "word_emb", ".", "weight", ".", "requires_grad", "=", "False", "\n", "self", ".", "use_entity_type", "=", "True", "\n", "self", ".", "use_coreference", "=", "True", "\n", "self", ".", "use_distance", "=", "True", "\n", "\n", "# performance is similar with char_embed", "\n", "# self.char_emb = nn.Embedding(config.data_char_vec.shape[0], config.data_char_vec.shape[1])", "\n", "# self.char_emb.weight.data.copy_(torch.from_numpy(config.data_char_vec))", "\n", "\n", "# char_dim = config.data_char_vec.shape[1]", "\n", "# char_hidden = 100", "\n", "# self.char_cnn = nn.Conv1d(char_dim,  char_hidden, 5)", "\n", "\n", "hidden_size", "=", "128", "\n", "#hidden_size = 768", "\n", "bert_hidden_size", "=", "768", "\n", "input_size", "=", "config", ".", "data_word_vec", ".", "shape", "[", "1", "]", "\n", "if", "self", ".", "use_entity_type", ":", "\n", "            ", "input_size", "+=", "config", ".", "entity_type_size", "\n", "self", ".", "ner_emb", "=", "nn", ".", "Embedding", "(", "7", ",", "config", ".", "entity_type_size", ",", "padding_idx", "=", "0", ")", "\n", "\n", "", "if", "self", ".", "use_coreference", ":", "\n", "            ", "input_size", "+=", "config", ".", "coref_size", "\n", "# self.coref_embed = nn.Embedding(config.max_length, config.coref_size, padding_idx=0)", "\n", "self", ".", "entity_embed", "=", "nn", ".", "Embedding", "(", "config", ".", "max_length", ",", "config", ".", "coref_size", ",", "padding_idx", "=", "0", ")", "\n", "\n", "# input_size += char_hidden", "\n", "\n", "", "self", ".", "input_size", "=", "input_size", "\n", "\n", "#self.rnn = EncoderLSTM(input_size, hidden_size, 1, True, True, 1 - config.keep_prob, False)", "\n", "#self.sent_rnn = EncoderLSTM(input_size, hidden_size, 1, True, True, 1 - config.keep_prob, False)", "\n", "#self.att_enc = SimpleEncoder(input_size, 4, 1)", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "'bert-base-uncased'", ")", "\n", "#self.linear_re = nn.Linear(bert_hidden_size+config.coref_size+config.entity_type_size, hidden_size)", "\n", "self", ".", "linear_re", "=", "nn", ".", "Linear", "(", "bert_hidden_size", ",", "hidden_size", ")", "\n", "#self.ent_att_enc = SimpleEncoder(hidden_size*2, 4, 1)", "\n", "\n", "if", "self", ".", "use_distance", ":", "\n", "            ", "self", ".", "dis_embed", "=", "nn", ".", "Embedding", "(", "20", ",", "config", ".", "dis_size", ",", "padding_idx", "=", "10", ")", "\n", "self", ".", "bili", "=", "torch", ".", "nn", ".", "Bilinear", "(", "hidden_size", "+", "config", ".", "dis_size", ",", "hidden_size", "+", "config", ".", "dis_size", ",", "config", ".", "relation_num", ")", "\n", "#self.linear_re = nn.Linear((hidden_size+config.dis_size)*2, config.relation_num)", "\n", "", "else", ":", "\n", "#self.linear_re = nn.Linear(hidden_size*2, config.relation_num)", "\n", "            ", "self", ".", "bili", "=", "torch", ".", "nn", ".", "Bilinear", "(", "hidden_size", ",", "hidden_size", ",", "config", ".", "relation_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.BiLSTM.BiLSTM.mask_lengths": [[72, 81], ["torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "torch.arange().expand().cuda", "index_matrix.long.long.long", "lengths.view", "lengths.view.expand", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["None"], ["", "", "def", "mask_lengths", "(", "self", ",", "batch_size", ",", "doc_size", ",", "lengths", ")", ":", "\n", "        ", "masks", "=", "torch", ".", "ones", "(", "batch_size", ",", "doc_size", ")", ".", "cuda", "(", ")", "\n", "index_matrix", "=", "torch", ".", "arange", "(", "0", ",", "doc_size", ")", ".", "expand", "(", "batch_size", ",", "-", "1", ")", ".", "cuda", "(", ")", "\n", "index_matrix", "=", "index_matrix", ".", "long", "(", ")", "\n", "#doc_lengths = torch.tensor(lengths).view(-1,1)", "\n", "doc_lengths", "=", "lengths", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "doc_lengths_matrix", "=", "doc_lengths", ".", "expand", "(", "-", "1", ",", "doc_size", ")", "\n", "masks", "[", "torch", ".", "ge", "(", "index_matrix", "-", "doc_lengths_matrix", ",", "0", ")", "]", "=", "0", "\n", "return", "masks", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.BiLSTM.BiLSTM.forward": [[82, 173], ["torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "BiLSTM.BiLSTM.linear_re", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "BiLSTM.BiLSTM.bert", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "BiLSTM.BiLSTM.bili", "BiLSTM.BiLSTM.bili", "zip", "starts.nonzero().squeeze", "context_idxs.size", "BiLSTM.BiLSTM.size", "BiLSTM.BiLSTM.dis_embed", "BiLSTM.BiLSTM.dis_embed", "starts.nonzero"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "context_idxs", ",", "pos", ",", "context_ner", ",", "context_char_idxs", ",", "context_lens", ",", "h_mapping", ",", "t_mapping", ",", "\n", "relation_mask", ",", "dis_h_2_t", ",", "dis_t_2_h", ",", "sent_idxs", ",", "sent_lengths", ",", "reverse_sent_idxs", ",", "context_masks", ",", "context_starts", ")", ":", "\n", "# para_size, char_size, bsz = context_idxs.size(1), context_char_idxs.size(2), context_idxs.size(0)", "\n", "# context_ch = self.char_emb(context_char_idxs.contiguous().view(-1, char_size)).view(bsz * para_size, char_size, -1)", "\n", "# context_ch = self.char_cnn(context_ch.permute(0, 2, 1).contiguous()).max(dim=-1)[0].view(bsz, para_size, -1)", "\n", "\n", "        ", "'''\n        sent = self.word_emb(context_idxs)\n        if self.use_coreference:\n            sent = torch.cat([sent, self.entity_embed(pos)], dim=-1)\n\n        if self.use_entity_type:\n            sent = torch.cat([sent, self.ner_emb(context_ner)], dim=-1)\n\n        batch_size, sent_limit, word_size = sent_idxs.size()\n        #print(batch_size, h_t_num, word_size)\n        i_ = torch.arange(batch_size).view(-1,1,1).expand(-1,sent_limit,word_size)\n        #print(i_[:5,:5,:5])\n        batch_sents = sent[i_, sent_idxs]\n        #print(batch_sents.size())\n        batch_sents = batch_sents.view(-1, word_size, self.input_size)\n        flatten_sents_lengths = sent_lengths.view(-1)\n        sent_emb = self.rnn(batch_sents, flatten_sents_lengths)\n        #print(sent_emb.size())\n        sent_emb = sent_emb.view(batch_size, sent_limit*word_size, -1)\n        i_ = torch.arange(batch_size).view(-1,1).expand(reverse_sent_idxs.size())\n        sent_emb = sent_emb[i_, reverse_sent_idxs]\n        '''", "\n", "\n", "# sent = torch.cat([sent, context_ch], dim=-1)", "\n", "#print(context_idxs.size())", "\n", "context_output", "=", "self", ".", "bert", "(", "context_idxs", ",", "attention_mask", "=", "context_masks", ")", "[", "0", "]", "\n", "#print('output_1',context_output[0])", "\n", "context_output", "=", "[", "layer", "[", "starts", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "]", "\n", "for", "layer", ",", "starts", "in", "zip", "(", "context_output", ",", "context_starts", ")", "]", "\n", "#print('output_2',context_output[0])", "\n", "context_output", "=", "pad_sequence", "(", "context_output", ",", "batch_first", "=", "True", ",", "padding_value", "=", "-", "1", ")", "\n", "#print('output_3',context_output[0])", "\n", "#print(context_output.size())", "\n", "context_output", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "context_output", ",", "(", "0", ",", "0", ",", "0", ",", "context_idxs", ".", "size", "(", "-", "1", ")", "-", "context_output", ".", "size", "(", "-", "2", ")", ")", ")", "\n", "#print('output_4',context_output[0])", "\n", "#print(context_output.size())", "\n", "#assert(False)", "\n", "#context_output = self.rnn(sent, context_lens)", "\n", "#context_output = torch.cat([context_output, sent_emb], dim=-1)", "\n", "#context_output = sent_emb", "\n", "\n", "'''\n        batch_size, doc_size = context_idxs.size()[:2]\n        mask = self.mask_lengths(batch_size, doc_size, context_lens)\n        context_output = self.att_enc(sent, mask)\n        '''", "\n", "\n", "'''\n        ent_mask = torch.zeros(context_idxs.size()[:2]).cuda()\n        ent_mask[pos>0] = 1\n        context_output = self.ent_att_enc(context_output, ent_mask)\n        '''", "\n", "\n", "#context_output = torch.relu(self.linear_re(context_output))", "\n", "#print('output_4',context_output[0])", "\n", "'''\n        if self.use_coreference:\n            context_output = torch.cat([context_output, self.entity_embed(pos)], dim=-1)\n\n        if self.use_entity_type:\n            context_output = torch.cat([context_output, self.ner_emb(context_ner)], dim=-1)\n        '''", "\n", "context_output", "=", "self", ".", "linear_re", "(", "context_output", ")", "\n", "\n", "\n", "start_re_output", "=", "torch", ".", "matmul", "(", "h_mapping", ",", "context_output", ")", "\n", "end_re_output", "=", "torch", ".", "matmul", "(", "t_mapping", ",", "context_output", ")", "\n", "\n", "\n", "if", "self", ".", "use_distance", ":", "\n", "            ", "s_rep", "=", "torch", ".", "cat", "(", "[", "start_re_output", ",", "self", ".", "dis_embed", "(", "dis_h_2_t", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "t_rep", "=", "torch", ".", "cat", "(", "[", "end_re_output", ",", "self", ".", "dis_embed", "(", "dis_t_2_h", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "#rep = torch.cat([s_rep, t_rep], dim=-1)", "\n", "#rep = s_rep - t_rep", "\n", "#predict_re = self.linear_re(rep)", "\n", "predict_re", "=", "self", ".", "bili", "(", "s_rep", ",", "t_rep", ")", "\n", "", "else", ":", "\n", "#rep = s_rep - t_rep", "\n", "#rep = torch.cat([s_rep, t_rep], dim=-1)", "\n", "#predict_re = self.linear_re(rep)", "\n", "            ", "predict_re", "=", "self", ".", "bili", "(", "start_re_output", ",", "end_re_output", ")", "\n", "\n", "#print(predict_re[0])", "\n", "\n", "", "return", "predict_re", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.BiLSTM.LockedDropout.__init__": [[176, 179], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.BiLSTM.LockedDropout.forward": [[180, 188], ["x.data.new().bernoulli_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "mask.expand_as.expand_as.expand_as", "x.data.new().bernoulli_.div_", "x.data.new", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "dropout", "=", "self", ".", "dropout", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "return", "x", "\n", "", "m", "=", "x", ".", "data", ".", "new", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "x", ".", "size", "(", "2", ")", ")", ".", "bernoulli_", "(", "1", "-", "dropout", ")", "\n", "mask", "=", "Variable", "(", "m", ".", "div_", "(", "1", "-", "dropout", ")", ",", "requires_grad", "=", "False", ")", "\n", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "return", "mask", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.BiLSTM.EncoderRNN.__init__": [[190, 207], ["torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "BiLSTM.LockedDropout", "BiLSTM.EncoderRNN.rnns.append", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "num_units", ",", "nlayers", ",", "concat", ",", "bidir", ",", "dropout", ",", "return_last", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnns", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nlayers", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "input_size_", "=", "input_size", "\n", "output_size_", "=", "num_units", "\n", "", "else", ":", "\n", "                ", "input_size_", "=", "num_units", "if", "not", "bidir", "else", "num_units", "*", "2", "\n", "output_size_", "=", "num_units", "\n", "", "self", ".", "rnns", ".", "append", "(", "nn", ".", "GRU", "(", "input_size_", ",", "output_size_", ",", "1", ",", "bidirectional", "=", "bidir", ",", "batch_first", "=", "True", ")", ")", "\n", "", "self", ".", "rnns", "=", "nn", ".", "ModuleList", "(", "self", ".", "rnns", ")", "\n", "self", ".", "init_hidden", "=", "nn", ".", "ParameterList", "(", "[", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "2", "if", "bidir", "else", "1", ",", "1", ",", "num_units", ")", ".", "zero_", "(", ")", ")", "for", "_", "in", "range", "(", "nlayers", ")", "]", ")", "\n", "self", ".", "dropout", "=", "LockedDropout", "(", "dropout", ")", "\n", "self", ".", "concat", "=", "concat", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "return_last", "=", "return_last", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.BiLSTM.EncoderRNN.reset_parameters": [[210, 217], ["torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "p.data.normal_", "p.data.zero_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "rnn", "in", "self", ".", "rnns", ":", "\n", "            ", "for", "name", ",", "p", "in", "rnn", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'weight'", "in", "name", ":", "\n", "                    ", "p", ".", "data", ".", "normal_", "(", "std", "=", "0.1", ")", "\n", "", "else", ":", "\n", "                    ", "p", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.BiLSTM.EncoderRNN.get_init": [[218, 220], ["BiLSTM.EncoderRNN.init_hidden[].expand().contiguous", "BiLSTM.EncoderRNN.init_hidden[].expand"], "methods", ["None"], ["", "", "", "", "def", "get_init", "(", "self", ",", "bsz", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "init_hidden", "[", "i", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.BiLSTM.EncoderRNN.forward": [[221, 248], ["range", "input.size", "input.size", "input_lengths.data.cpu().numpy", "BiLSTM.EncoderRNN.get_init", "BiLSTM.EncoderRNN.dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "outputs.append", "outputs.append", "input_lengths.data.cpu", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "BiLSTM.EncoderRNN.permute().contiguous().view", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "BiLSTM.EncoderRNN.permute().contiguous", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "BiLSTM.EncoderRNN.permute"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.EncoderLSTM.get_init"], ["", "def", "forward", "(", "self", ",", "input", ",", "input_lengths", "=", "None", ")", ":", "\n", "        ", "bsz", ",", "slen", "=", "input", ".", "size", "(", "0", ")", ",", "input", ".", "size", "(", "1", ")", "\n", "output", "=", "input", "\n", "outputs", "=", "[", "]", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "            ", "lens", "=", "input_lengths", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "nlayers", ")", ":", "\n", "            ", "hidden", "=", "self", ".", "get_init", "(", "bsz", ",", "i", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "                ", "output", "=", "rnn", ".", "pack_padded_sequence", "(", "output", ",", "lens", ",", "batch_first", "=", "True", ")", "\n", "\n", "", "output", ",", "hidden", "=", "self", ".", "rnns", "[", "i", "]", "(", "output", ",", "hidden", ")", "\n", "\n", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "                ", "output", ",", "_", "=", "rnn", ".", "pad_packed_sequence", "(", "output", ",", "batch_first", "=", "True", ")", "\n", "if", "output", ".", "size", "(", "1", ")", "<", "slen", ":", "# used for parallel", "\n", "                    ", "padding", "=", "Variable", "(", "output", ".", "data", ".", "new", "(", "1", ",", "1", ",", "1", ")", ".", "zero_", "(", ")", ")", "\n", "output", "=", "torch", ".", "cat", "(", "[", "output", ",", "padding", ".", "expand", "(", "output", ".", "size", "(", "0", ")", ",", "slen", "-", "output", ".", "size", "(", "1", ")", ",", "output", ".", "size", "(", "2", ")", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "", "if", "self", ".", "return_last", ":", "\n", "                ", "outputs", ".", "append", "(", "hidden", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ".", "append", "(", "output", ")", "\n", "", "", "if", "self", ".", "concat", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "2", ")", "\n", "", "return", "outputs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.BiLSTM.EncoderLSTM.__init__": [[253, 273], ["torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "BiLSTM.LockedDropout", "BiLSTM.EncoderLSTM.rnns.append", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "range", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "num_units", ",", "nlayers", ",", "concat", ",", "bidir", ",", "dropout", ",", "return_last", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnns", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nlayers", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "input_size_", "=", "input_size", "\n", "output_size_", "=", "num_units", "\n", "", "else", ":", "\n", "                ", "input_size_", "=", "num_units", "if", "not", "bidir", "else", "num_units", "*", "2", "\n", "output_size_", "=", "num_units", "\n", "", "self", ".", "rnns", ".", "append", "(", "nn", ".", "LSTM", "(", "input_size_", ",", "output_size_", ",", "1", ",", "bidirectional", "=", "bidir", ",", "batch_first", "=", "True", ")", ")", "\n", "", "self", ".", "rnns", "=", "nn", ".", "ModuleList", "(", "self", ".", "rnns", ")", "\n", "\n", "self", ".", "init_hidden", "=", "nn", ".", "ParameterList", "(", "[", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "2", "if", "bidir", "else", "1", ",", "1", ",", "num_units", ")", ".", "zero_", "(", ")", ")", "for", "_", "in", "range", "(", "nlayers", ")", "]", ")", "\n", "self", ".", "init_c", "=", "nn", ".", "ParameterList", "(", "[", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "2", "if", "bidir", "else", "1", ",", "1", ",", "num_units", ")", ".", "zero_", "(", ")", ")", "for", "_", "in", "range", "(", "nlayers", ")", "]", ")", "\n", "\n", "self", ".", "dropout", "=", "LockedDropout", "(", "dropout", ")", "\n", "self", ".", "concat", "=", "concat", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "return_last", "=", "return_last", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.BiLSTM.EncoderLSTM.reset_parameters": [[276, 283], ["torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "p.data.normal_", "p.data.zero_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "rnn", "in", "self", ".", "rnns", ":", "\n", "            ", "for", "name", ",", "p", "in", "rnn", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'weight'", "in", "name", ":", "\n", "                    ", "p", ".", "data", ".", "normal_", "(", "std", "=", "0.1", ")", "\n", "", "else", ":", "\n", "                    ", "p", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.BiLSTM.EncoderLSTM.get_init": [[284, 286], ["BiLSTM.EncoderLSTM.init_hidden[].expand().contiguous", "BiLSTM.EncoderLSTM.init_c[].expand().contiguous", "BiLSTM.EncoderLSTM.init_hidden[].expand", "BiLSTM.EncoderLSTM.init_c[].expand"], "methods", ["None"], ["", "", "", "", "def", "get_init", "(", "self", ",", "bsz", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "init_hidden", "[", "i", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", ".", "contiguous", "(", ")", ",", "self", ".", "init_c", "[", "i", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.BiLSTM.EncoderLSTM.forward": [[287, 324], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "range", "enumerate", "input.size", "input.size", "BiLSTM.EncoderLSTM.get_init", "BiLSTM.EncoderLSTM.dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "outputs.append", "outputs.append", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "hidden.permute().contiguous().view", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "hidden.permute().contiguous", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "hidden.permute"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.EncoderLSTM.get_init"], ["", "def", "forward", "(", "self", ",", "input", ",", "input_lengths", "=", "None", ")", ":", "\n", "        ", "lengths", "=", "torch", ".", "tensor", "(", "input_lengths", ")", "\n", "lens", ",", "indices", "=", "torch", ".", "sort", "(", "lengths", ",", "0", ",", "True", ")", "\n", "input", "=", "input", "[", "indices", "]", "\n", "_", ",", "_indices", "=", "torch", ".", "sort", "(", "indices", ",", "0", ")", "\n", "\n", "bsz", ",", "slen", "=", "input", ".", "size", "(", "0", ")", ",", "input", ".", "size", "(", "1", ")", "\n", "output", "=", "input", "\n", "outputs", "=", "[", "]", "\n", "#if input_lengths is not None:", "\n", "#    lens = input_lengths.data.cpu().numpy()", "\n", "lens", "[", "lens", "==", "0", "]", "=", "1", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "nlayers", ")", ":", "\n", "            ", "hidden", ",", "c", "=", "self", ".", "get_init", "(", "bsz", ",", "i", ")", "\n", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "                ", "output", "=", "rnn", ".", "pack_padded_sequence", "(", "output", ",", "lens", ",", "batch_first", "=", "True", ")", "\n", "\n", "", "output", ",", "(", "hidden", ",", "c", ")", "=", "self", ".", "rnns", "[", "i", "]", "(", "output", ",", "(", "hidden", ",", "c", ")", ")", "\n", "\n", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "                ", "output", ",", "_", "=", "rnn", ".", "pad_packed_sequence", "(", "output", ",", "batch_first", "=", "True", ")", "\n", "if", "output", ".", "size", "(", "1", ")", "<", "slen", ":", "# used for parallel", "\n", "                    ", "padding", "=", "Variable", "(", "output", ".", "data", ".", "new", "(", "1", ",", "1", ",", "1", ")", ".", "zero_", "(", ")", ")", "\n", "output", "=", "torch", ".", "cat", "(", "[", "output", ",", "padding", ".", "expand", "(", "output", ".", "size", "(", "0", ")", ",", "slen", "-", "output", ".", "size", "(", "1", ")", ",", "output", ".", "size", "(", "2", ")", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "", "if", "self", ".", "return_last", ":", "\n", "                ", "outputs", ".", "append", "(", "hidden", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ".", "append", "(", "output", ")", "\n", "", "", "for", "i", ",", "output", "in", "enumerate", "(", "outputs", ")", ":", "\n", "            ", "outputs", "[", "i", "]", "=", "output", "[", "_indices", "]", "\n", "", "if", "self", ".", "concat", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "-", "1", ")", "\n", "", "return", "outputs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.BiLSTM.BiAttention.__init__": [[326, 333], ["torch.Module.__init__", "BiLSTM.LockedDropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "LockedDropout", "(", "dropout", ")", "\n", "self", ".", "input_linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "memory_linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "dot_scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ".", "uniform_", "(", "1.0", "/", "(", "input_size", "**", "0.5", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.BiLSTM.BiAttention.forward": [[334, 352], ["BiLSTM.BiAttention.dropout", "BiLSTM.BiAttention.dropout", "BiLSTM.BiAttention.input_linear", "BiLSTM.BiAttention.memory_linear().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "BiLSTM.BiAttention.size", "BiLSTM.BiAttention.size", "BiLSTM.BiAttention.size", "BiLSTM.BiAttention.permute().contiguous", "BiLSTM.BiAttention.memory_linear", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "BiLSTM.BiAttention.permute", "att.max"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "memory", ",", "mask", ")", ":", "\n", "        ", "bsz", ",", "input_len", ",", "memory_len", "=", "input", ".", "size", "(", "0", ")", ",", "input", ".", "size", "(", "1", ")", ",", "memory", ".", "size", "(", "1", ")", "\n", "\n", "input", "=", "self", ".", "dropout", "(", "input", ")", "\n", "memory", "=", "self", ".", "dropout", "(", "memory", ")", "\n", "\n", "input_dot", "=", "self", ".", "input_linear", "(", "input", ")", "\n", "memory_dot", "=", "self", ".", "memory_linear", "(", "memory", ")", ".", "view", "(", "bsz", ",", "1", ",", "memory_len", ")", "\n", "cross_dot", "=", "torch", ".", "bmm", "(", "input", "*", "self", ".", "dot_scale", ",", "memory", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", ")", "\n", "att", "=", "input_dot", "+", "memory_dot", "+", "cross_dot", "\n", "att", "=", "att", "-", "1e30", "*", "(", "1", "-", "mask", "[", ":", ",", "None", "]", ")", "\n", "\n", "weight_one", "=", "F", ".", "softmax", "(", "att", ",", "dim", "=", "-", "1", ")", "\n", "output_one", "=", "torch", ".", "bmm", "(", "weight_one", ",", "memory", ")", "\n", "weight_two", "=", "F", ".", "softmax", "(", "att", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "0", "]", ",", "dim", "=", "-", "1", ")", ".", "view", "(", "bsz", ",", "1", ",", "input_len", ")", "\n", "output_two", "=", "torch", ".", "bmm", "(", "weight_two", ",", "input", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "[", "input", ",", "output_one", ",", "input", "*", "output_one", ",", "output_two", "*", "output_one", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.ContextAware.__init__": [[15, 48], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "ContextAware.ContextAware.word_emb.weight.data.copy_", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "ContextAware.EncoderLSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "ContextAware.SelfAttention", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.nn.Bilinear", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "ContextAware", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "word_emb", "=", "nn", ".", "Embedding", "(", "config", ".", "data_word_vec", ".", "shape", "[", "0", "]", ",", "config", ".", "data_word_vec", ".", "shape", "[", "1", "]", ")", "\n", "self", ".", "word_emb", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "config", ".", "data_word_vec", ")", ")", "\n", "self", ".", "word_emb", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n", "self", ".", "ner_emb", "=", "nn", ".", "Embedding", "(", "7", ",", "config", ".", "entity_type_size", ",", "padding_idx", "=", "0", ")", "\n", "\n", "self", ".", "coref_embed", "=", "nn", ".", "Embedding", "(", "config", ".", "max_length", ",", "config", ".", "coref_size", ",", "padding_idx", "=", "0", ")", "\n", "\n", "# self.char_emb = nn.Embedding(config.data_char_vec.shape[0], config.data_char_vec.shape[1])", "\n", "# self.char_emb.weight.data.copy_(torch.from_numpy(config.data_char_vec))", "\n", "# char_dim = config.data_char_vec.shape[1]", "\n", "# char_hidden = 100", "\n", "# self.char_cnn = nn.Conv1d(char_dim,  char_hidden, 5)", "\n", "\n", "hidden_size", "=", "128", "\n", "input_size", "=", "config", ".", "data_word_vec", ".", "shape", "[", "1", "]", "+", "config", ".", "coref_size", "+", "config", ".", "entity_type_size", "#+ char_hidden", "\n", "\n", "\n", "self", ".", "rnn", "=", "EncoderLSTM", "(", "input_size", ",", "hidden_size", ",", "1", ",", "True", ",", "True", ",", "1", "-", "config", ".", "keep_prob", ",", "False", ")", "\n", "\n", "\n", "self", ".", "linear_re", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", ",", "hidden_size", ")", "\n", "self", ".", "bili", "=", "torch", ".", "nn", ".", "Bilinear", "(", "hidden_size", ",", "hidden_size", ",", "hidden_size", ")", "\n", "\n", "self", ".", "self_att", "=", "SelfAttention", "(", "hidden_size", ",", "1.0", ")", "\n", "\n", "self", ".", "bili", "=", "torch", ".", "nn", ".", "Bilinear", "(", "hidden_size", "+", "config", ".", "dis_size", ",", "hidden_size", "+", "config", ".", "dis_size", ",", "hidden_size", ")", "\n", "self", ".", "dis_embed", "=", "nn", ".", "Embedding", "(", "20", ",", "config", ".", "dis_size", ",", "padding_idx", "=", "10", ")", "\n", "\n", "self", ".", "linear_output", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", ",", "config", ".", "relation_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.ContextAware.forward": [[50, 73], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ContextAware.ContextAware.rnn", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ContextAware.ContextAware.bili", "ContextAware.ContextAware.self_att", "ContextAware.ContextAware.linear_output", "ContextAware.ContextAware.linear_re", "ContextAware.ContextAware.word_emb", "ContextAware.ContextAware.coref_embed", "ContextAware.ContextAware.ner_emb", "ContextAware.ContextAware.dis_embed", "ContextAware.ContextAware.dis_embed"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "context_idxs", ",", "pos", ",", "context_ner", ",", "context_char_idxs", ",", "context_lens", ",", "h_mapping", ",", "t_mapping", ",", "relation_mask", ",", "dis_h_2_t", ",", "dis_t_2_h", ")", ":", "\n", "# para_size, char_size, bsz = context_idxs.size(1), context_char_idxs.size(2), context_idxs.size(0)", "\n", "# context_ch = self.char_emb(context_char_idxs.contiguous().view(-1, char_size)).view(bsz * para_size, char_size, -1)", "\n", "# context_ch = self.char_cnn(context_ch.permute(0, 2, 1).contiguous()).max(dim=-1)[0].view(bsz, para_size, -1)", "\n", "\n", "        ", "sent", "=", "torch", ".", "cat", "(", "[", "self", ".", "word_emb", "(", "context_idxs", ")", ",", "self", ".", "coref_embed", "(", "pos", ")", ",", "self", ".", "ner_emb", "(", "context_ner", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "context_output", "=", "self", ".", "rnn", "(", "sent", ",", "context_lens", ")", "\n", "\n", "\n", "context_output", "=", "torch", ".", "relu", "(", "self", ".", "linear_re", "(", "context_output", ")", ")", "\n", "\n", "start_re_output", "=", "torch", ".", "matmul", "(", "h_mapping", ",", "context_output", ")", "\n", "end_re_output", "=", "torch", ".", "matmul", "(", "t_mapping", ",", "context_output", ")", "\n", "\n", "s_rep", "=", "torch", ".", "cat", "(", "[", "start_re_output", ",", "self", ".", "dis_embed", "(", "dis_h_2_t", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "t_rep", "=", "torch", ".", "cat", "(", "[", "end_re_output", ",", "self", ".", "dis_embed", "(", "dis_t_2_h", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "\n", "re_rep", "=", "self", ".", "bili", "(", "s_rep", ",", "t_rep", ")", "\n", "re_rep", "=", "self", ".", "self_att", "(", "re_rep", ",", "re_rep", ",", "relation_mask", ")", "\n", "\n", "\n", "return", "self", ".", "linear_output", "(", "re_rep", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.LockedDropout.__init__": [[76, 79], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.LockedDropout.forward": [[80, 88], ["x.data.new().bernoulli_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "mask.expand_as.expand_as.expand_as", "x.data.new().bernoulli_.div_", "x.data.new", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "dropout", "=", "self", ".", "dropout", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "return", "x", "\n", "", "m", "=", "x", ".", "data", ".", "new", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "x", ".", "size", "(", "2", ")", ")", ".", "bernoulli_", "(", "1", "-", "dropout", ")", "\n", "mask", "=", "Variable", "(", "m", ".", "div_", "(", "1", "-", "dropout", ")", ",", "requires_grad", "=", "False", ")", "\n", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "return", "mask", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.EncoderRNN.__init__": [[90, 107], ["torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "ContextAware.LockedDropout", "ContextAware.EncoderRNN.rnns.append", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "num_units", ",", "nlayers", ",", "concat", ",", "bidir", ",", "dropout", ",", "return_last", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnns", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nlayers", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "input_size_", "=", "input_size", "\n", "output_size_", "=", "num_units", "\n", "", "else", ":", "\n", "                ", "input_size_", "=", "num_units", "if", "not", "bidir", "else", "num_units", "*", "2", "\n", "output_size_", "=", "num_units", "\n", "", "self", ".", "rnns", ".", "append", "(", "nn", ".", "GRU", "(", "input_size_", ",", "output_size_", ",", "1", ",", "bidirectional", "=", "bidir", ",", "batch_first", "=", "True", ")", ")", "\n", "", "self", ".", "rnns", "=", "nn", ".", "ModuleList", "(", "self", ".", "rnns", ")", "\n", "self", ".", "init_hidden", "=", "nn", ".", "ParameterList", "(", "[", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "2", "if", "bidir", "else", "1", ",", "1", ",", "num_units", ")", ".", "zero_", "(", ")", ")", "for", "_", "in", "range", "(", "nlayers", ")", "]", ")", "\n", "self", ".", "dropout", "=", "LockedDropout", "(", "dropout", ")", "\n", "self", ".", "concat", "=", "concat", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "return_last", "=", "return_last", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.EncoderRNN.reset_parameters": [[110, 117], ["torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "p.data.normal_", "p.data.zero_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "rnn", "in", "self", ".", "rnns", ":", "\n", "            ", "for", "name", ",", "p", "in", "rnn", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'weight'", "in", "name", ":", "\n", "                    ", "p", ".", "data", ".", "normal_", "(", "std", "=", "0.1", ")", "\n", "", "else", ":", "\n", "                    ", "p", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.EncoderRNN.get_init": [[118, 120], ["ContextAware.EncoderRNN.init_hidden[].expand().contiguous", "ContextAware.EncoderRNN.init_hidden[].expand"], "methods", ["None"], ["", "", "", "", "def", "get_init", "(", "self", ",", "bsz", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "init_hidden", "[", "i", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.EncoderRNN.forward": [[121, 148], ["range", "input.size", "input.size", "input_lengths.data.cpu().numpy", "ContextAware.EncoderRNN.get_init", "ContextAware.EncoderRNN.dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "outputs.append", "outputs.append", "input_lengths.data.cpu", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ContextAware.EncoderRNN.permute().contiguous().view", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "ContextAware.EncoderRNN.permute().contiguous", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "ContextAware.EncoderRNN.permute"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.EncoderLSTM.get_init"], ["", "def", "forward", "(", "self", ",", "input", ",", "input_lengths", "=", "None", ")", ":", "\n", "        ", "bsz", ",", "slen", "=", "input", ".", "size", "(", "0", ")", ",", "input", ".", "size", "(", "1", ")", "\n", "output", "=", "input", "\n", "outputs", "=", "[", "]", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "            ", "lens", "=", "input_lengths", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "nlayers", ")", ":", "\n", "            ", "hidden", "=", "self", ".", "get_init", "(", "bsz", ",", "i", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "                ", "output", "=", "rnn", ".", "pack_padded_sequence", "(", "output", ",", "lens", ",", "batch_first", "=", "True", ")", "\n", "\n", "", "output", ",", "hidden", "=", "self", ".", "rnns", "[", "i", "]", "(", "output", ",", "hidden", ")", "\n", "\n", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "                ", "output", ",", "_", "=", "rnn", ".", "pad_packed_sequence", "(", "output", ",", "batch_first", "=", "True", ")", "\n", "if", "output", ".", "size", "(", "1", ")", "<", "slen", ":", "# used for parallel", "\n", "                    ", "padding", "=", "Variable", "(", "output", ".", "data", ".", "new", "(", "1", ",", "1", ",", "1", ")", ".", "zero_", "(", ")", ")", "\n", "output", "=", "torch", ".", "cat", "(", "[", "output", ",", "padding", ".", "expand", "(", "output", ".", "size", "(", "0", ")", ",", "slen", "-", "output", ".", "size", "(", "1", ")", ",", "output", ".", "size", "(", "2", ")", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "", "if", "self", ".", "return_last", ":", "\n", "                ", "outputs", ".", "append", "(", "hidden", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ".", "append", "(", "output", ")", "\n", "", "", "if", "self", ".", "concat", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "2", ")", "\n", "", "return", "outputs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.EncoderLSTM.__init__": [[152, 172], ["torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "ContextAware.LockedDropout", "ContextAware.EncoderLSTM.rnns.append", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "range", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "num_units", ",", "nlayers", ",", "concat", ",", "bidir", ",", "dropout", ",", "return_last", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnns", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nlayers", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "input_size_", "=", "input_size", "\n", "output_size_", "=", "num_units", "\n", "", "else", ":", "\n", "                ", "input_size_", "=", "num_units", "if", "not", "bidir", "else", "num_units", "*", "2", "\n", "output_size_", "=", "num_units", "\n", "", "self", ".", "rnns", ".", "append", "(", "nn", ".", "LSTM", "(", "input_size_", ",", "output_size_", ",", "1", ",", "bidirectional", "=", "bidir", ",", "batch_first", "=", "True", ")", ")", "\n", "", "self", ".", "rnns", "=", "nn", ".", "ModuleList", "(", "self", ".", "rnns", ")", "\n", "\n", "self", ".", "init_hidden", "=", "nn", ".", "ParameterList", "(", "[", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "2", "if", "bidir", "else", "1", ",", "1", ",", "num_units", ")", ".", "zero_", "(", ")", ")", "for", "_", "in", "range", "(", "nlayers", ")", "]", ")", "\n", "self", ".", "init_c", "=", "nn", ".", "ParameterList", "(", "[", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "2", "if", "bidir", "else", "1", ",", "1", ",", "num_units", ")", ".", "zero_", "(", ")", ")", "for", "_", "in", "range", "(", "nlayers", ")", "]", ")", "\n", "\n", "self", ".", "dropout", "=", "LockedDropout", "(", "dropout", ")", "\n", "self", ".", "concat", "=", "concat", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "return_last", "=", "return_last", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.EncoderLSTM.reset_parameters": [[175, 182], ["torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "torch.nn.utils.rnn.named_parameters", "p.data.normal_", "p.data.zero_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "rnn", "in", "self", ".", "rnns", ":", "\n", "            ", "for", "name", ",", "p", "in", "rnn", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'weight'", "in", "name", ":", "\n", "                    ", "p", ".", "data", ".", "normal_", "(", "std", "=", "0.1", ")", "\n", "", "else", ":", "\n", "                    ", "p", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.EncoderLSTM.get_init": [[183, 185], ["ContextAware.EncoderLSTM.init_hidden[].expand().contiguous", "ContextAware.EncoderLSTM.init_c[].expand().contiguous", "ContextAware.EncoderLSTM.init_hidden[].expand", "ContextAware.EncoderLSTM.init_c[].expand"], "methods", ["None"], ["", "", "", "", "def", "get_init", "(", "self", ",", "bsz", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "init_hidden", "[", "i", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", ".", "contiguous", "(", ")", ",", "self", ".", "init_c", "[", "i", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.EncoderLSTM.forward": [[186, 215], ["range", "input.size", "input.size", "input_lengths.data.cpu().numpy", "ContextAware.EncoderLSTM.get_init", "ContextAware.EncoderLSTM.dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "outputs.append", "outputs.append", "input_lengths.data.cpu", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "hidden.permute().contiguous().view", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "hidden.permute().contiguous", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "hidden.permute"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.EncoderLSTM.get_init"], ["", "def", "forward", "(", "self", ",", "input", ",", "input_lengths", "=", "None", ")", ":", "\n", "        ", "bsz", ",", "slen", "=", "input", ".", "size", "(", "0", ")", ",", "input", ".", "size", "(", "1", ")", "\n", "output", "=", "input", "\n", "outputs", "=", "[", "]", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "            ", "lens", "=", "input_lengths", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "nlayers", ")", ":", "\n", "            ", "hidden", ",", "c", "=", "self", ".", "get_init", "(", "bsz", ",", "i", ")", "\n", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "                ", "output", "=", "rnn", ".", "pack_padded_sequence", "(", "output", ",", "lens", ",", "batch_first", "=", "True", ")", "\n", "\n", "", "output", ",", "hidden", "=", "self", ".", "rnns", "[", "i", "]", "(", "output", ",", "(", "hidden", ",", "c", ")", ")", "\n", "\n", "\n", "if", "input_lengths", "is", "not", "None", ":", "\n", "                ", "output", ",", "_", "=", "rnn", ".", "pad_packed_sequence", "(", "output", ",", "batch_first", "=", "True", ")", "\n", "if", "output", ".", "size", "(", "1", ")", "<", "slen", ":", "# used for parallel", "\n", "                    ", "padding", "=", "Variable", "(", "output", ".", "data", ".", "new", "(", "1", ",", "1", ",", "1", ")", ".", "zero_", "(", ")", ")", "\n", "output", "=", "torch", ".", "cat", "(", "[", "output", ",", "padding", ".", "expand", "(", "output", ".", "size", "(", "0", ")", ",", "slen", "-", "output", ".", "size", "(", "1", ")", ",", "output", ".", "size", "(", "2", ")", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "", "if", "self", ".", "return_last", ":", "\n", "                ", "outputs", ".", "append", "(", "hidden", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ".", "append", "(", "output", ")", "\n", "", "", "if", "self", ".", "concat", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "2", ")", "\n", "", "return", "outputs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.SelfAttention.__init__": [[217, 222], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# self.dropout = LockedDropout(dropout)", "\n", "self", ".", "input_linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "dot_scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ".", "uniform_", "(", "1.0", "/", "(", "input_size", "**", "0.5", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.SelfAttention.forward": [[223, 237], ["ContextAware.SelfAttention.input_linear", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "memory.permute().contiguous", "memory.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "memory", ",", "mask", ")", ":", "\n", "\n", "# input = self.dropout(input)", "\n", "# memory = self.dropout(memory)", "\n", "\n", "        ", "input_dot", "=", "self", ".", "input_linear", "(", "input", ")", "\n", "cross_dot", "=", "torch", ".", "bmm", "(", "input", "*", "self", ".", "dot_scale", ",", "memory", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", ")", "\n", "att", "=", "input_dot", "+", "cross_dot", "\n", "att", "=", "att", "-", "1e30", "*", "(", "1", "-", "mask", "[", ":", ",", "None", "]", ")", "\n", "\n", "weight_one", "=", "F", ".", "softmax", "(", "att", ",", "dim", "=", "-", "1", ")", "\n", "output_one", "=", "torch", ".", "bmm", "(", "weight_one", ",", "memory", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "[", "input", ",", "output_one", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__": [[240, 247], ["torch.Module.__init__", "ContextAware.LockedDropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor().uniform_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "LockedDropout", "(", "dropout", ")", "\n", "self", ".", "input_linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "memory_linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "dot_scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ".", "uniform_", "(", "1.0", "/", "(", "input_size", "**", "0.5", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hongwang600_DocRed.models.ContextAware.BiAttention.forward": [[248, 266], ["ContextAware.BiAttention.dropout", "ContextAware.BiAttention.dropout", "ContextAware.BiAttention.input_linear", "ContextAware.BiAttention.memory_linear().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ContextAware.BiAttention.size", "ContextAware.BiAttention.size", "ContextAware.BiAttention.size", "ContextAware.BiAttention.permute().contiguous", "ContextAware.BiAttention.memory_linear", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "ContextAware.BiAttention.permute", "att.max"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "memory", ",", "mask", ")", ":", "\n", "        ", "bsz", ",", "input_len", ",", "memory_len", "=", "input", ".", "size", "(", "0", ")", ",", "input", ".", "size", "(", "1", ")", ",", "memory", ".", "size", "(", "1", ")", "\n", "\n", "input", "=", "self", ".", "dropout", "(", "input", ")", "\n", "memory", "=", "self", ".", "dropout", "(", "memory", ")", "\n", "\n", "input_dot", "=", "self", ".", "input_linear", "(", "input", ")", "\n", "memory_dot", "=", "self", ".", "memory_linear", "(", "memory", ")", ".", "view", "(", "bsz", ",", "1", ",", "memory_len", ")", "\n", "cross_dot", "=", "torch", ".", "bmm", "(", "input", "*", "self", ".", "dot_scale", ",", "memory", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", ")", "\n", "att", "=", "input_dot", "+", "memory_dot", "+", "cross_dot", "\n", "att", "=", "att", "-", "1e30", "*", "(", "1", "-", "mask", "[", ":", ",", "None", "]", ")", "\n", "\n", "weight_one", "=", "F", ".", "softmax", "(", "att", ",", "dim", "=", "-", "1", ")", "\n", "output_one", "=", "torch", ".", "bmm", "(", "weight_one", ",", "memory", ")", "\n", "weight_two", "=", "F", ".", "softmax", "(", "att", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "0", "]", ",", "dim", "=", "-", "1", ")", ".", "view", "(", "bsz", ",", "1", ",", "input_len", ")", "\n", "output_two", "=", "torch", ".", "bmm", "(", "weight_two", ",", "input", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "[", "input", ",", "output_one", ",", "input", "*", "output_one", ",", "output_two", "*", "output_one", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "", ""]]}